
================================================= Mon Apr  1 06:43:46 AM UTC 2024 =========================================================

[2024-04-01 02:43:48,257] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:43:50,286] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2024-04-01 02:43:50,287] [INFO] [runner.py:573:main] cmd = /home/akane38/miniconda3/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/multi_ve_train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path /data/data1/akane/LLaVA/data/llava_v1_5_mix665k.json --image_folder /data/data1/akane/LLaVA/data --multiple_vision_towers openai/clip-vit-large-patch14-336 facebook/dinov2-large --pretrain_mm_mlp_adapter /data/data1/akane/pretrained/mm_projector_7b.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /data/data0/akane/multi-ve-shared-resampler-clip-dino-llava-pretrained-v1.5-7b/checkpoints --num_train_epochs 1 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 50 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --run_name multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it
[2024-04-01 02:43:52,542] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:43:54,162] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2024-04-01 02:43:54,163] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2024-04-01 02:43:54,163] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2024-04-01 02:43:54,163] [INFO] [launch.py:163:main] dist_world_size=2
[2024-04-01 02:43:54,163] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2024-04-01 02:43:57,577] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:43:57,730] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:43:58,683] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-01 02:43:58,683] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-04-01 02:43:58,989] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-04-01 02:44:05,613] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.33s/it]
[2024-04-01 02:44:16,860] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 682, num_elems = 7.04B
[2024-04-01 02:44:19,349] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1121, num_elems = 7.35B
MultiVELlavaLlamaForCausalLM(
  (model): MultiVELlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaFlashAttention2(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
    (multiple_vision_towers): ModuleList(
      (0): CLIPVisionTower(
        (vision_tower): CLIPVisionModel(
          (vision_model): CLIPVisionTransformer(
            (embeddings): CLIPVisionEmbeddings(
              (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
              (position_embedding): Embedding(577, 1024)
            )
            (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder): CLIPEncoder(
              (layers): ModuleList(
                (0-23): 24 x CLIPEncoderLayer(
                  (self_attn): CLIPAttention(
                    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  )
                  (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (mlp): CLIPMLP(
                    (activation_fn): QuickGELUActivation()
                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  )
                  (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DINOVisionTower(
        (vision_tower): Dinov2Model(
          (embeddings): Dinov2Embeddings(
            (patch_embeddings): Dinov2PatchEmbeddings(
              (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): Dinov2Encoder(
            (layer): ModuleList(
              (0-23): 24 x Dinov2Layer(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attention): Dinov2Attention(
                  (attention): Dinov2SelfAttention(
                    (query): Linear(in_features=1024, out_features=1024, bias=True)
                    (key): Linear(in_features=1024, out_features=1024, bias=True)
                    (value): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): Dinov2SelfOutput(
                    (dense): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (layer_scale1): Dinov2LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Dinov2MLP(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (activation): GELUActivation()
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_scale2): Dinov2LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (resampler): Resampler(
      (kv_proj): Identity()
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ln_q): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_kv): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_post): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    )
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)
trainable=26298368
frozen=65536
MultiVELlavaLlamaForCausalLM(
  (model): MultiVELlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaFlashAttention2(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
    (multiple_vision_towers): ModuleList(
      (0): CLIPVisionTower(
        (vision_tower): CLIPVisionModel(
          (vision_model): CLIPVisionTransformer(
            (embeddings): CLIPVisionEmbeddings(
              (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
              (position_embedding): Embedding(577, 1024)
            )
            (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder): CLIPEncoder(
              (layers): ModuleList(
                (0-23): 24 x CLIPEncoderLayer(
                  (self_attn): CLIPAttention(
                    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  )
                  (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (mlp): CLIPMLP(
                    (activation_fn): QuickGELUActivation()
                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  )
                  (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DINOVisionTower(
        (vision_tower): Dinov2Model(
          (embeddings): Dinov2Embeddings(
            (patch_embeddings): Dinov2PatchEmbeddings(
              (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): Dinov2Encoder(
            (layer): ModuleList(
              (0-23): 24 x Dinov2Layer(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attention): Dinov2Attention(
                  (attention): Dinov2SelfAttention(
                    (query): Linear(in_features=1024, out_features=1024, bias=True)
                    (key): Linear(in_features=1024, out_features=1024, bias=True)
                    (value): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): Dinov2SelfOutput(
                    (dense): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (layer_scale1): Dinov2LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Dinov2MLP(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (activation): GELUActivation()
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_scale2): Dinov2LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (resampler): Resampler(
      (kv_proj): Identity()
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ln_q): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_kv): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_post): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    )
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)
trainable=26298368
frozen=65536
Formatting inputs...Skip in lazy mode
/home/akane38/LLaVA/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/akane38/LLaVA/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Parameter Offload: Total persistent parameters: 983040 in 613 params
wandb: Currently logged in as: compyle. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/akane38/LLaVA/wandb/run-20240401_024452-dasan1t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it
wandb: ⭐️ View project at https://wandb.ai/compyle/multi-ve-llava
wandb: 🚀 View run at https://wandb.ai/compyle/multi-ve-llava/runs/dasan1t6
  0%|          | 0/10395 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/10395 [00:26<77:17:13, 26.77s/it]                                                    {'loss': 0.3125, 'learning_rate': 6.41025641025641e-08, 'epoch': 0.0}
  0%|          | 1/10395 [00:26<77:17:13, 26.77s/it]  0%|          | 2/10395 [00:34<45:08:36, 15.64s/it]                                                    {'loss': 1.6295, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.0}
  0%|          | 2/10395 [00:34<45:08:36, 15.64s/it]  0%|          | 3/10395 [00:42<34:56:47, 12.11s/it]                                                    {'loss': 1.479, 'learning_rate': 1.9230769230769234e-07, 'epoch': 0.0}
  0%|          | 3/10395 [00:42<34:56:47, 12.11s/it]  0%|          | 4/10395 [00:51<31:28:55, 10.91s/it]                                                    {'loss': 1.5864, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
  0%|          | 4/10395 [00:51<31:28:55, 10.91s/it]  0%|          | 5/10395 [00:59<28:43:38,  9.95s/it]                                                    {'loss': 1.4933, 'learning_rate': 3.205128205128205e-07, 'epoch': 0.0}
  0%|          | 5/10395 [00:59<28:43:38,  9.95s/it]  0%|          | 6/10395 [01:08<27:31:36,  9.54s/it]                                                    {'loss': 1.5774, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.0}
  0%|          | 6/10395 [01:08<27:31:36,  9.54s/it]  0%|          | 7/10395 [01:17<26:32:11,  9.20s/it]                                                    {'loss': 1.4567, 'learning_rate': 4.4871794871794876e-07, 'epoch': 0.0}
  0%|          | 7/10395 [01:17<26:32:11,  9.20s/it]  0%|          | 8/10395 [01:25<25:58:30,  9.00s/it]                                                    {'loss': 1.4756, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
  0%|          | 8/10395 [01:25<25:58:30,  9.00s/it]  0%|          | 9/10395 [01:33<25:20:00,  8.78s/it]                                                    {'loss': 1.4642, 'learning_rate': 5.76923076923077e-07, 'epoch': 0.0}
  0%|          | 9/10395 [01:33<25:20:00,  8.78s/it]  0%|          | 10/10395 [01:42<25:01:09,  8.67s/it]                                                     {'loss': 1.5539, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
  0%|          | 10/10395 [01:42<25:01:09,  8.67s/it]  0%|          | 11/10395 [01:50<24:53:57,  8.63s/it]                                                     {'loss': 1.5399, 'learning_rate': 7.051282051282052e-07, 'epoch': 0.0}
  0%|          | 11/10395 [01:50<24:53:57,  8.63s/it]  0%|          | 12/10395 [01:58<24:12:10,  8.39s/it]                                                     {'loss': 1.4284, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
  0%|          | 12/10395 [01:58<24:12:10,  8.39s/it]  0%|          | 13/10395 [02:07<24:28:09,  8.48s/it]                                                     {'loss': 1.4745, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.0}
  0%|          | 13/10395 [02:07<24:28:09,  8.48s/it]  0%|          | 14/10395 [02:15<24:05:24,  8.35s/it]                                                     {'loss': 1.4825, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.0}
  0%|          | 14/10395 [02:15<24:05:24,  8.35s/it]  0%|          | 15/10395 [02:24<24:15:22,  8.41s/it]                                                     {'loss': 1.4104, 'learning_rate': 9.615384615384617e-07, 'epoch': 0.0}
  0%|          | 15/10395 [02:24<24:15:22,  8.41s/it]  0%|          | 16/10395 [02:32<23:55:58,  8.30s/it]                                                     {'loss': 1.4038, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
  0%|          | 16/10395 [02:32<23:55:58,  8.30s/it]  0%|          | 17/10395 [02:40<23:46:03,  8.24s/it]                                                     {'loss': 1.471, 'learning_rate': 1.0897435897435899e-06, 'epoch': 0.0}
  0%|          | 17/10395 [02:40<23:46:03,  8.24s/it]  0%|          | 18/10395 [02:48<23:45:31,  8.24s/it]                                                     {'loss': 1.4128, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.0}
  0%|          | 18/10395 [02:48<23:45:31,  8.24s/it]  0%|          | 19/10395 [02:56<23:38:56,  8.21s/it]                                                     {'loss': 1.3745, 'learning_rate': 1.217948717948718e-06, 'epoch': 0.0}
  0%|          | 19/10395 [02:56<23:38:56,  8.21s/it][2024-04-01 02:47:57,424] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 272784
[2024-04-01 02:47:57,424] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 272785
[2024-04-01 02:47:58,125] [ERROR] [launch.py:321:sigkill_handler] ['/home/akane38/miniconda3/envs/llava/bin/python', '-u', 'llava/train/multi_ve_train_mem.py', '--local_rank=1', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', 'lmsys/vicuna-7b-v1.5', '--version', 'v1', '--data_path', '/data/data1/akane/LLaVA/data/llava_v1_5_mix665k.json', '--image_folder', '/data/data1/akane/LLaVA/data', '--multiple_vision_towers', 'openai/clip-vit-large-patch14-336', 'facebook/dinov2-large', '--pretrain_mm_mlp_adapter', '/data/data1/akane/pretrained/mm_projector_7b.bin', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/data/data0/akane/multi-ve-shared-resampler-clip-dino-llava-pretrained-v1.5-7b/checkpoints', '--num_train_epochs', '1', '--per_device_train_batch_size', '8', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb', '--run_name', 'multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it'] exits with return code = -15

================================================= Mon Apr  1 06:52:45 AM UTC 2024 =========================================================

[2024-04-01 02:52:47,028] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:52:49,168] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2024-04-01 02:52:49,168] [INFO] [runner.py:573:main] cmd = /home/akane38/miniconda3/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/multi_ve_train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path lmsys/vicuna-7b-v1.5 --version v1 --data_path /data/data1/akane/LLaVA/data/llava_v1_5_mix665k.json --image_folder /data/data1/akane/LLaVA/data --multiple_vision_towers openai/clip-vit-large-patch14-336 facebook/dinov2-large --pretrain_mm_mlp_adapter /data/data1/akane/pretrained/mm_projector_7b.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /data/data0/akane/multi-ve-shared-resampler-clip-dino-llava-pretrained-v1.5-7b/checkpoints --num_train_epochs 1 --per_device_train_batch_size 8 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 50 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --run_name multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it
[2024-04-01 02:52:51,074] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:52:52,566] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2024-04-01 02:52:52,566] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2024-04-01 02:52:52,566] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2024-04-01 02:52:52,566] [INFO] [launch.py:163:main] dist_world_size=2
[2024-04-01 02:52:52,566] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2024-04-01 02:52:55,960] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:52:55,961] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-04-01 02:52:57,047] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-01 02:52:57,150] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-04-01 02:52:57,150] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-04-01 02:53:04,678] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.77s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  4.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.53s/it]
[2024-04-01 02:53:16,244] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 682, num_elems = 7.04B
[2024-04-01 02:53:18,717] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 1121, num_elems = 7.35B
MultiVELlavaLlamaForCausalLM(
  (model): MultiVELlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaFlashAttention2(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
    (multiple_vision_towers): ModuleList(
      (0): CLIPVisionTower(
        (vision_tower): CLIPVisionModel(
          (vision_model): CLIPVisionTransformer(
            (embeddings): CLIPVisionEmbeddings(
              (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
              (position_embedding): Embedding(577, 1024)
            )
            (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder): CLIPEncoder(
              (layers): ModuleList(
                (0-23): 24 x CLIPEncoderLayer(
                  (self_attn): CLIPAttention(
                    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  )
                  (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (mlp): CLIPMLP(
                    (activation_fn): QuickGELUActivation()
                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  )
                  (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DINOVisionTower(
        (vision_tower): Dinov2Model(
          (embeddings): Dinov2Embeddings(
            (patch_embeddings): Dinov2PatchEmbeddings(
              (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): Dinov2Encoder(
            (layer): ModuleList(
              (0-23): 24 x Dinov2Layer(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attention): Dinov2Attention(
                  (attention): Dinov2SelfAttention(
                    (query): Linear(in_features=1024, out_features=1024, bias=True)
                    (key): Linear(in_features=1024, out_features=1024, bias=True)
                    (value): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): Dinov2SelfOutput(
                    (dense): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (layer_scale1): Dinov2LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Dinov2MLP(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (activation): GELUActivation()
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_scale2): Dinov2LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (resampler): Resampler(
      (kv_proj): Identity()
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ln_q): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_kv): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_post): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    )
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)
trainable=26298368
frozen=65536
MultiVELlavaLlamaForCausalLM(
  (model): MultiVELlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaFlashAttention2(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
    (multiple_vision_towers): ModuleList(
      (0): CLIPVisionTower(
        (vision_tower): CLIPVisionModel(
          (vision_model): CLIPVisionTransformer(
            (embeddings): CLIPVisionEmbeddings(
              (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
              (position_embedding): Embedding(577, 1024)
            )
            (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder): CLIPEncoder(
              (layers): ModuleList(
                (0-23): 24 x CLIPEncoderLayer(
                  (self_attn): CLIPAttention(
                    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
                    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
                  )
                  (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (mlp): CLIPMLP(
                    (activation_fn): QuickGELUActivation()
                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  )
                  (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                )
              )
            )
            (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DINOVisionTower(
        (vision_tower): Dinov2Model(
          (embeddings): Dinov2Embeddings(
            (patch_embeddings): Dinov2PatchEmbeddings(
              (projection): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
            )
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): Dinov2Encoder(
            (layer): ModuleList(
              (0-23): 24 x Dinov2Layer(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attention): Dinov2Attention(
                  (attention): Dinov2SelfAttention(
                    (query): Linear(in_features=1024, out_features=1024, bias=True)
                    (key): Linear(in_features=1024, out_features=1024, bias=True)
                    (value): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): Dinov2SelfOutput(
                    (dense): Linear(in_features=1024, out_features=1024, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (layer_scale1): Dinov2LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Dinov2MLP(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (activation): GELUActivation()
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                )
                (layer_scale2): Dinov2LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (layernorm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        )
      )
    )
    (resampler): Resampler(
      (kv_proj): Identity()
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ln_q): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_kv): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (ln_post): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    )
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)
trainable=26298368
frozen=65536
/home/akane38/LLaVA/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Formatting inputs...Skip in lazy mode
/home/akane38/LLaVA/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Parameter Offload: Total persistent parameters: 983040 in 613 params
wandb: Currently logged in as: compyle. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /home/akane38/LLaVA/wandb/run-20240401_025352-j0ubrpag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it
wandb: ⭐️ View project at https://wandb.ai/compyle/multi-ve-llava
wandb: 🚀 View run at https://wandb.ai/compyle/multi-ve-llava/runs/j0ubrpag
  0%|          | 0/10395 [00:00<?, ?it/s]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/10395 [00:26<76:21:10, 26.45s/it]                                                    {'loss': 0.3125, 'learning_rate': 6.41025641025641e-08, 'epoch': 0.0}
  0%|          | 1/10395 [00:26<76:21:10, 26.45s/it]  0%|          | 2/10395 [00:33<43:50:15, 15.18s/it]                                                    {'loss': 1.6262, 'learning_rate': 1.282051282051282e-07, 'epoch': 0.0}
  0%|          | 2/10395 [00:33<43:50:15, 15.18s/it]  0%|          | 3/10395 [00:41<33:28:04, 11.59s/it]                                                    {'loss': 1.4892, 'learning_rate': 1.9230769230769234e-07, 'epoch': 0.0}
  0%|          | 3/10395 [00:41<33:28:04, 11.59s/it]  0%|          | 4/10395 [00:49<30:02:13, 10.41s/it]                                                    {'loss': 1.6064, 'learning_rate': 2.564102564102564e-07, 'epoch': 0.0}
  0%|          | 4/10395 [00:49<30:02:13, 10.41s/it]  0%|          | 5/10395 [00:57<27:11:21,  9.42s/it]                                                    {'loss': 1.5012, 'learning_rate': 3.205128205128205e-07, 'epoch': 0.0}
  0%|          | 5/10395 [00:57<27:11:21,  9.42s/it]  0%|          | 6/10395 [01:05<25:56:41,  8.99s/it]                                                    {'loss': 1.5954, 'learning_rate': 3.846153846153847e-07, 'epoch': 0.0}
  0%|          | 6/10395 [01:05<25:56:41,  8.99s/it]  0%|          | 7/10395 [01:13<24:56:00,  8.64s/it]                                                    {'loss': 1.462, 'learning_rate': 4.4871794871794876e-07, 'epoch': 0.0}
  0%|          | 7/10395 [01:13<24:56:00,  8.64s/it]  0%|          | 8/10395 [01:21<24:22:33,  8.45s/it]                                                    {'loss': 1.4824, 'learning_rate': 5.128205128205128e-07, 'epoch': 0.0}
  0%|          | 8/10395 [01:21<24:22:33,  8.45s/it]  0%|          | 9/10395 [01:29<23:38:32,  8.19s/it]                                                    {'loss': 1.4726, 'learning_rate': 5.76923076923077e-07, 'epoch': 0.0}
  0%|          | 9/10395 [01:29<23:38:32,  8.19s/it]  0%|          | 10/10395 [01:36<23:15:42,  8.06s/it]                                                     {'loss': 1.5569, 'learning_rate': 6.41025641025641e-07, 'epoch': 0.0}
  0%|          | 10/10395 [01:36<23:15:42,  8.06s/it]  0%|          | 11/10395 [01:44<23:10:33,  8.03s/it]                                                     {'loss': 1.5424, 'learning_rate': 7.051282051282052e-07, 'epoch': 0.0}
  0%|          | 11/10395 [01:44<23:10:33,  8.03s/it]  0%|          | 12/10395 [01:52<22:30:57,  7.81s/it]                                                     {'loss': 1.4337, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
  0%|          | 12/10395 [01:52<22:30:57,  7.81s/it]  0%|          | 13/10395 [02:00<22:43:54,  7.88s/it]                                                     {'loss': 1.4973, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.0}
  0%|          | 13/10395 [02:00<22:43:54,  7.88s/it]  0%|          | 14/10395 [02:07<22:20:00,  7.74s/it]                                                     {'loss': 1.4943, 'learning_rate': 8.974358974358975e-07, 'epoch': 0.0}
  0%|          | 14/10395 [02:07<22:20:00,  7.74s/it]  0%|          | 15/10395 [02:15<22:40:09,  7.86s/it]                                                     {'loss': 1.4241, 'learning_rate': 9.615384615384617e-07, 'epoch': 0.0}
  0%|          | 15/10395 [02:15<22:40:09,  7.86s/it]  0%|          | 16/10395 [02:23<22:14:28,  7.71s/it]                                                     {'loss': 1.4228, 'learning_rate': 1.0256410256410257e-06, 'epoch': 0.0}
  0%|          | 16/10395 [02:23<22:14:28,  7.71s/it]  0%|          | 17/10395 [02:30<22:01:54,  7.64s/it]                                                     {'loss': 1.482, 'learning_rate': 1.0897435897435899e-06, 'epoch': 0.0}
  0%|          | 17/10395 [02:30<22:01:54,  7.64s/it]  0%|          | 18/10395 [02:38<22:01:12,  7.64s/it]                                                     {'loss': 1.4185, 'learning_rate': 1.153846153846154e-06, 'epoch': 0.0}
  0%|          | 18/10395 [02:38<22:01:12,  7.64s/it]  0%|          | 19/10395 [02:45<21:55:02,  7.60s/it]                                                     {'loss': 1.3832, 'learning_rate': 1.217948717948718e-06, 'epoch': 0.0}
  0%|          | 19/10395 [02:45<21:55:02,  7.60s/it]  0%|          | 20/10395 [02:52<21:28:41,  7.45s/it]                                                     {'loss': 1.4501, 'learning_rate': 1.282051282051282e-06, 'epoch': 0.0}
  0%|          | 20/10395 [02:52<21:28:41,  7.45s/it]  0%|          | 21/10395 [03:00<21:59:52,  7.63s/it]                                                     {'loss': 1.3669, 'learning_rate': 1.3461538461538462e-06, 'epoch': 0.0}
  0%|          | 21/10395 [03:00<21:59:52,  7.63s/it]  0%|          | 22/10395 [03:09<22:32:27,  7.82s/it]                                                     {'loss': 1.3053, 'learning_rate': 1.4102564102564104e-06, 'epoch': 0.0}
  0%|          | 22/10395 [03:09<22:32:27,  7.82s/it]  0%|          | 23/10395 [03:16<22:32:34,  7.82s/it]                                                     {'loss': 1.3407, 'learning_rate': 1.4743589743589745e-06, 'epoch': 0.0}
  0%|          | 23/10395 [03:16<22:32:34,  7.82s/it]  0%|          | 24/10395 [03:25<22:51:53,  7.94s/it]                                                     {'loss': 1.3915, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}
  0%|          | 24/10395 [03:25<22:51:53,  7.94s/it]  0%|          | 25/10395 [03:34<23:51:18,  8.28s/it]                                                     {'loss': 1.3406, 'learning_rate': 1.602564102564103e-06, 'epoch': 0.0}
  0%|          | 25/10395 [03:34<23:51:18,  8.28s/it]  0%|          | 26/10395 [03:42<23:32:13,  8.17s/it]                                                     {'loss': 1.2551, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.0}
  0%|          | 26/10395 [03:42<23:32:13,  8.17s/it]  0%|          | 27/10395 [03:49<22:58:11,  7.98s/it]                                                     {'loss': 1.2334, 'learning_rate': 1.7307692307692308e-06, 'epoch': 0.0}
  0%|          | 27/10395 [03:49<22:58:11,  7.98s/it]  0%|          | 28/10395 [03:57<23:15:26,  8.08s/it]                                                     {'loss': 1.3057, 'learning_rate': 1.794871794871795e-06, 'epoch': 0.0}
  0%|          | 28/10395 [03:58<23:15:26,  8.08s/it]  0%|          | 29/10395 [04:05<22:39:02,  7.87s/it]                                                     {'loss': 1.2501, 'learning_rate': 1.8589743589743592e-06, 'epoch': 0.0}
  0%|          | 29/10395 [04:05<22:39:02,  7.87s/it]  0%|          | 30/10395 [04:13<22:48:35,  7.92s/it]                                                     {'loss': 1.2274, 'learning_rate': 1.9230769230769234e-06, 'epoch': 0.0}
  0%|          | 30/10395 [04:13<22:48:35,  7.92s/it]  0%|          | 31/10395 [04:21<22:49:25,  7.93s/it]                                                     {'loss': 1.2351, 'learning_rate': 1.987179487179487e-06, 'epoch': 0.0}
  0%|          | 31/10395 [04:21<22:49:25,  7.93s/it]  0%|          | 32/10395 [04:28<22:22:28,  7.77s/it]                                                     {'loss': 1.2521, 'learning_rate': 2.0512820512820513e-06, 'epoch': 0.0}
  0%|          | 32/10395 [04:28<22:22:28,  7.77s/it]  0%|          | 33/10395 [04:36<22:37:22,  7.86s/it]                                                     {'loss': 1.2456, 'learning_rate': 2.1153846153846155e-06, 'epoch': 0.0}
  0%|          | 33/10395 [04:36<22:37:22,  7.86s/it]  0%|          | 34/10395 [04:44<22:07:37,  7.69s/it]                                                     {'loss': 1.3577, 'learning_rate': 2.1794871794871797e-06, 'epoch': 0.0}
  0%|          | 34/10395 [04:44<22:07:37,  7.69s/it]  0%|          | 35/10395 [04:51<22:10:48,  7.71s/it]                                                     {'loss': 1.2642, 'learning_rate': 2.243589743589744e-06, 'epoch': 0.0}
  0%|          | 35/10395 [04:51<22:10:48,  7.71s/it]  0%|          | 36/10395 [05:00<22:32:41,  7.83s/it]                                                     {'loss': 1.2076, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.0}
  0%|          | 36/10395 [05:00<22:32:41,  7.83s/it]  0%|          | 37/10395 [05:07<22:37:46,  7.87s/it]                                                     {'loss': 1.2314, 'learning_rate': 2.371794871794872e-06, 'epoch': 0.0}
  0%|          | 37/10395 [05:07<22:37:46,  7.87s/it]  0%|          | 38/10395 [05:16<22:47:19,  7.92s/it]                                                     {'loss': 1.2542, 'learning_rate': 2.435897435897436e-06, 'epoch': 0.0}
  0%|          | 38/10395 [05:16<22:47:19,  7.92s/it]  0%|          | 39/10395 [05:25<23:45:27,  8.26s/it]                                                     {'loss': 1.1151, 'learning_rate': 2.5e-06, 'epoch': 0.0}
  0%|          | 39/10395 [05:25<23:45:27,  8.26s/it]  0%|          | 40/10395 [05:32<23:15:03,  8.08s/it]                                                     {'loss': 1.1996, 'learning_rate': 2.564102564102564e-06, 'epoch': 0.0}
  0%|          | 40/10395 [05:32<23:15:03,  8.08s/it]  0%|          | 41/10395 [05:40<22:40:50,  7.89s/it]                                                     {'loss': 1.195, 'learning_rate': 2.6282051282051286e-06, 'epoch': 0.0}
  0%|          | 41/10395 [05:40<22:40:50,  7.89s/it]  0%|          | 42/10395 [05:57<31:14:40, 10.86s/it]                                                     {'loss': 0.3055, 'learning_rate': 2.6923076923076923e-06, 'epoch': 0.0}
  0%|          | 42/10395 [05:57<31:14:40, 10.86s/it]  0%|          | 43/10395 [06:05<28:24:17,  9.88s/it]                                                     {'loss': 1.2368, 'learning_rate': 2.756410256410257e-06, 'epoch': 0.0}
  0%|          | 43/10395 [06:05<28:24:17,  9.88s/it]  0%|          | 44/10395 [06:13<26:31:34,  9.23s/it]                                                     {'loss': 1.0909, 'learning_rate': 2.8205128205128207e-06, 'epoch': 0.0}
  0%|          | 44/10395 [06:13<26:31:34,  9.23s/it]  0%|          | 45/10395 [06:21<25:33:55,  8.89s/it]                                                     {'loss': 1.1273, 'learning_rate': 2.8846153846153845e-06, 'epoch': 0.0}
  0%|          | 45/10395 [06:21<25:33:55,  8.89s/it]  0%|          | 46/10395 [06:29<24:45:48,  8.61s/it]                                                     {'loss': 1.1377, 'learning_rate': 2.948717948717949e-06, 'epoch': 0.0}
  0%|          | 46/10395 [06:29<24:45:48,  8.61s/it]  0%|          | 47/10395 [06:47<33:05:37, 11.51s/it]                                                     {'loss': 0.3157, 'learning_rate': 3.012820512820513e-06, 'epoch': 0.0}
  0%|          | 47/10395 [06:47<33:05:37, 11.51s/it]  0%|          | 48/10395 [06:55<29:52:07, 10.39s/it]                                                     {'loss': 1.1498, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.0}
  0%|          | 48/10395 [06:55<29:52:07, 10.39s/it]  0%|          | 49/10395 [07:02<27:17:37,  9.50s/it]                                                     {'loss': 1.1849, 'learning_rate': 3.141025641025641e-06, 'epoch': 0.0}
  0%|          | 49/10395 [07:02<27:17:37,  9.50s/it]  0%|          | 50/10395 [07:10<25:31:21,  8.88s/it]                                                     {'loss': 1.1143, 'learning_rate': 3.205128205128206e-06, 'epoch': 0.0}
  0%|          | 50/10395 [07:10<25:31:21,  8.88s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 51/10395 [08:45<100:02:17, 34.82s/it]                                                      {'loss': 1.1603, 'learning_rate': 3.2692307692307696e-06, 'epoch': 0.0}
  0%|          | 51/10395 [08:45<100:02:17, 34.82s/it]  1%|          | 52/10395 [08:53<76:30:49, 26.63s/it]                                                      {'loss': 1.1777, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
  1%|          | 52/10395 [08:53<76:30:49, 26.63s/it]  1%|          | 53/10395 [09:00<59:53:36, 20.85s/it]                                                     {'loss': 1.1075, 'learning_rate': 3.397435897435898e-06, 'epoch': 0.01}
  1%|          | 53/10395 [09:00<59:53:36, 20.85s/it]  1%|          | 54/10395 [09:08<48:45:07, 16.97s/it]                                                     {'loss': 1.1076, 'learning_rate': 3.4615384615384617e-06, 'epoch': 0.01}
  1%|          | 54/10395 [09:08<48:45:07, 16.97s/it]  1%|          | 55/10395 [09:15<40:30:18, 14.10s/it]                                                     {'loss': 1.1331, 'learning_rate': 3.5256410256410263e-06, 'epoch': 0.01}
  1%|          | 55/10395 [09:15<40:30:18, 14.10s/it]  1%|          | 56/10395 [09:25<36:18:05, 12.64s/it]                                                     {'loss': 1.0259, 'learning_rate': 3.58974358974359e-06, 'epoch': 0.01}
  1%|          | 56/10395 [09:25<36:18:05, 12.64s/it]  1%|          | 57/10395 [09:32<31:33:02, 10.99s/it]                                                     {'loss': 1.098, 'learning_rate': 3.653846153846154e-06, 'epoch': 0.01}
  1%|          | 57/10395 [09:32<31:33:02, 10.99s/it]  1%|          | 58/10395 [09:39<28:32:11,  9.94s/it]                                                     {'loss': 1.2075, 'learning_rate': 3.7179487179487184e-06, 'epoch': 0.01}
  1%|          | 58/10395 [09:39<28:32:11,  9.94s/it]  1%|          | 59/10395 [09:49<28:10:44,  9.81s/it]                                                     {'loss': 1.1387, 'learning_rate': 3.782051282051282e-06, 'epoch': 0.01}
  1%|          | 59/10395 [09:49<28:10:44,  9.81s/it]  1%|          | 60/10395 [09:56<25:58:04,  9.05s/it]                                                     {'loss': 1.1971, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.01}
  1%|          | 60/10395 [09:56<25:58:04,  9.05s/it]  1%|          | 61/10395 [10:03<24:35:40,  8.57s/it]                                                     {'loss': 1.1141, 'learning_rate': 3.910256410256411e-06, 'epoch': 0.01}
  1%|          | 61/10395 [10:03<24:35:40,  8.57s/it]  1%|          | 62/10395 [10:11<24:12:01,  8.43s/it]                                                     {'loss': 1.1916, 'learning_rate': 3.974358974358974e-06, 'epoch': 0.01}
  1%|          | 62/10395 [10:11<24:12:01,  8.43s/it]  1%|          | 63/10395 [10:20<24:10:52,  8.43s/it]                                                     {'loss': 1.1414, 'learning_rate': 4.0384615384615385e-06, 'epoch': 0.01}
  1%|          | 63/10395 [10:20<24:10:52,  8.43s/it]  1%|          | 64/10395 [10:28<23:34:54,  8.22s/it]                                                     {'loss': 1.0572, 'learning_rate': 4.102564102564103e-06, 'epoch': 0.01}
  1%|          | 64/10395 [10:28<23:34:54,  8.22s/it]  1%|          | 65/10395 [10:35<23:00:46,  8.02s/it]                                                     {'loss': 1.1656, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.01}
  1%|          | 65/10395 [10:35<23:00:46,  8.02s/it]  1%|          | 66/10395 [10:43<22:32:34,  7.86s/it]                                                     {'loss': 1.1138, 'learning_rate': 4.230769230769231e-06, 'epoch': 0.01}
  1%|          | 66/10395 [10:43<22:32:34,  7.86s/it]  1%|          | 67/10395 [10:50<22:17:36,  7.77s/it]                                                     {'loss': 1.1403, 'learning_rate': 4.294871794871795e-06, 'epoch': 0.01}
  1%|          | 67/10395 [10:50<22:17:36,  7.77s/it]  1%|          | 68/10395 [10:58<22:02:16,  7.68s/it]                                                     {'loss': 1.0909, 'learning_rate': 4.358974358974359e-06, 'epoch': 0.01}
  1%|          | 68/10395 [10:58<22:02:16,  7.68s/it]  1%|          | 69/10395 [11:05<21:50:39,  7.62s/it]                                                     {'loss': 1.1404, 'learning_rate': 4.423076923076924e-06, 'epoch': 0.01}
  1%|          | 69/10395 [11:05<21:50:39,  7.62s/it]  1%|          | 70/10395 [11:13<22:11:13,  7.74s/it]                                                     {'loss': 1.1792, 'learning_rate': 4.487179487179488e-06, 'epoch': 0.01}
  1%|          | 70/10395 [11:13<22:11:13,  7.74s/it]  1%|          | 71/10395 [11:21<22:30:35,  7.85s/it]                                                     {'loss': 1.081, 'learning_rate': 4.551282051282052e-06, 'epoch': 0.01}
  1%|          | 71/10395 [11:21<22:30:35,  7.85s/it]  1%|          | 72/10395 [11:29<22:47:24,  7.95s/it]                                                     {'loss': 1.0979, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.01}
  1%|          | 72/10395 [11:29<22:47:24,  7.95s/it]  1%|          | 73/10395 [11:37<22:14:29,  7.76s/it]                                                     {'loss': 1.128, 'learning_rate': 4.6794871794871795e-06, 'epoch': 0.01}
  1%|          | 73/10395 [11:37<22:14:29,  7.76s/it]  1%|          | 74/10395 [11:45<22:27:32,  7.83s/it]                                                     {'loss': 1.0924, 'learning_rate': 4.743589743589744e-06, 'epoch': 0.01}
  1%|          | 74/10395 [11:45<22:27:32,  7.83s/it]  1%|          | 75/10395 [11:52<22:09:30,  7.73s/it]                                                     {'loss': 1.073, 'learning_rate': 4.807692307692308e-06, 'epoch': 0.01}
  1%|          | 75/10395 [11:52<22:09:30,  7.73s/it]  1%|          | 76/10395 [12:00<21:54:35,  7.64s/it]                                                     {'loss': 1.1378, 'learning_rate': 4.871794871794872e-06, 'epoch': 0.01}
  1%|          | 76/10395 [12:00<21:54:35,  7.64s/it]  1%|          | 77/10395 [12:08<22:32:19,  7.86s/it]                                                     {'loss': 1.1577, 'learning_rate': 4.935897435897436e-06, 'epoch': 0.01}
  1%|          | 77/10395 [12:08<22:32:19,  7.86s/it]  1%|          | 78/10395 [12:15<21:58:15,  7.67s/it]                                                     {'loss': 1.1906, 'learning_rate': 5e-06, 'epoch': 0.01}
  1%|          | 78/10395 [12:15<21:58:15,  7.67s/it]  1%|          | 79/10395 [12:23<21:51:52,  7.63s/it]                                                     {'loss': 1.0853, 'learning_rate': 5.064102564102565e-06, 'epoch': 0.01}
  1%|          | 79/10395 [12:23<21:51:52,  7.63s/it]  1%|          | 80/10395 [12:30<21:51:52,  7.63s/it]                                                     {'loss': 1.0957, 'learning_rate': 5.128205128205128e-06, 'epoch': 0.01}
  1%|          | 80/10395 [12:30<21:51:52,  7.63s/it]  1%|          | 81/10395 [12:38<21:31:24,  7.51s/it]                                                     {'loss': 1.1296, 'learning_rate': 5.192307692307693e-06, 'epoch': 0.01}
  1%|          | 81/10395 [12:38<21:31:24,  7.51s/it]  1%|          | 82/10395 [12:45<21:34:22,  7.53s/it]                                                     {'loss': 1.0936, 'learning_rate': 5.256410256410257e-06, 'epoch': 0.01}
  1%|          | 82/10395 [12:45<21:34:22,  7.53s/it]  1%|          | 83/10395 [12:53<21:22:49,  7.46s/it]                                                     {'loss': 1.1308, 'learning_rate': 5.320512820512821e-06, 'epoch': 0.01}
  1%|          | 83/10395 [12:53<21:22:49,  7.46s/it]  1%|          | 84/10395 [13:02<22:41:01,  7.92s/it]                                                     {'loss': 1.0374, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.01}
  1%|          | 84/10395 [13:02<22:41:01,  7.92s/it]  1%|          | 85/10395 [13:10<22:41:23,  7.92s/it]                                                     {'loss': 1.091, 'learning_rate': 5.448717948717949e-06, 'epoch': 0.01}
  1%|          | 85/10395 [13:10<22:41:23,  7.92s/it]  1%|          | 86/10395 [13:17<22:30:47,  7.86s/it]                                                     {'loss': 1.1127, 'learning_rate': 5.512820512820514e-06, 'epoch': 0.01}
  1%|          | 86/10395 [13:17<22:30:47,  7.86s/it]  1%|          | 87/10395 [13:36<31:55:39, 11.15s/it]                                                     {'loss': 0.3618, 'learning_rate': 5.576923076923077e-06, 'epoch': 0.01}
  1%|          | 87/10395 [13:36<31:55:39, 11.15s/it]  1%|          | 88/10395 [13:44<29:01:46, 10.14s/it]                                                     {'loss': 1.0343, 'learning_rate': 5.641025641025641e-06, 'epoch': 0.01}
  1%|          | 88/10395 [13:44<29:01:46, 10.14s/it]  1%|          | 89/10395 [13:52<27:19:15,  9.54s/it]                                                     {'loss': 1.135, 'learning_rate': 5.705128205128206e-06, 'epoch': 0.01}
  1%|          | 89/10395 [13:52<27:19:15,  9.54s/it]  1%|          | 90/10395 [14:00<26:12:15,  9.15s/it]                                                     {'loss': 1.0776, 'learning_rate': 5.769230769230769e-06, 'epoch': 0.01}
  1%|          | 90/10395 [14:00<26:12:15,  9.15s/it]  1%|          | 91/10395 [14:08<24:56:44,  8.72s/it]                                                     {'loss': 1.0663, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.01}
  1%|          | 91/10395 [14:08<24:56:44,  8.72s/it]  1%|          | 92/10395 [14:16<24:15:15,  8.47s/it]                                                     {'loss': 1.0425, 'learning_rate': 5.897435897435898e-06, 'epoch': 0.01}
  1%|          | 92/10395 [14:16<24:15:15,  8.47s/it]  1%|          | 93/10395 [14:24<23:38:30,  8.26s/it]                                                     {'loss': 1.0568, 'learning_rate': 5.961538461538462e-06, 'epoch': 0.01}
  1%|          | 93/10395 [14:24<23:38:30,  8.26s/it]  1%|          | 94/10395 [14:32<23:43:07,  8.29s/it]                                                     {'loss': 1.0906, 'learning_rate': 6.025641025641026e-06, 'epoch': 0.01}
  1%|          | 94/10395 [14:32<23:43:07,  8.29s/it]  1%|          | 95/10395 [14:40<23:11:52,  8.11s/it]                                                     {'loss': 1.0344, 'learning_rate': 6.08974358974359e-06, 'epoch': 0.01}
  1%|          | 95/10395 [14:40<23:11:52,  8.11s/it]  1%|          | 96/10395 [14:48<23:09:33,  8.10s/it]                                                     {'loss': 1.1267, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.01}
  1%|          | 96/10395 [14:48<23:09:33,  8.10s/it]  1%|          | 97/10395 [14:55<22:30:14,  7.87s/it]                                                     {'loss': 1.0282, 'learning_rate': 6.217948717948718e-06, 'epoch': 0.01}
  1%|          | 97/10395 [14:55<22:30:14,  7.87s/it]  1%|          | 98/10395 [15:03<22:22:19,  7.82s/it]                                                     {'loss': 1.1551, 'learning_rate': 6.282051282051282e-06, 'epoch': 0.01}
  1%|          | 98/10395 [15:03<22:22:19,  7.82s/it]  1%|          | 99/10395 [15:10<21:54:07,  7.66s/it]                                                     {'loss': 1.0728, 'learning_rate': 6.3461538461538466e-06, 'epoch': 0.01}
  1%|          | 99/10395 [15:10<21:54:07,  7.66s/it]  1%|          | 100/10395 [15:18<21:48:21,  7.63s/it]                                                      {'loss': 1.0904, 'learning_rate': 6.410256410256412e-06, 'epoch': 0.01}
  1%|          | 100/10395 [15:18<21:48:21,  7.63s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  1%|          | 101/10395 [16:59<102:05:44, 35.70s/it]                                                       {'loss': 1.0308, 'learning_rate': 6.474358974358975e-06, 'epoch': 0.01}
  1%|          | 101/10395 [16:59<102:05:44, 35.70s/it]  1%|          | 102/10395 [17:06<77:59:32, 27.28s/it]                                                       {'loss': 1.1635, 'learning_rate': 6.538461538461539e-06, 'epoch': 0.01}
  1%|          | 102/10395 [17:06<77:59:32, 27.28s/it]  1%|          | 103/10395 [17:14<61:02:16, 21.35s/it]                                                      {'loss': 1.0364, 'learning_rate': 6.602564102564103e-06, 'epoch': 0.01}
  1%|          | 103/10395 [17:14<61:02:16, 21.35s/it]  1%|          | 104/10395 [17:22<49:22:10, 17.27s/it]                                                      {'loss': 1.1201, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
  1%|          | 104/10395 [17:22<49:22:10, 17.27s/it]  1%|          | 105/10395 [17:29<41:00:34, 14.35s/it]                                                      {'loss': 1.1614, 'learning_rate': 6.730769230769232e-06, 'epoch': 0.01}
  1%|          | 105/10395 [17:29<41:00:34, 14.35s/it]  1%|          | 106/10395 [17:36<34:51:41, 12.20s/it]                                                      {'loss': 1.0456, 'learning_rate': 6.794871794871796e-06, 'epoch': 0.01}
  1%|          | 106/10395 [17:36<34:51:41, 12.20s/it]  1%|          | 107/10395 [17:47<33:16:46, 11.65s/it]                                                      {'loss': 0.9902, 'learning_rate': 6.858974358974359e-06, 'epoch': 0.01}
  1%|          | 107/10395 [17:47<33:16:46, 11.65s/it]  1%|          | 108/10395 [17:55<30:00:34, 10.50s/it]                                                      {'loss': 1.0652, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.01}
  1%|          | 108/10395 [17:55<30:00:34, 10.50s/it]  1%|          | 109/10395 [18:02<27:46:41,  9.72s/it]                                                      {'loss': 1.0731, 'learning_rate': 6.9871794871794876e-06, 'epoch': 0.01}
  1%|          | 109/10395 [18:03<27:46:41,  9.72s/it]  1%|          | 110/10395 [18:10<25:33:04,  8.94s/it]                                                      {'loss': 1.0336, 'learning_rate': 7.051282051282053e-06, 'epoch': 0.01}
  1%|          | 110/10395 [18:10<25:33:04,  8.94s/it]  1%|          | 111/10395 [18:18<25:16:23,  8.85s/it]                                                      {'loss': 1.0141, 'learning_rate': 7.115384615384616e-06, 'epoch': 0.01}
  1%|          | 111/10395 [18:18<25:16:23,  8.85s/it]  1%|          | 112/10395 [18:27<25:12:36,  8.83s/it]                                                      {'loss': 1.0508, 'learning_rate': 7.17948717948718e-06, 'epoch': 0.01}
  1%|          | 112/10395 [18:27<25:12:36,  8.83s/it]  1%|          | 113/10395 [18:35<24:32:25,  8.59s/it]                                                      {'loss': 0.9495, 'learning_rate': 7.243589743589744e-06, 'epoch': 0.01}
  1%|          | 113/10395 [18:35<24:32:25,  8.59s/it]  1%|          | 114/10395 [18:42<23:20:45,  8.17s/it]                                                      {'loss': 1.0299, 'learning_rate': 7.307692307692308e-06, 'epoch': 0.01}
  1%|          | 114/10395 [18:42<23:20:45,  8.17s/it]  1%|          | 115/10395 [18:50<22:48:29,  7.99s/it]                                                      {'loss': 1.0037, 'learning_rate': 7.371794871794873e-06, 'epoch': 0.01}
  1%|          | 115/10395 [18:50<22:48:29,  7.99s/it]  1%|          | 116/10395 [18:58<22:47:18,  7.98s/it]                                                      {'loss': 1.0618, 'learning_rate': 7.435897435897437e-06, 'epoch': 0.01}
  1%|          | 116/10395 [18:58<22:47:18,  7.98s/it]  1%|          | 117/10395 [19:05<22:14:18,  7.79s/it]                                                      {'loss': 1.0448, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.01}
  1%|          | 117/10395 [19:05<22:14:18,  7.79s/it]  1%|          | 118/10395 [19:13<22:00:28,  7.71s/it]                                                      {'loss': 1.0188, 'learning_rate': 7.564102564102564e-06, 'epoch': 0.01}
  1%|          | 118/10395 [19:13<22:00:28,  7.71s/it]  1%|          | 119/10395 [19:20<21:55:01,  7.68s/it]                                                      {'loss': 1.1522, 'learning_rate': 7.6282051282051286e-06, 'epoch': 0.01}
  1%|          | 119/10395 [19:20<21:55:01,  7.68s/it]  1%|          | 120/10395 [19:28<21:57:39,  7.69s/it]                                                      {'loss': 1.0564, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.01}
  1%|          | 120/10395 [19:28<21:57:39,  7.69s/it]  1%|          | 121/10395 [19:36<22:08:05,  7.76s/it]                                                      {'loss': 1.1586, 'learning_rate': 7.756410256410258e-06, 'epoch': 0.01}
  1%|          | 121/10395 [19:36<22:08:05,  7.76s/it]  1%|          | 122/10395 [19:43<21:49:19,  7.65s/it]                                                      {'loss': 0.963, 'learning_rate': 7.820512820512822e-06, 'epoch': 0.01}
  1%|          | 122/10395 [19:43<21:49:19,  7.65s/it]  1%|          | 123/10395 [19:51<21:42:57,  7.61s/it]                                                      {'loss': 1.1059, 'learning_rate': 7.884615384615384e-06, 'epoch': 0.01}
  1%|          | 123/10395 [19:51<21:42:57,  7.61s/it]  1%|          | 124/10395 [19:58<21:27:49,  7.52s/it]                                                      {'loss': 1.1198, 'learning_rate': 7.948717948717949e-06, 'epoch': 0.01}
  1%|          | 124/10395 [19:58<21:27:49,  7.52s/it]  1%|          | 125/10395 [20:07<22:42:25,  7.96s/it]                                                      {'loss': 1.0262, 'learning_rate': 8.012820512820515e-06, 'epoch': 0.01}
  1%|          | 125/10395 [20:07<22:42:25,  7.96s/it]  1%|          | 126/10395 [20:25<31:05:52, 10.90s/it]                                                      {'loss': 0.3995, 'learning_rate': 8.076923076923077e-06, 'epoch': 0.01}
  1%|          | 126/10395 [20:25<31:05:52, 10.90s/it]  1%|          | 127/10395 [20:33<28:49:08, 10.10s/it]                                                      {'loss': 1.0629, 'learning_rate': 8.141025641025641e-06, 'epoch': 0.01}
  1%|          | 127/10395 [20:33<28:49:08, 10.10s/it]  1%|          | 128/10395 [20:41<27:01:31,  9.48s/it]                                                      {'loss': 1.0966, 'learning_rate': 8.205128205128205e-06, 'epoch': 0.01}
  1%|          | 128/10395 [20:41<27:01:31,  9.48s/it]  1%|          | 129/10395 [20:48<25:11:47,  8.84s/it]                                                      {'loss': 1.0946, 'learning_rate': 8.26923076923077e-06, 'epoch': 0.01}
  1%|          | 129/10395 [20:48<25:11:47,  8.84s/it]  1%|▏         | 130/10395 [20:57<24:31:27,  8.60s/it]                                                      {'loss': 1.0699, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.01}
  1%|▏         | 130/10395 [20:57<24:31:27,  8.60s/it]  1%|▏         | 131/10395 [21:05<24:07:23,  8.46s/it]                                                      {'loss': 0.9564, 'learning_rate': 8.397435897435898e-06, 'epoch': 0.01}
  1%|▏         | 131/10395 [21:05<24:07:23,  8.46s/it]  1%|▏         | 132/10395 [21:21<30:50:25, 10.82s/it]                                                      {'loss': 0.3342, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.01}
  1%|▏         | 132/10395 [21:21<30:50:25, 10.82s/it]  1%|▏         | 133/10395 [21:29<28:03:11,  9.84s/it]                                                      {'loss': 1.1407, 'learning_rate': 8.525641025641026e-06, 'epoch': 0.01}
  1%|▏         | 133/10395 [21:29<28:03:11,  9.84s/it]  1%|▏         | 134/10395 [21:37<26:53:14,  9.43s/it]                                                      {'loss': 1.0781, 'learning_rate': 8.58974358974359e-06, 'epoch': 0.01}
  1%|▏         | 134/10395 [21:37<26:53:14,  9.43s/it]  1%|▏         | 135/10395 [21:45<25:38:56,  9.00s/it]                                                      {'loss': 1.0209, 'learning_rate': 8.653846153846155e-06, 'epoch': 0.01}
  1%|▏         | 135/10395 [21:45<25:38:56,  9.00s/it]  1%|▏         | 136/10395 [21:53<24:34:33,  8.62s/it]                                                      {'loss': 1.0063, 'learning_rate': 8.717948717948719e-06, 'epoch': 0.01}
  1%|▏         | 136/10395 [21:53<24:34:33,  8.62s/it]  1%|▏         | 137/10395 [22:01<23:57:04,  8.41s/it]                                                      {'loss': 0.9861, 'learning_rate': 8.782051282051283e-06, 'epoch': 0.01}
  1%|▏         | 137/10395 [22:01<23:57:04,  8.41s/it]  1%|▏         | 138/10395 [22:08<23:22:13,  8.20s/it]                                                      {'loss': 1.0173, 'learning_rate': 8.846153846153847e-06, 'epoch': 0.01}
  1%|▏         | 138/10395 [22:08<23:22:13,  8.20s/it]  1%|▏         | 139/10395 [22:16<23:10:04,  8.13s/it]                                                      {'loss': 1.0446, 'learning_rate': 8.910256410256411e-06, 'epoch': 0.01}
  1%|▏         | 139/10395 [22:16<23:10:04,  8.13s/it]  1%|▏         | 140/10395 [22:23<22:19:52,  7.84s/it]                                                      {'loss': 1.0343, 'learning_rate': 8.974358974358976e-06, 'epoch': 0.01}
  1%|▏         | 140/10395 [22:24<22:19:52,  7.84s/it]  1%|▏         | 141/10395 [22:32<22:59:45,  8.07s/it]                                                      {'loss': 1.0702, 'learning_rate': 9.03846153846154e-06, 'epoch': 0.01}
  1%|▏         | 141/10395 [22:32<22:59:45,  8.07s/it]  1%|▏         | 142/10395 [22:39<22:17:18,  7.83s/it]                                                      {'loss': 1.0613, 'learning_rate': 9.102564102564104e-06, 'epoch': 0.01}
  1%|▏         | 142/10395 [22:39<22:17:18,  7.83s/it]  1%|▏         | 143/10395 [22:56<29:45:58, 10.45s/it]                                                      {'loss': 0.341, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.01}
  1%|▏         | 143/10395 [22:56<29:45:58, 10.45s/it]  1%|▏         | 144/10395 [23:03<27:05:12,  9.51s/it]                                                      {'loss': 1.0462, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.01}
  1%|▏         | 144/10395 [23:03<27:05:12,  9.51s/it]  1%|▏         | 145/10395 [23:11<25:44:36,  9.04s/it]                                                      {'loss': 1.0608, 'learning_rate': 9.294871794871796e-06, 'epoch': 0.01}
  1%|▏         | 145/10395 [23:11<25:44:36,  9.04s/it]  1%|▏         | 146/10395 [23:19<24:28:39,  8.60s/it]                                                      {'loss': 1.0133, 'learning_rate': 9.358974358974359e-06, 'epoch': 0.01}
  1%|▏         | 146/10395 [23:19<24:28:39,  8.60s/it]  1%|▏         | 147/10395 [23:27<23:46:33,  8.35s/it]                                                      {'loss': 1.0521, 'learning_rate': 9.423076923076923e-06, 'epoch': 0.01}
  1%|▏         | 147/10395 [23:27<23:46:33,  8.35s/it]  1%|▏         | 148/10395 [23:45<31:59:49, 11.24s/it]                                                      {'loss': 0.2687, 'learning_rate': 9.487179487179487e-06, 'epoch': 0.01}
  1%|▏         | 148/10395 [23:45<31:59:49, 11.24s/it]  1%|▏         | 149/10395 [23:52<28:46:08, 10.11s/it]                                                      {'loss': 1.0748, 'learning_rate': 9.551282051282053e-06, 'epoch': 0.01}
  1%|▏         | 149/10395 [23:52<28:46:08, 10.11s/it]  1%|▏         | 150/10395 [24:10<35:39:08, 12.53s/it]                                                      {'loss': 0.3597, 'learning_rate': 9.615384615384616e-06, 'epoch': 0.01}
  1%|▏         | 150/10395 [24:10<35:39:08, 12.53s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  1%|▏         | 151/10395 [25:50<110:25:36, 38.81s/it]                                                       {'loss': 1.0926, 'learning_rate': 9.67948717948718e-06, 'epoch': 0.01}
  1%|▏         | 151/10395 [25:50<110:25:36, 38.81s/it]  1%|▏         | 152/10395 [25:58<84:10:22, 29.58s/it]                                                       {'loss': 1.0066, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.01}
  1%|▏         | 152/10395 [25:58<84:10:22, 29.58s/it]  1%|▏         | 153/10395 [26:06<65:43:05, 23.10s/it]                                                      {'loss': 1.0129, 'learning_rate': 9.807692307692308e-06, 'epoch': 0.01}
  1%|▏         | 153/10395 [26:06<65:43:05, 23.10s/it]  1%|▏         | 154/10395 [26:14<52:44:12, 18.54s/it]                                                      {'loss': 1.0151, 'learning_rate': 9.871794871794872e-06, 'epoch': 0.01}
  1%|▏         | 154/10395 [26:14<52:44:12, 18.54s/it]  1%|▏         | 155/10395 [26:32<52:13:16, 18.36s/it]                                                      {'loss': 0.3299, 'learning_rate': 9.935897435897437e-06, 'epoch': 0.01}
  1%|▏         | 155/10395 [26:32<52:13:16, 18.36s/it]  2%|▏         | 156/10395 [26:40<43:32:34, 15.31s/it]                                                      {'loss': 1.0693, 'learning_rate': 1e-05, 'epoch': 0.02}
  2%|▏         | 156/10395 [26:40<43:32:34, 15.31s/it]  2%|▏         | 157/10395 [26:48<37:02:41, 13.03s/it]                                                      {'loss': 0.9497, 'learning_rate': 1.0064102564102565e-05, 'epoch': 0.02}
  2%|▏         | 157/10395 [26:48<37:02:41, 13.03s/it]  2%|▏         | 158/10395 [26:56<32:21:22, 11.38s/it]                                                      {'loss': 0.9915, 'learning_rate': 1.012820512820513e-05, 'epoch': 0.02}
  2%|▏         | 158/10395 [26:56<32:21:22, 11.38s/it]  2%|▏         | 159/10395 [27:03<29:23:09, 10.34s/it]                                                      {'loss': 1.1016, 'learning_rate': 1.0192307692307692e-05, 'epoch': 0.02}
  2%|▏         | 159/10395 [27:03<29:23:09, 10.34s/it]  2%|▏         | 160/10395 [27:12<27:44:49,  9.76s/it]                                                      {'loss': 1.0451, 'learning_rate': 1.0256410256410256e-05, 'epoch': 0.02}
  2%|▏         | 160/10395 [27:12<27:44:49,  9.76s/it]  2%|▏         | 161/10395 [27:20<26:06:04,  9.18s/it]                                                      {'loss': 0.9802, 'learning_rate': 1.0320512820512822e-05, 'epoch': 0.02}
  2%|▏         | 161/10395 [27:20<26:06:04,  9.18s/it]  2%|▏         | 162/10395 [27:28<25:10:23,  8.86s/it]                                                      {'loss': 1.0493, 'learning_rate': 1.0384615384615386e-05, 'epoch': 0.02}
  2%|▏         | 162/10395 [27:28<25:10:23,  8.86s/it]  2%|▏         | 163/10395 [27:45<31:53:41, 11.22s/it]                                                      {'loss': 0.3132, 'learning_rate': 1.044871794871795e-05, 'epoch': 0.02}
  2%|▏         | 163/10395 [27:45<31:53:41, 11.22s/it]  2%|▏         | 164/10395 [27:52<28:32:27, 10.04s/it]                                                      {'loss': 1.0422, 'learning_rate': 1.0512820512820514e-05, 'epoch': 0.02}
  2%|▏         | 164/10395 [27:52<28:32:27, 10.04s/it]  2%|▏         | 165/10395 [27:59<26:28:00,  9.31s/it]                                                      {'loss': 1.0549, 'learning_rate': 1.0576923076923078e-05, 'epoch': 0.02}
  2%|▏         | 165/10395 [27:59<26:28:00,  9.31s/it]  2%|▏         | 166/10395 [28:07<25:00:38,  8.80s/it]                                                      {'loss': 1.002, 'learning_rate': 1.0641025641025643e-05, 'epoch': 0.02}
  2%|▏         | 166/10395 [28:07<25:00:38,  8.80s/it]  2%|▏         | 167/10395 [28:15<23:54:38,  8.42s/it]                                                      {'loss': 1.0388, 'learning_rate': 1.0705128205128205e-05, 'epoch': 0.02}
  2%|▏         | 167/10395 [28:15<23:54:38,  8.42s/it]  2%|▏         | 168/10395 [28:22<23:12:27,  8.17s/it]                                                      {'loss': 1.0875, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.02}
  2%|▏         | 168/10395 [28:22<23:12:27,  8.17s/it]  2%|▏         | 169/10395 [28:30<22:33:50,  7.94s/it]                                                      {'loss': 1.0688, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.02}
  2%|▏         | 169/10395 [28:30<22:33:50,  7.94s/it]  2%|▏         | 170/10395 [28:37<22:24:31,  7.89s/it]                                                      {'loss': 1.0337, 'learning_rate': 1.0897435897435898e-05, 'epoch': 0.02}
  2%|▏         | 170/10395 [28:37<22:24:31,  7.89s/it]  2%|▏         | 171/10395 [28:45<21:45:39,  7.66s/it]                                                      {'loss': 1.0536, 'learning_rate': 1.0961538461538464e-05, 'epoch': 0.02}
  2%|▏         | 171/10395 [28:45<21:45:39,  7.66s/it]  2%|▏         | 172/10395 [28:52<21:51:34,  7.70s/it]                                                      {'loss': 0.9909, 'learning_rate': 1.1025641025641028e-05, 'epoch': 0.02}
  2%|▏         | 172/10395 [28:52<21:51:34,  7.70s/it]  2%|▏         | 173/10395 [28:59<21:15:50,  7.49s/it]                                                      {'loss': 1.0645, 'learning_rate': 1.1089743589743592e-05, 'epoch': 0.02}
  2%|▏         | 173/10395 [28:59<21:15:50,  7.49s/it]  2%|▏         | 174/10395 [29:07<21:07:59,  7.44s/it]                                                      {'loss': 1.0889, 'learning_rate': 1.1153846153846154e-05, 'epoch': 0.02}
  2%|▏         | 174/10395 [29:07<21:07:59,  7.44s/it]  2%|▏         | 175/10395 [29:14<21:08:44,  7.45s/it]                                                      {'loss': 1.0794, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.02}
  2%|▏         | 175/10395 [29:14<21:08:44,  7.45s/it]  2%|▏         | 176/10395 [29:22<21:09:32,  7.45s/it]                                                      {'loss': 1.1096, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.02}
  2%|▏         | 176/10395 [29:22<21:09:32,  7.45s/it]  2%|▏         | 177/10395 [29:29<21:08:48,  7.45s/it]                                                      {'loss': 1.0471, 'learning_rate': 1.1346153846153847e-05, 'epoch': 0.02}
  2%|▏         | 177/10395 [29:29<21:08:48,  7.45s/it]  2%|▏         | 178/10395 [29:36<21:10:42,  7.46s/it]                                                      {'loss': 1.0138, 'learning_rate': 1.1410256410256411e-05, 'epoch': 0.02}
  2%|▏         | 178/10395 [29:36<21:10:42,  7.46s/it]  2%|▏         | 179/10395 [29:54<29:18:19, 10.33s/it]                                                      {'loss': 0.2939, 'learning_rate': 1.1474358974358974e-05, 'epoch': 0.02}
  2%|▏         | 179/10395 [29:54<29:18:19, 10.33s/it]  2%|▏         | 180/10395 [30:01<26:59:10,  9.51s/it]                                                      {'loss': 1.0738, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.02}
  2%|▏         | 180/10395 [30:01<26:59:10,  9.51s/it]  2%|▏         | 181/10395 [30:09<25:19:22,  8.93s/it]                                                      {'loss': 1.0764, 'learning_rate': 1.1602564102564104e-05, 'epoch': 0.02}
  2%|▏         | 181/10395 [30:09<25:19:22,  8.93s/it]  2%|▏         | 182/10395 [30:16<24:12:59,  8.54s/it]                                                      {'loss': 1.0495, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.02}
  2%|▏         | 182/10395 [30:16<24:12:59,  8.54s/it]  2%|▏         | 183/10395 [30:24<23:29:05,  8.28s/it]                                                      {'loss': 1.0639, 'learning_rate': 1.1730769230769232e-05, 'epoch': 0.02}
  2%|▏         | 183/10395 [30:24<23:29:05,  8.28s/it]  2%|▏         | 184/10395 [30:32<22:59:10,  8.10s/it]                                                      {'loss': 1.0282, 'learning_rate': 1.1794871794871796e-05, 'epoch': 0.02}
  2%|▏         | 184/10395 [30:32<22:59:10,  8.10s/it]  2%|▏         | 185/10395 [30:41<23:47:47,  8.39s/it]                                                      {'loss': 0.8948, 'learning_rate': 1.185897435897436e-05, 'epoch': 0.02}
  2%|▏         | 185/10395 [30:41<23:47:47,  8.39s/it]  2%|▏         | 186/10395 [30:48<23:05:40,  8.14s/it]                                                      {'loss': 1.0171, 'learning_rate': 1.1923076923076925e-05, 'epoch': 0.02}
  2%|▏         | 186/10395 [30:48<23:05:40,  8.14s/it]  2%|▏         | 187/10395 [30:56<22:53:15,  8.07s/it]                                                      {'loss': 1.0512, 'learning_rate': 1.1987179487179487e-05, 'epoch': 0.02}
  2%|▏         | 187/10395 [30:56<22:53:15,  8.07s/it]  2%|▏         | 188/10395 [31:06<24:32:34,  8.66s/it]                                                      {'loss': 1.0143, 'learning_rate': 1.2051282051282051e-05, 'epoch': 0.02}
  2%|▏         | 188/10395 [31:06<24:32:34,  8.66s/it]  2%|▏         | 189/10395 [31:14<23:41:56,  8.36s/it]                                                      {'loss': 1.0509, 'learning_rate': 1.2115384615384615e-05, 'epoch': 0.02}
  2%|▏         | 189/10395 [31:14<23:41:56,  8.36s/it]  2%|▏         | 190/10395 [31:22<23:21:40,  8.24s/it]                                                      {'loss': 1.0242, 'learning_rate': 1.217948717948718e-05, 'epoch': 0.02}
  2%|▏         | 190/10395 [31:22<23:21:40,  8.24s/it]  2%|▏         | 191/10395 [31:30<22:51:26,  8.06s/it]                                                      {'loss': 1.0575, 'learning_rate': 1.2243589743589746e-05, 'epoch': 0.02}
  2%|▏         | 191/10395 [31:30<22:51:26,  8.06s/it]  2%|▏         | 192/10395 [31:37<22:26:54,  7.92s/it]                                                      {'loss': 1.0703, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.02}
  2%|▏         | 192/10395 [31:37<22:26:54,  7.92s/it]  2%|▏         | 193/10395 [31:45<22:06:20,  7.80s/it]                                                      {'loss': 1.074, 'learning_rate': 1.2371794871794874e-05, 'epoch': 0.02}
  2%|▏         | 193/10395 [31:45<22:06:20,  7.80s/it]  2%|▏         | 194/10395 [31:52<21:50:19,  7.71s/it]                                                      {'loss': 1.0515, 'learning_rate': 1.2435897435897436e-05, 'epoch': 0.02}
  2%|▏         | 194/10395 [31:52<21:50:19,  7.71s/it]  2%|▏         | 195/10395 [31:59<21:29:18,  7.58s/it]                                                      {'loss': 1.039, 'learning_rate': 1.25e-05, 'epoch': 0.02}
  2%|▏         | 195/10395 [31:59<21:29:18,  7.58s/it]  2%|▏         | 196/10395 [32:08<22:04:31,  7.79s/it]                                                      {'loss': 1.0965, 'learning_rate': 1.2564102564102565e-05, 'epoch': 0.02}
  2%|▏         | 196/10395 [32:08<22:04:31,  7.79s/it]  2%|▏         | 197/10395 [32:15<21:55:34,  7.74s/it]                                                      {'loss': 1.1417, 'learning_rate': 1.2628205128205129e-05, 'epoch': 0.02}
  2%|▏         | 197/10395 [32:15<21:55:34,  7.74s/it]  2%|▏         | 198/10395 [32:23<22:08:36,  7.82s/it]                                                      {'loss': 1.0937, 'learning_rate': 1.2692307692307693e-05, 'epoch': 0.02}
  2%|▏         | 198/10395 [32:23<22:08:36,  7.82s/it]  2%|▏         | 199/10395 [32:31<21:55:28,  7.74s/it]                                                      {'loss': 1.0368, 'learning_rate': 1.2756410256410257e-05, 'epoch': 0.02}
  2%|▏         | 199/10395 [32:31<21:55:28,  7.74s/it]  2%|▏         | 200/10395 [32:39<21:55:25,  7.74s/it]                                                      {'loss': 1.123, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.02}
  2%|▏         | 200/10395 [32:39<21:55:25,  7.74s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  2%|▏         | 201/10395 [34:19<100:30:54, 35.50s/it]                                                       {'loss': 1.0234, 'learning_rate': 1.2884615384615386e-05, 'epoch': 0.02}
  2%|▏         | 201/10395 [34:19<100:30:54, 35.50s/it]  2%|▏         | 202/10395 [34:26<76:47:54, 27.12s/it]                                                       {'loss': 0.9853, 'learning_rate': 1.294871794871795e-05, 'epoch': 0.02}
  2%|▏         | 202/10395 [34:26<76:47:54, 27.12s/it]  2%|▏         | 203/10395 [34:35<60:39:13, 21.42s/it]                                                      {'loss': 1.0535, 'learning_rate': 1.3012820512820514e-05, 'epoch': 0.02}
  2%|▏         | 203/10395 [34:35<60:39:13, 21.42s/it]  2%|▏         | 204/10395 [34:50<55:54:48, 19.75s/it]                                                      {'loss': 0.2667, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.02}
  2%|▏         | 204/10395 [34:50<55:54:48, 19.75s/it]  2%|▏         | 205/10395 [34:58<45:35:02, 16.10s/it]                                                      {'loss': 1.0533, 'learning_rate': 1.3141025641025642e-05, 'epoch': 0.02}
  2%|▏         | 205/10395 [34:58<45:35:02, 16.10s/it]  2%|▏         | 206/10395 [35:06<38:24:57, 13.57s/it]                                                      {'loss': 1.0374, 'learning_rate': 1.3205128205128207e-05, 'epoch': 0.02}
  2%|▏         | 206/10395 [35:06<38:24:57, 13.57s/it]  2%|▏         | 207/10395 [35:13<33:07:51, 11.71s/it]                                                      {'loss': 1.0298, 'learning_rate': 1.3269230769230769e-05, 'epoch': 0.02}
  2%|▏         | 207/10395 [35:13<33:07:51, 11.71s/it]  2%|▏         | 208/10395 [35:30<37:29:33, 13.25s/it]                                                      {'loss': 0.273, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
  2%|▏         | 208/10395 [35:30<37:29:33, 13.25s/it]  2%|▏         | 209/10395 [35:38<32:49:22, 11.60s/it]                                                      {'loss': 1.0366, 'learning_rate': 1.3397435897435897e-05, 'epoch': 0.02}
  2%|▏         | 209/10395 [35:38<32:49:22, 11.60s/it]  2%|▏         | 210/10395 [35:45<29:15:32, 10.34s/it]                                                      {'loss': 1.0071, 'learning_rate': 1.3461538461538463e-05, 'epoch': 0.02}
  2%|▏         | 210/10395 [35:45<29:15:32, 10.34s/it]  2%|▏         | 211/10395 [35:53<27:32:15,  9.73s/it]                                                      {'loss': 0.9588, 'learning_rate': 1.3525641025641028e-05, 'epoch': 0.02}
  2%|▏         | 211/10395 [35:53<27:32:15,  9.73s/it]  2%|▏         | 212/10395 [36:00<25:20:02,  8.96s/it]                                                      {'loss': 1.0793, 'learning_rate': 1.3589743589743592e-05, 'epoch': 0.02}
  2%|▏         | 212/10395 [36:00<25:20:02,  8.96s/it]  2%|▏         | 213/10395 [36:09<24:37:13,  8.70s/it]                                                      {'loss': 1.0373, 'learning_rate': 1.3653846153846156e-05, 'epoch': 0.02}
  2%|▏         | 213/10395 [36:09<24:37:13,  8.70s/it]  2%|▏         | 214/10395 [36:16<23:19:35,  8.25s/it]                                                      {'loss': 1.0667, 'learning_rate': 1.3717948717948718e-05, 'epoch': 0.02}
  2%|▏         | 214/10395 [36:16<23:19:35,  8.25s/it]  2%|▏         | 215/10395 [36:24<22:55:14,  8.11s/it]                                                      {'loss': 1.1271, 'learning_rate': 1.3782051282051283e-05, 'epoch': 0.02}
  2%|▏         | 215/10395 [36:24<22:55:14,  8.11s/it]  2%|▏         | 216/10395 [36:31<22:31:36,  7.97s/it]                                                      {'loss': 1.1252, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.02}
  2%|▏         | 216/10395 [36:31<22:31:36,  7.97s/it]  2%|▏         | 217/10395 [36:39<22:10:32,  7.84s/it]                                                      {'loss': 0.9962, 'learning_rate': 1.3910256410256411e-05, 'epoch': 0.02}
  2%|▏         | 217/10395 [36:39<22:10:32,  7.84s/it]  2%|▏         | 218/10395 [36:48<23:11:37,  8.20s/it]                                                      {'loss': 1.0899, 'learning_rate': 1.3974358974358975e-05, 'epoch': 0.02}
  2%|▏         | 218/10395 [36:48<23:11:37,  8.20s/it]  2%|▏         | 219/10395 [36:56<22:49:05,  8.07s/it]                                                      {'loss': 0.9961, 'learning_rate': 1.403846153846154e-05, 'epoch': 0.02}
  2%|▏         | 219/10395 [36:56<22:49:05,  8.07s/it]  2%|▏         | 220/10395 [37:04<22:55:33,  8.11s/it]                                                      {'loss': 0.9895, 'learning_rate': 1.4102564102564105e-05, 'epoch': 0.02}
  2%|▏         | 220/10395 [37:04<22:55:33,  8.11s/it]  2%|▏         | 221/10395 [37:12<22:58:08,  8.13s/it]                                                      {'loss': 0.9811, 'learning_rate': 1.416666666666667e-05, 'epoch': 0.02}
  2%|▏         | 221/10395 [37:12<22:58:08,  8.13s/it]  2%|▏         | 222/10395 [37:20<22:35:23,  7.99s/it]                                                      {'loss': 1.0286, 'learning_rate': 1.4230769230769232e-05, 'epoch': 0.02}
  2%|▏         | 222/10395 [37:20<22:35:23,  7.99s/it]  2%|▏         | 223/10395 [37:28<23:05:29,  8.17s/it]                                                      {'loss': 0.9992, 'learning_rate': 1.4294871794871796e-05, 'epoch': 0.02}
  2%|▏         | 223/10395 [37:28<23:05:29,  8.17s/it]  2%|▏         | 224/10395 [37:36<22:36:18,  8.00s/it]                                                      {'loss': 1.1453, 'learning_rate': 1.435897435897436e-05, 'epoch': 0.02}
  2%|▏         | 224/10395 [37:36<22:36:18,  8.00s/it]  2%|▏         | 225/10395 [37:44<22:26:20,  7.94s/it]                                                      {'loss': 1.0876, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.02}
  2%|▏         | 225/10395 [37:44<22:26:20,  7.94s/it]  2%|▏         | 226/10395 [37:51<21:57:12,  7.77s/it]                                                      {'loss': 1.0827, 'learning_rate': 1.4487179487179489e-05, 'epoch': 0.02}
  2%|▏         | 226/10395 [37:51<21:57:12,  7.77s/it]  2%|▏         | 227/10395 [38:07<28:56:05, 10.24s/it]                                                      {'loss': 0.3069, 'learning_rate': 1.4551282051282051e-05, 'epoch': 0.02}
  2%|▏         | 227/10395 [38:07<28:56:05, 10.24s/it]  2%|▏         | 228/10395 [38:15<27:18:53,  9.67s/it]                                                      {'loss': 0.9854, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.02}
  2%|▏         | 228/10395 [38:15<27:18:53,  9.67s/it]  2%|▏         | 229/10395 [38:23<25:43:32,  9.11s/it]                                                      {'loss': 1.0459, 'learning_rate': 1.467948717948718e-05, 'epoch': 0.02}
  2%|▏         | 229/10395 [38:23<25:43:32,  9.11s/it]  2%|▏         | 230/10395 [38:32<25:25:31,  9.00s/it]                                                      {'loss': 0.9879, 'learning_rate': 1.4743589743589745e-05, 'epoch': 0.02}
  2%|▏         | 230/10395 [38:32<25:25:31,  9.00s/it]  2%|▏         | 231/10395 [38:39<24:11:06,  8.57s/it]                                                      {'loss': 1.0337, 'learning_rate': 1.480769230769231e-05, 'epoch': 0.02}
  2%|▏         | 231/10395 [38:39<24:11:06,  8.57s/it]  2%|▏         | 232/10395 [38:47<23:40:23,  8.39s/it]                                                      {'loss': 0.9991, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.02}
  2%|▏         | 232/10395 [38:47<23:40:23,  8.39s/it]  2%|▏         | 233/10395 [38:55<23:20:24,  8.27s/it]                                                      {'loss': 0.951, 'learning_rate': 1.4935897435897438e-05, 'epoch': 0.02}
  2%|▏         | 233/10395 [38:55<23:20:24,  8.27s/it]  2%|▏         | 234/10395 [39:03<22:54:29,  8.12s/it]                                                      {'loss': 1.075, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.02}
  2%|▏         | 234/10395 [39:03<22:54:29,  8.12s/it]  2%|▏         | 235/10395 [39:11<22:18:14,  7.90s/it]                                                      {'loss': 1.1117, 'learning_rate': 1.5064102564102565e-05, 'epoch': 0.02}
  2%|▏         | 235/10395 [39:11<22:18:14,  7.90s/it]  2%|▏         | 236/10395 [39:18<22:07:44,  7.84s/it]                                                      {'loss': 1.1026, 'learning_rate': 1.5128205128205129e-05, 'epoch': 0.02}
  2%|▏         | 236/10395 [39:18<22:07:44,  7.84s/it]  2%|▏         | 237/10395 [39:26<21:44:05,  7.70s/it]                                                      {'loss': 1.066, 'learning_rate': 1.5192307692307693e-05, 'epoch': 0.02}
  2%|▏         | 237/10395 [39:26<21:44:05,  7.70s/it]  2%|▏         | 238/10395 [39:33<21:42:38,  7.70s/it]                                                      {'loss': 1.0016, 'learning_rate': 1.5256410256410257e-05, 'epoch': 0.02}
  2%|▏         | 238/10395 [39:33<21:42:38,  7.70s/it]  2%|▏         | 239/10395 [39:41<21:39:07,  7.68s/it]                                                      {'loss': 1.1047, 'learning_rate': 1.5320512820512823e-05, 'epoch': 0.02}
  2%|▏         | 239/10395 [39:41<21:39:07,  7.68s/it]  2%|▏         | 240/10395 [39:48<21:28:52,  7.62s/it]                                                      {'loss': 1.014, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
  2%|▏         | 240/10395 [39:48<21:28:52,  7.62s/it]  2%|▏         | 241/10395 [39:56<21:33:36,  7.64s/it]                                                      {'loss': 1.0022, 'learning_rate': 1.544871794871795e-05, 'epoch': 0.02}
  2%|▏         | 241/10395 [39:56<21:33:36,  7.64s/it]  2%|▏         | 242/10395 [40:04<21:24:39,  7.59s/it]                                                      {'loss': 1.0687, 'learning_rate': 1.5512820512820516e-05, 'epoch': 0.02}
  2%|▏         | 242/10395 [40:04<21:24:39,  7.59s/it]  2%|▏         | 243/10395 [40:22<30:13:47, 10.72s/it]                                                      {'loss': 0.3214, 'learning_rate': 1.557692307692308e-05, 'epoch': 0.02}
  2%|▏         | 243/10395 [40:22<30:13:47, 10.72s/it]  2%|▏         | 244/10395 [40:30<27:49:44,  9.87s/it]                                                      {'loss': 1.0935, 'learning_rate': 1.5641025641025644e-05, 'epoch': 0.02}
  2%|▏         | 244/10395 [40:30<27:49:44,  9.87s/it]  2%|▏         | 245/10395 [40:38<26:22:24,  9.35s/it]                                                      {'loss': 1.0747, 'learning_rate': 1.5705128205128205e-05, 'epoch': 0.02}
  2%|▏         | 245/10395 [40:38<26:22:24,  9.35s/it]  2%|▏         | 246/10395 [40:46<25:51:32,  9.17s/it]                                                      {'loss': 1.0249, 'learning_rate': 1.576923076923077e-05, 'epoch': 0.02}
  2%|▏         | 246/10395 [40:46<25:51:32,  9.17s/it]  2%|▏         | 247/10395 [40:54<24:21:35,  8.64s/it]                                                      {'loss': 1.0021, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.02}
  2%|▏         | 247/10395 [40:54<24:21:35,  8.64s/it]  2%|▏         | 248/10395 [41:01<23:10:55,  8.22s/it]                                                      {'loss': 1.0252, 'learning_rate': 1.5897435897435897e-05, 'epoch': 0.02}
  2%|▏         | 248/10395 [41:01<23:10:55,  8.22s/it]  2%|▏         | 249/10395 [41:08<22:12:03,  7.88s/it]                                                      {'loss': 1.0285, 'learning_rate': 1.5961538461538465e-05, 'epoch': 0.02}
  2%|▏         | 249/10395 [41:08<22:12:03,  7.88s/it]  2%|▏         | 250/10395 [41:15<21:44:39,  7.72s/it]                                                      {'loss': 1.1146, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.02}
  2%|▏         | 250/10395 [41:15<21:44:39,  7.72s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  2%|▏         | 251/10395 [42:59<102:59:52, 36.55s/it]                                                       {'loss': 1.0351, 'learning_rate': 1.6089743589743593e-05, 'epoch': 0.02}
  2%|▏         | 251/10395 [42:59<102:59:52, 36.55s/it]  2%|▏         | 252/10395 [43:16<86:13:09, 30.60s/it]                                                       {'loss': 0.316, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.02}
  2%|▏         | 252/10395 [43:16<86:13:09, 30.60s/it]  2%|▏         | 253/10395 [43:23<66:15:36, 23.52s/it]                                                      {'loss': 1.12, 'learning_rate': 1.6217948717948718e-05, 'epoch': 0.02}
  2%|▏         | 253/10395 [43:23<66:15:36, 23.52s/it]  2%|▏         | 254/10395 [43:31<52:51:02, 18.76s/it]                                                      {'loss': 0.9906, 'learning_rate': 1.6282051282051282e-05, 'epoch': 0.02}
  2%|▏         | 254/10395 [43:31<52:51:02, 18.76s/it]  2%|▏         | 255/10395 [43:39<44:01:58, 15.63s/it]                                                      {'loss': 1.0816, 'learning_rate': 1.6346153846153847e-05, 'epoch': 0.02}
  2%|▏         | 255/10395 [43:39<44:01:58, 15.63s/it]  2%|▏         | 256/10395 [43:47<37:45:01, 13.40s/it]                                                      {'loss': 1.1076, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.02}
  2%|▏         | 256/10395 [43:47<37:45:01, 13.40s/it]  2%|▏         | 257/10395 [43:55<33:21:18, 11.84s/it]                                                      {'loss': 1.0654, 'learning_rate': 1.6474358974358975e-05, 'epoch': 0.02}
  2%|▏         | 257/10395 [43:55<33:21:18, 11.84s/it]  2%|▏         | 258/10395 [44:03<29:38:44, 10.53s/it]                                                      {'loss': 1.0639, 'learning_rate': 1.653846153846154e-05, 'epoch': 0.02}
  2%|▏         | 258/10395 [44:03<29:38:44, 10.53s/it]  2%|▏         | 259/10395 [44:11<27:26:18,  9.75s/it]                                                      {'loss': 1.0575, 'learning_rate': 1.6602564102564103e-05, 'epoch': 0.02}
  2%|▏         | 259/10395 [44:11<27:26:18,  9.75s/it]  3%|▎         | 260/10395 [44:29<34:17:22, 12.18s/it]                                                      {'loss': 0.3401, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
  3%|▎         | 260/10395 [44:29<34:17:22, 12.18s/it]  3%|▎         | 261/10395 [44:37<31:25:18, 11.16s/it]                                                      {'loss': 1.0751, 'learning_rate': 1.673076923076923e-05, 'epoch': 0.03}
  3%|▎         | 261/10395 [44:37<31:25:18, 11.16s/it]  3%|▎         | 262/10395 [44:46<29:12:30, 10.38s/it]                                                      {'loss': 1.047, 'learning_rate': 1.6794871794871796e-05, 'epoch': 0.03}
  3%|▎         | 262/10395 [44:46<29:12:30, 10.38s/it]  3%|▎         | 263/10395 [44:54<27:11:41,  9.66s/it]                                                      {'loss': 1.0474, 'learning_rate': 1.685897435897436e-05, 'epoch': 0.03}
  3%|▎         | 263/10395 [44:54<27:11:41,  9.66s/it]  3%|▎         | 264/10395 [45:01<25:18:00,  8.99s/it]                                                      {'loss': 0.9929, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.03}
  3%|▎         | 264/10395 [45:01<25:18:00,  8.99s/it]  3%|▎         | 265/10395 [45:09<23:44:49,  8.44s/it]                                                      {'loss': 1.0383, 'learning_rate': 1.698717948717949e-05, 'epoch': 0.03}
  3%|▎         | 265/10395 [45:09<23:44:49,  8.44s/it]  3%|▎         | 266/10395 [45:16<23:15:07,  8.26s/it]                                                      {'loss': 0.9621, 'learning_rate': 1.7051282051282053e-05, 'epoch': 0.03}
  3%|▎         | 266/10395 [45:16<23:15:07,  8.26s/it]  3%|▎         | 267/10395 [45:24<22:43:45,  8.08s/it]                                                      {'loss': 1.1037, 'learning_rate': 1.7115384615384617e-05, 'epoch': 0.03}
  3%|▎         | 267/10395 [45:24<22:43:45,  8.08s/it]  3%|▎         | 268/10395 [45:31<21:56:17,  7.80s/it]                                                      {'loss': 1.0549, 'learning_rate': 1.717948717948718e-05, 'epoch': 0.03}
  3%|▎         | 268/10395 [45:31<21:56:17,  7.80s/it]  3%|▎         | 269/10395 [45:39<22:09:15,  7.88s/it]                                                      {'loss': 1.0347, 'learning_rate': 1.7243589743589745e-05, 'epoch': 0.03}
  3%|▎         | 269/10395 [45:39<22:09:15,  7.88s/it]  3%|▎         | 270/10395 [45:48<23:00:34,  8.18s/it]                                                      {'loss': 0.9591, 'learning_rate': 1.730769230769231e-05, 'epoch': 0.03}
  3%|▎         | 270/10395 [45:48<23:00:34,  8.18s/it]  3%|▎         | 271/10395 [45:56<22:33:18,  8.02s/it]                                                      {'loss': 1.0478, 'learning_rate': 1.7371794871794873e-05, 'epoch': 0.03}
  3%|▎         | 271/10395 [45:56<22:33:18,  8.02s/it]  3%|▎         | 272/10395 [46:03<21:51:59,  7.78s/it]                                                      {'loss': 1.1083, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.03}
  3%|▎         | 272/10395 [46:03<21:51:59,  7.78s/it]  3%|▎         | 273/10395 [46:11<21:37:19,  7.69s/it]                                                      {'loss': 1.1066, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.03}
  3%|▎         | 273/10395 [46:11<21:37:19,  7.69s/it]  3%|▎         | 274/10395 [46:18<21:47:49,  7.75s/it]                                                      {'loss': 0.9742, 'learning_rate': 1.7564102564102566e-05, 'epoch': 0.03}
  3%|▎         | 274/10395 [46:18<21:47:49,  7.75s/it]  3%|▎         | 275/10395 [46:26<21:40:19,  7.71s/it]                                                      {'loss': 1.0245, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.03}
  3%|▎         | 275/10395 [46:26<21:40:19,  7.71s/it]  3%|▎         | 276/10395 [46:34<21:44:07,  7.73s/it]                                                      {'loss': 1.1068, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.03}
  3%|▎         | 276/10395 [46:34<21:44:07,  7.73s/it]  3%|▎         | 277/10395 [46:42<21:45:39,  7.74s/it]                                                      {'loss': 1.0576, 'learning_rate': 1.775641025641026e-05, 'epoch': 0.03}
  3%|▎         | 277/10395 [46:42<21:45:39,  7.74s/it]  3%|▎         | 278/10395 [46:50<22:01:28,  7.84s/it]                                                      {'loss': 1.0164, 'learning_rate': 1.7820512820512823e-05, 'epoch': 0.03}
  3%|▎         | 278/10395 [46:50<22:01:28,  7.84s/it]  3%|▎         | 279/10395 [46:58<22:17:00,  7.93s/it]                                                      {'loss': 1.0061, 'learning_rate': 1.7884615384615387e-05, 'epoch': 0.03}
  3%|▎         | 279/10395 [46:58<22:17:00,  7.93s/it]  3%|▎         | 280/10395 [47:07<23:30:54,  8.37s/it]                                                      {'loss': 1.0122, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.03}
  3%|▎         | 280/10395 [47:07<23:30:54,  8.37s/it]  3%|▎         | 281/10395 [47:14<22:35:39,  8.04s/it]                                                      {'loss': 1.1276, 'learning_rate': 1.8012820512820515e-05, 'epoch': 0.03}
  3%|▎         | 281/10395 [47:14<22:35:39,  8.04s/it]  3%|▎         | 282/10395 [47:23<23:06:34,  8.23s/it]                                                      {'loss': 1.1074, 'learning_rate': 1.807692307692308e-05, 'epoch': 0.03}
  3%|▎         | 282/10395 [47:23<23:06:34,  8.23s/it]  3%|▎         | 283/10395 [47:31<22:43:34,  8.09s/it]                                                      {'loss': 1.0354, 'learning_rate': 1.8141025641025644e-05, 'epoch': 0.03}
  3%|▎         | 283/10395 [47:31<22:43:34,  8.09s/it]  3%|▎         | 284/10395 [47:48<30:31:14, 10.87s/it]                                                      {'loss': 0.3522, 'learning_rate': 1.8205128205128208e-05, 'epoch': 0.03}
  3%|▎         | 284/10395 [47:48<30:31:14, 10.87s/it]  3%|▎         | 285/10395 [47:56<28:04:09,  9.99s/it]                                                      {'loss': 1.0862, 'learning_rate': 1.826923076923077e-05, 'epoch': 0.03}
  3%|▎         | 285/10395 [47:56<28:04:09,  9.99s/it]  3%|▎         | 286/10395 [48:04<25:57:53,  9.25s/it]                                                      {'loss': 1.0479, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.03}
  3%|▎         | 286/10395 [48:04<25:57:53,  9.25s/it]  3%|▎         | 287/10395 [48:11<24:40:59,  8.79s/it]                                                      {'loss': 1.1193, 'learning_rate': 1.8397435897435897e-05, 'epoch': 0.03}
  3%|▎         | 287/10395 [48:11<24:40:59,  8.79s/it]  3%|▎         | 288/10395 [48:19<23:18:36,  8.30s/it]                                                      {'loss': 1.1415, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.03}
  3%|▎         | 288/10395 [48:19<23:18:36,  8.30s/it]  3%|▎         | 289/10395 [48:26<22:55:07,  8.16s/it]                                                      {'loss': 0.9256, 'learning_rate': 1.852564102564103e-05, 'epoch': 0.03}
  3%|▎         | 289/10395 [48:26<22:55:07,  8.16s/it]  3%|▎         | 290/10395 [48:34<22:36:36,  8.06s/it]                                                      {'loss': 0.9846, 'learning_rate': 1.8589743589743593e-05, 'epoch': 0.03}
  3%|▎         | 290/10395 [48:34<22:36:36,  8.06s/it]  3%|▎         | 291/10395 [48:42<22:22:49,  7.97s/it]                                                      {'loss': 1.0492, 'learning_rate': 1.8653846153846157e-05, 'epoch': 0.03}
  3%|▎         | 291/10395 [48:42<22:22:49,  7.97s/it]  3%|▎         | 292/10395 [48:50<22:27:54,  8.01s/it]                                                      {'loss': 0.984, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.03}
  3%|▎         | 292/10395 [48:50<22:27:54,  8.01s/it]  3%|▎         | 293/10395 [48:58<22:22:26,  7.97s/it]                                                      {'loss': 1.079, 'learning_rate': 1.8782051282051282e-05, 'epoch': 0.03}
  3%|▎         | 293/10395 [48:58<22:22:26,  7.97s/it]  3%|▎         | 294/10395 [49:06<22:18:33,  7.95s/it]                                                      {'loss': 1.0514, 'learning_rate': 1.8846153846153846e-05, 'epoch': 0.03}
  3%|▎         | 294/10395 [49:06<22:18:33,  7.95s/it]  3%|▎         | 295/10395 [49:14<22:13:47,  7.92s/it]                                                      {'loss': 1.0629, 'learning_rate': 1.891025641025641e-05, 'epoch': 0.03}
  3%|▎         | 295/10395 [49:14<22:13:47,  7.92s/it]  3%|▎         | 296/10395 [49:21<21:47:28,  7.77s/it]                                                      {'loss': 1.1457, 'learning_rate': 1.8974358974358975e-05, 'epoch': 0.03}
  3%|▎         | 296/10395 [49:21<21:47:28,  7.77s/it]  3%|▎         | 297/10395 [49:28<21:22:14,  7.62s/it]                                                      {'loss': 1.0815, 'learning_rate': 1.903846153846154e-05, 'epoch': 0.03}
  3%|▎         | 297/10395 [49:28<21:22:14,  7.62s/it]  3%|▎         | 298/10395 [49:36<21:24:52,  7.64s/it]                                                      {'loss': 1.0664, 'learning_rate': 1.9102564102564106e-05, 'epoch': 0.03}
  3%|▎         | 298/10395 [49:36<21:24:52,  7.64s/it]  3%|▎         | 299/10395 [49:44<21:24:07,  7.63s/it]                                                      {'loss': 1.0688, 'learning_rate': 1.916666666666667e-05, 'epoch': 0.03}
  3%|▎         | 299/10395 [49:44<21:24:07,  7.63s/it]  3%|▎         | 300/10395 [49:52<21:43:43,  7.75s/it]                                                      {'loss': 0.9986, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.03}
  3%|▎         | 300/10395 [49:52<21:43:43,  7.75s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  3%|▎         | 301/10395 [51:30<98:01:34, 34.96s/it]                                                      {'loss': 0.9868, 'learning_rate': 1.9294871794871796e-05, 'epoch': 0.03}
  3%|▎         | 301/10395 [51:30<98:01:34, 34.96s/it]  3%|▎         | 302/10395 [51:38<74:57:06, 26.73s/it]                                                      {'loss': 1.0995, 'learning_rate': 1.935897435897436e-05, 'epoch': 0.03}
  3%|▎         | 302/10395 [51:38<74:57:06, 26.73s/it]  3%|▎         | 303/10395 [51:45<58:42:47, 20.94s/it]                                                      {'loss': 1.0676, 'learning_rate': 1.9423076923076924e-05, 'epoch': 0.03}
  3%|▎         | 303/10395 [51:45<58:42:47, 20.94s/it]  3%|▎         | 304/10395 [51:54<48:34:36, 17.33s/it]                                                      {'loss': 1.1247, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.03}
  3%|▎         | 304/10395 [51:54<48:34:36, 17.33s/it]  3%|▎         | 305/10395 [52:01<39:56:21, 14.25s/it]                                                      {'loss': 1.0291, 'learning_rate': 1.9551282051282052e-05, 'epoch': 0.03}
  3%|▎         | 305/10395 [52:01<39:56:21, 14.25s/it]  3%|▎         | 306/10395 [52:09<34:54:15, 12.45s/it]                                                      {'loss': 0.9698, 'learning_rate': 1.9615384615384617e-05, 'epoch': 0.03}
  3%|▎         | 306/10395 [52:09<34:54:15, 12.45s/it]  3%|▎         | 307/10395 [52:17<30:37:12, 10.93s/it]                                                      {'loss': 1.0814, 'learning_rate': 1.967948717948718e-05, 'epoch': 0.03}
  3%|▎         | 307/10395 [52:17<30:37:12, 10.93s/it]  3%|▎         | 308/10395 [52:24<27:51:53,  9.94s/it]                                                      {'loss': 0.9954, 'learning_rate': 1.9743589743589745e-05, 'epoch': 0.03}
  3%|▎         | 308/10395 [52:24<27:51:53,  9.94s/it]  3%|▎         | 309/10395 [52:32<25:39:08,  9.16s/it]                                                      {'loss': 1.0024, 'learning_rate': 1.980769230769231e-05, 'epoch': 0.03}
  3%|▎         | 309/10395 [52:32<25:39:08,  9.16s/it]  3%|▎         | 310/10395 [52:39<24:24:50,  8.72s/it]                                                      {'loss': 1.1844, 'learning_rate': 1.9871794871794873e-05, 'epoch': 0.03}
  3%|▎         | 310/10395 [52:39<24:24:50,  8.72s/it]  3%|▎         | 311/10395 [52:47<23:42:41,  8.47s/it]                                                      {'loss': 0.9622, 'learning_rate': 1.9935897435897437e-05, 'epoch': 0.03}
  3%|▎         | 311/10395 [52:47<23:42:41,  8.47s/it]  3%|▎         | 312/10395 [52:57<24:39:21,  8.80s/it]                                                      {'loss': 0.9893, 'learning_rate': 2e-05, 'epoch': 0.03}
  3%|▎         | 312/10395 [52:57<24:39:21,  8.80s/it]  3%|▎         | 313/10395 [53:05<24:05:35,  8.60s/it]                                                      {'loss': 1.0617, 'learning_rate': 1.9999999514610685e-05, 'epoch': 0.03}
  3%|▎         | 313/10395 [53:05<24:05:35,  8.60s/it]  3%|▎         | 314/10395 [53:12<23:01:28,  8.22s/it]                                                      {'loss': 1.096, 'learning_rate': 1.999999805844279e-05, 'epoch': 0.03}
  3%|▎         | 314/10395 [53:12<23:01:28,  8.22s/it]  3%|▎         | 315/10395 [53:20<22:08:46,  7.91s/it]                                                      {'loss': 1.0701, 'learning_rate': 1.999999563149645e-05, 'epoch': 0.03}
  3%|▎         | 315/10395 [53:20<22:08:46,  7.91s/it]  3%|▎         | 316/10395 [53:27<21:59:38,  7.86s/it]                                                      {'loss': 1.0352, 'learning_rate': 1.9999992233771905e-05, 'epoch': 0.03}
  3%|▎         | 316/10395 [53:27<21:59:38,  7.86s/it]  3%|▎         | 317/10395 [53:35<21:50:01,  7.80s/it]                                                      {'loss': 0.9877, 'learning_rate': 1.9999987865269485e-05, 'epoch': 0.03}
  3%|▎         | 317/10395 [53:35<21:50:01,  7.80s/it]  3%|▎         | 318/10395 [53:42<21:11:07,  7.57s/it]                                                      {'loss': 1.0446, 'learning_rate': 1.999998252598961e-05, 'epoch': 0.03}
  3%|▎         | 318/10395 [53:42<21:11:07,  7.57s/it]  3%|▎         | 319/10395 [53:51<22:35:39,  8.07s/it]                                                      {'loss': 1.0805, 'learning_rate': 1.9999976215932804e-05, 'epoch': 0.03}
  3%|▎         | 319/10395 [53:51<22:35:39,  8.07s/it]  3%|▎         | 320/10395 [53:59<22:39:49,  8.10s/it]                                                      {'loss': 1.0296, 'learning_rate': 1.9999968935099675e-05, 'epoch': 0.03}
  3%|▎         | 320/10395 [53:59<22:39:49,  8.10s/it]  3%|▎         | 321/10395 [54:07<22:27:38,  8.03s/it]                                                      {'loss': 1.0776, 'learning_rate': 1.9999960683490935e-05, 'epoch': 0.03}
  3%|▎         | 321/10395 [54:07<22:27:38,  8.03s/it]  3%|▎         | 322/10395 [54:15<22:14:19,  7.95s/it]                                                      {'loss': 1.0137, 'learning_rate': 1.999995146110738e-05, 'epoch': 0.03}
  3%|▎         | 322/10395 [54:15<22:14:19,  7.95s/it]  3%|▎         | 323/10395 [54:23<22:08:52,  7.92s/it]                                                      {'loss': 1.0731, 'learning_rate': 1.9999941267949908e-05, 'epoch': 0.03}
  3%|▎         | 323/10395 [54:23<22:08:52,  7.92s/it]  3%|▎         | 324/10395 [54:31<22:04:16,  7.89s/it]                                                      {'loss': 1.0562, 'learning_rate': 1.9999930104019505e-05, 'epoch': 0.03}
  3%|▎         | 324/10395 [54:31<22:04:16,  7.89s/it]  3%|▎         | 325/10395 [54:38<21:50:19,  7.81s/it]                                                      {'loss': 1.0687, 'learning_rate': 1.999991796931726e-05, 'epoch': 0.03}
  3%|▎         | 325/10395 [54:38<21:50:19,  7.81s/it]  3%|▎         | 326/10395 [54:47<22:12:31,  7.94s/it]                                                      {'loss': 1.0039, 'learning_rate': 1.9999904863844345e-05, 'epoch': 0.03}
  3%|▎         | 326/10395 [54:47<22:12:31,  7.94s/it]  3%|▎         | 327/10395 [54:54<22:11:43,  7.94s/it]                                                      {'loss': 1.0012, 'learning_rate': 1.999989078760204e-05, 'epoch': 0.03}
  3%|▎         | 327/10395 [54:54<22:11:43,  7.94s/it]  3%|▎         | 328/10395 [55:03<22:25:54,  8.02s/it]                                                      {'loss': 1.0073, 'learning_rate': 1.9999875740591707e-05, 'epoch': 0.03}
  3%|▎         | 328/10395 [55:03<22:25:54,  8.02s/it]  3%|▎         | 329/10395 [55:10<22:07:21,  7.91s/it]                                                      {'loss': 1.1025, 'learning_rate': 1.9999859722814806e-05, 'epoch': 0.03}
  3%|▎         | 329/10395 [55:10<22:07:21,  7.91s/it]  3%|▎         | 330/10395 [55:19<22:26:02,  8.02s/it]                                                      {'loss': 1.0443, 'learning_rate': 1.9999842734272892e-05, 'epoch': 0.03}
  3%|▎         | 330/10395 [55:19<22:26:02,  8.02s/it]  3%|▎         | 331/10395 [55:26<22:11:20,  7.94s/it]                                                      {'loss': 1.0888, 'learning_rate': 1.9999824774967615e-05, 'epoch': 0.03}
  3%|▎         | 331/10395 [55:26<22:11:20,  7.94s/it]  3%|▎         | 332/10395 [55:34<22:03:52,  7.89s/it]                                                      {'loss': 0.98, 'learning_rate': 1.999980584490072e-05, 'epoch': 0.03}
  3%|▎         | 332/10395 [55:34<22:03:52,  7.89s/it]  3%|▎         | 333/10395 [55:42<21:43:57,  7.78s/it]                                                      {'loss': 1.0982, 'learning_rate': 1.999978594407404e-05, 'epoch': 0.03}
  3%|▎         | 333/10395 [55:42<21:43:57,  7.78s/it]  3%|▎         | 334/10395 [55:49<21:45:14,  7.78s/it]                                                      {'loss': 1.0788, 'learning_rate': 1.9999765072489512e-05, 'epoch': 0.03}
  3%|▎         | 334/10395 [55:49<21:45:14,  7.78s/it]  3%|▎         | 335/10395 [55:58<22:29:41,  8.05s/it]                                                      {'loss': 1.0317, 'learning_rate': 1.9999743230149164e-05, 'epoch': 0.03}
  3%|▎         | 335/10395 [55:58<22:29:41,  8.05s/it]  3%|▎         | 336/10395 [56:05<21:49:38,  7.81s/it]                                                      {'loss': 1.0203, 'learning_rate': 1.999972041705511e-05, 'epoch': 0.03}
  3%|▎         | 336/10395 [56:05<21:49:38,  7.81s/it]  3%|▎         | 337/10395 [56:13<21:39:18,  7.75s/it]                                                      {'loss': 1.0557, 'learning_rate': 1.9999696633209563e-05, 'epoch': 0.03}
  3%|▎         | 337/10395 [56:13<21:39:18,  7.75s/it]  3%|▎         | 338/10395 [56:21<21:30:26,  7.70s/it]                                                      {'loss': 1.0383, 'learning_rate': 1.999967187861484e-05, 'epoch': 0.03}
  3%|▎         | 338/10395 [56:21<21:30:26,  7.70s/it]  3%|▎         | 339/10395 [56:28<21:16:24,  7.62s/it]                                                      {'loss': 1.0969, 'learning_rate': 1.9999646153273343e-05, 'epoch': 0.03}
  3%|▎         | 339/10395 [56:28<21:16:24,  7.62s/it]  3%|▎         | 340/10395 [56:35<20:53:28,  7.48s/it]                                                      {'loss': 1.122, 'learning_rate': 1.999961945718756e-05, 'epoch': 0.03}
  3%|▎         | 340/10395 [56:35<20:53:28,  7.48s/it]  3%|▎         | 341/10395 [56:43<20:59:49,  7.52s/it]                                                      {'loss': 1.0169, 'learning_rate': 1.9999591790360097e-05, 'epoch': 0.03}
  3%|▎         | 341/10395 [56:43<20:59:49,  7.52s/it]  3%|▎         | 342/10395 [56:51<21:26:28,  7.68s/it]                                                      {'loss': 0.9336, 'learning_rate': 1.999956315279363e-05, 'epoch': 0.03}
  3%|▎         | 342/10395 [56:51<21:26:28,  7.68s/it]  3%|▎         | 343/10395 [56:59<21:55:20,  7.85s/it]                                                      {'loss': 1.0301, 'learning_rate': 1.999953354449094e-05, 'epoch': 0.03}
  3%|▎         | 343/10395 [56:59<21:55:20,  7.85s/it]  3%|▎         | 344/10395 [57:07<21:39:09,  7.76s/it]                                                      {'loss': 1.0743, 'learning_rate': 1.9999502965454902e-05, 'epoch': 0.03}
  3%|▎         | 344/10395 [57:07<21:39:09,  7.76s/it]  3%|▎         | 345/10395 [57:17<23:39:42,  8.48s/it]                                                      {'loss': 1.0601, 'learning_rate': 1.9999471415688484e-05, 'epoch': 0.03}
  3%|▎         | 345/10395 [57:17<23:39:42,  8.48s/it]  3%|▎         | 346/10395 [57:24<22:48:31,  8.17s/it]                                                      {'loss': 1.0464, 'learning_rate': 1.999943889519475e-05, 'epoch': 0.03}
  3%|▎         | 346/10395 [57:24<22:48:31,  8.17s/it]  3%|▎         | 347/10395 [57:33<23:04:26,  8.27s/it]                                                      {'loss': 1.0215, 'learning_rate': 1.999940540397686e-05, 'epoch': 0.03}
  3%|▎         | 347/10395 [57:33<23:04:26,  8.27s/it]  3%|▎         | 348/10395 [57:40<22:34:38,  8.09s/it]                                                      {'loss': 0.9906, 'learning_rate': 1.9999370942038065e-05, 'epoch': 0.03}
  3%|▎         | 348/10395 [57:40<22:34:38,  8.09s/it]  3%|▎         | 349/10395 [57:49<22:42:42,  8.14s/it]                                                      {'loss': 0.9922, 'learning_rate': 1.99993355093817e-05, 'epoch': 0.03}
  3%|▎         | 349/10395 [57:49<22:42:42,  8.14s/it]  3%|▎         | 350/10395 [57:56<22:14:39,  7.97s/it]                                                      {'loss': 0.9945, 'learning_rate': 1.9999299106011216e-05, 'epoch': 0.03}
  3%|▎         | 350/10395 [57:56<22:14:39,  7.97s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  3%|▎         | 351/10395 [59:35<98:40:14, 35.37s/it]                                                      {'loss': 1.0214, 'learning_rate': 1.999926173193014e-05, 'epoch': 0.03}
  3%|▎         | 351/10395 [59:35<98:40:14, 35.37s/it]  3%|▎         | 352/10395 [59:43<75:24:38, 27.03s/it]                                                      {'loss': 1.023, 'learning_rate': 1.999922338714211e-05, 'epoch': 0.03}
  3%|▎         | 352/10395 [59:43<75:24:38, 27.03s/it]  3%|▎         | 353/10395 [59:50<58:59:34, 21.15s/it]                                                      {'loss': 1.0748, 'learning_rate': 1.999918407165084e-05, 'epoch': 0.03}
  3%|▎         | 353/10395 [59:50<58:59:34, 21.15s/it]  3%|▎         | 354/10395 [59:58<47:35:06, 17.06s/it]                                                      {'loss': 1.0794, 'learning_rate': 1.9999143785460148e-05, 'epoch': 0.03}
  3%|▎         | 354/10395 [59:58<47:35:06, 17.06s/it]  3%|▎         | 355/10395 [1:00:15<47:06:59, 16.89s/it]                                                        {'loss': 0.3521, 'learning_rate': 1.9999102528573945e-05, 'epoch': 0.03}
  3%|▎         | 355/10395 [1:00:15<47:06:59, 16.89s/it]  3%|▎         | 356/10395 [1:00:22<39:11:12, 14.05s/it]                                                        {'loss': 0.9872, 'learning_rate': 1.9999060300996234e-05, 'epoch': 0.03}
  3%|▎         | 356/10395 [1:00:22<39:11:12, 14.05s/it]  3%|▎         | 357/10395 [1:00:30<34:18:10, 12.30s/it]                                                        {'loss': 0.9785, 'learning_rate': 1.999901710273112e-05, 'epoch': 0.03}
  3%|▎         | 357/10395 [1:00:30<34:18:10, 12.30s/it]  3%|▎         | 358/10395 [1:00:39<31:15:02, 11.21s/it]                                                        {'loss': 1.0737, 'learning_rate': 1.9998972933782795e-05, 'epoch': 0.03}
  3%|▎         | 358/10395 [1:00:39<31:15:02, 11.21s/it]  3%|▎         | 359/10395 [1:00:47<28:33:19, 10.24s/it]                                                        {'loss': 1.0446, 'learning_rate': 1.9998927794155543e-05, 'epoch': 0.03}
  3%|▎         | 359/10395 [1:00:47<28:33:19, 10.24s/it]  3%|▎         | 360/10395 [1:00:54<26:12:43,  9.40s/it]                                                        {'loss': 0.9664, 'learning_rate': 1.999888168385375e-05, 'epoch': 0.03}
  3%|▎         | 360/10395 [1:00:54<26:12:43,  9.40s/it]  3%|▎         | 361/10395 [1:01:02<24:42:24,  8.86s/it]                                                        {'loss': 0.9535, 'learning_rate': 1.999883460288189e-05, 'epoch': 0.03}
  3%|▎         | 361/10395 [1:01:02<24:42:24,  8.86s/it]  3%|▎         | 362/10395 [1:01:10<24:29:29,  8.79s/it]                                                        {'loss': 1.03, 'learning_rate': 1.9998786551244533e-05, 'epoch': 0.03}
  3%|▎         | 362/10395 [1:01:10<24:29:29,  8.79s/it]  3%|▎         | 363/10395 [1:01:18<23:23:52,  8.40s/it]                                                        {'loss': 1.0538, 'learning_rate': 1.999873752894635e-05, 'epoch': 0.03}
  3%|▎         | 363/10395 [1:01:18<23:23:52,  8.40s/it]  4%|▎         | 364/10395 [1:01:25<22:28:39,  8.07s/it]                                                        {'loss': 0.9781, 'learning_rate': 1.9998687535992088e-05, 'epoch': 0.04}
  4%|▎         | 364/10395 [1:01:25<22:28:39,  8.07s/it]  4%|▎         | 365/10395 [1:01:33<21:56:35,  7.88s/it]                                                        {'loss': 1.0938, 'learning_rate': 1.999863657238661e-05, 'epoch': 0.04}
  4%|▎         | 365/10395 [1:01:33<21:56:35,  7.88s/it]  4%|▎         | 366/10395 [1:01:40<21:48:50,  7.83s/it]                                                        {'loss': 0.95, 'learning_rate': 1.9998584638134864e-05, 'epoch': 0.04}
  4%|▎         | 366/10395 [1:01:40<21:48:50,  7.83s/it]  4%|▎         | 367/10395 [1:01:48<21:43:12,  7.80s/it]                                                        {'loss': 1.1088, 'learning_rate': 1.9998531733241884e-05, 'epoch': 0.04}
  4%|▎         | 367/10395 [1:01:48<21:43:12,  7.80s/it]  4%|▎         | 368/10395 [1:01:56<21:38:56,  7.77s/it]                                                        {'loss': 0.9769, 'learning_rate': 1.9998477857712815e-05, 'epoch': 0.04}
  4%|▎         | 368/10395 [1:01:56<21:38:56,  7.77s/it]  4%|▎         | 369/10395 [1:02:03<21:19:17,  7.66s/it]                                                        {'loss': 1.014, 'learning_rate': 1.9998423011552877e-05, 'epoch': 0.04}
  4%|▎         | 369/10395 [1:02:03<21:19:17,  7.66s/it]  4%|▎         | 370/10395 [1:02:10<20:54:40,  7.51s/it]                                                        {'loss': 1.0661, 'learning_rate': 1.9998367194767404e-05, 'epoch': 0.04}
  4%|▎         | 370/10395 [1:02:10<20:54:40,  7.51s/it]  4%|▎         | 371/10395 [1:02:19<21:36:04,  7.76s/it]                                                        {'loss': 1.0092, 'learning_rate': 1.9998310407361806e-05, 'epoch': 0.04}
  4%|▎         | 371/10395 [1:02:19<21:36:04,  7.76s/it]  4%|▎         | 372/10395 [1:02:27<21:46:06,  7.82s/it]                                                        {'loss': 0.962, 'learning_rate': 1.9998252649341607e-05, 'epoch': 0.04}
  4%|▎         | 372/10395 [1:02:27<21:46:06,  7.82s/it]  4%|▎         | 373/10395 [1:02:35<21:49:33,  7.84s/it]                                                        {'loss': 1.0463, 'learning_rate': 1.99981939207124e-05, 'epoch': 0.04}
  4%|▎         | 373/10395 [1:02:35<21:49:33,  7.84s/it]  4%|▎         | 374/10395 [1:02:42<21:43:47,  7.81s/it]                                                        {'loss': 1.0248, 'learning_rate': 1.9998134221479895e-05, 'epoch': 0.04}
  4%|▎         | 374/10395 [1:02:42<21:43:47,  7.81s/it]  4%|▎         | 375/10395 [1:02:50<21:46:43,  7.82s/it]                                                        {'loss': 1.0267, 'learning_rate': 1.999807355164989e-05, 'epoch': 0.04}
  4%|▎         | 375/10395 [1:02:50<21:46:43,  7.82s/it]  4%|▎         | 376/10395 [1:02:58<21:48:23,  7.84s/it]                                                        {'loss': 1.0929, 'learning_rate': 1.9998011911228267e-05, 'epoch': 0.04}
  4%|▎         | 376/10395 [1:02:58<21:48:23,  7.84s/it]  4%|▎         | 377/10395 [1:03:05<21:19:10,  7.66s/it]                                                        {'loss': 1.0693, 'learning_rate': 1.9997949300221014e-05, 'epoch': 0.04}
  4%|▎         | 377/10395 [1:03:05<21:19:10,  7.66s/it]  4%|▎         | 378/10395 [1:03:14<22:10:57,  7.97s/it]                                                        {'loss': 0.9597, 'learning_rate': 1.999788571863421e-05, 'epoch': 0.04}
  4%|▎         | 378/10395 [1:03:14<22:10:57,  7.97s/it]  4%|▎         | 379/10395 [1:03:23<22:41:19,  8.15s/it]                                                        {'loss': 1.0108, 'learning_rate': 1.9997821166474023e-05, 'epoch': 0.04}
  4%|▎         | 379/10395 [1:03:23<22:41:19,  8.15s/it]  4%|▎         | 380/10395 [1:03:30<22:08:46,  7.96s/it]                                                        {'loss': 1.114, 'learning_rate': 1.9997755643746724e-05, 'epoch': 0.04}
  4%|▎         | 380/10395 [1:03:30<22:08:46,  7.96s/it]  4%|▎         | 381/10395 [1:03:39<23:00:57,  8.27s/it]                                                        {'loss': 0.9906, 'learning_rate': 1.9997689150458676e-05, 'epoch': 0.04}
  4%|▎         | 381/10395 [1:03:39<23:00:57,  8.27s/it]  4%|▎         | 382/10395 [1:03:47<22:47:41,  8.20s/it]                                                        {'loss': 1.0598, 'learning_rate': 1.9997621686616326e-05, 'epoch': 0.04}
  4%|▎         | 382/10395 [1:03:47<22:47:41,  8.20s/it]  4%|▎         | 383/10395 [1:03:55<22:10:37,  7.97s/it]                                                        {'loss': 0.9636, 'learning_rate': 1.9997553252226226e-05, 'epoch': 0.04}
  4%|▎         | 383/10395 [1:03:55<22:10:37,  7.97s/it]  4%|▎         | 384/10395 [1:04:02<21:48:29,  7.84s/it]                                                        {'loss': 1.0397, 'learning_rate': 1.9997483847295026e-05, 'epoch': 0.04}
  4%|▎         | 384/10395 [1:04:02<21:48:29,  7.84s/it]  4%|▎         | 385/10395 [1:04:10<21:55:15,  7.88s/it]                                                        {'loss': 1.0135, 'learning_rate': 1.999741347182946e-05, 'epoch': 0.04}
  4%|▎         | 385/10395 [1:04:10<21:55:15,  7.88s/it]  4%|▎         | 386/10395 [1:04:18<21:51:00,  7.86s/it]                                                        {'loss': 1.0276, 'learning_rate': 1.9997342125836354e-05, 'epoch': 0.04}
  4%|▎         | 386/10395 [1:04:18<21:51:00,  7.86s/it]  4%|▎         | 387/10395 [1:04:25<21:22:43,  7.69s/it]                                                        {'loss': 1.025, 'learning_rate': 1.9997269809322638e-05, 'epoch': 0.04}
  4%|▎         | 387/10395 [1:04:25<21:22:43,  7.69s/it]  4%|▎         | 388/10395 [1:04:33<21:18:48,  7.67s/it]                                                        {'loss': 1.0244, 'learning_rate': 1.9997196522295336e-05, 'epoch': 0.04}
  4%|▎         | 388/10395 [1:04:33<21:18:48,  7.67s/it]  4%|▎         | 389/10395 [1:04:40<21:05:05,  7.59s/it]                                                        {'loss': 1.0782, 'learning_rate': 1.999712226476156e-05, 'epoch': 0.04}
  4%|▎         | 389/10395 [1:04:40<21:05:05,  7.59s/it]  4%|▍         | 390/10395 [1:04:48<21:15:31,  7.65s/it]                                                        {'loss': 1.1309, 'learning_rate': 1.9997047036728518e-05, 'epoch': 0.04}
  4%|▍         | 390/10395 [1:04:48<21:15:31,  7.65s/it]  4%|▍         | 391/10395 [1:04:56<21:37:55,  7.78s/it]                                                        {'loss': 1.0147, 'learning_rate': 1.999697083820351e-05, 'epoch': 0.04}
  4%|▍         | 391/10395 [1:04:56<21:37:55,  7.78s/it]  4%|▍         | 392/10395 [1:05:04<22:01:34,  7.93s/it]                                                        {'loss': 1.0585, 'learning_rate': 1.999689366919394e-05, 'epoch': 0.04}
  4%|▍         | 392/10395 [1:05:04<22:01:34,  7.93s/it]  4%|▍         | 393/10395 [1:05:12<22:03:46,  7.94s/it]                                                        {'loss': 0.9693, 'learning_rate': 1.9996815529707296e-05, 'epoch': 0.04}
  4%|▍         | 393/10395 [1:05:12<22:03:46,  7.94s/it]  4%|▍         | 394/10395 [1:05:20<22:05:30,  7.95s/it]                                                        {'loss': 0.9985, 'learning_rate': 1.9996736419751164e-05, 'epoch': 0.04}
  4%|▍         | 394/10395 [1:05:20<22:05:30,  7.95s/it]  4%|▍         | 395/10395 [1:05:29<22:21:49,  8.05s/it]                                                        {'loss': 1.0407, 'learning_rate': 1.9996656339333224e-05, 'epoch': 0.04}
  4%|▍         | 395/10395 [1:05:29<22:21:49,  8.05s/it]  4%|▍         | 396/10395 [1:05:36<21:46:52,  7.84s/it]                                                        {'loss': 1.0212, 'learning_rate': 1.9996575288461247e-05, 'epoch': 0.04}
  4%|▍         | 396/10395 [1:05:36<21:46:52,  7.84s/it]  4%|▍         | 397/10395 [1:05:44<22:11:33,  7.99s/it]                                                        {'loss': 1.0523, 'learning_rate': 1.9996493267143107e-05, 'epoch': 0.04}
  4%|▍         | 397/10395 [1:05:44<22:11:33,  7.99s/it]  4%|▍         | 398/10395 [1:05:52<21:56:17,  7.90s/it]                                                        {'loss': 1.0293, 'learning_rate': 1.999641027538676e-05, 'epoch': 0.04}
  4%|▍         | 398/10395 [1:05:52<21:56:17,  7.90s/it]  4%|▍         | 399/10395 [1:05:59<21:27:52,  7.73s/it]                                                        {'loss': 1.0022, 'learning_rate': 1.9996326313200266e-05, 'epoch': 0.04}
  4%|▍         | 399/10395 [1:05:59<21:27:52,  7.73s/it]  4%|▍         | 400/10395 [1:06:07<21:13:40,  7.65s/it]                                                        {'loss': 1.1012, 'learning_rate': 1.999624138059178e-05, 'epoch': 0.04}
  4%|▍         | 400/10395 [1:06:07<21:13:40,  7.65s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  4%|▍         | 401/10395 [1:07:47<98:30:12, 35.48s/it]                                                        {'loss': 1.0534, 'learning_rate': 1.999615547756954e-05, 'epoch': 0.04}
  4%|▍         | 401/10395 [1:07:47<98:30:12, 35.48s/it]  4%|▍         | 402/10395 [1:07:55<75:28:20, 27.19s/it]                                                        {'loss': 1.0418, 'learning_rate': 1.9996068604141885e-05, 'epoch': 0.04}
  4%|▍         | 402/10395 [1:07:55<75:28:20, 27.19s/it]  4%|▍         | 403/10395 [1:08:12<67:10:05, 24.20s/it]                                                        {'loss': 0.3296, 'learning_rate': 1.9995980760317256e-05, 'epoch': 0.04}
  4%|▍         | 403/10395 [1:08:12<67:10:05, 24.20s/it]  4%|▍         | 404/10395 [1:08:20<53:45:08, 19.37s/it]                                                        {'loss': 0.9584, 'learning_rate': 1.9995891946104175e-05, 'epoch': 0.04}
  4%|▍         | 404/10395 [1:08:20<53:45:08, 19.37s/it]  4%|▍         | 405/10395 [1:08:28<44:16:55, 15.96s/it]                                                        {'loss': 0.9639, 'learning_rate': 1.9995802161511265e-05, 'epoch': 0.04}
  4%|▍         | 405/10395 [1:08:28<44:16:55, 15.96s/it]  4%|▍         | 406/10395 [1:08:36<37:23:53, 13.48s/it]                                                        {'loss': 1.1282, 'learning_rate': 1.999571140654724e-05, 'epoch': 0.04}
  4%|▍         | 406/10395 [1:08:36<37:23:53, 13.48s/it]  4%|▍         | 407/10395 [1:08:43<32:22:25, 11.67s/it]                                                        {'loss': 1.1007, 'learning_rate': 1.9995619681220916e-05, 'epoch': 0.04}
  4%|▍         | 407/10395 [1:08:43<32:22:25, 11.67s/it]  4%|▍         | 408/10395 [1:08:51<28:49:05, 10.39s/it]                                                        {'loss': 1.0249, 'learning_rate': 1.999552698554119e-05, 'epoch': 0.04}
  4%|▍         | 408/10395 [1:08:51<28:49:05, 10.39s/it]  4%|▍         | 409/10395 [1:08:59<26:34:05,  9.58s/it]                                                        {'loss': 1.0308, 'learning_rate': 1.999543331951707e-05, 'epoch': 0.04}
  4%|▍         | 409/10395 [1:08:59<26:34:05,  9.58s/it]  4%|▍         | 410/10395 [1:09:06<24:50:39,  8.96s/it]                                                        {'loss': 1.0461, 'learning_rate': 1.9995338683157638e-05, 'epoch': 0.04}
  4%|▍         | 410/10395 [1:09:06<24:50:39,  8.96s/it]  4%|▍         | 411/10395 [1:09:14<24:05:22,  8.69s/it]                                                        {'loss': 1.0206, 'learning_rate': 1.999524307647209e-05, 'epoch': 0.04}
  4%|▍         | 411/10395 [1:09:14<24:05:22,  8.69s/it]  4%|▍         | 412/10395 [1:09:32<31:42:01, 11.43s/it]                                                        {'loss': 0.3215, 'learning_rate': 1.9995146499469705e-05, 'epoch': 0.04}
  4%|▍         | 412/10395 [1:09:32<31:42:01, 11.43s/it]  4%|▍         | 413/10395 [1:09:39<28:19:51, 10.22s/it]                                                        {'loss': 0.9893, 'learning_rate': 1.999504895215986e-05, 'epoch': 0.04}
  4%|▍         | 413/10395 [1:09:39<28:19:51, 10.22s/it]  4%|▍         | 414/10395 [1:09:47<26:06:27,  9.42s/it]                                                        {'loss': 0.9821, 'learning_rate': 1.9994950434552016e-05, 'epoch': 0.04}
  4%|▍         | 414/10395 [1:09:47<26:06:27,  9.42s/it]  4%|▍         | 415/10395 [1:09:54<24:29:41,  8.84s/it]                                                        {'loss': 1.0534, 'learning_rate': 1.9994850946655745e-05, 'epoch': 0.04}
  4%|▍         | 415/10395 [1:09:54<24:29:41,  8.84s/it]  4%|▍         | 416/10395 [1:10:02<23:21:49,  8.43s/it]                                                        {'loss': 1.0939, 'learning_rate': 1.9994750488480706e-05, 'epoch': 0.04}
  4%|▍         | 416/10395 [1:10:02<23:21:49,  8.43s/it]  4%|▍         | 417/10395 [1:10:09<22:41:55,  8.19s/it]                                                        {'loss': 1.0657, 'learning_rate': 1.9994649060036642e-05, 'epoch': 0.04}
  4%|▍         | 417/10395 [1:10:09<22:41:55,  8.19s/it]  4%|▍         | 418/10395 [1:10:18<22:49:31,  8.24s/it]                                                        {'loss': 1.1804, 'learning_rate': 1.9994546661333414e-05, 'epoch': 0.04}
  4%|▍         | 418/10395 [1:10:18<22:49:31,  8.24s/it]  4%|▍         | 419/10395 [1:10:25<22:19:13,  8.05s/it]                                                        {'loss': 1.0052, 'learning_rate': 1.999444329238095e-05, 'epoch': 0.04}
  4%|▍         | 419/10395 [1:10:25<22:19:13,  8.05s/it]  4%|▍         | 420/10395 [1:10:33<21:40:36,  7.82s/it]                                                        {'loss': 1.0411, 'learning_rate': 1.9994338953189293e-05, 'epoch': 0.04}
  4%|▍         | 420/10395 [1:10:33<21:40:36,  7.82s/it]  4%|▍         | 421/10395 [1:10:40<21:24:43,  7.73s/it]                                                        {'loss': 1.0439, 'learning_rate': 1.999423364376856e-05, 'epoch': 0.04}
  4%|▍         | 421/10395 [1:10:40<21:24:43,  7.73s/it]  4%|▍         | 422/10395 [1:10:49<22:17:34,  8.05s/it]                                                        {'loss': 1.0407, 'learning_rate': 1.999412736412899e-05, 'epoch': 0.04}
  4%|▍         | 422/10395 [1:10:49<22:17:34,  8.05s/it]  4%|▍         | 423/10395 [1:10:56<21:42:15,  7.84s/it]                                                        {'loss': 1.0901, 'learning_rate': 1.9994020114280892e-05, 'epoch': 0.04}
  4%|▍         | 423/10395 [1:10:56<21:42:15,  7.84s/it]  4%|▍         | 424/10395 [1:11:04<21:20:42,  7.71s/it]                                                        {'loss': 1.1433, 'learning_rate': 1.999391189423468e-05, 'epoch': 0.04}
  4%|▍         | 424/10395 [1:11:04<21:20:42,  7.71s/it]  4%|▍         | 425/10395 [1:11:11<21:13:28,  7.66s/it]                                                        {'loss': 1.0041, 'learning_rate': 1.9993802704000857e-05, 'epoch': 0.04}
  4%|▍         | 425/10395 [1:11:11<21:13:28,  7.66s/it]  4%|▍         | 426/10395 [1:11:20<21:55:20,  7.92s/it]                                                        {'loss': 1.05, 'learning_rate': 1.999369254359002e-05, 'epoch': 0.04}
  4%|▍         | 426/10395 [1:11:20<21:55:20,  7.92s/it]  4%|▍         | 427/10395 [1:11:28<22:06:11,  7.98s/it]                                                        {'loss': 1.0075, 'learning_rate': 1.999358141301287e-05, 'epoch': 0.04}
  4%|▍         | 427/10395 [1:11:28<22:06:11,  7.98s/it]  4%|▍         | 428/10395 [1:11:36<21:53:44,  7.91s/it]                                                        {'loss': 1.0133, 'learning_rate': 1.9993469312280193e-05, 'epoch': 0.04}
  4%|▍         | 428/10395 [1:11:36<21:53:44,  7.91s/it]  4%|▍         | 429/10395 [1:11:43<21:46:50,  7.87s/it]                                                        {'loss': 1.0659, 'learning_rate': 1.9993356241402876e-05, 'epoch': 0.04}
  4%|▍         | 429/10395 [1:11:43<21:46:50,  7.87s/it]  4%|▍         | 430/10395 [1:11:52<21:56:33,  7.93s/it]                                                        {'loss': 1.0646, 'learning_rate': 1.9993242200391883e-05, 'epoch': 0.04}
  4%|▍         | 430/10395 [1:11:52<21:56:33,  7.93s/it]  4%|▍         | 431/10395 [1:11:59<21:48:44,  7.88s/it]                                                        {'loss': 1.0807, 'learning_rate': 1.9993127189258298e-05, 'epoch': 0.04}
  4%|▍         | 431/10395 [1:11:59<21:48:44,  7.88s/it]  4%|▍         | 432/10395 [1:12:07<21:40:32,  7.83s/it]                                                        {'loss': 1.057, 'learning_rate': 1.999301120801328e-05, 'epoch': 0.04}
  4%|▍         | 432/10395 [1:12:07<21:40:32,  7.83s/it]  4%|▍         | 433/10395 [1:12:15<21:58:34,  7.94s/it]                                                        {'loss': 1.059, 'learning_rate': 1.9992894256668086e-05, 'epoch': 0.04}
  4%|▍         | 433/10395 [1:12:15<21:58:34,  7.94s/it]  4%|▍         | 434/10395 [1:12:23<22:04:45,  7.98s/it]                                                        {'loss': 1.0934, 'learning_rate': 1.999277633523408e-05, 'epoch': 0.04}
  4%|▍         | 434/10395 [1:12:23<22:04:45,  7.98s/it]  4%|▍         | 435/10395 [1:12:31<21:26:03,  7.75s/it]                                                        {'loss': 1.0673, 'learning_rate': 1.9992657443722697e-05, 'epoch': 0.04}
  4%|▍         | 435/10395 [1:12:31<21:26:03,  7.75s/it]  4%|▍         | 436/10395 [1:12:47<28:18:01, 10.23s/it]                                                        {'loss': 0.3479, 'learning_rate': 1.999253758214548e-05, 'epoch': 0.04}
  4%|▍         | 436/10395 [1:12:47<28:18:01, 10.23s/it]  4%|▍         | 437/10395 [1:12:54<25:58:55,  9.39s/it]                                                        {'loss': 1.0808, 'learning_rate': 1.9992416750514074e-05, 'epoch': 0.04}
  4%|▍         | 437/10395 [1:12:54<25:58:55,  9.39s/it]  4%|▍         | 438/10395 [1:13:03<25:30:12,  9.22s/it]                                                        {'loss': 1.0437, 'learning_rate': 1.9992294948840204e-05, 'epoch': 0.04}
  4%|▍         | 438/10395 [1:13:03<25:30:12,  9.22s/it]  4%|▍         | 439/10395 [1:13:10<23:53:19,  8.64s/it]                                                        {'loss': 1.0474, 'learning_rate': 1.999217217713569e-05, 'epoch': 0.04}
  4%|▍         | 439/10395 [1:13:10<23:53:19,  8.64s/it]  4%|▍         | 440/10395 [1:13:18<23:08:37,  8.37s/it]                                                        {'loss': 1.0124, 'learning_rate': 1.9992048435412457e-05, 'epoch': 0.04}
  4%|▍         | 440/10395 [1:13:18<23:08:37,  8.37s/it]  4%|▍         | 441/10395 [1:13:25<22:29:37,  8.14s/it]                                                        {'loss': 1.0076, 'learning_rate': 1.9991923723682514e-05, 'epoch': 0.04}
  4%|▍         | 441/10395 [1:13:25<22:29:37,  8.14s/it]  4%|▍         | 442/10395 [1:13:33<22:09:43,  8.02s/it]                                                        {'loss': 0.9802, 'learning_rate': 1.9991798041957972e-05, 'epoch': 0.04}
  4%|▍         | 442/10395 [1:13:33<22:09:43,  8.02s/it]  4%|▍         | 443/10395 [1:13:40<21:34:03,  7.80s/it]                                                        {'loss': 1.0716, 'learning_rate': 1.9991671390251024e-05, 'epoch': 0.04}
  4%|▍         | 443/10395 [1:13:40<21:34:03,  7.80s/it]  4%|▍         | 444/10395 [1:13:49<22:26:28,  8.12s/it]                                                        {'loss': 1.0046, 'learning_rate': 1.9991543768573974e-05, 'epoch': 0.04}
  4%|▍         | 444/10395 [1:13:49<22:26:28,  8.12s/it]  4%|▍         | 445/10395 [1:13:57<22:24:55,  8.11s/it]                                                        {'loss': 0.9918, 'learning_rate': 1.9991415176939203e-05, 'epoch': 0.04}
  4%|▍         | 445/10395 [1:13:57<22:24:55,  8.11s/it]  4%|▍         | 446/10395 [1:14:05<21:37:29,  7.82s/it]                                                        {'loss': 1.0562, 'learning_rate': 1.99912856153592e-05, 'epoch': 0.04}
  4%|▍         | 446/10395 [1:14:05<21:37:29,  7.82s/it]  4%|▍         | 447/10395 [1:14:12<21:19:52,  7.72s/it]                                                        {'loss': 0.9966, 'learning_rate': 1.9991155083846537e-05, 'epoch': 0.04}
  4%|▍         | 447/10395 [1:14:12<21:19:52,  7.72s/it]  4%|▍         | 448/10395 [1:14:29<29:22:56, 10.63s/it]                                                        {'loss': 0.3703, 'learning_rate': 1.9991023582413897e-05, 'epoch': 0.04}
  4%|▍         | 448/10395 [1:14:29<29:22:56, 10.63s/it]  4%|▍         | 449/10395 [1:14:37<26:50:51,  9.72s/it]                                                        {'loss': 1.0699, 'learning_rate': 1.9990891111074037e-05, 'epoch': 0.04}
  4%|▍         | 449/10395 [1:14:37<26:50:51,  9.72s/it]  4%|▍         | 450/10395 [1:14:45<25:09:21,  9.11s/it]                                                        {'loss': 1.008, 'learning_rate': 1.9990757669839812e-05, 'epoch': 0.04}
  4%|▍         | 450/10395 [1:14:45<25:09:21,  9.11s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  4%|▍         | 451/10395 [1:16:25<100:37:31, 36.43s/it]                                                         {'loss': 1.0764, 'learning_rate': 1.999062325872419e-05, 'epoch': 0.04}
  4%|▍         | 451/10395 [1:16:25<100:37:31, 36.43s/it]  4%|▍         | 452/10395 [1:16:33<76:54:08, 27.84s/it]                                                         {'loss': 1.026, 'learning_rate': 1.999048787774021e-05, 'epoch': 0.04}
  4%|▍         | 452/10395 [1:16:33<76:54:08, 27.84s/it]  4%|▍         | 453/10395 [1:16:41<60:25:41, 21.88s/it]                                                        {'loss': 1.1069, 'learning_rate': 1.9990351526901012e-05, 'epoch': 0.04}
  4%|▍         | 453/10395 [1:16:41<60:25:41, 21.88s/it]  4%|▍         | 454/10395 [1:16:49<48:47:43, 17.67s/it]                                                        {'loss': 0.9863, 'learning_rate': 1.9990214206219843e-05, 'epoch': 0.04}
  4%|▍         | 454/10395 [1:16:49<48:47:43, 17.67s/it]  4%|▍         | 455/10395 [1:16:56<40:25:14, 14.64s/it]                                                        {'loss': 0.8745, 'learning_rate': 1.9990075915710028e-05, 'epoch': 0.04}
  4%|▍         | 455/10395 [1:16:56<40:25:14, 14.64s/it]  4%|▍         | 456/10395 [1:17:04<34:25:48, 12.47s/it]                                                        {'loss': 1.0434, 'learning_rate': 1.998993665538499e-05, 'epoch': 0.04}
  4%|▍         | 456/10395 [1:17:04<34:25:48, 12.47s/it]  4%|▍         | 457/10395 [1:17:11<30:38:09, 11.10s/it]                                                        {'loss': 1.0792, 'learning_rate': 1.998979642525825e-05, 'epoch': 0.04}
  4%|▍         | 457/10395 [1:17:11<30:38:09, 11.10s/it]  4%|▍         | 458/10395 [1:17:19<27:46:14, 10.06s/it]                                                        {'loss': 1.0452, 'learning_rate': 1.9989655225343422e-05, 'epoch': 0.04}
  4%|▍         | 458/10395 [1:17:19<27:46:14, 10.06s/it]  4%|▍         | 459/10395 [1:17:28<26:54:29,  9.75s/it]                                                        {'loss': 1.1016, 'learning_rate': 1.998951305565421e-05, 'epoch': 0.04}
  4%|▍         | 459/10395 [1:17:28<26:54:29,  9.75s/it]  4%|▍         | 460/10395 [1:17:37<26:01:22,  9.43s/it]                                                        {'loss': 0.9671, 'learning_rate': 1.998936991620442e-05, 'epoch': 0.04}
  4%|▍         | 460/10395 [1:17:37<26:01:22,  9.43s/it]  4%|▍         | 461/10395 [1:17:45<24:54:37,  9.03s/it]                                                        {'loss': 0.9403, 'learning_rate': 1.9989225807007947e-05, 'epoch': 0.04}
  4%|▍         | 461/10395 [1:17:45<24:54:37,  9.03s/it]  4%|▍         | 462/10395 [1:17:53<23:59:22,  8.69s/it]                                                        {'loss': 1.0242, 'learning_rate': 1.9989080728078778e-05, 'epoch': 0.04}
  4%|▍         | 462/10395 [1:17:53<23:59:22,  8.69s/it]  4%|▍         | 463/10395 [1:18:01<23:28:17,  8.51s/it]                                                        {'loss': 0.9561, 'learning_rate': 1.9988934679431e-05, 'epoch': 0.04}
  4%|▍         | 463/10395 [1:18:01<23:28:17,  8.51s/it]  4%|▍         | 464/10395 [1:18:09<22:52:51,  8.29s/it]                                                        {'loss': 0.9166, 'learning_rate': 1.998878766107879e-05, 'epoch': 0.04}
  4%|▍         | 464/10395 [1:18:09<22:52:51,  8.29s/it]  4%|▍         | 465/10395 [1:18:27<30:50:50, 11.18s/it]                                                        {'loss': 0.3693, 'learning_rate': 1.998863967303642e-05, 'epoch': 0.04}
  4%|▍         | 465/10395 [1:18:27<30:50:50, 11.18s/it]  4%|▍         | 466/10395 [1:18:34<27:58:14, 10.14s/it]                                                        {'loss': 1.012, 'learning_rate': 1.9988490715318253e-05, 'epoch': 0.04}
  4%|▍         | 466/10395 [1:18:34<27:58:14, 10.14s/it]  4%|▍         | 467/10395 [1:18:42<25:51:54,  9.38s/it]                                                        {'loss': 1.0034, 'learning_rate': 1.9988340787938754e-05, 'epoch': 0.04}
  4%|▍         | 467/10395 [1:18:42<25:51:54,  9.38s/it]  5%|▍         | 468/10395 [1:18:49<24:22:53,  8.84s/it]                                                        {'loss': 0.9875, 'learning_rate': 1.9988189890912482e-05, 'epoch': 0.05}
  5%|▍         | 468/10395 [1:18:49<24:22:53,  8.84s/it]  5%|▍         | 469/10395 [1:18:58<23:51:59,  8.66s/it]                                                        {'loss': 0.9334, 'learning_rate': 1.9988038024254077e-05, 'epoch': 0.05}
  5%|▍         | 469/10395 [1:18:58<23:51:59,  8.66s/it]  5%|▍         | 470/10395 [1:19:05<22:52:52,  8.30s/it]                                                        {'loss': 1.011, 'learning_rate': 1.9987885187978283e-05, 'epoch': 0.05}
  5%|▍         | 470/10395 [1:19:05<22:52:52,  8.30s/it]  5%|▍         | 471/10395 [1:19:13<22:06:58,  8.02s/it]                                                        {'loss': 1.0163, 'learning_rate': 1.998773138209994e-05, 'epoch': 0.05}
  5%|▍         | 471/10395 [1:19:13<22:06:58,  8.02s/it]  5%|▍         | 472/10395 [1:19:20<21:52:20,  7.94s/it]                                                        {'loss': 0.9939, 'learning_rate': 1.9987576606633978e-05, 'epoch': 0.05}
  5%|▍         | 472/10395 [1:19:20<21:52:20,  7.94s/it]  5%|▍         | 473/10395 [1:19:28<21:47:31,  7.91s/it]                                                        {'loss': 0.9952, 'learning_rate': 1.9987420861595425e-05, 'epoch': 0.05}
  5%|▍         | 473/10395 [1:19:28<21:47:31,  7.91s/it]  5%|▍         | 474/10395 [1:19:36<21:47:28,  7.91s/it]                                                        {'loss': 1.0333, 'learning_rate': 1.9987264146999396e-05, 'epoch': 0.05}
  5%|▍         | 474/10395 [1:19:36<21:47:28,  7.91s/it]  5%|▍         | 475/10395 [1:19:44<21:28:46,  7.79s/it]                                                        {'loss': 1.0348, 'learning_rate': 1.9987106462861107e-05, 'epoch': 0.05}
  5%|▍         | 475/10395 [1:19:44<21:28:46,  7.79s/it]  5%|▍         | 476/10395 [1:19:51<21:35:50,  7.84s/it]                                                        {'loss': 0.9964, 'learning_rate': 1.9986947809195865e-05, 'epoch': 0.05}
  5%|▍         | 476/10395 [1:19:51<21:35:50,  7.84s/it]  5%|▍         | 477/10395 [1:19:59<21:13:22,  7.70s/it]                                                        {'loss': 1.0901, 'learning_rate': 1.998678818601907e-05, 'epoch': 0.05}
  5%|▍         | 477/10395 [1:19:59<21:13:22,  7.70s/it]  5%|▍         | 478/10395 [1:20:08<22:08:43,  8.04s/it]                                                        {'loss': 0.9991, 'learning_rate': 1.998662759334622e-05, 'epoch': 0.05}
  5%|▍         | 478/10395 [1:20:08<22:08:43,  8.04s/it]  5%|▍         | 479/10395 [1:20:16<22:43:30,  8.25s/it]                                                        {'loss': 1.0084, 'learning_rate': 1.998646603119291e-05, 'epoch': 0.05}
  5%|▍         | 479/10395 [1:20:16<22:43:30,  8.25s/it]  5%|▍         | 480/10395 [1:20:25<22:43:04,  8.25s/it]                                                        {'loss': 1.0489, 'learning_rate': 1.998630349957481e-05, 'epoch': 0.05}
  5%|▍         | 480/10395 [1:20:25<22:43:04,  8.25s/it]  5%|▍         | 481/10395 [1:20:34<23:14:51,  8.44s/it]                                                        {'loss': 1.0936, 'learning_rate': 1.9986139998507715e-05, 'epoch': 0.05}
  5%|▍         | 481/10395 [1:20:34<23:14:51,  8.44s/it]  5%|▍         | 482/10395 [1:20:42<22:52:43,  8.31s/it]                                                        {'loss': 1.0538, 'learning_rate': 1.9985975528007488e-05, 'epoch': 0.05}
  5%|▍         | 482/10395 [1:20:42<22:52:43,  8.31s/it]  5%|▍         | 483/10395 [1:20:49<22:32:45,  8.19s/it]                                                        {'loss': 1.0194, 'learning_rate': 1.9985810088090093e-05, 'epoch': 0.05}
  5%|▍         | 483/10395 [1:20:49<22:32:45,  8.19s/it]  5%|▍         | 484/10395 [1:20:57<22:10:51,  8.06s/it]                                                        {'loss': 0.9538, 'learning_rate': 1.9985643678771595e-05, 'epoch': 0.05}
  5%|▍         | 484/10395 [1:20:57<22:10:51,  8.06s/it]  5%|▍         | 485/10395 [1:21:05<21:32:41,  7.83s/it]                                                        {'loss': 1.0204, 'learning_rate': 1.9985476300068152e-05, 'epoch': 0.05}
  5%|▍         | 485/10395 [1:21:05<21:32:41,  7.83s/it]  5%|▍         | 486/10395 [1:21:13<22:11:30,  8.06s/it]                                                        {'loss': 1.066, 'learning_rate': 1.9985307951996005e-05, 'epoch': 0.05}
  5%|▍         | 486/10395 [1:21:13<22:11:30,  8.06s/it]  5%|▍         | 487/10395 [1:21:22<22:31:59,  8.19s/it]                                                        {'loss': 1.007, 'learning_rate': 1.9985138634571504e-05, 'epoch': 0.05}
  5%|▍         | 487/10395 [1:21:22<22:31:59,  8.19s/it]  5%|▍         | 488/10395 [1:21:29<21:41:36,  7.88s/it]                                                        {'loss': 1.0318, 'learning_rate': 1.9984968347811083e-05, 'epoch': 0.05}
  5%|▍         | 488/10395 [1:21:29<21:41:36,  7.88s/it]  5%|▍         | 489/10395 [1:21:36<21:17:19,  7.74s/it]                                                        {'loss': 1.0357, 'learning_rate': 1.9984797091731267e-05, 'epoch': 0.05}
  5%|▍         | 489/10395 [1:21:36<21:17:19,  7.74s/it]  5%|▍         | 490/10395 [1:21:44<20:59:50,  7.63s/it]                                                        {'loss': 1.002, 'learning_rate': 1.998462486634869e-05, 'epoch': 0.05}
  5%|▍         | 490/10395 [1:21:44<20:59:50,  7.63s/it]  5%|▍         | 491/10395 [1:21:51<20:48:35,  7.56s/it]                                                        {'loss': 1.0307, 'learning_rate': 1.998445167168007e-05, 'epoch': 0.05}
  5%|▍         | 491/10395 [1:21:51<20:48:35,  7.56s/it]  5%|▍         | 492/10395 [1:21:59<20:57:19,  7.62s/it]                                                        {'loss': 1.0928, 'learning_rate': 1.998427750774222e-05, 'epoch': 0.05}
  5%|▍         | 492/10395 [1:21:59<20:57:19,  7.62s/it]  5%|▍         | 493/10395 [1:22:06<20:34:46,  7.48s/it]                                                        {'loss': 1.0974, 'learning_rate': 1.9984102374552043e-05, 'epoch': 0.05}
  5%|▍         | 493/10395 [1:22:06<20:34:46,  7.48s/it]  5%|▍         | 494/10395 [1:22:14<20:50:37,  7.58s/it]                                                        {'loss': 1.0263, 'learning_rate': 1.9983926272126544e-05, 'epoch': 0.05}
  5%|▍         | 494/10395 [1:22:14<20:50:37,  7.58s/it]  5%|▍         | 495/10395 [1:22:21<20:31:57,  7.47s/it]                                                        {'loss': 1.0043, 'learning_rate': 1.9983749200482816e-05, 'epoch': 0.05}
  5%|▍         | 495/10395 [1:22:21<20:31:57,  7.47s/it]  5%|▍         | 496/10395 [1:22:29<20:56:35,  7.62s/it]                                                        {'loss': 1.0263, 'learning_rate': 1.9983571159638053e-05, 'epoch': 0.05}
  5%|▍         | 496/10395 [1:22:29<20:56:35,  7.62s/it]  5%|▍         | 497/10395 [1:22:36<20:41:31,  7.53s/it]                                                        {'loss': 1.0522, 'learning_rate': 1.9983392149609536e-05, 'epoch': 0.05}
  5%|▍         | 497/10395 [1:22:36<20:41:31,  7.53s/it]  5%|▍         | 498/10395 [1:22:44<21:15:10,  7.73s/it]                                                        {'loss': 0.9831, 'learning_rate': 1.9983212170414648e-05, 'epoch': 0.05}
  5%|▍         | 498/10395 [1:22:44<21:15:10,  7.73s/it]  5%|▍         | 499/10395 [1:23:01<28:13:39, 10.27s/it]                                                        {'loss': 0.2901, 'learning_rate': 1.998303122207085e-05, 'epoch': 0.05}
  5%|▍         | 499/10395 [1:23:01<28:13:39, 10.27s/it]  5%|▍         | 500/10395 [1:23:08<25:54:38,  9.43s/it]                                                        {'loss': 1.1128, 'learning_rate': 1.998284930459572e-05, 'epoch': 0.05}
  5%|▍         | 500/10395 [1:23:08<25:54:38,  9.43s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  5%|▍         | 501/10395 [1:24:49<101:17:47, 36.86s/it]                                                         {'loss': 0.9393, 'learning_rate': 1.9982666418006912e-05, 'epoch': 0.05}
  5%|▍         | 501/10395 [1:24:49<101:17:47, 36.86s/it]  5%|▍         | 502/10395 [1:24:57<77:14:46, 28.11s/it]                                                         {'loss': 1.1025, 'learning_rate': 1.998248256232218e-05, 'epoch': 0.05}
  5%|▍         | 502/10395 [1:24:57<77:14:46, 28.11s/it]  5%|▍         | 503/10395 [1:25:04<60:03:13, 21.86s/it]                                                        {'loss': 1.1153, 'learning_rate': 1.9982297737559372e-05, 'epoch': 0.05}
  5%|▍         | 503/10395 [1:25:04<60:03:13, 21.86s/it]  5%|▍         | 504/10395 [1:25:11<48:16:14, 17.57s/it]                                                        {'loss': 0.9662, 'learning_rate': 1.9982111943736435e-05, 'epoch': 0.05}
  5%|▍         | 504/10395 [1:25:11<48:16:14, 17.57s/it]  5%|▍         | 505/10395 [1:25:19<40:01:24, 14.57s/it]                                                        {'loss': 1.0501, 'learning_rate': 1.9981925180871398e-05, 'epoch': 0.05}
  5%|▍         | 505/10395 [1:25:19<40:01:24, 14.57s/it]  5%|▍         | 506/10395 [1:25:27<34:17:54, 12.49s/it]                                                        {'loss': 1.0728, 'learning_rate': 1.99817374489824e-05, 'epoch': 0.05}
  5%|▍         | 506/10395 [1:25:27<34:17:54, 12.49s/it]  5%|▍         | 507/10395 [1:25:34<30:04:17, 10.95s/it]                                                        {'loss': 0.9823, 'learning_rate': 1.998154874808766e-05, 'epoch': 0.05}
  5%|▍         | 507/10395 [1:25:34<30:04:17, 10.95s/it]  5%|▍         | 508/10395 [1:25:43<28:25:29, 10.35s/it]                                                        {'loss': 1.0186, 'learning_rate': 1.99813590782055e-05, 'epoch': 0.05}
  5%|▍         | 508/10395 [1:25:43<28:25:29, 10.35s/it]  5%|▍         | 509/10395 [1:25:51<26:37:44,  9.70s/it]                                                        {'loss': 0.9688, 'learning_rate': 1.998116843935433e-05, 'epoch': 0.05}
  5%|▍         | 509/10395 [1:25:51<26:37:44,  9.70s/it]  5%|▍         | 510/10395 [1:25:58<24:35:48,  8.96s/it]                                                        {'loss': 1.0593, 'learning_rate': 1.9980976831552653e-05, 'epoch': 0.05}
  5%|▍         | 510/10395 [1:25:58<24:35:48,  8.96s/it]  5%|▍         | 511/10395 [1:26:07<24:43:47,  9.01s/it]                                                        {'loss': 0.9248, 'learning_rate': 1.998078425481908e-05, 'epoch': 0.05}
  5%|▍         | 511/10395 [1:26:07<24:43:47,  9.01s/it]  5%|▍         | 512/10395 [1:26:15<23:42:21,  8.64s/it]                                                        {'loss': 1.0574, 'learning_rate': 1.99805907091723e-05, 'epoch': 0.05}
  5%|▍         | 512/10395 [1:26:15<23:42:21,  8.64s/it]  5%|▍         | 513/10395 [1:26:23<22:39:08,  8.25s/it]                                                        {'loss': 1.0714, 'learning_rate': 1.9980396194631104e-05, 'epoch': 0.05}
  5%|▍         | 513/10395 [1:26:23<22:39:08,  8.25s/it]  5%|▍         | 514/10395 [1:26:32<23:36:48,  8.60s/it]                                                        {'loss': 1.0332, 'learning_rate': 1.9980200711214367e-05, 'epoch': 0.05}
  5%|▍         | 514/10395 [1:26:32<23:36:48,  8.60s/it]  5%|▍         | 515/10395 [1:26:40<23:02:48,  8.40s/it]                                                        {'loss': 1.0646, 'learning_rate': 1.9980004258941078e-05, 'epoch': 0.05}
  5%|▍         | 515/10395 [1:26:40<23:02:48,  8.40s/it]  5%|▍         | 516/10395 [1:26:49<23:25:49,  8.54s/it]                                                        {'loss': 1.0164, 'learning_rate': 1.9979806837830305e-05, 'epoch': 0.05}
  5%|▍         | 516/10395 [1:26:49<23:25:49,  8.54s/it]  5%|▍         | 517/10395 [1:26:56<22:31:40,  8.21s/it]                                                        {'loss': 1.0504, 'learning_rate': 1.9979608447901207e-05, 'epoch': 0.05}
  5%|▍         | 517/10395 [1:26:56<22:31:40,  8.21s/it]  5%|▍         | 518/10395 [1:27:04<22:11:24,  8.09s/it]                                                        {'loss': 1.0276, 'learning_rate': 1.997940908917305e-05, 'epoch': 0.05}
  5%|▍         | 518/10395 [1:27:04<22:11:24,  8.09s/it]  5%|▍         | 519/10395 [1:27:11<21:24:16,  7.80s/it]                                                        {'loss': 1.1592, 'learning_rate': 1.997920876166518e-05, 'epoch': 0.05}
  5%|▍         | 519/10395 [1:27:11<21:24:16,  7.80s/it]  5%|▌         | 520/10395 [1:27:19<21:27:04,  7.82s/it]                                                        {'loss': 1.1095, 'learning_rate': 1.9979007465397054e-05, 'epoch': 0.05}
  5%|▌         | 520/10395 [1:27:19<21:27:04,  7.82s/it]  5%|▌         | 521/10395 [1:27:27<21:16:46,  7.76s/it]                                                        {'loss': 1.0071, 'learning_rate': 1.9978805200388205e-05, 'epoch': 0.05}
  5%|▌         | 521/10395 [1:27:27<21:16:46,  7.76s/it]  5%|▌         | 522/10395 [1:27:35<21:23:26,  7.80s/it]                                                        {'loss': 0.9525, 'learning_rate': 1.9978601966658277e-05, 'epoch': 0.05}
  5%|▌         | 522/10395 [1:27:35<21:23:26,  7.80s/it]  5%|▌         | 523/10395 [1:27:42<21:27:27,  7.82s/it]                                                        {'loss': 0.9613, 'learning_rate': 1.997839776422699e-05, 'epoch': 0.05}
  5%|▌         | 523/10395 [1:27:42<21:27:27,  7.82s/it]  5%|▌         | 524/10395 [1:27:50<21:28:34,  7.83s/it]                                                        {'loss': 1.0253, 'learning_rate': 1.9978192593114173e-05, 'epoch': 0.05}
  5%|▌         | 524/10395 [1:27:50<21:28:34,  7.83s/it]  5%|▌         | 525/10395 [1:27:58<21:07:35,  7.71s/it]                                                        {'loss': 1.0707, 'learning_rate': 1.997798645333974e-05, 'epoch': 0.05}
  5%|▌         | 525/10395 [1:27:58<21:07:35,  7.71s/it]  5%|▌         | 526/10395 [1:28:06<21:34:57,  7.87s/it]                                                        {'loss': 1.0323, 'learning_rate': 1.9977779344923708e-05, 'epoch': 0.05}
  5%|▌         | 526/10395 [1:28:06<21:34:57,  7.87s/it]  5%|▌         | 527/10395 [1:28:13<21:10:05,  7.72s/it]                                                        {'loss': 1.0553, 'learning_rate': 1.997757126788618e-05, 'epoch': 0.05}
  5%|▌         | 527/10395 [1:28:13<21:10:05,  7.72s/it]  5%|▌         | 528/10395 [1:28:21<21:28:22,  7.83s/it]                                                        {'loss': 0.9589, 'learning_rate': 1.9977362222247353e-05, 'epoch': 0.05}
  5%|▌         | 528/10395 [1:28:21<21:28:22,  7.83s/it]  5%|▌         | 529/10395 [1:28:30<21:58:00,  8.02s/it]                                                        {'loss': 1.0616, 'learning_rate': 1.9977152208027525e-05, 'epoch': 0.05}
  5%|▌         | 529/10395 [1:28:30<21:58:00,  8.02s/it]  5%|▌         | 530/10395 [1:28:38<22:01:59,  8.04s/it]                                                        {'loss': 1.0075, 'learning_rate': 1.9976941225247085e-05, 'epoch': 0.05}
  5%|▌         | 530/10395 [1:28:38<22:01:59,  8.04s/it]  5%|▌         | 531/10395 [1:28:45<21:15:25,  7.76s/it]                                                        {'loss': 1.0603, 'learning_rate': 1.997672927392651e-05, 'epoch': 0.05}
  5%|▌         | 531/10395 [1:28:45<21:15:25,  7.76s/it]  5%|▌         | 532/10395 [1:28:53<21:47:34,  7.95s/it]                                                        {'loss': 1.0009, 'learning_rate': 1.9976516354086374e-05, 'epoch': 0.05}
  5%|▌         | 532/10395 [1:28:53<21:47:34,  7.95s/it]  5%|▌         | 533/10395 [1:29:01<21:16:11,  7.76s/it]                                                        {'loss': 1.0896, 'learning_rate': 1.9976302465747354e-05, 'epoch': 0.05}
  5%|▌         | 533/10395 [1:29:01<21:16:11,  7.76s/it]  5%|▌         | 534/10395 [1:29:18<28:37:53, 10.45s/it]                                                        {'loss': 0.3068, 'learning_rate': 1.9976087608930208e-05, 'epoch': 0.05}
  5%|▌         | 534/10395 [1:29:18<28:37:53, 10.45s/it]  5%|▌         | 535/10395 [1:29:26<27:00:24,  9.86s/it]                                                        {'loss': 1.0587, 'learning_rate': 1.9975871783655794e-05, 'epoch': 0.05}
  5%|▌         | 535/10395 [1:29:26<27:00:24,  9.86s/it]  5%|▌         | 536/10395 [1:29:34<25:41:54,  9.38s/it]                                                        {'loss': 0.997, 'learning_rate': 1.997565498994507e-05, 'epoch': 0.05}
  5%|▌         | 536/10395 [1:29:34<25:41:54,  9.38s/it]  5%|▌         | 537/10395 [1:29:42<24:14:27,  8.85s/it]                                                        {'loss': 1.0392, 'learning_rate': 1.9975437227819076e-05, 'epoch': 0.05}
  5%|▌         | 537/10395 [1:29:42<24:14:27,  8.85s/it]  5%|▌         | 538/10395 [1:29:58<30:10:31, 11.02s/it]                                                        {'loss': 0.3815, 'learning_rate': 1.9975218497298953e-05, 'epoch': 0.05}
  5%|▌         | 538/10395 [1:29:58<30:10:31, 11.02s/it]  5%|▌         | 539/10395 [1:30:05<27:08:16,  9.91s/it]                                                        {'loss': 0.9924, 'learning_rate': 1.9974998798405933e-05, 'epoch': 0.05}
  5%|▌         | 539/10395 [1:30:05<27:08:16,  9.91s/it]  5%|▌         | 540/10395 [1:30:13<25:08:11,  9.18s/it]                                                        {'loss': 0.9371, 'learning_rate': 1.997477813116135e-05, 'epoch': 0.05}
  5%|▌         | 540/10395 [1:30:13<25:08:11,  9.18s/it]  5%|▌         | 541/10395 [1:30:21<24:07:09,  8.81s/it]                                                        {'loss': 0.973, 'learning_rate': 1.997455649558662e-05, 'epoch': 0.05}
  5%|▌         | 541/10395 [1:30:21<24:07:09,  8.81s/it]  5%|▌         | 542/10395 [1:30:28<23:05:00,  8.43s/it]                                                        {'loss': 0.964, 'learning_rate': 1.9974333891703262e-05, 'epoch': 0.05}
  5%|▌         | 542/10395 [1:30:28<23:05:00,  8.43s/it]  5%|▌         | 543/10395 [1:30:38<23:59:07,  8.76s/it]                                                        {'loss': 0.923, 'learning_rate': 1.9974110319532886e-05, 'epoch': 0.05}
  5%|▌         | 543/10395 [1:30:38<23:59:07,  8.76s/it]  5%|▌         | 544/10395 [1:30:46<23:09:27,  8.46s/it]                                                        {'loss': 1.0972, 'learning_rate': 1.9973885779097192e-05, 'epoch': 0.05}
  5%|▌         | 544/10395 [1:30:46<23:09:27,  8.46s/it]  5%|▌         | 545/10395 [1:30:54<22:58:10,  8.39s/it]                                                        {'loss': 1.0486, 'learning_rate': 1.9973660270417984e-05, 'epoch': 0.05}
  5%|▌         | 545/10395 [1:30:54<22:58:10,  8.39s/it]  5%|▌         | 546/10395 [1:31:03<23:17:12,  8.51s/it]                                                        {'loss': 1.023, 'learning_rate': 1.997343379351715e-05, 'epoch': 0.05}
  5%|▌         | 546/10395 [1:31:03<23:17:12,  8.51s/it]  5%|▌         | 547/10395 [1:31:20<30:18:20, 11.08s/it]                                                        {'loss': 0.3253, 'learning_rate': 1.9973206348416676e-05, 'epoch': 0.05}
  5%|▌         | 547/10395 [1:31:20<30:18:20, 11.08s/it]  5%|▌         | 548/10395 [1:31:27<27:07:40,  9.92s/it]                                                        {'loss': 1.0314, 'learning_rate': 1.997297793513864e-05, 'epoch': 0.05}
  5%|▌         | 548/10395 [1:31:27<27:07:40,  9.92s/it]  5%|▌         | 549/10395 [1:31:34<24:55:48,  9.12s/it]                                                        {'loss': 1.0575, 'learning_rate': 1.9972748553705225e-05, 'epoch': 0.05}
  5%|▌         | 549/10395 [1:31:34<24:55:48,  9.12s/it]  5%|▌         | 550/10395 [1:31:42<23:52:36,  8.73s/it]                                                        {'loss': 0.9814, 'learning_rate': 1.997251820413869e-05, 'epoch': 0.05}
  5%|▌         | 550/10395 [1:31:42<23:52:36,  8.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  5%|▌         | 551/10395 [1:33:20<97:22:00, 35.61s/it]                                                        {'loss': 0.9803, 'learning_rate': 1.9972286886461396e-05, 'epoch': 0.05}
  5%|▌         | 551/10395 [1:33:20<97:22:00, 35.61s/it]  5%|▌         | 552/10395 [1:33:37<81:59:21, 29.99s/it]                                                        {'loss': 0.3277, 'learning_rate': 1.9972054600695802e-05, 'epoch': 0.05}
  5%|▌         | 552/10395 [1:33:37<81:59:21, 29.99s/it]  5%|▌         | 553/10395 [1:33:46<64:29:29, 23.59s/it]                                                        {'loss': 0.9719, 'learning_rate': 1.997182134686446e-05, 'epoch': 0.05}
  5%|▌         | 553/10395 [1:33:46<64:29:29, 23.59s/it]  5%|▌         | 554/10395 [1:33:53<51:09:06, 18.71s/it]                                                        {'loss': 1.0442, 'learning_rate': 1.997158712499001e-05, 'epoch': 0.05}
  5%|▌         | 554/10395 [1:33:53<51:09:06, 18.71s/it]  5%|▌         | 555/10395 [1:34:01<42:00:43, 15.37s/it]                                                        {'loss': 1.06, 'learning_rate': 1.9971351935095194e-05, 'epoch': 0.05}
  5%|▌         | 555/10395 [1:34:01<42:00:43, 15.37s/it]  5%|▌         | 556/10395 [1:34:08<35:47:36, 13.10s/it]                                                        {'loss': 1.0547, 'learning_rate': 1.9971115777202836e-05, 'epoch': 0.05}
  5%|▌         | 556/10395 [1:34:08<35:47:36, 13.10s/it]  5%|▌         | 557/10395 [1:34:16<31:00:40, 11.35s/it]                                                        {'loss': 1.0687, 'learning_rate': 1.997087865133587e-05, 'epoch': 0.05}
  5%|▌         | 557/10395 [1:34:16<31:00:40, 11.35s/it]  5%|▌         | 558/10395 [1:34:24<28:29:46, 10.43s/it]                                                        {'loss': 1.0555, 'learning_rate': 1.9970640557517314e-05, 'epoch': 0.05}
  5%|▌         | 558/10395 [1:34:24<28:29:46, 10.43s/it]  5%|▌         | 559/10395 [1:34:42<34:21:50, 12.58s/it]                                                        {'loss': 0.3415, 'learning_rate': 1.9970401495770275e-05, 'epoch': 0.05}
  5%|▌         | 559/10395 [1:34:42<34:21:50, 12.58s/it]  5%|▌         | 560/10395 [1:34:49<30:27:20, 11.15s/it]                                                        {'loss': 1.046, 'learning_rate': 1.997016146611797e-05, 'epoch': 0.05}
  5%|▌         | 560/10395 [1:34:49<30:27:20, 11.15s/it]  5%|▌         | 561/10395 [1:34:57<27:54:10, 10.21s/it]                                                        {'loss': 0.9505, 'learning_rate': 1.9969920468583693e-05, 'epoch': 0.05}
  5%|▌         | 561/10395 [1:34:57<27:54:10, 10.21s/it]  5%|▌         | 562/10395 [1:35:06<26:29:28,  9.70s/it]                                                        {'loss': 0.9994, 'learning_rate': 1.9969678503190845e-05, 'epoch': 0.05}
  5%|▌         | 562/10395 [1:35:06<26:29:28,  9.70s/it]  5%|▌         | 563/10395 [1:35:14<25:00:51,  9.16s/it]                                                        {'loss': 0.9679, 'learning_rate': 1.9969435569962915e-05, 'epoch': 0.05}
  5%|▌         | 563/10395 [1:35:14<25:00:51,  9.16s/it]  5%|▌         | 564/10395 [1:35:22<24:28:20,  8.96s/it]                                                        {'loss': 1.0118, 'learning_rate': 1.996919166892348e-05, 'epoch': 0.05}
  5%|▌         | 564/10395 [1:35:22<24:28:20,  8.96s/it]  5%|▌         | 565/10395 [1:35:30<23:23:32,  8.57s/it]                                                        {'loss': 1.0448, 'learning_rate': 1.9968946800096226e-05, 'epoch': 0.05}
  5%|▌         | 565/10395 [1:35:30<23:23:32,  8.57s/it]  5%|▌         | 566/10395 [1:35:38<23:18:41,  8.54s/it]                                                        {'loss': 1.0446, 'learning_rate': 1.9968700963504918e-05, 'epoch': 0.05}
  5%|▌         | 566/10395 [1:35:38<23:18:41,  8.54s/it]  5%|▌         | 567/10395 [1:35:46<22:32:21,  8.26s/it]                                                        {'loss': 1.0485, 'learning_rate': 1.9968454159173426e-05, 'epoch': 0.05}
  5%|▌         | 567/10395 [1:35:46<22:32:21,  8.26s/it]  5%|▌         | 568/10395 [1:35:54<22:34:28,  8.27s/it]                                                        {'loss': 0.9388, 'learning_rate': 1.99682063871257e-05, 'epoch': 0.05}
  5%|▌         | 568/10395 [1:35:54<22:34:28,  8.27s/it]  5%|▌         | 569/10395 [1:36:03<22:52:29,  8.38s/it]                                                        {'loss': 1.0801, 'learning_rate': 1.9967957647385806e-05, 'epoch': 0.05}
  5%|▌         | 569/10395 [1:36:03<22:52:29,  8.38s/it]  5%|▌         | 570/10395 [1:36:10<21:54:01,  8.02s/it]                                                        {'loss': 1.0629, 'learning_rate': 1.9967707939977887e-05, 'epoch': 0.05}
  5%|▌         | 570/10395 [1:36:10<21:54:01,  8.02s/it]  5%|▌         | 571/10395 [1:36:18<21:33:44,  7.90s/it]                                                        {'loss': 1.0186, 'learning_rate': 1.996745726492618e-05, 'epoch': 0.05}
  5%|▌         | 571/10395 [1:36:18<21:33:44,  7.90s/it]  6%|▌         | 572/10395 [1:36:26<21:34:04,  7.90s/it]                                                        {'loss': 1.0431, 'learning_rate': 1.9967205622255022e-05, 'epoch': 0.06}
  6%|▌         | 572/10395 [1:36:26<21:34:04,  7.90s/it]  6%|▌         | 573/10395 [1:36:43<29:04:02, 10.65s/it]                                                        {'loss': 0.3568, 'learning_rate': 1.9966953011988842e-05, 'epoch': 0.06}
  6%|▌         | 573/10395 [1:36:43<29:04:02, 10.65s/it]  6%|▌         | 574/10395 [1:36:52<27:34:51, 10.11s/it]                                                        {'loss': 0.9862, 'learning_rate': 1.9966699434152162e-05, 'epoch': 0.06}
  6%|▌         | 574/10395 [1:36:52<27:34:51, 10.11s/it]  6%|▌         | 575/10395 [1:36:59<25:29:36,  9.35s/it]                                                        {'loss': 1.0829, 'learning_rate': 1.99664448887696e-05, 'epoch': 0.06}
  6%|▌         | 575/10395 [1:36:59<25:29:36,  9.35s/it]  6%|▌         | 576/10395 [1:37:07<23:54:43,  8.77s/it]                                                        {'loss': 0.9931, 'learning_rate': 1.9966189375865868e-05, 'epoch': 0.06}
  6%|▌         | 576/10395 [1:37:07<23:54:43,  8.77s/it]  6%|▌         | 577/10395 [1:37:23<29:56:04, 10.98s/it]                                                        {'loss': 0.3234, 'learning_rate': 1.9965932895465768e-05, 'epoch': 0.06}
  6%|▌         | 577/10395 [1:37:23<29:56:04, 10.98s/it]  6%|▌         | 578/10395 [1:37:31<27:37:37, 10.13s/it]                                                        {'loss': 1.0335, 'learning_rate': 1.99656754475942e-05, 'epoch': 0.06}
  6%|▌         | 578/10395 [1:37:31<27:37:37, 10.13s/it]  6%|▌         | 579/10395 [1:37:39<25:46:51,  9.46s/it]                                                        {'loss': 0.9683, 'learning_rate': 1.9965417032276157e-05, 'epoch': 0.06}
  6%|▌         | 579/10395 [1:37:39<25:46:51,  9.46s/it]  6%|▌         | 580/10395 [1:37:46<23:55:35,  8.78s/it]                                                        {'loss': 1.0275, 'learning_rate': 1.9965157649536725e-05, 'epoch': 0.06}
  6%|▌         | 580/10395 [1:37:46<23:55:35,  8.78s/it]  6%|▌         | 581/10395 [1:37:54<23:36:53,  8.66s/it]                                                        {'loss': 1.0551, 'learning_rate': 1.9964897299401086e-05, 'epoch': 0.06}
  6%|▌         | 581/10395 [1:37:54<23:36:53,  8.66s/it]  6%|▌         | 582/10395 [1:38:02<22:36:08,  8.29s/it]                                                        {'loss': 1.137, 'learning_rate': 1.9964635981894505e-05, 'epoch': 0.06}
  6%|▌         | 582/10395 [1:38:02<22:36:08,  8.29s/it]  6%|▌         | 583/10395 [1:38:10<22:30:20,  8.26s/it]                                                        {'loss': 0.9894, 'learning_rate': 1.9964373697042366e-05, 'epoch': 0.06}
  6%|▌         | 583/10395 [1:38:10<22:30:20,  8.26s/it]  6%|▌         | 584/10395 [1:38:17<21:41:10,  7.96s/it]                                                        {'loss': 1.009, 'learning_rate': 1.9964110444870118e-05, 'epoch': 0.06}
  6%|▌         | 584/10395 [1:38:17<21:41:10,  7.96s/it]  6%|▌         | 585/10395 [1:38:26<22:14:38,  8.16s/it]                                                        {'loss': 0.9917, 'learning_rate': 1.996384622540332e-05, 'epoch': 0.06}
  6%|▌         | 585/10395 [1:38:26<22:14:38,  8.16s/it]  6%|▌         | 586/10395 [1:38:34<21:51:55,  8.02s/it]                                                        {'loss': 1.0257, 'learning_rate': 1.9963581038667624e-05, 'epoch': 0.06}
  6%|▌         | 586/10395 [1:38:34<21:51:55,  8.02s/it]  6%|▌         | 587/10395 [1:38:41<21:13:17,  7.79s/it]                                                        {'loss': 1.1213, 'learning_rate': 1.9963314884688777e-05, 'epoch': 0.06}
  6%|▌         | 587/10395 [1:38:41<21:13:17,  7.79s/it]  6%|▌         | 588/10395 [1:38:48<21:02:12,  7.72s/it]                                                        {'loss': 0.9758, 'learning_rate': 1.996304776349261e-05, 'epoch': 0.06}
  6%|▌         | 588/10395 [1:38:48<21:02:12,  7.72s/it]  6%|▌         | 589/10395 [1:38:56<20:55:05,  7.68s/it]                                                        {'loss': 1.111, 'learning_rate': 1.9962779675105056e-05, 'epoch': 0.06}
  6%|▌         | 589/10395 [1:38:56<20:55:05,  7.68s/it]  6%|▌         | 590/10395 [1:39:03<20:30:27,  7.53s/it]                                                        {'loss': 1.0607, 'learning_rate': 1.9962510619552144e-05, 'epoch': 0.06}
  6%|▌         | 590/10395 [1:39:03<20:30:27,  7.53s/it]  6%|▌         | 591/10395 [1:39:12<21:27:39,  7.88s/it]                                                        {'loss': 0.9402, 'learning_rate': 1.9962240596859987e-05, 'epoch': 0.06}
  6%|▌         | 591/10395 [1:39:12<21:27:39,  7.88s/it]  6%|▌         | 592/10395 [1:39:28<28:28:53, 10.46s/it]                                                        {'loss': 0.3147, 'learning_rate': 1.9961969607054806e-05, 'epoch': 0.06}
  6%|▌         | 592/10395 [1:39:28<28:28:53, 10.46s/it]  6%|▌         | 593/10395 [1:39:36<26:33:36,  9.75s/it]                                                        {'loss': 0.9695, 'learning_rate': 1.9961697650162904e-05, 'epoch': 0.06}
  6%|▌         | 593/10395 [1:39:36<26:33:36,  9.75s/it]  6%|▌         | 594/10395 [1:39:44<24:43:46,  9.08s/it]                                                        {'loss': 1.0749, 'learning_rate': 1.996142472621068e-05, 'epoch': 0.06}
  6%|▌         | 594/10395 [1:39:44<24:43:46,  9.08s/it]  6%|▌         | 595/10395 [1:39:51<23:22:32,  8.59s/it]                                                        {'loss': 0.9981, 'learning_rate': 1.9961150835224635e-05, 'epoch': 0.06}
  6%|▌         | 595/10395 [1:39:51<23:22:32,  8.59s/it]  6%|▌         | 596/10395 [1:39:59<22:27:41,  8.25s/it]                                                        {'loss': 1.041, 'learning_rate': 1.996087597723135e-05, 'epoch': 0.06}
  6%|▌         | 596/10395 [1:39:59<22:27:41,  8.25s/it]  6%|▌         | 597/10395 [1:40:06<21:57:17,  8.07s/it]                                                        {'loss': 1.034, 'learning_rate': 1.9960600152257513e-05, 'epoch': 0.06}
  6%|▌         | 597/10395 [1:40:06<21:57:17,  8.07s/it]  6%|▌         | 598/10395 [1:40:15<22:33:33,  8.29s/it]                                                        {'loss': 0.9673, 'learning_rate': 1.9960323360329902e-05, 'epoch': 0.06}
  6%|▌         | 598/10395 [1:40:15<22:33:33,  8.29s/it]  6%|▌         | 599/10395 [1:40:24<22:33:22,  8.29s/it]                                                        {'loss': 1.0385, 'learning_rate': 1.996004560147538e-05, 'epoch': 0.06}
  6%|▌         | 599/10395 [1:40:24<22:33:22,  8.29s/it]  6%|▌         | 600/10395 [1:40:32<22:49:18,  8.39s/it]                                                        {'loss': 1.0315, 'learning_rate': 1.9959766875720915e-05, 'epoch': 0.06}
  6%|▌         | 600/10395 [1:40:32<22:49:18,  8.39s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  6%|▌         | 601/10395 [1:42:12<97:40:47, 35.90s/it]                                                        {'loss': 1.0306, 'learning_rate': 1.995948718309357e-05, 'epoch': 0.06}
  6%|▌         | 601/10395 [1:42:12<97:40:47, 35.90s/it]  6%|▌         | 602/10395 [1:42:20<74:25:08, 27.36s/it]                                                        {'loss': 0.994, 'learning_rate': 1.9959206523620494e-05, 'epoch': 0.06}
  6%|▌         | 602/10395 [1:42:20<74:25:08, 27.36s/it]  6%|▌         | 603/10395 [1:42:28<59:11:32, 21.76s/it]                                                        {'loss': 0.9714, 'learning_rate': 1.9958924897328925e-05, 'epoch': 0.06}
  6%|▌         | 603/10395 [1:42:28<59:11:32, 21.76s/it]  6%|▌         | 604/10395 [1:42:36<47:33:04, 17.48s/it]                                                        {'loss': 1.0118, 'learning_rate': 1.9958642304246215e-05, 'epoch': 0.06}
  6%|▌         | 604/10395 [1:42:36<47:33:04, 17.48s/it]  6%|▌         | 605/10395 [1:42:43<39:23:18, 14.48s/it]                                                        {'loss': 1.0688, 'learning_rate': 1.9958358744399788e-05, 'epoch': 0.06}
  6%|▌         | 605/10395 [1:42:43<39:23:18, 14.48s/it]  6%|▌         | 606/10395 [1:42:51<33:54:08, 12.47s/it]                                                        {'loss': 1.0244, 'learning_rate': 1.995807421781718e-05, 'epoch': 0.06}
  6%|▌         | 606/10395 [1:42:51<33:54:08, 12.47s/it]  6%|▌         | 607/10395 [1:42:58<29:40:19, 10.91s/it]                                                        {'loss': 1.122, 'learning_rate': 1.9957788724526e-05, 'epoch': 0.06}
  6%|▌         | 607/10395 [1:42:58<29:40:19, 10.91s/it]  6%|▌         | 608/10395 [1:43:06<27:14:01, 10.02s/it]                                                        {'loss': 0.9551, 'learning_rate': 1.995750226455398e-05, 'epoch': 0.06}
  6%|▌         | 608/10395 [1:43:06<27:14:01, 10.02s/it]  6%|▌         | 609/10395 [1:43:14<25:05:51,  9.23s/it]                                                        {'loss': 1.0343, 'learning_rate': 1.9957214837928913e-05, 'epoch': 0.06}
  6%|▌         | 609/10395 [1:43:14<25:05:51,  9.23s/it]  6%|▌         | 610/10395 [1:43:22<23:51:22,  8.78s/it]                                                        {'loss': 1.0048, 'learning_rate': 1.9956926444678707e-05, 'epoch': 0.06}
  6%|▌         | 610/10395 [1:43:22<23:51:22,  8.78s/it]  6%|▌         | 611/10395 [1:43:29<23:02:18,  8.48s/it]                                                        {'loss': 0.9778, 'learning_rate': 1.9956637084831362e-05, 'epoch': 0.06}
  6%|▌         | 611/10395 [1:43:29<23:02:18,  8.48s/it]  6%|▌         | 612/10395 [1:43:38<23:14:15,  8.55s/it]                                                        {'loss': 1.1164, 'learning_rate': 1.9956346758414968e-05, 'epoch': 0.06}
  6%|▌         | 612/10395 [1:43:38<23:14:15,  8.55s/it]  6%|▌         | 613/10395 [1:43:46<22:41:10,  8.35s/it]                                                        {'loss': 0.996, 'learning_rate': 1.9956055465457707e-05, 'epoch': 0.06}
  6%|▌         | 613/10395 [1:43:46<22:41:10,  8.35s/it]  6%|▌         | 614/10395 [1:43:54<22:44:10,  8.37s/it]                                                        {'loss': 0.9108, 'learning_rate': 1.9955763205987857e-05, 'epoch': 0.06}
  6%|▌         | 614/10395 [1:43:54<22:44:10,  8.37s/it]  6%|▌         | 615/10395 [1:44:02<22:16:08,  8.20s/it]                                                        {'loss': 1.092, 'learning_rate': 1.9955469980033787e-05, 'epoch': 0.06}
  6%|▌         | 615/10395 [1:44:02<22:16:08,  8.20s/it]  6%|▌         | 616/10395 [1:44:10<22:07:57,  8.15s/it]                                                        {'loss': 1.0315, 'learning_rate': 1.9955175787623974e-05, 'epoch': 0.06}
  6%|▌         | 616/10395 [1:44:10<22:07:57,  8.15s/it]  6%|▌         | 617/10395 [1:44:18<22:11:32,  8.17s/it]                                                        {'loss': 1.0176, 'learning_rate': 1.9954880628786963e-05, 'epoch': 0.06}
  6%|▌         | 617/10395 [1:44:18<22:11:32,  8.17s/it]  6%|▌         | 618/10395 [1:44:26<22:01:18,  8.11s/it]                                                        {'loss': 0.9754, 'learning_rate': 1.9954584503551414e-05, 'epoch': 0.06}
  6%|▌         | 618/10395 [1:44:26<22:01:18,  8.11s/it]  6%|▌         | 619/10395 [1:44:34<21:58:15,  8.09s/it]                                                        {'loss': 1.0868, 'learning_rate': 1.995428741194608e-05, 'epoch': 0.06}
  6%|▌         | 619/10395 [1:44:34<21:58:15,  8.09s/it]  6%|▌         | 620/10395 [1:44:42<21:42:53,  8.00s/it]                                                        {'loss': 1.0381, 'learning_rate': 1.995398935399979e-05, 'epoch': 0.06}
  6%|▌         | 620/10395 [1:44:42<21:42:53,  8.00s/it]  6%|▌         | 621/10395 [1:44:50<21:39:43,  7.98s/it]                                                        {'loss': 0.9928, 'learning_rate': 1.995369032974149e-05, 'epoch': 0.06}
  6%|▌         | 621/10395 [1:44:50<21:39:43,  7.98s/it]  6%|▌         | 622/10395 [1:44:57<21:09:44,  7.80s/it]                                                        {'loss': 1.1314, 'learning_rate': 1.9953390339200202e-05, 'epoch': 0.06}
  6%|▌         | 622/10395 [1:44:57<21:09:44,  7.80s/it]  6%|▌         | 623/10395 [1:45:06<21:32:51,  7.94s/it]                                                        {'loss': 1.0598, 'learning_rate': 1.9953089382405052e-05, 'epoch': 0.06}
  6%|▌         | 623/10395 [1:45:06<21:32:51,  7.94s/it]  6%|▌         | 624/10395 [1:45:13<21:06:49,  7.78s/it]                                                        {'loss': 1.044, 'learning_rate': 1.9952787459385254e-05, 'epoch': 0.06}
  6%|▌         | 624/10395 [1:45:13<21:06:49,  7.78s/it]  6%|▌         | 625/10395 [1:45:21<21:10:19,  7.80s/it]                                                        {'loss': 0.9994, 'learning_rate': 1.9952484570170117e-05, 'epoch': 0.06}
  6%|▌         | 625/10395 [1:45:21<21:10:19,  7.80s/it]  6%|▌         | 626/10395 [1:45:29<21:10:22,  7.80s/it]                                                        {'loss': 0.942, 'learning_rate': 1.9952180714789048e-05, 'epoch': 0.06}
  6%|▌         | 626/10395 [1:45:29<21:10:22,  7.80s/it]  6%|▌         | 627/10395 [1:45:37<21:44:23,  8.01s/it]                                                        {'loss': 1.0134, 'learning_rate': 1.995187589327154e-05, 'epoch': 0.06}
  6%|▌         | 627/10395 [1:45:37<21:44:23,  8.01s/it]  6%|▌         | 628/10395 [1:45:45<21:27:37,  7.91s/it]                                                        {'loss': 1.0579, 'learning_rate': 1.9951570105647192e-05, 'epoch': 0.06}
  6%|▌         | 628/10395 [1:45:45<21:27:37,  7.91s/it]  6%|▌         | 629/10395 [1:45:53<21:30:10,  7.93s/it]                                                        {'loss': 1.0608, 'learning_rate': 1.995126335194568e-05, 'epoch': 0.06}
  6%|▌         | 629/10395 [1:45:53<21:30:10,  7.93s/it]  6%|▌         | 630/10395 [1:46:01<21:34:22,  7.95s/it]                                                        {'loss': 1.0023, 'learning_rate': 1.9950955632196792e-05, 'epoch': 0.06}
  6%|▌         | 630/10395 [1:46:01<21:34:22,  7.95s/it]  6%|▌         | 631/10395 [1:46:08<21:06:30,  7.78s/it]                                                        {'loss': 0.939, 'learning_rate': 1.9950646946430394e-05, 'epoch': 0.06}
  6%|▌         | 631/10395 [1:46:08<21:06:30,  7.78s/it]  6%|▌         | 632/10395 [1:46:16<20:41:38,  7.63s/it]                                                        {'loss': 1.0767, 'learning_rate': 1.9950337294676456e-05, 'epoch': 0.06}
  6%|▌         | 632/10395 [1:46:16<20:41:38,  7.63s/it]  6%|▌         | 633/10395 [1:46:33<28:56:05, 10.67s/it]                                                        {'loss': 0.3603, 'learning_rate': 1.9950026676965037e-05, 'epoch': 0.06}
  6%|▌         | 633/10395 [1:46:33<28:56:05, 10.67s/it]  6%|▌         | 634/10395 [1:46:41<26:30:15,  9.78s/it]                                                        {'loss': 1.0081, 'learning_rate': 1.994971509332629e-05, 'epoch': 0.06}
  6%|▌         | 634/10395 [1:46:41<26:30:15,  9.78s/it]  6%|▌         | 635/10395 [1:46:50<25:50:08,  9.53s/it]                                                        {'loss': 0.9897, 'learning_rate': 1.9949402543790468e-05, 'epoch': 0.06}
  6%|▌         | 635/10395 [1:46:50<25:50:08,  9.53s/it]  6%|▌         | 636/10395 [1:46:57<23:52:57,  8.81s/it]                                                        {'loss': 1.0304, 'learning_rate': 1.9949089028387908e-05, 'epoch': 0.06}
  6%|▌         | 636/10395 [1:46:57<23:52:57,  8.81s/it]  6%|▌         | 637/10395 [1:47:05<23:13:46,  8.57s/it]                                                        {'loss': 1.0247, 'learning_rate': 1.9948774547149044e-05, 'epoch': 0.06}
  6%|▌         | 637/10395 [1:47:05<23:13:46,  8.57s/it]  6%|▌         | 638/10395 [1:47:13<22:31:46,  8.31s/it]                                                        {'loss': 0.9771, 'learning_rate': 1.9948459100104412e-05, 'epoch': 0.06}
  6%|▌         | 638/10395 [1:47:13<22:31:46,  8.31s/it]  6%|▌         | 639/10395 [1:47:21<22:27:06,  8.28s/it]                                                        {'loss': 0.9764, 'learning_rate': 1.9948142687284625e-05, 'epoch': 0.06}
  6%|▌         | 639/10395 [1:47:21<22:27:06,  8.28s/it]  6%|▌         | 640/10395 [1:47:28<21:43:23,  8.02s/it]                                                        {'loss': 1.0241, 'learning_rate': 1.994782530872041e-05, 'epoch': 0.06}
  6%|▌         | 640/10395 [1:47:28<21:43:23,  8.02s/it]  6%|▌         | 641/10395 [1:47:36<21:41:34,  8.01s/it]                                                        {'loss': 1.024, 'learning_rate': 1.9947506964442567e-05, 'epoch': 0.06}
  6%|▌         | 641/10395 [1:47:36<21:41:34,  8.01s/it]  6%|▌         | 642/10395 [1:47:44<21:35:41,  7.97s/it]                                                        {'loss': 1.0109, 'learning_rate': 1.994718765448201e-05, 'epoch': 0.06}
  6%|▌         | 642/10395 [1:47:44<21:35:41,  7.97s/it]  6%|▌         | 643/10395 [1:47:52<21:20:30,  7.88s/it]                                                        {'loss': 1.1534, 'learning_rate': 1.9946867378869733e-05, 'epoch': 0.06}
  6%|▌         | 643/10395 [1:47:52<21:20:30,  7.88s/it]  6%|▌         | 644/10395 [1:48:00<21:04:54,  7.78s/it]                                                        {'loss': 0.9924, 'learning_rate': 1.9946546137636825e-05, 'epoch': 0.06}
  6%|▌         | 644/10395 [1:48:00<21:04:54,  7.78s/it]  6%|▌         | 645/10395 [1:48:07<20:59:36,  7.75s/it]                                                        {'loss': 0.9947, 'learning_rate': 1.9946223930814475e-05, 'epoch': 0.06}
  6%|▌         | 645/10395 [1:48:07<20:59:36,  7.75s/it]  6%|▌         | 646/10395 [1:48:16<22:00:58,  8.13s/it]                                                        {'loss': 0.932, 'learning_rate': 1.9945900758433963e-05, 'epoch': 0.06}
  6%|▌         | 646/10395 [1:48:16<22:00:58,  8.13s/it]  6%|▌         | 647/10395 [1:48:24<21:37:07,  7.98s/it]                                                        {'loss': 1.0085, 'learning_rate': 1.9945576620526656e-05, 'epoch': 0.06}
  6%|▌         | 647/10395 [1:48:24<21:37:07,  7.98s/it]  6%|▌         | 648/10395 [1:48:32<21:29:31,  7.94s/it]                                                        {'loss': 0.9886, 'learning_rate': 1.9945251517124026e-05, 'epoch': 0.06}
  6%|▌         | 648/10395 [1:48:32<21:29:31,  7.94s/it]  6%|▌         | 649/10395 [1:48:39<21:07:03,  7.80s/it]                                                        {'loss': 0.9817, 'learning_rate': 1.9944925448257633e-05, 'epoch': 0.06}
  6%|▌         | 649/10395 [1:48:39<21:07:03,  7.80s/it]  6%|▋         | 650/10395 [1:48:48<21:48:48,  8.06s/it]                                                        {'loss': 0.9731, 'learning_rate': 1.994459841395913e-05, 'epoch': 0.06}
  6%|▋         | 650/10395 [1:48:48<21:48:48,  8.06s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  6%|▋         | 651/10395 [1:50:28<96:22:16, 35.61s/it]                                                        {'loss': 0.9784, 'learning_rate': 1.9944270414260263e-05, 'epoch': 0.06}
  6%|▋         | 651/10395 [1:50:28<96:22:16, 35.61s/it]  6%|▋         | 652/10395 [1:50:35<73:26:50, 27.14s/it]                                                        {'loss': 1.0071, 'learning_rate': 1.9943941449192878e-05, 'epoch': 0.06}
  6%|▋         | 652/10395 [1:50:35<73:26:50, 27.14s/it]  6%|▋         | 653/10395 [1:50:42<57:14:55, 21.16s/it]                                                        {'loss': 1.1417, 'learning_rate': 1.99436115187889e-05, 'epoch': 0.06}
  6%|▋         | 653/10395 [1:50:42<57:14:55, 21.16s/it]  6%|▋         | 654/10395 [1:50:50<46:24:18, 17.15s/it]                                                        {'loss': 1.0108, 'learning_rate': 1.994328062308037e-05, 'epoch': 0.06}
  6%|▋         | 654/10395 [1:50:50<46:24:18, 17.15s/it]  6%|▋         | 655/10395 [1:50:58<38:46:12, 14.33s/it]                                                        {'loss': 1.0534, 'learning_rate': 1.994294876209941e-05, 'epoch': 0.06}
  6%|▋         | 655/10395 [1:50:58<38:46:12, 14.33s/it]  6%|▋         | 656/10395 [1:51:05<33:03:42, 12.22s/it]                                                        {'loss': 1.0387, 'learning_rate': 1.9942615935878225e-05, 'epoch': 0.06}
  6%|▋         | 656/10395 [1:51:05<33:03:42, 12.22s/it]  6%|▋         | 657/10395 [1:51:13<29:24:47, 10.87s/it]                                                        {'loss': 1.0103, 'learning_rate': 1.9942282144449138e-05, 'epoch': 0.06}
  6%|▋         | 657/10395 [1:51:13<29:24:47, 10.87s/it]  6%|▋         | 658/10395 [1:51:21<27:24:56, 10.14s/it]                                                        {'loss': 0.9642, 'learning_rate': 1.9941947387844543e-05, 'epoch': 0.06}
  6%|▋         | 658/10395 [1:51:21<27:24:56, 10.14s/it]  6%|▋         | 659/10395 [1:51:30<26:15:08,  9.71s/it]                                                        {'loss': 0.9984, 'learning_rate': 1.9941611666096948e-05, 'epoch': 0.06}
  6%|▋         | 659/10395 [1:51:30<26:15:08,  9.71s/it]  6%|▋         | 660/10395 [1:51:38<24:27:23,  9.04s/it]                                                        {'loss': 1.1001, 'learning_rate': 1.994127497923893e-05, 'epoch': 0.06}
  6%|▋         | 660/10395 [1:51:38<24:27:23,  9.04s/it]  6%|▋         | 661/10395 [1:51:46<23:56:46,  8.86s/it]                                                        {'loss': 0.9926, 'learning_rate': 1.9940937327303186e-05, 'epoch': 0.06}
  6%|▋         | 661/10395 [1:51:46<23:56:46,  8.86s/it]  6%|▋         | 662/10395 [1:52:04<31:30:32, 11.65s/it]                                                        {'loss': 0.3907, 'learning_rate': 1.994059871032249e-05, 'epoch': 0.06}
  6%|▋         | 662/10395 [1:52:04<31:30:32, 11.65s/it]  6%|▋         | 663/10395 [1:52:11<27:53:24, 10.32s/it]                                                        {'loss': 1.0468, 'learning_rate': 1.9940259128329714e-05, 'epoch': 0.06}
  6%|▋         | 663/10395 [1:52:11<27:53:24, 10.32s/it]  6%|▋         | 664/10395 [1:52:18<25:15:14,  9.34s/it]                                                        {'loss': 1.0657, 'learning_rate': 1.9939918581357826e-05, 'epoch': 0.06}
  6%|▋         | 664/10395 [1:52:18<25:15:14,  9.34s/it]  6%|▋         | 665/10395 [1:52:26<23:51:56,  8.83s/it]                                                        {'loss': 1.0143, 'learning_rate': 1.9939577069439878e-05, 'epoch': 0.06}
  6%|▋         | 665/10395 [1:52:26<23:51:56,  8.83s/it]  6%|▋         | 666/10395 [1:52:34<23:18:29,  8.62s/it]                                                        {'loss': 1.0558, 'learning_rate': 1.9939234592609034e-05, 'epoch': 0.06}
  6%|▋         | 666/10395 [1:52:34<23:18:29,  8.62s/it]  6%|▋         | 667/10395 [1:52:43<23:10:39,  8.58s/it]                                                        {'loss': 1.0173, 'learning_rate': 1.9938891150898535e-05, 'epoch': 0.06}
  6%|▋         | 667/10395 [1:52:43<23:10:39,  8.58s/it]  6%|▋         | 668/10395 [1:52:50<22:27:49,  8.31s/it]                                                        {'loss': 1.0224, 'learning_rate': 1.9938546744341724e-05, 'epoch': 0.06}
  6%|▋         | 668/10395 [1:52:50<22:27:49,  8.31s/it]  6%|▋         | 669/10395 [1:52:58<22:10:41,  8.21s/it]                                                        {'loss': 1.0428, 'learning_rate': 1.993820137297203e-05, 'epoch': 0.06}
  6%|▋         | 669/10395 [1:52:58<22:10:41,  8.21s/it]  6%|▋         | 670/10395 [1:53:06<21:56:38,  8.12s/it]                                                        {'loss': 0.9693, 'learning_rate': 1.9937855036822987e-05, 'epoch': 0.06}
  6%|▋         | 670/10395 [1:53:06<21:56:38,  8.12s/it]  6%|▋         | 671/10395 [1:53:14<21:15:00,  7.87s/it]                                                        {'loss': 1.1641, 'learning_rate': 1.9937507735928214e-05, 'epoch': 0.06}
  6%|▋         | 671/10395 [1:53:14<21:15:00,  7.87s/it]  6%|▋         | 672/10395 [1:53:21<21:15:59,  7.87s/it]                                                        {'loss': 1.038, 'learning_rate': 1.9937159470321424e-05, 'epoch': 0.06}
  6%|▋         | 672/10395 [1:53:21<21:15:59,  7.87s/it]  6%|▋         | 673/10395 [1:53:29<21:00:37,  7.78s/it]                                                        {'loss': 0.9951, 'learning_rate': 1.993681024003643e-05, 'epoch': 0.06}
  6%|▋         | 673/10395 [1:53:29<21:00:37,  7.78s/it]  6%|▋         | 674/10395 [1:53:37<20:54:32,  7.74s/it]                                                        {'loss': 1.0694, 'learning_rate': 1.993646004510714e-05, 'epoch': 0.06}
  6%|▋         | 674/10395 [1:53:37<20:54:32,  7.74s/it]  6%|▋         | 675/10395 [1:53:44<20:31:40,  7.60s/it]                                                        {'loss': 1.074, 'learning_rate': 1.9936108885567534e-05, 'epoch': 0.06}
  6%|▋         | 675/10395 [1:53:44<20:31:40,  7.60s/it]  7%|▋         | 676/10395 [1:53:52<20:34:10,  7.62s/it]                                                        {'loss': 1.0827, 'learning_rate': 1.9935756761451716e-05, 'epoch': 0.07}
  7%|▋         | 676/10395 [1:53:52<20:34:10,  7.62s/it]  7%|▋         | 677/10395 [1:53:59<20:42:56,  7.67s/it]                                                        {'loss': 1.0516, 'learning_rate': 1.993540367279386e-05, 'epoch': 0.07}
  7%|▋         | 677/10395 [1:53:59<20:42:56,  7.67s/it]  7%|▋         | 678/10395 [1:54:08<21:23:41,  7.93s/it]                                                        {'loss': 0.9719, 'learning_rate': 1.9935049619628252e-05, 'epoch': 0.07}
  7%|▋         | 678/10395 [1:54:08<21:23:41,  7.93s/it]  7%|▋         | 679/10395 [1:54:18<22:50:04,  8.46s/it]                                                        {'loss': 0.9699, 'learning_rate': 1.9934694601989254e-05, 'epoch': 0.07}
  7%|▋         | 679/10395 [1:54:18<22:50:04,  8.46s/it]  7%|▋         | 680/10395 [1:54:25<22:08:58,  8.21s/it]                                                        {'loss': 1.0837, 'learning_rate': 1.993433861991134e-05, 'epoch': 0.07}
  7%|▋         | 680/10395 [1:54:25<22:08:58,  8.21s/it]  7%|▋         | 681/10395 [1:54:34<22:48:08,  8.45s/it]                                                        {'loss': 1.0187, 'learning_rate': 1.9933981673429056e-05, 'epoch': 0.07}
  7%|▋         | 681/10395 [1:54:34<22:48:08,  8.45s/it]  7%|▋         | 682/10395 [1:54:41<21:46:26,  8.07s/it]                                                        {'loss': 1.1296, 'learning_rate': 1.9933623762577062e-05, 'epoch': 0.07}
  7%|▋         | 682/10395 [1:54:41<21:46:26,  8.07s/it]  7%|▋         | 683/10395 [1:54:49<21:26:46,  7.95s/it]                                                        {'loss': 1.0705, 'learning_rate': 1.9933264887390106e-05, 'epoch': 0.07}
  7%|▋         | 683/10395 [1:54:49<21:26:46,  7.95s/it]  7%|▋         | 684/10395 [1:54:57<21:22:35,  7.92s/it]                                                        {'loss': 1.0337, 'learning_rate': 1.9932905047903017e-05, 'epoch': 0.07}
  7%|▋         | 684/10395 [1:54:57<21:22:35,  7.92s/it]  7%|▋         | 685/10395 [1:55:04<20:54:30,  7.75s/it]                                                        {'loss': 1.0431, 'learning_rate': 1.9932544244150735e-05, 'epoch': 0.07}
  7%|▋         | 685/10395 [1:55:04<20:54:30,  7.75s/it]  7%|▋         | 686/10395 [1:55:12<20:51:47,  7.74s/it]                                                        {'loss': 1.0535, 'learning_rate': 1.993218247616828e-05, 'epoch': 0.07}
  7%|▋         | 686/10395 [1:55:12<20:51:47,  7.74s/it]  7%|▋         | 687/10395 [1:55:21<21:48:51,  8.09s/it]                                                        {'loss': 1.0185, 'learning_rate': 1.993181974399078e-05, 'epoch': 0.07}
  7%|▋         | 687/10395 [1:55:21<21:48:51,  8.09s/it]  7%|▋         | 688/10395 [1:55:29<21:38:35,  8.03s/it]                                                        {'loss': 1.0153, 'learning_rate': 1.9931456047653444e-05, 'epoch': 0.07}
  7%|▋         | 688/10395 [1:55:29<21:38:35,  8.03s/it]  7%|▋         | 689/10395 [1:55:36<21:04:07,  7.81s/it]                                                        {'loss': 0.9937, 'learning_rate': 1.9931091387191576e-05, 'epoch': 0.07}
  7%|▋         | 689/10395 [1:55:36<21:04:07,  7.81s/it]  7%|▋         | 690/10395 [1:55:44<21:27:35,  7.96s/it]                                                        {'loss': 1.0126, 'learning_rate': 1.993072576264058e-05, 'epoch': 0.07}
  7%|▋         | 690/10395 [1:55:44<21:27:35,  7.96s/it]  7%|▋         | 691/10395 [1:55:53<22:20:05,  8.29s/it]                                                        {'loss': 0.9282, 'learning_rate': 1.9930359174035946e-05, 'epoch': 0.07}
  7%|▋         | 691/10395 [1:55:53<22:20:05,  8.29s/it]  7%|▋         | 692/10395 [1:56:02<22:13:10,  8.24s/it]                                                        {'loss': 0.9647, 'learning_rate': 1.992999162141327e-05, 'epoch': 0.07}
  7%|▋         | 692/10395 [1:56:02<22:13:10,  8.24s/it]  7%|▋         | 693/10395 [1:56:09<21:52:20,  8.12s/it]                                                        {'loss': 1.0296, 'learning_rate': 1.9929623104808224e-05, 'epoch': 0.07}
  7%|▋         | 693/10395 [1:56:09<21:52:20,  8.12s/it]  7%|▋         | 694/10395 [1:56:17<21:43:00,  8.06s/it]                                                        {'loss': 1.0624, 'learning_rate': 1.9929253624256584e-05, 'epoch': 0.07}
  7%|▋         | 694/10395 [1:56:17<21:43:00,  8.06s/it]  7%|▋         | 695/10395 [1:56:25<21:32:33,  8.00s/it]                                                        {'loss': 1.1022, 'learning_rate': 1.9928883179794227e-05, 'epoch': 0.07}
  7%|▋         | 695/10395 [1:56:25<21:32:33,  8.00s/it]  7%|▋         | 696/10395 [1:56:33<21:32:36,  8.00s/it]                                                        {'loss': 1.0402, 'learning_rate': 1.9928511771457108e-05, 'epoch': 0.07}
  7%|▋         | 696/10395 [1:56:33<21:32:36,  8.00s/it]  7%|▋         | 697/10395 [1:56:41<21:08:35,  7.85s/it]                                                        {'loss': 1.0422, 'learning_rate': 1.9928139399281282e-05, 'epoch': 0.07}
  7%|▋         | 697/10395 [1:56:41<21:08:35,  7.85s/it]  7%|▋         | 698/10395 [1:56:49<21:08:25,  7.85s/it]                                                        {'loss': 1.0539, 'learning_rate': 1.99277660633029e-05, 'epoch': 0.07}
  7%|▋         | 698/10395 [1:56:49<21:08:25,  7.85s/it]  7%|▋         | 699/10395 [1:56:56<21:05:53,  7.83s/it]                                                        {'loss': 1.012, 'learning_rate': 1.9927391763558203e-05, 'epoch': 0.07}
  7%|▋         | 699/10395 [1:56:56<21:05:53,  7.83s/it]  7%|▋         | 700/10395 [1:57:04<20:49:58,  7.74s/it]                                                        {'loss': 1.0148, 'learning_rate': 1.992701650008353e-05, 'epoch': 0.07}
  7%|▋         | 700/10395 [1:57:04<20:49:58,  7.74s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  7%|▋         | 701/10395 [1:58:44<95:32:06, 35.48s/it]                                                        {'loss': 1.0261, 'learning_rate': 1.992664027291531e-05, 'epoch': 0.07}
  7%|▋         | 701/10395 [1:58:44<95:32:06, 35.48s/it]  7%|▋         | 702/10395 [1:58:52<73:19:45, 27.23s/it]                                                        {'loss': 1.0581, 'learning_rate': 1.9926263082090064e-05, 'epoch': 0.07}
  7%|▋         | 702/10395 [1:58:52<73:19:45, 27.23s/it]  7%|▋         | 703/10395 [1:59:00<57:59:45, 21.54s/it]                                                        {'loss': 0.982, 'learning_rate': 1.992588492764441e-05, 'epoch': 0.07}
  7%|▋         | 703/10395 [1:59:00<57:59:45, 21.54s/it]  7%|▋         | 704/10395 [1:59:08<46:56:21, 17.44s/it]                                                        {'loss': 1.0833, 'learning_rate': 1.992550580961506e-05, 'epoch': 0.07}
  7%|▋         | 704/10395 [1:59:08<46:56:21, 17.44s/it]  7%|▋         | 705/10395 [1:59:16<39:10:40, 14.56s/it]                                                        {'loss': 1.0526, 'learning_rate': 1.9925125728038816e-05, 'epoch': 0.07}
  7%|▋         | 705/10395 [1:59:16<39:10:40, 14.56s/it]  7%|▋         | 706/10395 [1:59:24<33:44:23, 12.54s/it]                                                        {'loss': 1.0184, 'learning_rate': 1.992474468295258e-05, 'epoch': 0.07}
  7%|▋         | 706/10395 [1:59:24<33:44:23, 12.54s/it]  7%|▋         | 707/10395 [1:59:31<29:41:37, 11.03s/it]                                                        {'loss': 1.0026, 'learning_rate': 1.9924362674393336e-05, 'epoch': 0.07}
  7%|▋         | 707/10395 [1:59:31<29:41:37, 11.03s/it]  7%|▋         | 708/10395 [1:59:39<27:14:49, 10.13s/it]                                                        {'loss': 1.1306, 'learning_rate': 1.9923979702398172e-05, 'epoch': 0.07}
  7%|▋         | 708/10395 [1:59:39<27:14:49, 10.13s/it]  7%|▋         | 709/10395 [1:59:47<25:26:05,  9.45s/it]                                                        {'loss': 1.0222, 'learning_rate': 1.9923595767004268e-05, 'epoch': 0.07}
  7%|▋         | 709/10395 [1:59:47<25:26:05,  9.45s/it]  7%|▋         | 710/10395 [1:59:55<23:56:16,  8.90s/it]                                                        {'loss': 1.029, 'learning_rate': 1.9923210868248893e-05, 'epoch': 0.07}
  7%|▋         | 710/10395 [1:59:55<23:56:16,  8.90s/it]  7%|▋         | 711/10395 [2:00:03<23:24:39,  8.70s/it]                                                        {'loss': 1.0053, 'learning_rate': 1.992282500616941e-05, 'epoch': 0.07}
  7%|▋         | 711/10395 [2:00:03<23:24:39,  8.70s/it]  7%|▋         | 712/10395 [2:00:10<22:00:26,  8.18s/it]                                                        {'loss': 1.0342, 'learning_rate': 1.9922438180803284e-05, 'epoch': 0.07}
  7%|▋         | 712/10395 [2:00:10<22:00:26,  8.18s/it]  7%|▋         | 713/10395 [2:00:18<22:11:12,  8.25s/it]                                                        {'loss': 1.1307, 'learning_rate': 1.9922050392188062e-05, 'epoch': 0.07}
  7%|▋         | 713/10395 [2:00:18<22:11:12,  8.25s/it]  7%|▋         | 714/10395 [2:00:36<29:45:54, 11.07s/it]                                                        {'loss': 0.3352, 'learning_rate': 1.992166164036139e-05, 'epoch': 0.07}
  7%|▋         | 714/10395 [2:00:36<29:45:54, 11.07s/it]  7%|▋         | 715/10395 [2:00:44<26:59:22, 10.04s/it]                                                        {'loss': 1.0443, 'learning_rate': 1.992127192536101e-05, 'epoch': 0.07}
  7%|▋         | 715/10395 [2:00:44<26:59:22, 10.04s/it]  7%|▋         | 716/10395 [2:00:52<25:12:08,  9.37s/it]                                                        {'loss': 1.0252, 'learning_rate': 1.9920881247224756e-05, 'epoch': 0.07}
  7%|▋         | 716/10395 [2:00:52<25:12:08,  9.37s/it]  7%|▋         | 717/10395 [2:01:00<24:21:26,  9.06s/it]                                                        {'loss': 1.0612, 'learning_rate': 1.992048960599055e-05, 'epoch': 0.07}
  7%|▋         | 717/10395 [2:01:00<24:21:26,  9.06s/it]  7%|▋         | 718/10395 [2:01:18<31:26:30, 11.70s/it]                                                        {'loss': 0.3717, 'learning_rate': 1.992009700169641e-05, 'epoch': 0.07}
  7%|▋         | 718/10395 [2:01:18<31:26:30, 11.70s/it]  7%|▋         | 719/10395 [2:01:26<28:38:30, 10.66s/it]                                                        {'loss': 0.9742, 'learning_rate': 1.9919703434380457e-05, 'epoch': 0.07}
  7%|▋         | 719/10395 [2:01:26<28:38:30, 10.66s/it]  7%|▋         | 720/10395 [2:01:34<26:20:18,  9.80s/it]                                                        {'loss': 1.0192, 'learning_rate': 1.9919308904080893e-05, 'epoch': 0.07}
  7%|▋         | 720/10395 [2:01:34<26:20:18,  9.80s/it]  7%|▋         | 721/10395 [2:01:41<24:32:19,  9.13s/it]                                                        {'loss': 1.081, 'learning_rate': 1.9918913410836013e-05, 'epoch': 0.07}
  7%|▋         | 721/10395 [2:01:41<24:32:19,  9.13s/it]  7%|▋         | 722/10395 [2:01:49<23:15:31,  8.66s/it]                                                        {'loss': 1.0189, 'learning_rate': 1.991851695468422e-05, 'epoch': 0.07}
  7%|▋         | 722/10395 [2:01:49<23:15:31,  8.66s/it]  7%|▋         | 723/10395 [2:01:56<22:00:39,  8.19s/it]                                                        {'loss': 1.0699, 'learning_rate': 1.9918119535664e-05, 'epoch': 0.07}
  7%|▋         | 723/10395 [2:01:56<22:00:39,  8.19s/it]  7%|▋         | 724/10395 [2:02:05<22:29:11,  8.37s/it]                                                        {'loss': 1.0173, 'learning_rate': 1.9917721153813924e-05, 'epoch': 0.07}
  7%|▋         | 724/10395 [2:02:05<22:29:11,  8.37s/it]  7%|▋         | 725/10395 [2:02:13<22:02:37,  8.21s/it]                                                        {'loss': 1.0791, 'learning_rate': 1.9917321809172676e-05, 'epoch': 0.07}
  7%|▋         | 725/10395 [2:02:13<22:02:37,  8.21s/it]  7%|▋         | 726/10395 [2:02:31<29:54:03, 11.13s/it]                                                        {'loss': 0.3507, 'learning_rate': 1.9916921501779018e-05, 'epoch': 0.07}
  7%|▋         | 726/10395 [2:02:31<29:54:03, 11.13s/it]  7%|▋         | 727/10395 [2:02:39<27:22:06, 10.19s/it]                                                        {'loss': 0.9817, 'learning_rate': 1.9916520231671815e-05, 'epoch': 0.07}
  7%|▋         | 727/10395 [2:02:39<27:22:06, 10.19s/it]  7%|▋         | 728/10395 [2:02:46<25:21:45,  9.45s/it]                                                        {'loss': 1.0252, 'learning_rate': 1.991611799889002e-05, 'epoch': 0.07}
  7%|▋         | 728/10395 [2:02:46<25:21:45,  9.45s/it]  7%|▋         | 729/10395 [2:02:54<23:41:52,  8.83s/it]                                                        {'loss': 1.0163, 'learning_rate': 1.991571480347268e-05, 'epoch': 0.07}
  7%|▋         | 729/10395 [2:02:54<23:41:52,  8.83s/it]  7%|▋         | 730/10395 [2:03:02<23:30:02,  8.75s/it]                                                        {'loss': 0.9853, 'learning_rate': 1.9915310645458936e-05, 'epoch': 0.07}
  7%|▋         | 730/10395 [2:03:02<23:30:02,  8.75s/it]  7%|▋         | 731/10395 [2:03:10<22:45:24,  8.48s/it]                                                        {'loss': 1.0915, 'learning_rate': 1.9914905524888027e-05, 'epoch': 0.07}
  7%|▋         | 731/10395 [2:03:10<22:45:24,  8.48s/it]  7%|▋         | 732/10395 [2:03:18<22:06:33,  8.24s/it]                                                        {'loss': 1.0611, 'learning_rate': 1.9914499441799274e-05, 'epoch': 0.07}
  7%|▋         | 732/10395 [2:03:18<22:06:33,  8.24s/it]  7%|▋         | 733/10395 [2:03:27<23:00:00,  8.57s/it]                                                        {'loss': 0.981, 'learning_rate': 1.9914092396232104e-05, 'epoch': 0.07}
  7%|▋         | 733/10395 [2:03:27<23:00:00,  8.57s/it]  7%|▋         | 734/10395 [2:03:44<29:52:39, 11.13s/it]                                                        {'loss': 0.3504, 'learning_rate': 1.991368438822603e-05, 'epoch': 0.07}
  7%|▋         | 734/10395 [2:03:44<29:52:39, 11.13s/it]  7%|▋         | 735/10395 [2:03:53<27:40:39, 10.31s/it]                                                        {'loss': 1.0216, 'learning_rate': 1.991327541782066e-05, 'epoch': 0.07}
  7%|▋         | 735/10395 [2:03:53<27:40:39, 10.31s/it]  7%|▋         | 736/10395 [2:04:00<25:33:27,  9.53s/it]                                                        {'loss': 1.1164, 'learning_rate': 1.99128654850557e-05, 'epoch': 0.07}
  7%|▋         | 736/10395 [2:04:00<25:33:27,  9.53s/it]  7%|▋         | 737/10395 [2:04:09<24:35:15,  9.16s/it]                                                        {'loss': 0.9835, 'learning_rate': 1.991245458997094e-05, 'epoch': 0.07}
  7%|▋         | 737/10395 [2:04:09<24:35:15,  9.16s/it]  7%|▋         | 738/10395 [2:04:16<23:24:19,  8.73s/it]                                                        {'loss': 1.0281, 'learning_rate': 1.9912042732606274e-05, 'epoch': 0.07}
  7%|▋         | 738/10395 [2:04:16<23:24:19,  8.73s/it]  7%|▋         | 739/10395 [2:04:23<22:03:46,  8.23s/it]                                                        {'loss': 1.1111, 'learning_rate': 1.991162991300168e-05, 'epoch': 0.07}
  7%|▋         | 739/10395 [2:04:23<22:03:46,  8.23s/it]  7%|▋         | 740/10395 [2:04:41<29:37:21, 11.05s/it]                                                        {'loss': 0.3597, 'learning_rate': 1.9911216131197235e-05, 'epoch': 0.07}
  7%|▋         | 740/10395 [2:04:41<29:37:21, 11.05s/it]  7%|▋         | 741/10395 [2:04:49<26:57:34, 10.05s/it]                                                        {'loss': 1.0392, 'learning_rate': 1.991080138723311e-05, 'epoch': 0.07}
  7%|▋         | 741/10395 [2:04:49<26:57:34, 10.05s/it]  7%|▋         | 742/10395 [2:04:56<24:53:35,  9.28s/it]                                                        {'loss': 1.07, 'learning_rate': 1.991038568114956e-05, 'epoch': 0.07}
  7%|▋         | 742/10395 [2:04:56<24:53:35,  9.28s/it]  7%|▋         | 743/10395 [2:05:04<23:59:11,  8.95s/it]                                                        {'loss': 1.0468, 'learning_rate': 1.9909969012986952e-05, 'epoch': 0.07}
  7%|▋         | 743/10395 [2:05:04<23:59:11,  8.95s/it]  7%|▋         | 744/10395 [2:05:12<22:58:16,  8.57s/it]                                                        {'loss': 1.045, 'learning_rate': 1.990955138278573e-05, 'epoch': 0.07}
  7%|▋         | 744/10395 [2:05:12<22:58:16,  8.57s/it]  7%|▋         | 745/10395 [2:05:21<23:29:53,  8.77s/it]                                                        {'loss': 1.0172, 'learning_rate': 1.9909132790586438e-05, 'epoch': 0.07}
  7%|▋         | 745/10395 [2:05:21<23:29:53,  8.77s/it]  7%|▋         | 746/10395 [2:05:29<22:27:39,  8.38s/it]                                                        {'loss': 1.1005, 'learning_rate': 1.9908713236429708e-05, 'epoch': 0.07}
  7%|▋         | 746/10395 [2:05:29<22:27:39,  8.38s/it]  7%|▋         | 747/10395 [2:05:36<21:30:39,  8.03s/it]                                                        {'loss': 1.0857, 'learning_rate': 1.990829272035627e-05, 'epoch': 0.07}
  7%|▋         | 747/10395 [2:05:36<21:30:39,  8.03s/it]  7%|▋         | 748/10395 [2:05:45<22:06:42,  8.25s/it]                                                        {'loss': 0.9931, 'learning_rate': 1.9907871242406952e-05, 'epoch': 0.07}
  7%|▋         | 748/10395 [2:05:45<22:06:42,  8.25s/it]  7%|▋         | 749/10395 [2:05:53<21:44:20,  8.11s/it]                                                        {'loss': 1.052, 'learning_rate': 1.9907448802622667e-05, 'epoch': 0.07}
  7%|▋         | 749/10395 [2:05:53<21:44:20,  8.11s/it]  7%|▋         | 750/10395 [2:06:00<21:21:24,  7.97s/it]                                                        {'loss': 1.0363, 'learning_rate': 1.9907025401044425e-05, 'epoch': 0.07}
  7%|▋         | 750/10395 [2:06:00<21:21:24,  7.97s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  7%|▋         | 751/10395 [2:07:40<95:16:17, 35.56s/it]                                                        {'loss': 0.9816, 'learning_rate': 1.990660103771333e-05, 'epoch': 0.07}
  7%|▋         | 751/10395 [2:07:40<95:16:17, 35.56s/it]  7%|▋         | 752/10395 [2:07:48<72:51:29, 27.20s/it]                                                        {'loss': 1.0326, 'learning_rate': 1.990617571267057e-05, 'epoch': 0.07}
  7%|▋         | 752/10395 [2:07:48<72:51:29, 27.20s/it]  7%|▋         | 753/10395 [2:07:56<57:17:24, 21.39s/it]                                                        {'loss': 1.0329, 'learning_rate': 1.9905749425957445e-05, 'epoch': 0.07}
  7%|▋         | 753/10395 [2:07:56<57:17:24, 21.39s/it]  7%|▋         | 754/10395 [2:08:03<45:58:50, 17.17s/it]                                                        {'loss': 1.0076, 'learning_rate': 1.9905322177615332e-05, 'epoch': 0.07}
  7%|▋         | 754/10395 [2:08:03<45:58:50, 17.17s/it]  7%|▋         | 755/10395 [2:08:11<38:31:12, 14.39s/it]                                                        {'loss': 0.9944, 'learning_rate': 1.9904893967685717e-05, 'epoch': 0.07}
  7%|▋         | 755/10395 [2:08:11<38:31:12, 14.39s/it]  7%|▋         | 756/10395 [2:08:18<33:04:15, 12.35s/it]                                                        {'loss': 1.0301, 'learning_rate': 1.9904464796210158e-05, 'epoch': 0.07}
  7%|▋         | 756/10395 [2:08:18<33:04:15, 12.35s/it]  7%|▋         | 757/10395 [2:08:26<29:12:45, 10.91s/it]                                                        {'loss': 1.0158, 'learning_rate': 1.990403466323032e-05, 'epoch': 0.07}
  7%|▋         | 757/10395 [2:08:26<29:12:45, 10.91s/it]  7%|▋         | 758/10395 [2:08:34<26:59:00, 10.08s/it]                                                        {'loss': 1.0794, 'learning_rate': 1.9903603568787962e-05, 'epoch': 0.07}
  7%|▋         | 758/10395 [2:08:34<26:59:00, 10.08s/it]  7%|▋         | 759/10395 [2:08:43<25:41:16,  9.60s/it]                                                        {'loss': 1.0145, 'learning_rate': 1.9903171512924938e-05, 'epoch': 0.07}
  7%|▋         | 759/10395 [2:08:43<25:41:16,  9.60s/it]  7%|▋         | 760/10395 [2:08:50<24:10:04,  9.03s/it]                                                        {'loss': 0.9322, 'learning_rate': 1.9902738495683185e-05, 'epoch': 0.07}
  7%|▋         | 760/10395 [2:08:50<24:10:04,  9.03s/it]  7%|▋         | 761/10395 [2:08:58<22:44:18,  8.50s/it]                                                        {'loss': 1.0092, 'learning_rate': 1.990230451710474e-05, 'epoch': 0.07}
  7%|▋         | 761/10395 [2:08:58<22:44:18,  8.50s/it]  7%|▋         | 762/10395 [2:09:06<22:29:52,  8.41s/it]                                                        {'loss': 1.0598, 'learning_rate': 1.9901869577231732e-05, 'epoch': 0.07}
  7%|▋         | 762/10395 [2:09:06<22:29:52,  8.41s/it]  7%|▋         | 763/10395 [2:09:15<22:48:22,  8.52s/it]                                                        {'loss': 0.9961, 'learning_rate': 1.9901433676106394e-05, 'epoch': 0.07}
  7%|▋         | 763/10395 [2:09:15<22:48:22,  8.52s/it]  7%|▋         | 764/10395 [2:09:22<22:16:57,  8.33s/it]                                                        {'loss': 0.9979, 'learning_rate': 1.9900996813771024e-05, 'epoch': 0.07}
  7%|▋         | 764/10395 [2:09:22<22:16:57,  8.33s/it]  7%|▋         | 765/10395 [2:09:30<21:40:52,  8.11s/it]                                                        {'loss': 1.0029, 'learning_rate': 1.9900558990268047e-05, 'epoch': 0.07}
  7%|▋         | 765/10395 [2:09:30<21:40:52,  8.11s/it]  7%|▋         | 766/10395 [2:09:37<20:49:37,  7.79s/it]                                                        {'loss': 1.0356, 'learning_rate': 1.9900120205639963e-05, 'epoch': 0.07}
  7%|▋         | 766/10395 [2:09:37<20:49:37,  7.79s/it]  7%|▋         | 767/10395 [2:09:45<20:35:17,  7.70s/it]                                                        {'loss': 1.0868, 'learning_rate': 1.989968045992936e-05, 'epoch': 0.07}
  7%|▋         | 767/10395 [2:09:45<20:35:17,  7.70s/it]  7%|▋         | 768/10395 [2:09:52<20:30:52,  7.67s/it]                                                        {'loss': 0.9615, 'learning_rate': 1.9899239753178936e-05, 'epoch': 0.07}
  7%|▋         | 768/10395 [2:09:52<20:30:52,  7.67s/it]  7%|▋         | 769/10395 [2:10:00<20:15:49,  7.58s/it]                                                        {'loss': 1.0524, 'learning_rate': 1.9898798085431473e-05, 'epoch': 0.07}
  7%|▋         | 769/10395 [2:10:00<20:15:49,  7.58s/it]  7%|▋         | 770/10395 [2:10:07<20:22:17,  7.62s/it]                                                        {'loss': 1.0067, 'learning_rate': 1.9898355456729844e-05, 'epoch': 0.07}
  7%|▋         | 770/10395 [2:10:07<20:22:17,  7.62s/it]  7%|▋         | 771/10395 [2:10:15<20:17:52,  7.59s/it]                                                        {'loss': 1.0904, 'learning_rate': 1.989791186711702e-05, 'epoch': 0.07}
  7%|▋         | 771/10395 [2:10:15<20:17:52,  7.59s/it]  7%|▋         | 772/10395 [2:10:23<20:25:45,  7.64s/it]                                                        {'loss': 0.9661, 'learning_rate': 1.9897467316636064e-05, 'epoch': 0.07}
  7%|▋         | 772/10395 [2:10:23<20:25:45,  7.64s/it]  7%|▋         | 773/10395 [2:10:30<20:23:16,  7.63s/it]                                                        {'loss': 0.9726, 'learning_rate': 1.9897021805330134e-05, 'epoch': 0.07}
  7%|▋         | 773/10395 [2:10:30<20:23:16,  7.63s/it]  7%|▋         | 774/10395 [2:10:38<20:20:59,  7.61s/it]                                                        {'loss': 1.0888, 'learning_rate': 1.9896575333242477e-05, 'epoch': 0.07}
  7%|▋         | 774/10395 [2:10:38<20:20:59,  7.61s/it]  7%|▋         | 775/10395 [2:10:45<20:09:37,  7.54s/it]                                                        {'loss': 1.0204, 'learning_rate': 1.9896127900416434e-05, 'epoch': 0.07}
  7%|▋         | 775/10395 [2:10:45<20:09:37,  7.54s/it]  7%|▋         | 776/10395 [2:10:53<20:06:37,  7.53s/it]                                                        {'loss': 1.0686, 'learning_rate': 1.989567950689544e-05, 'epoch': 0.07}
  7%|▋         | 776/10395 [2:10:53<20:06:37,  7.53s/it]  7%|▋         | 777/10395 [2:11:00<20:17:34,  7.60s/it]                                                        {'loss': 0.977, 'learning_rate': 1.9895230152723033e-05, 'epoch': 0.07}
  7%|▋         | 777/10395 [2:11:00<20:17:34,  7.60s/it]  7%|▋         | 778/10395 [2:11:08<20:01:06,  7.49s/it]                                                        {'loss': 1.0582, 'learning_rate': 1.9894779837942827e-05, 'epoch': 0.07}
  7%|▋         | 778/10395 [2:11:08<20:01:06,  7.49s/it]  7%|▋         | 779/10395 [2:11:15<19:59:56,  7.49s/it]                                                        {'loss': 1.003, 'learning_rate': 1.989432856259854e-05, 'epoch': 0.07}
  7%|▋         | 779/10395 [2:11:15<19:59:56,  7.49s/it]  8%|▊         | 780/10395 [2:11:23<20:29:56,  7.68s/it]                                                        {'loss': 0.9841, 'learning_rate': 1.9893876326733974e-05, 'epoch': 0.08}
  8%|▊         | 780/10395 [2:11:23<20:29:56,  7.68s/it]  8%|▊         | 781/10395 [2:11:31<20:15:31,  7.59s/it]                                                        {'loss': 1.0237, 'learning_rate': 1.9893423130393043e-05, 'epoch': 0.08}
  8%|▊         | 781/10395 [2:11:31<20:15:31,  7.59s/it]  8%|▊         | 782/10395 [2:11:48<28:08:32, 10.54s/it]                                                        {'loss': 0.3775, 'learning_rate': 1.9892968973619734e-05, 'epoch': 0.08}
  8%|▊         | 782/10395 [2:11:48<28:08:32, 10.54s/it]  8%|▊         | 783/10395 [2:11:56<25:43:57,  9.64s/it]                                                        {'loss': 1.0558, 'learning_rate': 1.989251385645814e-05, 'epoch': 0.08}
  8%|▊         | 783/10395 [2:11:56<25:43:57,  9.64s/it]  8%|▊         | 784/10395 [2:12:03<24:17:49,  9.10s/it]                                                        {'loss': 1.0552, 'learning_rate': 1.989205777895244e-05, 'epoch': 0.08}
  8%|▊         | 784/10395 [2:12:03<24:17:49,  9.10s/it]  8%|▊         | 785/10395 [2:12:11<22:55:40,  8.59s/it]                                                        {'loss': 1.0553, 'learning_rate': 1.9891600741146915e-05, 'epoch': 0.08}
  8%|▊         | 785/10395 [2:12:11<22:55:40,  8.59s/it]  8%|▊         | 786/10395 [2:12:19<22:30:31,  8.43s/it]                                                        {'loss': 1.0091, 'learning_rate': 1.9891142743085923e-05, 'epoch': 0.08}
  8%|▊         | 786/10395 [2:12:19<22:30:31,  8.43s/it]  8%|▊         | 787/10395 [2:12:27<22:06:06,  8.28s/it]                                                        {'loss': 1.0348, 'learning_rate': 1.9890683784813935e-05, 'epoch': 0.08}
  8%|▊         | 787/10395 [2:12:27<22:06:06,  8.28s/it]  8%|▊         | 788/10395 [2:12:34<21:26:37,  8.04s/it]                                                        {'loss': 1.0368, 'learning_rate': 1.98902238663755e-05, 'epoch': 0.08}
  8%|▊         | 788/10395 [2:12:34<21:26:37,  8.04s/it]  8%|▊         | 789/10395 [2:12:43<22:09:14,  8.30s/it]                                                        {'loss': 0.9728, 'learning_rate': 1.9889762987815264e-05, 'epoch': 0.08}
  8%|▊         | 789/10395 [2:12:43<22:09:14,  8.30s/it]  8%|▊         | 790/10395 [2:12:51<22:00:39,  8.25s/it]                                                        {'loss': 0.9495, 'learning_rate': 1.9889301149177974e-05, 'epoch': 0.08}
  8%|▊         | 790/10395 [2:12:51<22:00:39,  8.25s/it]  8%|▊         | 791/10395 [2:13:00<22:34:03,  8.46s/it]                                                        {'loss': 0.9303, 'learning_rate': 1.9888838350508463e-05, 'epoch': 0.08}
  8%|▊         | 791/10395 [2:13:00<22:34:03,  8.46s/it]  8%|▊         | 792/10395 [2:13:09<22:42:14,  8.51s/it]                                                        {'loss': 1.0558, 'learning_rate': 1.9888374591851658e-05, 'epoch': 0.08}
  8%|▊         | 792/10395 [2:13:09<22:42:14,  8.51s/it]  8%|▊         | 793/10395 [2:13:17<22:12:53,  8.33s/it]                                                        {'loss': 0.9966, 'learning_rate': 1.988790987325258e-05, 'epoch': 0.08}
  8%|▊         | 793/10395 [2:13:17<22:12:53,  8.33s/it]  8%|▊         | 794/10395 [2:13:24<21:43:38,  8.15s/it]                                                        {'loss': 1.0727, 'learning_rate': 1.988744419475634e-05, 'epoch': 0.08}
  8%|▊         | 794/10395 [2:13:24<21:43:38,  8.15s/it]  8%|▊         | 795/10395 [2:13:42<28:53:48, 10.84s/it]                                                        {'loss': 0.3757, 'learning_rate': 1.9886977556408145e-05, 'epoch': 0.08}
  8%|▊         | 795/10395 [2:13:42<28:53:48, 10.84s/it]  8%|▊         | 796/10395 [2:13:49<26:07:25,  9.80s/it]                                                        {'loss': 1.0793, 'learning_rate': 1.98865099582533e-05, 'epoch': 0.08}
  8%|▊         | 796/10395 [2:13:49<26:07:25,  9.80s/it]  8%|▊         | 797/10395 [2:13:57<24:42:06,  9.27s/it]                                                        {'loss': 0.9955, 'learning_rate': 1.9886041400337198e-05, 'epoch': 0.08}
  8%|▊         | 797/10395 [2:13:57<24:42:06,  9.27s/it]  8%|▊         | 798/10395 [2:14:05<23:32:00,  8.83s/it]                                                        {'loss': 1.0752, 'learning_rate': 1.9885571882705322e-05, 'epoch': 0.08}
  8%|▊         | 798/10395 [2:14:05<23:32:00,  8.83s/it]  8%|▊         | 799/10395 [2:14:12<22:23:16,  8.40s/it]                                                        {'loss': 1.0178, 'learning_rate': 1.988510140540325e-05, 'epoch': 0.08}
  8%|▊         | 799/10395 [2:14:12<22:23:16,  8.40s/it]  8%|▊         | 800/10395 [2:14:20<21:52:42,  8.21s/it]                                                        {'loss': 1.0178, 'learning_rate': 1.988462996847666e-05, 'epoch': 0.08}
  8%|▊         | 800/10395 [2:14:20<21:52:42,  8.21s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  8%|▊         | 801/10395 [2:15:58<93:50:06, 35.21s/it]                                                        {'loss': 1.0461, 'learning_rate': 1.9884157571971318e-05, 'epoch': 0.08}
  8%|▊         | 801/10395 [2:15:58<93:50:06, 35.21s/it]  8%|▊         | 802/10395 [2:16:06<72:17:58, 27.13s/it]                                                        {'loss': 1.0711, 'learning_rate': 1.988368421593308e-05, 'epoch': 0.08}
  8%|▊         | 802/10395 [2:16:06<72:17:58, 27.13s/it]  8%|▊         | 803/10395 [2:16:14<56:39:56, 21.27s/it]                                                        {'loss': 1.0569, 'learning_rate': 1.98832099004079e-05, 'epoch': 0.08}
  8%|▊         | 803/10395 [2:16:14<56:39:56, 21.27s/it]  8%|▊         | 804/10395 [2:16:21<45:13:22, 16.97s/it]                                                        {'loss': 1.0979, 'learning_rate': 1.988273462544182e-05, 'epoch': 0.08}
  8%|▊         | 804/10395 [2:16:21<45:13:22, 16.97s/it]  8%|▊         | 805/10395 [2:16:29<37:53:25, 14.22s/it]                                                        {'loss': 1.0103, 'learning_rate': 1.9882258391080986e-05, 'epoch': 0.08}
  8%|▊         | 805/10395 [2:16:29<37:53:25, 14.22s/it]  8%|▊         | 806/10395 [2:16:38<33:42:55, 12.66s/it]                                                        {'loss': 1.0378, 'learning_rate': 1.9881781197371624e-05, 'epoch': 0.08}
  8%|▊         | 806/10395 [2:16:38<33:42:55, 12.66s/it]  8%|▊         | 807/10395 [2:16:46<29:45:14, 11.17s/it]                                                        {'loss': 0.9633, 'learning_rate': 1.9881303044360065e-05, 'epoch': 0.08}
  8%|▊         | 807/10395 [2:16:46<29:45:14, 11.17s/it]  8%|▊         | 808/10395 [2:16:54<27:34:07, 10.35s/it]                                                        {'loss': 1.0006, 'learning_rate': 1.9880823932092718e-05, 'epoch': 0.08}
  8%|▊         | 808/10395 [2:16:54<27:34:07, 10.35s/it]  8%|▊         | 809/10395 [2:17:02<25:21:24,  9.52s/it]                                                        {'loss': 1.035, 'learning_rate': 1.9880343860616104e-05, 'epoch': 0.08}
  8%|▊         | 809/10395 [2:17:02<25:21:24,  9.52s/it]  8%|▊         | 810/10395 [2:17:09<23:44:21,  8.92s/it]                                                        {'loss': 1.0292, 'learning_rate': 1.9879862829976816e-05, 'epoch': 0.08}
  8%|▊         | 810/10395 [2:17:09<23:44:21,  8.92s/it]  8%|▊         | 811/10395 [2:17:27<31:17:45, 11.76s/it]                                                        {'loss': 0.3215, 'learning_rate': 1.9879380840221562e-05, 'epoch': 0.08}
  8%|▊         | 811/10395 [2:17:27<31:17:45, 11.76s/it]  8%|▊         | 812/10395 [2:17:35<27:39:01, 10.39s/it]                                                        {'loss': 0.9994, 'learning_rate': 1.987889789139713e-05, 'epoch': 0.08}
  8%|▊         | 812/10395 [2:17:35<27:39:01, 10.39s/it]  8%|▊         | 813/10395 [2:17:42<25:21:30,  9.53s/it]                                                        {'loss': 1.0362, 'learning_rate': 1.9878413983550397e-05, 'epoch': 0.08}
  8%|▊         | 813/10395 [2:17:42<25:21:30,  9.53s/it]  8%|▊         | 814/10395 [2:17:49<23:13:14,  8.73s/it]                                                        {'loss': 1.0073, 'learning_rate': 1.9877929116728344e-05, 'epoch': 0.08}
  8%|▊         | 814/10395 [2:17:49<23:13:14,  8.73s/it]  8%|▊         | 815/10395 [2:17:57<22:52:53,  8.60s/it]                                                        {'loss': 1.048, 'learning_rate': 1.987744329097805e-05, 'epoch': 0.08}
  8%|▊         | 815/10395 [2:17:57<22:52:53,  8.60s/it]  8%|▊         | 816/10395 [2:18:05<22:23:51,  8.42s/it]                                                        {'loss': 0.9385, 'learning_rate': 1.987695650634666e-05, 'epoch': 0.08}
  8%|▊         | 816/10395 [2:18:05<22:23:51,  8.42s/it]  8%|▊         | 817/10395 [2:18:13<21:53:17,  8.23s/it]                                                        {'loss': 1.0057, 'learning_rate': 1.9876468762881445e-05, 'epoch': 0.08}
  8%|▊         | 817/10395 [2:18:13<21:53:17,  8.23s/it]  8%|▊         | 818/10395 [2:18:21<21:29:09,  8.08s/it]                                                        {'loss': 1.1053, 'learning_rate': 1.9875980060629744e-05, 'epoch': 0.08}
  8%|▊         | 818/10395 [2:18:21<21:29:09,  8.08s/it]  8%|▊         | 819/10395 [2:18:29<21:12:17,  7.97s/it]                                                        {'loss': 0.9739, 'learning_rate': 1.9875490399639007e-05, 'epoch': 0.08}
  8%|▊         | 819/10395 [2:18:29<21:12:17,  7.97s/it]  8%|▊         | 820/10395 [2:18:37<21:22:32,  8.04s/it]                                                        {'loss': 1.0361, 'learning_rate': 1.9874999779956767e-05, 'epoch': 0.08}
  8%|▊         | 820/10395 [2:18:37<21:22:32,  8.04s/it]  8%|▊         | 821/10395 [2:18:46<22:05:37,  8.31s/it]                                                        {'loss': 0.9486, 'learning_rate': 1.987450820163065e-05, 'epoch': 0.08}
  8%|▊         | 821/10395 [2:18:46<22:05:37,  8.31s/it]  8%|▊         | 822/10395 [2:18:53<21:42:17,  8.16s/it]                                                        {'loss': 1.002, 'learning_rate': 1.9874015664708378e-05, 'epoch': 0.08}
  8%|▊         | 822/10395 [2:18:53<21:42:17,  8.16s/it]  8%|▊         | 823/10395 [2:19:02<21:50:03,  8.21s/it]                                                        {'loss': 0.982, 'learning_rate': 1.9873522169237768e-05, 'epoch': 0.08}
  8%|▊         | 823/10395 [2:19:02<21:50:03,  8.21s/it]  8%|▊         | 824/10395 [2:19:09<21:22:51,  8.04s/it]                                                        {'loss': 0.9494, 'learning_rate': 1.9873027715266725e-05, 'epoch': 0.08}
  8%|▊         | 824/10395 [2:19:09<21:22:51,  8.04s/it]  8%|▊         | 825/10395 [2:19:18<21:48:22,  8.20s/it]                                                        {'loss': 0.9898, 'learning_rate': 1.987253230284325e-05, 'epoch': 0.08}
  8%|▊         | 825/10395 [2:19:18<21:48:22,  8.20s/it]  8%|▊         | 826/10395 [2:19:26<21:30:06,  8.09s/it]                                                        {'loss': 1.037, 'learning_rate': 1.9872035932015435e-05, 'epoch': 0.08}
  8%|▊         | 826/10395 [2:19:26<21:30:06,  8.09s/it]  8%|▊         | 827/10395 [2:19:33<20:45:35,  7.81s/it]                                                        {'loss': 1.0202, 'learning_rate': 1.987153860283147e-05, 'epoch': 0.08}
  8%|▊         | 827/10395 [2:19:33<20:45:35,  7.81s/it]  8%|▊         | 828/10395 [2:19:41<20:34:55,  7.74s/it]                                                        {'loss': 1.0644, 'learning_rate': 1.9871040315339632e-05, 'epoch': 0.08}
  8%|▊         | 828/10395 [2:19:41<20:34:55,  7.74s/it]  8%|▊         | 829/10395 [2:19:57<27:27:04, 10.33s/it]                                                        {'loss': 0.3398, 'learning_rate': 1.9870541069588294e-05, 'epoch': 0.08}
  8%|▊         | 829/10395 [2:19:57<27:27:04, 10.33s/it]  8%|▊         | 830/10395 [2:20:05<25:21:22,  9.54s/it]                                                        {'loss': 0.9964, 'learning_rate': 1.9870040865625924e-05, 'epoch': 0.08}
  8%|▊         | 830/10395 [2:20:05<25:21:22,  9.54s/it]  8%|▊         | 831/10395 [2:20:13<24:41:54,  9.30s/it]                                                        {'loss': 0.993, 'learning_rate': 1.9869539703501083e-05, 'epoch': 0.08}
  8%|▊         | 831/10395 [2:20:13<24:41:54,  9.30s/it]  8%|▊         | 832/10395 [2:20:21<23:10:23,  8.72s/it]                                                        {'loss': 0.943, 'learning_rate': 1.9869037583262415e-05, 'epoch': 0.08}
  8%|▊         | 832/10395 [2:20:21<23:10:23,  8.72s/it]  8%|▊         | 833/10395 [2:20:30<23:22:18,  8.80s/it]                                                        {'loss': 0.9907, 'learning_rate': 1.9868534504958665e-05, 'epoch': 0.08}
  8%|▊         | 833/10395 [2:20:30<23:22:18,  8.80s/it]  8%|▊         | 834/10395 [2:20:37<22:27:23,  8.46s/it]                                                        {'loss': 1.0296, 'learning_rate': 1.9868030468638677e-05, 'epoch': 0.08}
  8%|▊         | 834/10395 [2:20:37<22:27:23,  8.46s/it]  8%|▊         | 835/10395 [2:20:46<22:11:22,  8.36s/it]                                                        {'loss': 0.9416, 'learning_rate': 1.986752547435138e-05, 'epoch': 0.08}
  8%|▊         | 835/10395 [2:20:46<22:11:22,  8.36s/it]  8%|▊         | 836/10395 [2:20:54<22:10:22,  8.35s/it]                                                        {'loss': 0.9027, 'learning_rate': 1.98670195221458e-05, 'epoch': 0.08}
  8%|▊         | 836/10395 [2:20:54<22:10:22,  8.35s/it]  8%|▊         | 837/10395 [2:21:01<21:02:00,  7.92s/it]                                                        {'loss': 0.9403, 'learning_rate': 1.9866512612071046e-05, 'epoch': 0.08}
  8%|▊         | 837/10395 [2:21:01<21:02:00,  7.92s/it]  8%|▊         | 838/10395 [2:21:08<20:48:17,  7.84s/it]                                                        {'loss': 1.0534, 'learning_rate': 1.9866004744176334e-05, 'epoch': 0.08}
  8%|▊         | 838/10395 [2:21:08<20:48:17,  7.84s/it]  8%|▊         | 839/10395 [2:21:16<20:22:47,  7.68s/it]                                                        {'loss': 1.0465, 'learning_rate': 1.9865495918510965e-05, 'epoch': 0.08}
  8%|▊         | 839/10395 [2:21:16<20:22:47,  7.68s/it]  8%|▊         | 840/10395 [2:21:24<20:26:25,  7.70s/it]                                                        {'loss': 1.0217, 'learning_rate': 1.9864986135124336e-05, 'epoch': 0.08}
  8%|▊         | 840/10395 [2:21:24<20:26:25,  7.70s/it]  8%|▊         | 841/10395 [2:21:31<20:14:13,  7.63s/it]                                                        {'loss': 1.0006, 'learning_rate': 1.9864475394065932e-05, 'epoch': 0.08}
  8%|▊         | 841/10395 [2:21:31<20:14:13,  7.63s/it]  8%|▊         | 842/10395 [2:21:38<20:02:23,  7.55s/it]                                                        {'loss': 1.0108, 'learning_rate': 1.986396369538534e-05, 'epoch': 0.08}
  8%|▊         | 842/10395 [2:21:38<20:02:23,  7.55s/it]  8%|▊         | 843/10395 [2:21:46<19:52:17,  7.49s/it]                                                        {'loss': 1.0436, 'learning_rate': 1.9863451039132227e-05, 'epoch': 0.08}
  8%|▊         | 843/10395 [2:21:46<19:52:17,  7.49s/it]  8%|▊         | 844/10395 [2:22:03<27:28:43, 10.36s/it]                                                        {'loss': 0.3511, 'learning_rate': 1.986293742535637e-05, 'epoch': 0.08}
  8%|▊         | 844/10395 [2:22:03<27:28:43, 10.36s/it]  8%|▊         | 845/10395 [2:22:10<24:56:16,  9.40s/it]                                                        {'loss': 0.9509, 'learning_rate': 1.9862422854107626e-05, 'epoch': 0.08}
  8%|▊         | 845/10395 [2:22:10<24:56:16,  9.40s/it]  8%|▊         | 846/10395 [2:22:18<23:34:49,  8.89s/it]                                                        {'loss': 0.992, 'learning_rate': 1.9861907325435946e-05, 'epoch': 0.08}
  8%|▊         | 846/10395 [2:22:18<23:34:49,  8.89s/it]  8%|▊         | 847/10395 [2:22:26<22:48:30,  8.60s/it]                                                        {'loss': 1.0361, 'learning_rate': 1.9861390839391374e-05, 'epoch': 0.08}
  8%|▊         | 847/10395 [2:22:26<22:48:30,  8.60s/it]  8%|▊         | 848/10395 [2:22:34<22:37:20,  8.53s/it]                                                        {'loss': 0.9792, 'learning_rate': 1.986087339602406e-05, 'epoch': 0.08}
  8%|▊         | 848/10395 [2:22:34<22:37:20,  8.53s/it]  8%|▊         | 849/10395 [2:22:42<22:15:20,  8.39s/it]                                                        {'loss': 0.9496, 'learning_rate': 1.986035499538422e-05, 'epoch': 0.08}
  8%|▊         | 849/10395 [2:22:42<22:15:20,  8.39s/it]  8%|▊         | 850/10395 [2:22:50<21:43:02,  8.19s/it]                                                        {'loss': 1.0148, 'learning_rate': 1.98598356375222e-05, 'epoch': 0.08}
  8%|▊         | 850/10395 [2:22:50<21:43:02,  8.19s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  8%|▊         | 851/10395 [2:24:32<96:30:25, 36.40s/it]                                                        {'loss': 1.013, 'learning_rate': 1.9859315322488397e-05, 'epoch': 0.08}
  8%|▊         | 851/10395 [2:24:32<96:30:25, 36.40s/it]  8%|▊         | 852/10395 [2:24:40<73:50:37, 27.86s/it]                                                        {'loss': 0.9885, 'learning_rate': 1.9858794050333338e-05, 'epoch': 0.08}
  8%|▊         | 852/10395 [2:24:40<73:50:37, 27.86s/it]  8%|▊         | 853/10395 [2:24:48<58:00:35, 21.89s/it]                                                        {'loss': 0.9773, 'learning_rate': 1.9858271821107617e-05, 'epoch': 0.08}
  8%|▊         | 853/10395 [2:24:48<58:00:35, 21.89s/it]  8%|▊         | 854/10395 [2:24:56<47:28:42, 17.91s/it]                                                        {'loss': 1.0699, 'learning_rate': 1.9857748634861937e-05, 'epoch': 0.08}
  8%|▊         | 854/10395 [2:24:56<47:28:42, 17.91s/it]  8%|▊         | 855/10395 [2:25:04<39:02:54, 14.74s/it]                                                        {'loss': 1.0281, 'learning_rate': 1.9857224491647087e-05, 'epoch': 0.08}
  8%|▊         | 855/10395 [2:25:04<39:02:54, 14.74s/it]  8%|▊         | 856/10395 [2:25:12<34:11:57, 12.91s/it]                                                        {'loss': 0.9653, 'learning_rate': 1.9856699391513946e-05, 'epoch': 0.08}
  8%|▊         | 856/10395 [2:25:12<34:11:57, 12.91s/it]  8%|▊         | 857/10395 [2:25:20<30:18:31, 11.44s/it]                                                        {'loss': 0.9943, 'learning_rate': 1.9856173334513495e-05, 'epoch': 0.08}
  8%|▊         | 857/10395 [2:25:20<30:18:31, 11.44s/it]  8%|▊         | 858/10395 [2:25:28<27:36:03, 10.42s/it]                                                        {'loss': 0.9493, 'learning_rate': 1.9855646320696797e-05, 'epoch': 0.08}
  8%|▊         | 858/10395 [2:25:28<27:36:03, 10.42s/it]  8%|▊         | 859/10395 [2:25:36<25:41:02,  9.70s/it]                                                        {'loss': 0.9525, 'learning_rate': 1.9855118350115012e-05, 'epoch': 0.08}
  8%|▊         | 859/10395 [2:25:36<25:41:02,  9.70s/it]  8%|▊         | 860/10395 [2:25:45<24:28:42,  9.24s/it]                                                        {'loss': 0.995, 'learning_rate': 1.9854589422819404e-05, 'epoch': 0.08}
  8%|▊         | 860/10395 [2:25:45<24:28:42,  9.24s/it]  8%|▊         | 861/10395 [2:25:52<23:20:06,  8.81s/it]                                                        {'loss': 0.9595, 'learning_rate': 1.9854059538861312e-05, 'epoch': 0.08}
  8%|▊         | 861/10395 [2:25:52<23:20:06,  8.81s/it]  8%|▊         | 862/10395 [2:26:00<22:19:13,  8.43s/it]                                                        {'loss': 1.0233, 'learning_rate': 1.985352869829218e-05, 'epoch': 0.08}
  8%|▊         | 862/10395 [2:26:00<22:19:13,  8.43s/it]  8%|▊         | 863/10395 [2:26:08<22:00:19,  8.31s/it]                                                        {'loss': 0.9869, 'learning_rate': 1.9852996901163533e-05, 'epoch': 0.08}
  8%|▊         | 863/10395 [2:26:08<22:00:19,  8.31s/it]  8%|▊         | 864/10395 [2:26:16<21:25:05,  8.09s/it]                                                        {'loss': 0.8928, 'learning_rate': 1.985246414752701e-05, 'epoch': 0.08}
  8%|▊         | 864/10395 [2:26:16<21:25:05,  8.09s/it]  8%|▊         | 865/10395 [2:26:23<20:54:50,  7.90s/it]                                                        {'loss': 0.9969, 'learning_rate': 1.985193043743432e-05, 'epoch': 0.08}
  8%|▊         | 865/10395 [2:26:23<20:54:50,  7.90s/it]  8%|▊         | 866/10395 [2:26:30<20:30:22,  7.75s/it]                                                        {'loss': 1.0586, 'learning_rate': 1.9851395770937273e-05, 'epoch': 0.08}
  8%|▊         | 866/10395 [2:26:30<20:30:22,  7.75s/it]  8%|▊         | 867/10395 [2:26:39<20:48:03,  7.86s/it]                                                        {'loss': 1.0952, 'learning_rate': 1.985086014808778e-05, 'epoch': 0.08}
  8%|▊         | 867/10395 [2:26:39<20:48:03,  7.86s/it]  8%|▊         | 868/10395 [2:26:48<21:56:11,  8.29s/it]                                                        {'loss': 1.051, 'learning_rate': 1.9850323568937836e-05, 'epoch': 0.08}
  8%|▊         | 868/10395 [2:26:48<21:56:11,  8.29s/it]  8%|▊         | 869/10395 [2:27:06<29:53:51, 11.30s/it]                                                        {'loss': 0.3285, 'learning_rate': 1.9849786033539533e-05, 'epoch': 0.08}
  8%|▊         | 869/10395 [2:27:06<29:53:51, 11.30s/it]  8%|▊         | 870/10395 [2:27:14<27:03:08, 10.22s/it]                                                        {'loss': 0.9485, 'learning_rate': 1.9849247541945044e-05, 'epoch': 0.08}
  8%|▊         | 870/10395 [2:27:14<27:03:08, 10.22s/it]  8%|▊         | 871/10395 [2:27:22<25:19:26,  9.57s/it]                                                        {'loss': 0.9721, 'learning_rate': 1.9848708094206656e-05, 'epoch': 0.08}
  8%|▊         | 871/10395 [2:27:22<25:19:26,  9.57s/it]  8%|▊         | 872/10395 [2:27:30<23:48:40,  9.00s/it]                                                        {'loss': 1.0219, 'learning_rate': 1.9848167690376732e-05, 'epoch': 0.08}
  8%|▊         | 872/10395 [2:27:30<23:48:40,  9.00s/it]  8%|▊         | 873/10395 [2:27:37<22:56:10,  8.67s/it]                                                        {'loss': 0.972, 'learning_rate': 1.9847626330507734e-05, 'epoch': 0.08}
  8%|▊         | 873/10395 [2:27:37<22:56:10,  8.67s/it]  8%|▊         | 874/10395 [2:27:46<22:25:59,  8.48s/it]                                                        {'loss': 0.9351, 'learning_rate': 1.9847084014652214e-05, 'epoch': 0.08}
  8%|▊         | 874/10395 [2:27:46<22:25:59,  8.48s/it]  8%|▊         | 875/10395 [2:27:53<21:43:50,  8.22s/it]                                                        {'loss': 0.9994, 'learning_rate': 1.9846540742862826e-05, 'epoch': 0.08}
  8%|▊         | 875/10395 [2:27:53<21:43:50,  8.22s/it]  8%|▊         | 876/10395 [2:28:01<21:34:12,  8.16s/it]                                                        {'loss': 1.0263, 'learning_rate': 1.98459965151923e-05, 'epoch': 0.08}
  8%|▊         | 876/10395 [2:28:01<21:34:12,  8.16s/it]  8%|▊         | 877/10395 [2:28:10<22:13:49,  8.41s/it]                                                        {'loss': 0.9819, 'learning_rate': 1.9845451331693478e-05, 'epoch': 0.08}
  8%|▊         | 877/10395 [2:28:10<22:13:49,  8.41s/it]  8%|▊         | 878/10395 [2:28:19<22:36:55,  8.55s/it]                                                        {'loss': 0.9938, 'learning_rate': 1.9844905192419276e-05, 'epoch': 0.08}
  8%|▊         | 878/10395 [2:28:19<22:36:55,  8.55s/it]  8%|▊         | 879/10395 [2:28:27<22:21:28,  8.46s/it]                                                        {'loss': 0.9637, 'learning_rate': 1.984435809742272e-05, 'epoch': 0.08}
  8%|▊         | 879/10395 [2:28:27<22:21:28,  8.46s/it]  8%|▊         | 880/10395 [2:28:35<21:52:47,  8.28s/it]                                                        {'loss': 1.05, 'learning_rate': 1.9843810046756915e-05, 'epoch': 0.08}
  8%|▊         | 880/10395 [2:28:35<21:52:47,  8.28s/it]  8%|▊         | 881/10395 [2:28:53<29:32:42, 11.18s/it]                                                        {'loss': 0.3776, 'learning_rate': 1.984326104047507e-05, 'epoch': 0.08}
  8%|▊         | 881/10395 [2:28:53<29:32:42, 11.18s/it]  8%|▊         | 882/10395 [2:29:01<27:08:18, 10.27s/it]                                                        {'loss': 1.0463, 'learning_rate': 1.9842711078630477e-05, 'epoch': 0.08}
  8%|▊         | 882/10395 [2:29:01<27:08:18, 10.27s/it]  8%|▊         | 883/10395 [2:29:10<25:59:49,  9.84s/it]                                                        {'loss': 1.0448, 'learning_rate': 1.9842160161276522e-05, 'epoch': 0.08}
  8%|▊         | 883/10395 [2:29:10<25:59:49,  9.84s/it]  9%|▊         | 884/10395 [2:29:18<24:49:56,  9.40s/it]                                                        {'loss': 0.9937, 'learning_rate': 1.9841608288466698e-05, 'epoch': 0.09}
  9%|▊         | 884/10395 [2:29:18<24:49:56,  9.40s/it]  9%|▊         | 885/10395 [2:29:26<23:11:57,  8.78s/it]                                                        {'loss': 1.0344, 'learning_rate': 1.9841055460254572e-05, 'epoch': 0.09}
  9%|▊         | 885/10395 [2:29:26<23:11:57,  8.78s/it]  9%|▊         | 886/10395 [2:29:33<22:15:03,  8.42s/it]                                                        {'loss': 1.0255, 'learning_rate': 1.9840501676693805e-05, 'epoch': 0.09}
  9%|▊         | 886/10395 [2:29:33<22:15:03,  8.42s/it]  9%|▊         | 887/10395 [2:29:41<21:31:17,  8.15s/it]                                                        {'loss': 0.9359, 'learning_rate': 1.983994693783817e-05, 'epoch': 0.09}
  9%|▊         | 887/10395 [2:29:41<21:31:17,  8.15s/it]  9%|▊         | 888/10395 [2:29:48<20:53:53,  7.91s/it]                                                        {'loss': 1.0053, 'learning_rate': 1.9839391243741514e-05, 'epoch': 0.09}
  9%|▊         | 888/10395 [2:29:48<20:53:53,  7.91s/it]  9%|▊         | 889/10395 [2:29:56<20:58:20,  7.94s/it]                                                        {'loss': 0.9384, 'learning_rate': 1.9838834594457785e-05, 'epoch': 0.09}
  9%|▊         | 889/10395 [2:29:56<20:58:20,  7.94s/it]  9%|▊         | 890/10395 [2:30:05<21:32:56,  8.16s/it]                                                        {'loss': 1.013, 'learning_rate': 1.9838276990041017e-05, 'epoch': 0.09}
  9%|▊         | 890/10395 [2:30:05<21:32:56,  8.16s/it]  9%|▊         | 891/10395 [2:30:14<22:01:41,  8.34s/it]                                                        {'loss': 0.9814, 'learning_rate': 1.9837718430545343e-05, 'epoch': 0.09}
  9%|▊         | 891/10395 [2:30:14<22:01:41,  8.34s/it]  9%|▊         | 892/10395 [2:30:21<21:23:24,  8.10s/it]                                                        {'loss': 1.0494, 'learning_rate': 1.983715891602499e-05, 'epoch': 0.09}
  9%|▊         | 892/10395 [2:30:21<21:23:24,  8.10s/it]  9%|▊         | 893/10395 [2:30:29<21:13:28,  8.04s/it]                                                        {'loss': 1.0913, 'learning_rate': 1.983659844653427e-05, 'epoch': 0.09}
  9%|▊         | 893/10395 [2:30:29<21:13:28,  8.04s/it]  9%|▊         | 894/10395 [2:30:38<21:42:30,  8.23s/it]                                                        {'loss': 0.9522, 'learning_rate': 1.9836037022127593e-05, 'epoch': 0.09}
  9%|▊         | 894/10395 [2:30:38<21:42:30,  8.23s/it]  9%|▊         | 895/10395 [2:30:46<21:36:16,  8.19s/it]                                                        {'loss': 1.002, 'learning_rate': 1.983547464285946e-05, 'epoch': 0.09}
  9%|▊         | 895/10395 [2:30:46<21:36:16,  8.19s/it]  9%|▊         | 896/10395 [2:30:53<21:02:50,  7.98s/it]                                                        {'loss': 1.0174, 'learning_rate': 1.9834911308784467e-05, 'epoch': 0.09}
  9%|▊         | 896/10395 [2:30:53<21:02:50,  7.98s/it]  9%|▊         | 897/10395 [2:31:01<20:35:02,  7.80s/it]                                                        {'loss': 1.0663, 'learning_rate': 1.9834347019957302e-05, 'epoch': 0.09}
  9%|▊         | 897/10395 [2:31:01<20:35:02,  7.80s/it]  9%|▊         | 898/10395 [2:31:09<21:15:55,  8.06s/it]                                                        {'loss': 1.0139, 'learning_rate': 1.9833781776432745e-05, 'epoch': 0.09}
  9%|▊         | 898/10395 [2:31:09<21:15:55,  8.06s/it]  9%|▊         | 899/10395 [2:31:17<20:51:29,  7.91s/it]                                                        {'loss': 0.9646, 'learning_rate': 1.983321557826567e-05, 'epoch': 0.09}
  9%|▊         | 899/10395 [2:31:17<20:51:29,  7.91s/it]  9%|▊         | 900/10395 [2:31:25<20:49:08,  7.89s/it]                                                        {'loss': 0.9861, 'learning_rate': 1.9832648425511038e-05, 'epoch': 0.09}
  9%|▊         | 900/10395 [2:31:25<20:49:08,  7.89s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  9%|▊         | 901/10395 [2:33:14<101:02:37, 38.31s/it]                                                         {'loss': 0.3704, 'learning_rate': 1.983208031822391e-05, 'epoch': 0.09}
  9%|▊         | 901/10395 [2:33:14<101:02:37, 38.31s/it]  9%|▊         | 902/10395 [2:33:22<76:44:40, 29.10s/it]                                                         {'loss': 0.9445, 'learning_rate': 1.9831511256459433e-05, 'epoch': 0.09}
  9%|▊         | 902/10395 [2:33:22<76:44:40, 29.10s/it]  9%|▊         | 903/10395 [2:33:30<60:09:50, 22.82s/it]                                                        {'loss': 0.9568, 'learning_rate': 1.9830941240272858e-05, 'epoch': 0.09}
  9%|▊         | 903/10395 [2:33:30<60:09:50, 22.82s/it]  9%|▊         | 904/10395 [2:33:38<48:32:34, 18.41s/it]                                                        {'loss': 0.9766, 'learning_rate': 1.9830370269719516e-05, 'epoch': 0.09}
  9%|▊         | 904/10395 [2:33:38<48:32:34, 18.41s/it]  9%|▊         | 905/10395 [2:33:46<40:12:22, 15.25s/it]                                                        {'loss': 1.0497, 'learning_rate': 1.9829798344854833e-05, 'epoch': 0.09}
  9%|▊         | 905/10395 [2:33:46<40:12:22, 15.25s/it]  9%|▊         | 906/10395 [2:33:53<34:05:54, 12.94s/it]                                                        {'loss': 1.0512, 'learning_rate': 1.9829225465734335e-05, 'epoch': 0.09}
  9%|▊         | 906/10395 [2:33:53<34:05:54, 12.94s/it]  9%|▊         | 907/10395 [2:34:01<29:56:06, 11.36s/it]                                                        {'loss': 1.0989, 'learning_rate': 1.982865163241363e-05, 'epoch': 0.09}
  9%|▊         | 907/10395 [2:34:01<29:56:06, 11.36s/it]  9%|▊         | 908/10395 [2:34:09<27:10:04, 10.31s/it]                                                        {'loss': 1.0688, 'learning_rate': 1.9828076844948435e-05, 'epoch': 0.09}
  9%|▊         | 908/10395 [2:34:09<27:10:04, 10.31s/it]  9%|▊         | 909/10395 [2:34:17<25:08:02,  9.54s/it]                                                        {'loss': 0.9866, 'learning_rate': 1.9827501103394536e-05, 'epoch': 0.09}
  9%|▊         | 909/10395 [2:34:17<25:08:02,  9.54s/it]  9%|▉         | 910/10395 [2:34:24<23:21:18,  8.86s/it]                                                        {'loss': 1.0034, 'learning_rate': 1.9826924407807838e-05, 'epoch': 0.09}
  9%|▉         | 910/10395 [2:34:24<23:21:18,  8.86s/it]  9%|▉         | 911/10395 [2:34:32<22:33:28,  8.56s/it]                                                        {'loss': 0.9985, 'learning_rate': 1.9826346758244314e-05, 'epoch': 0.09}
  9%|▉         | 911/10395 [2:34:32<22:33:28,  8.56s/it]  9%|▉         | 912/10395 [2:34:39<21:39:36,  8.22s/it]                                                        {'loss': 1.0133, 'learning_rate': 1.9825768154760046e-05, 'epoch': 0.09}
  9%|▉         | 912/10395 [2:34:39<21:39:36,  8.22s/it]  9%|▉         | 913/10395 [2:34:47<21:34:25,  8.19s/it]                                                        {'loss': 1.053, 'learning_rate': 1.9825188597411204e-05, 'epoch': 0.09}
  9%|▉         | 913/10395 [2:34:47<21:34:25,  8.19s/it]  9%|▉         | 914/10395 [2:34:55<21:10:42,  8.04s/it]                                                        {'loss': 1.0693, 'learning_rate': 1.9824608086254048e-05, 'epoch': 0.09}
  9%|▉         | 914/10395 [2:34:55<21:10:42,  8.04s/it]  9%|▉         | 915/10395 [2:35:12<28:04:23, 10.66s/it]                                                        {'loss': 0.3218, 'learning_rate': 1.9824026621344935e-05, 'epoch': 0.09}
  9%|▉         | 915/10395 [2:35:12<28:04:23, 10.66s/it]  9%|▉         | 916/10395 [2:35:21<26:38:43, 10.12s/it]                                                        {'loss': 0.8893, 'learning_rate': 1.9823444202740315e-05, 'epoch': 0.09}
  9%|▉         | 916/10395 [2:35:21<26:38:43, 10.12s/it]  9%|▉         | 917/10395 [2:35:29<25:06:54,  9.54s/it]                                                        {'loss': 1.1289, 'learning_rate': 1.982286083049672e-05, 'epoch': 0.09}
  9%|▉         | 917/10395 [2:35:29<25:06:54,  9.54s/it]  9%|▉         | 918/10395 [2:35:36<23:31:01,  8.93s/it]                                                        {'loss': 0.9992, 'learning_rate': 1.982227650467079e-05, 'epoch': 0.09}
  9%|▉         | 918/10395 [2:35:36<23:31:01,  8.93s/it]  9%|▉         | 919/10395 [2:35:56<31:31:57, 11.98s/it]                                                        {'loss': 0.3438, 'learning_rate': 1.9821691225319247e-05, 'epoch': 0.09}
  9%|▉         | 919/10395 [2:35:56<31:31:57, 11.98s/it]  9%|▉         | 920/10395 [2:36:03<28:16:10, 10.74s/it]                                                        {'loss': 0.9659, 'learning_rate': 1.9821104992498906e-05, 'epoch': 0.09}
  9%|▉         | 920/10395 [2:36:03<28:16:10, 10.74s/it]  9%|▉         | 921/10395 [2:36:11<25:58:25,  9.87s/it]                                                        {'loss': 1.0022, 'learning_rate': 1.9820517806266682e-05, 'epoch': 0.09}
  9%|▉         | 921/10395 [2:36:11<25:58:25,  9.87s/it]  9%|▉         | 922/10395 [2:36:19<24:13:02,  9.20s/it]                                                        {'loss': 1.0103, 'learning_rate': 1.9819929666679578e-05, 'epoch': 0.09}
  9%|▉         | 922/10395 [2:36:19<24:13:02,  9.20s/it]  9%|▉         | 923/10395 [2:36:27<23:08:18,  8.79s/it]                                                        {'loss': 1.1175, 'learning_rate': 1.9819340573794682e-05, 'epoch': 0.09}
  9%|▉         | 923/10395 [2:36:27<23:08:18,  8.79s/it]  9%|▉         | 924/10395 [2:36:34<22:15:50,  8.46s/it]                                                        {'loss': 1.0287, 'learning_rate': 1.9818750527669194e-05, 'epoch': 0.09}
  9%|▉         | 924/10395 [2:36:34<22:15:50,  8.46s/it]  9%|▉         | 925/10395 [2:36:42<21:42:44,  8.25s/it]                                                        {'loss': 1.0594, 'learning_rate': 1.9818159528360383e-05, 'epoch': 0.09}
  9%|▉         | 925/10395 [2:36:42<21:42:44,  8.25s/it]  9%|▉         | 926/10395 [2:36:50<21:29:55,  8.17s/it]                                                        {'loss': 0.992, 'learning_rate': 1.9817567575925627e-05, 'epoch': 0.09}
  9%|▉         | 926/10395 [2:36:50<21:29:55,  8.17s/it]  9%|▉         | 927/10395 [2:36:58<21:14:25,  8.08s/it]                                                        {'loss': 1.0052, 'learning_rate': 1.9816974670422392e-05, 'epoch': 0.09}
  9%|▉         | 927/10395 [2:36:58<21:14:25,  8.08s/it]  9%|▉         | 928/10395 [2:37:06<20:55:04,  7.95s/it]                                                        {'loss': 1.0482, 'learning_rate': 1.9816380811908233e-05, 'epoch': 0.09}
  9%|▉         | 928/10395 [2:37:06<20:55:04,  7.95s/it]  9%|▉         | 929/10395 [2:37:14<21:11:07,  8.06s/it]                                                        {'loss': 0.9651, 'learning_rate': 1.9815786000440802e-05, 'epoch': 0.09}
  9%|▉         | 929/10395 [2:37:14<21:11:07,  8.06s/it]  9%|▉         | 930/10395 [2:37:22<20:49:23,  7.92s/it]                                                        {'loss': 1.0168, 'learning_rate': 1.9815190236077846e-05, 'epoch': 0.09}
  9%|▉         | 930/10395 [2:37:22<20:49:23,  7.92s/it]  9%|▉         | 931/10395 [2:37:29<20:40:10,  7.86s/it]                                                        {'loss': 0.957, 'learning_rate': 1.9814593518877197e-05, 'epoch': 0.09}
  9%|▉         | 931/10395 [2:37:29<20:40:10,  7.86s/it]  9%|▉         | 932/10395 [2:37:37<20:33:50,  7.82s/it]                                                        {'loss': 1.032, 'learning_rate': 1.981399584889678e-05, 'epoch': 0.09}
  9%|▉         | 932/10395 [2:37:37<20:33:50,  7.82s/it]  9%|▉         | 933/10395 [2:37:55<28:40:19, 10.91s/it]                                                        {'loss': 0.3774, 'learning_rate': 1.981339722619462e-05, 'epoch': 0.09}
  9%|▉         | 933/10395 [2:37:55<28:40:19, 10.91s/it]  9%|▉         | 934/10395 [2:38:03<25:56:53,  9.87s/it]                                                        {'loss': 1.004, 'learning_rate': 1.9812797650828827e-05, 'epoch': 0.09}
  9%|▉         | 934/10395 [2:38:03<25:56:53,  9.87s/it]  9%|▉         | 935/10395 [2:38:10<24:08:32,  9.19s/it]                                                        {'loss': 0.9496, 'learning_rate': 1.981219712285761e-05, 'epoch': 0.09}
  9%|▉         | 935/10395 [2:38:10<24:08:32,  9.19s/it]  9%|▉         | 936/10395 [2:38:17<22:38:11,  8.62s/it]                                                        {'loss': 0.9791, 'learning_rate': 1.981159564233926e-05, 'epoch': 0.09}
  9%|▉         | 936/10395 [2:38:17<22:38:11,  8.62s/it]  9%|▉         | 937/10395 [2:38:25<21:43:32,  8.27s/it]                                                        {'loss': 0.9951, 'learning_rate': 1.981099320933218e-05, 'epoch': 0.09}
  9%|▉         | 937/10395 [2:38:25<21:43:32,  8.27s/it]  9%|▉         | 938/10395 [2:38:33<21:35:52,  8.22s/it]                                                        {'loss': 0.9803, 'learning_rate': 1.9810389823894846e-05, 'epoch': 0.09}
  9%|▉         | 938/10395 [2:38:33<21:35:52,  8.22s/it]  9%|▉         | 939/10395 [2:38:42<21:48:12,  8.30s/it]                                                        {'loss': 1.0074, 'learning_rate': 1.9809785486085825e-05, 'epoch': 0.09}
  9%|▉         | 939/10395 [2:38:42<21:48:12,  8.30s/it]  9%|▉         | 940/10395 [2:38:50<21:55:47,  8.35s/it]                                                        {'loss': 0.9669, 'learning_rate': 1.98091801959638e-05, 'epoch': 0.09}
  9%|▉         | 940/10395 [2:38:50<21:55:47,  8.35s/it]  9%|▉         | 941/10395 [2:38:58<21:42:55,  8.27s/it]                                                        {'loss': 1.0425, 'learning_rate': 1.980857395358752e-05, 'epoch': 0.09}
  9%|▉         | 941/10395 [2:38:58<21:42:55,  8.27s/it]  9%|▉         | 942/10395 [2:39:06<21:12:27,  8.08s/it]                                                        {'loss': 0.9756, 'learning_rate': 1.980796675901584e-05, 'epoch': 0.09}
  9%|▉         | 942/10395 [2:39:06<21:12:27,  8.08s/it]  9%|▉         | 943/10395 [2:39:14<21:17:28,  8.11s/it]                                                        {'loss': 0.9758, 'learning_rate': 1.980735861230771e-05, 'epoch': 0.09}
  9%|▉         | 943/10395 [2:39:14<21:17:28,  8.11s/it]  9%|▉         | 944/10395 [2:39:31<28:43:38, 10.94s/it]                                                        {'loss': 0.3462, 'learning_rate': 1.9806749513522163e-05, 'epoch': 0.09}
  9%|▉         | 944/10395 [2:39:31<28:43:38, 10.94s/it]  9%|▉         | 945/10395 [2:39:39<26:22:25, 10.05s/it]                                                        {'loss': 0.912, 'learning_rate': 1.980613946271833e-05, 'epoch': 0.09}
  9%|▉         | 945/10395 [2:39:39<26:22:25, 10.05s/it]  9%|▉         | 946/10395 [2:39:47<24:04:53,  9.17s/it]                                                        {'loss': 1.0716, 'learning_rate': 1.9805528459955433e-05, 'epoch': 0.09}
  9%|▉         | 946/10395 [2:39:47<24:04:53,  9.17s/it]  9%|▉         | 947/10395 [2:39:54<22:58:02,  8.75s/it]                                                        {'loss': 1.0133, 'learning_rate': 1.980491650529279e-05, 'epoch': 0.09}
  9%|▉         | 947/10395 [2:39:54<22:58:02,  8.75s/it]  9%|▉         | 948/10395 [2:40:02<22:06:52,  8.43s/it]                                                        {'loss': 1.0174, 'learning_rate': 1.9804303598789804e-05, 'epoch': 0.09}
  9%|▉         | 948/10395 [2:40:02<22:06:52,  8.43s/it]  9%|▉         | 949/10395 [2:40:19<29:12:53, 11.13s/it]                                                        {'loss': 0.3499, 'learning_rate': 1.980368974050598e-05, 'epoch': 0.09}
  9%|▉         | 949/10395 [2:40:19<29:12:53, 11.13s/it]  9%|▉         | 950/10395 [2:40:27<26:48:21, 10.22s/it]                                                        {'loss': 0.9659, 'learning_rate': 1.98030749305009e-05, 'epoch': 0.09}
  9%|▉         | 950/10395 [2:40:27<26:48:21, 10.22s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  9%|▉         | 951/10395 [2:42:03<93:44:38, 35.73s/it]                                                        {'loss': 1.0004, 'learning_rate': 1.980245916883426e-05, 'epoch': 0.09}
  9%|▉         | 951/10395 [2:42:03<93:44:38, 35.73s/it]  9%|▉         | 952/10395 [2:42:11<72:12:55, 27.53s/it]                                                        {'loss': 0.991, 'learning_rate': 1.980184245556583e-05, 'epoch': 0.09}
  9%|▉         | 952/10395 [2:42:11<72:12:55, 27.53s/it]  9%|▉         | 953/10395 [2:42:18<56:10:00, 21.42s/it]                                                        {'loss': 1.0848, 'learning_rate': 1.9801224790755484e-05, 'epoch': 0.09}
  9%|▉         | 953/10395 [2:42:18<56:10:00, 21.42s/it]  9%|▉         | 954/10395 [2:42:26<45:26:47, 17.33s/it]                                                        {'loss': 0.9921, 'learning_rate': 1.9800606174463177e-05, 'epoch': 0.09}
  9%|▉         | 954/10395 [2:42:26<45:26:47, 17.33s/it]  9%|▉         | 955/10395 [2:42:34<38:06:03, 14.53s/it]                                                        {'loss': 0.9718, 'learning_rate': 1.979998660674897e-05, 'epoch': 0.09}
  9%|▉         | 955/10395 [2:42:34<38:06:03, 14.53s/it]  9%|▉         | 956/10395 [2:42:42<32:41:07, 12.47s/it]                                                        {'loss': 0.91, 'learning_rate': 1.9799366087673e-05, 'epoch': 0.09}
  9%|▉         | 956/10395 [2:42:42<32:41:07, 12.47s/it]  9%|▉         | 957/10395 [2:42:49<28:44:47, 10.97s/it]                                                        {'loss': 1.05, 'learning_rate': 1.979874461729552e-05, 'epoch': 0.09}
  9%|▉         | 957/10395 [2:42:49<28:44:47, 10.97s/it]  9%|▉         | 958/10395 [2:42:57<26:09:50,  9.98s/it]                                                        {'loss': 1.0241, 'learning_rate': 1.9798122195676845e-05, 'epoch': 0.09}
  9%|▉         | 958/10395 [2:42:57<26:09:50,  9.98s/it]  9%|▉         | 959/10395 [2:43:05<24:24:42,  9.31s/it]                                                        {'loss': 0.9296, 'learning_rate': 1.9797498822877407e-05, 'epoch': 0.09}
  9%|▉         | 959/10395 [2:43:05<24:24:42,  9.31s/it]  9%|▉         | 960/10395 [2:43:12<22:54:01,  8.74s/it]                                                        {'loss': 1.0637, 'learning_rate': 1.979687449895772e-05, 'epoch': 0.09}
  9%|▉         | 960/10395 [2:43:12<22:54:01,  8.74s/it]  9%|▉         | 961/10395 [2:43:19<21:40:38,  8.27s/it]                                                        {'loss': 1.0353, 'learning_rate': 1.9796249223978397e-05, 'epoch': 0.09}
  9%|▉         | 961/10395 [2:43:19<21:40:38,  8.27s/it]  9%|▉         | 962/10395 [2:43:26<20:50:17,  7.95s/it]                                                        {'loss': 1.1021, 'learning_rate': 1.9795622998000132e-05, 'epoch': 0.09}
  9%|▉         | 962/10395 [2:43:26<20:50:17,  7.95s/it]  9%|▉         | 963/10395 [2:43:44<28:38:09, 10.93s/it]                                                        {'loss': 0.3604, 'learning_rate': 1.979499582108372e-05, 'epoch': 0.09}
  9%|▉         | 963/10395 [2:43:44<28:38:09, 10.93s/it]  9%|▉         | 964/10395 [2:43:52<25:53:37,  9.88s/it]                                                        {'loss': 1.1156, 'learning_rate': 1.9794367693290045e-05, 'epoch': 0.09}
  9%|▉         | 964/10395 [2:43:52<25:53:37,  9.88s/it]  9%|▉         | 965/10395 [2:44:00<24:21:30,  9.30s/it]                                                        {'loss': 1.0075, 'learning_rate': 1.9793738614680084e-05, 'epoch': 0.09}
  9%|▉         | 965/10395 [2:44:00<24:21:30,  9.30s/it]  9%|▉         | 966/10395 [2:44:07<22:47:46,  8.70s/it]                                                        {'loss': 1.0266, 'learning_rate': 1.979310858531491e-05, 'epoch': 0.09}
  9%|▉         | 966/10395 [2:44:07<22:47:46,  8.70s/it]  9%|▉         | 967/10395 [2:44:15<22:06:25,  8.44s/it]                                                        {'loss': 1.0268, 'learning_rate': 1.979247760525568e-05, 'epoch': 0.09}
  9%|▉         | 967/10395 [2:44:15<22:06:25,  8.44s/it]  9%|▉         | 968/10395 [2:44:23<21:48:21,  8.33s/it]                                                        {'loss': 0.906, 'learning_rate': 1.979184567456365e-05, 'epoch': 0.09}
  9%|▉         | 968/10395 [2:44:23<21:48:21,  8.33s/it]  9%|▉         | 969/10395 [2:44:32<22:14:17,  8.49s/it]                                                        {'loss': 0.9435, 'learning_rate': 1.9791212793300173e-05, 'epoch': 0.09}
  9%|▉         | 969/10395 [2:44:32<22:14:17,  8.49s/it]  9%|▉         | 970/10395 [2:44:41<22:56:02,  8.76s/it]                                                        {'loss': 0.9399, 'learning_rate': 1.9790578961526675e-05, 'epoch': 0.09}
  9%|▉         | 970/10395 [2:44:41<22:56:02,  8.76s/it]  9%|▉         | 971/10395 [2:44:48<21:38:00,  8.26s/it]                                                        {'loss': 1.0778, 'learning_rate': 1.9789944179304697e-05, 'epoch': 0.09}
  9%|▉         | 971/10395 [2:44:48<21:38:00,  8.26s/it]  9%|▉         | 972/10395 [2:44:56<21:01:22,  8.03s/it]                                                        {'loss': 1.0228, 'learning_rate': 1.978930844669586e-05, 'epoch': 0.09}
  9%|▉         | 972/10395 [2:44:56<21:01:22,  8.03s/it]  9%|▉         | 973/10395 [2:45:03<20:37:41,  7.88s/it]                                                        {'loss': 1.0106, 'learning_rate': 1.9788671763761877e-05, 'epoch': 0.09}
  9%|▉         | 973/10395 [2:45:03<20:37:41,  7.88s/it]  9%|▉         | 974/10395 [2:45:11<20:17:09,  7.75s/it]                                                        {'loss': 1.0078, 'learning_rate': 1.978803413056456e-05, 'epoch': 0.09}
  9%|▉         | 974/10395 [2:45:11<20:17:09,  7.75s/it]  9%|▉         | 975/10395 [2:45:19<20:33:40,  7.86s/it]                                                        {'loss': 0.992, 'learning_rate': 1.9787395547165804e-05, 'epoch': 0.09}
  9%|▉         | 975/10395 [2:45:19<20:33:40,  7.86s/it]  9%|▉         | 976/10395 [2:45:28<21:26:41,  8.20s/it]                                                        {'loss': 0.9907, 'learning_rate': 1.9786756013627606e-05, 'epoch': 0.09}
  9%|▉         | 976/10395 [2:45:28<21:26:41,  8.20s/it]  9%|▉         | 977/10395 [2:45:35<20:51:48,  7.97s/it]                                                        {'loss': 1.0259, 'learning_rate': 1.978611553001205e-05, 'epoch': 0.09}
  9%|▉         | 977/10395 [2:45:35<20:51:48,  7.97s/it]  9%|▉         | 978/10395 [2:45:43<20:29:20,  7.83s/it]                                                        {'loss': 0.9984, 'learning_rate': 1.978547409638131e-05, 'epoch': 0.09}
  9%|▉         | 978/10395 [2:45:43<20:29:20,  7.83s/it]  9%|▉         | 979/10395 [2:45:51<20:48:12,  7.95s/it]                                                        {'loss': 0.9195, 'learning_rate': 1.978483171279765e-05, 'epoch': 0.09}
  9%|▉         | 979/10395 [2:45:51<20:48:12,  7.95s/it]  9%|▉         | 980/10395 [2:45:58<20:10:35,  7.71s/it]                                                        {'loss': 1.0841, 'learning_rate': 1.9784188379323444e-05, 'epoch': 0.09}
  9%|▉         | 980/10395 [2:45:58<20:10:35,  7.71s/it]  9%|▉         | 981/10395 [2:46:06<20:01:06,  7.66s/it]                                                        {'loss': 0.9401, 'learning_rate': 1.978354409602114e-05, 'epoch': 0.09}
  9%|▉         | 981/10395 [2:46:06<20:01:06,  7.66s/it]  9%|▉         | 982/10395 [2:46:13<20:00:27,  7.65s/it]                                                        {'loss': 0.9474, 'learning_rate': 1.978289886295328e-05, 'epoch': 0.09}
  9%|▉         | 982/10395 [2:46:13<20:00:27,  7.65s/it]  9%|▉         | 983/10395 [2:46:22<20:45:28,  7.94s/it]                                                        {'loss': 1.0486, 'learning_rate': 1.9782252680182504e-05, 'epoch': 0.09}
  9%|▉         | 983/10395 [2:46:22<20:45:28,  7.94s/it]  9%|▉         | 984/10395 [2:46:29<20:16:44,  7.76s/it]                                                        {'loss': 1.0183, 'learning_rate': 1.9781605547771546e-05, 'epoch': 0.09}
  9%|▉         | 984/10395 [2:46:29<20:16:44,  7.76s/it]  9%|▉         | 985/10395 [2:46:37<20:35:21,  7.88s/it]                                                        {'loss': 0.9396, 'learning_rate': 1.9780957465783223e-05, 'epoch': 0.09}
  9%|▉         | 985/10395 [2:46:37<20:35:21,  7.88s/it]  9%|▉         | 986/10395 [2:46:45<20:29:01,  7.84s/it]                                                        {'loss': 1.046, 'learning_rate': 1.978030843428045e-05, 'epoch': 0.09}
  9%|▉         | 986/10395 [2:46:45<20:29:01,  7.84s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2639 > 2048). Running this sequence through the model will result in indexing errors
  9%|▉         | 987/10395 [2:46:55<21:56:53,  8.40s/it]                                                        {'loss': 1.006, 'learning_rate': 1.9779658453326234e-05, 'epoch': 0.09}
  9%|▉         | 987/10395 [2:46:55<21:56:53,  8.40s/it] 10%|▉         | 988/10395 [2:47:02<21:14:52,  8.13s/it]                                                        {'loss': 1.0754, 'learning_rate': 1.977900752298368e-05, 'epoch': 0.1}
 10%|▉         | 988/10395 [2:47:02<21:14:52,  8.13s/it] 10%|▉         | 989/10395 [2:47:19<27:33:03, 10.54s/it]                                                        {'loss': 0.3538, 'learning_rate': 1.9778355643315967e-05, 'epoch': 0.1}
 10%|▉         | 989/10395 [2:47:19<27:33:03, 10.54s/it] 10%|▉         | 990/10395 [2:47:29<27:26:14, 10.50s/it]                                                        {'loss': 1.0129, 'learning_rate': 1.9777702814386387e-05, 'epoch': 0.1}
 10%|▉         | 990/10395 [2:47:29<27:26:14, 10.50s/it] 10%|▉         | 991/10395 [2:47:36<24:51:24,  9.52s/it]                                                        {'loss': 0.9946, 'learning_rate': 1.9777049036258314e-05, 'epoch': 0.1}
 10%|▉         | 991/10395 [2:47:36<24:51:24,  9.52s/it] 10%|▉         | 992/10395 [2:47:45<24:38:51,  9.44s/it]                                                        {'loss': 0.9751, 'learning_rate': 1.9776394308995213e-05, 'epoch': 0.1}
 10%|▉         | 992/10395 [2:47:45<24:38:51,  9.44s/it] 10%|▉         | 993/10395 [2:47:53<23:12:47,  8.89s/it]                                                        {'loss': 1.0485, 'learning_rate': 1.9775738632660647e-05, 'epoch': 0.1}
 10%|▉         | 993/10395 [2:47:53<23:12:47,  8.89s/it] 10%|▉         | 994/10395 [2:48:10<29:25:00, 11.26s/it]                                                        {'loss': 0.3488, 'learning_rate': 1.9775082007318264e-05, 'epoch': 0.1}
 10%|▉         | 994/10395 [2:48:10<29:25:00, 11.26s/it] 10%|▉         | 995/10395 [2:48:17<26:33:40, 10.17s/it]                                                        {'loss': 1.0524, 'learning_rate': 1.9774424433031805e-05, 'epoch': 0.1}
 10%|▉         | 995/10395 [2:48:17<26:33:40, 10.17s/it] 10%|▉         | 996/10395 [2:48:25<24:47:14,  9.49s/it]                                                        {'loss': 0.9891, 'learning_rate': 1.9773765909865114e-05, 'epoch': 0.1}
 10%|▉         | 996/10395 [2:48:25<24:47:14,  9.49s/it] 10%|▉         | 997/10395 [2:48:33<23:05:43,  8.85s/it]                                                        {'loss': 1.0091, 'learning_rate': 1.9773106437882114e-05, 'epoch': 0.1}
 10%|▉         | 997/10395 [2:48:33<23:05:43,  8.85s/it] 10%|▉         | 998/10395 [2:48:41<22:55:22,  8.78s/it]                                                        {'loss': 1.0104, 'learning_rate': 1.9772446017146827e-05, 'epoch': 0.1}
 10%|▉         | 998/10395 [2:48:41<22:55:22,  8.78s/it] 10%|▉         | 999/10395 [2:48:49<21:57:51,  8.42s/it]                                                        {'loss': 0.977, 'learning_rate': 1.9771784647723363e-05, 'epoch': 0.1}
 10%|▉         | 999/10395 [2:48:49<21:57:51,  8.42s/it] 10%|▉         | 1000/10395 [2:48:56<21:15:52,  8.15s/it]                                                         {'loss': 1.0692, 'learning_rate': 1.9771122329675928e-05, 'epoch': 0.1}
 10%|▉         | 1000/10395 [2:48:56<21:15:52,  8.15s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 10%|▉         | 1001/10395 [2:50:36<92:27:05, 35.43s/it]                                                         {'loss': 0.9954, 'learning_rate': 1.977045906306882e-05, 'epoch': 0.1}
 10%|▉         | 1001/10395 [2:50:36<92:27:05, 35.43s/it] 10%|▉         | 1002/10395 [2:50:44<71:33:15, 27.42s/it]                                                         {'loss': 0.9604, 'learning_rate': 1.9769794847966427e-05, 'epoch': 0.1}
 10%|▉         | 1002/10395 [2:50:44<71:33:15, 27.42s/it] 10%|▉         | 1003/10395 [2:50:53<57:13:11, 21.93s/it]                                                         {'loss': 0.9723, 'learning_rate': 1.9769129684433226e-05, 'epoch': 0.1}
 10%|▉         | 1003/10395 [2:50:53<57:13:11, 21.93s/it] 10%|▉         | 1004/10395 [2:51:02<46:34:43, 17.86s/it]                                                         {'loss': 0.9508, 'learning_rate': 1.9768463572533792e-05, 'epoch': 0.1}
 10%|▉         | 1004/10395 [2:51:02<46:34:43, 17.86s/it] 10%|▉         | 1005/10395 [2:51:09<38:25:32, 14.73s/it]                                                         {'loss': 1.0999, 'learning_rate': 1.976779651233279e-05, 'epoch': 0.1}
 10%|▉         | 1005/10395 [2:51:10<38:25:32, 14.73s/it] 10%|▉         | 1006/10395 [2:51:17<32:56:40, 12.63s/it]                                                         {'loss': 1.0127, 'learning_rate': 1.9767128503894976e-05, 'epoch': 0.1}
 10%|▉         | 1006/10395 [2:51:17<32:56:40, 12.63s/it] 10%|▉         | 1007/10395 [2:51:24<28:38:11, 10.98s/it]                                                         {'loss': 1.0062, 'learning_rate': 1.9766459547285198e-05, 'epoch': 0.1}
 10%|▉         | 1007/10395 [2:51:24<28:38:11, 10.98s/it] 10%|▉         | 1008/10395 [2:51:32<26:37:54, 10.21s/it]                                                         {'loss': 1.0157, 'learning_rate': 1.97657896425684e-05, 'epoch': 0.1}
 10%|▉         | 1008/10395 [2:51:32<26:37:54, 10.21s/it] 10%|▉         | 1009/10395 [2:51:50<32:14:03, 12.36s/it]                                                         {'loss': 0.3713, 'learning_rate': 1.9765118789809615e-05, 'epoch': 0.1}
 10%|▉         | 1009/10395 [2:51:50<32:14:03, 12.36s/it] 10%|▉         | 1010/10395 [2:51:57<28:31:21, 10.94s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.976444698907396e-05, 'epoch': 0.1}
 10%|▉         | 1010/10395 [2:51:57<28:31:21, 10.94s/it] 10%|▉         | 1011/10395 [2:52:06<26:24:11, 10.13s/it]                                                         {'loss': 0.9763, 'learning_rate': 1.9763774240426664e-05, 'epoch': 0.1}
 10%|▉         | 1011/10395 [2:52:06<26:24:11, 10.13s/it] 10%|▉         | 1012/10395 [2:52:14<24:34:39,  9.43s/it]                                                         {'loss': 0.9549, 'learning_rate': 1.9763100543933026e-05, 'epoch': 0.1}
 10%|▉         | 1012/10395 [2:52:14<24:34:39,  9.43s/it] 10%|▉         | 1013/10395 [2:52:21<22:49:35,  8.76s/it]                                                         {'loss': 1.0991, 'learning_rate': 1.976242589965845e-05, 'epoch': 0.1}
 10%|▉         | 1013/10395 [2:52:21<22:49:35,  8.76s/it] 10%|▉         | 1014/10395 [2:52:29<22:11:17,  8.51s/it]                                                         {'loss': 0.9376, 'learning_rate': 1.9761750307668436e-05, 'epoch': 0.1}
 10%|▉         | 1014/10395 [2:52:29<22:11:17,  8.51s/it] 10%|▉         | 1015/10395 [2:52:39<23:41:09,  9.09s/it]                                                         {'loss': 0.8728, 'learning_rate': 1.976107376802856e-05, 'epoch': 0.1}
 10%|▉         | 1015/10395 [2:52:39<23:41:09,  9.09s/it] 10%|▉         | 1016/10395 [2:52:47<22:28:55,  8.63s/it]                                                         {'loss': 1.0861, 'learning_rate': 1.97603962808045e-05, 'epoch': 0.1}
 10%|▉         | 1016/10395 [2:52:47<22:28:55,  8.63s/it] 10%|▉         | 1017/10395 [2:52:55<22:34:42,  8.67s/it]                                                         {'loss': 0.9925, 'learning_rate': 1.975971784606203e-05, 'epoch': 0.1}
 10%|▉         | 1017/10395 [2:52:55<22:34:42,  8.67s/it] 10%|▉         | 1018/10395 [2:53:03<21:38:16,  8.31s/it]                                                         {'loss': 0.9956, 'learning_rate': 1.9759038463867008e-05, 'epoch': 0.1}
 10%|▉         | 1018/10395 [2:53:03<21:38:16,  8.31s/it] 10%|▉         | 1019/10395 [2:53:10<20:59:51,  8.06s/it]                                                         {'loss': 0.986, 'learning_rate': 1.9758358134285384e-05, 'epoch': 0.1}
 10%|▉         | 1019/10395 [2:53:10<20:59:51,  8.06s/it] 10%|▉         | 1020/10395 [2:53:18<20:39:22,  7.93s/it]                                                         {'loss': 0.9792, 'learning_rate': 1.975767685738321e-05, 'epoch': 0.1}
 10%|▉         | 1020/10395 [2:53:18<20:39:22,  7.93s/it] 10%|▉         | 1021/10395 [2:53:26<20:35:59,  7.91s/it]                                                         {'loss': 1.0674, 'learning_rate': 1.975699463322662e-05, 'epoch': 0.1}
 10%|▉         | 1021/10395 [2:53:26<20:35:59,  7.91s/it] 10%|▉         | 1022/10395 [2:53:43<27:54:04, 10.72s/it]                                                         {'loss': 0.3395, 'learning_rate': 1.9756311461881838e-05, 'epoch': 0.1}
 10%|▉         | 1022/10395 [2:53:43<27:54:04, 10.72s/it] 10%|▉         | 1023/10395 [2:53:51<25:26:37,  9.77s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.975562734341519e-05, 'epoch': 0.1}
 10%|▉         | 1023/10395 [2:53:51<25:26:37,  9.77s/it] 10%|▉         | 1024/10395 [2:53:58<23:22:15,  8.98s/it]                                                         {'loss': 1.0655, 'learning_rate': 1.9754942277893083e-05, 'epoch': 0.1}
 10%|▉         | 1024/10395 [2:53:58<23:22:15,  8.98s/it] 10%|▉         | 1025/10395 [2:54:05<22:17:09,  8.56s/it]                                                         {'loss': 1.0106, 'learning_rate': 1.9754256265382034e-05, 'epoch': 0.1}
 10%|▉         | 1025/10395 [2:54:05<22:17:09,  8.56s/it] 10%|▉         | 1026/10395 [2:54:13<21:10:13,  8.13s/it]                                                         {'loss': 0.9832, 'learning_rate': 1.9753569305948624e-05, 'epoch': 0.1}
 10%|▉         | 1026/10395 [2:54:13<21:10:13,  8.13s/it] 10%|▉         | 1027/10395 [2:54:20<20:58:18,  8.06s/it]                                                         {'loss': 0.9942, 'learning_rate': 1.9752881399659553e-05, 'epoch': 0.1}
 10%|▉         | 1027/10395 [2:54:20<20:58:18,  8.06s/it] 10%|▉         | 1028/10395 [2:54:29<21:13:31,  8.16s/it]                                                         {'loss': 1.002, 'learning_rate': 1.9752192546581598e-05, 'epoch': 0.1}
 10%|▉         | 1028/10395 [2:54:29<21:13:31,  8.16s/it] 10%|▉         | 1029/10395 [2:54:37<20:58:55,  8.06s/it]                                                         {'loss': 1.0532, 'learning_rate': 1.975150274678163e-05, 'epoch': 0.1}
 10%|▉         | 1029/10395 [2:54:37<20:58:55,  8.06s/it] 10%|▉         | 1030/10395 [2:54:44<20:26:50,  7.86s/it]                                                         {'loss': 1.008, 'learning_rate': 1.9750812000326616e-05, 'epoch': 0.1}
 10%|▉         | 1030/10395 [2:54:44<20:26:50,  7.86s/it] 10%|▉         | 1031/10395 [2:54:52<20:08:55,  7.75s/it]                                                         {'loss': 0.9805, 'learning_rate': 1.9750120307283608e-05, 'epoch': 0.1}
 10%|▉         | 1031/10395 [2:54:52<20:08:55,  7.75s/it] 10%|▉         | 1032/10395 [2:55:00<20:47:49,  8.00s/it]                                                         {'loss': 1.041, 'learning_rate': 1.9749427667719757e-05, 'epoch': 0.1}
 10%|▉         | 1032/10395 [2:55:00<20:47:49,  8.00s/it] 10%|▉         | 1033/10395 [2:55:08<21:06:39,  8.12s/it]                                                         {'loss': 0.944, 'learning_rate': 1.9748734081702304e-05, 'epoch': 0.1}
 10%|▉         | 1033/10395 [2:55:08<21:06:39,  8.12s/it] 10%|▉         | 1034/10395 [2:55:25<27:43:42, 10.66s/it]                                                         {'loss': 0.3531, 'learning_rate': 1.974803954929858e-05, 'epoch': 0.1}
 10%|▉         | 1034/10395 [2:55:25<27:43:42, 10.66s/it] 10%|▉         | 1035/10395 [2:55:33<25:15:18,  9.71s/it]                                                         {'loss': 1.058, 'learning_rate': 1.9747344070576005e-05, 'epoch': 0.1}
 10%|▉         | 1035/10395 [2:55:33<25:15:18,  9.71s/it] 10%|▉         | 1036/10395 [2:55:40<23:28:45,  9.03s/it]                                                         {'loss': 1.0082, 'learning_rate': 1.9746647645602102e-05, 'epoch': 0.1}
 10%|▉         | 1036/10395 [2:55:40<23:28:45,  9.03s/it] 10%|▉         | 1037/10395 [2:55:48<22:26:44,  8.63s/it]                                                         {'loss': 0.9559, 'learning_rate': 1.9745950274444472e-05, 'epoch': 0.1}
 10%|▉         | 1037/10395 [2:55:48<22:26:44,  8.63s/it] 10%|▉         | 1038/10395 [2:55:55<21:41:32,  8.35s/it]                                                         {'loss': 1.0463, 'learning_rate': 1.9745251957170817e-05, 'epoch': 0.1}
 10%|▉         | 1038/10395 [2:55:55<21:41:32,  8.35s/it] 10%|▉         | 1039/10395 [2:56:03<20:50:21,  8.02s/it]                                                         {'loss': 0.9175, 'learning_rate': 1.9744552693848925e-05, 'epoch': 0.1}
 10%|▉         | 1039/10395 [2:56:03<20:50:21,  8.02s/it] 10%|█         | 1040/10395 [2:56:11<20:51:39,  8.03s/it]                                                         {'loss': 1.011, 'learning_rate': 1.974385248454669e-05, 'epoch': 0.1}
 10%|█         | 1040/10395 [2:56:11<20:51:39,  8.03s/it] 10%|█         | 1041/10395 [2:56:18<20:23:19,  7.85s/it]                                                         {'loss': 1.0558, 'learning_rate': 1.9743151329332072e-05, 'epoch': 0.1}
 10%|█         | 1041/10395 [2:56:18<20:23:19,  7.85s/it] 10%|█         | 1042/10395 [2:56:26<20:25:17,  7.86s/it]                                                         {'loss': 1.0577, 'learning_rate': 1.9742449228273143e-05, 'epoch': 0.1}
 10%|█         | 1042/10395 [2:56:26<20:25:17,  7.86s/it] 10%|█         | 1043/10395 [2:56:34<20:14:16,  7.79s/it]                                                         {'loss': 0.9921, 'learning_rate': 1.9741746181438063e-05, 'epoch': 0.1}
 10%|█         | 1043/10395 [2:56:34<20:14:16,  7.79s/it] 10%|█         | 1044/10395 [2:56:42<20:22:40,  7.85s/it]                                                         {'loss': 1.0462, 'learning_rate': 1.9741042188895084e-05, 'epoch': 0.1}
 10%|█         | 1044/10395 [2:56:42<20:22:40,  7.85s/it] 10%|█         | 1045/10395 [2:56:49<19:54:07,  7.66s/it]                                                         {'loss': 0.9585, 'learning_rate': 1.9740337250712546e-05, 'epoch': 0.1}
 10%|█         | 1045/10395 [2:56:49<19:54:07,  7.66s/it] 10%|█         | 1046/10395 [2:56:56<19:41:22,  7.58s/it]                                                         {'loss': 0.9698, 'learning_rate': 1.973963136695888e-05, 'epoch': 0.1}
 10%|█         | 1046/10395 [2:56:56<19:41:22,  7.58s/it] 10%|█         | 1047/10395 [2:57:04<20:06:50,  7.75s/it]                                                         {'loss': 0.9668, 'learning_rate': 1.9738924537702618e-05, 'epoch': 0.1}
 10%|█         | 1047/10395 [2:57:04<20:06:50,  7.75s/it] 10%|█         | 1048/10395 [2:57:12<19:56:57,  7.68s/it]                                                         {'loss': 1.0385, 'learning_rate': 1.9738216763012372e-05, 'epoch': 0.1}
 10%|█         | 1048/10395 [2:57:12<19:56:57,  7.68s/it] 10%|█         | 1049/10395 [2:57:20<20:15:18,  7.80s/it]                                                         {'loss': 0.97, 'learning_rate': 1.9737508042956853e-05, 'epoch': 0.1}
 10%|█         | 1049/10395 [2:57:20<20:15:18,  7.80s/it] 10%|█         | 1050/10395 [2:57:28<20:06:09,  7.74s/it]                                                         {'loss': 0.9315, 'learning_rate': 1.9736798377604864e-05, 'epoch': 0.1}
 10%|█         | 1050/10395 [2:57:28<20:06:09,  7.74s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 10%|█         | 1051/10395 [2:59:20<101:42:26, 39.19s/it]                                                          {'loss': 0.3412, 'learning_rate': 1.9736087767025295e-05, 'epoch': 0.1}
 10%|█         | 1051/10395 [2:59:20<101:42:26, 39.19s/it] 10%|█         | 1052/10395 [2:59:28<77:12:49, 29.75s/it]                                                          {'loss': 1.0215, 'learning_rate': 1.9735376211287132e-05, 'epoch': 0.1}
 10%|█         | 1052/10395 [2:59:28<77:12:49, 29.75s/it] 10%|█         | 1053/10395 [2:59:36<60:00:59, 23.13s/it]                                                         {'loss': 0.932, 'learning_rate': 1.9734663710459454e-05, 'epoch': 0.1}
 10%|█         | 1053/10395 [2:59:36<60:00:59, 23.13s/it] 10%|█         | 1054/10395 [2:59:43<47:49:59, 18.43s/it]                                                         {'loss': 1.0195, 'learning_rate': 1.973395026461142e-05, 'epoch': 0.1}
 10%|█         | 1054/10395 [2:59:43<47:49:59, 18.43s/it] 10%|█         | 1055/10395 [2:59:51<39:32:00, 15.24s/it]                                                         {'loss': 1.0469, 'learning_rate': 1.9733235873812302e-05, 'epoch': 0.1}
 10%|█         | 1055/10395 [2:59:51<39:32:00, 15.24s/it] 10%|█         | 1056/10395 [2:59:59<33:39:37, 12.98s/it]                                                         {'loss': 0.9932, 'learning_rate': 1.9732520538131442e-05, 'epoch': 0.1}
 10%|█         | 1056/10395 [2:59:59<33:39:37, 12.98s/it] 10%|█         | 1057/10395 [3:00:06<29:20:00, 11.31s/it]                                                         {'loss': 0.9667, 'learning_rate': 1.9731804257638285e-05, 'epoch': 0.1}
 10%|█         | 1057/10395 [3:00:06<29:20:00, 11.31s/it] 10%|█         | 1058/10395 [3:00:14<26:28:27, 10.21s/it]                                                         {'loss': 0.9205, 'learning_rate': 1.973108703240237e-05, 'epoch': 0.1}
 10%|█         | 1058/10395 [3:00:14<26:28:27, 10.21s/it] 10%|█         | 1059/10395 [3:00:21<24:16:10,  9.36s/it]                                                         {'loss': 1.0211, 'learning_rate': 1.973036886249332e-05, 'epoch': 0.1}
 10%|█         | 1059/10395 [3:00:21<24:16:10,  9.36s/it] 10%|█         | 1060/10395 [3:00:29<23:05:35,  8.91s/it]                                                         {'loss': 1.0997, 'learning_rate': 1.9729649747980856e-05, 'epoch': 0.1}
 10%|█         | 1060/10395 [3:00:29<23:05:35,  8.91s/it] 10%|█         | 1061/10395 [3:00:46<29:12:28, 11.27s/it]                                                         {'loss': 0.3509, 'learning_rate': 1.972892968893479e-05, 'epoch': 0.1}
 10%|█         | 1061/10395 [3:00:46<29:12:28, 11.27s/it] 10%|█         | 1062/10395 [3:00:54<27:08:55, 10.47s/it]                                                         {'loss': 0.8924, 'learning_rate': 1.972820868542501e-05, 'epoch': 0.1}
 10%|█         | 1062/10395 [3:00:54<27:08:55, 10.47s/it] 10%|█         | 1063/10395 [3:01:02<25:14:41,  9.74s/it]                                                         {'loss': 0.9695, 'learning_rate': 1.972748673752153e-05, 'epoch': 0.1}
 10%|█         | 1063/10395 [3:01:02<25:14:41,  9.74s/it] 10%|█         | 1064/10395 [3:01:11<24:12:35,  9.34s/it]                                                         {'loss': 0.989, 'learning_rate': 1.9726763845294423e-05, 'epoch': 0.1}
 10%|█         | 1064/10395 [3:01:11<24:12:35,  9.34s/it] 10%|█         | 1065/10395 [3:01:19<23:21:08,  9.01s/it]                                                         {'loss': 0.9665, 'learning_rate': 1.9726040008813866e-05, 'epoch': 0.1}
 10%|█         | 1065/10395 [3:01:19<23:21:08,  9.01s/it] 10%|█         | 1066/10395 [3:01:26<22:08:50,  8.55s/it]                                                         {'loss': 1.0069, 'learning_rate': 1.9725315228150134e-05, 'epoch': 0.1}
 10%|█         | 1066/10395 [3:01:26<22:08:50,  8.55s/it] 10%|█         | 1067/10395 [3:01:34<21:37:34,  8.35s/it]                                                         {'loss': 0.9869, 'learning_rate': 1.9724589503373575e-05, 'epoch': 0.1}
 10%|█         | 1067/10395 [3:01:34<21:37:34,  8.35s/it] 10%|█         | 1068/10395 [3:01:43<21:34:08,  8.33s/it]                                                         {'loss': 1.0071, 'learning_rate': 1.9723862834554656e-05, 'epoch': 0.1}
 10%|█         | 1068/10395 [3:01:43<21:34:08,  8.33s/it] 10%|█         | 1069/10395 [3:01:50<20:58:49,  8.10s/it]                                                         {'loss': 1.0777, 'learning_rate': 1.972313522176391e-05, 'epoch': 0.1}
 10%|█         | 1069/10395 [3:01:50<20:58:49,  8.10s/it] 10%|█         | 1070/10395 [3:01:58<20:56:28,  8.08s/it]                                                         {'loss': 0.9786, 'learning_rate': 1.9722406665071973e-05, 'epoch': 0.1}
 10%|█         | 1070/10395 [3:01:58<20:56:28,  8.08s/it] 10%|█         | 1071/10395 [3:02:06<20:35:36,  7.95s/it]                                                         {'loss': 1.067, 'learning_rate': 1.972167716454958e-05, 'epoch': 0.1}
 10%|█         | 1071/10395 [3:02:06<20:35:36,  7.95s/it] 10%|█         | 1072/10395 [3:02:14<20:51:03,  8.05s/it]                                                         {'loss': 1.0596, 'learning_rate': 1.9720946720267537e-05, 'epoch': 0.1}
 10%|█         | 1072/10395 [3:02:14<20:51:03,  8.05s/it] 10%|█         | 1073/10395 [3:02:22<21:06:39,  8.15s/it]                                                         {'loss': 0.9486, 'learning_rate': 1.972021533229676e-05, 'epoch': 0.1}
 10%|█         | 1073/10395 [3:02:22<21:06:39,  8.15s/it] 10%|█         | 1074/10395 [3:02:30<20:33:24,  7.94s/it]                                                         {'loss': 1.0009, 'learning_rate': 1.9719483000708255e-05, 'epoch': 0.1}
 10%|█         | 1074/10395 [3:02:30<20:33:24,  7.94s/it] 10%|█         | 1075/10395 [3:02:38<20:36:35,  7.96s/it]                                                         {'loss': 1.0104, 'learning_rate': 1.971874972557311e-05, 'epoch': 0.1}
 10%|█         | 1075/10395 [3:02:38<20:36:35,  7.96s/it] 10%|█         | 1076/10395 [3:02:46<20:32:06,  7.93s/it]                                                         {'loss': 1.0463, 'learning_rate': 1.9718015506962508e-05, 'epoch': 0.1}
 10%|█         | 1076/10395 [3:02:46<20:32:06,  7.93s/it] 10%|█         | 1077/10395 [3:02:54<20:59:03,  8.11s/it]                                                         {'loss': 0.9495, 'learning_rate': 1.971728034494773e-05, 'epoch': 0.1}
 10%|█         | 1077/10395 [3:02:54<20:59:03,  8.11s/it] 10%|█         | 1078/10395 [3:03:02<20:44:31,  8.01s/it]                                                         {'loss': 1.0036, 'learning_rate': 1.9716544239600142e-05, 'epoch': 0.1}
 10%|█         | 1078/10395 [3:03:02<20:44:31,  8.01s/it] 10%|█         | 1079/10395 [3:03:19<28:00:58, 10.83s/it]                                                         {'loss': 0.3802, 'learning_rate': 1.9715807190991202e-05, 'epoch': 0.1}
 10%|█         | 1079/10395 [3:03:19<28:00:58, 10.83s/it] 10%|█         | 1080/10395 [3:03:37<32:57:00, 12.73s/it]                                                         {'loss': 0.3491, 'learning_rate': 1.9715069199192465e-05, 'epoch': 0.1}
 10%|█         | 1080/10395 [3:03:37<32:57:00, 12.73s/it] 10%|█         | 1081/10395 [3:03:45<29:44:30, 11.50s/it]                                                         {'loss': 1.0246, 'learning_rate': 1.971433026427557e-05, 'epoch': 0.1}
 10%|█         | 1081/10395 [3:03:45<29:44:30, 11.50s/it] 10%|█         | 1082/10395 [3:03:54<27:24:46, 10.60s/it]                                                         {'loss': 0.9183, 'learning_rate': 1.9713590386312252e-05, 'epoch': 0.1}
 10%|█         | 1082/10395 [3:03:54<27:24:46, 10.60s/it] 10%|█         | 1083/10395 [3:04:01<25:03:04,  9.68s/it]                                                         {'loss': 0.9803, 'learning_rate': 1.9712849565374336e-05, 'epoch': 0.1}
 10%|█         | 1083/10395 [3:04:01<25:03:04,  9.68s/it] 10%|█         | 1084/10395 [3:04:09<23:19:32,  9.02s/it]                                                         {'loss': 1.0785, 'learning_rate': 1.9712107801533745e-05, 'epoch': 0.1}
 10%|█         | 1084/10395 [3:04:09<23:19:32,  9.02s/it] 10%|█         | 1085/10395 [3:04:16<22:02:21,  8.52s/it]                                                         {'loss': 0.9889, 'learning_rate': 1.971136509486248e-05, 'epoch': 0.1}
 10%|█         | 1085/10395 [3:04:16<22:02:21,  8.52s/it] 10%|█         | 1086/10395 [3:04:23<21:04:44,  8.15s/it]                                                         {'loss': 0.9644, 'learning_rate': 1.9710621445432646e-05, 'epoch': 0.1}
 10%|█         | 1086/10395 [3:04:23<21:04:44,  8.15s/it] 10%|█         | 1087/10395 [3:04:31<20:47:43,  8.04s/it]                                                         {'loss': 1.062, 'learning_rate': 1.9709876853316434e-05, 'epoch': 0.1}
 10%|█         | 1087/10395 [3:04:31<20:47:43,  8.04s/it] 10%|█         | 1088/10395 [3:04:38<20:09:40,  7.80s/it]                                                         {'loss': 1.0488, 'learning_rate': 1.9709131318586126e-05, 'epoch': 0.1}
 10%|█         | 1088/10395 [3:04:38<20:09:40,  7.80s/it] 10%|█         | 1089/10395 [3:04:46<20:00:06,  7.74s/it]                                                         {'loss': 1.0151, 'learning_rate': 1.9708384841314098e-05, 'epoch': 0.1}
 10%|█         | 1089/10395 [3:04:46<20:00:06,  7.74s/it] 10%|█         | 1090/10395 [3:04:53<19:29:52,  7.54s/it]                                                         {'loss': 0.9833, 'learning_rate': 1.970763742157282e-05, 'epoch': 0.1}
 10%|█         | 1090/10395 [3:04:53<19:29:52,  7.54s/it] 10%|█         | 1091/10395 [3:05:01<20:03:21,  7.76s/it]                                                         {'loss': 1.0125, 'learning_rate': 1.9706889059434844e-05, 'epoch': 0.1}
 10%|█         | 1091/10395 [3:05:01<20:03:21,  7.76s/it] 11%|█         | 1092/10395 [3:05:10<20:25:44,  7.91s/it]                                                         {'loss': 0.9755, 'learning_rate': 1.970613975497282e-05, 'epoch': 0.11}
 11%|█         | 1092/10395 [3:05:10<20:25:44,  7.91s/it] 11%|█         | 1093/10395 [3:05:27<27:23:03, 10.60s/it]                                                         {'loss': 0.3765, 'learning_rate': 1.970538950825949e-05, 'epoch': 0.11}
 11%|█         | 1093/10395 [3:05:27<27:23:03, 10.60s/it] 11%|█         | 1094/10395 [3:05:35<25:39:57,  9.93s/it]                                                         {'loss': 1.0084, 'learning_rate': 1.970463831936769e-05, 'epoch': 0.11}
 11%|█         | 1094/10395 [3:05:35<25:39:57,  9.93s/it] 11%|█         | 1095/10395 [3:05:53<31:38:08, 12.25s/it]                                                         {'loss': 0.4068, 'learning_rate': 1.970388618837034e-05, 'epoch': 0.11}
 11%|█         | 1095/10395 [3:05:53<31:38:08, 12.25s/it] 11%|█         | 1096/10395 [3:06:00<27:55:49, 10.81s/it]                                                         {'loss': 1.0553, 'learning_rate': 1.9703133115340458e-05, 'epoch': 0.11}
 11%|█         | 1096/10395 [3:06:00<27:55:49, 10.81s/it] 11%|█         | 1097/10395 [3:06:08<25:29:02,  9.87s/it]                                                         {'loss': 0.9888, 'learning_rate': 1.9702379100351146e-05, 'epoch': 0.11}
 11%|█         | 1097/10395 [3:06:08<25:29:02,  9.87s/it] 11%|█         | 1098/10395 [3:06:15<23:52:25,  9.24s/it]                                                         {'loss': 0.9857, 'learning_rate': 1.9701624143475608e-05, 'epoch': 0.11}
 11%|█         | 1098/10395 [3:06:15<23:52:25,  9.24s/it] 11%|█         | 1099/10395 [3:06:23<22:52:47,  8.86s/it]                                                         {'loss': 0.9695, 'learning_rate': 1.9700868244787127e-05, 'epoch': 0.11}
 11%|█         | 1099/10395 [3:06:23<22:52:47,  8.86s/it] 11%|█         | 1100/10395 [3:06:31<21:41:28,  8.40s/it]                                                         {'loss': 1.0562, 'learning_rate': 1.970011140435909e-05, 'epoch': 0.11}
 11%|█         | 1100/10395 [3:06:31<21:41:28,  8.40s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 1101/10395 [3:08:11<93:06:51, 36.07s/it]                                                         {'loss': 1.0096, 'learning_rate': 1.9699353622264967e-05, 'epoch': 0.11}
 11%|█         | 1101/10395 [3:08:11<93:06:51, 36.07s/it] 11%|█         | 1102/10395 [3:08:19<71:05:30, 27.54s/it]                                                         {'loss': 0.9592, 'learning_rate': 1.969859489857832e-05, 'epoch': 0.11}
 11%|█         | 1102/10395 [3:08:19<71:05:30, 27.54s/it] 11%|█         | 1103/10395 [3:08:27<56:00:51, 21.70s/it]                                                         {'loss': 0.9459, 'learning_rate': 1.969783523337281e-05, 'epoch': 0.11}
 11%|█         | 1103/10395 [3:08:27<56:00:51, 21.70s/it] 11%|█         | 1104/10395 [3:08:35<45:16:53, 17.55s/it]                                                         {'loss': 0.9452, 'learning_rate': 1.969707462672218e-05, 'epoch': 0.11}
 11%|█         | 1104/10395 [3:08:35<45:16:53, 17.55s/it] 11%|█         | 1105/10395 [3:08:42<37:14:36, 14.43s/it]                                                         {'loss': 1.0282, 'learning_rate': 1.9696313078700262e-05, 'epoch': 0.11}
 11%|█         | 1105/10395 [3:08:42<37:14:36, 14.43s/it] 11%|█         | 1106/10395 [3:08:49<31:45:09, 12.31s/it]                                                         {'loss': 1.0031, 'learning_rate': 1.9695550589380993e-05, 'epoch': 0.11}
 11%|█         | 1106/10395 [3:08:49<31:45:09, 12.31s/it] 11%|█         | 1107/10395 [3:08:57<28:16:23, 10.96s/it]                                                         {'loss': 0.9611, 'learning_rate': 1.9694787158838394e-05, 'epoch': 0.11}
 11%|█         | 1107/10395 [3:08:57<28:16:23, 10.96s/it] 11%|█         | 1108/10395 [3:09:05<25:49:24, 10.01s/it]                                                         {'loss': 1.0356, 'learning_rate': 1.9694022787146578e-05, 'epoch': 0.11}
 11%|█         | 1108/10395 [3:09:05<25:49:24, 10.01s/it] 11%|█         | 1109/10395 [3:09:15<25:23:19,  9.84s/it]                                                         {'loss': 0.9812, 'learning_rate': 1.969325747437974e-05, 'epoch': 0.11}
 11%|█         | 1109/10395 [3:09:15<25:23:19,  9.84s/it] 11%|█         | 1110/10395 [3:09:22<23:41:09,  9.18s/it]                                                         {'loss': 0.9784, 'learning_rate': 1.9692491220612188e-05, 'epoch': 0.11}
 11%|█         | 1110/10395 [3:09:22<23:41:09,  9.18s/it] 11%|█         | 1111/10395 [3:09:30<22:20:11,  8.66s/it]                                                         {'loss': 0.9677, 'learning_rate': 1.9691724025918296e-05, 'epoch': 0.11}
 11%|█         | 1111/10395 [3:09:30<22:20:11,  8.66s/it] 11%|█         | 1112/10395 [3:09:39<23:00:47,  8.92s/it]                                                         {'loss': 0.9859, 'learning_rate': 1.969095589037255e-05, 'epoch': 0.11}
 11%|█         | 1112/10395 [3:09:39<23:00:47,  8.92s/it] 11%|█         | 1113/10395 [3:09:47<22:05:32,  8.57s/it]                                                         {'loss': 0.9394, 'learning_rate': 1.9690186814049513e-05, 'epoch': 0.11}
 11%|█         | 1113/10395 [3:09:47<22:05:32,  8.57s/it] 11%|█         | 1114/10395 [3:09:55<21:23:36,  8.30s/it]                                                         {'loss': 1.0401, 'learning_rate': 1.968941679702385e-05, 'epoch': 0.11}
 11%|█         | 1114/10395 [3:09:55<21:23:36,  8.30s/it] 11%|█         | 1115/10395 [3:10:02<20:33:33,  7.98s/it]                                                         {'loss': 1.0719, 'learning_rate': 1.9688645839370307e-05, 'epoch': 0.11}
 11%|█         | 1115/10395 [3:10:02<20:33:33,  7.98s/it] 11%|█         | 1116/10395 [3:10:10<20:54:34,  8.11s/it]                                                         {'loss': 1.0701, 'learning_rate': 1.9687873941163737e-05, 'epoch': 0.11}
 11%|█         | 1116/10395 [3:10:10<20:54:34,  8.11s/it] 11%|█         | 1117/10395 [3:10:17<20:04:28,  7.79s/it]                                                         {'loss': 1.0267, 'learning_rate': 1.9687101102479063e-05, 'epoch': 0.11}
 11%|█         | 1117/10395 [3:10:17<20:04:28,  7.79s/it] 11%|█         | 1118/10395 [3:10:25<20:14:47,  7.86s/it]                                                         {'loss': 0.9383, 'learning_rate': 1.9686327323391317e-05, 'epoch': 0.11}
 11%|█         | 1118/10395 [3:10:25<20:14:47,  7.86s/it] 11%|█         | 1119/10395 [3:10:35<21:30:13,  8.35s/it]                                                         {'loss': 0.9511, 'learning_rate': 1.9685552603975612e-05, 'epoch': 0.11}
 11%|█         | 1119/10395 [3:10:35<21:30:13,  8.35s/it] 11%|█         | 1120/10395 [3:10:42<20:39:49,  8.02s/it]                                                         {'loss': 1.0619, 'learning_rate': 1.9684776944307162e-05, 'epoch': 0.11}
 11%|█         | 1120/10395 [3:10:42<20:39:49,  8.02s/it] 11%|█         | 1121/10395 [3:10:59<27:21:03, 10.62s/it]                                                         {'loss': 0.3985, 'learning_rate': 1.968400034446126e-05, 'epoch': 0.11}
 11%|█         | 1121/10395 [3:10:59<27:21:03, 10.62s/it] 11%|█         | 1122/10395 [3:11:07<25:21:56,  9.85s/it]                                                         {'loss': 0.8639, 'learning_rate': 1.96832228045133e-05, 'epoch': 0.11}
 11%|█         | 1122/10395 [3:11:07<25:21:56,  9.85s/it] 11%|█         | 1123/10395 [3:11:14<23:28:27,  9.11s/it]                                                         {'loss': 1.018, 'learning_rate': 1.9682444324538766e-05, 'epoch': 0.11}
 11%|█         | 1123/10395 [3:11:14<23:28:27,  9.11s/it] 11%|█         | 1124/10395 [3:11:21<21:58:38,  8.53s/it]                                                         {'loss': 0.9723, 'learning_rate': 1.9681664904613224e-05, 'epoch': 0.11}
 11%|█         | 1124/10395 [3:11:21<21:58:38,  8.53s/it] 11%|█         | 1125/10395 [3:11:29<21:09:29,  8.22s/it]                                                         {'loss': 0.9719, 'learning_rate': 1.9680884544812347e-05, 'epoch': 0.11}
 11%|█         | 1125/10395 [3:11:29<21:09:29,  8.22s/it] 11%|█         | 1126/10395 [3:11:38<21:37:49,  8.40s/it]                                                         {'loss': 0.9841, 'learning_rate': 1.9680103245211884e-05, 'epoch': 0.11}
 11%|█         | 1126/10395 [3:11:38<21:37:49,  8.40s/it] 11%|█         | 1127/10395 [3:11:45<21:01:06,  8.16s/it]                                                         {'loss': 0.969, 'learning_rate': 1.9679321005887683e-05, 'epoch': 0.11}
 11%|█         | 1127/10395 [3:11:45<21:01:06,  8.16s/it] 11%|█         | 1128/10395 [3:11:53<20:59:03,  8.15s/it]                                                         {'loss': 0.9793, 'learning_rate': 1.9678537826915687e-05, 'epoch': 0.11}
 11%|█         | 1128/10395 [3:11:53<20:59:03,  8.15s/it] 11%|█         | 1129/10395 [3:12:00<20:06:18,  7.81s/it]                                                         {'loss': 1.1091, 'learning_rate': 1.967775370837192e-05, 'epoch': 0.11}
 11%|█         | 1129/10395 [3:12:00<20:06:18,  7.81s/it] 11%|█         | 1130/10395 [3:12:17<26:38:55, 10.35s/it]                                                         {'loss': 0.3372, 'learning_rate': 1.9676968650332504e-05, 'epoch': 0.11}
 11%|█         | 1130/10395 [3:12:17<26:38:55, 10.35s/it] 11%|█         | 1131/10395 [3:12:24<24:16:27,  9.43s/it]                                                         {'loss': 1.0126, 'learning_rate': 1.9676182652873653e-05, 'epoch': 0.11}
 11%|█         | 1131/10395 [3:12:24<24:16:27,  9.43s/it] 11%|█         | 1132/10395 [3:12:31<22:37:59,  8.80s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.9675395716071666e-05, 'epoch': 0.11}
 11%|█         | 1132/10395 [3:12:31<22:37:59,  8.80s/it] 11%|█         | 1133/10395 [3:12:39<21:44:34,  8.45s/it]                                                         {'loss': 0.9687, 'learning_rate': 1.9674607840002942e-05, 'epoch': 0.11}
 11%|█         | 1133/10395 [3:12:39<21:44:34,  8.45s/it] 11%|█         | 1134/10395 [3:12:48<22:36:13,  8.79s/it]                                                         {'loss': 1.0233, 'learning_rate': 1.967381902474396e-05, 'epoch': 0.11}
 11%|█         | 1134/10395 [3:12:48<22:36:13,  8.79s/it] 11%|█         | 1135/10395 [3:13:06<29:21:12, 11.41s/it]                                                         {'loss': 0.3195, 'learning_rate': 1.9673029270371303e-05, 'epoch': 0.11}
 11%|█         | 1135/10395 [3:13:06<29:21:12, 11.41s/it] 11%|█         | 1136/10395 [3:13:13<25:58:08, 10.10s/it]                                                         {'loss': 1.0659, 'learning_rate': 1.9672238576961634e-05, 'epoch': 0.11}
 11%|█         | 1136/10395 [3:13:13<25:58:08, 10.10s/it] 11%|█         | 1137/10395 [3:13:21<23:56:56,  9.31s/it]                                                         {'loss': 0.9994, 'learning_rate': 1.9671446944591714e-05, 'epoch': 0.11}
 11%|█         | 1137/10395 [3:13:21<23:56:56,  9.31s/it] 11%|█         | 1138/10395 [3:13:28<22:34:51,  8.78s/it]                                                         {'loss': 1.0624, 'learning_rate': 1.9670654373338393e-05, 'epoch': 0.11}
 11%|█         | 1138/10395 [3:13:28<22:34:51,  8.78s/it] 11%|█         | 1139/10395 [3:13:36<21:33:01,  8.38s/it]                                                         {'loss': 0.9607, 'learning_rate': 1.9669860863278612e-05, 'epoch': 0.11}
 11%|█         | 1139/10395 [3:13:36<21:33:01,  8.38s/it] 11%|█         | 1140/10395 [3:13:43<20:39:55,  8.04s/it]                                                         {'loss': 0.9752, 'learning_rate': 1.96690664144894e-05, 'epoch': 0.11}
 11%|█         | 1140/10395 [3:13:43<20:39:55,  8.04s/it] 11%|█         | 1141/10395 [3:13:51<20:47:22,  8.09s/it]                                                         {'loss': 1.0919, 'learning_rate': 1.9668271027047886e-05, 'epoch': 0.11}
 11%|█         | 1141/10395 [3:13:51<20:47:22,  8.09s/it] 11%|█         | 1142/10395 [3:13:58<20:18:58,  7.90s/it]                                                         {'loss': 1.0126, 'learning_rate': 1.9667474701031284e-05, 'epoch': 0.11}
 11%|█         | 1142/10395 [3:13:58<20:18:58,  7.90s/it] 11%|█         | 1143/10395 [3:14:06<19:41:47,  7.66s/it]                                                         {'loss': 1.0561, 'learning_rate': 1.9666677436516894e-05, 'epoch': 0.11}
 11%|█         | 1143/10395 [3:14:06<19:41:47,  7.66s/it] 11%|█         | 1144/10395 [3:14:13<19:36:41,  7.63s/it]                                                         {'loss': 0.9792, 'learning_rate': 1.966587923358212e-05, 'epoch': 0.11}
 11%|█         | 1144/10395 [3:14:13<19:36:41,  7.63s/it] 11%|█         | 1145/10395 [3:14:22<20:29:21,  7.97s/it]                                                         {'loss': 0.9705, 'learning_rate': 1.9665080092304444e-05, 'epoch': 0.11}
 11%|█         | 1145/10395 [3:14:22<20:29:21,  7.97s/it] 11%|█         | 1146/10395 [3:14:30<20:25:37,  7.95s/it]                                                         {'loss': 0.9587, 'learning_rate': 1.9664280012761445e-05, 'epoch': 0.11}
 11%|█         | 1146/10395 [3:14:30<20:25:37,  7.95s/it] 11%|█         | 1147/10395 [3:14:38<20:28:32,  7.97s/it]                                                         {'loss': 0.9771, 'learning_rate': 1.9663478995030795e-05, 'epoch': 0.11}
 11%|█         | 1147/10395 [3:14:38<20:28:32,  7.97s/it] 11%|█         | 1148/10395 [3:14:46<20:26:26,  7.96s/it]                                                         {'loss': 0.9829, 'learning_rate': 1.9662677039190257e-05, 'epoch': 0.11}
 11%|█         | 1148/10395 [3:14:46<20:26:26,  7.96s/it] 11%|█         | 1149/10395 [3:14:53<20:16:01,  7.89s/it]                                                         {'loss': 1.0389, 'learning_rate': 1.966187414531768e-05, 'epoch': 0.11}
 11%|█         | 1149/10395 [3:14:53<20:16:01,  7.89s/it] 11%|█         | 1150/10395 [3:15:02<20:26:59,  7.96s/it]                                                         {'loss': 1.0242, 'learning_rate': 1.9661070313491012e-05, 'epoch': 0.11}
 11%|█         | 1150/10395 [3:15:02<20:26:59,  7.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 1151/10395 [3:16:41<91:17:11, 35.55s/it]                                                         {'loss': 0.9692, 'learning_rate': 1.966026554378828e-05, 'epoch': 0.11}
 11%|█         | 1151/10395 [3:16:41<91:17:11, 35.55s/it] 11%|█         | 1152/10395 [3:16:59<77:38:42, 30.24s/it]                                                         {'loss': 0.3598, 'learning_rate': 1.9659459836287614e-05, 'epoch': 0.11}
 11%|█         | 1152/10395 [3:16:59<77:38:42, 30.24s/it] 11%|█         | 1153/10395 [3:17:07<60:02:47, 23.39s/it]                                                         {'loss': 0.9915, 'learning_rate': 1.965865319106723e-05, 'epoch': 0.11}
 11%|█         | 1153/10395 [3:17:07<60:02:47, 23.39s/it] 11%|█         | 1154/10395 [3:17:17<49:50:37, 19.42s/it]                                                         {'loss': 0.9363, 'learning_rate': 1.9657845608205435e-05, 'epoch': 0.11}
 11%|█         | 1154/10395 [3:17:17<49:50:37, 19.42s/it] 11%|█         | 1155/10395 [3:17:25<40:45:25, 15.88s/it]                                                         {'loss': 0.9513, 'learning_rate': 1.9657037087780626e-05, 'epoch': 0.11}
 11%|█         | 1155/10395 [3:17:25<40:45:25, 15.88s/it] 11%|█         | 1156/10395 [3:17:32<34:21:38, 13.39s/it]                                                         {'loss': 0.9532, 'learning_rate': 1.9656227629871295e-05, 'epoch': 0.11}
 11%|█         | 1156/10395 [3:17:32<34:21:38, 13.39s/it] 11%|█         | 1157/10395 [3:17:40<30:06:09, 11.73s/it]                                                         {'loss': 0.9542, 'learning_rate': 1.9655417234556018e-05, 'epoch': 0.11}
 11%|█         | 1157/10395 [3:17:40<30:06:09, 11.73s/it] 11%|█         | 1158/10395 [3:17:48<26:54:02, 10.48s/it]                                                         {'loss': 1.1102, 'learning_rate': 1.9654605901913472e-05, 'epoch': 0.11}
 11%|█         | 1158/10395 [3:17:48<26:54:02, 10.48s/it] 11%|█         | 1159/10395 [3:17:56<25:41:52, 10.02s/it]                                                         {'loss': 1.0191, 'learning_rate': 1.9653793632022418e-05, 'epoch': 0.11}
 11%|█         | 1159/10395 [3:17:56<25:41:52, 10.02s/it] 11%|█         | 1160/10395 [3:18:14<31:37:05, 12.33s/it]                                                         {'loss': 0.38, 'learning_rate': 1.9652980424961707e-05, 'epoch': 0.11}
 11%|█         | 1160/10395 [3:18:14<31:37:05, 12.33s/it] 11%|█         | 1161/10395 [3:18:22<27:46:56, 10.83s/it]                                                         {'loss': 1.0016, 'learning_rate': 1.9652166280810285e-05, 'epoch': 0.11}
 11%|█         | 1161/10395 [3:18:22<27:46:56, 10.83s/it] 11%|█         | 1162/10395 [3:18:30<25:54:11, 10.10s/it]                                                         {'loss': 1.0051, 'learning_rate': 1.965135119964719e-05, 'epoch': 0.11}
 11%|█         | 1162/10395 [3:18:30<25:54:11, 10.10s/it] 11%|█         | 1163/10395 [3:18:38<24:00:21,  9.36s/it]                                                         {'loss': 0.9729, 'learning_rate': 1.965053518155154e-05, 'epoch': 0.11}
 11%|█         | 1163/10395 [3:18:38<24:00:21,  9.36s/it] 11%|█         | 1164/10395 [3:18:45<22:43:55,  8.87s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.9649718226602562e-05, 'epoch': 0.11}
 11%|█         | 1164/10395 [3:18:45<22:43:55,  8.87s/it] 11%|█         | 1165/10395 [3:19:03<29:21:51, 11.45s/it]                                                         {'loss': 0.356, 'learning_rate': 1.964890033487956e-05, 'epoch': 0.11}
 11%|█         | 1165/10395 [3:19:03<29:21:51, 11.45s/it] 11%|█         | 1166/10395 [3:19:10<26:29:50, 10.34s/it]                                                         {'loss': 0.9401, 'learning_rate': 1.964808150646193e-05, 'epoch': 0.11}
 11%|█         | 1166/10395 [3:19:10<26:29:50, 10.34s/it] 11%|█         | 1167/10395 [3:19:18<24:08:04,  9.42s/it]                                                         {'loss': 1.0425, 'learning_rate': 1.964726174142917e-05, 'epoch': 0.11}
 11%|█         | 1167/10395 [3:19:18<24:08:04,  9.42s/it] 11%|█         | 1168/10395 [3:19:25<22:31:54,  8.79s/it]                                                         {'loss': 1.0333, 'learning_rate': 1.9646441039860853e-05, 'epoch': 0.11}
 11%|█         | 1168/10395 [3:19:25<22:31:54,  8.79s/it] 11%|█         | 1169/10395 [3:19:34<22:31:13,  8.79s/it]                                                         {'loss': 0.952, 'learning_rate': 1.9645619401836654e-05, 'epoch': 0.11}
 11%|█         | 1169/10395 [3:19:34<22:31:13,  8.79s/it] 11%|█▏        | 1170/10395 [3:19:41<21:29:36,  8.39s/it]                                                         {'loss': 1.0129, 'learning_rate': 1.964479682743634e-05, 'epoch': 0.11}
 11%|█▏        | 1170/10395 [3:19:41<21:29:36,  8.39s/it] 11%|█▏        | 1171/10395 [3:19:49<21:06:43,  8.24s/it]                                                         {'loss': 1.045, 'learning_rate': 1.9643973316739758e-05, 'epoch': 0.11}
 11%|█▏        | 1171/10395 [3:19:49<21:06:43,  8.24s/it] 11%|█▏        | 1172/10395 [3:19:57<20:37:34,  8.05s/it]                                                         {'loss': 1.0557, 'learning_rate': 1.9643148869826854e-05, 'epoch': 0.11}
 11%|█▏        | 1172/10395 [3:19:57<20:37:34,  8.05s/it] 11%|█▏        | 1173/10395 [3:20:04<20:09:00,  7.87s/it]                                                         {'loss': 0.9835, 'learning_rate': 1.9642323486777668e-05, 'epoch': 0.11}
 11%|█▏        | 1173/10395 [3:20:04<20:09:00,  7.87s/it] 11%|█▏        | 1174/10395 [3:20:22<27:51:46, 10.88s/it]                                                         {'loss': 0.3361, 'learning_rate': 1.9641497167672323e-05, 'epoch': 0.11}
 11%|█▏        | 1174/10395 [3:20:22<27:51:46, 10.88s/it] 11%|█▏        | 1175/10395 [3:20:30<25:23:36,  9.91s/it]                                                         {'loss': 0.9456, 'learning_rate': 1.9640669912591036e-05, 'epoch': 0.11}
 11%|█▏        | 1175/10395 [3:20:30<25:23:36,  9.91s/it] 11%|█▏        | 1176/10395 [3:20:37<23:34:43,  9.21s/it]                                                         {'loss': 0.9507, 'learning_rate': 1.963984172161412e-05, 'epoch': 0.11}
 11%|█▏        | 1176/10395 [3:20:37<23:34:43,  9.21s/it] 11%|█▏        | 1177/10395 [3:20:46<22:46:43,  8.90s/it]                                                         {'loss': 1.0433, 'learning_rate': 1.9639012594821968e-05, 'epoch': 0.11}
 11%|█▏        | 1177/10395 [3:20:46<22:46:43,  8.90s/it] 11%|█▏        | 1178/10395 [3:20:55<22:51:37,  8.93s/it]                                                         {'loss': 0.941, 'learning_rate': 1.9638182532295066e-05, 'epoch': 0.11}
 11%|█▏        | 1178/10395 [3:20:55<22:51:37,  8.93s/it] 11%|█▏        | 1179/10395 [3:21:02<22:03:02,  8.61s/it]                                                         {'loss': 1.0004, 'learning_rate': 1.9637351534114008e-05, 'epoch': 0.11}
 11%|█▏        | 1179/10395 [3:21:02<22:03:02,  8.61s/it] 11%|█▏        | 1180/10395 [3:21:10<21:34:53,  8.43s/it]                                                         {'loss': 0.9236, 'learning_rate': 1.9636519600359456e-05, 'epoch': 0.11}
 11%|█▏        | 1180/10395 [3:21:10<21:34:53,  8.43s/it] 11%|█▏        | 1181/10395 [3:21:17<20:23:55,  7.97s/it]                                                         {'loss': 1.0376, 'learning_rate': 1.9635686731112173e-05, 'epoch': 0.11}
 11%|█▏        | 1181/10395 [3:21:17<20:23:55,  7.97s/it] 11%|█▏        | 1182/10395 [3:21:25<20:00:21,  7.82s/it]                                                         {'loss': 1.0528, 'learning_rate': 1.9634852926453016e-05, 'epoch': 0.11}
 11%|█▏        | 1182/10395 [3:21:25<20:00:21,  7.82s/it] 11%|█▏        | 1183/10395 [3:21:33<20:03:25,  7.84s/it]                                                         {'loss': 1.0094, 'learning_rate': 1.9634018186462924e-05, 'epoch': 0.11}
 11%|█▏        | 1183/10395 [3:21:33<20:03:25,  7.84s/it] 11%|█▏        | 1184/10395 [3:21:41<20:09:16,  7.88s/it]                                                         {'loss': 0.9768, 'learning_rate': 1.963318251122294e-05, 'epoch': 0.11}
 11%|█▏        | 1184/10395 [3:21:41<20:09:16,  7.88s/it] 11%|█▏        | 1185/10395 [3:21:49<20:12:31,  7.90s/it]                                                         {'loss': 0.9321, 'learning_rate': 1.9632345900814178e-05, 'epoch': 0.11}
 11%|█▏        | 1185/10395 [3:21:49<20:12:31,  7.90s/it] 11%|█▏        | 1186/10395 [3:21:56<20:02:08,  7.83s/it]                                                         {'loss': 0.9244, 'learning_rate': 1.9631508355317862e-05, 'epoch': 0.11}
 11%|█▏        | 1186/10395 [3:21:56<20:02:08,  7.83s/it] 11%|█▏        | 1187/10395 [3:22:04<20:00:48,  7.82s/it]                                                         {'loss': 0.9741, 'learning_rate': 1.96306698748153e-05, 'epoch': 0.11}
 11%|█▏        | 1187/10395 [3:22:04<20:00:48,  7.82s/it] 11%|█▏        | 1188/10395 [3:22:12<19:44:09,  7.72s/it]                                                         {'loss': 1.0052, 'learning_rate': 1.9629830459387884e-05, 'epoch': 0.11}
 11%|█▏        | 1188/10395 [3:22:12<19:44:09,  7.72s/it] 11%|█▏        | 1189/10395 [3:22:19<19:40:24,  7.69s/it]                                                         {'loss': 1.126, 'learning_rate': 1.9628990109117106e-05, 'epoch': 0.11}
 11%|█▏        | 1189/10395 [3:22:19<19:40:24,  7.69s/it] 11%|█▏        | 1190/10395 [3:22:35<26:06:30, 10.21s/it]                                                         {'loss': 0.3036, 'learning_rate': 1.962814882408455e-05, 'epoch': 0.11}
 11%|█▏        | 1190/10395 [3:22:35<26:06:30, 10.21s/it] 11%|█▏        | 1191/10395 [3:22:43<24:31:34,  9.59s/it]                                                         {'loss': 1.0211, 'learning_rate': 1.9627306604371873e-05, 'epoch': 0.11}
 11%|█▏        | 1191/10395 [3:22:43<24:31:34,  9.59s/it] 11%|█▏        | 1192/10395 [3:22:51<22:53:40,  8.96s/it]                                                         {'loss': 0.9975, 'learning_rate': 1.962646345006085e-05, 'epoch': 0.11}
 11%|█▏        | 1192/10395 [3:22:51<22:53:40,  8.96s/it] 11%|█▏        | 1193/10395 [3:23:08<29:20:34, 11.48s/it]                                                         {'loss': 0.3883, 'learning_rate': 1.9625619361233327e-05, 'epoch': 0.11}
 11%|█▏        | 1193/10395 [3:23:08<29:20:34, 11.48s/it] 11%|█▏        | 1194/10395 [3:23:17<26:51:30, 10.51s/it]                                                         {'loss': 1.0842, 'learning_rate': 1.962477433797125e-05, 'epoch': 0.11}
 11%|█▏        | 1194/10395 [3:23:17<26:51:30, 10.51s/it] 11%|█▏        | 1195/10395 [3:23:25<25:03:08,  9.80s/it]                                                         {'loss': 0.9896, 'learning_rate': 1.9623928380356642e-05, 'epoch': 0.11}
 11%|█▏        | 1195/10395 [3:23:25<25:03:08,  9.80s/it] 12%|█▏        | 1196/10395 [3:23:32<23:18:52,  9.12s/it]                                                         {'loss': 1.0591, 'learning_rate': 1.9623081488471636e-05, 'epoch': 0.12}
 12%|█▏        | 1196/10395 [3:23:32<23:18:52,  9.12s/it] 12%|█▏        | 1197/10395 [3:23:40<21:56:09,  8.59s/it]                                                         {'loss': 0.961, 'learning_rate': 1.9622233662398444e-05, 'epoch': 0.12}
 12%|█▏        | 1197/10395 [3:23:40<21:56:09,  8.59s/it] 12%|█▏        | 1198/10395 [3:23:47<21:02:14,  8.23s/it]                                                         {'loss': 0.9221, 'learning_rate': 1.9621384902219368e-05, 'epoch': 0.12}
 12%|█▏        | 1198/10395 [3:23:47<21:02:14,  8.23s/it] 12%|█▏        | 1199/10395 [3:23:55<21:16:11,  8.33s/it]                                                         {'loss': 0.9106, 'learning_rate': 1.962053520801681e-05, 'epoch': 0.12}
 12%|█▏        | 1199/10395 [3:23:55<21:16:11,  8.33s/it] 12%|█▏        | 1200/10395 [3:24:03<20:33:42,  8.05s/it]                                                         {'loss': 1.0068, 'learning_rate': 1.9619684579873254e-05, 'epoch': 0.12}
 12%|█▏        | 1200/10395 [3:24:03<20:33:42,  8.05s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 12%|█▏        | 1201/10395 [3:25:46<93:09:22, 36.48s/it]                                                         {'loss': 0.9309, 'learning_rate': 1.9618833017871273e-05, 'epoch': 0.12}
 12%|█▏        | 1201/10395 [3:25:46<93:09:22, 36.48s/it] 12%|█▏        | 1202/10395 [3:25:53<71:05:35, 27.84s/it]                                                         {'loss': 1.041, 'learning_rate': 1.9617980522093544e-05, 'epoch': 0.12}
 12%|█▏        | 1202/10395 [3:25:53<71:05:35, 27.84s/it] 12%|█▏        | 1203/10395 [3:26:02<56:10:18, 22.00s/it]                                                         {'loss': 1.0445, 'learning_rate': 1.961712709262281e-05, 'epoch': 0.12}
 12%|█▏        | 1203/10395 [3:26:02<56:10:18, 22.00s/it] 12%|█▏        | 1204/10395 [3:26:09<44:51:51, 17.57s/it]                                                         {'loss': 1.0525, 'learning_rate': 1.9616272729541936e-05, 'epoch': 0.12}
 12%|█▏        | 1204/10395 [3:26:09<44:51:51, 17.57s/it] 12%|█▏        | 1205/10395 [3:26:16<36:55:11, 14.46s/it]                                                         {'loss': 1.0276, 'learning_rate': 1.9615417432933855e-05, 'epoch': 0.12}
 12%|█▏        | 1205/10395 [3:26:16<36:55:11, 14.46s/it] 12%|█▏        | 1206/10395 [3:26:32<37:36:57, 14.74s/it]                                                         {'loss': 0.3638, 'learning_rate': 1.9614561202881596e-05, 'epoch': 0.12}
 12%|█▏        | 1206/10395 [3:26:32<37:36:57, 14.74s/it] 12%|█▏        | 1207/10395 [3:26:39<32:22:01, 12.68s/it]                                                         {'loss': 1.0382, 'learning_rate': 1.9613704039468285e-05, 'epoch': 0.12}
 12%|█▏        | 1207/10395 [3:26:39<32:22:01, 12.68s/it] 12%|█▏        | 1208/10395 [3:26:49<29:51:20, 11.70s/it]                                                         {'loss': 0.9556, 'learning_rate': 1.961284594277713e-05, 'epoch': 0.12}
 12%|█▏        | 1208/10395 [3:26:49<29:51:20, 11.70s/it] 12%|█▏        | 1209/10395 [3:26:57<27:07:12, 10.63s/it]                                                         {'loss': 0.9823, 'learning_rate': 1.961198691289143e-05, 'epoch': 0.12}
 12%|█▏        | 1209/10395 [3:26:57<27:07:12, 10.63s/it] 12%|█▏        | 1210/10395 [3:27:05<25:22:20,  9.94s/it]                                                         {'loss': 0.9754, 'learning_rate': 1.9611126949894586e-05, 'epoch': 0.12}
 12%|█▏        | 1210/10395 [3:27:05<25:22:20,  9.94s/it] 12%|█▏        | 1211/10395 [3:27:13<23:50:55,  9.35s/it]                                                         {'loss': 0.9674, 'learning_rate': 1.9610266053870074e-05, 'epoch': 0.12}
 12%|█▏        | 1211/10395 [3:27:13<23:50:55,  9.35s/it] 12%|█▏        | 1212/10395 [3:27:21<22:31:30,  8.83s/it]                                                         {'loss': 0.9839, 'learning_rate': 1.960940422490147e-05, 'epoch': 0.12}
 12%|█▏        | 1212/10395 [3:27:21<22:31:30,  8.83s/it] 12%|█▏        | 1213/10395 [3:27:29<21:37:57,  8.48s/it]                                                         {'loss': 1.0244, 'learning_rate': 1.960854146307244e-05, 'epoch': 0.12}
 12%|█▏        | 1213/10395 [3:27:29<21:37:57,  8.48s/it] 12%|█▏        | 1214/10395 [3:27:37<21:14:52,  8.33s/it]                                                         {'loss': 1.0168, 'learning_rate': 1.960767776846674e-05, 'epoch': 0.12}
 12%|█▏        | 1214/10395 [3:27:37<21:14:52,  8.33s/it] 12%|█▏        | 1215/10395 [3:27:44<20:44:04,  8.13s/it]                                                         {'loss': 0.9372, 'learning_rate': 1.9606813141168214e-05, 'epoch': 0.12}
 12%|█▏        | 1215/10395 [3:27:44<20:44:04,  8.13s/it] 12%|█▏        | 1216/10395 [3:27:52<20:27:42,  8.03s/it]                                                         {'loss': 0.9736, 'learning_rate': 1.9605947581260795e-05, 'epoch': 0.12}
 12%|█▏        | 1216/10395 [3:27:52<20:27:42,  8.03s/it] 12%|█▏        | 1217/10395 [3:28:01<21:25:53,  8.41s/it]                                                         {'loss': 0.9895, 'learning_rate': 1.9605081088828512e-05, 'epoch': 0.12}
 12%|█▏        | 1217/10395 [3:28:01<21:25:53,  8.41s/it] 12%|█▏        | 1218/10395 [3:28:09<21:05:53,  8.28s/it]                                                         {'loss': 0.9941, 'learning_rate': 1.9604213663955483e-05, 'epoch': 0.12}
 12%|█▏        | 1218/10395 [3:28:09<21:05:53,  8.28s/it] 12%|█▏        | 1219/10395 [3:28:17<20:22:18,  7.99s/it]                                                         {'loss': 1.0044, 'learning_rate': 1.9603345306725923e-05, 'epoch': 0.12}
 12%|█▏        | 1219/10395 [3:28:17<20:22:18,  7.99s/it] 12%|█▏        | 1220/10395 [3:28:24<19:52:24,  7.80s/it]                                                         {'loss': 1.0196, 'learning_rate': 1.9602476017224115e-05, 'epoch': 0.12}
 12%|█▏        | 1220/10395 [3:28:24<19:52:24,  7.80s/it] 12%|█▏        | 1221/10395 [3:28:31<19:31:29,  7.66s/it]                                                         {'loss': 0.941, 'learning_rate': 1.960160579553446e-05, 'epoch': 0.12}
 12%|█▏        | 1221/10395 [3:28:31<19:31:29,  7.66s/it] 12%|█▏        | 1222/10395 [3:28:39<19:46:53,  7.76s/it]                                                         {'loss': 0.9993, 'learning_rate': 1.960073464174143e-05, 'epoch': 0.12}
 12%|█▏        | 1222/10395 [3:28:39<19:46:53,  7.76s/it] 12%|█▏        | 1223/10395 [3:28:47<19:59:32,  7.85s/it]                                                         {'loss': 0.966, 'learning_rate': 1.95998625559296e-05, 'epoch': 0.12}
 12%|█▏        | 1223/10395 [3:28:47<19:59:32,  7.85s/it] 12%|█▏        | 1224/10395 [3:29:05<27:24:18, 10.76s/it]                                                         {'loss': 0.3663, 'learning_rate': 1.959898953818363e-05, 'epoch': 0.12}
 12%|█▏        | 1224/10395 [3:29:05<27:24:18, 10.76s/it] 12%|█▏        | 1225/10395 [3:29:13<25:09:04,  9.87s/it]                                                         {'loss': 0.9883, 'learning_rate': 1.9598115588588266e-05, 'epoch': 0.12}
 12%|█▏        | 1225/10395 [3:29:13<25:09:04,  9.87s/it] 12%|█▏        | 1226/10395 [3:29:20<23:13:03,  9.12s/it]                                                         {'loss': 0.9954, 'learning_rate': 1.9597240707228352e-05, 'epoch': 0.12}
 12%|█▏        | 1226/10395 [3:29:20<23:13:03,  9.12s/it] 12%|█▏        | 1227/10395 [3:29:28<22:01:42,  8.65s/it]                                                         {'loss': 0.8641, 'learning_rate': 1.9596364894188822e-05, 'epoch': 0.12}
 12%|█▏        | 1227/10395 [3:29:28<22:01:42,  8.65s/it] 12%|█▏        | 1228/10395 [3:29:35<20:47:04,  8.16s/it]                                                         {'loss': 1.1355, 'learning_rate': 1.9595488149554695e-05, 'epoch': 0.12}
 12%|█▏        | 1228/10395 [3:29:35<20:47:04,  8.16s/it] 12%|█▏        | 1229/10395 [3:29:42<20:10:53,  7.93s/it]                                                         {'loss': 0.9375, 'learning_rate': 1.959461047341108e-05, 'epoch': 0.12}
 12%|█▏        | 1229/10395 [3:29:42<20:10:53,  7.93s/it] 12%|█▏        | 1230/10395 [3:30:00<27:45:41, 10.90s/it]                                                         {'loss': 0.364, 'learning_rate': 1.9593731865843187e-05, 'epoch': 0.12}
 12%|█▏        | 1230/10395 [3:30:00<27:45:41, 10.90s/it] 12%|█▏        | 1231/10395 [3:30:08<25:18:58,  9.95s/it]                                                         {'loss': 1.0755, 'learning_rate': 1.9592852326936305e-05, 'epoch': 0.12}
 12%|█▏        | 1231/10395 [3:30:08<25:18:58,  9.95s/it] 12%|█▏        | 1232/10395 [3:30:15<23:33:35,  9.26s/it]                                                         {'loss': 0.9955, 'learning_rate': 1.959197185677582e-05, 'epoch': 0.12}
 12%|█▏        | 1232/10395 [3:30:15<23:33:35,  9.26s/it] 12%|█▏        | 1233/10395 [3:30:24<23:09:19,  9.10s/it]                                                         {'loss': 0.9225, 'learning_rate': 1.959109045544721e-05, 'epoch': 0.12}
 12%|█▏        | 1233/10395 [3:30:24<23:09:19,  9.10s/it] 12%|█▏        | 1234/10395 [3:30:41<29:23:28, 11.55s/it]                                                         {'loss': 0.3811, 'learning_rate': 1.9590208123036024e-05, 'epoch': 0.12}
 12%|█▏        | 1234/10395 [3:30:41<29:23:28, 11.55s/it] 12%|█▏        | 1235/10395 [3:30:50<26:55:57, 10.58s/it]                                                         {'loss': 0.9556, 'learning_rate': 1.9589324859627935e-05, 'epoch': 0.12}
 12%|█▏        | 1235/10395 [3:30:50<26:55:57, 10.58s/it] 12%|█▏        | 1236/10395 [3:31:08<32:44:04, 12.87s/it]                                                         {'loss': 0.3469, 'learning_rate': 1.9588440665308682e-05, 'epoch': 0.12}
 12%|█▏        | 1236/10395 [3:31:08<32:44:04, 12.87s/it] 12%|█▏        | 1237/10395 [3:31:18<30:22:36, 11.94s/it]                                                         {'loss': 0.9157, 'learning_rate': 1.9587555540164097e-05, 'epoch': 0.12}
 12%|█▏        | 1237/10395 [3:31:18<30:22:36, 11.94s/it] 12%|█▏        | 1238/10395 [3:31:26<27:28:32, 10.80s/it]                                                         {'loss': 1.0373, 'learning_rate': 1.958666948428011e-05, 'epoch': 0.12}
 12%|█▏        | 1238/10395 [3:31:26<27:28:32, 10.80s/it] 12%|█▏        | 1239/10395 [3:31:33<24:47:33,  9.75s/it]                                                         {'loss': 0.9694, 'learning_rate': 1.9585782497742735e-05, 'epoch': 0.12}
 12%|█▏        | 1239/10395 [3:31:33<24:47:33,  9.75s/it] 12%|█▏        | 1240/10395 [3:31:41<23:12:56,  9.13s/it]                                                         {'loss': 1.0428, 'learning_rate': 1.958489458063808e-05, 'epoch': 0.12}
 12%|█▏        | 1240/10395 [3:31:41<23:12:56,  9.13s/it] 12%|█▏        | 1241/10395 [3:31:49<22:22:13,  8.80s/it]                                                         {'loss': 0.9851, 'learning_rate': 1.9584005733052346e-05, 'epoch': 0.12}
 12%|█▏        | 1241/10395 [3:31:49<22:22:13,  8.80s/it] 12%|█▏        | 1242/10395 [3:31:56<21:35:02,  8.49s/it]                                                         {'loss': 1.0345, 'learning_rate': 1.9583115955071813e-05, 'epoch': 0.12}
 12%|█▏        | 1242/10395 [3:31:56<21:35:02,  8.49s/it] 12%|█▏        | 1243/10395 [3:32:05<21:25:32,  8.43s/it]                                                         {'loss': 1.0482, 'learning_rate': 1.958222524678286e-05, 'epoch': 0.12}
 12%|█▏        | 1243/10395 [3:32:05<21:25:32,  8.43s/it] 12%|█▏        | 1244/10395 [3:32:12<20:32:06,  8.08s/it]                                                         {'loss': 0.9584, 'learning_rate': 1.9581333608271963e-05, 'epoch': 0.12}
 12%|█▏        | 1244/10395 [3:32:12<20:32:06,  8.08s/it] 12%|█▏        | 1245/10395 [3:32:20<20:24:48,  8.03s/it]                                                         {'loss': 0.922, 'learning_rate': 1.958044103962567e-05, 'epoch': 0.12}
 12%|█▏        | 1245/10395 [3:32:20<20:24:48,  8.03s/it] 12%|█▏        | 1246/10395 [3:32:28<20:21:27,  8.01s/it]                                                         {'loss': 1.0119, 'learning_rate': 1.9579547540930636e-05, 'epoch': 0.12}
 12%|█▏        | 1246/10395 [3:32:28<20:21:27,  8.01s/it] 12%|█▏        | 1247/10395 [3:32:35<19:54:03,  7.83s/it]                                                         {'loss': 0.9553, 'learning_rate': 1.95786531122736e-05, 'epoch': 0.12}
 12%|█▏        | 1247/10395 [3:32:35<19:54:03,  7.83s/it] 12%|█▏        | 1248/10395 [3:32:43<19:37:23,  7.72s/it]                                                         {'loss': 1.0783, 'learning_rate': 1.9577757753741385e-05, 'epoch': 0.12}
 12%|█▏        | 1248/10395 [3:32:43<19:37:23,  7.72s/it] 12%|█▏        | 1249/10395 [3:33:00<27:14:04, 10.72s/it]                                                         {'loss': 0.3662, 'learning_rate': 1.957686146542092e-05, 'epoch': 0.12}
 12%|█▏        | 1249/10395 [3:33:00<27:14:04, 10.72s/it] 12%|█▏        | 1250/10395 [3:33:09<25:15:43,  9.94s/it]                                                         {'loss': 0.945, 'learning_rate': 1.957596424739921e-05, 'epoch': 0.12}
 12%|█▏        | 1250/10395 [3:33:09<25:15:43,  9.94s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 12%|█▏        | 1251/10395 [3:34:48<93:30:30, 36.81s/it]                                                         {'loss': 0.9258, 'learning_rate': 1.957506609976335e-05, 'epoch': 0.12}
 12%|█▏        | 1251/10395 [3:34:48<93:30:30, 36.81s/it] 12%|█▏        | 1252/10395 [3:34:57<71:57:27, 28.33s/it]                                                         {'loss': 0.9552, 'learning_rate': 1.9574167022600536e-05, 'epoch': 0.12}
 12%|█▏        | 1252/10395 [3:34:57<71:57:27, 28.33s/it] 12%|█▏        | 1253/10395 [3:35:04<56:18:00, 22.17s/it]                                                         {'loss': 0.96, 'learning_rate': 1.957326701599805e-05, 'epoch': 0.12}
 12%|█▏        | 1253/10395 [3:35:04<56:18:00, 22.17s/it] 12%|█▏        | 1254/10395 [3:35:12<44:49:36, 17.65s/it]                                                         {'loss': 1.0337, 'learning_rate': 1.957236608004326e-05, 'epoch': 0.12}
 12%|█▏        | 1254/10395 [3:35:12<44:49:36, 17.65s/it] 12%|█▏        | 1255/10395 [3:35:20<37:39:14, 14.83s/it]                                                         {'loss': 1.0506, 'learning_rate': 1.9571464214823627e-05, 'epoch': 0.12}
 12%|█▏        | 1255/10395 [3:35:20<37:39:14, 14.83s/it] 12%|█▏        | 1256/10395 [3:35:28<32:16:31, 12.71s/it]                                                         {'loss': 0.9693, 'learning_rate': 1.9570561420426703e-05, 'epoch': 0.12}
 12%|█▏        | 1256/10395 [3:35:28<32:16:31, 12.71s/it] 12%|█▏        | 1257/10395 [3:35:35<28:36:21, 11.27s/it]                                                         {'loss': 0.9957, 'learning_rate': 1.9569657696940124e-05, 'epoch': 0.12}
 12%|█▏        | 1257/10395 [3:35:36<28:36:21, 11.27s/it] 12%|█▏        | 1258/10395 [3:35:43<25:52:33, 10.20s/it]                                                         {'loss': 0.9374, 'learning_rate': 1.956875304445163e-05, 'epoch': 0.12}
 12%|█▏        | 1258/10395 [3:35:43<25:52:33, 10.20s/it] 12%|█▏        | 1259/10395 [3:35:51<23:56:49,  9.44s/it]                                                         {'loss': 0.9658, 'learning_rate': 1.956784746304904e-05, 'epoch': 0.12}
 12%|█▏        | 1259/10395 [3:35:51<23:56:49,  9.44s/it] 12%|█▏        | 1260/10395 [3:35:59<23:10:12,  9.13s/it]                                                         {'loss': 0.9538, 'learning_rate': 1.956694095282026e-05, 'epoch': 0.12}
 12%|█▏        | 1260/10395 [3:35:59<23:10:12,  9.13s/it] 12%|█▏        | 1261/10395 [3:36:07<22:06:31,  8.71s/it]                                                         {'loss': 1.0546, 'learning_rate': 1.9566033513853302e-05, 'epoch': 0.12}
 12%|█▏        | 1261/10395 [3:36:07<22:06:31,  8.71s/it] 12%|█▏        | 1262/10395 [3:36:15<21:55:07,  8.64s/it]                                                         {'loss': 1.0251, 'learning_rate': 1.9565125146236252e-05, 'epoch': 0.12}
 12%|█▏        | 1262/10395 [3:36:15<21:55:07,  8.64s/it] 12%|█▏        | 1263/10395 [3:36:23<20:50:20,  8.22s/it]                                                         {'loss': 1.0537, 'learning_rate': 1.9564215850057294e-05, 'epoch': 0.12}
 12%|█▏        | 1263/10395 [3:36:23<20:50:20,  8.22s/it] 12%|█▏        | 1264/10395 [3:36:32<21:19:10,  8.41s/it]                                                         {'loss': 0.9932, 'learning_rate': 1.95633056254047e-05, 'epoch': 0.12}
 12%|█▏        | 1264/10395 [3:36:32<21:19:10,  8.41s/it] 12%|█▏        | 1265/10395 [3:36:40<21:01:45,  8.29s/it]                                                         {'loss': 1.0665, 'learning_rate': 1.956239447236683e-05, 'epoch': 0.12}
 12%|█▏        | 1265/10395 [3:36:40<21:01:45,  8.29s/it] 12%|█▏        | 1266/10395 [3:36:48<21:19:43,  8.41s/it]                                                         {'loss': 0.8652, 'learning_rate': 1.956148239103214e-05, 'epoch': 0.12}
 12%|█▏        | 1266/10395 [3:36:48<21:19:43,  8.41s/it] 12%|█▏        | 1267/10395 [3:36:56<20:32:48,  8.10s/it]                                                         {'loss': 0.9657, 'learning_rate': 1.9560569381489178e-05, 'epoch': 0.12}
 12%|█▏        | 1267/10395 [3:36:56<20:32:48,  8.10s/it] 12%|█▏        | 1268/10395 [3:37:03<20:04:10,  7.92s/it]                                                         {'loss': 1.046, 'learning_rate': 1.9559655443826564e-05, 'epoch': 0.12}
 12%|█▏        | 1268/10395 [3:37:03<20:04:10,  7.92s/it] 12%|█▏        | 1269/10395 [3:37:11<20:17:33,  8.01s/it]                                                         {'loss': 0.9351, 'learning_rate': 1.9558740578133033e-05, 'epoch': 0.12}
 12%|█▏        | 1269/10395 [3:37:11<20:17:33,  8.01s/it] 12%|█▏        | 1270/10395 [3:37:19<20:02:48,  7.91s/it]                                                         {'loss': 1.0149, 'learning_rate': 1.9557824784497392e-05, 'epoch': 0.12}
 12%|█▏        | 1270/10395 [3:37:19<20:02:48,  7.91s/it] 12%|█▏        | 1271/10395 [3:37:26<19:38:50,  7.75s/it]                                                         {'loss': 1.0027, 'learning_rate': 1.9556908063008546e-05, 'epoch': 0.12}
 12%|█▏        | 1271/10395 [3:37:26<19:38:50,  7.75s/it] 12%|█▏        | 1272/10395 [3:37:34<19:39:35,  7.76s/it]                                                         {'loss': 1.041, 'learning_rate': 1.955599041375549e-05, 'epoch': 0.12}
 12%|█▏        | 1272/10395 [3:37:34<19:39:35,  7.76s/it] 12%|█▏        | 1273/10395 [3:37:42<19:57:28,  7.88s/it]                                                         {'loss': 0.9928, 'learning_rate': 1.9555071836827304e-05, 'epoch': 0.12}
 12%|█▏        | 1273/10395 [3:37:42<19:57:28,  7.88s/it] 12%|█▏        | 1274/10395 [3:37:50<19:59:54,  7.89s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.9554152332313165e-05, 'epoch': 0.12}
 12%|█▏        | 1274/10395 [3:37:50<19:59:54,  7.89s/it] 12%|█▏        | 1275/10395 [3:37:58<19:50:56,  7.84s/it]                                                         {'loss': 1.0029, 'learning_rate': 1.9553231900302334e-05, 'epoch': 0.12}
 12%|█▏        | 1275/10395 [3:37:58<19:50:56,  7.84s/it] 12%|█▏        | 1276/10395 [3:38:05<19:28:56,  7.69s/it]                                                         {'loss': 0.974, 'learning_rate': 1.9552310540884164e-05, 'epoch': 0.12}
 12%|█▏        | 1276/10395 [3:38:05<19:28:56,  7.69s/it] 12%|█▏        | 1277/10395 [3:38:13<19:47:11,  7.81s/it]                                                         {'loss': 0.9763, 'learning_rate': 1.9551388254148103e-05, 'epoch': 0.12}
 12%|█▏        | 1277/10395 [3:38:13<19:47:11,  7.81s/it] 12%|█▏        | 1278/10395 [3:38:32<27:46:10, 10.97s/it]                                                         {'loss': 0.407, 'learning_rate': 1.955046504018368e-05, 'epoch': 0.12}
 12%|█▏        | 1278/10395 [3:38:32<27:46:10, 10.97s/it] 12%|█▏        | 1279/10395 [3:38:39<25:13:39,  9.96s/it]                                                         {'loss': 1.0006, 'learning_rate': 1.9549540899080522e-05, 'epoch': 0.12}
 12%|█▏        | 1279/10395 [3:38:39<25:13:39,  9.96s/it] 12%|█▏        | 1280/10395 [3:38:49<24:36:16,  9.72s/it]                                                         {'loss': 0.9949, 'learning_rate': 1.954861583092834e-05, 'epoch': 0.12}
 12%|█▏        | 1280/10395 [3:38:49<24:36:16,  9.72s/it] 12%|█▏        | 1281/10395 [3:38:56<23:00:10,  9.09s/it]                                                         {'loss': 0.9573, 'learning_rate': 1.9547689835816936e-05, 'epoch': 0.12}
 12%|█▏        | 1281/10395 [3:38:56<23:00:10,  9.09s/it] 12%|█▏        | 1282/10395 [3:39:03<21:34:12,  8.52s/it]                                                         {'loss': 1.0176, 'learning_rate': 1.954676291383621e-05, 'epoch': 0.12}
 12%|█▏        | 1282/10395 [3:39:03<21:34:12,  8.52s/it] 12%|█▏        | 1283/10395 [3:39:11<20:50:16,  8.23s/it]                                                         {'loss': 1.0665, 'learning_rate': 1.9545835065076136e-05, 'epoch': 0.12}
 12%|█▏        | 1283/10395 [3:39:11<20:50:16,  8.23s/it] 12%|█▏        | 1284/10395 [3:39:19<20:31:09,  8.11s/it]                                                         {'loss': 1.0544, 'learning_rate': 1.9544906289626802e-05, 'epoch': 0.12}
 12%|█▏        | 1284/10395 [3:39:19<20:31:09,  8.11s/it] 12%|█▏        | 1285/10395 [3:39:27<20:30:17,  8.10s/it]                                                         {'loss': 0.9097, 'learning_rate': 1.954397658757836e-05, 'epoch': 0.12}
 12%|█▏        | 1285/10395 [3:39:27<20:30:17,  8.10s/it] 12%|█▏        | 1286/10395 [3:39:36<21:25:02,  8.46s/it]                                                         {'loss': 0.9219, 'learning_rate': 1.954304595902106e-05, 'epoch': 0.12}
 12%|█▏        | 1286/10395 [3:39:36<21:25:02,  8.46s/it] 12%|█▏        | 1287/10395 [3:39:44<20:50:24,  8.24s/it]                                                         {'loss': 0.9858, 'learning_rate': 1.954211440404526e-05, 'epoch': 0.12}
 12%|█▏        | 1287/10395 [3:39:44<20:50:24,  8.24s/it] 12%|█▏        | 1288/10395 [3:39:52<20:44:46,  8.20s/it]                                                         {'loss': 0.9237, 'learning_rate': 1.954118192274138e-05, 'epoch': 0.12}
 12%|█▏        | 1288/10395 [3:39:52<20:44:46,  8.20s/it] 12%|█▏        | 1289/10395 [3:39:59<20:08:05,  7.96s/it]                                                         {'loss': 0.9664, 'learning_rate': 1.954024851519995e-05, 'epoch': 0.12}
 12%|█▏        | 1289/10395 [3:39:59<20:08:05,  7.96s/it] 12%|█▏        | 1290/10395 [3:40:07<19:45:58,  7.82s/it]                                                         {'loss': 0.9485, 'learning_rate': 1.9539314181511584e-05, 'epoch': 0.12}
 12%|█▏        | 1290/10395 [3:40:07<19:45:58,  7.82s/it] 12%|█▏        | 1291/10395 [3:40:15<20:19:12,  8.04s/it]                                                         {'loss': 0.9645, 'learning_rate': 1.953837892176698e-05, 'epoch': 0.12}
 12%|█▏        | 1291/10395 [3:40:15<20:19:12,  8.04s/it] 12%|█▏        | 1292/10395 [3:40:24<20:32:05,  8.12s/it]                                                         {'loss': 0.8964, 'learning_rate': 1.9537442736056935e-05, 'epoch': 0.12}
 12%|█▏        | 1292/10395 [3:40:24<20:32:05,  8.12s/it] 12%|█▏        | 1293/10395 [3:40:31<20:04:16,  7.94s/it]                                                         {'loss': 1.0452, 'learning_rate': 1.9536505624472332e-05, 'epoch': 0.12}
 12%|█▏        | 1293/10395 [3:40:31<20:04:16,  7.94s/it] 12%|█▏        | 1294/10395 [3:40:39<19:40:21,  7.78s/it]                                                         {'loss': 1.0985, 'learning_rate': 1.953556758710414e-05, 'epoch': 0.12}
 12%|█▏        | 1294/10395 [3:40:39<19:40:21,  7.78s/it] 12%|█▏        | 1295/10395 [3:40:46<19:15:15,  7.62s/it]                                                         {'loss': 1.0434, 'learning_rate': 1.9534628624043427e-05, 'epoch': 0.12}
 12%|█▏        | 1295/10395 [3:40:46<19:15:15,  7.62s/it] 12%|█▏        | 1296/10395 [3:40:54<19:44:09,  7.81s/it]                                                         {'loss': 0.9608, 'learning_rate': 1.953368873538134e-05, 'epoch': 0.12}
 12%|█▏        | 1296/10395 [3:40:54<19:44:09,  7.81s/it] 12%|█▏        | 1297/10395 [3:41:11<26:23:59, 10.45s/it]                                                         {'loss': 0.3683, 'learning_rate': 1.9532747921209126e-05, 'epoch': 0.12}
 12%|█▏        | 1297/10395 [3:41:11<26:23:59, 10.45s/it] 12%|█▏        | 1298/10395 [3:41:18<24:14:54,  9.60s/it]                                                         {'loss': 1.0674, 'learning_rate': 1.9531806181618112e-05, 'epoch': 0.12}
 12%|█▏        | 1298/10395 [3:41:18<24:14:54,  9.60s/it] 12%|█▏        | 1299/10395 [3:41:26<22:53:27,  9.06s/it]                                                         {'loss': 0.9718, 'learning_rate': 1.953086351669973e-05, 'epoch': 0.12}
 12%|█▏        | 1299/10395 [3:41:26<22:53:27,  9.06s/it] 13%|█▎        | 1300/10395 [3:41:34<21:47:18,  8.62s/it]                                                         {'loss': 0.9982, 'learning_rate': 1.952991992654548e-05, 'epoch': 0.13}
 13%|█▎        | 1300/10395 [3:41:34<21:47:18,  8.62s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 13%|█▎        | 1301/10395 [3:43:14<91:10:11, 36.09s/it]                                                         {'loss': 0.9999, 'learning_rate': 1.952897541124697e-05, 'epoch': 0.13}
 13%|█▎        | 1301/10395 [3:43:14<91:10:11, 36.09s/it] 13%|█▎        | 1302/10395 [3:43:21<69:18:25, 27.44s/it]                                                         {'loss': 1.0099, 'learning_rate': 1.9528029970895892e-05, 'epoch': 0.13}
 13%|█▎        | 1302/10395 [3:43:21<69:18:25, 27.44s/it] 13%|█▎        | 1303/10395 [3:43:29<54:42:05, 21.66s/it]                                                         {'loss': 1.0735, 'learning_rate': 1.9527083605584022e-05, 'epoch': 0.13}
 13%|█▎        | 1303/10395 [3:43:29<54:42:05, 21.66s/it] 13%|█▎        | 1304/10395 [3:43:37<43:57:56, 17.41s/it]                                                         {'loss': 0.9972, 'learning_rate': 1.9526136315403243e-05, 'epoch': 0.13}
 13%|█▎        | 1304/10395 [3:43:37<43:57:56, 17.41s/it] 13%|█▎        | 1305/10395 [3:43:45<36:38:59, 14.51s/it]                                                         {'loss': 0.9305, 'learning_rate': 1.95251881004455e-05, 'epoch': 0.13}
 13%|█▎        | 1305/10395 [3:43:45<36:38:59, 14.51s/it] 13%|█▎        | 1306/10395 [3:43:53<31:41:08, 12.55s/it]                                                         {'loss': 1.0253, 'learning_rate': 1.9524238960802854e-05, 'epoch': 0.13}
 13%|█▎        | 1306/10395 [3:43:53<31:41:08, 12.55s/it] 13%|█▎        | 1307/10395 [3:44:02<29:27:45, 11.67s/it]                                                         {'loss': 0.8749, 'learning_rate': 1.9523288896567445e-05, 'epoch': 0.13}
 13%|█▎        | 1307/10395 [3:44:02<29:27:45, 11.67s/it] 13%|█▎        | 1308/10395 [3:44:10<26:16:52, 10.41s/it]                                                         {'loss': 1.0176, 'learning_rate': 1.9522337907831497e-05, 'epoch': 0.13}
 13%|█▎        | 1308/10395 [3:44:10<26:16:52, 10.41s/it] 13%|█▎        | 1309/10395 [3:44:18<24:28:37,  9.70s/it]                                                         {'loss': 1.0569, 'learning_rate': 1.952138599468734e-05, 'epoch': 0.13}
 13%|█▎        | 1309/10395 [3:44:18<24:28:37,  9.70s/it] 13%|█▎        | 1310/10395 [3:44:35<30:19:25, 12.02s/it]                                                         {'loss': 0.3659, 'learning_rate': 1.9520433157227374e-05, 'epoch': 0.13}
 13%|█▎        | 1310/10395 [3:44:35<30:19:25, 12.02s/it] 13%|█▎        | 1311/10395 [3:44:43<26:50:58, 10.64s/it]                                                         {'loss': 0.9715, 'learning_rate': 1.9519479395544103e-05, 'epoch': 0.13}
 13%|█▎        | 1311/10395 [3:44:43<26:50:58, 10.64s/it] 13%|█▎        | 1312/10395 [3:44:50<24:35:48,  9.75s/it]                                                         {'loss': 0.9434, 'learning_rate': 1.9518524709730115e-05, 'epoch': 0.13}
 13%|█▎        | 1312/10395 [3:44:50<24:35:48,  9.75s/it] 13%|█▎        | 1313/10395 [3:44:58<22:45:58,  9.02s/it]                                                         {'loss': 0.9972, 'learning_rate': 1.9517569099878093e-05, 'epoch': 0.13}
 13%|█▎        | 1313/10395 [3:44:58<22:45:58,  9.02s/it] 13%|█▎        | 1314/10395 [3:45:05<21:54:24,  8.68s/it]                                                         {'loss': 1.025, 'learning_rate': 1.9516612566080797e-05, 'epoch': 0.13}
 13%|█▎        | 1314/10395 [3:45:05<21:54:24,  8.68s/it] 13%|█▎        | 1315/10395 [3:45:14<21:31:46,  8.54s/it]                                                         {'loss': 0.9846, 'learning_rate': 1.9515655108431094e-05, 'epoch': 0.13}
 13%|█▎        | 1315/10395 [3:45:14<21:31:46,  8.54s/it] 13%|█▎        | 1316/10395 [3:45:22<21:05:10,  8.36s/it]                                                         {'loss': 1.0354, 'learning_rate': 1.9514696727021925e-05, 'epoch': 0.13}
 13%|█▎        | 1316/10395 [3:45:22<21:05:10,  8.36s/it] 13%|█▎        | 1317/10395 [3:45:30<20:46:04,  8.24s/it]                                                         {'loss': 1.0663, 'learning_rate': 1.9513737421946332e-05, 'epoch': 0.13}
 13%|█▎        | 1317/10395 [3:45:30<20:46:04,  8.24s/it] 13%|█▎        | 1318/10395 [3:45:38<20:50:30,  8.27s/it]                                                         {'loss': 0.9717, 'learning_rate': 1.951277719329744e-05, 'epoch': 0.13}
 13%|█▎        | 1318/10395 [3:45:38<20:50:30,  8.27s/it] 13%|█▎        | 1319/10395 [3:45:46<20:46:01,  8.24s/it]                                                         {'loss': 1.0527, 'learning_rate': 1.951181604116847e-05, 'epoch': 0.13}
 13%|█▎        | 1319/10395 [3:45:46<20:46:01,  8.24s/it] 13%|█▎        | 1320/10395 [3:45:54<20:56:09,  8.31s/it]                                                         {'loss': 0.9666, 'learning_rate': 1.9510853965652723e-05, 'epoch': 0.13}
 13%|█▎        | 1320/10395 [3:45:54<20:56:09,  8.31s/it] 13%|█▎        | 1321/10395 [3:46:02<20:20:33,  8.07s/it]                                                         {'loss': 1.0054, 'learning_rate': 1.9509890966843596e-05, 'epoch': 0.13}
 13%|█▎        | 1321/10395 [3:46:02<20:20:33,  8.07s/it] 13%|█▎        | 1322/10395 [3:46:11<21:17:18,  8.45s/it]                                                         {'loss': 1.0036, 'learning_rate': 1.950892704483458e-05, 'epoch': 0.13}
 13%|█▎        | 1322/10395 [3:46:11<21:17:18,  8.45s/it] 13%|█▎        | 1323/10395 [3:46:19<20:28:34,  8.13s/it]                                                         {'loss': 0.9537, 'learning_rate': 1.9507962199719245e-05, 'epoch': 0.13}
 13%|█▎        | 1323/10395 [3:46:19<20:28:34,  8.13s/it] 13%|█▎        | 1324/10395 [3:46:36<27:32:46, 10.93s/it]                                                         {'loss': 0.3504, 'learning_rate': 1.950699643159126e-05, 'epoch': 0.13}
 13%|█▎        | 1324/10395 [3:46:36<27:32:46, 10.93s/it] 13%|█▎        | 1325/10395 [3:46:44<25:24:09, 10.08s/it]                                                         {'loss': 0.999, 'learning_rate': 1.9506029740544377e-05, 'epoch': 0.13}
 13%|█▎        | 1325/10395 [3:46:44<25:24:09, 10.08s/it] 13%|█▎        | 1326/10395 [3:46:52<23:32:29,  9.35s/it]                                                         {'loss': 1.0213, 'learning_rate': 1.9505062126672442e-05, 'epoch': 0.13}
 13%|█▎        | 1326/10395 [3:46:52<23:32:29,  9.35s/it] 13%|█▎        | 1327/10395 [3:46:59<22:10:28,  8.80s/it]                                                         {'loss': 0.941, 'learning_rate': 1.9504093590069385e-05, 'epoch': 0.13}
 13%|█▎        | 1327/10395 [3:46:59<22:10:28,  8.80s/it] 13%|█▎        | 1328/10395 [3:47:06<20:50:59,  8.28s/it]                                                         {'loss': 0.9681, 'learning_rate': 1.9503124130829238e-05, 'epoch': 0.13}
 13%|█▎        | 1328/10395 [3:47:07<20:50:59,  8.28s/it] 13%|█▎        | 1329/10395 [3:47:15<20:59:59,  8.34s/it]                                                         {'loss': 1.025, 'learning_rate': 1.9502153749046105e-05, 'epoch': 0.13}
 13%|█▎        | 1329/10395 [3:47:15<20:59:59,  8.34s/it] 13%|█▎        | 1330/10395 [3:47:23<20:31:21,  8.15s/it]                                                         {'loss': 0.9591, 'learning_rate': 1.9501182444814192e-05, 'epoch': 0.13}
 13%|█▎        | 1330/10395 [3:47:23<20:31:21,  8.15s/it] 13%|█▎        | 1331/10395 [3:47:31<20:35:56,  8.18s/it]                                                         {'loss': 0.9677, 'learning_rate': 1.9500210218227794e-05, 'epoch': 0.13}
 13%|█▎        | 1331/10395 [3:47:31<20:35:56,  8.18s/it] 13%|█▎        | 1332/10395 [3:47:40<21:08:17,  8.40s/it]                                                         {'loss': 0.995, 'learning_rate': 1.9499237069381288e-05, 'epoch': 0.13}
 13%|█▎        | 1332/10395 [3:47:40<21:08:17,  8.40s/it] 13%|█▎        | 1333/10395 [3:47:48<20:40:11,  8.21s/it]                                                         {'loss': 1.0624, 'learning_rate': 1.9498262998369148e-05, 'epoch': 0.13}
 13%|█▎        | 1333/10395 [3:47:48<20:40:11,  8.21s/it] 13%|█▎        | 1334/10395 [3:47:55<20:17:18,  8.06s/it]                                                         {'loss': 1.0529, 'learning_rate': 1.9497288005285934e-05, 'epoch': 0.13}
 13%|█▎        | 1334/10395 [3:47:55<20:17:18,  8.06s/it] 13%|█▎        | 1335/10395 [3:48:03<20:16:13,  8.05s/it]                                                         {'loss': 1.064, 'learning_rate': 1.9496312090226296e-05, 'epoch': 0.13}
 13%|█▎        | 1335/10395 [3:48:03<20:16:13,  8.05s/it] 13%|█▎        | 1336/10395 [3:48:12<20:26:41,  8.12s/it]                                                         {'loss': 1.0276, 'learning_rate': 1.9495335253284974e-05, 'epoch': 0.13}
 13%|█▎        | 1336/10395 [3:48:12<20:26:41,  8.12s/it] 13%|█▎        | 1337/10395 [3:48:20<20:37:28,  8.20s/it]                                                         {'loss': 0.9906, 'learning_rate': 1.9494357494556798e-05, 'epoch': 0.13}
 13%|█▎        | 1337/10395 [3:48:20<20:37:28,  8.20s/it] 13%|█▎        | 1338/10395 [3:48:29<21:33:10,  8.57s/it]                                                         {'loss': 0.9692, 'learning_rate': 1.9493378814136683e-05, 'epoch': 0.13}
 13%|█▎        | 1338/10395 [3:48:29<21:33:10,  8.57s/it] 13%|█▎        | 1339/10395 [3:48:38<21:34:52,  8.58s/it]                                                         {'loss': 1.069, 'learning_rate': 1.9492399212119643e-05, 'epoch': 0.13}
 13%|█▎        | 1339/10395 [3:48:38<21:34:52,  8.58s/it] 13%|█▎        | 1340/10395 [3:48:46<20:57:03,  8.33s/it]                                                         {'loss': 1.0102, 'learning_rate': 1.949141868860077e-05, 'epoch': 0.13}
 13%|█▎        | 1340/10395 [3:48:46<20:57:03,  8.33s/it] 13%|█▎        | 1341/10395 [3:49:04<28:20:55, 11.27s/it]                                                         {'loss': 0.3593, 'learning_rate': 1.949043724367526e-05, 'epoch': 0.13}
 13%|█▎        | 1341/10395 [3:49:04<28:20:55, 11.27s/it] 13%|█▎        | 1342/10395 [3:49:11<25:30:20, 10.14s/it]                                                         {'loss': 1.0334, 'learning_rate': 1.9489454877438375e-05, 'epoch': 0.13}
 13%|█▎        | 1342/10395 [3:49:11<25:30:20, 10.14s/it] 13%|█▎        | 1343/10395 [3:49:19<23:23:27,  9.30s/it]                                                         {'loss': 1.0791, 'learning_rate': 1.9488471589985494e-05, 'epoch': 0.13}
 13%|█▎        | 1343/10395 [3:49:19<23:23:27,  9.30s/it] 13%|█▎        | 1344/10395 [3:49:26<21:45:19,  8.65s/it]                                                         {'loss': 1.0035, 'learning_rate': 1.9487487381412065e-05, 'epoch': 0.13}
 13%|█▎        | 1344/10395 [3:49:26<21:45:19,  8.65s/it] 13%|█▎        | 1345/10395 [3:49:33<20:51:04,  8.29s/it]                                                         {'loss': 0.993, 'learning_rate': 1.948650225181364e-05, 'epoch': 0.13}
 13%|█▎        | 1345/10395 [3:49:33<20:51:04,  8.29s/it] 13%|█▎        | 1346/10395 [3:49:41<20:32:26,  8.17s/it]                                                         {'loss': 0.9867, 'learning_rate': 1.948551620128585e-05, 'epoch': 0.13}
 13%|█▎        | 1346/10395 [3:49:41<20:32:26,  8.17s/it] 13%|█▎        | 1347/10395 [3:49:49<20:11:25,  8.03s/it]                                                         {'loss': 0.93, 'learning_rate': 1.9484529229924416e-05, 'epoch': 0.13}
 13%|█▎        | 1347/10395 [3:49:49<20:11:25,  8.03s/it] 13%|█▎        | 1348/10395 [3:49:56<19:29:49,  7.76s/it]                                                         {'loss': 0.965, 'learning_rate': 1.9483541337825152e-05, 'epoch': 0.13}
 13%|█▎        | 1348/10395 [3:49:56<19:29:49,  7.76s/it] 13%|█▎        | 1349/10395 [3:50:03<19:10:29,  7.63s/it]                                                         {'loss': 1.0044, 'learning_rate': 1.948255252508396e-05, 'epoch': 0.13}
 13%|█▎        | 1349/10395 [3:50:03<19:10:29,  7.63s/it] 13%|█▎        | 1350/10395 [3:50:11<19:19:20,  7.69s/it]                                                         {'loss': 1.0349, 'learning_rate': 1.9481562791796834e-05, 'epoch': 0.13}
 13%|█▎        | 1350/10395 [3:50:11<19:19:20,  7.69s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 13%|█▎        | 1351/10395 [3:51:53<90:24:29, 35.99s/it]                                                         {'loss': 1.009, 'learning_rate': 1.948057213805986e-05, 'epoch': 0.13}
 13%|█▎        | 1351/10395 [3:51:53<90:24:29, 35.99s/it] 13%|█▎        | 1352/10395 [3:52:01<69:09:56, 27.53s/it]                                                         {'loss': 0.9671, 'learning_rate': 1.9479580563969194e-05, 'epoch': 0.13}
 13%|█▎        | 1352/10395 [3:52:01<69:09:56, 27.53s/it] 13%|█▎        | 1353/10395 [3:52:08<53:58:21, 21.49s/it]                                                         {'loss': 1.0318, 'learning_rate': 1.947858806962111e-05, 'epoch': 0.13}
 13%|█▎        | 1353/10395 [3:52:08<53:58:21, 21.49s/it] 13%|█▎        | 1354/10395 [3:52:16<43:22:25, 17.27s/it]                                                         {'loss': 0.9767, 'learning_rate': 1.9477594655111953e-05, 'epoch': 0.13}
 13%|█▎        | 1354/10395 [3:52:16<43:22:25, 17.27s/it] 13%|█▎        | 1355/10395 [3:52:24<36:10:39, 14.41s/it]                                                         {'loss': 0.9734, 'learning_rate': 1.9476600320538158e-05, 'epoch': 0.13}
 13%|█▎        | 1355/10395 [3:52:24<36:10:39, 14.41s/it] 13%|█▎        | 1356/10395 [3:52:31<30:50:29, 12.28s/it]                                                         {'loss': 0.9677, 'learning_rate': 1.9475605065996258e-05, 'epoch': 0.13}
 13%|█▎        | 1356/10395 [3:52:31<30:50:29, 12.28s/it] 13%|█▎        | 1357/10395 [3:52:49<34:59:26, 13.94s/it]                                                         {'loss': 0.3608, 'learning_rate': 1.9474608891582862e-05, 'epoch': 0.13}
 13%|█▎        | 1357/10395 [3:52:49<34:59:26, 13.94s/it] 13%|█▎        | 1358/10395 [3:52:57<31:02:53, 12.37s/it]                                                         {'loss': 1.0331, 'learning_rate': 1.9473611797394688e-05, 'epoch': 0.13}
 13%|█▎        | 1358/10395 [3:52:57<31:02:53, 12.37s/it] 13%|█▎        | 1359/10395 [3:53:05<27:09:11, 10.82s/it]                                                         {'loss': 1.0285, 'learning_rate': 1.9472613783528522e-05, 'epoch': 0.13}
 13%|█▎        | 1359/10395 [3:53:05<27:09:11, 10.82s/it] 13%|█▎        | 1360/10395 [3:53:13<25:02:28,  9.98s/it]                                                         {'loss': 1.0053, 'learning_rate': 1.9471614850081256e-05, 'epoch': 0.13}
 13%|█▎        | 1360/10395 [3:53:13<25:02:28,  9.98s/it] 13%|█▎        | 1361/10395 [3:53:20<23:16:27,  9.27s/it]                                                         {'loss': 1.0027, 'learning_rate': 1.947061499714986e-05, 'epoch': 0.13}
 13%|█▎        | 1361/10395 [3:53:20<23:16:27,  9.27s/it] 13%|█▎        | 1362/10395 [3:53:28<21:44:27,  8.66s/it]                                                         {'loss': 1.0388, 'learning_rate': 1.9469614224831397e-05, 'epoch': 0.13}
 13%|█▎        | 1362/10395 [3:53:28<21:44:27,  8.66s/it] 13%|█▎        | 1363/10395 [3:53:36<21:35:06,  8.60s/it]                                                         {'loss': 0.9734, 'learning_rate': 1.9468612533223024e-05, 'epoch': 0.13}
 13%|█▎        | 1363/10395 [3:53:36<21:35:06,  8.60s/it] 13%|█▎        | 1364/10395 [3:53:43<20:37:17,  8.22s/it]                                                         {'loss': 0.9432, 'learning_rate': 1.946760992242198e-05, 'epoch': 0.13}
 13%|█▎        | 1364/10395 [3:53:43<20:37:17,  8.22s/it] 13%|█▎        | 1365/10395 [3:53:51<20:05:58,  8.01s/it]                                                         {'loss': 0.983, 'learning_rate': 1.9466606392525595e-05, 'epoch': 0.13}
 13%|█▎        | 1365/10395 [3:53:51<20:05:58,  8.01s/it] 13%|█▎        | 1366/10395 [3:53:59<20:25:32,  8.14s/it]                                                         {'loss': 0.8995, 'learning_rate': 1.9465601943631297e-05, 'epoch': 0.13}
 13%|█▎        | 1366/10395 [3:53:59<20:25:32,  8.14s/it] 13%|█▎        | 1367/10395 [3:54:07<20:09:08,  8.04s/it]                                                         {'loss': 1.0136, 'learning_rate': 1.9464596575836588e-05, 'epoch': 0.13}
 13%|█▎        | 1367/10395 [3:54:07<20:09:08,  8.04s/it] 13%|█▎        | 1368/10395 [3:54:15<19:46:23,  7.89s/it]                                                         {'loss': 1.0077, 'learning_rate': 1.946359028923907e-05, 'epoch': 0.13}
 13%|█▎        | 1368/10395 [3:54:15<19:46:23,  7.89s/it] 13%|█▎        | 1369/10395 [3:54:22<19:27:21,  7.76s/it]                                                         {'loss': 1.0433, 'learning_rate': 1.9462583083936427e-05, 'epoch': 0.13}
 13%|█▎        | 1369/10395 [3:54:22<19:27:21,  7.76s/it] 13%|█▎        | 1370/10395 [3:54:29<18:55:53,  7.55s/it]                                                         {'loss': 1.0824, 'learning_rate': 1.946157496002644e-05, 'epoch': 0.13}
 13%|█▎        | 1370/10395 [3:54:29<18:55:53,  7.55s/it] 13%|█▎        | 1371/10395 [3:54:37<19:27:17,  7.76s/it]                                                         {'loss': 1.0072, 'learning_rate': 1.9460565917606976e-05, 'epoch': 0.13}
 13%|█▎        | 1371/10395 [3:54:37<19:27:17,  7.76s/it] 13%|█▎        | 1372/10395 [3:54:47<20:47:36,  8.30s/it]                                                         {'loss': 0.9517, 'learning_rate': 1.9459555956775992e-05, 'epoch': 0.13}
 13%|█▎        | 1372/10395 [3:54:47<20:47:36,  8.30s/it] 13%|█▎        | 1373/10395 [3:54:54<20:10:45,  8.05s/it]                                                         {'loss': 1.0154, 'learning_rate': 1.9458545077631532e-05, 'epoch': 0.13}
 13%|█▎        | 1373/10395 [3:54:54<20:10:45,  8.05s/it] 13%|█▎        | 1374/10395 [3:55:02<19:48:54,  7.91s/it]                                                         {'loss': 0.9867, 'learning_rate': 1.9457533280271725e-05, 'epoch': 0.13}
 13%|█▎        | 1374/10395 [3:55:02<19:48:54,  7.91s/it] 13%|█▎        | 1375/10395 [3:55:10<19:38:56,  7.84s/it]                                                         {'loss': 0.9094, 'learning_rate': 1.9456520564794797e-05, 'epoch': 0.13}
 13%|█▎        | 1375/10395 [3:55:10<19:38:56,  7.84s/it] 13%|█▎        | 1376/10395 [3:55:19<20:22:04,  8.13s/it]                                                         {'loss': 1.0181, 'learning_rate': 1.9455506931299068e-05, 'epoch': 0.13}
 13%|█▎        | 1376/10395 [3:55:19<20:22:04,  8.13s/it] 13%|█▎        | 1377/10395 [3:55:26<19:55:31,  7.95s/it]                                                         {'loss': 0.9372, 'learning_rate': 1.9454492379882926e-05, 'epoch': 0.13}
 13%|█▎        | 1377/10395 [3:55:26<19:55:31,  7.95s/it] 13%|█▎        | 1378/10395 [3:55:35<20:23:40,  8.14s/it]                                                         {'loss': 0.946, 'learning_rate': 1.945347691064487e-05, 'epoch': 0.13}
 13%|█▎        | 1378/10395 [3:55:35<20:23:40,  8.14s/it] 13%|█▎        | 1379/10395 [3:55:42<20:00:12,  7.99s/it]                                                         {'loss': 0.9928, 'learning_rate': 1.945246052368348e-05, 'epoch': 0.13}
 13%|█▎        | 1379/10395 [3:55:42<20:00:12,  7.99s/it] 13%|█▎        | 1380/10395 [3:55:50<19:37:41,  7.84s/it]                                                         {'loss': 1.0195, 'learning_rate': 1.945144321909742e-05, 'epoch': 0.13}
 13%|█▎        | 1380/10395 [3:55:50<19:37:41,  7.84s/it] 13%|█▎        | 1381/10395 [3:55:57<19:10:30,  7.66s/it]                                                         {'loss': 1.0339, 'learning_rate': 1.945042499698545e-05, 'epoch': 0.13}
 13%|█▎        | 1381/10395 [3:55:57<19:10:30,  7.66s/it] 13%|█▎        | 1382/10395 [3:56:04<19:00:55,  7.60s/it]                                                         {'loss': 0.9427, 'learning_rate': 1.9449405857446422e-05, 'epoch': 0.13}
 13%|█▎        | 1382/10395 [3:56:04<19:00:55,  7.60s/it] 13%|█▎        | 1383/10395 [3:56:13<19:39:04,  7.85s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.9448385800579262e-05, 'epoch': 0.13}
 13%|█▎        | 1383/10395 [3:56:13<19:39:04,  7.85s/it] 13%|█▎        | 1384/10395 [3:56:21<19:48:32,  7.91s/it]                                                         {'loss': 0.9803, 'learning_rate': 1.9447364826483e-05, 'epoch': 0.13}
 13%|█▎        | 1384/10395 [3:56:21<19:48:32,  7.91s/it] 13%|█▎        | 1385/10395 [3:56:29<19:41:31,  7.87s/it]                                                         {'loss': 1.0371, 'learning_rate': 1.9446342935256747e-05, 'epoch': 0.13}
 13%|█▎        | 1385/10395 [3:56:29<19:41:31,  7.87s/it] 13%|█▎        | 1386/10395 [3:56:36<19:10:00,  7.66s/it]                                                         {'loss': 1.1254, 'learning_rate': 1.9445320126999715e-05, 'epoch': 0.13}
 13%|█▎        | 1386/10395 [3:56:36<19:10:00,  7.66s/it] 13%|█▎        | 1387/10395 [3:56:44<19:16:03,  7.70s/it]                                                         {'loss': 0.9805, 'learning_rate': 1.9444296401811185e-05, 'epoch': 0.13}
 13%|█▎        | 1387/10395 [3:56:44<19:16:03,  7.70s/it] 13%|█▎        | 1388/10395 [3:56:51<19:13:35,  7.68s/it]                                                         {'loss': 0.9745, 'learning_rate': 1.9443271759790544e-05, 'epoch': 0.13}
 13%|█▎        | 1388/10395 [3:56:51<19:13:35,  7.68s/it] 13%|█▎        | 1389/10395 [3:57:09<26:50:33, 10.73s/it]                                                         {'loss': 0.332, 'learning_rate': 1.9442246201037264e-05, 'epoch': 0.13}
 13%|█▎        | 1389/10395 [3:57:09<26:50:33, 10.73s/it] 13%|█▎        | 1390/10395 [3:57:17<24:24:01,  9.75s/it]                                                         {'loss': 0.9857, 'learning_rate': 1.9441219725650895e-05, 'epoch': 0.13}
 13%|█▎        | 1390/10395 [3:57:17<24:24:01,  9.75s/it] 13%|█▎        | 1391/10395 [3:57:24<22:48:56,  9.12s/it]                                                         {'loss': 0.9831, 'learning_rate': 1.9440192333731095e-05, 'epoch': 0.13}
 13%|█▎        | 1391/10395 [3:57:24<22:48:56,  9.12s/it] 13%|█▎        | 1392/10395 [3:57:31<21:20:23,  8.53s/it]                                                         {'loss': 1.065, 'learning_rate': 1.94391640253776e-05, 'epoch': 0.13}
 13%|█▎        | 1392/10395 [3:57:31<21:20:23,  8.53s/it] 13%|█▎        | 1393/10395 [3:57:39<20:32:34,  8.22s/it]                                                         {'loss': 0.9506, 'learning_rate': 1.9438134800690225e-05, 'epoch': 0.13}
 13%|█▎        | 1393/10395 [3:57:39<20:32:34,  8.22s/it] 13%|█▎        | 1394/10395 [3:57:47<20:21:02,  8.14s/it]                                                         {'loss': 0.9943, 'learning_rate': 1.94371046597689e-05, 'epoch': 0.13}
 13%|█▎        | 1394/10395 [3:57:47<20:21:02,  8.14s/it] 13%|█▎        | 1395/10395 [3:58:03<26:35:14, 10.63s/it]                                                         {'loss': 0.3541, 'learning_rate': 1.9436073602713617e-05, 'epoch': 0.13}
 13%|█▎        | 1395/10395 [3:58:03<26:35:14, 10.63s/it] 13%|█▎        | 1396/10395 [3:58:12<24:50:16,  9.94s/it]                                                         {'loss': 0.9747, 'learning_rate': 1.9435041629624477e-05, 'epoch': 0.13}
 13%|█▎        | 1396/10395 [3:58:12<24:50:16,  9.94s/it] 13%|█▎        | 1397/10395 [3:58:19<22:47:58,  9.12s/it]                                                         {'loss': 0.9895, 'learning_rate': 1.9434008740601654e-05, 'epoch': 0.13}
 13%|█▎        | 1397/10395 [3:58:19<22:47:58,  9.12s/it] 13%|█▎        | 1398/10395 [3:58:27<22:00:11,  8.80s/it]                                                         {'loss': 1.0616, 'learning_rate': 1.9432974935745426e-05, 'epoch': 0.13}
 13%|█▎        | 1398/10395 [3:58:27<22:00:11,  8.80s/it] 13%|█▎        | 1399/10395 [3:58:35<21:10:08,  8.47s/it]                                                         {'loss': 1.0111, 'learning_rate': 1.9431940215156152e-05, 'epoch': 0.13}
 13%|█▎        | 1399/10395 [3:58:35<21:10:08,  8.47s/it] 13%|█▎        | 1400/10395 [3:58:44<21:33:09,  8.63s/it]                                                         {'loss': 0.9456, 'learning_rate': 1.9430904578934275e-05, 'epoch': 0.13}
 13%|█▎        | 1400/10395 [3:58:44<21:33:09,  8.63s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 13%|█▎        | 1401/10395 [4:00:24<90:05:57, 36.06s/it]                                                         {'loss': 1.0334, 'learning_rate': 1.9429868027180333e-05, 'epoch': 0.13}
 13%|█▎        | 1401/10395 [4:00:24<90:05:57, 36.06s/it] 13%|█▎        | 1402/10395 [4:00:34<70:39:58, 28.29s/it]                                                         {'loss': 0.9466, 'learning_rate': 1.942883055999496e-05, 'epoch': 0.13}
 13%|█▎        | 1402/10395 [4:00:34<70:39:58, 28.29s/it] 13%|█▎        | 1403/10395 [4:00:41<55:04:55, 22.05s/it]                                                         {'loss': 1.0599, 'learning_rate': 1.9427792177478863e-05, 'epoch': 0.13}
 13%|█▎        | 1403/10395 [4:00:41<55:04:55, 22.05s/it] 14%|█▎        | 1404/10395 [4:00:59<51:56:09, 20.80s/it]                                                         {'loss': 0.3546, 'learning_rate': 1.9426752879732848e-05, 'epoch': 0.14}
 14%|█▎        | 1404/10395 [4:00:59<51:56:09, 20.80s/it] 14%|█▎        | 1405/10395 [4:01:07<42:21:54, 16.96s/it]                                                         {'loss': 1.0059, 'learning_rate': 1.942571266685781e-05, 'epoch': 0.14}
 14%|█▎        | 1405/10395 [4:01:07<42:21:54, 16.96s/it] 14%|█▎        | 1406/10395 [4:01:15<35:47:23, 14.33s/it]                                                         {'loss': 1.0526, 'learning_rate': 1.9424671538954726e-05, 'epoch': 0.14}
 14%|█▎        | 1406/10395 [4:01:15<35:47:23, 14.33s/it] 14%|█▎        | 1407/10395 [4:01:24<31:12:45, 12.50s/it]                                                         {'loss': 1.0491, 'learning_rate': 1.9423629496124674e-05, 'epoch': 0.14}
 14%|█▎        | 1407/10395 [4:01:24<31:12:45, 12.50s/it] 14%|█▎        | 1408/10395 [4:01:32<27:51:23, 11.16s/it]                                                         {'loss': 1.0113, 'learning_rate': 1.9422586538468807e-05, 'epoch': 0.14}
 14%|█▎        | 1408/10395 [4:01:32<27:51:23, 11.16s/it] 14%|█▎        | 1409/10395 [4:01:40<25:23:52, 10.18s/it]                                                         {'loss': 0.9856, 'learning_rate': 1.9421542666088375e-05, 'epoch': 0.14}
 14%|█▎        | 1409/10395 [4:01:40<25:23:52, 10.18s/it] 14%|█▎        | 1410/10395 [4:01:48<23:50:51,  9.56s/it]                                                         {'loss': 1.0171, 'learning_rate': 1.9420497879084715e-05, 'epoch': 0.14}
 14%|█▎        | 1410/10395 [4:01:48<23:50:51,  9.56s/it] 14%|█▎        | 1411/10395 [4:01:55<22:24:58,  8.98s/it]                                                         {'loss': 0.9383, 'learning_rate': 1.9419452177559252e-05, 'epoch': 0.14}
 14%|█▎        | 1411/10395 [4:01:55<22:24:58,  8.98s/it] 14%|█▎        | 1412/10395 [4:02:04<22:16:15,  8.93s/it]                                                         {'loss': 1.024, 'learning_rate': 1.94184055616135e-05, 'epoch': 0.14}
 14%|█▎        | 1412/10395 [4:02:04<22:16:15,  8.93s/it] 14%|█▎        | 1413/10395 [4:02:12<21:10:40,  8.49s/it]                                                         {'loss': 0.9733, 'learning_rate': 1.941735803134907e-05, 'epoch': 0.14}
 14%|█▎        | 1413/10395 [4:02:12<21:10:40,  8.49s/it] 14%|█▎        | 1414/10395 [4:02:30<28:27:10, 11.41s/it]                                                         {'loss': 0.3575, 'learning_rate': 1.941630958686764e-05, 'epoch': 0.14}
 14%|█▎        | 1414/10395 [4:02:30<28:27:10, 11.41s/it] 14%|█▎        | 1415/10395 [4:02:38<25:50:49, 10.36s/it]                                                         {'loss': 1.0636, 'learning_rate': 1.9415260228271e-05, 'epoch': 0.14}
 14%|█▎        | 1415/10395 [4:02:38<25:50:49, 10.36s/it] 14%|█▎        | 1416/10395 [4:02:54<30:33:39, 12.25s/it]                                                         {'loss': 0.3336, 'learning_rate': 1.9414209955661015e-05, 'epoch': 0.14}
 14%|█▎        | 1416/10395 [4:02:54<30:33:39, 12.25s/it] 14%|█▎        | 1417/10395 [4:03:02<27:18:36, 10.95s/it]                                                         {'loss': 1.0453, 'learning_rate': 1.941315876913965e-05, 'epoch': 0.14}
 14%|█▎        | 1417/10395 [4:03:02<27:18:36, 10.95s/it] 14%|█▎        | 1418/10395 [4:03:11<25:19:15, 10.15s/it]                                                         {'loss': 0.9899, 'learning_rate': 1.9412106668808944e-05, 'epoch': 0.14}
 14%|█▎        | 1418/10395 [4:03:11<25:19:15, 10.15s/it] 14%|█▎        | 1419/10395 [4:03:18<23:19:54,  9.36s/it]                                                         {'loss': 1.0635, 'learning_rate': 1.941105365477104e-05, 'epoch': 0.14}
 14%|█▎        | 1419/10395 [4:03:18<23:19:54,  9.36s/it] 14%|█▎        | 1420/10395 [4:03:26<22:15:52,  8.93s/it]                                                         {'loss': 1.0261, 'learning_rate': 1.9409999727128155e-05, 'epoch': 0.14}
 14%|█▎        | 1420/10395 [4:03:26<22:15:52,  8.93s/it] 14%|█▎        | 1421/10395 [4:03:34<21:47:01,  8.74s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.940894488598261e-05, 'epoch': 0.14}
 14%|█▎        | 1421/10395 [4:03:34<21:47:01,  8.74s/it] 14%|█▎        | 1422/10395 [4:03:42<20:56:10,  8.40s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.94078891314368e-05, 'epoch': 0.14}
 14%|█▎        | 1422/10395 [4:03:42<20:56:10,  8.40s/it] 14%|█▎        | 1423/10395 [4:03:49<20:07:37,  8.08s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.9406832463593217e-05, 'epoch': 0.14}
 14%|█▎        | 1423/10395 [4:03:49<20:07:37,  8.08s/it] 14%|█▎        | 1424/10395 [4:03:58<20:20:21,  8.16s/it]                                                         {'loss': 0.9565, 'learning_rate': 1.940577488255444e-05, 'epoch': 0.14}
 14%|█▎        | 1424/10395 [4:03:58<20:20:21,  8.16s/it] 14%|█▎        | 1425/10395 [4:04:05<19:38:18,  7.88s/it]                                                         {'loss': 1.0182, 'learning_rate': 1.940471638842314e-05, 'epoch': 0.14}
 14%|█▎        | 1425/10395 [4:04:05<19:38:18,  7.88s/it] 14%|█▎        | 1426/10395 [4:04:13<19:53:20,  7.98s/it]                                                         {'loss': 0.982, 'learning_rate': 1.940365698130207e-05, 'epoch': 0.14}
 14%|█▎        | 1426/10395 [4:04:13<19:53:20,  7.98s/it] 14%|█▎        | 1427/10395 [4:04:21<19:43:02,  7.92s/it]                                                         {'loss': 0.9929, 'learning_rate': 1.940259666129408e-05, 'epoch': 0.14}
 14%|█▎        | 1427/10395 [4:04:21<19:43:02,  7.92s/it] 14%|█▎        | 1428/10395 [4:04:29<20:17:16,  8.15s/it]                                                         {'loss': 0.9673, 'learning_rate': 1.9401535428502096e-05, 'epoch': 0.14}
 14%|█▎        | 1428/10395 [4:04:29<20:17:16,  8.15s/it] 14%|█▎        | 1429/10395 [4:04:37<19:53:29,  7.99s/it]                                                         {'loss': 0.9638, 'learning_rate': 1.9400473283029142e-05, 'epoch': 0.14}
 14%|█▎        | 1429/10395 [4:04:37<19:53:29,  7.99s/it] 14%|█▍        | 1430/10395 [4:04:45<19:38:43,  7.89s/it]                                                         {'loss': 1.0475, 'learning_rate': 1.939941022497833e-05, 'epoch': 0.14}
 14%|█▍        | 1430/10395 [4:04:45<19:38:43,  7.89s/it] 14%|█▍        | 1431/10395 [4:04:52<19:28:52,  7.82s/it]                                                         {'loss': 0.9924, 'learning_rate': 1.9398346254452864e-05, 'epoch': 0.14}
 14%|█▍        | 1431/10395 [4:04:52<19:28:52,  7.82s/it] 14%|█▍        | 1432/10395 [4:05:01<19:53:30,  7.99s/it]                                                         {'loss': 0.9697, 'learning_rate': 1.9397281371556026e-05, 'epoch': 0.14}
 14%|█▍        | 1432/10395 [4:05:01<19:53:30,  7.99s/it] 14%|█▍        | 1433/10395 [4:05:09<20:08:18,  8.09s/it]                                                         {'loss': 0.9843, 'learning_rate': 1.9396215576391196e-05, 'epoch': 0.14}
 14%|█▍        | 1433/10395 [4:05:09<20:08:18,  8.09s/it] 14%|█▍        | 1434/10395 [4:05:17<20:09:54,  8.10s/it]                                                         {'loss': 0.9963, 'learning_rate': 1.9395148869061836e-05, 'epoch': 0.14}
 14%|█▍        | 1434/10395 [4:05:17<20:09:54,  8.10s/it] 14%|█▍        | 1435/10395 [4:05:25<19:53:51,  7.99s/it]                                                         {'loss': 0.9858, 'learning_rate': 1.9394081249671502e-05, 'epoch': 0.14}
 14%|█▍        | 1435/10395 [4:05:25<19:53:51,  7.99s/it] 14%|█▍        | 1436/10395 [4:05:33<19:42:06,  7.92s/it]                                                         {'loss': 1.0117, 'learning_rate': 1.9393012718323833e-05, 'epoch': 0.14}
 14%|█▍        | 1436/10395 [4:05:33<19:42:06,  7.92s/it] 14%|█▍        | 1437/10395 [4:05:50<26:42:35, 10.73s/it]                                                         {'loss': 0.3533, 'learning_rate': 1.9391943275122567e-05, 'epoch': 0.14}
 14%|█▍        | 1437/10395 [4:05:50<26:42:35, 10.73s/it] 14%|█▍        | 1438/10395 [4:05:58<24:15:30,  9.75s/it]                                                         {'loss': 1.0292, 'learning_rate': 1.9390872920171512e-05, 'epoch': 0.14}
 14%|█▍        | 1438/10395 [4:05:58<24:15:30,  9.75s/it] 14%|█▍        | 1439/10395 [4:06:05<22:15:57,  8.95s/it]                                                         {'loss': 1.092, 'learning_rate': 1.9389801653574588e-05, 'epoch': 0.14}
 14%|█▍        | 1439/10395 [4:06:05<22:15:57,  8.95s/it] 14%|█▍        | 1440/10395 [4:06:13<21:33:51,  8.67s/it]                                                         {'loss': 0.9417, 'learning_rate': 1.9388729475435784e-05, 'epoch': 0.14}
 14%|█▍        | 1440/10395 [4:06:13<21:33:51,  8.67s/it] 14%|█▍        | 1441/10395 [4:06:20<20:45:46,  8.35s/it]                                                         {'loss': 1.0348, 'learning_rate': 1.9387656385859185e-05, 'epoch': 0.14}
 14%|█▍        | 1441/10395 [4:06:20<20:45:46,  8.35s/it] 14%|█▍        | 1442/10395 [4:06:28<20:30:53,  8.25s/it]                                                         {'loss': 1.0562, 'learning_rate': 1.9386582384948965e-05, 'epoch': 0.14}
 14%|█▍        | 1442/10395 [4:06:28<20:30:53,  8.25s/it] 14%|█▍        | 1443/10395 [4:06:38<21:55:58,  8.82s/it]                                                         {'loss': 0.9193, 'learning_rate': 1.938550747280939e-05, 'epoch': 0.14}
 14%|█▍        | 1443/10395 [4:06:38<21:55:58,  8.82s/it] 14%|█▍        | 1444/10395 [4:06:48<22:46:08,  9.16s/it]                                                         {'loss': 0.9476, 'learning_rate': 1.9384431649544805e-05, 'epoch': 0.14}
 14%|█▍        | 1444/10395 [4:06:48<22:46:08,  9.16s/it] 14%|█▍        | 1445/10395 [4:06:56<21:26:56,  8.63s/it]                                                         {'loss': 1.043, 'learning_rate': 1.9383354915259648e-05, 'epoch': 0.14}
 14%|█▍        | 1445/10395 [4:06:56<21:26:56,  8.63s/it] 14%|█▍        | 1446/10395 [4:07:03<20:37:12,  8.30s/it]                                                         {'loss': 0.965, 'learning_rate': 1.938227727005845e-05, 'epoch': 0.14}
 14%|█▍        | 1446/10395 [4:07:03<20:37:12,  8.30s/it] 14%|█▍        | 1447/10395 [4:07:11<20:02:36,  8.06s/it]                                                         {'loss': 1.0204, 'learning_rate': 1.9381198714045825e-05, 'epoch': 0.14}
 14%|█▍        | 1447/10395 [4:07:11<20:02:36,  8.06s/it] 14%|█▍        | 1448/10395 [4:07:19<20:13:40,  8.14s/it]                                                         {'loss': 1.0151, 'learning_rate': 1.9380119247326475e-05, 'epoch': 0.14}
 14%|█▍        | 1448/10395 [4:07:19<20:13:40,  8.14s/it] 14%|█▍        | 1449/10395 [4:07:27<20:00:31,  8.05s/it]                                                         {'loss': 0.8979, 'learning_rate': 1.9379038870005195e-05, 'epoch': 0.14}
 14%|█▍        | 1449/10395 [4:07:27<20:00:31,  8.05s/it] 14%|█▍        | 1450/10395 [4:07:35<19:54:53,  8.01s/it]                                                         {'loss': 0.922, 'learning_rate': 1.9377957582186862e-05, 'epoch': 0.14}
 14%|█▍        | 1450/10395 [4:07:35<19:54:53,  8.01s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 14%|█▍        | 1451/10395 [4:09:17<89:50:30, 36.16s/it]                                                         {'loss': 0.9758, 'learning_rate': 1.937687538397645e-05, 'epoch': 0.14}
 14%|█▍        | 1451/10395 [4:09:17<89:50:30, 36.16s/it] 14%|█▍        | 1452/10395 [4:09:25<68:46:07, 27.68s/it]                                                         {'loss': 0.9473, 'learning_rate': 1.9375792275479014e-05, 'epoch': 0.14}
 14%|█▍        | 1452/10395 [4:09:25<68:46:07, 27.68s/it] 14%|█▍        | 1453/10395 [4:09:42<61:18:08, 24.68s/it]                                                         {'loss': 0.3511, 'learning_rate': 1.9374708256799703e-05, 'epoch': 0.14}
 14%|█▍        | 1453/10395 [4:09:42<61:18:08, 24.68s/it] 14%|█▍        | 1454/10395 [4:09:50<48:39:31, 19.59s/it]                                                         {'loss': 1.0465, 'learning_rate': 1.937362332804374e-05, 'epoch': 0.14}
 14%|█▍        | 1454/10395 [4:09:50<48:39:31, 19.59s/it] 14%|█▍        | 1455/10395 [4:09:58<39:49:23, 16.04s/it]                                                         {'loss': 0.977, 'learning_rate': 1.9372537489316462e-05, 'epoch': 0.14}
 14%|█▍        | 1455/10395 [4:09:58<39:49:23, 16.04s/it] 14%|█▍        | 1456/10395 [4:10:05<33:20:22, 13.43s/it]                                                         {'loss': 1.0571, 'learning_rate': 1.937145074072327e-05, 'epoch': 0.14}
 14%|█▍        | 1456/10395 [4:10:05<33:20:22, 13.43s/it] 14%|█▍        | 1457/10395 [4:10:14<29:44:56, 11.98s/it]                                                         {'loss': 0.9019, 'learning_rate': 1.937036308236967e-05, 'epoch': 0.14}
 14%|█▍        | 1457/10395 [4:10:14<29:44:56, 11.98s/it] 14%|█▍        | 1458/10395 [4:10:21<26:36:28, 10.72s/it]                                                         {'loss': 1.0039, 'learning_rate': 1.936927451436125e-05, 'epoch': 0.14}
 14%|█▍        | 1458/10395 [4:10:21<26:36:28, 10.72s/it] 14%|█▍        | 1459/10395 [4:10:29<24:35:14,  9.91s/it]                                                         {'loss': 0.9292, 'learning_rate': 1.9368185036803677e-05, 'epoch': 0.14}
 14%|█▍        | 1459/10395 [4:10:29<24:35:14,  9.91s/it] 14%|█▍        | 1460/10395 [4:10:38<23:24:13,  9.43s/it]                                                         {'loss': 1.0239, 'learning_rate': 1.936709464980272e-05, 'epoch': 0.14}
 14%|█▍        | 1460/10395 [4:10:38<23:24:13,  9.43s/it] 14%|█▍        | 1461/10395 [4:10:45<22:07:30,  8.92s/it]                                                         {'loss': 1.006, 'learning_rate': 1.9366003353464235e-05, 'epoch': 0.14}
 14%|█▍        | 1461/10395 [4:10:45<22:07:30,  8.92s/it] 14%|█▍        | 1462/10395 [4:10:55<22:12:41,  8.95s/it]                                                         {'loss': 0.8432, 'learning_rate': 1.936491114789416e-05, 'epoch': 0.14}
 14%|█▍        | 1462/10395 [4:10:55<22:12:41,  8.95s/it] 14%|█▍        | 1463/10395 [4:11:03<21:49:46,  8.80s/it]                                                         {'loss': 0.9972, 'learning_rate': 1.936381803319852e-05, 'epoch': 0.14}
 14%|█▍        | 1463/10395 [4:11:03<21:49:46,  8.80s/it] 14%|█▍        | 1464/10395 [4:11:11<20:59:06,  8.46s/it]                                                         {'loss': 0.8943, 'learning_rate': 1.936272400948344e-05, 'epoch': 0.14}
 14%|█▍        | 1464/10395 [4:11:11<20:59:06,  8.46s/it] 14%|█▍        | 1465/10395 [4:11:18<20:04:29,  8.09s/it]                                                         {'loss': 1.0454, 'learning_rate': 1.9361629076855118e-05, 'epoch': 0.14}
 14%|█▍        | 1465/10395 [4:11:18<20:04:29,  8.09s/it] 14%|█▍        | 1466/10395 [4:11:25<19:37:48,  7.91s/it]                                                         {'loss': 0.9289, 'learning_rate': 1.9360533235419854e-05, 'epoch': 0.14}
 14%|█▍        | 1466/10395 [4:11:25<19:37:48,  7.91s/it] 14%|█▍        | 1467/10395 [4:11:42<26:25:34, 10.66s/it]                                                         {'loss': 0.3912, 'learning_rate': 1.9359436485284025e-05, 'epoch': 0.14}
 14%|█▍        | 1467/10395 [4:11:42<26:25:34, 10.66s/it] 14%|█▍        | 1468/10395 [4:11:50<24:10:45,  9.75s/it]                                                         {'loss': 0.9321, 'learning_rate': 1.9358338826554104e-05, 'epoch': 0.14}
 14%|█▍        | 1468/10395 [4:11:50<24:10:45,  9.75s/it] 14%|█▍        | 1469/10395 [4:11:58<22:38:35,  9.13s/it]                                                         {'loss': 0.9815, 'learning_rate': 1.9357240259336648e-05, 'epoch': 0.14}
 14%|█▍        | 1469/10395 [4:11:58<22:38:35,  9.13s/it] 14%|█▍        | 1470/10395 [4:12:06<22:09:38,  8.94s/it]                                                         {'loss': 1.0238, 'learning_rate': 1.9356140783738304e-05, 'epoch': 0.14}
 14%|█▍        | 1470/10395 [4:12:06<22:09:38,  8.94s/it] 14%|█▍        | 1471/10395 [4:12:14<20:58:33,  8.46s/it]                                                         {'loss': 0.9894, 'learning_rate': 1.935504039986581e-05, 'epoch': 0.14}
 14%|█▍        | 1471/10395 [4:12:14<20:58:33,  8.46s/it] 14%|█▍        | 1472/10395 [4:12:21<20:08:59,  8.13s/it]                                                         {'loss': 0.9734, 'learning_rate': 1.9353939107825984e-05, 'epoch': 0.14}
 14%|█▍        | 1472/10395 [4:12:21<20:08:59,  8.13s/it] 14%|█▍        | 1473/10395 [4:12:30<21:10:09,  8.54s/it]                                                         {'loss': 0.9629, 'learning_rate': 1.9352836907725735e-05, 'epoch': 0.14}
 14%|█▍        | 1473/10395 [4:12:30<21:10:09,  8.54s/it] 14%|█▍        | 1474/10395 [4:12:38<20:15:30,  8.18s/it]                                                         {'loss': 1.0415, 'learning_rate': 1.935173379967207e-05, 'epoch': 0.14}
 14%|█▍        | 1474/10395 [4:12:38<20:15:30,  8.18s/it] 14%|█▍        | 1475/10395 [4:12:45<19:45:12,  7.97s/it]                                                         {'loss': 1.0505, 'learning_rate': 1.935062978377207e-05, 'epoch': 0.14}
 14%|█▍        | 1475/10395 [4:12:45<19:45:12,  7.97s/it] 14%|█▍        | 1476/10395 [4:12:55<20:46:11,  8.38s/it]                                                         {'loss': 0.9948, 'learning_rate': 1.9349524860132916e-05, 'epoch': 0.14}
 14%|█▍        | 1476/10395 [4:12:55<20:46:11,  8.38s/it] 14%|█▍        | 1477/10395 [4:13:02<20:19:46,  8.21s/it]                                                         {'loss': 0.9693, 'learning_rate': 1.9348419028861863e-05, 'epoch': 0.14}
 14%|█▍        | 1477/10395 [4:13:02<20:19:46,  8.21s/it] 14%|█▍        | 1478/10395 [4:13:10<20:04:46,  8.11s/it]                                                         {'loss': 1.0065, 'learning_rate': 1.9347312290066273e-05, 'epoch': 0.14}
 14%|█▍        | 1478/10395 [4:13:10<20:04:46,  8.11s/it] 14%|█▍        | 1479/10395 [4:13:18<19:42:50,  7.96s/it]                                                         {'loss': 0.9351, 'learning_rate': 1.934620464385358e-05, 'epoch': 0.14}
 14%|█▍        | 1479/10395 [4:13:18<19:42:50,  7.96s/it] 14%|█▍        | 1480/10395 [4:13:26<19:38:25,  7.93s/it]                                                         {'loss': 0.967, 'learning_rate': 1.9345096090331315e-05, 'epoch': 0.14}
 14%|█▍        | 1480/10395 [4:13:26<19:38:25,  7.93s/it] 14%|█▍        | 1481/10395 [4:13:34<19:34:10,  7.90s/it]                                                         {'loss': 0.9266, 'learning_rate': 1.9343986629607093e-05, 'epoch': 0.14}
 14%|█▍        | 1481/10395 [4:13:34<19:34:10,  7.90s/it] 14%|█▍        | 1482/10395 [4:13:41<19:23:34,  7.83s/it]                                                         {'loss': 1.0471, 'learning_rate': 1.9342876261788612e-05, 'epoch': 0.14}
 14%|█▍        | 1482/10395 [4:13:41<19:23:34,  7.83s/it] 14%|█▍        | 1483/10395 [4:13:49<19:12:50,  7.76s/it]                                                         {'loss': 0.9466, 'learning_rate': 1.9341764986983674e-05, 'epoch': 0.14}
 14%|█▍        | 1483/10395 [4:13:49<19:12:50,  7.76s/it] 14%|█▍        | 1484/10395 [4:13:56<18:34:48,  7.51s/it]                                                         {'loss': 1.0935, 'learning_rate': 1.9340652805300154e-05, 'epoch': 0.14}
 14%|█▍        | 1484/10395 [4:13:56<18:34:48,  7.51s/it] 14%|█▍        | 1485/10395 [4:14:03<18:35:48,  7.51s/it]                                                         {'loss': 1.0546, 'learning_rate': 1.9339539716846016e-05, 'epoch': 0.14}
 14%|█▍        | 1485/10395 [4:14:03<18:35:48,  7.51s/it] 14%|█▍        | 1486/10395 [4:14:11<18:36:14,  7.52s/it]                                                         {'loss': 1.0139, 'learning_rate': 1.9338425721729327e-05, 'epoch': 0.14}
 14%|█▍        | 1486/10395 [4:14:11<18:36:14,  7.52s/it] 14%|█▍        | 1487/10395 [4:14:18<18:20:10,  7.41s/it]                                                         {'loss': 1.0551, 'learning_rate': 1.933731082005822e-05, 'epoch': 0.14}
 14%|█▍        | 1487/10395 [4:14:18<18:20:10,  7.41s/it] 14%|█▍        | 1488/10395 [4:14:26<18:39:32,  7.54s/it]                                                         {'loss': 1.0554, 'learning_rate': 1.9336195011940938e-05, 'epoch': 0.14}
 14%|█▍        | 1488/10395 [4:14:26<18:39:32,  7.54s/it] 14%|█▍        | 1489/10395 [4:14:33<18:28:00,  7.46s/it]                                                         {'loss': 1.0009, 'learning_rate': 1.933507829748579e-05, 'epoch': 0.14}
 14%|█▍        | 1489/10395 [4:14:33<18:28:00,  7.46s/it] 14%|█▍        | 1490/10395 [4:14:41<18:37:47,  7.53s/it]                                                         {'loss': 1.0473, 'learning_rate': 1.9333960676801194e-05, 'epoch': 0.14}
 14%|█▍        | 1490/10395 [4:14:41<18:37:47,  7.53s/it] 14%|█▍        | 1491/10395 [4:14:48<18:36:16,  7.52s/it]                                                         {'loss': 1.0176, 'learning_rate': 1.933284214999564e-05, 'epoch': 0.14}
 14%|█▍        | 1491/10395 [4:14:48<18:36:16,  7.52s/it] 14%|█▍        | 1492/10395 [4:14:57<19:07:16,  7.73s/it]                                                         {'loss': 1.0543, 'learning_rate': 1.9331722717177714e-05, 'epoch': 0.14}
 14%|█▍        | 1492/10395 [4:14:57<19:07:16,  7.73s/it] 14%|█▍        | 1493/10395 [4:15:05<19:31:40,  7.90s/it]                                                         {'loss': 0.9046, 'learning_rate': 1.9330602378456093e-05, 'epoch': 0.14}
 14%|█▍        | 1493/10395 [4:15:05<19:31:40,  7.90s/it] 14%|█▍        | 1494/10395 [4:15:15<21:01:55,  8.51s/it]                                                         {'loss': 0.9503, 'learning_rate': 1.9329481133939527e-05, 'epoch': 0.14}
 14%|█▍        | 1494/10395 [4:15:15<21:01:55,  8.51s/it] 14%|█▍        | 1495/10395 [4:15:22<20:27:26,  8.27s/it]                                                         {'loss': 0.9787, 'learning_rate': 1.9328358983736873e-05, 'epoch': 0.14}
 14%|█▍        | 1495/10395 [4:15:22<20:27:26,  8.27s/it] 14%|█▍        | 1496/10395 [4:15:30<20:12:07,  8.17s/it]                                                         {'loss': 1.0381, 'learning_rate': 1.932723592795706e-05, 'epoch': 0.14}
 14%|█▍        | 1496/10395 [4:15:30<20:12:07,  8.17s/it] 14%|█▍        | 1497/10395 [4:15:47<26:05:54, 10.56s/it]                                                         {'loss': 0.3273, 'learning_rate': 1.9326111966709122e-05, 'epoch': 0.14}
 14%|█▍        | 1497/10395 [4:15:47<26:05:54, 10.56s/it] 14%|█▍        | 1498/10395 [4:16:03<30:29:38, 12.34s/it]                                                         {'loss': 0.3766, 'learning_rate': 1.932498710010216e-05, 'epoch': 0.14}
 14%|█▍        | 1498/10395 [4:16:03<30:29:38, 12.34s/it] 14%|█▍        | 1499/10395 [4:16:10<26:35:23, 10.76s/it]                                                         {'loss': 0.8835, 'learning_rate': 1.932386132824538e-05, 'epoch': 0.14}
 14%|█▍        | 1499/10395 [4:16:10<26:35:23, 10.76s/it] 14%|█▍        | 1500/10395 [4:16:19<24:55:27, 10.09s/it]                                                         {'loss': 1.0019, 'learning_rate': 1.932273465124806e-05, 'epoch': 0.14}
 14%|█▍        | 1500/10395 [4:16:19<24:55:27, 10.09s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 14%|█▍        | 1501/10395 [4:18:01<93:38:01, 37.90s/it]                                                         {'loss': 0.9627, 'learning_rate': 1.932160706921959e-05, 'epoch': 0.14}
 14%|█▍        | 1501/10395 [4:18:01<93:38:01, 37.90s/it] 14%|█▍        | 1502/10395 [4:18:09<71:22:41, 28.89s/it]                                                         {'loss': 0.9932, 'learning_rate': 1.9320478582269427e-05, 'epoch': 0.14}
 14%|█▍        | 1502/10395 [4:18:09<71:22:41, 28.89s/it] 14%|█▍        | 1503/10395 [4:18:16<55:13:15, 22.36s/it]                                                         {'loss': 0.9984, 'learning_rate': 1.931934919050712e-05, 'epoch': 0.14}
 14%|█▍        | 1503/10395 [4:18:16<55:13:15, 22.36s/it] 14%|█▍        | 1504/10395 [4:18:25<44:40:03, 18.09s/it]                                                         {'loss': 0.9817, 'learning_rate': 1.9318218894042307e-05, 'epoch': 0.14}
 14%|█▍        | 1504/10395 [4:18:25<44:40:03, 18.09s/it] 14%|█▍        | 1505/10395 [4:18:32<36:38:45, 14.84s/it]                                                         {'loss': 1.037, 'learning_rate': 1.9317087692984718e-05, 'epoch': 0.14}
 14%|█▍        | 1505/10395 [4:18:32<36:38:45, 14.84s/it] 14%|█▍        | 1506/10395 [4:18:39<31:03:30, 12.58s/it]                                                         {'loss': 1.023, 'learning_rate': 1.931595558744417e-05, 'epoch': 0.14}
 14%|█▍        | 1506/10395 [4:18:39<31:03:30, 12.58s/it] 14%|█▍        | 1507/10395 [4:18:47<27:30:24, 11.14s/it]                                                         {'loss': 0.9396, 'learning_rate': 1.9314822577530554e-05, 'epoch': 0.14}
 14%|█▍        | 1507/10395 [4:18:47<27:30:24, 11.14s/it] 15%|█▍        | 1508/10395 [4:18:54<24:41:26, 10.00s/it]                                                         {'loss': 0.9405, 'learning_rate': 1.9313688663353875e-05, 'epoch': 0.15}
 15%|█▍        | 1508/10395 [4:18:54<24:41:26, 10.00s/it] 15%|█▍        | 1509/10395 [4:19:01<22:33:04,  9.14s/it]                                                         {'loss': 1.0089, 'learning_rate': 1.93125538450242e-05, 'epoch': 0.15}
 15%|█▍        | 1509/10395 [4:19:01<22:33:04,  9.14s/it] 15%|█▍        | 1510/10395 [4:19:10<22:13:32,  9.01s/it]                                                         {'loss': 0.8984, 'learning_rate': 1.93114181226517e-05, 'epoch': 0.15}
 15%|█▍        | 1510/10395 [4:19:10<22:13:32,  9.01s/it] 15%|█▍        | 1511/10395 [4:19:18<21:23:52,  8.67s/it]                                                         {'loss': 1.0126, 'learning_rate': 1.9310281496346625e-05, 'epoch': 0.15}
 15%|█▍        | 1511/10395 [4:19:18<21:23:52,  8.67s/it] 15%|█▍        | 1512/10395 [4:19:28<22:07:32,  8.97s/it]                                                         {'loss': 0.942, 'learning_rate': 1.930914396621932e-05, 'epoch': 0.15}
 15%|█▍        | 1512/10395 [4:19:28<22:07:32,  8.97s/it] 15%|█▍        | 1513/10395 [4:19:35<21:01:16,  8.52s/it]                                                         {'loss': 1.1205, 'learning_rate': 1.9308005532380213e-05, 'epoch': 0.15}
 15%|█▍        | 1513/10395 [4:19:35<21:01:16,  8.52s/it] 15%|█▍        | 1514/10395 [4:19:44<21:13:06,  8.60s/it]                                                         {'loss': 0.9267, 'learning_rate': 1.9306866194939822e-05, 'epoch': 0.15}
 15%|█▍        | 1514/10395 [4:19:44<21:13:06,  8.60s/it] 15%|█▍        | 1515/10395 [4:19:52<20:43:28,  8.40s/it]                                                         {'loss': 0.9127, 'learning_rate': 1.930572595400875e-05, 'epoch': 0.15}
 15%|█▍        | 1515/10395 [4:19:52<20:43:28,  8.40s/it] 15%|█▍        | 1516/10395 [4:20:00<20:20:24,  8.25s/it]                                                         {'loss': 1.0469, 'learning_rate': 1.9304584809697684e-05, 'epoch': 0.15}
 15%|█▍        | 1516/10395 [4:20:00<20:20:24,  8.25s/it] 15%|█▍        | 1517/10395 [4:20:07<19:44:26,  8.00s/it]                                                         {'loss': 0.9747, 'learning_rate': 1.9303442762117414e-05, 'epoch': 0.15}
 15%|█▍        | 1517/10395 [4:20:07<19:44:26,  8.00s/it] 15%|█▍        | 1518/10395 [4:20:17<20:46:53,  8.43s/it]                                                         {'loss': 1.0742, 'learning_rate': 1.9302299811378797e-05, 'epoch': 0.15}
 15%|█▍        | 1518/10395 [4:20:17<20:46:53,  8.43s/it] 15%|█▍        | 1519/10395 [4:20:24<20:12:16,  8.19s/it]                                                         {'loss': 1.056, 'learning_rate': 1.9301155957592798e-05, 'epoch': 0.15}
 15%|█▍        | 1519/10395 [4:20:24<20:12:16,  8.19s/it] 15%|█▍        | 1520/10395 [4:20:31<19:24:58,  7.88s/it]                                                         {'loss': 1.0481, 'learning_rate': 1.9300011200870453e-05, 'epoch': 0.15}
 15%|█▍        | 1520/10395 [4:20:32<19:24:58,  7.88s/it] 15%|█▍        | 1521/10395 [4:20:39<19:26:52,  7.89s/it]                                                         {'loss': 1.0006, 'learning_rate': 1.9298865541322893e-05, 'epoch': 0.15}
 15%|█▍        | 1521/10395 [4:20:39<19:26:52,  7.89s/it] 15%|█▍        | 1522/10395 [4:20:46<18:53:40,  7.67s/it]                                                         {'loss': 1.062, 'learning_rate': 1.929771897906134e-05, 'epoch': 0.15}
 15%|█▍        | 1522/10395 [4:20:46<18:53:40,  7.67s/it] 15%|█▍        | 1523/10395 [4:20:54<18:53:52,  7.67s/it]                                                         {'loss': 0.9945, 'learning_rate': 1.92965715141971e-05, 'epoch': 0.15}
 15%|█▍        | 1523/10395 [4:20:54<18:53:52,  7.67s/it] 15%|█▍        | 1524/10395 [4:21:02<19:17:25,  7.83s/it]                                                         {'loss': 0.8726, 'learning_rate': 1.9295423146841562e-05, 'epoch': 0.15}
 15%|█▍        | 1524/10395 [4:21:02<19:17:25,  7.83s/it] 15%|█▍        | 1525/10395 [4:21:10<19:24:09,  7.87s/it]                                                         {'loss': 0.9339, 'learning_rate': 1.9294273877106207e-05, 'epoch': 0.15}
 15%|█▍        | 1525/10395 [4:21:10<19:24:09,  7.87s/it] 15%|█▍        | 1526/10395 [4:21:18<19:41:32,  7.99s/it]                                                         {'loss': 0.9476, 'learning_rate': 1.929312370510261e-05, 'epoch': 0.15}
 15%|█▍        | 1526/10395 [4:21:18<19:41:32,  7.99s/it] 15%|█▍        | 1527/10395 [4:21:26<19:39:55,  7.98s/it]                                                         {'loss': 0.9822, 'learning_rate': 1.929197263094242e-05, 'epoch': 0.15}
 15%|█▍        | 1527/10395 [4:21:26<19:39:55,  7.98s/it] 15%|█▍        | 1528/10395 [4:21:34<19:09:34,  7.78s/it]                                                         {'loss': 0.9453, 'learning_rate': 1.929082065473739e-05, 'epoch': 0.15}
 15%|█▍        | 1528/10395 [4:21:34<19:09:34,  7.78s/it] 15%|█▍        | 1529/10395 [4:21:42<19:12:33,  7.80s/it]                                                         {'loss': 1.0547, 'learning_rate': 1.9289667776599338e-05, 'epoch': 0.15}
 15%|█▍        | 1529/10395 [4:21:42<19:12:33,  7.80s/it] 15%|█▍        | 1530/10395 [4:21:49<19:03:03,  7.74s/it]                                                         {'loss': 1.0158, 'learning_rate': 1.928851399664019e-05, 'epoch': 0.15}
 15%|█▍        | 1530/10395 [4:21:49<19:03:03,  7.74s/it] 15%|█▍        | 1531/10395 [4:22:06<25:43:25, 10.45s/it]                                                         {'loss': 0.3702, 'learning_rate': 1.9287359314971958e-05, 'epoch': 0.15}
 15%|█▍        | 1531/10395 [4:22:06<25:43:25, 10.45s/it] 15%|█▍        | 1532/10395 [4:22:14<24:05:59,  9.79s/it]                                                         {'loss': 0.9979, 'learning_rate': 1.9286203731706728e-05, 'epoch': 0.15}
 15%|█▍        | 1532/10395 [4:22:14<24:05:59,  9.79s/it] 15%|█▍        | 1533/10395 [4:22:22<22:44:56,  9.24s/it]                                                         {'loss': 0.9779, 'learning_rate': 1.928504724695669e-05, 'epoch': 0.15}
 15%|█▍        | 1533/10395 [4:22:22<22:44:56,  9.24s/it] 15%|█▍        | 1534/10395 [4:22:31<22:14:43,  9.04s/it]                                                         {'loss': 1.044, 'learning_rate': 1.92838898608341e-05, 'epoch': 0.15}
 15%|█▍        | 1534/10395 [4:22:31<22:14:43,  9.04s/it] 15%|█▍        | 1535/10395 [4:22:49<29:18:23, 11.91s/it]                                                         {'loss': 0.3936, 'learning_rate': 1.9282731573451323e-05, 'epoch': 0.15}
 15%|█▍        | 1535/10395 [4:22:49<29:18:23, 11.91s/it] 15%|█▍        | 1536/10395 [4:22:57<26:29:06, 10.76s/it]                                                         {'loss': 1.0249, 'learning_rate': 1.9281572384920806e-05, 'epoch': 0.15}
 15%|█▍        | 1536/10395 [4:22:57<26:29:06, 10.76s/it] 15%|█▍        | 1537/10395 [4:23:06<24:33:05,  9.98s/it]                                                         {'loss': 0.9778, 'learning_rate': 1.9280412295355075e-05, 'epoch': 0.15}
 15%|█▍        | 1537/10395 [4:23:06<24:33:05,  9.98s/it] 15%|█▍        | 1538/10395 [4:23:14<23:26:36,  9.53s/it]                                                         {'loss': 1.0478, 'learning_rate': 1.9279251304866747e-05, 'epoch': 0.15}
 15%|█▍        | 1538/10395 [4:23:14<23:26:36,  9.53s/it] 15%|█▍        | 1539/10395 [4:23:23<22:45:31,  9.25s/it]                                                         {'loss': 1.0086, 'learning_rate': 1.9278089413568537e-05, 'epoch': 0.15}
 15%|█▍        | 1539/10395 [4:23:23<22:45:31,  9.25s/it] 15%|█▍        | 1540/10395 [4:23:37<26:47:55, 10.90s/it]                                                         {'loss': 0.3081, 'learning_rate': 1.9276926621573234e-05, 'epoch': 0.15}
 15%|█▍        | 1540/10395 [4:23:37<26:47:55, 10.90s/it] 15%|█▍        | 1541/10395 [4:23:45<24:40:11, 10.03s/it]                                                         {'loss': 1.1326, 'learning_rate': 1.9275762928993714e-05, 'epoch': 0.15}
 15%|█▍        | 1541/10395 [4:23:45<24:40:11, 10.03s/it] 15%|█▍        | 1542/10395 [4:23:55<24:03:00,  9.78s/it]                                                         {'loss': 0.9805, 'learning_rate': 1.9274598335942958e-05, 'epoch': 0.15}
 15%|█▍        | 1542/10395 [4:23:55<24:03:00,  9.78s/it] 15%|█▍        | 1543/10395 [4:24:03<22:44:15,  9.25s/it]                                                         {'loss': 0.9218, 'learning_rate': 1.927343284253401e-05, 'epoch': 0.15}
 15%|█▍        | 1543/10395 [4:24:03<22:44:15,  9.25s/it] 15%|█▍        | 1544/10395 [4:24:13<23:38:25,  9.62s/it]                                                         {'loss': 0.9135, 'learning_rate': 1.9272266448880024e-05, 'epoch': 0.15}
 15%|█▍        | 1544/10395 [4:24:13<23:38:25,  9.62s/it] 15%|█▍        | 1545/10395 [4:24:20<21:43:34,  8.84s/it]                                                         {'loss': 1.055, 'learning_rate': 1.9271099155094223e-05, 'epoch': 0.15}
 15%|█▍        | 1545/10395 [4:24:20<21:43:34,  8.84s/it] 15%|█▍        | 1546/10395 [4:24:38<28:12:41, 11.48s/it]                                                         {'loss': 0.3934, 'learning_rate': 1.9269930961289928e-05, 'epoch': 0.15}
 15%|█▍        | 1546/10395 [4:24:38<28:12:41, 11.48s/it] 15%|█▍        | 1547/10395 [4:24:47<26:21:54, 10.73s/it]                                                         {'loss': 0.9933, 'learning_rate': 1.9268761867580544e-05, 'epoch': 0.15}
 15%|█▍        | 1547/10395 [4:24:47<26:21:54, 10.73s/it] 15%|█▍        | 1548/10395 [4:24:56<25:33:39, 10.40s/it]                                                         {'loss': 0.9597, 'learning_rate': 1.926759187407957e-05, 'epoch': 0.15}
 15%|█▍        | 1548/10395 [4:24:56<25:33:39, 10.40s/it] 15%|█▍        | 1549/10395 [4:25:06<24:49:16, 10.10s/it]                                                         {'loss': 0.9213, 'learning_rate': 1.926642098090058e-05, 'epoch': 0.15}
 15%|█▍        | 1549/10395 [4:25:06<24:49:16, 10.10s/it] 15%|█▍        | 1550/10395 [4:25:13<22:32:45,  9.18s/it]                                                         {'loss': 0.9421, 'learning_rate': 1.9265249188157243e-05, 'epoch': 0.15}
 15%|█▍        | 1550/10395 [4:25:13<22:32:45,  9.18s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 15%|█▍        | 1551/10395 [4:26:50<87:12:08, 35.50s/it]                                                         {'loss': 1.0034, 'learning_rate': 1.9264076495963312e-05, 'epoch': 0.15}
 15%|█▍        | 1551/10395 [4:26:50<87:12:08, 35.50s/it] 15%|█▍        | 1552/10395 [4:26:57<66:29:25, 27.07s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.9262902904432637e-05, 'epoch': 0.15}
 15%|█▍        | 1552/10395 [4:26:57<66:29:25, 27.07s/it] 15%|█▍        | 1553/10395 [4:27:06<53:05:35, 21.62s/it]                                                         {'loss': 1.0071, 'learning_rate': 1.926172841367914e-05, 'epoch': 0.15}
 15%|█▍        | 1553/10395 [4:27:06<53:05:35, 21.62s/it] 15%|█▍        | 1554/10395 [4:27:14<42:43:58, 17.40s/it]                                                         {'loss': 1.0248, 'learning_rate': 1.926055302381684e-05, 'epoch': 0.15}
 15%|█▍        | 1554/10395 [4:27:14<42:43:58, 17.40s/it] 15%|█▍        | 1555/10395 [4:27:21<35:23:31, 14.41s/it]                                                         {'loss': 0.9927, 'learning_rate': 1.9259376734959848e-05, 'epoch': 0.15}
 15%|█▍        | 1555/10395 [4:27:21<35:23:31, 14.41s/it] 15%|█▍        | 1556/10395 [4:27:29<30:33:34, 12.45s/it]                                                         {'loss': 0.9662, 'learning_rate': 1.9258199547222344e-05, 'epoch': 0.15}
 15%|█▍        | 1556/10395 [4:27:29<30:33:34, 12.45s/it] 15%|█▍        | 1557/10395 [4:27:36<26:47:53, 10.92s/it]                                                         {'loss': 0.9552, 'learning_rate': 1.9257021460718618e-05, 'epoch': 0.15}
 15%|█▍        | 1557/10395 [4:27:36<26:47:53, 10.92s/it] 15%|█▍        | 1558/10395 [4:27:53<31:12:36, 12.71s/it]                                                         {'loss': 0.3648, 'learning_rate': 1.9255842475563024e-05, 'epoch': 0.15}
 15%|█▍        | 1558/10395 [4:27:53<31:12:36, 12.71s/it] 15%|█▍        | 1559/10395 [4:28:01<27:35:40, 11.24s/it]                                                         {'loss': 1.1021, 'learning_rate': 1.9254662591870028e-05, 'epoch': 0.15}
 15%|█▍        | 1559/10395 [4:28:01<27:35:40, 11.24s/it] 15%|█▌        | 1560/10395 [4:28:09<24:53:44, 10.14s/it]                                                         {'loss': 0.989, 'learning_rate': 1.9253481809754163e-05, 'epoch': 0.15}
 15%|█▌        | 1560/10395 [4:28:09<24:53:44, 10.14s/it] 15%|█▌        | 1561/10395 [4:28:16<23:05:18,  9.41s/it]                                                         {'loss': 0.9465, 'learning_rate': 1.9252300129330058e-05, 'epoch': 0.15}
 15%|█▌        | 1561/10395 [4:28:16<23:05:18,  9.41s/it] 15%|█▌        | 1562/10395 [4:28:24<21:36:41,  8.81s/it]                                                         {'loss': 1.0206, 'learning_rate': 1.925111755071243e-05, 'epoch': 0.15}
 15%|█▌        | 1562/10395 [4:28:24<21:36:41,  8.81s/it] 15%|█▌        | 1563/10395 [4:28:31<20:36:09,  8.40s/it]                                                         {'loss': 1.0903, 'learning_rate': 1.9249934074016077e-05, 'epoch': 0.15}
 15%|█▌        | 1563/10395 [4:28:31<20:36:09,  8.40s/it] 15%|█▌        | 1564/10395 [4:28:39<20:03:18,  8.18s/it]                                                         {'loss': 0.9962, 'learning_rate': 1.9248749699355892e-05, 'epoch': 0.15}
 15%|█▌        | 1564/10395 [4:28:39<20:03:18,  8.18s/it] 15%|█▌        | 1565/10395 [4:28:46<19:20:30,  7.89s/it]                                                         {'loss': 1.0955, 'learning_rate': 1.9247564426846855e-05, 'epoch': 0.15}
 15%|█▌        | 1565/10395 [4:28:46<19:20:30,  7.89s/it] 15%|█▌        | 1566/10395 [4:28:54<19:08:04,  7.80s/it]                                                         {'loss': 0.9811, 'learning_rate': 1.9246378256604023e-05, 'epoch': 0.15}
 15%|█▌        | 1566/10395 [4:28:54<19:08:04,  7.80s/it] 15%|█▌        | 1567/10395 [4:29:01<19:10:15,  7.82s/it]                                                         {'loss': 0.9787, 'learning_rate': 1.9245191188742548e-05, 'epoch': 0.15}
 15%|█▌        | 1567/10395 [4:29:01<19:10:15,  7.82s/it] 15%|█▌        | 1568/10395 [4:29:09<19:04:28,  7.78s/it]                                                         {'loss': 1.0067, 'learning_rate': 1.924400322337767e-05, 'epoch': 0.15}
 15%|█▌        | 1568/10395 [4:29:09<19:04:28,  7.78s/it] 15%|█▌        | 1569/10395 [4:29:17<19:06:58,  7.80s/it]                                                         {'loss': 0.9114, 'learning_rate': 1.9242814360624714e-05, 'epoch': 0.15}
 15%|█▌        | 1569/10395 [4:29:17<19:06:58,  7.80s/it] 15%|█▌        | 1570/10395 [4:29:24<18:54:10,  7.71s/it]                                                         {'loss': 0.9595, 'learning_rate': 1.924162460059909e-05, 'epoch': 0.15}
 15%|█▌        | 1570/10395 [4:29:24<18:54:10,  7.71s/it] 15%|█▌        | 1571/10395 [4:29:32<18:42:51,  7.64s/it]                                                         {'loss': 0.9485, 'learning_rate': 1.9240433943416304e-05, 'epoch': 0.15}
 15%|█▌        | 1571/10395 [4:29:32<18:42:51,  7.64s/it] 15%|█▌        | 1572/10395 [4:29:39<18:40:32,  7.62s/it]                                                         {'loss': 0.9379, 'learning_rate': 1.9239242389191936e-05, 'epoch': 0.15}
 15%|█▌        | 1572/10395 [4:29:39<18:40:32,  7.62s/it] 15%|█▌        | 1573/10395 [4:29:47<18:38:36,  7.61s/it]                                                         {'loss': 0.9931, 'learning_rate': 1.923804993804166e-05, 'epoch': 0.15}
 15%|█▌        | 1573/10395 [4:29:47<18:38:36,  7.61s/it] 15%|█▌        | 1574/10395 [4:29:55<19:14:11,  7.85s/it]                                                         {'loss': 0.9997, 'learning_rate': 1.9236856590081235e-05, 'epoch': 0.15}
 15%|█▌        | 1574/10395 [4:29:55<19:14:11,  7.85s/it] 15%|█▌        | 1575/10395 [4:30:03<19:03:34,  7.78s/it]                                                         {'loss': 0.999, 'learning_rate': 1.9235662345426513e-05, 'epoch': 0.15}
 15%|█▌        | 1575/10395 [4:30:03<19:03:34,  7.78s/it] 15%|█▌        | 1576/10395 [4:30:11<18:59:32,  7.75s/it]                                                         {'loss': 1.0007, 'learning_rate': 1.923446720419343e-05, 'epoch': 0.15}
 15%|█▌        | 1576/10395 [4:30:11<18:59:32,  7.75s/it] 15%|█▌        | 1577/10395 [4:30:19<19:19:08,  7.89s/it]                                                         {'loss': 0.943, 'learning_rate': 1.9233271166498002e-05, 'epoch': 0.15}
 15%|█▌        | 1577/10395 [4:30:19<19:19:08,  7.89s/it] 15%|█▌        | 1578/10395 [4:30:27<19:30:10,  7.96s/it]                                                         {'loss': 0.9796, 'learning_rate': 1.9232074232456345e-05, 'epoch': 0.15}
 15%|█▌        | 1578/10395 [4:30:27<19:30:10,  7.96s/it] 15%|█▌        | 1579/10395 [4:30:35<19:10:07,  7.83s/it]                                                         {'loss': 1.0222, 'learning_rate': 1.9230876402184647e-05, 'epoch': 0.15}
 15%|█▌        | 1579/10395 [4:30:35<19:10:07,  7.83s/it] 15%|█▌        | 1580/10395 [4:30:43<19:22:29,  7.91s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.9229677675799193e-05, 'epoch': 0.15}
 15%|█▌        | 1580/10395 [4:30:43<19:22:29,  7.91s/it] 15%|█▌        | 1581/10395 [4:30:51<19:23:22,  7.92s/it]                                                         {'loss': 0.83, 'learning_rate': 1.9228478053416358e-05, 'epoch': 0.15}
 15%|█▌        | 1581/10395 [4:30:51<19:23:22,  7.92s/it] 15%|█▌        | 1582/10395 [4:30:58<18:36:22,  7.60s/it]                                                         {'loss': 1.0139, 'learning_rate': 1.9227277535152592e-05, 'epoch': 0.15}
 15%|█▌        | 1582/10395 [4:30:58<18:36:22,  7.60s/it] 15%|█▌        | 1583/10395 [4:31:15<25:38:01, 10.47s/it]                                                         {'loss': 0.3614, 'learning_rate': 1.922607612112444e-05, 'epoch': 0.15}
 15%|█▌        | 1583/10395 [4:31:15<25:38:01, 10.47s/it] 15%|█▌        | 1584/10395 [4:31:22<23:36:00,  9.64s/it]                                                         {'loss': 1.0197, 'learning_rate': 1.922487381144854e-05, 'epoch': 0.15}
 15%|█▌        | 1584/10395 [4:31:22<23:36:00,  9.64s/it] 15%|█▌        | 1585/10395 [4:31:30<22:12:07,  9.07s/it]                                                         {'loss': 1.0487, 'learning_rate': 1.92236706062416e-05, 'epoch': 0.15}
 15%|█▌        | 1585/10395 [4:31:30<22:12:07,  9.07s/it] 15%|█▌        | 1586/10395 [4:31:38<21:05:04,  8.62s/it]                                                         {'loss': 0.932, 'learning_rate': 1.922246650562043e-05, 'epoch': 0.15}
 15%|█▌        | 1586/10395 [4:31:38<21:05:04,  8.62s/it] 15%|█▌        | 1587/10395 [4:31:45<20:22:34,  8.33s/it]                                                         {'loss': 0.9923, 'learning_rate': 1.9221261509701922e-05, 'epoch': 0.15}
 15%|█▌        | 1587/10395 [4:31:45<20:22:34,  8.33s/it] 15%|█▌        | 1588/10395 [4:31:53<20:10:14,  8.25s/it]                                                         {'loss': 0.9988, 'learning_rate': 1.9220055618603045e-05, 'epoch': 0.15}
 15%|█▌        | 1588/10395 [4:31:53<20:10:14,  8.25s/it] 15%|█▌        | 1589/10395 [4:32:01<19:40:51,  8.05s/it]                                                         {'loss': 0.9709, 'learning_rate': 1.9218848832440878e-05, 'epoch': 0.15}
 15%|█▌        | 1589/10395 [4:32:01<19:40:51,  8.05s/it] 15%|█▌        | 1590/10395 [4:32:09<19:33:21,  8.00s/it]                                                         {'loss': 1.0523, 'learning_rate': 1.921764115133257e-05, 'epoch': 0.15}
 15%|█▌        | 1590/10395 [4:32:09<19:33:21,  8.00s/it] 15%|█▌        | 1591/10395 [4:32:17<19:23:33,  7.93s/it]                                                         {'loss': 1.0299, 'learning_rate': 1.921643257539535e-05, 'epoch': 0.15}
 15%|█▌        | 1591/10395 [4:32:17<19:23:33,  7.93s/it] 15%|█▌        | 1592/10395 [4:32:26<20:35:43,  8.42s/it]                                                         {'loss': 0.9228, 'learning_rate': 1.9215223104746556e-05, 'epoch': 0.15}
 15%|█▌        | 1592/10395 [4:32:26<20:35:43,  8.42s/it] 15%|█▌        | 1593/10395 [4:32:34<20:14:59,  8.28s/it]                                                         {'loss': 0.958, 'learning_rate': 1.9214012739503594e-05, 'epoch': 0.15}
 15%|█▌        | 1593/10395 [4:32:34<20:14:59,  8.28s/it] 15%|█▌        | 1594/10395 [4:32:43<20:23:04,  8.34s/it]                                                         {'loss': 1.0509, 'learning_rate': 1.9212801479783967e-05, 'epoch': 0.15}
 15%|█▌        | 1594/10395 [4:32:43<20:23:04,  8.34s/it] 15%|█▌        | 1595/10395 [4:32:51<20:17:44,  8.30s/it]                                                         {'loss': 1.0304, 'learning_rate': 1.921158932570526e-05, 'epoch': 0.15}
 15%|█▌        | 1595/10395 [4:32:51<20:17:44,  8.30s/it] 15%|█▌        | 1596/10395 [4:32:58<19:28:51,  7.97s/it]                                                         {'loss': 1.0703, 'learning_rate': 1.9210376277385143e-05, 'epoch': 0.15}
 15%|█▌        | 1596/10395 [4:32:58<19:28:51,  7.97s/it] 15%|█▌        | 1597/10395 [4:33:05<18:58:06,  7.76s/it]                                                         {'loss': 1.0066, 'learning_rate': 1.9209162334941386e-05, 'epoch': 0.15}
 15%|█▌        | 1597/10395 [4:33:05<18:58:06,  7.76s/it] 15%|█▌        | 1598/10395 [4:33:13<19:03:47,  7.80s/it]                                                         {'loss': 0.9917, 'learning_rate': 1.9207947498491823e-05, 'epoch': 0.15}
 15%|█▌        | 1598/10395 [4:33:13<19:03:47,  7.80s/it] 15%|█▌        | 1599/10395 [4:33:21<19:00:41,  7.78s/it]                                                         {'loss': 0.9562, 'learning_rate': 1.92067317681544e-05, 'epoch': 0.15}
 15%|█▌        | 1599/10395 [4:33:21<19:00:41,  7.78s/it] 15%|█▌        | 1600/10395 [4:33:28<18:49:41,  7.71s/it]                                                         {'loss': 0.9876, 'learning_rate': 1.920551514404713e-05, 'epoch': 0.15}
 15%|█▌        | 1600/10395 [4:33:28<18:49:41,  7.71s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 15%|█▌        | 1601/10395 [4:35:17<92:33:53, 37.89s/it]                                                         {'loss': 0.3784, 'learning_rate': 1.9204297626288118e-05, 'epoch': 0.15}
 15%|█▌        | 1601/10395 [4:35:17<92:33:53, 37.89s/it] 15%|█▌        | 1602/10395 [4:35:24<70:05:30, 28.70s/it]                                                         {'loss': 0.974, 'learning_rate': 1.9203079214995565e-05, 'epoch': 0.15}
 15%|█▌        | 1602/10395 [4:35:24<70:05:30, 28.70s/it] 15%|█▌        | 1603/10395 [4:35:32<55:11:38, 22.60s/it]                                                         {'loss': 0.9435, 'learning_rate': 1.920185991028775e-05, 'epoch': 0.15}
 15%|█▌        | 1603/10395 [4:35:32<55:11:38, 22.60s/it] 15%|█▌        | 1604/10395 [4:35:41<44:42:06, 18.31s/it]                                                         {'loss': 1.0278, 'learning_rate': 1.9200639712283037e-05, 'epoch': 0.15}
 15%|█▌        | 1604/10395 [4:35:41<44:42:06, 18.31s/it] 15%|█▌        | 1605/10395 [4:35:48<36:49:10, 15.08s/it]                                                         {'loss': 1.0688, 'learning_rate': 1.9199418621099886e-05, 'epoch': 0.15}
 15%|█▌        | 1605/10395 [4:35:48<36:49:10, 15.08s/it] 15%|█▌        | 1606/10395 [4:35:55<30:55:40, 12.67s/it]                                                         {'loss': 1.0585, 'learning_rate': 1.9198196636856833e-05, 'epoch': 0.15}
 15%|█▌        | 1606/10395 [4:35:56<30:55:40, 12.67s/it] 15%|█▌        | 1607/10395 [4:36:03<27:36:42, 11.31s/it]                                                         {'loss': 0.9942, 'learning_rate': 1.9196973759672506e-05, 'epoch': 0.15}
 15%|█▌        | 1607/10395 [4:36:03<27:36:42, 11.31s/it] 15%|█▌        | 1608/10395 [4:36:11<25:09:27, 10.31s/it]                                                         {'loss': 1.0102, 'learning_rate': 1.919574998966562e-05, 'epoch': 0.15}
 15%|█▌        | 1608/10395 [4:36:11<25:09:27, 10.31s/it] 15%|█▌        | 1609/10395 [4:36:19<23:18:14,  9.55s/it]                                                         {'loss': 0.9782, 'learning_rate': 1.9194525326954978e-05, 'epoch': 0.15}
 15%|█▌        | 1609/10395 [4:36:19<23:18:14,  9.55s/it] 15%|█▌        | 1610/10395 [4:36:28<22:44:32,  9.32s/it]                                                         {'loss': 0.9598, 'learning_rate': 1.9193299771659465e-05, 'epoch': 0.15}
 15%|█▌        | 1610/10395 [4:36:28<22:44:32,  9.32s/it] 15%|█▌        | 1611/10395 [4:36:35<21:13:38,  8.70s/it]                                                         {'loss': 1.0161, 'learning_rate': 1.919207332389806e-05, 'epoch': 0.15}
 15%|█▌        | 1611/10395 [4:36:35<21:13:38,  8.70s/it] 16%|█▌        | 1612/10395 [4:36:43<20:24:40,  8.37s/it]                                                         {'loss': 0.9853, 'learning_rate': 1.9190845983789814e-05, 'epoch': 0.16}
 16%|█▌        | 1612/10395 [4:36:43<20:24:40,  8.37s/it] 16%|█▌        | 1613/10395 [4:36:51<20:01:14,  8.21s/it]                                                         {'loss': 0.99, 'learning_rate': 1.9189617751453885e-05, 'epoch': 0.16}
 16%|█▌        | 1613/10395 [4:36:51<20:01:14,  8.21s/it] 16%|█▌        | 1614/10395 [4:36:58<19:22:51,  7.95s/it]                                                         {'loss': 1.0537, 'learning_rate': 1.91883886270095e-05, 'epoch': 0.16}
 16%|█▌        | 1614/10395 [4:36:58<19:22:51,  7.95s/it] 16%|█▌        | 1615/10395 [4:37:05<18:57:13,  7.77s/it]                                                         {'loss': 0.915, 'learning_rate': 1.9187158610575985e-05, 'epoch': 0.16}
 16%|█▌        | 1615/10395 [4:37:05<18:57:13,  7.77s/it] 16%|█▌        | 1616/10395 [4:37:13<19:02:44,  7.81s/it]                                                         {'loss': 0.9196, 'learning_rate': 1.9185927702272746e-05, 'epoch': 0.16}
 16%|█▌        | 1616/10395 [4:37:13<19:02:44,  7.81s/it] 16%|█▌        | 1617/10395 [4:37:21<18:45:55,  7.70s/it]                                                         {'loss': 1.015, 'learning_rate': 1.9184695902219274e-05, 'epoch': 0.16}
 16%|█▌        | 1617/10395 [4:37:21<18:45:55,  7.70s/it] 16%|█▌        | 1618/10395 [4:37:28<18:39:29,  7.65s/it]                                                         {'loss': 0.9901, 'learning_rate': 1.918346321053515e-05, 'epoch': 0.16}
 16%|█▌        | 1618/10395 [4:37:28<18:39:29,  7.65s/it] 16%|█▌        | 1619/10395 [4:37:37<19:09:47,  7.86s/it]                                                         {'loss': 0.9503, 'learning_rate': 1.9182229627340048e-05, 'epoch': 0.16}
 16%|█▌        | 1619/10395 [4:37:37<19:09:47,  7.86s/it] 16%|█▌        | 1620/10395 [4:37:45<19:24:17,  7.96s/it]                                                         {'loss': 0.988, 'learning_rate': 1.9180995152753713e-05, 'epoch': 0.16}
 16%|█▌        | 1620/10395 [4:37:45<19:24:17,  7.96s/it] 16%|█▌        | 1621/10395 [4:37:53<19:18:57,  7.93s/it]                                                         {'loss': 0.9646, 'learning_rate': 1.9179759786895987e-05, 'epoch': 0.16}
 16%|█▌        | 1621/10395 [4:37:53<19:18:57,  7.93s/it] 16%|█▌        | 1622/10395 [4:38:00<19:07:43,  7.85s/it]                                                         {'loss': 0.9019, 'learning_rate': 1.9178523529886802e-05, 'epoch': 0.16}
 16%|█▌        | 1622/10395 [4:38:00<19:07:43,  7.85s/it] 16%|█▌        | 1623/10395 [4:38:08<19:18:45,  7.93s/it]                                                         {'loss': 0.9793, 'learning_rate': 1.9177286381846165e-05, 'epoch': 0.16}
 16%|█▌        | 1623/10395 [4:38:08<19:18:45,  7.93s/it] 16%|█▌        | 1624/10395 [4:38:16<18:57:40,  7.78s/it]                                                         {'loss': 1.0161, 'learning_rate': 1.9176048342894176e-05, 'epoch': 0.16}
 16%|█▌        | 1624/10395 [4:38:16<18:57:40,  7.78s/it] 16%|█▌        | 1625/10395 [4:38:24<19:32:04,  8.02s/it]                                                         {'loss': 0.9857, 'learning_rate': 1.9174809413151026e-05, 'epoch': 0.16}
 16%|█▌        | 1625/10395 [4:38:24<19:32:04,  8.02s/it] 16%|█▌        | 1626/10395 [4:38:33<20:11:11,  8.29s/it]                                                         {'loss': 1.0008, 'learning_rate': 1.917356959273698e-05, 'epoch': 0.16}
 16%|█▌        | 1626/10395 [4:38:33<20:11:11,  8.29s/it] 16%|█▌        | 1627/10395 [4:38:41<19:45:38,  8.11s/it]                                                         {'loss': 0.8719, 'learning_rate': 1.917232888177241e-05, 'epoch': 0.16}
 16%|█▌        | 1627/10395 [4:38:41<19:45:38,  8.11s/it] 16%|█▌        | 1628/10395 [4:38:59<26:48:42, 11.01s/it]                                                         {'loss': 0.3742, 'learning_rate': 1.917108728037775e-05, 'epoch': 0.16}
 16%|█▌        | 1628/10395 [4:38:59<26:48:42, 11.01s/it] 16%|█▌        | 1629/10395 [4:39:06<24:19:03,  9.99s/it]                                                         {'loss': 1.0151, 'learning_rate': 1.9169844788673534e-05, 'epoch': 0.16}
 16%|█▌        | 1629/10395 [4:39:06<24:19:03,  9.99s/it] 16%|█▌        | 1630/10395 [4:39:14<22:36:03,  9.28s/it]                                                         {'loss': 0.9992, 'learning_rate': 1.916860140678038e-05, 'epoch': 0.16}
 16%|█▌        | 1630/10395 [4:39:14<22:36:03,  9.28s/it] 16%|█▌        | 1631/10395 [4:39:22<21:30:18,  8.83s/it]                                                         {'loss': 0.9586, 'learning_rate': 1.9167357134819e-05, 'epoch': 0.16}
 16%|█▌        | 1631/10395 [4:39:22<21:30:18,  8.83s/it] 16%|█▌        | 1632/10395 [4:39:30<20:58:13,  8.62s/it]                                                         {'loss': 1.0275, 'learning_rate': 1.9166111972910178e-05, 'epoch': 0.16}
 16%|█▌        | 1632/10395 [4:39:30<20:58:13,  8.62s/it] 16%|█▌        | 1633/10395 [4:39:39<21:02:24,  8.64s/it]                                                         {'loss': 0.9771, 'learning_rate': 1.9164865921174792e-05, 'epoch': 0.16}
 16%|█▌        | 1633/10395 [4:39:39<21:02:24,  8.64s/it] 16%|█▌        | 1634/10395 [4:39:47<20:28:42,  8.41s/it]                                                         {'loss': 0.9442, 'learning_rate': 1.9163618979733808e-05, 'epoch': 0.16}
 16%|█▌        | 1634/10395 [4:39:47<20:28:42,  8.41s/it] 16%|█▌        | 1635/10395 [4:39:55<20:33:39,  8.45s/it]                                                         {'loss': 0.9938, 'learning_rate': 1.9162371148708278e-05, 'epoch': 0.16}
 16%|█▌        | 1635/10395 [4:39:55<20:33:39,  8.45s/it] 16%|█▌        | 1636/10395 [4:40:03<20:01:28,  8.23s/it]                                                         {'loss': 1.0666, 'learning_rate': 1.9161122428219338e-05, 'epoch': 0.16}
 16%|█▌        | 1636/10395 [4:40:03<20:01:28,  8.23s/it] 16%|█▌        | 1637/10395 [4:40:11<20:14:26,  8.32s/it]                                                         {'loss': 0.9149, 'learning_rate': 1.9159872818388207e-05, 'epoch': 0.16}
 16%|█▌        | 1637/10395 [4:40:11<20:14:26,  8.32s/it] 16%|█▌        | 1638/10395 [4:40:19<19:40:13,  8.09s/it]                                                         {'loss': 1.054, 'learning_rate': 1.91586223193362e-05, 'epoch': 0.16}
 16%|█▌        | 1638/10395 [4:40:19<19:40:13,  8.09s/it] 16%|█▌        | 1639/10395 [4:40:26<19:10:39,  7.88s/it]                                                         {'loss': 1.0264, 'learning_rate': 1.915737093118471e-05, 'epoch': 0.16}
 16%|█▌        | 1639/10395 [4:40:26<19:10:39,  7.88s/it] 16%|█▌        | 1640/10395 [4:40:42<25:04:25, 10.31s/it]                                                         {'loss': 0.3468, 'learning_rate': 1.9156118654055217e-05, 'epoch': 0.16}
 16%|█▌        | 1640/10395 [4:40:42<25:04:25, 10.31s/it] 16%|█▌        | 1641/10395 [4:40:50<23:01:15,  9.47s/it]                                                         {'loss': 0.9434, 'learning_rate': 1.9154865488069294e-05, 'epoch': 0.16}
 16%|█▌        | 1641/10395 [4:40:50<23:01:15,  9.47s/it] 16%|█▌        | 1642/10395 [4:40:58<22:01:22,  9.06s/it]                                                         {'loss': 1.0497, 'learning_rate': 1.915361143334859e-05, 'epoch': 0.16}
 16%|█▌        | 1642/10395 [4:40:58<22:01:22,  9.06s/it] 16%|█▌        | 1643/10395 [4:41:14<27:01:46, 11.12s/it]                                                         {'loss': 0.3805, 'learning_rate': 1.9152356490014855e-05, 'epoch': 0.16}
 16%|█▌        | 1643/10395 [4:41:14<27:01:46, 11.12s/it] 16%|█▌        | 1644/10395 [4:41:21<24:21:06, 10.02s/it]                                                         {'loss': 0.9217, 'learning_rate': 1.9151100658189906e-05, 'epoch': 0.16}
 16%|█▌        | 1644/10395 [4:41:21<24:21:06, 10.02s/it] 16%|█▌        | 1645/10395 [4:41:29<22:40:32,  9.33s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.9149843937995665e-05, 'epoch': 0.16}
 16%|█▌        | 1645/10395 [4:41:29<22:40:32,  9.33s/it] 16%|█▌        | 1646/10395 [4:41:36<21:20:08,  8.78s/it]                                                         {'loss': 1.0432, 'learning_rate': 1.9148586329554123e-05, 'epoch': 0.16}
 16%|█▌        | 1646/10395 [4:41:36<21:20:08,  8.78s/it] 16%|█▌        | 1647/10395 [4:41:44<20:28:40,  8.43s/it]                                                         {'loss': 0.9731, 'learning_rate': 1.9147327832987375e-05, 'epoch': 0.16}
 16%|█▌        | 1647/10395 [4:41:44<20:28:40,  8.43s/it] 16%|█▌        | 1648/10395 [4:41:52<20:16:17,  8.34s/it]                                                         {'loss': 0.9019, 'learning_rate': 1.9146068448417584e-05, 'epoch': 0.16}
 16%|█▌        | 1648/10395 [4:41:52<20:16:17,  8.34s/it] 16%|█▌        | 1649/10395 [4:42:00<19:38:20,  8.08s/it]                                                         {'loss': 0.9379, 'learning_rate': 1.9144808175967017e-05, 'epoch': 0.16}
 16%|█▌        | 1649/10395 [4:42:00<19:38:20,  8.08s/it] 16%|█▌        | 1650/10395 [4:42:17<26:13:33, 10.80s/it]                                                         {'loss': 0.3868, 'learning_rate': 1.9143547015758014e-05, 'epoch': 0.16}
 16%|█▌        | 1650/10395 [4:42:17<26:13:33, 10.80s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 16%|█▌        | 1651/10395 [4:43:59<92:56:29, 38.27s/it]                                                         {'loss': 0.9385, 'learning_rate': 1.9142284967913007e-05, 'epoch': 0.16}
 16%|█▌        | 1651/10395 [4:43:59<92:56:29, 38.27s/it] 16%|█▌        | 1652/10395 [4:44:07<70:58:00, 29.22s/it]                                                         {'loss': 0.9878, 'learning_rate': 1.9141022032554514e-05, 'epoch': 0.16}
 16%|█▌        | 1652/10395 [4:44:07<70:58:00, 29.22s/it] 16%|█▌        | 1653/10395 [4:44:17<56:42:29, 23.35s/it]                                                         {'loss': 0.9432, 'learning_rate': 1.9139758209805132e-05, 'epoch': 0.16}
 16%|█▌        | 1653/10395 [4:44:17<56:42:29, 23.35s/it] 16%|█▌        | 1654/10395 [4:44:26<46:01:14, 18.95s/it]                                                         {'loss': 0.9365, 'learning_rate': 1.913849349978756e-05, 'epoch': 0.16}
 16%|█▌        | 1654/10395 [4:44:26<46:01:14, 18.95s/it] 16%|█▌        | 1655/10395 [4:44:33<37:29:54, 15.45s/it]                                                         {'loss': 1.0366, 'learning_rate': 1.9137227902624564e-05, 'epoch': 0.16}
 16%|█▌        | 1655/10395 [4:44:33<37:29:54, 15.45s/it] 16%|█▌        | 1656/10395 [4:44:42<32:40:22, 13.46s/it]                                                         {'loss': 0.8908, 'learning_rate': 1.913596141843901e-05, 'epoch': 0.16}
 16%|█▌        | 1656/10395 [4:44:42<32:40:22, 13.46s/it] 16%|█▌        | 1657/10395 [4:44:49<28:28:37, 11.73s/it]                                                         {'loss': 1.0012, 'learning_rate': 1.9134694047353846e-05, 'epoch': 0.16}
 16%|█▌        | 1657/10395 [4:44:49<28:28:37, 11.73s/it] 16%|█▌        | 1658/10395 [4:44:57<25:24:08, 10.47s/it]                                                         {'loss': 1.0063, 'learning_rate': 1.9133425789492106e-05, 'epoch': 0.16}
 16%|█▌        | 1658/10395 [4:44:57<25:24:08, 10.47s/it] 16%|█▌        | 1659/10395 [4:45:04<23:04:38,  9.51s/it]                                                         {'loss': 1.0721, 'learning_rate': 1.9132156644976906e-05, 'epoch': 0.16}
 16%|█▌        | 1659/10395 [4:45:04<23:04:38,  9.51s/it] 16%|█▌        | 1660/10395 [4:45:13<22:35:24,  9.31s/it]                                                         {'loss': 1.0001, 'learning_rate': 1.9130886613931457e-05, 'epoch': 0.16}
 16%|█▌        | 1660/10395 [4:45:13<22:35:24,  9.31s/it] 16%|█▌        | 1661/10395 [4:45:21<21:23:46,  8.82s/it]                                                         {'loss': 0.9618, 'learning_rate': 1.9129615696479046e-05, 'epoch': 0.16}
 16%|█▌        | 1661/10395 [4:45:21<21:23:46,  8.82s/it] 16%|█▌        | 1662/10395 [4:45:30<21:26:06,  8.84s/it]                                                         {'loss': 0.9273, 'learning_rate': 1.9128343892743055e-05, 'epoch': 0.16}
 16%|█▌        | 1662/10395 [4:45:30<21:26:06,  8.84s/it] 16%|█▌        | 1663/10395 [4:45:37<20:30:58,  8.46s/it]                                                         {'loss': 0.9426, 'learning_rate': 1.9127071202846945e-05, 'epoch': 0.16}
 16%|█▌        | 1663/10395 [4:45:37<20:30:58,  8.46s/it] 16%|█▌        | 1664/10395 [4:45:45<20:20:13,  8.39s/it]                                                         {'loss': 0.943, 'learning_rate': 1.912579762691427e-05, 'epoch': 0.16}
 16%|█▌        | 1664/10395 [4:45:45<20:20:13,  8.39s/it] 16%|█▌        | 1665/10395 [4:45:53<19:42:47,  8.13s/it]                                                         {'loss': 0.9208, 'learning_rate': 1.912452316506866e-05, 'epoch': 0.16}
 16%|█▌        | 1665/10395 [4:45:53<19:42:47,  8.13s/it] 16%|█▌        | 1666/10395 [4:46:01<19:56:47,  8.23s/it]                                                         {'loss': 0.9962, 'learning_rate': 1.912324781743384e-05, 'epoch': 0.16}
 16%|█▌        | 1666/10395 [4:46:01<19:56:47,  8.23s/it] 16%|█▌        | 1667/10395 [4:46:09<19:46:53,  8.16s/it]                                                         {'loss': 0.9561, 'learning_rate': 1.912197158413362e-05, 'epoch': 0.16}
 16%|█▌        | 1667/10395 [4:46:09<19:46:53,  8.16s/it] 16%|█▌        | 1668/10395 [4:46:17<19:38:52,  8.11s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.9120694465291893e-05, 'epoch': 0.16}
 16%|█▌        | 1668/10395 [4:46:17<19:38:52,  8.11s/it] 16%|█▌        | 1669/10395 [4:46:27<20:56:19,  8.64s/it]                                                         {'loss': 0.993, 'learning_rate': 1.9119416461032636e-05, 'epoch': 0.16}
 16%|█▌        | 1669/10395 [4:46:27<20:56:19,  8.64s/it] 16%|█▌        | 1670/10395 [4:46:35<20:01:32,  8.26s/it]                                                         {'loss': 0.9503, 'learning_rate': 1.911813757147992e-05, 'epoch': 0.16}
 16%|█▌        | 1670/10395 [4:46:35<20:01:32,  8.26s/it] 16%|█▌        | 1671/10395 [4:46:44<20:33:30,  8.48s/it]                                                         {'loss': 1.0002, 'learning_rate': 1.9116857796757892e-05, 'epoch': 0.16}
 16%|█▌        | 1671/10395 [4:46:44<20:33:30,  8.48s/it] 16%|█▌        | 1672/10395 [4:46:51<20:04:49,  8.29s/it]                                                         {'loss': 0.9533, 'learning_rate': 1.9115577136990792e-05, 'epoch': 0.16}
 16%|█▌        | 1672/10395 [4:46:51<20:04:49,  8.29s/it] 16%|█▌        | 1673/10395 [4:46:59<19:51:03,  8.19s/it]                                                         {'loss': 0.9866, 'learning_rate': 1.9114295592302944e-05, 'epoch': 0.16}
 16%|█▌        | 1673/10395 [4:46:59<19:51:03,  8.19s/it] 16%|█▌        | 1674/10395 [4:47:07<19:14:04,  7.94s/it]                                                         {'loss': 1.0382, 'learning_rate': 1.9113013162818757e-05, 'epoch': 0.16}
 16%|█▌        | 1674/10395 [4:47:07<19:14:04,  7.94s/it] 16%|█▌        | 1675/10395 [4:47:16<19:55:58,  8.23s/it]                                                         {'loss': 0.9439, 'learning_rate': 1.9111729848662728e-05, 'epoch': 0.16}
 16%|█▌        | 1675/10395 [4:47:16<19:55:58,  8.23s/it] 16%|█▌        | 1676/10395 [4:47:23<19:19:17,  7.98s/it]                                                         {'loss': 1.0108, 'learning_rate': 1.9110445649959435e-05, 'epoch': 0.16}
 16%|█▌        | 1676/10395 [4:47:23<19:19:17,  7.98s/it] 16%|█▌        | 1677/10395 [4:47:31<19:02:03,  7.86s/it]                                                         {'loss': 1.0255, 'learning_rate': 1.9109160566833548e-05, 'epoch': 0.16}
 16%|█▌        | 1677/10395 [4:47:31<19:02:03,  7.86s/it] 16%|█▌        | 1678/10395 [4:47:38<18:48:35,  7.77s/it]                                                         {'loss': 1.0779, 'learning_rate': 1.910787459940982e-05, 'epoch': 0.16}
 16%|█▌        | 1678/10395 [4:47:38<18:48:35,  7.77s/it] 16%|█▌        | 1679/10395 [4:47:46<18:53:30,  7.80s/it]                                                         {'loss': 1.0198, 'learning_rate': 1.9106587747813092e-05, 'epoch': 0.16}
 16%|█▌        | 1679/10395 [4:47:46<18:53:30,  7.80s/it] 16%|█▌        | 1680/10395 [4:47:54<18:44:49,  7.74s/it]                                                         {'loss': 1.0269, 'learning_rate': 1.910530001216828e-05, 'epoch': 0.16}
 16%|█▌        | 1680/10395 [4:47:54<18:44:49,  7.74s/it] 16%|█▌        | 1681/10395 [4:48:02<19:01:50,  7.86s/it]                                                         {'loss': 1.0369, 'learning_rate': 1.9104011392600407e-05, 'epoch': 0.16}
 16%|█▌        | 1681/10395 [4:48:02<19:01:50,  7.86s/it] 16%|█▌        | 1682/10395 [4:48:09<18:23:08,  7.60s/it]                                                         {'loss': 1.0318, 'learning_rate': 1.910272188923456e-05, 'epoch': 0.16}
 16%|█▌        | 1682/10395 [4:48:09<18:23:08,  7.60s/it] 16%|█▌        | 1683/10395 [4:48:18<19:36:12,  8.10s/it]                                                         {'loss': 0.9113, 'learning_rate': 1.9101431502195925e-05, 'epoch': 0.16}
 16%|█▌        | 1683/10395 [4:48:18<19:36:12,  8.10s/it] 16%|█▌        | 1684/10395 [4:48:26<19:16:04,  7.96s/it]                                                         {'loss': 0.9963, 'learning_rate': 1.910014023160977e-05, 'epoch': 0.16}
 16%|█▌        | 1684/10395 [4:48:26<19:16:04,  7.96s/it] 16%|█▌        | 1685/10395 [4:48:34<19:09:24,  7.92s/it]                                                         {'loss': 0.9601, 'learning_rate': 1.909884807760145e-05, 'epoch': 0.16}
 16%|█▌        | 1685/10395 [4:48:34<19:09:24,  7.92s/it] 16%|█▌        | 1686/10395 [4:48:41<19:07:50,  7.91s/it]                                                         {'loss': 0.9089, 'learning_rate': 1.90975550402964e-05, 'epoch': 0.16}
 16%|█▌        | 1686/10395 [4:48:41<19:07:50,  7.91s/it] 16%|█▌        | 1687/10395 [4:48:49<18:45:17,  7.75s/it]                                                         {'loss': 0.9962, 'learning_rate': 1.909626111982015e-05, 'epoch': 0.16}
 16%|█▌        | 1687/10395 [4:48:49<18:45:17,  7.75s/it] 16%|█▌        | 1688/10395 [4:48:57<19:13:37,  7.95s/it]                                                         {'loss': 1.0182, 'learning_rate': 1.909496631629831e-05, 'epoch': 0.16}
 16%|█▌        | 1688/10395 [4:48:57<19:13:37,  7.95s/it] 16%|█▌        | 1689/10395 [4:49:05<18:51:33,  7.80s/it]                                                         {'loss': 0.9889, 'learning_rate': 1.9093670629856577e-05, 'epoch': 0.16}
 16%|█▌        | 1689/10395 [4:49:05<18:51:33,  7.80s/it] 16%|█▋        | 1690/10395 [4:49:12<18:25:00,  7.62s/it]                                                         {'loss': 1.0275, 'learning_rate': 1.909237406062073e-05, 'epoch': 0.16}
 16%|█▋        | 1690/10395 [4:49:12<18:25:00,  7.62s/it] 16%|█▋        | 1691/10395 [4:49:21<19:50:47,  8.21s/it]                                                         {'loss': 0.8879, 'learning_rate': 1.9091076608716638e-05, 'epoch': 0.16}
 16%|█▋        | 1691/10395 [4:49:21<19:50:47,  8.21s/it] 16%|█▋        | 1692/10395 [4:49:30<20:13:47,  8.37s/it]                                                         {'loss': 0.9498, 'learning_rate': 1.9089778274270262e-05, 'epoch': 0.16}
 16%|█▋        | 1692/10395 [4:49:30<20:13:47,  8.37s/it] 16%|█▋        | 1693/10395 [4:49:38<20:09:52,  8.34s/it]                                                         {'loss': 0.9785, 'learning_rate': 1.9088479057407632e-05, 'epoch': 0.16}
 16%|█▋        | 1693/10395 [4:49:38<20:09:52,  8.34s/it] 16%|█▋        | 1694/10395 [4:49:47<20:05:15,  8.31s/it]                                                         {'loss': 0.9438, 'learning_rate': 1.9087178958254877e-05, 'epoch': 0.16}
 16%|█▋        | 1694/10395 [4:49:47<20:05:15,  8.31s/it] 16%|█▋        | 1695/10395 [4:49:55<19:49:23,  8.20s/it]                                                         {'loss': 1.0414, 'learning_rate': 1.908587797693821e-05, 'epoch': 0.16}
 16%|█▋        | 1695/10395 [4:49:55<19:49:23,  8.20s/it] 16%|█▋        | 1696/10395 [4:50:02<19:17:08,  7.98s/it]                                                         {'loss': 1.0014, 'learning_rate': 1.9084576113583924e-05, 'epoch': 0.16}
 16%|█▋        | 1696/10395 [4:50:02<19:17:08,  7.98s/it] 16%|█▋        | 1697/10395 [4:50:10<19:20:00,  8.00s/it]                                                         {'loss': 0.9455, 'learning_rate': 1.9083273368318403e-05, 'epoch': 0.16}
 16%|█▋        | 1697/10395 [4:50:10<19:20:00,  8.00s/it] 16%|█▋        | 1698/10395 [4:50:18<18:58:25,  7.85s/it]                                                         {'loss': 1.0063, 'learning_rate': 1.9081969741268117e-05, 'epoch': 0.16}
 16%|█▋        | 1698/10395 [4:50:18<18:58:25,  7.85s/it] 16%|█▋        | 1699/10395 [4:50:25<18:40:51,  7.73s/it]                                                         {'loss': 0.9486, 'learning_rate': 1.9080665232559614e-05, 'epoch': 0.16}
 16%|█▋        | 1699/10395 [4:50:25<18:40:51,  7.73s/it] 16%|█▋        | 1700/10395 [4:50:32<18:15:58,  7.56s/it]                                                         {'loss': 1.0613, 'learning_rate': 1.9079359842319534e-05, 'epoch': 0.16}
 16%|█▋        | 1700/10395 [4:50:32<18:15:58,  7.56s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 16%|█▋        | 1701/10395 [4:52:12<84:56:25, 35.17s/it]                                                         {'loss': 1.0002, 'learning_rate': 1.907805357067461e-05, 'epoch': 0.16}
 16%|█▋        | 1701/10395 [4:52:12<84:56:25, 35.17s/it] 16%|█▋        | 1702/10395 [4:52:20<65:20:27, 27.06s/it]                                                         {'loss': 1.0092, 'learning_rate': 1.907674641775164e-05, 'epoch': 0.16}
 16%|█▋        | 1702/10395 [4:52:20<65:20:27, 27.06s/it] 16%|█▋        | 1703/10395 [4:52:28<51:16:57, 21.24s/it]                                                         {'loss': 1.007, 'learning_rate': 1.9075438383677523e-05, 'epoch': 0.16}
 16%|█▋        | 1703/10395 [4:52:28<51:16:57, 21.24s/it] 16%|█▋        | 1704/10395 [4:52:35<41:22:58, 17.14s/it]                                                         {'loss': 1.0086, 'learning_rate': 1.9074129468579247e-05, 'epoch': 0.16}
 16%|█▋        | 1704/10395 [4:52:35<41:22:58, 17.14s/it] 16%|█▋        | 1705/10395 [4:52:43<34:31:47, 14.30s/it]                                                         {'loss': 1.0029, 'learning_rate': 1.907281967258387e-05, 'epoch': 0.16}
 16%|█▋        | 1705/10395 [4:52:43<34:31:47, 14.30s/it] 16%|█▋        | 1706/10395 [4:52:50<29:32:17, 12.24s/it]                                                         {'loss': 1.083, 'learning_rate': 1.9071508995818547e-05, 'epoch': 0.16}
 16%|█▋        | 1706/10395 [4:52:50<29:32:17, 12.24s/it] 16%|█▋        | 1707/10395 [4:53:08<33:47:02, 14.00s/it]                                                         {'loss': 0.3582, 'learning_rate': 1.907019743841052e-05, 'epoch': 0.16}
 16%|█▋        | 1707/10395 [4:53:08<33:47:02, 14.00s/it] 16%|█▋        | 1708/10395 [4:53:16<29:02:18, 12.03s/it]                                                         {'loss': 0.9772, 'learning_rate': 1.9068885000487107e-05, 'epoch': 0.16}
 16%|█▋        | 1708/10395 [4:53:16<29:02:18, 12.03s/it] 16%|█▋        | 1709/10395 [4:53:24<25:54:32, 10.74s/it]                                                         {'loss': 0.9403, 'learning_rate': 1.906757168217572e-05, 'epoch': 0.16}
 16%|█▋        | 1709/10395 [4:53:24<25:54:32, 10.74s/it] 16%|█▋        | 1710/10395 [4:53:31<23:31:48,  9.75s/it]                                                         {'loss': 1.0097, 'learning_rate': 1.906625748360385e-05, 'epoch': 0.16}
 16%|█▋        | 1710/10395 [4:53:31<23:31:48,  9.75s/it] 16%|█▋        | 1711/10395 [4:53:39<22:20:44,  9.26s/it]                                                         {'loss': 1.0115, 'learning_rate': 1.9064942404899075e-05, 'epoch': 0.16}
 16%|█▋        | 1711/10395 [4:53:39<22:20:44,  9.26s/it] 16%|█▋        | 1712/10395 [4:53:47<21:32:20,  8.93s/it]                                                         {'loss': 0.8583, 'learning_rate': 1.9063626446189068e-05, 'epoch': 0.16}
 16%|█▋        | 1712/10395 [4:53:47<21:32:20,  8.93s/it] 16%|█▋        | 1713/10395 [4:53:56<21:04:34,  8.74s/it]                                                         {'loss': 0.9986, 'learning_rate': 1.9062309607601575e-05, 'epoch': 0.16}
 16%|█▋        | 1713/10395 [4:53:56<21:04:34,  8.74s/it] 16%|█▋        | 1714/10395 [4:54:03<20:04:26,  8.32s/it]                                                         {'loss': 0.9747, 'learning_rate': 1.906099188926443e-05, 'epoch': 0.16}
 16%|█▋        | 1714/10395 [4:54:03<20:04:26,  8.32s/it] 16%|█▋        | 1715/10395 [4:54:10<19:22:36,  8.04s/it]                                                         {'loss': 1.013, 'learning_rate': 1.9059673291305553e-05, 'epoch': 0.16}
 16%|█▋        | 1715/10395 [4:54:10<19:22:36,  8.04s/it] 17%|█▋        | 1716/10395 [4:54:18<19:06:46,  7.93s/it]                                                         {'loss': 0.946, 'learning_rate': 1.9058353813852958e-05, 'epoch': 0.17}
 17%|█▋        | 1716/10395 [4:54:18<19:06:46,  7.93s/it] 17%|█▋        | 1717/10395 [4:54:26<19:07:27,  7.93s/it]                                                         {'loss': 0.9408, 'learning_rate': 1.905703345703473e-05, 'epoch': 0.17}
 17%|█▋        | 1717/10395 [4:54:26<19:07:27,  7.93s/it] 17%|█▋        | 1718/10395 [4:54:35<19:40:48,  8.17s/it]                                                         {'loss': 0.9751, 'learning_rate': 1.9055712220979052e-05, 'epoch': 0.17}
 17%|█▋        | 1718/10395 [4:54:35<19:40:48,  8.17s/it] 17%|█▋        | 1719/10395 [4:54:43<19:30:40,  8.10s/it]                                                         {'loss': 0.9536, 'learning_rate': 1.905439010581418e-05, 'epoch': 0.17}
 17%|█▋        | 1719/10395 [4:54:43<19:30:40,  8.10s/it] 17%|█▋        | 1720/10395 [4:54:50<19:19:28,  8.02s/it]                                                         {'loss': 0.8593, 'learning_rate': 1.9053067111668465e-05, 'epoch': 0.17}
 17%|█▋        | 1720/10395 [4:54:50<19:19:28,  8.02s/it] 17%|█▋        | 1721/10395 [4:54:58<19:01:10,  7.89s/it]                                                         {'loss': 0.9168, 'learning_rate': 1.9051743238670344e-05, 'epoch': 0.17}
 17%|█▋        | 1721/10395 [4:54:58<19:01:10,  7.89s/it] 17%|█▋        | 1722/10395 [4:55:07<19:39:27,  8.16s/it]                                                         {'loss': 0.8411, 'learning_rate': 1.9050418486948334e-05, 'epoch': 0.17}
 17%|█▋        | 1722/10395 [4:55:07<19:39:27,  8.16s/it] 17%|█▋        | 1723/10395 [4:55:15<19:20:13,  8.03s/it]                                                         {'loss': 0.9483, 'learning_rate': 1.9049092856631035e-05, 'epoch': 0.17}
 17%|█▋        | 1723/10395 [4:55:15<19:20:13,  8.03s/it] 17%|█▋        | 1724/10395 [4:55:23<19:34:22,  8.13s/it]                                                         {'loss': 1.0224, 'learning_rate': 1.9047766347847142e-05, 'epoch': 0.17}
 17%|█▋        | 1724/10395 [4:55:23<19:34:22,  8.13s/it] 17%|█▋        | 1725/10395 [4:55:30<18:53:34,  7.84s/it]                                                         {'loss': 1.0049, 'learning_rate': 1.9046438960725428e-05, 'epoch': 0.17}
 17%|█▋        | 1725/10395 [4:55:30<18:53:34,  7.84s/it] 17%|█▋        | 1726/10395 [4:55:37<18:25:21,  7.65s/it]                                                         {'loss': 1.0497, 'learning_rate': 1.904511069539475e-05, 'epoch': 0.17}
 17%|█▋        | 1726/10395 [4:55:37<18:25:21,  7.65s/it] 17%|█▋        | 1727/10395 [4:55:45<18:33:52,  7.71s/it]                                                         {'loss': 0.9661, 'learning_rate': 1.9043781551984053e-05, 'epoch': 0.17}
 17%|█▋        | 1727/10395 [4:55:45<18:33:52,  7.71s/it] 17%|█▋        | 1728/10395 [4:55:53<18:38:12,  7.74s/it]                                                         {'loss': 0.9607, 'learning_rate': 1.9042451530622372e-05, 'epoch': 0.17}
 17%|█▋        | 1728/10395 [4:55:53<18:38:12,  7.74s/it] 17%|█▋        | 1729/10395 [4:56:00<18:25:18,  7.65s/it]                                                         {'loss': 0.989, 'learning_rate': 1.9041120631438818e-05, 'epoch': 0.17}
 17%|█▋        | 1729/10395 [4:56:00<18:25:18,  7.65s/it] 17%|█▋        | 1730/10395 [4:56:08<18:41:26,  7.77s/it]                                                         {'loss': 1.0248, 'learning_rate': 1.9039788854562597e-05, 'epoch': 0.17}
 17%|█▋        | 1730/10395 [4:56:08<18:41:26,  7.77s/it] 17%|█▋        | 1731/10395 [4:56:16<18:21:43,  7.63s/it]                                                         {'loss': 1.0255, 'learning_rate': 1.903845620012299e-05, 'epoch': 0.17}
 17%|█▋        | 1731/10395 [4:56:16<18:21:43,  7.63s/it] 17%|█▋        | 1732/10395 [4:56:23<18:26:03,  7.66s/it]                                                         {'loss': 0.903, 'learning_rate': 1.9037122668249372e-05, 'epoch': 0.17}
 17%|█▋        | 1732/10395 [4:56:23<18:26:03,  7.66s/it] 17%|█▋        | 1733/10395 [4:56:31<18:14:31,  7.58s/it]                                                         {'loss': 1.0132, 'learning_rate': 1.90357882590712e-05, 'epoch': 0.17}
 17%|█▋        | 1733/10395 [4:56:31<18:14:31,  7.58s/it] 17%|█▋        | 1734/10395 [4:56:39<18:28:48,  7.68s/it]                                                         {'loss': 0.9985, 'learning_rate': 1.9034452972718008e-05, 'epoch': 0.17}
 17%|█▋        | 1734/10395 [4:56:39<18:28:48,  7.68s/it] 17%|█▋        | 1735/10395 [4:56:46<18:21:42,  7.63s/it]                                                         {'loss': 1.0135, 'learning_rate': 1.903311680931943e-05, 'epoch': 0.17}
 17%|█▋        | 1735/10395 [4:56:46<18:21:42,  7.63s/it] 17%|█▋        | 1736/10395 [4:56:54<18:12:44,  7.57s/it]                                                         {'loss': 1.015, 'learning_rate': 1.903177976900518e-05, 'epoch': 0.17}
 17%|█▋        | 1736/10395 [4:56:54<18:12:44,  7.57s/it] 17%|█▋        | 1737/10395 [4:57:02<18:33:09,  7.71s/it]                                                         {'loss': 1.028, 'learning_rate': 1.9030441851905046e-05, 'epoch': 0.17}
 17%|█▋        | 1737/10395 [4:57:02<18:33:09,  7.71s/it] 17%|█▋        | 1738/10395 [4:57:09<18:14:57,  7.59s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.9029103058148916e-05, 'epoch': 0.17}
 17%|█▋        | 1738/10395 [4:57:09<18:14:57,  7.59s/it] 17%|█▋        | 1739/10395 [4:57:17<18:08:05,  7.54s/it]                                                         {'loss': 0.9035, 'learning_rate': 1.9027763387866757e-05, 'epoch': 0.17}
 17%|█▋        | 1739/10395 [4:57:17<18:08:05,  7.54s/it] 17%|█▋        | 1740/10395 [4:57:25<18:30:22,  7.70s/it]                                                         {'loss': 0.9706, 'learning_rate': 1.902642284118862e-05, 'epoch': 0.17}
 17%|█▋        | 1740/10395 [4:57:25<18:30:22,  7.70s/it] 17%|█▋        | 1741/10395 [4:57:42<25:45:13, 10.71s/it]                                                         {'loss': 0.4029, 'learning_rate': 1.9025081418244645e-05, 'epoch': 0.17}
 17%|█▋        | 1741/10395 [4:57:42<25:45:13, 10.71s/it] 17%|█▋        | 1742/10395 [4:57:50<23:41:28,  9.86s/it]                                                         {'loss': 0.9775, 'learning_rate': 1.902373911916505e-05, 'epoch': 0.17}
 17%|█▋        | 1742/10395 [4:57:50<23:41:28,  9.86s/it] 17%|█▋        | 1743/10395 [4:57:58<21:54:44,  9.12s/it]                                                         {'loss': 1.069, 'learning_rate': 1.9022395944080147e-05, 'epoch': 0.17}
 17%|█▋        | 1743/10395 [4:57:58<21:54:44,  9.12s/it] 17%|█▋        | 1744/10395 [4:58:05<20:46:56,  8.65s/it]                                                         {'loss': 0.944, 'learning_rate': 1.9021051893120324e-05, 'epoch': 0.17}
 17%|█▋        | 1744/10395 [4:58:05<20:46:56,  8.65s/it] 17%|█▋        | 1745/10395 [4:58:13<20:04:26,  8.35s/it]                                                         {'loss': 1.0266, 'learning_rate': 1.9019706966416068e-05, 'epoch': 0.17}
 17%|█▋        | 1745/10395 [4:58:13<20:04:26,  8.35s/it] 17%|█▋        | 1746/10395 [4:58:21<19:38:34,  8.18s/it]                                                         {'loss': 0.9153, 'learning_rate': 1.901836116409793e-05, 'epoch': 0.17}
 17%|█▋        | 1746/10395 [4:58:21<19:38:34,  8.18s/it] 17%|█▋        | 1747/10395 [4:58:28<19:22:44,  8.07s/it]                                                         {'loss': 1.0202, 'learning_rate': 1.9017014486296563e-05, 'epoch': 0.17}
 17%|█▋        | 1747/10395 [4:58:28<19:22:44,  8.07s/it] 17%|█▋        | 1748/10395 [4:58:36<19:02:21,  7.93s/it]                                                         {'loss': 0.9047, 'learning_rate': 1.90156669331427e-05, 'epoch': 0.17}
 17%|█▋        | 1748/10395 [4:58:36<19:02:21,  7.93s/it] 17%|█▋        | 1749/10395 [4:58:44<19:07:32,  7.96s/it]                                                         {'loss': 1.0192, 'learning_rate': 1.9014318504767155e-05, 'epoch': 0.17}
 17%|█▋        | 1749/10395 [4:58:44<19:07:32,  7.96s/it] 17%|█▋        | 1750/10395 [4:58:53<19:46:06,  8.23s/it]                                                         {'loss': 0.9413, 'learning_rate': 1.9012969201300833e-05, 'epoch': 0.17}
 17%|█▋        | 1750/10395 [4:58:53<19:46:06,  8.23s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 17%|█▋        | 1751/10395 [5:00:35<87:28:54, 36.43s/it]                                                         {'loss': 0.986, 'learning_rate': 1.9011619022874726e-05, 'epoch': 0.17}
 17%|█▋        | 1751/10395 [5:00:35<87:28:54, 36.43s/it] 17%|█▋        | 1752/10395 [5:00:44<67:51:19, 28.26s/it]                                                         {'loss': 1.0028, 'learning_rate': 1.90102679696199e-05, 'epoch': 0.17}
 17%|█▋        | 1752/10395 [5:00:44<67:51:19, 28.26s/it] 17%|█▋        | 1753/10395 [5:00:52<52:48:10, 22.00s/it]                                                         {'loss': 1.0061, 'learning_rate': 1.9008916041667513e-05, 'epoch': 0.17}
 17%|█▋        | 1753/10395 [5:00:52<52:48:10, 22.00s/it] 17%|█▋        | 1754/10395 [5:00:59<42:24:37, 17.67s/it]                                                         {'loss': 0.9644, 'learning_rate': 1.9007563239148812e-05, 'epoch': 0.17}
 17%|█▋        | 1754/10395 [5:00:59<42:24:37, 17.67s/it] 17%|█▋        | 1755/10395 [5:01:07<35:13:53, 14.68s/it]                                                         {'loss': 1.0009, 'learning_rate': 1.9006209562195116e-05, 'epoch': 0.17}
 17%|█▋        | 1755/10395 [5:01:07<35:13:53, 14.68s/it] 17%|█▋        | 1756/10395 [5:01:14<30:00:35, 12.51s/it]                                                         {'loss': 0.9352, 'learning_rate': 1.9004855010937847e-05, 'epoch': 0.17}
 17%|█▋        | 1756/10395 [5:01:14<30:00:35, 12.51s/it] 17%|█▋        | 1757/10395 [5:01:22<26:39:03, 11.11s/it]                                                         {'loss': 0.9799, 'learning_rate': 1.9003499585508495e-05, 'epoch': 0.17}
 17%|█▋        | 1757/10395 [5:01:22<26:39:03, 11.11s/it] 17%|█▋        | 1758/10395 [5:01:30<24:18:46, 10.13s/it]                                                         {'loss': 1.0507, 'learning_rate': 1.9002143286038642e-05, 'epoch': 0.17}
 17%|█▋        | 1758/10395 [5:01:30<24:18:46, 10.13s/it] 17%|█▋        | 1759/10395 [5:01:38<22:40:24,  9.45s/it]                                                         {'loss': 1.0211, 'learning_rate': 1.900078611265996e-05, 'epoch': 0.17}
 17%|█▋        | 1759/10395 [5:01:38<22:40:24,  9.45s/it] 17%|█▋        | 1760/10395 [5:01:46<21:35:13,  9.00s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.8999428065504195e-05, 'epoch': 0.17}
 17%|█▋        | 1760/10395 [5:01:46<21:35:13,  9.00s/it] 17%|█▋        | 1761/10395 [5:01:54<20:47:08,  8.67s/it]                                                         {'loss': 1.0503, 'learning_rate': 1.8998069144703187e-05, 'epoch': 0.17}
 17%|█▋        | 1761/10395 [5:01:54<20:47:08,  8.67s/it] 17%|█▋        | 1762/10395 [5:02:01<19:43:36,  8.23s/it]                                                         {'loss': 0.9019, 'learning_rate': 1.8996709350388855e-05, 'epoch': 0.17}
 17%|█▋        | 1762/10395 [5:02:01<19:43:36,  8.23s/it] 17%|█▋        | 1763/10395 [5:02:09<19:40:02,  8.20s/it]                                                         {'loss': 0.9643, 'learning_rate': 1.8995348682693203e-05, 'epoch': 0.17}
 17%|█▋        | 1763/10395 [5:02:09<19:40:02,  8.20s/it] 17%|█▋        | 1764/10395 [5:02:17<19:27:58,  8.12s/it]                                                         {'loss': 1.0501, 'learning_rate': 1.8993987141748324e-05, 'epoch': 0.17}
 17%|█▋        | 1764/10395 [5:02:17<19:27:58,  8.12s/it] 17%|█▋        | 1765/10395 [5:02:25<19:35:03,  8.17s/it]                                                         {'loss': 1.0184, 'learning_rate': 1.8992624727686395e-05, 'epoch': 0.17}
 17%|█▋        | 1765/10395 [5:02:25<19:35:03,  8.17s/it] 17%|█▋        | 1766/10395 [5:02:33<19:12:25,  8.01s/it]                                                         {'loss': 0.9911, 'learning_rate': 1.8991261440639674e-05, 'epoch': 0.17}
 17%|█▋        | 1766/10395 [5:02:33<19:12:25,  8.01s/it] 17%|█▋        | 1767/10395 [5:02:40<18:42:42,  7.81s/it]                                                         {'loss': 1.0113, 'learning_rate': 1.898989728074051e-05, 'epoch': 0.17}
 17%|█▋        | 1767/10395 [5:02:40<18:42:42,  7.81s/it] 17%|█▋        | 1768/10395 [5:02:48<18:41:22,  7.80s/it]                                                         {'loss': 0.9531, 'learning_rate': 1.8988532248121324e-05, 'epoch': 0.17}
 17%|█▋        | 1768/10395 [5:02:48<18:41:22,  7.80s/it] 17%|█▋        | 1769/10395 [5:02:56<18:33:09,  7.74s/it]                                                         {'loss': 0.9689, 'learning_rate': 1.8987166342914638e-05, 'epoch': 0.17}
 17%|█▋        | 1769/10395 [5:02:56<18:33:09,  7.74s/it] 17%|█▋        | 1770/10395 [5:03:05<19:48:49,  8.27s/it]                                                         {'loss': 0.9682, 'learning_rate': 1.8985799565253052e-05, 'epoch': 0.17}
 17%|█▋        | 1770/10395 [5:03:05<19:48:49,  8.27s/it] 17%|█▋        | 1771/10395 [5:03:13<19:41:55,  8.22s/it]                                                         {'loss': 0.9945, 'learning_rate': 1.8984431915269243e-05, 'epoch': 0.17}
 17%|█▋        | 1771/10395 [5:03:13<19:41:55,  8.22s/it] 17%|█▋        | 1772/10395 [5:03:21<19:19:31,  8.07s/it]                                                         {'loss': 1.0271, 'learning_rate': 1.8983063393095983e-05, 'epoch': 0.17}
 17%|█▋        | 1772/10395 [5:03:21<19:19:31,  8.07s/it] 17%|█▋        | 1773/10395 [5:03:29<19:19:00,  8.07s/it]                                                         {'loss': 1.0753, 'learning_rate': 1.898169399886613e-05, 'epoch': 0.17}
 17%|█▋        | 1773/10395 [5:03:29<19:19:00,  8.07s/it] 17%|█▋        | 1774/10395 [5:03:37<18:50:26,  7.87s/it]                                                         {'loss': 0.9439, 'learning_rate': 1.898032373271261e-05, 'epoch': 0.17}
 17%|█▋        | 1774/10395 [5:03:37<18:50:26,  7.87s/it] 17%|█▋        | 1775/10395 [5:03:44<18:30:28,  7.73s/it]                                                         {'loss': 1.0124, 'learning_rate': 1.8978952594768464e-05, 'epoch': 0.17}
 17%|█▋        | 1775/10395 [5:03:44<18:30:28,  7.73s/it] 17%|█▋        | 1776/10395 [5:03:52<18:54:50,  7.90s/it]                                                         {'loss': 1.0046, 'learning_rate': 1.897758058516678e-05, 'epoch': 0.17}
 17%|█▋        | 1776/10395 [5:03:52<18:54:50,  7.90s/it] 17%|█▋        | 1777/10395 [5:04:00<18:56:07,  7.91s/it]                                                         {'loss': 0.9916, 'learning_rate': 1.897620770404076e-05, 'epoch': 0.17}
 17%|█▋        | 1777/10395 [5:04:00<18:56:07,  7.91s/it] 17%|█▋        | 1778/10395 [5:04:08<19:10:28,  8.01s/it]                                                         {'loss': 1.0288, 'learning_rate': 1.897483395152368e-05, 'epoch': 0.17}
 17%|█▋        | 1778/10395 [5:04:08<19:10:28,  8.01s/it] 17%|█▋        | 1779/10395 [5:04:16<18:45:20,  7.84s/it]                                                         {'loss': 0.99, 'learning_rate': 1.8973459327748897e-05, 'epoch': 0.17}
 17%|█▋        | 1779/10395 [5:04:16<18:45:20,  7.84s/it] 17%|█▋        | 1780/10395 [5:04:25<19:38:52,  8.21s/it]                                                         {'loss': 1.0339, 'learning_rate': 1.8972083832849863e-05, 'epoch': 0.17}
 17%|█▋        | 1780/10395 [5:04:25<19:38:52,  8.21s/it] 17%|█▋        | 1781/10395 [5:04:33<19:12:24,  8.03s/it]                                                         {'loss': 1.0325, 'learning_rate': 1.89707074669601e-05, 'epoch': 0.17}
 17%|█▋        | 1781/10395 [5:04:33<19:12:24,  8.03s/it] 17%|█▋        | 1782/10395 [5:04:41<19:11:54,  8.02s/it]                                                         {'loss': 0.9166, 'learning_rate': 1.8969330230213225e-05, 'epoch': 0.17}
 17%|█▋        | 1782/10395 [5:04:41<19:11:54,  8.02s/it] 17%|█▋        | 1783/10395 [5:04:49<19:13:53,  8.04s/it]                                                         {'loss': 0.9911, 'learning_rate': 1.8967952122742942e-05, 'epoch': 0.17}
 17%|█▋        | 1783/10395 [5:04:49<19:13:53,  8.04s/it] 17%|█▋        | 1784/10395 [5:04:57<19:07:42,  8.00s/it]                                                         {'loss': 0.9251, 'learning_rate': 1.8966573144683028e-05, 'epoch': 0.17}
 17%|█▋        | 1784/10395 [5:04:57<19:07:42,  8.00s/it] 17%|█▋        | 1785/10395 [5:05:15<26:18:48, 11.00s/it]                                                         {'loss': 0.3785, 'learning_rate': 1.896519329616736e-05, 'epoch': 0.17}
 17%|█▋        | 1785/10395 [5:05:15<26:18:48, 11.00s/it] 17%|█▋        | 1786/10395 [5:05:31<30:16:01, 12.66s/it]                                                         {'loss': 0.3641, 'learning_rate': 1.896381257732988e-05, 'epoch': 0.17}
 17%|█▋        | 1786/10395 [5:05:31<30:16:01, 12.66s/it] 17%|█▋        | 1787/10395 [5:05:40<27:33:39, 11.53s/it]                                                         {'loss': 0.9707, 'learning_rate': 1.8962430988304638e-05, 'epoch': 0.17}
 17%|█▋        | 1787/10395 [5:05:40<27:33:39, 11.53s/it] 17%|█▋        | 1788/10395 [5:05:58<32:05:01, 13.42s/it]                                                         {'loss': 0.3862, 'learning_rate': 1.896104852922574e-05, 'epoch': 0.17}
 17%|█▋        | 1788/10395 [5:05:58<32:05:01, 13.42s/it] 17%|█▋        | 1789/10395 [5:06:06<28:40:15, 11.99s/it]                                                         {'loss': 0.9816, 'learning_rate': 1.8959665200227406e-05, 'epoch': 0.17}
 17%|█▋        | 1789/10395 [5:06:06<28:40:15, 11.99s/it] 17%|█▋        | 1790/10395 [5:06:14<25:42:54, 10.76s/it]                                                         {'loss': 0.8651, 'learning_rate': 1.895828100144392e-05, 'epoch': 0.17}
 17%|█▋        | 1790/10395 [5:06:14<25:42:54, 10.76s/it] 17%|█▋        | 1791/10395 [5:06:22<23:45:10,  9.94s/it]                                                         {'loss': 0.9488, 'learning_rate': 1.895689593300966e-05, 'epoch': 0.17}
 17%|█▋        | 1791/10395 [5:06:22<23:45:10,  9.94s/it] 17%|█▋        | 1792/10395 [5:06:30<21:47:34,  9.12s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.895550999505908e-05, 'epoch': 0.17}
 17%|█▋        | 1792/10395 [5:06:30<21:47:34,  9.12s/it] 17%|█▋        | 1793/10395 [5:06:37<20:52:33,  8.74s/it]                                                         {'loss': 1.0715, 'learning_rate': 1.8954123187726728e-05, 'epoch': 0.17}
 17%|█▋        | 1793/10395 [5:06:37<20:52:33,  8.74s/it] 17%|█▋        | 1794/10395 [5:06:46<20:41:50,  8.66s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.8952735511147234e-05, 'epoch': 0.17}
 17%|█▋        | 1794/10395 [5:06:46<20:41:50,  8.66s/it] 17%|█▋        | 1795/10395 [5:06:53<19:51:52,  8.32s/it]                                                         {'loss': 1.0237, 'learning_rate': 1.8951346965455307e-05, 'epoch': 0.17}
 17%|█▋        | 1795/10395 [5:06:53<19:51:52,  8.32s/it] 17%|█▋        | 1796/10395 [5:07:02<20:08:45,  8.43s/it]                                                         {'loss': 0.9594, 'learning_rate': 1.8949957550785748e-05, 'epoch': 0.17}
 17%|█▋        | 1796/10395 [5:07:02<20:08:45,  8.43s/it] 17%|█▋        | 1797/10395 [5:07:10<19:33:28,  8.19s/it]                                                         {'loss': 0.9374, 'learning_rate': 1.8948567267273433e-05, 'epoch': 0.17}
 17%|█▋        | 1797/10395 [5:07:10<19:33:28,  8.19s/it] 17%|█▋        | 1798/10395 [5:07:17<19:06:46,  8.00s/it]                                                         {'loss': 0.9837, 'learning_rate': 1.8947176115053334e-05, 'epoch': 0.17}
 17%|█▋        | 1798/10395 [5:07:17<19:06:46,  8.00s/it] 17%|█▋        | 1799/10395 [5:07:24<18:33:09,  7.77s/it]                                                         {'loss': 1.0507, 'learning_rate': 1.8945784094260497e-05, 'epoch': 0.17}
 17%|█▋        | 1799/10395 [5:07:25<18:33:09,  7.77s/it] 17%|█▋        | 1800/10395 [5:07:32<18:20:25,  7.68s/it]                                                         {'loss': 0.9525, 'learning_rate': 1.8944391205030057e-05, 'epoch': 0.17}
 17%|█▋        | 1800/10395 [5:07:32<18:20:25,  7.68s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 17%|█▋        | 1801/10395 [5:09:11<83:34:41, 35.01s/it]                                                         {'loss': 0.9827, 'learning_rate': 1.894299744749723e-05, 'epoch': 0.17}
 17%|█▋        | 1801/10395 [5:09:11<83:34:41, 35.01s/it] 17%|█▋        | 1802/10395 [5:09:19<64:19:20, 26.95s/it]                                                         {'loss': 0.9191, 'learning_rate': 1.894160282179733e-05, 'epoch': 0.17}
 17%|█▋        | 1802/10395 [5:09:19<64:19:20, 26.95s/it] 17%|█▋        | 1803/10395 [5:09:27<50:42:56, 21.25s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.8940207328065728e-05, 'epoch': 0.17}
 17%|█▋        | 1803/10395 [5:09:27<50:42:56, 21.25s/it] 17%|█▋        | 1804/10395 [5:09:35<41:29:58, 17.39s/it]                                                         {'loss': 0.9813, 'learning_rate': 1.8938810966437908e-05, 'epoch': 0.17}
 17%|█▋        | 1804/10395 [5:09:35<41:29:58, 17.39s/it] 17%|█▋        | 1805/10395 [5:09:42<34:04:32, 14.28s/it]                                                         {'loss': 1.0162, 'learning_rate': 1.893741373704942e-05, 'epoch': 0.17}
 17%|█▋        | 1805/10395 [5:09:42<34:04:32, 14.28s/it] 17%|█▋        | 1806/10395 [5:09:49<28:58:08, 12.14s/it]                                                         {'loss': 1.0072, 'learning_rate': 1.8936015640035907e-05, 'epoch': 0.17}
 17%|█▋        | 1806/10395 [5:09:49<28:58:08, 12.14s/it] 17%|█▋        | 1807/10395 [5:09:59<26:53:46, 11.27s/it]                                                         {'loss': 0.8979, 'learning_rate': 1.8934616675533092e-05, 'epoch': 0.17}
 17%|█▋        | 1807/10395 [5:09:59<26:53:46, 11.27s/it] 17%|█▋        | 1808/10395 [5:10:07<24:48:20, 10.40s/it]                                                         {'loss': 0.913, 'learning_rate': 1.8933216843676787e-05, 'epoch': 0.17}
 17%|█▋        | 1808/10395 [5:10:07<24:48:20, 10.40s/it] 17%|█▋        | 1809/10395 [5:10:15<22:48:28,  9.56s/it]                                                         {'loss': 0.9762, 'learning_rate': 1.8931816144602874e-05, 'epoch': 0.17}
 17%|█▋        | 1809/10395 [5:10:15<22:48:28,  9.56s/it] 17%|█▋        | 1810/10395 [5:10:24<22:32:23,  9.45s/it]                                                         {'loss': 1.0027, 'learning_rate': 1.893041457844734e-05, 'epoch': 0.17}
 17%|█▋        | 1810/10395 [5:10:24<22:32:23,  9.45s/it] 17%|█▋        | 1811/10395 [5:10:31<20:48:49,  8.73s/it]                                                         {'loss': 0.9479, 'learning_rate': 1.8929012145346243e-05, 'epoch': 0.17}
 17%|█▋        | 1811/10395 [5:10:31<20:48:49,  8.73s/it] 17%|█▋        | 1812/10395 [5:10:38<19:51:43,  8.33s/it]                                                         {'loss': 1.0252, 'learning_rate': 1.8927608845435728e-05, 'epoch': 0.17}
 17%|█▋        | 1812/10395 [5:10:38<19:51:43,  8.33s/it] 17%|█▋        | 1813/10395 [5:10:46<19:10:04,  8.04s/it]                                                         {'loss': 0.9414, 'learning_rate': 1.8926204678852027e-05, 'epoch': 0.17}
 17%|█▋        | 1813/10395 [5:10:46<19:10:04,  8.04s/it] 17%|█▋        | 1814/10395 [5:11:03<26:04:15, 10.94s/it]                                                         {'loss': 0.4401, 'learning_rate': 1.892479964573145e-05, 'epoch': 0.17}
 17%|█▋        | 1814/10395 [5:11:03<26:04:15, 10.94s/it] 17%|█▋        | 1815/10395 [5:11:11<23:51:35, 10.01s/it]                                                         {'loss': 0.9633, 'learning_rate': 1.8923393746210395e-05, 'epoch': 0.17}
 17%|█▋        | 1815/10395 [5:11:11<23:51:35, 10.01s/it] 17%|█▋        | 1816/10395 [5:11:30<29:57:41, 12.57s/it]                                                         {'loss': 0.41, 'learning_rate': 1.8921986980425344e-05, 'epoch': 0.17}
 17%|█▋        | 1816/10395 [5:11:30<29:57:41, 12.57s/it] 17%|█▋        | 1817/10395 [5:11:37<26:31:03, 11.13s/it]                                                         {'loss': 1.0037, 'learning_rate': 1.8920579348512864e-05, 'epoch': 0.17}
 17%|█▋        | 1817/10395 [5:11:37<26:31:03, 11.13s/it] 17%|█▋        | 1818/10395 [5:11:45<24:15:59, 10.19s/it]                                                         {'loss': 1.0217, 'learning_rate': 1.8919170850609606e-05, 'epoch': 0.17}
 17%|█▋        | 1818/10395 [5:11:45<24:15:59, 10.19s/it] 17%|█▋        | 1819/10395 [5:11:53<22:34:35,  9.48s/it]                                                         {'loss': 1.0024, 'learning_rate': 1.89177614868523e-05, 'epoch': 0.17}
 17%|█▋        | 1819/10395 [5:11:53<22:34:35,  9.48s/it] 18%|█▊        | 1820/10395 [5:12:01<20:58:09,  8.80s/it]                                                         {'loss': 0.9808, 'learning_rate': 1.8916351257377764e-05, 'epoch': 0.18}
 18%|█▊        | 1820/10395 [5:12:01<20:58:09,  8.80s/it] 18%|█▊        | 1821/10395 [5:12:08<20:13:59,  8.50s/it]                                                         {'loss': 0.9825, 'learning_rate': 1.8914940162322907e-05, 'epoch': 0.18}
 18%|█▊        | 1821/10395 [5:12:08<20:13:59,  8.50s/it] 18%|█▊        | 1822/10395 [5:12:16<19:21:46,  8.13s/it]                                                         {'loss': 1.0099, 'learning_rate': 1.8913528201824706e-05, 'epoch': 0.18}
 18%|█▊        | 1822/10395 [5:12:16<19:21:46,  8.13s/it] 18%|█▊        | 1823/10395 [5:12:24<19:37:53,  8.24s/it]                                                         {'loss': 0.957, 'learning_rate': 1.891211537602024e-05, 'epoch': 0.18}
 18%|█▊        | 1823/10395 [5:12:24<19:37:53,  8.24s/it] 18%|█▊        | 1824/10395 [5:12:32<19:05:05,  8.02s/it]                                                         {'loss': 0.9073, 'learning_rate': 1.8910701685046656e-05, 'epoch': 0.18}
 18%|█▊        | 1824/10395 [5:12:32<19:05:05,  8.02s/it] 18%|█▊        | 1825/10395 [5:12:39<18:50:51,  7.92s/it]                                                         {'loss': 1.0121, 'learning_rate': 1.890928712904119e-05, 'epoch': 0.18}
 18%|█▊        | 1825/10395 [5:12:39<18:50:51,  7.92s/it] 18%|█▊        | 1826/10395 [5:12:47<18:30:10,  7.77s/it]                                                         {'loss': 1.0328, 'learning_rate': 1.8907871708141177e-05, 'epoch': 0.18}
 18%|█▊        | 1826/10395 [5:12:47<18:30:10,  7.77s/it] 18%|█▊        | 1827/10395 [5:12:55<18:47:23,  7.89s/it]                                                         {'loss': 1.051, 'learning_rate': 1.890645542248401e-05, 'epoch': 0.18}
 18%|█▊        | 1827/10395 [5:12:55<18:47:23,  7.89s/it] 18%|█▊        | 1828/10395 [5:13:03<18:36:06,  7.82s/it]                                                         {'loss': 1.0132, 'learning_rate': 1.8905038272207187e-05, 'epoch': 0.18}
 18%|█▊        | 1828/10395 [5:13:03<18:36:06,  7.82s/it] 18%|█▊        | 1829/10395 [5:13:09<17:58:05,  7.55s/it]                                                         {'loss': 1.0876, 'learning_rate': 1.8903620257448273e-05, 'epoch': 0.18}
 18%|█▊        | 1829/10395 [5:13:09<17:58:05,  7.55s/it] 18%|█▊        | 1830/10395 [5:13:27<25:14:43, 10.61s/it]                                                         {'loss': 0.3634, 'learning_rate': 1.8902201378344938e-05, 'epoch': 0.18}
 18%|█▊        | 1830/10395 [5:13:27<25:14:43, 10.61s/it] 18%|█▊        | 1831/10395 [5:13:34<22:52:26,  9.62s/it]                                                         {'loss': 1.0402, 'learning_rate': 1.8900781635034914e-05, 'epoch': 0.18}
 18%|█▊        | 1831/10395 [5:13:34<22:52:26,  9.62s/it] 18%|█▊        | 1832/10395 [5:13:42<21:19:35,  8.97s/it]                                                         {'loss': 1.0038, 'learning_rate': 1.889936102765603e-05, 'epoch': 0.18}
 18%|█▊        | 1832/10395 [5:13:42<21:19:35,  8.97s/it] 18%|█▊        | 1833/10395 [5:13:50<20:41:28,  8.70s/it]                                                         {'loss': 0.9655, 'learning_rate': 1.8897939556346196e-05, 'epoch': 0.18}
 18%|█▊        | 1833/10395 [5:13:50<20:41:28,  8.70s/it] 18%|█▊        | 1834/10395 [5:13:58<19:54:30,  8.37s/it]                                                         {'loss': 1.01, 'learning_rate': 1.8896517221243404e-05, 'epoch': 0.18}
 18%|█▊        | 1834/10395 [5:13:58<19:54:30,  8.37s/it] 18%|█▊        | 1835/10395 [5:14:05<19:23:07,  8.15s/it]                                                         {'loss': 0.916, 'learning_rate': 1.8895094022485735e-05, 'epoch': 0.18}
 18%|█▊        | 1835/10395 [5:14:05<19:23:07,  8.15s/it] 18%|█▊        | 1836/10395 [5:14:13<19:15:50,  8.10s/it]                                                         {'loss': 0.9504, 'learning_rate': 1.8893669960211342e-05, 'epoch': 0.18}
 18%|█▊        | 1836/10395 [5:14:13<19:15:50,  8.10s/it] 18%|█▊        | 1837/10395 [5:14:21<18:59:25,  7.99s/it]                                                         {'loss': 0.953, 'learning_rate': 1.8892245034558478e-05, 'epoch': 0.18}
 18%|█▊        | 1837/10395 [5:14:21<18:59:25,  7.99s/it] 18%|█▊        | 1838/10395 [5:14:28<18:39:04,  7.85s/it]                                                         {'loss': 0.9354, 'learning_rate': 1.889081924566547e-05, 'epoch': 0.18}
 18%|█▊        | 1838/10395 [5:14:28<18:39:04,  7.85s/it] 18%|█▊        | 1839/10395 [5:14:36<18:19:00,  7.71s/it]                                                         {'loss': 1.0013, 'learning_rate': 1.888939259367073e-05, 'epoch': 0.18}
 18%|█▊        | 1839/10395 [5:14:36<18:19:00,  7.71s/it] 18%|█▊        | 1840/10395 [5:14:44<18:16:14,  7.69s/it]                                                         {'loss': 1.0102, 'learning_rate': 1.888796507871275e-05, 'epoch': 0.18}
 18%|█▊        | 1840/10395 [5:14:44<18:16:14,  7.69s/it] 18%|█▊        | 1841/10395 [5:14:52<18:47:24,  7.91s/it]                                                         {'loss': 0.9436, 'learning_rate': 1.8886536700930116e-05, 'epoch': 0.18}
 18%|█▊        | 1841/10395 [5:14:52<18:47:24,  7.91s/it] 18%|█▊        | 1842/10395 [5:15:00<19:07:01,  8.05s/it]                                                         {'loss': 0.9901, 'learning_rate': 1.888510746046149e-05, 'epoch': 0.18}
 18%|█▊        | 1842/10395 [5:15:00<19:07:01,  8.05s/it] 18%|█▊        | 1843/10395 [5:15:08<18:35:53,  7.83s/it]                                                         {'loss': 1.0433, 'learning_rate': 1.8883677357445617e-05, 'epoch': 0.18}
 18%|█▊        | 1843/10395 [5:15:08<18:35:53,  7.83s/it] 18%|█▊        | 1844/10395 [5:15:15<18:18:52,  7.71s/it]                                                         {'loss': 0.9864, 'learning_rate': 1.888224639202133e-05, 'epoch': 0.18}
 18%|█▊        | 1844/10395 [5:15:15<18:18:52,  7.71s/it] 18%|█▊        | 1845/10395 [5:15:23<18:18:18,  7.71s/it]                                                         {'loss': 1.0127, 'learning_rate': 1.8880814564327548e-05, 'epoch': 0.18}
 18%|█▊        | 1845/10395 [5:15:23<18:18:18,  7.71s/it] 18%|█▊        | 1846/10395 [5:15:32<19:04:03,  8.03s/it]                                                         {'loss': 0.9405, 'learning_rate': 1.8879381874503265e-05, 'epoch': 0.18}
 18%|█▊        | 1846/10395 [5:15:32<19:04:03,  8.03s/it] 18%|█▊        | 1847/10395 [5:15:39<18:56:01,  7.97s/it]                                                         {'loss': 0.8817, 'learning_rate': 1.8877948322687568e-05, 'epoch': 0.18}
 18%|█▊        | 1847/10395 [5:15:39<18:56:01,  7.97s/it] 18%|█▊        | 1848/10395 [5:15:47<18:41:06,  7.87s/it]                                                         {'loss': 1.0529, 'learning_rate': 1.8876513909019615e-05, 'epoch': 0.18}
 18%|█▊        | 1848/10395 [5:15:47<18:41:06,  7.87s/it] 18%|█▊        | 1849/10395 [5:15:56<19:10:53,  8.08s/it]                                                         {'loss': 0.9108, 'learning_rate': 1.8875078633638664e-05, 'epoch': 0.18}
 18%|█▊        | 1849/10395 [5:15:56<19:10:53,  8.08s/it] 18%|█▊        | 1850/10395 [5:16:03<18:32:42,  7.81s/it]                                                         {'loss': 0.9566, 'learning_rate': 1.8873642496684047e-05, 'epoch': 0.18}
 18%|█▊        | 1850/10395 [5:16:03<18:32:42,  7.81s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 18%|█▊        | 1851/10395 [5:17:45<85:45:04, 36.13s/it]                                                         {'loss': 0.9758, 'learning_rate': 1.8872205498295174e-05, 'epoch': 0.18}
 18%|█▊        | 1851/10395 [5:17:45<85:45:04, 36.13s/it] 18%|█▊        | 1852/10395 [5:17:53<65:52:01, 27.76s/it]                                                         {'loss': 0.8929, 'learning_rate': 1.8870767638611555e-05, 'epoch': 0.18}
 18%|█▊        | 1852/10395 [5:17:53<65:52:01, 27.76s/it] 18%|█▊        | 1853/10395 [5:18:01<51:31:29, 21.72s/it]                                                         {'loss': 1.027, 'learning_rate': 1.886932891777277e-05, 'epoch': 0.18}
 18%|█▊        | 1853/10395 [5:18:01<51:31:29, 21.72s/it] 18%|█▊        | 1854/10395 [5:18:09<41:49:01, 17.63s/it]                                                         {'loss': 1.0019, 'learning_rate': 1.8867889335918487e-05, 'epoch': 0.18}
 18%|█▊        | 1854/10395 [5:18:09<41:49:01, 17.63s/it] 18%|█▊        | 1855/10395 [5:18:17<34:43:42, 14.64s/it]                                                         {'loss': 0.9788, 'learning_rate': 1.8866448893188458e-05, 'epoch': 0.18}
 18%|█▊        | 1855/10395 [5:18:17<34:43:42, 14.64s/it] 18%|█▊        | 1856/10395 [5:18:25<30:19:04, 12.78s/it]                                                         {'loss': 0.9613, 'learning_rate': 1.886500758972252e-05, 'epoch': 0.18}
 18%|█▊        | 1856/10395 [5:18:25<30:19:04, 12.78s/it] 18%|█▊        | 1857/10395 [5:18:32<26:31:53, 11.19s/it]                                                         {'loss': 1.0501, 'learning_rate': 1.886356542566059e-05, 'epoch': 0.18}
 18%|█▊        | 1857/10395 [5:18:32<26:31:53, 11.19s/it] 18%|█▊        | 1858/10395 [5:18:40<23:41:50,  9.99s/it]                                                         {'loss': 1.0592, 'learning_rate': 1.8862122401142668e-05, 'epoch': 0.18}
 18%|█▊        | 1858/10395 [5:18:40<23:41:50,  9.99s/it] 18%|█▊        | 1859/10395 [5:18:48<22:23:43,  9.45s/it]                                                         {'loss': 0.9442, 'learning_rate': 1.886067851630884e-05, 'epoch': 0.18}
 18%|█▊        | 1859/10395 [5:18:48<22:23:43,  9.45s/it] 18%|█▊        | 1860/10395 [5:18:56<21:12:26,  8.95s/it]                                                         {'loss': 0.9866, 'learning_rate': 1.885923377129928e-05, 'epoch': 0.18}
 18%|█▊        | 1860/10395 [5:18:56<21:12:26,  8.95s/it] 18%|█▊        | 1861/10395 [5:19:04<20:38:17,  8.71s/it]                                                         {'loss': 0.9338, 'learning_rate': 1.8857788166254236e-05, 'epoch': 0.18}
 18%|█▊        | 1861/10395 [5:19:04<20:38:17,  8.71s/it] 18%|█▊        | 1862/10395 [5:19:12<20:00:59,  8.44s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.8856341701314047e-05, 'epoch': 0.18}
 18%|█▊        | 1862/10395 [5:19:12<20:00:59,  8.44s/it] 18%|█▊        | 1863/10395 [5:19:19<19:35:24,  8.27s/it]                                                         {'loss': 1.032, 'learning_rate': 1.885489437661913e-05, 'epoch': 0.18}
 18%|█▊        | 1863/10395 [5:19:20<19:35:24,  8.27s/it] 18%|█▊        | 1864/10395 [5:19:27<19:19:18,  8.15s/it]                                                         {'loss': 0.9432, 'learning_rate': 1.8853446192309988e-05, 'epoch': 0.18}
 18%|█▊        | 1864/10395 [5:19:27<19:19:18,  8.15s/it] 18%|█▊        | 1865/10395 [5:19:37<20:02:04,  8.46s/it]                                                         {'loss': 1.0406, 'learning_rate': 1.8851997148527217e-05, 'epoch': 0.18}
 18%|█▊        | 1865/10395 [5:19:37<20:02:04,  8.46s/it] 18%|█▊        | 1866/10395 [5:19:44<19:13:58,  8.12s/it]                                                         {'loss': 0.99, 'learning_rate': 1.8850547245411476e-05, 'epoch': 0.18}
 18%|█▊        | 1866/10395 [5:19:44<19:13:58,  8.12s/it] 18%|█▊        | 1867/10395 [5:19:51<18:47:10,  7.93s/it]                                                         {'loss': 0.9107, 'learning_rate': 1.8849096483103518e-05, 'epoch': 0.18}
 18%|█▊        | 1867/10395 [5:19:51<18:47:10,  7.93s/it] 18%|█▊        | 1868/10395 [5:20:00<19:37:17,  8.28s/it]                                                         {'loss': 0.8279, 'learning_rate': 1.8847644861744188e-05, 'epoch': 0.18}
 18%|█▊        | 1868/10395 [5:20:00<19:37:17,  8.28s/it] 18%|█▊        | 1869/10395 [5:20:09<19:38:33,  8.29s/it]                                                         {'loss': 1.0635, 'learning_rate': 1.8846192381474404e-05, 'epoch': 0.18}
 18%|█▊        | 1869/10395 [5:20:09<19:38:33,  8.29s/it] 18%|█▊        | 1870/10395 [5:20:16<18:49:32,  7.95s/it]                                                         {'loss': 1.0555, 'learning_rate': 1.8844739042435164e-05, 'epoch': 0.18}
 18%|█▊        | 1870/10395 [5:20:16<18:49:32,  7.95s/it] 18%|█▊        | 1871/10395 [5:20:24<18:34:42,  7.85s/it]                                                         {'loss': 0.884, 'learning_rate': 1.8843284844767564e-05, 'epoch': 0.18}
 18%|█▊        | 1871/10395 [5:20:24<18:34:42,  7.85s/it] 18%|█▊        | 1872/10395 [5:20:31<18:22:14,  7.76s/it]                                                         {'loss': 0.9971, 'learning_rate': 1.8841829788612762e-05, 'epoch': 0.18}
 18%|█▊        | 1872/10395 [5:20:31<18:22:14,  7.76s/it] 18%|█▊        | 1873/10395 [5:20:39<18:08:43,  7.67s/it]                                                         {'loss': 0.9775, 'learning_rate': 1.8840373874112024e-05, 'epoch': 0.18}
 18%|█▊        | 1873/10395 [5:20:39<18:08:43,  7.67s/it] 18%|█▊        | 1874/10395 [5:20:46<18:16:31,  7.72s/it]                                                         {'loss': 0.9632, 'learning_rate': 1.8838917101406683e-05, 'epoch': 0.18}
 18%|█▊        | 1874/10395 [5:20:46<18:16:31,  7.72s/it] 18%|█▊        | 1875/10395 [5:20:56<19:21:50,  8.18s/it]                                                         {'loss': 0.9778, 'learning_rate': 1.8837459470638158e-05, 'epoch': 0.18}
 18%|█▊        | 1875/10395 [5:20:56<19:21:50,  8.18s/it] 18%|█▊        | 1876/10395 [5:21:03<18:50:52,  7.96s/it]                                                         {'loss': 1.0065, 'learning_rate': 1.883600098194795e-05, 'epoch': 0.18}
 18%|█▊        | 1876/10395 [5:21:03<18:50:52,  7.96s/it] 18%|█▊        | 1877/10395 [5:21:11<18:50:09,  7.96s/it]                                                         {'loss': 0.956, 'learning_rate': 1.8834541635477652e-05, 'epoch': 0.18}
 18%|█▊        | 1877/10395 [5:21:11<18:50:09,  7.96s/it] 18%|█▊        | 1878/10395 [5:21:19<18:49:12,  7.96s/it]                                                         {'loss': 0.9184, 'learning_rate': 1.8833081431368932e-05, 'epoch': 0.18}
 18%|█▊        | 1878/10395 [5:21:19<18:49:12,  7.96s/it] 18%|█▊        | 1879/10395 [5:21:27<18:36:42,  7.87s/it]                                                         {'loss': 1.0143, 'learning_rate': 1.883162036976354e-05, 'epoch': 0.18}
 18%|█▊        | 1879/10395 [5:21:27<18:36:42,  7.87s/it] 18%|█▊        | 1880/10395 [5:21:34<18:13:01,  7.70s/it]                                                         {'loss': 1.0171, 'learning_rate': 1.883015845080332e-05, 'epoch': 0.18}
 18%|█▊        | 1880/10395 [5:21:34<18:13:01,  7.70s/it] 18%|█▊        | 1881/10395 [5:21:41<17:51:43,  7.55s/it]                                                         {'loss': 0.9914, 'learning_rate': 1.8828695674630183e-05, 'epoch': 0.18}
 18%|█▊        | 1881/10395 [5:21:41<17:51:43,  7.55s/it] 18%|█▊        | 1882/10395 [5:21:49<18:15:57,  7.72s/it]                                                         {'loss': 0.9956, 'learning_rate': 1.882723204138614e-05, 'epoch': 0.18}
 18%|█▊        | 1882/10395 [5:21:49<18:15:57,  7.72s/it] 18%|█▊        | 1883/10395 [5:21:57<18:05:58,  7.65s/it]                                                         {'loss': 1.0364, 'learning_rate': 1.8825767551213275e-05, 'epoch': 0.18}
 18%|█▊        | 1883/10395 [5:21:57<18:05:58,  7.65s/it] 18%|█▊        | 1884/10395 [5:22:04<17:52:15,  7.56s/it]                                                         {'loss': 0.9835, 'learning_rate': 1.8824302204253756e-05, 'epoch': 0.18}
 18%|█▊        | 1884/10395 [5:22:04<17:52:15,  7.56s/it] 18%|█▊        | 1885/10395 [5:22:15<20:05:48,  8.50s/it]                                                         {'loss': 0.8997, 'learning_rate': 1.8822836000649837e-05, 'epoch': 0.18}
 18%|█▊        | 1885/10395 [5:22:15<20:05:48,  8.50s/it] 18%|█▊        | 1886/10395 [5:22:23<20:06:33,  8.51s/it]                                                         {'loss': 0.978, 'learning_rate': 1.8821368940543855e-05, 'epoch': 0.18}
 18%|█▊        | 1886/10395 [5:22:23<20:06:33,  8.51s/it] 18%|█▊        | 1887/10395 [5:22:32<19:54:17,  8.42s/it]                                                         {'loss': 0.9613, 'learning_rate': 1.8819901024078225e-05, 'epoch': 0.18}
 18%|█▊        | 1887/10395 [5:22:32<19:54:17,  8.42s/it] 18%|█▊        | 1888/10395 [5:22:39<19:17:31,  8.16s/it]                                                         {'loss': 1.0246, 'learning_rate': 1.8818432251395452e-05, 'epoch': 0.18}
 18%|█▊        | 1888/10395 [5:22:39<19:17:31,  8.16s/it] 18%|█▊        | 1889/10395 [5:22:47<18:56:01,  8.01s/it]                                                         {'loss': 1.0287, 'learning_rate': 1.881696262263812e-05, 'epoch': 0.18}
 18%|█▊        | 1889/10395 [5:22:47<18:56:01,  8.01s/it] 18%|█▊        | 1890/10395 [5:22:54<18:41:44,  7.91s/it]                                                         {'loss': 0.9539, 'learning_rate': 1.88154921379489e-05, 'epoch': 0.18}
 18%|█▊        | 1890/10395 [5:22:54<18:41:44,  7.91s/it] 18%|█▊        | 1891/10395 [5:23:02<18:36:05,  7.87s/it]                                                         {'loss': 1.0077, 'learning_rate': 1.881402079747054e-05, 'epoch': 0.18}
 18%|█▊        | 1891/10395 [5:23:02<18:36:05,  7.87s/it] 18%|█▊        | 1892/10395 [5:23:11<19:18:02,  8.17s/it]                                                         {'loss': 1.0108, 'learning_rate': 1.881254860134588e-05, 'epoch': 0.18}
 18%|█▊        | 1892/10395 [5:23:11<19:18:02,  8.17s/it] 18%|█▊        | 1893/10395 [5:23:19<19:13:38,  8.14s/it]                                                         {'loss': 0.9967, 'learning_rate': 1.8811075549717835e-05, 'epoch': 0.18}
 18%|█▊        | 1893/10395 [5:23:19<19:13:38,  8.14s/it] 18%|█▊        | 1894/10395 [5:23:26<18:35:51,  7.88s/it]                                                         {'loss': 1.0922, 'learning_rate': 1.88096016427294e-05, 'epoch': 0.18}
 18%|█▊        | 1894/10395 [5:23:26<18:35:51,  7.88s/it] 18%|█▊        | 1895/10395 [5:23:44<25:16:27, 10.70s/it]                                                         {'loss': 0.3848, 'learning_rate': 1.8808126880523666e-05, 'epoch': 0.18}
 18%|█▊        | 1895/10395 [5:23:44<25:16:27, 10.70s/it] 18%|█▊        | 1896/10395 [5:23:51<23:05:38,  9.78s/it]                                                         {'loss': 0.8669, 'learning_rate': 1.88066512632438e-05, 'epoch': 0.18}
 18%|█▊        | 1896/10395 [5:23:51<23:05:38,  9.78s/it] 18%|█▊        | 1897/10395 [5:23:59<21:43:49,  9.21s/it]                                                         {'loss': 0.9347, 'learning_rate': 1.8805174791033044e-05, 'epoch': 0.18}
 18%|█▊        | 1897/10395 [5:23:59<21:43:49,  9.21s/it] 18%|█▊        | 1898/10395 [5:24:07<20:31:05,  8.69s/it]                                                         {'loss': 1.0131, 'learning_rate': 1.880369746403474e-05, 'epoch': 0.18}
 18%|█▊        | 1898/10395 [5:24:07<20:31:05,  8.69s/it] 18%|█▊        | 1899/10395 [5:24:14<19:33:11,  8.29s/it]                                                         {'loss': 0.9316, 'learning_rate': 1.88022192823923e-05, 'epoch': 0.18}
 18%|█▊        | 1899/10395 [5:24:14<19:33:11,  8.29s/it] 18%|█▊        | 1900/10395 [5:24:22<19:02:00,  8.07s/it]                                                         {'loss': 1.0784, 'learning_rate': 1.880074024624922e-05, 'epoch': 0.18}
 18%|█▊        | 1900/10395 [5:24:22<19:02:00,  8.07s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 18%|█▊        | 1901/10395 [5:26:07<87:47:44, 37.21s/it]                                                         {'loss': 0.9061, 'learning_rate': 1.8799260355749086e-05, 'epoch': 0.18}
 18%|█▊        | 1901/10395 [5:26:07<87:47:44, 37.21s/it] 18%|█▊        | 1902/10395 [5:26:14<66:37:29, 28.24s/it]                                                         {'loss': 0.9633, 'learning_rate': 1.879777961103556e-05, 'epoch': 0.18}
 18%|█▊        | 1902/10395 [5:26:14<66:37:29, 28.24s/it] 18%|█▊        | 1903/10395 [5:26:23<52:35:08, 22.29s/it]                                                         {'loss': 1.0248, 'learning_rate': 1.8796298012252392e-05, 'epoch': 0.18}
 18%|█▊        | 1903/10395 [5:26:23<52:35:08, 22.29s/it] 18%|█▊        | 1904/10395 [5:26:30<42:10:12, 17.88s/it]                                                         {'loss': 0.998, 'learning_rate': 1.8794815559543408e-05, 'epoch': 0.18}
 18%|█▊        | 1904/10395 [5:26:30<42:10:12, 17.88s/it] 18%|█▊        | 1905/10395 [5:26:40<36:08:28, 15.32s/it]                                                         {'loss': 0.9702, 'learning_rate': 1.8793332253052525e-05, 'epoch': 0.18}
 18%|█▊        | 1905/10395 [5:26:40<36:08:28, 15.32s/it] 18%|█▊        | 1906/10395 [5:26:47<30:49:54, 13.08s/it]                                                         {'loss': 0.9881, 'learning_rate': 1.879184809292374e-05, 'epoch': 0.18}
 18%|█▊        | 1906/10395 [5:26:47<30:49:54, 13.08s/it] 18%|█▊        | 1907/10395 [5:26:56<27:30:39, 11.67s/it]                                                         {'loss': 0.8782, 'learning_rate': 1.879036307930113e-05, 'epoch': 0.18}
 18%|█▊        | 1907/10395 [5:26:56<27:30:39, 11.67s/it] 18%|█▊        | 1908/10395 [5:27:03<24:39:23, 10.46s/it]                                                         {'loss': 0.9891, 'learning_rate': 1.8788877212328852e-05, 'epoch': 0.18}
 18%|█▊        | 1908/10395 [5:27:03<24:39:23, 10.46s/it] 18%|█▊        | 1909/10395 [5:27:11<22:43:13,  9.64s/it]                                                         {'loss': 1.0274, 'learning_rate': 1.8787390492151162e-05, 'epoch': 0.18}
 18%|█▊        | 1909/10395 [5:27:11<22:43:13,  9.64s/it] 18%|█▊        | 1910/10395 [5:27:19<21:45:43,  9.23s/it]                                                         {'loss': 0.9456, 'learning_rate': 1.878590291891238e-05, 'epoch': 0.18}
 18%|█▊        | 1910/10395 [5:27:19<21:45:43,  9.23s/it] 18%|█▊        | 1911/10395 [5:27:27<20:17:19,  8.61s/it]                                                         {'loss': 1.0395, 'learning_rate': 1.878441449275692e-05, 'epoch': 0.18}
 18%|█▊        | 1911/10395 [5:27:27<20:17:19,  8.61s/it] 18%|█▊        | 1912/10395 [5:27:34<19:17:05,  8.18s/it]                                                         {'loss': 0.9792, 'learning_rate': 1.878292521382927e-05, 'epoch': 0.18}
 18%|█▊        | 1912/10395 [5:27:34<19:17:05,  8.18s/it] 18%|█▊        | 1913/10395 [5:27:41<18:54:18,  8.02s/it]                                                         {'loss': 0.8935, 'learning_rate': 1.8781435082274013e-05, 'epoch': 0.18}
 18%|█▊        | 1913/10395 [5:27:41<18:54:18,  8.02s/it] 18%|█▊        | 1914/10395 [5:27:49<18:36:59,  7.90s/it]                                                         {'loss': 0.9984, 'learning_rate': 1.87799440982358e-05, 'epoch': 0.18}
 18%|█▊        | 1914/10395 [5:27:49<18:36:59,  7.90s/it] 18%|█▊        | 1915/10395 [5:27:58<19:15:26,  8.18s/it]                                                         {'loss': 0.9141, 'learning_rate': 1.877845226185938e-05, 'epoch': 0.18}
 18%|█▊        | 1915/10395 [5:27:58<19:15:26,  8.18s/it] 18%|█▊        | 1916/10395 [5:28:05<18:52:22,  8.01s/it]                                                         {'loss': 1.0343, 'learning_rate': 1.8776959573289572e-05, 'epoch': 0.18}
 18%|█▊        | 1916/10395 [5:28:05<18:52:22,  8.01s/it] 18%|█▊        | 1917/10395 [5:28:13<18:30:59,  7.86s/it]                                                         {'loss': 0.9463, 'learning_rate': 1.8775466032671288e-05, 'epoch': 0.18}
 18%|█▊        | 1917/10395 [5:28:13<18:30:59,  7.86s/it] 18%|█▊        | 1918/10395 [5:28:23<19:47:44,  8.41s/it]                                                         {'loss': 0.9373, 'learning_rate': 1.8773971640149515e-05, 'epoch': 0.18}
 18%|█▊        | 1918/10395 [5:28:23<19:47:44,  8.41s/it] 18%|█▊        | 1919/10395 [5:28:32<20:10:58,  8.57s/it]                                                         {'loss': 1.0065, 'learning_rate': 1.8772476395869323e-05, 'epoch': 0.18}
 18%|█▊        | 1919/10395 [5:28:32<20:10:58,  8.57s/it] 18%|█▊        | 1920/10395 [5:28:39<19:38:03,  8.34s/it]                                                         {'loss': 0.9101, 'learning_rate': 1.8770980299975867e-05, 'epoch': 0.18}
 18%|█▊        | 1920/10395 [5:28:39<19:38:03,  8.34s/it] 18%|█▊        | 1921/10395 [5:28:47<19:19:27,  8.21s/it]                                                         {'loss': 0.9826, 'learning_rate': 1.876948335261439e-05, 'epoch': 0.18}
 18%|█▊        | 1921/10395 [5:28:47<19:19:27,  8.21s/it] 18%|█▊        | 1922/10395 [5:28:57<20:15:36,  8.61s/it]                                                         {'loss': 1.0078, 'learning_rate': 1.876798555393021e-05, 'epoch': 0.18}
 18%|█▊        | 1922/10395 [5:28:57<20:15:36,  8.61s/it] 18%|█▊        | 1923/10395 [5:29:14<26:23:34, 11.22s/it]                                                         {'loss': 0.4268, 'learning_rate': 1.876648690406873e-05, 'epoch': 0.18}
 18%|█▊        | 1923/10395 [5:29:14<26:23:34, 11.22s/it] 19%|█▊        | 1924/10395 [5:29:21<23:28:13,  9.97s/it]                                                         {'loss': 1.0757, 'learning_rate': 1.8764987403175433e-05, 'epoch': 0.19}
 19%|█▊        | 1924/10395 [5:29:21<23:28:13,  9.97s/it] 19%|█▊        | 1925/10395 [5:29:29<21:57:12,  9.33s/it]                                                         {'loss': 0.9656, 'learning_rate': 1.876348705139589e-05, 'epoch': 0.19}
 19%|█▊        | 1925/10395 [5:29:29<21:57:12,  9.33s/it] 19%|█▊        | 1926/10395 [5:29:36<20:33:37,  8.74s/it]                                                         {'loss': 1.0214, 'learning_rate': 1.8761985848875752e-05, 'epoch': 0.19}
 19%|█▊        | 1926/10395 [5:29:36<20:33:37,  8.74s/it] 19%|█▊        | 1927/10395 [5:29:44<19:54:08,  8.46s/it]                                                         {'loss': 0.9361, 'learning_rate': 1.8760483795760753e-05, 'epoch': 0.19}
 19%|█▊        | 1927/10395 [5:29:44<19:54:08,  8.46s/it] 19%|█▊        | 1928/10395 [5:29:52<19:33:28,  8.32s/it]                                                         {'loss': 0.9515, 'learning_rate': 1.8758980892196706e-05, 'epoch': 0.19}
 19%|█▊        | 1928/10395 [5:29:52<19:33:28,  8.32s/it] 19%|█▊        | 1929/10395 [5:30:00<19:30:51,  8.30s/it]                                                         {'loss': 0.9434, 'learning_rate': 1.8757477138329515e-05, 'epoch': 0.19}
 19%|█▊        | 1929/10395 [5:30:00<19:30:51,  8.30s/it] 19%|█▊        | 1930/10395 [5:30:08<18:51:35,  8.02s/it]                                                         {'loss': 0.9771, 'learning_rate': 1.875597253430516e-05, 'epoch': 0.19}
 19%|█▊        | 1930/10395 [5:30:08<18:51:35,  8.02s/it] 19%|█▊        | 1931/10395 [5:30:16<19:06:45,  8.13s/it]                                                         {'loss': 0.9914, 'learning_rate': 1.87544670802697e-05, 'epoch': 0.19}
 19%|█▊        | 1931/10395 [5:30:16<19:06:45,  8.13s/it] 19%|█▊        | 1932/10395 [5:30:24<18:46:57,  7.99s/it]                                                         {'loss': 0.9472, 'learning_rate': 1.8752960776369283e-05, 'epoch': 0.19}
 19%|█▊        | 1932/10395 [5:30:24<18:46:57,  7.99s/it] 19%|█▊        | 1933/10395 [5:30:31<18:22:30,  7.82s/it]                                                         {'loss': 0.9356, 'learning_rate': 1.8751453622750142e-05, 'epoch': 0.19}
 19%|█▊        | 1933/10395 [5:30:31<18:22:30,  7.82s/it] 19%|█▊        | 1934/10395 [5:30:39<18:23:03,  7.82s/it]                                                         {'loss': 1.0526, 'learning_rate': 1.8749945619558585e-05, 'epoch': 0.19}
 19%|█▊        | 1934/10395 [5:30:39<18:23:03,  7.82s/it] 19%|█▊        | 1935/10395 [5:30:47<18:30:13,  7.87s/it]                                                         {'loss': 0.9634, 'learning_rate': 1.8748436766941e-05, 'epoch': 0.19}
 19%|█▊        | 1935/10395 [5:30:47<18:30:13,  7.87s/it] 19%|█▊        | 1936/10395 [5:30:55<18:29:44,  7.87s/it]                                                         {'loss': 0.959, 'learning_rate': 1.8746927065043876e-05, 'epoch': 0.19}
 19%|█▊        | 1936/10395 [5:30:55<18:29:44,  7.87s/it] 19%|█▊        | 1937/10395 [5:31:03<18:42:05,  7.96s/it]                                                         {'loss': 0.9892, 'learning_rate': 1.8745416514013764e-05, 'epoch': 0.19}
 19%|█▊        | 1937/10395 [5:31:03<18:42:05,  7.96s/it] 19%|█▊        | 1938/10395 [5:31:11<18:39:38,  7.94s/it]                                                         {'loss': 0.9863, 'learning_rate': 1.87439051139973e-05, 'epoch': 0.19}
 19%|█▊        | 1938/10395 [5:31:11<18:39:38,  7.94s/it] 19%|█▊        | 1939/10395 [5:31:19<18:24:31,  7.84s/it]                                                         {'loss': 0.9162, 'learning_rate': 1.874239286514122e-05, 'epoch': 0.19}
 19%|█▊        | 1939/10395 [5:31:19<18:24:31,  7.84s/it] 19%|█▊        | 1940/10395 [5:31:26<18:22:41,  7.83s/it]                                                         {'loss': 1.017, 'learning_rate': 1.874087976759232e-05, 'epoch': 0.19}
 19%|█▊        | 1940/10395 [5:31:26<18:22:41,  7.83s/it] 19%|█▊        | 1941/10395 [5:31:33<17:49:11,  7.59s/it]                                                         {'loss': 1.064, 'learning_rate': 1.8739365821497496e-05, 'epoch': 0.19}
 19%|█▊        | 1941/10395 [5:31:33<17:49:11,  7.59s/it] 19%|█▊        | 1942/10395 [5:31:51<24:38:28, 10.49s/it]                                                         {'loss': 0.4064, 'learning_rate': 1.873785102700371e-05, 'epoch': 0.19}
 19%|█▊        | 1942/10395 [5:31:51<24:38:28, 10.49s/it] 19%|█▊        | 1943/10395 [5:31:58<22:39:57,  9.65s/it]                                                         {'loss': 1.0225, 'learning_rate': 1.8736335384258022e-05, 'epoch': 0.19}
 19%|█▊        | 1943/10395 [5:31:58<22:39:57,  9.65s/it] 19%|█▊        | 1944/10395 [5:32:06<21:07:10,  9.00s/it]                                                         {'loss': 1.008, 'learning_rate': 1.873481889340756e-05, 'epoch': 0.19}
 19%|█▊        | 1944/10395 [5:32:06<21:07:10,  9.00s/it] 19%|█▊        | 1945/10395 [5:32:15<20:51:51,  8.89s/it]                                                         {'loss': 0.9491, 'learning_rate': 1.873330155459955e-05, 'epoch': 0.19}
 19%|█▊        | 1945/10395 [5:32:15<20:51:51,  8.89s/it] 19%|█▊        | 1946/10395 [5:32:22<20:08:36,  8.58s/it]                                                         {'loss': 0.923, 'learning_rate': 1.8731783367981283e-05, 'epoch': 0.19}
 19%|█▊        | 1946/10395 [5:32:22<20:08:36,  8.58s/it] 19%|█▊        | 1947/10395 [5:32:30<19:31:44,  8.32s/it]                                                         {'loss': 0.9206, 'learning_rate': 1.8730264333700153e-05, 'epoch': 0.19}
 19%|█▊        | 1947/10395 [5:32:30<19:31:44,  8.32s/it] 19%|█▊        | 1948/10395 [5:32:38<19:06:05,  8.14s/it]                                                         {'loss': 0.9226, 'learning_rate': 1.8728744451903617e-05, 'epoch': 0.19}
 19%|█▊        | 1948/10395 [5:32:38<19:06:05,  8.14s/it] 19%|█▊        | 1949/10395 [5:32:45<18:33:29,  7.91s/it]                                                         {'loss': 1.0792, 'learning_rate': 1.872722372273922e-05, 'epoch': 0.19}
 19%|█▊        | 1949/10395 [5:32:45<18:33:29,  7.91s/it] 19%|█▉        | 1950/10395 [5:32:52<18:08:00,  7.73s/it]                                                         {'loss': 0.9995, 'learning_rate': 1.8725702146354593e-05, 'epoch': 0.19}
 19%|█▉        | 1950/10395 [5:32:53<18:08:00,  7.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 19%|█▉        | 1951/10395 [5:34:33<83:30:44, 35.60s/it]                                                         {'loss': 1.1272, 'learning_rate': 1.8724179722897452e-05, 'epoch': 0.19}
 19%|█▉        | 1951/10395 [5:34:33<83:30:44, 35.60s/it] 19%|█▉        | 1952/10395 [5:34:40<63:29:24, 27.07s/it]                                                         {'loss': 1.0323, 'learning_rate': 1.8722656452515588e-05, 'epoch': 0.19}
 19%|█▉        | 1952/10395 [5:34:40<63:29:24, 27.07s/it] 19%|█▉        | 1953/10395 [5:34:47<49:26:22, 21.08s/it]                                                         {'loss': 1.0639, 'learning_rate': 1.872113233535687e-05, 'epoch': 0.19}
 19%|█▉        | 1953/10395 [5:34:47<49:26:22, 21.08s/it] 19%|█▉        | 1954/10395 [5:34:55<39:41:36, 16.93s/it]                                                         {'loss': 1.0268, 'learning_rate': 1.871960737156927e-05, 'epoch': 0.19}
 19%|█▉        | 1954/10395 [5:34:55<39:41:36, 16.93s/it] 19%|█▉        | 1955/10395 [5:35:02<33:02:10, 14.09s/it]                                                         {'loss': 1.0813, 'learning_rate': 1.8718081561300817e-05, 'epoch': 0.19}
 19%|█▉        | 1955/10395 [5:35:02<33:02:10, 14.09s/it] 19%|█▉        | 1956/10395 [5:35:20<35:48:33, 15.28s/it]                                                         {'loss': 0.4164, 'learning_rate': 1.8716554904699635e-05, 'epoch': 0.19}
 19%|█▉        | 1956/10395 [5:35:20<35:48:33, 15.28s/it] 19%|█▉        | 1957/10395 [5:35:28<30:19:29, 12.94s/it]                                                         {'loss': 0.9887, 'learning_rate': 1.8715027401913932e-05, 'epoch': 0.19}
 19%|█▉        | 1957/10395 [5:35:28<30:19:29, 12.94s/it] 19%|█▉        | 1958/10395 [5:35:35<26:39:15, 11.37s/it]                                                         {'loss': 0.9656, 'learning_rate': 1.871349905309199e-05, 'epoch': 0.19}
 19%|█▉        | 1958/10395 [5:35:35<26:39:15, 11.37s/it] 19%|█▉        | 1959/10395 [5:35:44<24:34:18, 10.49s/it]                                                         {'loss': 1.0131, 'learning_rate': 1.871196985838218e-05, 'epoch': 0.19}
 19%|█▉        | 1959/10395 [5:35:44<24:34:18, 10.49s/it] 19%|█▉        | 1960/10395 [5:35:52<23:05:55,  9.86s/it]                                                         {'loss': 0.9439, 'learning_rate': 1.871043981793296e-05, 'epoch': 0.19}
 19%|█▉        | 1960/10395 [5:35:52<23:05:55,  9.86s/it] 19%|█▉        | 1961/10395 [5:35:59<21:15:08,  9.07s/it]                                                         {'loss': 0.9892, 'learning_rate': 1.8708908931892853e-05, 'epoch': 0.19}
 19%|█▉        | 1961/10395 [5:35:59<21:15:08,  9.07s/it] 19%|█▉        | 1962/10395 [5:36:07<20:20:42,  8.69s/it]                                                         {'loss': 0.8989, 'learning_rate': 1.870737720041048e-05, 'epoch': 0.19}
 19%|█▉        | 1962/10395 [5:36:07<20:20:42,  8.69s/it] 19%|█▉        | 1963/10395 [5:36:16<20:08:17,  8.60s/it]                                                         {'loss': 0.9722, 'learning_rate': 1.8705844623634533e-05, 'epoch': 0.19}
 19%|█▉        | 1963/10395 [5:36:16<20:08:17,  8.60s/it] 19%|█▉        | 1964/10395 [5:36:24<19:54:57,  8.50s/it]                                                         {'loss': 0.9869, 'learning_rate': 1.8704311201713795e-05, 'epoch': 0.19}
 19%|█▉        | 1964/10395 [5:36:24<19:54:57,  8.50s/it] 19%|█▉        | 1965/10395 [5:36:33<20:08:45,  8.60s/it]                                                         {'loss': 0.9173, 'learning_rate': 1.8702776934797125e-05, 'epoch': 0.19}
 19%|█▉        | 1965/10395 [5:36:33<20:08:45,  8.60s/it] 19%|█▉        | 1966/10395 [5:36:42<20:17:10,  8.66s/it]                                                         {'loss': 0.8746, 'learning_rate': 1.8701241823033473e-05, 'epoch': 0.19}
 19%|█▉        | 1966/10395 [5:36:42<20:17:10,  8.66s/it] 19%|█▉        | 1967/10395 [5:36:49<19:37:31,  8.38s/it]                                                         {'loss': 0.9688, 'learning_rate': 1.8699705866571856e-05, 'epoch': 0.19}
 19%|█▉        | 1967/10395 [5:36:49<19:37:31,  8.38s/it] 19%|█▉        | 1968/10395 [5:36:57<19:09:20,  8.18s/it]                                                         {'loss': 0.9752, 'learning_rate': 1.8698169065561385e-05, 'epoch': 0.19}
 19%|█▉        | 1968/10395 [5:36:57<19:09:20,  8.18s/it] 19%|█▉        | 1969/10395 [5:37:05<18:49:38,  8.04s/it]                                                         {'loss': 0.9494, 'learning_rate': 1.8696631420151254e-05, 'epoch': 0.19}
 19%|█▉        | 1969/10395 [5:37:05<18:49:38,  8.04s/it] 19%|█▉        | 1970/10395 [5:37:12<18:18:53,  7.83s/it]                                                         {'loss': 0.9785, 'learning_rate': 1.8695092930490722e-05, 'epoch': 0.19}
 19%|█▉        | 1970/10395 [5:37:12<18:18:53,  7.83s/it] 19%|█▉        | 1971/10395 [5:37:20<18:23:44,  7.86s/it]                                                         {'loss': 1.0516, 'learning_rate': 1.8693553596729153e-05, 'epoch': 0.19}
 19%|█▉        | 1971/10395 [5:37:20<18:23:44,  7.86s/it] 19%|█▉        | 1972/10395 [5:37:28<18:28:41,  7.90s/it]                                                         {'loss': 0.9583, 'learning_rate': 1.869201341901598e-05, 'epoch': 0.19}
 19%|█▉        | 1972/10395 [5:37:28<18:28:41,  7.90s/it] 19%|█▉        | 1973/10395 [5:37:36<18:56:41,  8.10s/it]                                                         {'loss': 0.9938, 'learning_rate': 1.8690472397500717e-05, 'epoch': 0.19}
 19%|█▉        | 1973/10395 [5:37:36<18:56:41,  8.10s/it] 19%|█▉        | 1974/10395 [5:37:44<18:37:23,  7.96s/it]                                                         {'loss': 0.9465, 'learning_rate': 1.868893053233297e-05, 'epoch': 0.19}
 19%|█▉        | 1974/10395 [5:37:44<18:37:23,  7.96s/it] 19%|█▉        | 1975/10395 [5:37:52<18:17:09,  7.82s/it]                                                         {'loss': 1.0565, 'learning_rate': 1.8687387823662408e-05, 'epoch': 0.19}
 19%|█▉        | 1975/10395 [5:37:52<18:17:09,  7.82s/it] 19%|█▉        | 1976/10395 [5:37:59<17:51:46,  7.64s/it]                                                         {'loss': 0.874, 'learning_rate': 1.8685844271638808e-05, 'epoch': 0.19}
 19%|█▉        | 1976/10395 [5:37:59<17:51:46,  7.64s/it] 19%|█▉        | 1977/10395 [5:38:07<17:54:12,  7.66s/it]                                                         {'loss': 0.9594, 'learning_rate': 1.8684299876412e-05, 'epoch': 0.19}
 19%|█▉        | 1977/10395 [5:38:07<17:54:12,  7.66s/it] 19%|█▉        | 1978/10395 [5:38:14<17:50:49,  7.63s/it]                                                         {'loss': 0.9812, 'learning_rate': 1.8682754638131926e-05, 'epoch': 0.19}
 19%|█▉        | 1978/10395 [5:38:14<17:50:49,  7.63s/it] 19%|█▉        | 1979/10395 [5:38:24<19:28:23,  8.33s/it]                                                         {'loss': 0.9229, 'learning_rate': 1.8681208556948583e-05, 'epoch': 0.19}
 19%|█▉        | 1979/10395 [5:38:24<19:28:23,  8.33s/it] 19%|█▉        | 1980/10395 [5:38:32<19:22:25,  8.29s/it]                                                         {'loss': 0.9614, 'learning_rate': 1.8679661633012065e-05, 'epoch': 0.19}
 19%|█▉        | 1980/10395 [5:38:32<19:22:25,  8.29s/it] 19%|█▉        | 1981/10395 [5:38:40<18:59:47,  8.13s/it]                                                         {'loss': 0.9802, 'learning_rate': 1.8678113866472545e-05, 'epoch': 0.19}
 19%|█▉        | 1981/10395 [5:38:40<18:59:47,  8.13s/it] 19%|█▉        | 1982/10395 [5:38:47<18:30:03,  7.92s/it]                                                         {'loss': 0.9653, 'learning_rate': 1.8676565257480277e-05, 'epoch': 0.19}
 19%|█▉        | 1982/10395 [5:38:47<18:30:03,  7.92s/it] 19%|█▉        | 1983/10395 [5:38:55<18:30:05,  7.92s/it]                                                         {'loss': 0.9885, 'learning_rate': 1.8675015806185594e-05, 'epoch': 0.19}
 19%|█▉        | 1983/10395 [5:38:55<18:30:05,  7.92s/it] 19%|█▉        | 1984/10395 [5:39:03<18:13:37,  7.80s/it]                                                         {'loss': 0.9717, 'learning_rate': 1.8673465512738917e-05, 'epoch': 0.19}
 19%|█▉        | 1984/10395 [5:39:03<18:13:37,  7.80s/it] 19%|█▉        | 1985/10395 [5:39:12<18:49:13,  8.06s/it]                                                         {'loss': 0.9605, 'learning_rate': 1.8671914377290743e-05, 'epoch': 0.19}
 19%|█▉        | 1985/10395 [5:39:12<18:49:13,  8.06s/it] 19%|█▉        | 1986/10395 [5:39:19<18:44:32,  8.02s/it]                                                         {'loss': 1.004, 'learning_rate': 1.8670362399991654e-05, 'epoch': 0.19}
 19%|█▉        | 1986/10395 [5:39:19<18:44:32,  8.02s/it] 19%|█▉        | 1987/10395 [5:39:27<18:15:35,  7.82s/it]                                                         {'loss': 0.9724, 'learning_rate': 1.8668809580992307e-05, 'epoch': 0.19}
 19%|█▉        | 1987/10395 [5:39:27<18:15:35,  7.82s/it] 19%|█▉        | 1988/10395 [5:39:34<17:59:21,  7.70s/it]                                                         {'loss': 0.9518, 'learning_rate': 1.8667255920443453e-05, 'epoch': 0.19}
 19%|█▉        | 1988/10395 [5:39:34<17:59:21,  7.70s/it] 19%|█▉        | 1989/10395 [5:39:42<17:56:18,  7.68s/it]                                                         {'loss': 0.9931, 'learning_rate': 1.8665701418495922e-05, 'epoch': 0.19}
 19%|█▉        | 1989/10395 [5:39:42<17:56:18,  7.68s/it] 19%|█▉        | 1990/10395 [5:39:50<18:02:47,  7.73s/it]                                                         {'loss': 1.0639, 'learning_rate': 1.866414607530061e-05, 'epoch': 0.19}
 19%|█▉        | 1990/10395 [5:39:50<18:02:47,  7.73s/it] 19%|█▉        | 1991/10395 [5:39:58<18:27:34,  7.91s/it]                                                         {'loss': 0.8915, 'learning_rate': 1.8662589891008512e-05, 'epoch': 0.19}
 19%|█▉        | 1991/10395 [5:39:58<18:27:34,  7.91s/it] 19%|█▉        | 1992/10395 [5:40:06<18:09:49,  7.78s/it]                                                         {'loss': 0.9757, 'learning_rate': 1.8661032865770706e-05, 'epoch': 0.19}
 19%|█▉        | 1992/10395 [5:40:06<18:09:49,  7.78s/it] 19%|█▉        | 1993/10395 [5:40:13<18:04:31,  7.74s/it]                                                         {'loss': 0.9651, 'learning_rate': 1.8659474999738333e-05, 'epoch': 0.19}
 19%|█▉        | 1993/10395 [5:40:13<18:04:31,  7.74s/it] 19%|█▉        | 1994/10395 [5:40:21<18:05:28,  7.75s/it]                                                         {'loss': 0.9883, 'learning_rate': 1.865791629306263e-05, 'epoch': 0.19}
 19%|█▉        | 1994/10395 [5:40:21<18:05:28,  7.75s/it] 19%|█▉        | 1995/10395 [5:40:29<18:18:16,  7.84s/it]                                                         {'loss': 1.0866, 'learning_rate': 1.8656356745894922e-05, 'epoch': 0.19}
 19%|█▉        | 1995/10395 [5:40:29<18:18:16,  7.84s/it] 19%|█▉        | 1996/10395 [5:40:36<17:57:16,  7.70s/it]                                                         {'loss': 0.9937, 'learning_rate': 1.8654796358386595e-05, 'epoch': 0.19}
 19%|█▉        | 1996/10395 [5:40:36<17:57:16,  7.70s/it] 19%|█▉        | 1997/10395 [5:40:44<18:03:45,  7.74s/it]                                                         {'loss': 0.9732, 'learning_rate': 1.8653235130689132e-05, 'epoch': 0.19}
 19%|█▉        | 1997/10395 [5:40:44<18:03:45,  7.74s/it] 19%|█▉        | 1998/10395 [5:40:53<19:04:37,  8.18s/it]                                                         {'loss': 1.0715, 'learning_rate': 1.8651673062954097e-05, 'epoch': 0.19}
 19%|█▉        | 1998/10395 [5:40:53<19:04:37,  8.18s/it] 19%|█▉        | 1999/10395 [5:41:01<18:55:04,  8.11s/it]                                                         {'loss': 1.0313, 'learning_rate': 1.865011015533313e-05, 'epoch': 0.19}
 19%|█▉        | 1999/10395 [5:41:01<18:55:04,  8.11s/it] 19%|█▉        | 2000/10395 [5:41:09<18:44:19,  8.04s/it]                                                         {'loss': 0.9992, 'learning_rate': 1.864854640797795e-05, 'epoch': 0.19}
 19%|█▉        | 2000/10395 [5:41:09<18:44:19,  8.04s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 19%|█▉        | 2001/10395 [5:42:54<86:12:01, 36.97s/it]                                                         {'loss': 1.0182, 'learning_rate': 1.8646981821040377e-05, 'epoch': 0.19}
 19%|█▉        | 2001/10395 [5:42:54<86:12:01, 36.97s/it] 19%|█▉        | 2002/10395 [5:43:01<65:37:25, 28.15s/it]                                                         {'loss': 0.8977, 'learning_rate': 1.8645416394672278e-05, 'epoch': 0.19}
 19%|█▉        | 2002/10395 [5:43:01<65:37:25, 28.15s/it] 19%|█▉        | 2003/10395 [5:43:09<51:07:03, 21.93s/it]                                                         {'loss': 0.9583, 'learning_rate': 1.8643850129025635e-05, 'epoch': 0.19}
 19%|█▉        | 2003/10395 [5:43:09<51:07:03, 21.93s/it] 19%|█▉        | 2004/10395 [5:43:26<48:11:54, 20.68s/it]                                                         {'loss': 0.4214, 'learning_rate': 1.864228302425249e-05, 'epoch': 0.19}
 19%|█▉        | 2004/10395 [5:43:26<48:11:54, 20.68s/it] 19%|█▉        | 2005/10395 [5:43:34<39:01:11, 16.74s/it]                                                         {'loss': 0.9337, 'learning_rate': 1.864071508050498e-05, 'epoch': 0.19}
 19%|█▉        | 2005/10395 [5:43:34<39:01:11, 16.74s/it] 19%|█▉        | 2006/10395 [5:43:42<32:49:14, 14.08s/it]                                                         {'loss': 0.9923, 'learning_rate': 1.8639146297935316e-05, 'epoch': 0.19}
 19%|█▉        | 2006/10395 [5:43:42<32:49:14, 14.08s/it] 19%|█▉        | 2007/10395 [5:43:50<28:57:53, 12.43s/it]                                                         {'loss': 1.014, 'learning_rate': 1.863757667669579e-05, 'epoch': 0.19}
 19%|█▉        | 2007/10395 [5:43:50<28:57:53, 12.43s/it] 19%|█▉        | 2008/10395 [5:43:58<25:30:23, 10.95s/it]                                                         {'loss': 1.0479, 'learning_rate': 1.8636006216938777e-05, 'epoch': 0.19}
 19%|█▉        | 2008/10395 [5:43:58<25:30:23, 10.95s/it] 19%|█▉        | 2009/10395 [5:44:05<22:48:49,  9.79s/it]                                                         {'loss': 1.1077, 'learning_rate': 1.863443491881674e-05, 'epoch': 0.19}
 19%|█▉        | 2009/10395 [5:44:05<22:48:49,  9.79s/it] 19%|█▉        | 2010/10395 [5:44:14<22:30:11,  9.66s/it]                                                         {'loss': 0.9645, 'learning_rate': 1.8632862782482208e-05, 'epoch': 0.19}
 19%|█▉        | 2010/10395 [5:44:14<22:30:11,  9.66s/it] 19%|█▉        | 2011/10395 [5:44:22<20:59:15,  9.01s/it]                                                         {'loss': 1.0503, 'learning_rate': 1.8631289808087808e-05, 'epoch': 0.19}
 19%|█▉        | 2011/10395 [5:44:22<20:59:15,  9.01s/it] 19%|█▉        | 2012/10395 [5:44:30<20:02:02,  8.60s/it]                                                         {'loss': 1.0488, 'learning_rate': 1.862971599578624e-05, 'epoch': 0.19}
 19%|█▉        | 2012/10395 [5:44:30<20:02:02,  8.60s/it] 19%|█▉        | 2013/10395 [5:44:38<19:35:11,  8.41s/it]                                                         {'loss': 0.9783, 'learning_rate': 1.862814134573028e-05, 'epoch': 0.19}
 19%|█▉        | 2013/10395 [5:44:38<19:35:11,  8.41s/it] 19%|█▉        | 2014/10395 [5:44:45<19:14:49,  8.27s/it]                                                         {'loss': 0.9068, 'learning_rate': 1.8626565858072805e-05, 'epoch': 0.19}
 19%|█▉        | 2014/10395 [5:44:45<19:14:49,  8.27s/it] 19%|█▉        | 2015/10395 [5:45:03<25:52:55, 11.12s/it]                                                         {'loss': 0.3995, 'learning_rate': 1.8624989532966746e-05, 'epoch': 0.19}
 19%|█▉        | 2015/10395 [5:45:03<25:52:55, 11.12s/it] 19%|█▉        | 2016/10395 [5:45:11<23:21:23, 10.04s/it]                                                         {'loss': 1.0341, 'learning_rate': 1.8623412370565135e-05, 'epoch': 0.19}
 19%|█▉        | 2016/10395 [5:45:11<23:21:23, 10.04s/it] 19%|█▉        | 2017/10395 [5:45:18<21:38:59,  9.30s/it]                                                         {'loss': 0.9325, 'learning_rate': 1.862183437102108e-05, 'epoch': 0.19}
 19%|█▉        | 2017/10395 [5:45:18<21:38:59,  9.30s/it] 19%|█▉        | 2018/10395 [5:45:26<20:27:03,  8.79s/it]                                                         {'loss': 1.0359, 'learning_rate': 1.8620255534487767e-05, 'epoch': 0.19}
 19%|█▉        | 2018/10395 [5:45:26<20:27:03,  8.79s/it] 19%|█▉        | 2019/10395 [5:45:35<20:41:54,  8.90s/it]                                                         {'loss': 0.9816, 'learning_rate': 1.861867586111847e-05, 'epoch': 0.19}
 19%|█▉        | 2019/10395 [5:45:35<20:41:54,  8.90s/it] 19%|█▉        | 2020/10395 [5:45:42<19:39:56,  8.45s/it]                                                         {'loss': 1.0141, 'learning_rate': 1.8617095351066542e-05, 'epoch': 0.19}
 19%|█▉        | 2020/10395 [5:45:42<19:39:56,  8.45s/it] 19%|█▉        | 2021/10395 [5:46:00<26:06:05, 11.22s/it]                                                         {'loss': 0.3545, 'learning_rate': 1.8615514004485405e-05, 'epoch': 0.19}
 19%|█▉        | 2021/10395 [5:46:00<26:06:05, 11.22s/it] 19%|█▉        | 2022/10395 [5:46:08<23:41:58, 10.19s/it]                                                         {'loss': 0.927, 'learning_rate': 1.8613931821528588e-05, 'epoch': 0.19}
 19%|█▉        | 2022/10395 [5:46:08<23:41:58, 10.19s/it] 19%|█▉        | 2023/10395 [5:46:15<21:48:48,  9.38s/it]                                                         {'loss': 0.9378, 'learning_rate': 1.8612348802349675e-05, 'epoch': 0.19}
 19%|█▉        | 2023/10395 [5:46:15<21:48:48,  9.38s/it] 19%|█▉        | 2024/10395 [5:46:23<20:33:57,  8.84s/it]                                                         {'loss': 0.91, 'learning_rate': 1.861076494710234e-05, 'epoch': 0.19}
 19%|█▉        | 2024/10395 [5:46:23<20:33:57,  8.84s/it] 19%|█▉        | 2025/10395 [5:46:31<19:43:08,  8.48s/it]                                                         {'loss': 1.0046, 'learning_rate': 1.860918025594035e-05, 'epoch': 0.19}
 19%|█▉        | 2025/10395 [5:46:31<19:43:08,  8.48s/it] 19%|█▉        | 2026/10395 [5:46:38<19:10:24,  8.25s/it]                                                         {'loss': 1.0266, 'learning_rate': 1.860759472901754e-05, 'epoch': 0.19}
 19%|█▉        | 2026/10395 [5:46:38<19:10:24,  8.25s/it] 19%|█▉        | 2027/10395 [5:46:55<25:16:56, 10.88s/it]                                                         {'loss': 0.4038, 'learning_rate': 1.8606008366487822e-05, 'epoch': 0.19}
 19%|█▉        | 2027/10395 [5:46:55<25:16:56, 10.88s/it] 20%|█▉        | 2028/10395 [5:47:03<23:19:13, 10.03s/it]                                                         {'loss': 0.9666, 'learning_rate': 1.860442116850521e-05, 'epoch': 0.2}
 20%|█▉        | 2028/10395 [5:47:03<23:19:13, 10.03s/it] 20%|█▉        | 2029/10395 [5:47:11<21:36:12,  9.30s/it]                                                         {'loss': 0.9558, 'learning_rate': 1.8602833135223773e-05, 'epoch': 0.2}
 20%|█▉        | 2029/10395 [5:47:11<21:36:12,  9.30s/it] 20%|█▉        | 2030/10395 [5:47:19<20:31:40,  8.83s/it]                                                         {'loss': 1.014, 'learning_rate': 1.860124426679768e-05, 'epoch': 0.2}
 20%|█▉        | 2030/10395 [5:47:19<20:31:40,  8.83s/it] 20%|█▉        | 2031/10395 [5:47:27<20:06:54,  8.66s/it]                                                         {'loss': 0.9814, 'learning_rate': 1.8599654563381178e-05, 'epoch': 0.2}
 20%|█▉        | 2031/10395 [5:47:27<20:06:54,  8.66s/it] 20%|█▉        | 2032/10395 [5:47:35<19:29:29,  8.39s/it]                                                         {'loss': 1.0296, 'learning_rate': 1.8598064025128587e-05, 'epoch': 0.2}
 20%|█▉        | 2032/10395 [5:47:35<19:29:29,  8.39s/it] 20%|█▉        | 2033/10395 [5:47:42<18:42:09,  8.05s/it]                                                         {'loss': 1.0183, 'learning_rate': 1.8596472652194313e-05, 'epoch': 0.2}
 20%|█▉        | 2033/10395 [5:47:42<18:42:09,  8.05s/it] 20%|█▉        | 2034/10395 [5:47:50<18:53:58,  8.14s/it]                                                         {'loss': 0.9513, 'learning_rate': 1.8594880444732846e-05, 'epoch': 0.2}
 20%|█▉        | 2034/10395 [5:47:50<18:53:58,  8.14s/it] 20%|█▉        | 2035/10395 [5:47:58<18:32:33,  7.98s/it]                                                         {'loss': 1.0275, 'learning_rate': 1.8593287402898755e-05, 'epoch': 0.2}
 20%|█▉        | 2035/10395 [5:47:58<18:32:33,  7.98s/it] 20%|█▉        | 2036/10395 [5:48:06<18:19:17,  7.89s/it]                                                         {'loss': 0.9695, 'learning_rate': 1.8591693526846685e-05, 'epoch': 0.2}
 20%|█▉        | 2036/10395 [5:48:06<18:19:17,  7.89s/it] 20%|█▉        | 2037/10395 [5:48:13<18:07:12,  7.80s/it]                                                         {'loss': 0.9858, 'learning_rate': 1.8590098816731365e-05, 'epoch': 0.2}
 20%|█▉        | 2037/10395 [5:48:13<18:07:12,  7.80s/it] 20%|█▉        | 2038/10395 [5:48:21<18:11:54,  7.84s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.8588503272707612e-05, 'epoch': 0.2}
 20%|█▉        | 2038/10395 [5:48:21<18:11:54,  7.84s/it] 20%|█▉        | 2039/10395 [5:48:29<18:27:22,  7.95s/it]                                                         {'loss': 0.9263, 'learning_rate': 1.8586906894930315e-05, 'epoch': 0.2}
 20%|█▉        | 2039/10395 [5:48:29<18:27:22,  7.95s/it] 20%|█▉        | 2040/10395 [5:48:38<18:36:30,  8.02s/it]                                                         {'loss': 0.9457, 'learning_rate': 1.8585309683554444e-05, 'epoch': 0.2}
 20%|█▉        | 2040/10395 [5:48:38<18:36:30,  8.02s/it] 20%|█▉        | 2041/10395 [5:48:45<18:00:48,  7.76s/it]                                                         {'loss': 0.9337, 'learning_rate': 1.858371163873506e-05, 'epoch': 0.2}
 20%|█▉        | 2041/10395 [5:48:45<18:00:48,  7.76s/it] 20%|█▉        | 2042/10395 [5:48:52<17:35:08,  7.58s/it]                                                         {'loss': 1.0064, 'learning_rate': 1.858211276062729e-05, 'epoch': 0.2}
 20%|█▉        | 2042/10395 [5:48:52<17:35:08,  7.58s/it] 20%|█▉        | 2043/10395 [5:48:59<17:30:11,  7.54s/it]                                                         {'loss': 0.9151, 'learning_rate': 1.8580513049386356e-05, 'epoch': 0.2}
 20%|█▉        | 2043/10395 [5:48:59<17:30:11,  7.54s/it] 20%|█▉        | 2044/10395 [5:49:08<18:09:45,  7.83s/it]                                                         {'loss': 1.0296, 'learning_rate': 1.857891250516755e-05, 'epoch': 0.2}
 20%|█▉        | 2044/10395 [5:49:08<18:09:45,  7.83s/it] 20%|█▉        | 2045/10395 [5:49:16<18:07:08,  7.81s/it]                                                         {'loss': 1.0564, 'learning_rate': 1.8577311128126255e-05, 'epoch': 0.2}
 20%|█▉        | 2045/10395 [5:49:16<18:07:08,  7.81s/it] 20%|█▉        | 2046/10395 [5:49:23<17:58:54,  7.75s/it]                                                         {'loss': 0.9864, 'learning_rate': 1.857570891841792e-05, 'epoch': 0.2}
 20%|█▉        | 2046/10395 [5:49:23<17:58:54,  7.75s/it] 20%|█▉        | 2047/10395 [5:49:30<17:31:00,  7.55s/it]                                                         {'loss': 1.0363, 'learning_rate': 1.8574105876198093e-05, 'epoch': 0.2}
 20%|█▉        | 2047/10395 [5:49:30<17:31:00,  7.55s/it] 20%|█▉        | 2048/10395 [5:49:38<17:34:35,  7.58s/it]                                                         {'loss': 0.9906, 'learning_rate': 1.8572502001622388e-05, 'epoch': 0.2}
 20%|█▉        | 2048/10395 [5:49:38<17:34:35,  7.58s/it] 20%|█▉        | 2049/10395 [5:49:46<17:59:18,  7.76s/it]                                                         {'loss': 0.8921, 'learning_rate': 1.8570897294846508e-05, 'epoch': 0.2}
 20%|█▉        | 2049/10395 [5:49:46<17:59:18,  7.76s/it] 20%|█▉        | 2050/10395 [5:49:54<17:43:40,  7.65s/it]                                                         {'loss': 0.9969, 'learning_rate': 1.8569291756026237e-05, 'epoch': 0.2}
 20%|█▉        | 2050/10395 [5:49:54<17:43:40,  7.65s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 20%|█▉        | 2051/10395 [5:51:37<84:15:47, 36.36s/it]                                                         {'loss': 0.9579, 'learning_rate': 1.8567685385317437e-05, 'epoch': 0.2}
 20%|█▉        | 2051/10395 [5:51:37<84:15:47, 36.36s/it] 20%|█▉        | 2052/10395 [5:51:44<64:02:21, 27.63s/it]                                                         {'loss': 1.0158, 'learning_rate': 1.8566078182876045e-05, 'epoch': 0.2}
 20%|█▉        | 2052/10395 [5:51:44<64:02:21, 27.63s/it] 20%|█▉        | 2053/10395 [5:52:02<56:59:27, 24.59s/it]                                                         {'loss': 0.4204, 'learning_rate': 1.8564470148858088e-05, 'epoch': 0.2}
 20%|█▉        | 2053/10395 [5:52:02<56:59:27, 24.59s/it] 20%|█▉        | 2054/10395 [5:52:10<45:23:21, 19.59s/it]                                                         {'loss': 1.0028, 'learning_rate': 1.8562861283419672e-05, 'epoch': 0.2}
 20%|█▉        | 2054/10395 [5:52:10<45:23:21, 19.59s/it] 20%|█▉        | 2055/10395 [5:52:18<37:48:48, 16.32s/it]                                                         {'loss': 0.9938, 'learning_rate': 1.8561251586716985e-05, 'epoch': 0.2}
 20%|█▉        | 2055/10395 [5:52:18<37:48:48, 16.32s/it] 20%|█▉        | 2056/10395 [5:52:26<31:52:29, 13.76s/it]                                                         {'loss': 0.9728, 'learning_rate': 1.855964105890629e-05, 'epoch': 0.2}
 20%|█▉        | 2056/10395 [5:52:26<31:52:29, 13.76s/it] 20%|█▉        | 2057/10395 [5:52:33<27:22:25, 11.82s/it]                                                         {'loss': 1.0153, 'learning_rate': 1.8558029700143926e-05, 'epoch': 0.2}
 20%|█▉        | 2057/10395 [5:52:33<27:22:25, 11.82s/it] 20%|█▉        | 2058/10395 [5:52:41<24:24:59, 10.54s/it]                                                         {'loss': 1.0197, 'learning_rate': 1.855641751058633e-05, 'epoch': 0.2}
 20%|█▉        | 2058/10395 [5:52:41<24:24:59, 10.54s/it] 20%|█▉        | 2059/10395 [5:52:49<22:31:56,  9.73s/it]                                                         {'loss': 1.0196, 'learning_rate': 1.855480449039001e-05, 'epoch': 0.2}
 20%|█▉        | 2059/10395 [5:52:49<22:31:56,  9.73s/it] 20%|█▉        | 2060/10395 [5:52:57<21:32:39,  9.31s/it]                                                         {'loss': 1.0023, 'learning_rate': 1.8553190639711554e-05, 'epoch': 0.2}
 20%|█▉        | 2060/10395 [5:52:57<21:32:39,  9.31s/it] 20%|█▉        | 2061/10395 [5:53:05<20:25:28,  8.82s/it]                                                         {'loss': 1.0344, 'learning_rate': 1.8551575958707623e-05, 'epoch': 0.2}
 20%|█▉        | 2061/10395 [5:53:05<20:25:28,  8.82s/it] 20%|█▉        | 2062/10395 [5:53:12<19:24:34,  8.39s/it]                                                         {'loss': 0.9748, 'learning_rate': 1.8549960447534975e-05, 'epoch': 0.2}
 20%|█▉        | 2062/10395 [5:53:12<19:24:34,  8.39s/it] 20%|█▉        | 2063/10395 [5:53:20<18:55:27,  8.18s/it]                                                         {'loss': 0.9993, 'learning_rate': 1.854834410635044e-05, 'epoch': 0.2}
 20%|█▉        | 2063/10395 [5:53:20<18:55:27,  8.18s/it] 20%|█▉        | 2064/10395 [5:53:27<18:24:31,  7.95s/it]                                                         {'loss': 1.0027, 'learning_rate': 1.8546726935310925e-05, 'epoch': 0.2}
 20%|█▉        | 2064/10395 [5:53:27<18:24:31,  7.95s/it] 20%|█▉        | 2065/10395 [5:53:35<18:24:17,  7.95s/it]                                                         {'loss': 0.9865, 'learning_rate': 1.8545108934573424e-05, 'epoch': 0.2}
 20%|█▉        | 2065/10395 [5:53:35<18:24:17,  7.95s/it] 20%|█▉        | 2066/10395 [5:53:43<18:01:50,  7.79s/it]                                                         {'loss': 1.003, 'learning_rate': 1.8543490104295006e-05, 'epoch': 0.2}
 20%|█▉        | 2066/10395 [5:53:43<18:01:50,  7.79s/it] 20%|█▉        | 2067/10395 [5:53:51<18:09:25,  7.85s/it]                                                         {'loss': 0.9714, 'learning_rate': 1.854187044463283e-05, 'epoch': 0.2}
 20%|█▉        | 2067/10395 [5:53:51<18:09:25,  7.85s/it] 20%|█▉        | 2068/10395 [5:53:59<18:21:06,  7.93s/it]                                                         {'loss': 1.0077, 'learning_rate': 1.8540249955744124e-05, 'epoch': 0.2}
 20%|█▉        | 2068/10395 [5:53:59<18:21:06,  7.93s/it] 20%|█▉        | 2069/10395 [5:54:06<18:00:22,  7.79s/it]                                                         {'loss': 1.0143, 'learning_rate': 1.8538628637786203e-05, 'epoch': 0.2}
 20%|█▉        | 2069/10395 [5:54:06<18:00:22,  7.79s/it] 20%|█▉        | 2070/10395 [5:54:14<17:59:01,  7.78s/it]                                                         {'loss': 1.0385, 'learning_rate': 1.853700649091646e-05, 'epoch': 0.2}
 20%|█▉        | 2070/10395 [5:54:14<17:59:01,  7.78s/it] 20%|█▉        | 2071/10395 [5:54:22<17:51:52,  7.73s/it]                                                         {'loss': 0.9922, 'learning_rate': 1.853538351529237e-05, 'epoch': 0.2}
 20%|█▉        | 2071/10395 [5:54:22<17:51:52,  7.73s/it] 20%|█▉        | 2072/10395 [5:54:29<17:46:55,  7.69s/it]                                                         {'loss': 0.9319, 'learning_rate': 1.853375971107149e-05, 'epoch': 0.2}
 20%|█▉        | 2072/10395 [5:54:29<17:46:55,  7.69s/it] 20%|█▉        | 2073/10395 [5:54:37<17:38:44,  7.63s/it]                                                         {'loss': 1.0052, 'learning_rate': 1.8532135078411453e-05, 'epoch': 0.2}
 20%|█▉        | 2073/10395 [5:54:37<17:38:44,  7.63s/it] 20%|█▉        | 2074/10395 [5:54:45<17:59:19,  7.78s/it]                                                         {'loss': 0.9522, 'learning_rate': 1.853050961746998e-05, 'epoch': 0.2}
 20%|█▉        | 2074/10395 [5:54:45<17:59:19,  7.78s/it] 20%|█▉        | 2075/10395 [5:54:52<17:40:21,  7.65s/it]                                                         {'loss': 0.9901, 'learning_rate': 1.8528883328404857e-05, 'epoch': 0.2}
 20%|█▉        | 2075/10395 [5:54:52<17:40:21,  7.65s/it] 20%|█▉        | 2076/10395 [5:55:00<17:39:04,  7.64s/it]                                                         {'loss': 1.079, 'learning_rate': 1.852725621137397e-05, 'epoch': 0.2}
 20%|█▉        | 2076/10395 [5:55:00<17:39:04,  7.64s/it] 20%|█▉        | 2077/10395 [5:55:08<18:03:52,  7.82s/it]                                                         {'loss': 0.9497, 'learning_rate': 1.8525628266535272e-05, 'epoch': 0.2}
 20%|█▉        | 2077/10395 [5:55:08<18:03:52,  7.82s/it] 20%|█▉        | 2078/10395 [5:55:25<24:25:12, 10.57s/it]                                                         {'loss': 0.3799, 'learning_rate': 1.85239994940468e-05, 'epoch': 0.2}
 20%|█▉        | 2078/10395 [5:55:25<24:25:12, 10.57s/it] 20%|██        | 2079/10395 [5:55:33<22:22:35,  9.69s/it]                                                         {'loss': 1.0127, 'learning_rate': 1.8522369894066674e-05, 'epoch': 0.2}
 20%|██        | 2079/10395 [5:55:33<22:22:35,  9.69s/it] 20%|██        | 2080/10395 [5:55:40<20:47:34,  9.00s/it]                                                         {'loss': 0.997, 'learning_rate': 1.852073946675309e-05, 'epoch': 0.2}
 20%|██        | 2080/10395 [5:55:40<20:47:34,  9.00s/it] 20%|██        | 2081/10395 [5:55:48<20:17:23,  8.79s/it]                                                         {'loss': 0.975, 'learning_rate': 1.851910821226433e-05, 'epoch': 0.2}
 20%|██        | 2081/10395 [5:55:48<20:17:23,  8.79s/it] 20%|██        | 2082/10395 [5:56:05<25:50:34, 11.19s/it]                                                         {'loss': 0.2986, 'learning_rate': 1.851747613075875e-05, 'epoch': 0.2}
 20%|██        | 2082/10395 [5:56:05<25:50:34, 11.19s/it] 20%|██        | 2083/10395 [5:56:13<23:27:25, 10.16s/it]                                                         {'loss': 0.9408, 'learning_rate': 1.8515843222394786e-05, 'epoch': 0.2}
 20%|██        | 2083/10395 [5:56:13<23:27:25, 10.16s/it] 20%|██        | 2084/10395 [5:56:22<22:36:03,  9.79s/it]                                                         {'loss': 0.9324, 'learning_rate': 1.8514209487330964e-05, 'epoch': 0.2}
 20%|██        | 2084/10395 [5:56:22<22:36:03,  9.79s/it] 20%|██        | 2085/10395 [5:56:30<21:15:29,  9.21s/it]                                                         {'loss': 1.03, 'learning_rate': 1.8512574925725878e-05, 'epoch': 0.2}
 20%|██        | 2085/10395 [5:56:30<21:15:29,  9.21s/it] 20%|██        | 2086/10395 [5:56:38<20:19:48,  8.81s/it]                                                         {'loss': 0.9275, 'learning_rate': 1.8510939537738212e-05, 'epoch': 0.2}
 20%|██        | 2086/10395 [5:56:38<20:19:48,  8.81s/it] 20%|██        | 2087/10395 [5:56:45<19:25:35,  8.42s/it]                                                         {'loss': 0.9009, 'learning_rate': 1.850930332352672e-05, 'epoch': 0.2}
 20%|██        | 2087/10395 [5:56:45<19:25:35,  8.42s/it] 20%|██        | 2088/10395 [5:56:53<19:19:20,  8.37s/it]                                                         {'loss': 0.9462, 'learning_rate': 1.8507666283250246e-05, 'epoch': 0.2}
 20%|██        | 2088/10395 [5:56:53<19:19:20,  8.37s/it] 20%|██        | 2089/10395 [5:57:01<18:41:42,  8.10s/it]                                                         {'loss': 1.0329, 'learning_rate': 1.8506028417067712e-05, 'epoch': 0.2}
 20%|██        | 2089/10395 [5:57:01<18:41:42,  8.10s/it] 20%|██        | 2090/10395 [5:57:10<19:14:24,  8.34s/it]                                                         {'loss': 0.928, 'learning_rate': 1.8504389725138118e-05, 'epoch': 0.2}
 20%|██        | 2090/10395 [5:57:10<19:14:24,  8.34s/it] 20%|██        | 2091/10395 [5:57:28<25:56:30, 11.25s/it]                                                         {'loss': 0.4486, 'learning_rate': 1.850275020762054e-05, 'epoch': 0.2}
 20%|██        | 2091/10395 [5:57:28<25:56:30, 11.25s/it] 20%|██        | 2092/10395 [5:57:36<23:41:15, 10.27s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.8501109864674146e-05, 'epoch': 0.2}
 20%|██        | 2092/10395 [5:57:36<23:41:15, 10.27s/it] 20%|██        | 2093/10395 [5:57:53<28:53:19, 12.53s/it]                                                         {'loss': 0.3941, 'learning_rate': 1.849946869645817e-05, 'epoch': 0.2}
 20%|██        | 2093/10395 [5:57:53<28:53:19, 12.53s/it] 20%|██        | 2094/10395 [5:58:01<25:40:10, 11.13s/it]                                                         {'loss': 0.917, 'learning_rate': 1.8497826703131938e-05, 'epoch': 0.2}
 20%|██        | 2094/10395 [5:58:01<25:40:10, 11.13s/it] 20%|██        | 2095/10395 [5:58:10<23:39:24, 10.26s/it]                                                         {'loss': 0.9707, 'learning_rate': 1.8496183884854846e-05, 'epoch': 0.2}
 20%|██        | 2095/10395 [5:58:10<23:39:24, 10.26s/it] 20%|██        | 2096/10395 [5:58:18<22:03:11,  9.57s/it]                                                         {'loss': 0.9904, 'learning_rate': 1.8494540241786385e-05, 'epoch': 0.2}
 20%|██        | 2096/10395 [5:58:18<22:03:11,  9.57s/it] 20%|██        | 2097/10395 [5:58:25<20:52:13,  9.05s/it]                                                         {'loss': 0.9956, 'learning_rate': 1.8492895774086107e-05, 'epoch': 0.2}
 20%|██        | 2097/10395 [5:58:25<20:52:13,  9.05s/it] 20%|██        | 2098/10395 [5:58:33<20:03:41,  8.70s/it]                                                         {'loss': 0.9774, 'learning_rate': 1.8491250481913656e-05, 'epoch': 0.2}
 20%|██        | 2098/10395 [5:58:33<20:03:41,  8.70s/it] 20%|██        | 2099/10395 [5:58:41<19:33:10,  8.48s/it]                                                         {'loss': 0.9804, 'learning_rate': 1.8489604365428754e-05, 'epoch': 0.2}
 20%|██        | 2099/10395 [5:58:41<19:33:10,  8.48s/it] 20%|██        | 2100/10395 [5:58:50<19:33:38,  8.49s/it]                                                         {'loss': 0.9589, 'learning_rate': 1.8487957424791206e-05, 'epoch': 0.2}
 20%|██        | 2100/10395 [5:58:50<19:33:38,  8.49s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 20%|██        | 2101/10395 [6:00:33<85:03:31, 36.92s/it]                                                         {'loss': 1.0078, 'learning_rate': 1.8486309660160885e-05, 'epoch': 0.2}
 20%|██        | 2101/10395 [6:00:33<85:03:31, 36.92s/it] 20%|██        | 2102/10395 [6:00:40<64:33:13, 28.02s/it]                                                         {'loss': 1.0963, 'learning_rate': 1.848466107169776e-05, 'epoch': 0.2}
 20%|██        | 2102/10395 [6:00:40<64:33:13, 28.02s/it] 20%|██        | 2103/10395 [6:00:48<50:15:02, 21.82s/it]                                                         {'loss': 0.8928, 'learning_rate': 1.848301165956187e-05, 'epoch': 0.2}
 20%|██        | 2103/10395 [6:00:48<50:15:02, 21.82s/it] 20%|██        | 2104/10395 [6:00:57<41:33:33, 18.05s/it]                                                         {'loss': 0.8554, 'learning_rate': 1.8481361423913338e-05, 'epoch': 0.2}
 20%|██        | 2104/10395 [6:00:57<41:33:33, 18.05s/it] 20%|██        | 2105/10395 [6:01:04<34:11:15, 14.85s/it]                                                         {'loss': 0.9873, 'learning_rate': 1.847971036491236e-05, 'epoch': 0.2}
 20%|██        | 2105/10395 [6:01:04<34:11:15, 14.85s/it] 20%|██        | 2106/10395 [6:01:22<36:13:53, 15.74s/it]                                                         {'loss': 0.3859, 'learning_rate': 1.8478058482719222e-05, 'epoch': 0.2}
 20%|██        | 2106/10395 [6:01:22<36:13:53, 15.74s/it] 20%|██        | 2107/10395 [6:01:30<30:34:10, 13.28s/it]                                                         {'loss': 0.9818, 'learning_rate': 1.8476405777494285e-05, 'epoch': 0.2}
 20%|██        | 2107/10395 [6:01:30<30:34:10, 13.28s/it] 20%|██        | 2108/10395 [6:01:37<26:34:36, 11.55s/it]                                                         {'loss': 0.9599, 'learning_rate': 1.8474752249397992e-05, 'epoch': 0.2}
 20%|██        | 2108/10395 [6:01:37<26:34:36, 11.55s/it] 20%|██        | 2109/10395 [6:01:45<24:02:18, 10.44s/it]                                                         {'loss': 0.9292, 'learning_rate': 1.847309789859086e-05, 'epoch': 0.2}
 20%|██        | 2109/10395 [6:01:45<24:02:18, 10.44s/it] 20%|██        | 2110/10395 [6:01:52<22:00:07,  9.56s/it]                                                         {'loss': 0.9412, 'learning_rate': 1.8471442725233488e-05, 'epoch': 0.2}
 20%|██        | 2110/10395 [6:01:52<22:00:07,  9.56s/it] 20%|██        | 2111/10395 [6:02:00<20:20:18,  8.84s/it]                                                         {'loss': 1.0422, 'learning_rate': 1.8469786729486562e-05, 'epoch': 0.2}
 20%|██        | 2111/10395 [6:02:00<20:20:18,  8.84s/it] 20%|██        | 2112/10395 [6:02:07<19:31:49,  8.49s/it]                                                         {'loss': 1.0079, 'learning_rate': 1.846812991151084e-05, 'epoch': 0.2}
 20%|██        | 2112/10395 [6:02:07<19:31:49,  8.49s/it] 20%|██        | 2113/10395 [6:02:14<18:39:39,  8.11s/it]                                                         {'loss': 0.9856, 'learning_rate': 1.846647227146716e-05, 'epoch': 0.2}
 20%|██        | 2113/10395 [6:02:15<18:39:39,  8.11s/it] 20%|██        | 2114/10395 [6:02:22<18:17:45,  7.95s/it]                                                         {'loss': 0.8896, 'learning_rate': 1.8464813809516447e-05, 'epoch': 0.2}
 20%|██        | 2114/10395 [6:02:22<18:17:45,  7.95s/it] 20%|██        | 2115/10395 [6:02:30<18:07:31,  7.88s/it]                                                         {'loss': 0.9768, 'learning_rate': 1.84631545258197e-05, 'epoch': 0.2}
 20%|██        | 2115/10395 [6:02:30<18:07:31,  7.88s/it] 20%|██        | 2116/10395 [6:02:38<18:05:44,  7.87s/it]                                                         {'loss': 0.9767, 'learning_rate': 1.8461494420537997e-05, 'epoch': 0.2}
 20%|██        | 2116/10395 [6:02:38<18:05:44,  7.87s/it] 20%|██        | 2117/10395 [6:02:45<17:35:54,  7.65s/it]                                                         {'loss': 1.033, 'learning_rate': 1.8459833493832496e-05, 'epoch': 0.2}
 20%|██        | 2117/10395 [6:02:45<17:35:54,  7.65s/it] 20%|██        | 2118/10395 [6:02:53<17:44:38,  7.72s/it]                                                         {'loss': 0.9677, 'learning_rate': 1.8458171745864443e-05, 'epoch': 0.2}
 20%|██        | 2118/10395 [6:02:53<17:44:38,  7.72s/it] 20%|██        | 2119/10395 [6:03:01<18:14:09,  7.93s/it]                                                         {'loss': 0.9862, 'learning_rate': 1.845650917679515e-05, 'epoch': 0.2}
 20%|██        | 2119/10395 [6:03:01<18:14:09,  7.93s/it] 20%|██        | 2120/10395 [6:03:10<19:14:44,  8.37s/it]                                                         {'loss': 0.9294, 'learning_rate': 1.8454845786786012e-05, 'epoch': 0.2}
 20%|██        | 2120/10395 [6:03:10<19:14:44,  8.37s/it] 20%|██        | 2121/10395 [6:03:18<18:54:34,  8.23s/it]                                                         {'loss': 0.9051, 'learning_rate': 1.8453181575998518e-05, 'epoch': 0.2}
 20%|██        | 2121/10395 [6:03:19<18:54:34,  8.23s/it] 20%|██        | 2122/10395 [6:03:27<19:07:19,  8.32s/it]                                                         {'loss': 0.8837, 'learning_rate': 1.845151654459422e-05, 'epoch': 0.2}
 20%|██        | 2122/10395 [6:03:27<19:07:19,  8.32s/it] 20%|██        | 2123/10395 [6:03:35<19:11:02,  8.35s/it]                                                         {'loss': 0.9937, 'learning_rate': 1.844985069273476e-05, 'epoch': 0.2}
 20%|██        | 2123/10395 [6:03:35<19:11:02,  8.35s/it] 20%|██        | 2124/10395 [6:03:44<19:21:33,  8.43s/it]                                                         {'loss': 0.9799, 'learning_rate': 1.8448184020581847e-05, 'epoch': 0.2}
 20%|██        | 2124/10395 [6:03:44<19:21:33,  8.43s/it] 20%|██        | 2125/10395 [6:03:52<19:04:12,  8.30s/it]                                                         {'loss': 0.8696, 'learning_rate': 1.8446516528297286e-05, 'epoch': 0.2}
 20%|██        | 2125/10395 [6:03:52<19:04:12,  8.30s/it] 20%|██        | 2126/10395 [6:03:59<18:30:49,  8.06s/it]                                                         {'loss': 0.956, 'learning_rate': 1.844484821604295e-05, 'epoch': 0.2}
 20%|██        | 2126/10395 [6:03:59<18:30:49,  8.06s/it] 20%|██        | 2127/10395 [6:04:07<18:16:32,  7.96s/it]                                                         {'loss': 0.9948, 'learning_rate': 1.84431790839808e-05, 'epoch': 0.2}
 20%|██        | 2127/10395 [6:04:07<18:16:32,  7.96s/it] 20%|██        | 2128/10395 [6:04:15<18:13:49,  7.94s/it]                                                         {'loss': 0.9751, 'learning_rate': 1.8441509132272862e-05, 'epoch': 0.2}
 20%|██        | 2128/10395 [6:04:15<18:13:49,  7.94s/it] 20%|██        | 2129/10395 [6:04:22<17:48:05,  7.75s/it]                                                         {'loss': 0.9615, 'learning_rate': 1.8439838361081258e-05, 'epoch': 0.2}
 20%|██        | 2129/10395 [6:04:22<17:48:05,  7.75s/it] 20%|██        | 2130/10395 [6:04:30<17:45:33,  7.74s/it]                                                         {'loss': 1.0249, 'learning_rate': 1.8438166770568182e-05, 'epoch': 0.2}
 20%|██        | 2130/10395 [6:04:30<17:45:33,  7.74s/it] 21%|██        | 2131/10395 [6:04:38<17:45:24,  7.74s/it]                                                         {'loss': 1.0398, 'learning_rate': 1.843649436089591e-05, 'epoch': 0.2}
 21%|██        | 2131/10395 [6:04:38<17:45:24,  7.74s/it] 21%|██        | 2132/10395 [6:04:46<18:09:00,  7.91s/it]                                                         {'loss': 0.9804, 'learning_rate': 1.8434821132226792e-05, 'epoch': 0.21}
 21%|██        | 2132/10395 [6:04:46<18:09:00,  7.91s/it] 21%|██        | 2133/10395 [6:04:54<18:18:10,  7.98s/it]                                                         {'loss': 0.9589, 'learning_rate': 1.8433147084723268e-05, 'epoch': 0.21}
 21%|██        | 2133/10395 [6:04:54<18:18:10,  7.98s/it] 21%|██        | 2134/10395 [6:05:02<18:04:35,  7.88s/it]                                                         {'loss': 1.0406, 'learning_rate': 1.843147221854784e-05, 'epoch': 0.21}
 21%|██        | 2134/10395 [6:05:02<18:04:35,  7.88s/it] 21%|██        | 2135/10395 [6:05:09<17:47:40,  7.76s/it]                                                         {'loss': 1.0533, 'learning_rate': 1.842979653386311e-05, 'epoch': 0.21}
 21%|██        | 2135/10395 [6:05:09<17:47:40,  7.76s/it] 21%|██        | 2136/10395 [6:05:17<17:59:28,  7.84s/it]                                                         {'loss': 0.9859, 'learning_rate': 1.842812003083175e-05, 'epoch': 0.21}
 21%|██        | 2136/10395 [6:05:17<17:59:28,  7.84s/it] 21%|██        | 2137/10395 [6:05:25<17:41:54,  7.72s/it]                                                         {'loss': 0.9853, 'learning_rate': 1.8426442709616507e-05, 'epoch': 0.21}
 21%|██        | 2137/10395 [6:05:25<17:41:54,  7.72s/it] 21%|██        | 2138/10395 [6:05:32<17:26:44,  7.61s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.8424764570380215e-05, 'epoch': 0.21}
 21%|██        | 2138/10395 [6:05:32<17:26:44,  7.61s/it] 21%|██        | 2139/10395 [6:05:41<18:07:23,  7.90s/it]                                                         {'loss': 1.0519, 'learning_rate': 1.8423085613285775e-05, 'epoch': 0.21}
 21%|██        | 2139/10395 [6:05:41<18:07:23,  7.90s/it] 21%|██        | 2140/10395 [6:05:49<18:34:06,  8.10s/it]                                                         {'loss': 0.9432, 'learning_rate': 1.842140583849619e-05, 'epoch': 0.21}
 21%|██        | 2140/10395 [6:05:49<18:34:06,  8.10s/it] 21%|██        | 2141/10395 [6:05:57<18:25:16,  8.03s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.841972524617452e-05, 'epoch': 0.21}
 21%|██        | 2141/10395 [6:05:57<18:25:16,  8.03s/it] 21%|██        | 2142/10395 [6:06:05<18:05:16,  7.89s/it]                                                         {'loss': 0.9896, 'learning_rate': 1.841804383648392e-05, 'epoch': 0.21}
 21%|██        | 2142/10395 [6:06:05<18:05:16,  7.89s/it] 21%|██        | 2143/10395 [6:06:13<18:23:33,  8.02s/it]                                                         {'loss': 0.9497, 'learning_rate': 1.841636160958761e-05, 'epoch': 0.21}
 21%|██        | 2143/10395 [6:06:13<18:23:33,  8.02s/it] 21%|██        | 2144/10395 [6:06:21<18:34:41,  8.11s/it]                                                         {'loss': 0.9494, 'learning_rate': 1.8414678565648905e-05, 'epoch': 0.21}
 21%|██        | 2144/10395 [6:06:21<18:34:41,  8.11s/it] 21%|██        | 2145/10395 [6:06:37<23:25:45, 10.22s/it]                                                         {'loss': 0.3495, 'learning_rate': 1.841299470483118e-05, 'epoch': 0.21}
 21%|██        | 2145/10395 [6:06:37<23:25:45, 10.22s/it] 21%|██        | 2146/10395 [6:06:45<21:51:22,  9.54s/it]                                                         {'loss': 0.9901, 'learning_rate': 1.8411310027297915e-05, 'epoch': 0.21}
 21%|██        | 2146/10395 [6:06:45<21:51:22,  9.54s/it] 21%|██        | 2147/10395 [6:06:53<21:14:50,  9.27s/it]                                                         {'loss': 0.9618, 'learning_rate': 1.8409624533212644e-05, 'epoch': 0.21}
 21%|██        | 2147/10395 [6:06:53<21:14:50,  9.27s/it] 21%|██        | 2148/10395 [6:07:00<19:40:15,  8.59s/it]                                                         {'loss': 0.9137, 'learning_rate': 1.8407938222738993e-05, 'epoch': 0.21}
 21%|██        | 2148/10395 [6:07:00<19:40:15,  8.59s/it] 21%|██        | 2149/10395 [6:07:08<18:59:08,  8.29s/it]                                                         {'loss': 1.0085, 'learning_rate': 1.840625109604067e-05, 'epoch': 0.21}
 21%|██        | 2149/10395 [6:07:08<18:59:08,  8.29s/it] 21%|██        | 2150/10395 [6:07:16<18:54:15,  8.25s/it]                                                         {'loss': 1.0288, 'learning_rate': 1.8404563153281456e-05, 'epoch': 0.21}
 21%|██        | 2150/10395 [6:07:16<18:54:15,  8.25s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 21%|██        | 2151/10395 [6:08:56<82:04:26, 35.84s/it]                                                         {'loss': 0.8558, 'learning_rate': 1.8402874394625208e-05, 'epoch': 0.21}
 21%|██        | 2151/10395 [6:08:56<82:04:26, 35.84s/it] 21%|██        | 2152/10395 [6:09:04<62:51:24, 27.45s/it]                                                         {'loss': 1.0198, 'learning_rate': 1.8401184820235873e-05, 'epoch': 0.21}
 21%|██        | 2152/10395 [6:09:04<62:51:24, 27.45s/it] 21%|██        | 2153/10395 [6:09:12<49:20:46, 21.55s/it]                                                         {'loss': 0.9404, 'learning_rate': 1.839949443027747e-05, 'epoch': 0.21}
 21%|██        | 2153/10395 [6:09:12<49:20:46, 21.55s/it] 21%|██        | 2154/10395 [6:09:28<45:37:12, 19.93s/it]                                                         {'loss': 0.3768, 'learning_rate': 1.8397803224914095e-05, 'epoch': 0.21}
 21%|██        | 2154/10395 [6:09:28<45:37:12, 19.93s/it] 21%|██        | 2155/10395 [6:09:36<37:10:32, 16.24s/it]                                                         {'loss': 1.0491, 'learning_rate': 1.839611120430993e-05, 'epoch': 0.21}
 21%|██        | 2155/10395 [6:09:36<37:10:32, 16.24s/it] 21%|██        | 2156/10395 [6:09:44<31:29:17, 13.76s/it]                                                         {'loss': 0.9984, 'learning_rate': 1.8394418368629234e-05, 'epoch': 0.21}
 21%|██        | 2156/10395 [6:09:44<31:29:17, 13.76s/it] 21%|██        | 2157/10395 [6:09:52<27:37:51, 12.07s/it]                                                         {'loss': 1.0037, 'learning_rate': 1.8392724718036338e-05, 'epoch': 0.21}
 21%|██        | 2157/10395 [6:09:52<27:37:51, 12.07s/it] 21%|██        | 2158/10395 [6:09:59<24:30:00, 10.71s/it]                                                         {'loss': 0.9053, 'learning_rate': 1.8391030252695664e-05, 'epoch': 0.21}
 21%|██        | 2158/10395 [6:09:59<24:30:00, 10.71s/it] 21%|██        | 2159/10395 [6:10:16<28:41:12, 12.54s/it]                                                         {'loss': 0.3901, 'learning_rate': 1.8389334972771705e-05, 'epoch': 0.21}
 21%|██        | 2159/10395 [6:10:16<28:41:12, 12.54s/it] 21%|██        | 2160/10395 [6:10:24<25:15:50, 11.04s/it]                                                         {'loss': 1.0388, 'learning_rate': 1.8387638878429034e-05, 'epoch': 0.21}
 21%|██        | 2160/10395 [6:10:24<25:15:50, 11.04s/it] 21%|██        | 2161/10395 [6:10:31<22:37:48,  9.89s/it]                                                         {'loss': 0.9701, 'learning_rate': 1.8385941969832303e-05, 'epoch': 0.21}
 21%|██        | 2161/10395 [6:10:31<22:37:48,  9.89s/it] 21%|██        | 2162/10395 [6:10:38<21:06:32,  9.23s/it]                                                         {'loss': 0.9612, 'learning_rate': 1.8384244247146253e-05, 'epoch': 0.21}
 21%|██        | 2162/10395 [6:10:38<21:06:32,  9.23s/it] 21%|██        | 2163/10395 [6:10:47<20:22:21,  8.91s/it]                                                         {'loss': 1.005, 'learning_rate': 1.838254571053568e-05, 'epoch': 0.21}
 21%|██        | 2163/10395 [6:10:47<20:22:21,  8.91s/it] 21%|██        | 2164/10395 [6:10:55<20:16:21,  8.87s/it]                                                         {'loss': 0.9165, 'learning_rate': 1.8380846360165488e-05, 'epoch': 0.21}
 21%|██        | 2164/10395 [6:10:55<20:16:21,  8.87s/it] 21%|██        | 2165/10395 [6:11:03<19:12:51,  8.40s/it]                                                         {'loss': 0.9937, 'learning_rate': 1.8379146196200645e-05, 'epoch': 0.21}
 21%|██        | 2165/10395 [6:11:03<19:12:51,  8.40s/it] 21%|██        | 2166/10395 [6:11:11<18:57:41,  8.30s/it]                                                         {'loss': 0.9265, 'learning_rate': 1.8377445218806186e-05, 'epoch': 0.21}
 21%|██        | 2166/10395 [6:11:11<18:57:41,  8.30s/it] 21%|██        | 2167/10395 [6:11:19<18:51:56,  8.25s/it]                                                         {'loss': 0.9144, 'learning_rate': 1.8375743428147255e-05, 'epoch': 0.21}
 21%|██        | 2167/10395 [6:11:19<18:51:56,  8.25s/it] 21%|██        | 2168/10395 [6:11:26<18:14:37,  7.98s/it]                                                         {'loss': 1.0046, 'learning_rate': 1.837404082438905e-05, 'epoch': 0.21}
 21%|██        | 2168/10395 [6:11:26<18:14:37,  7.98s/it] 21%|██        | 2169/10395 [6:11:33<17:42:36,  7.75s/it]                                                         {'loss': 1.0193, 'learning_rate': 1.8372337407696858e-05, 'epoch': 0.21}
 21%|██        | 2169/10395 [6:11:33<17:42:36,  7.75s/it] 21%|██        | 2170/10395 [6:11:50<23:47:53, 10.42s/it]                                                         {'loss': 0.3576, 'learning_rate': 1.8370633178236037e-05, 'epoch': 0.21}
 21%|██        | 2170/10395 [6:11:50<23:47:53, 10.42s/it] 21%|██        | 2171/10395 [6:11:58<22:16:17,  9.75s/it]                                                         {'loss': 1.0228, 'learning_rate': 1.836892813617204e-05, 'epoch': 0.21}
 21%|██        | 2171/10395 [6:11:58<22:16:17,  9.75s/it] 21%|██        | 2172/10395 [6:12:06<21:03:44,  9.22s/it]                                                         {'loss': 0.9214, 'learning_rate': 1.8367222281670384e-05, 'epoch': 0.21}
 21%|██        | 2172/10395 [6:12:06<21:03:44,  9.22s/it] 21%|██        | 2173/10395 [6:12:14<20:02:57,  8.78s/it]                                                         {'loss': 0.9745, 'learning_rate': 1.8365515614896666e-05, 'epoch': 0.21}
 21%|██        | 2173/10395 [6:12:14<20:02:57,  8.78s/it] 21%|██        | 2174/10395 [6:12:22<19:14:36,  8.43s/it]                                                         {'loss': 1.0175, 'learning_rate': 1.836380813601657e-05, 'epoch': 0.21}
 21%|██        | 2174/10395 [6:12:22<19:14:36,  8.43s/it] 21%|██        | 2175/10395 [6:12:36<23:24:47, 10.25s/it]                                                         {'loss': 0.3694, 'learning_rate': 1.8362099845195857e-05, 'epoch': 0.21}
 21%|██        | 2175/10395 [6:12:36<23:24:47, 10.25s/it] 21%|██        | 2176/10395 [6:12:45<22:31:59,  9.87s/it]                                                         {'loss': 0.9222, 'learning_rate': 1.8360390742600362e-05, 'epoch': 0.21}
 21%|██        | 2176/10395 [6:12:45<22:31:59,  9.87s/it] 21%|██        | 2177/10395 [6:12:54<21:53:38,  9.59s/it]                                                         {'loss': 0.9103, 'learning_rate': 1.8358680828395993e-05, 'epoch': 0.21}
 21%|██        | 2177/10395 [6:12:54<21:53:38,  9.59s/it] 21%|██        | 2178/10395 [6:13:03<21:11:19,  9.28s/it]                                                         {'loss': 0.9556, 'learning_rate': 1.8356970102748758e-05, 'epoch': 0.21}
 21%|██        | 2178/10395 [6:13:03<21:11:19,  9.28s/it] 21%|██        | 2179/10395 [6:13:11<20:15:55,  8.88s/it]                                                         {'loss': 0.9541, 'learning_rate': 1.835525856582472e-05, 'epoch': 0.21}
 21%|██        | 2179/10395 [6:13:11<20:15:55,  8.88s/it] 21%|██        | 2180/10395 [6:13:28<25:55:19, 11.36s/it]                                                         {'loss': 0.4266, 'learning_rate': 1.835354621779004e-05, 'epoch': 0.21}
 21%|██        | 2180/10395 [6:13:28<25:55:19, 11.36s/it] 21%|██        | 2181/10395 [6:13:36<23:40:45, 10.38s/it]                                                         {'loss': 0.9584, 'learning_rate': 1.835183305881094e-05, 'epoch': 0.21}
 21%|██        | 2181/10395 [6:13:36<23:40:45, 10.38s/it] 21%|██        | 2182/10395 [6:13:43<21:44:48,  9.53s/it]                                                         {'loss': 0.9409, 'learning_rate': 1.8350119089053738e-05, 'epoch': 0.21}
 21%|██        | 2182/10395 [6:13:43<21:44:48,  9.53s/it] 21%|██        | 2183/10395 [6:13:52<21:01:38,  9.22s/it]                                                         {'loss': 0.8855, 'learning_rate': 1.8348404308684816e-05, 'epoch': 0.21}
 21%|██        | 2183/10395 [6:13:52<21:01:38,  9.22s/it] 21%|██        | 2184/10395 [6:14:00<20:04:45,  8.80s/it]                                                         {'loss': 1.0088, 'learning_rate': 1.834668871787065e-05, 'epoch': 0.21}
 21%|██        | 2184/10395 [6:14:00<20:04:45,  8.80s/it] 21%|██        | 2185/10395 [6:14:09<20:30:08,  8.99s/it]                                                         {'loss': 0.9166, 'learning_rate': 1.8344972316777774e-05, 'epoch': 0.21}
 21%|██        | 2185/10395 [6:14:09<20:30:08,  8.99s/it] 21%|██        | 2186/10395 [6:14:17<19:35:23,  8.59s/it]                                                         {'loss': 0.9836, 'learning_rate': 1.8343255105572822e-05, 'epoch': 0.21}
 21%|██        | 2186/10395 [6:14:17<19:35:23,  8.59s/it] 21%|██        | 2187/10395 [6:14:24<18:49:52,  8.26s/it]                                                         {'loss': 0.9041, 'learning_rate': 1.8341537084422495e-05, 'epoch': 0.21}
 21%|██        | 2187/10395 [6:14:24<18:49:52,  8.26s/it] 21%|██        | 2188/10395 [6:14:33<19:09:26,  8.40s/it]                                                         {'loss': 0.9225, 'learning_rate': 1.8339818253493572e-05, 'epoch': 0.21}
 21%|██        | 2188/10395 [6:14:33<19:09:26,  8.40s/it] 21%|██        | 2189/10395 [6:14:41<18:57:16,  8.32s/it]                                                         {'loss': 0.9896, 'learning_rate': 1.8338098612952913e-05, 'epoch': 0.21}
 21%|██        | 2189/10395 [6:14:41<18:57:16,  8.32s/it] 21%|██        | 2190/10395 [6:14:49<18:31:30,  8.13s/it]                                                         {'loss': 1.0407, 'learning_rate': 1.8336378162967465e-05, 'epoch': 0.21}
 21%|██        | 2190/10395 [6:14:49<18:31:30,  8.13s/it] 21%|██        | 2191/10395 [6:15:06<24:45:15, 10.86s/it]                                                         {'loss': 0.3647, 'learning_rate': 1.8334656903704234e-05, 'epoch': 0.21}
 21%|██        | 2191/10395 [6:15:06<24:45:15, 10.86s/it] 21%|██        | 2192/10395 [6:15:13<22:24:25,  9.83s/it]                                                         {'loss': 1.0574, 'learning_rate': 1.8332934835330325e-05, 'epoch': 0.21}
 21%|██        | 2192/10395 [6:15:13<22:24:25,  9.83s/it] 21%|██        | 2193/10395 [6:15:22<21:46:06,  9.55s/it]                                                         {'loss': 0.9458, 'learning_rate': 1.833121195801291e-05, 'epoch': 0.21}
 21%|██        | 2193/10395 [6:15:22<21:46:06,  9.55s/it] 21%|██        | 2194/10395 [6:15:30<20:21:55,  8.94s/it]                                                         {'loss': 0.9317, 'learning_rate': 1.832948827191924e-05, 'epoch': 0.21}
 21%|██        | 2194/10395 [6:15:30<20:21:55,  8.94s/it] 21%|██        | 2195/10395 [6:15:38<19:38:02,  8.62s/it]                                                         {'loss': 0.9951, 'learning_rate': 1.8327763777216653e-05, 'epoch': 0.21}
 21%|██        | 2195/10395 [6:15:38<19:38:02,  8.62s/it] 21%|██        | 2196/10395 [6:15:48<20:38:40,  9.06s/it]                                                         {'loss': 0.8663, 'learning_rate': 1.832603847407255e-05, 'epoch': 0.21}
 21%|██        | 2196/10395 [6:15:48<20:38:40,  9.06s/it] 21%|██        | 2197/10395 [6:15:55<19:34:58,  8.60s/it]                                                         {'loss': 0.958, 'learning_rate': 1.8324312362654425e-05, 'epoch': 0.21}
 21%|██        | 2197/10395 [6:15:55<19:34:58,  8.60s/it] 21%|██        | 2198/10395 [6:16:03<18:44:49,  8.23s/it]                                                         {'loss': 0.9846, 'learning_rate': 1.832258544312985e-05, 'epoch': 0.21}
 21%|██        | 2198/10395 [6:16:03<18:44:49,  8.23s/it] 21%|██        | 2199/10395 [6:16:11<18:46:46,  8.25s/it]                                                         {'loss': 0.8898, 'learning_rate': 1.832085771566646e-05, 'epoch': 0.21}
 21%|██        | 2199/10395 [6:16:11<18:46:46,  8.25s/it] 21%|██        | 2200/10395 [6:16:19<18:14:58,  8.02s/it]                                                         {'loss': 1.0381, 'learning_rate': 1.831912918043199e-05, 'epoch': 0.21}
 21%|██        | 2200/10395 [6:16:19<18:14:58,  8.02s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 21%|██        | 2201/10395 [6:17:57<79:55:54, 35.12s/it]                                                         {'loss': 0.9345, 'learning_rate': 1.831739983759423e-05, 'epoch': 0.21}
 21%|██        | 2201/10395 [6:17:57<79:55:54, 35.12s/it] 21%|██        | 2202/10395 [6:18:15<68:05:55, 29.92s/it]                                                         {'loss': 0.4009, 'learning_rate': 1.831566968732107e-05, 'epoch': 0.21}
 21%|██        | 2202/10395 [6:18:15<68:05:55, 29.92s/it] 21%|██        | 2203/10395 [6:18:24<53:42:02, 23.60s/it]                                                         {'loss': 0.9294, 'learning_rate': 1.8313938729780472e-05, 'epoch': 0.21}
 21%|██        | 2203/10395 [6:18:24<53:42:02, 23.60s/it] 21%|██        | 2204/10395 [6:18:42<49:59:28, 21.97s/it]                                                         {'loss': 0.3452, 'learning_rate': 1.8312206965140467e-05, 'epoch': 0.21}
 21%|██        | 2204/10395 [6:18:42<49:59:28, 21.97s/it] 21%|██        | 2205/10395 [6:18:50<40:35:34, 17.84s/it]                                                         {'loss': 0.9991, 'learning_rate': 1.8310474393569172e-05, 'epoch': 0.21}
 21%|██        | 2205/10395 [6:18:50<40:35:34, 17.84s/it] 21%|██        | 2206/10395 [6:18:57<33:28:09, 14.71s/it]                                                         {'loss': 0.898, 'learning_rate': 1.8308741015234784e-05, 'epoch': 0.21}
 21%|██        | 2206/10395 [6:18:57<33:28:09, 14.71s/it] 21%|██        | 2207/10395 [6:19:06<29:10:22, 12.83s/it]                                                         {'loss': 0.9154, 'learning_rate': 1.8307006830305574e-05, 'epoch': 0.21}
 21%|██        | 2207/10395 [6:19:06<29:10:22, 12.83s/it] 21%|██        | 2208/10395 [6:19:13<25:40:55, 11.29s/it]                                                         {'loss': 0.9819, 'learning_rate': 1.830527183894989e-05, 'epoch': 0.21}
 21%|██        | 2208/10395 [6:19:13<25:40:55, 11.29s/it] 21%|██▏       | 2209/10395 [6:19:21<23:14:11, 10.22s/it]                                                         {'loss': 0.9236, 'learning_rate': 1.8303536041336167e-05, 'epoch': 0.21}
 21%|██▏       | 2209/10395 [6:19:21<23:14:11, 10.22s/it] 21%|██▏       | 2210/10395 [6:19:29<21:28:08,  9.44s/it]                                                         {'loss': 0.9206, 'learning_rate': 1.830179943763291e-05, 'epoch': 0.21}
 21%|██▏       | 2210/10395 [6:19:29<21:28:08,  9.44s/it] 21%|██▏       | 2211/10395 [6:19:36<20:09:22,  8.87s/it]                                                         {'loss': 0.9988, 'learning_rate': 1.8300062028008704e-05, 'epoch': 0.21}
 21%|██▏       | 2211/10395 [6:19:36<20:09:22,  8.87s/it] 21%|██▏       | 2212/10395 [6:19:44<19:18:26,  8.49s/it]                                                         {'loss': 0.9821, 'learning_rate': 1.8298323812632212e-05, 'epoch': 0.21}
 21%|██▏       | 2212/10395 [6:19:44<19:18:26,  8.49s/it] 21%|██▏       | 2213/10395 [6:19:51<18:36:52,  8.19s/it]                                                         {'loss': 0.9174, 'learning_rate': 1.829658479167218e-05, 'epoch': 0.21}
 21%|██▏       | 2213/10395 [6:19:51<18:36:52,  8.19s/it] 21%|██▏       | 2214/10395 [6:19:59<18:03:47,  7.95s/it]                                                         {'loss': 0.952, 'learning_rate': 1.8294844965297426e-05, 'epoch': 0.21}
 21%|██▏       | 2214/10395 [6:19:59<18:03:47,  7.95s/it] 21%|██▏       | 2215/10395 [6:20:06<17:38:50,  7.77s/it]                                                         {'loss': 1.0109, 'learning_rate': 1.829310433367685e-05, 'epoch': 0.21}
 21%|██▏       | 2215/10395 [6:20:06<17:38:50,  7.77s/it] 21%|██▏       | 2216/10395 [6:20:13<17:19:46,  7.63s/it]                                                         {'loss': 0.893, 'learning_rate': 1.829136289697943e-05, 'epoch': 0.21}
 21%|██▏       | 2216/10395 [6:20:13<17:19:46,  7.63s/it] 21%|██▏       | 2217/10395 [6:20:21<17:10:08,  7.56s/it]                                                         {'loss': 0.9686, 'learning_rate': 1.8289620655374213e-05, 'epoch': 0.21}
 21%|██▏       | 2217/10395 [6:20:21<17:10:08,  7.56s/it] 21%|██▏       | 2218/10395 [6:20:29<17:15:55,  7.60s/it]                                                         {'loss': 0.9996, 'learning_rate': 1.828787760903034e-05, 'epoch': 0.21}
 21%|██▏       | 2218/10395 [6:20:29<17:15:55,  7.60s/it] 21%|██▏       | 2219/10395 [6:20:36<17:06:47,  7.54s/it]                                                         {'loss': 1.0041, 'learning_rate': 1.8286133758117017e-05, 'epoch': 0.21}
 21%|██▏       | 2219/10395 [6:20:36<17:06:47,  7.54s/it] 21%|██▏       | 2220/10395 [6:20:43<17:02:43,  7.51s/it]                                                         {'loss': 1.0884, 'learning_rate': 1.8284389102803542e-05, 'epoch': 0.21}
 21%|██▏       | 2220/10395 [6:20:43<17:02:43,  7.51s/it] 21%|██▏       | 2221/10395 [6:20:51<17:17:19,  7.61s/it]                                                         {'loss': 0.9678, 'learning_rate': 1.828264364325927e-05, 'epoch': 0.21}
 21%|██▏       | 2221/10395 [6:20:51<17:17:19,  7.61s/it] 21%|██▏       | 2222/10395 [6:20:59<17:39:45,  7.78s/it]                                                         {'loss': 0.9083, 'learning_rate': 1.8280897379653657e-05, 'epoch': 0.21}
 21%|██▏       | 2222/10395 [6:20:59<17:39:45,  7.78s/it] 21%|██▏       | 2223/10395 [6:21:07<17:23:24,  7.66s/it]                                                         {'loss': 0.9537, 'learning_rate': 1.8279150312156225e-05, 'epoch': 0.21}
 21%|██▏       | 2223/10395 [6:21:07<17:23:24,  7.66s/it] 21%|██▏       | 2224/10395 [6:21:15<17:37:51,  7.77s/it]                                                         {'loss': 0.9819, 'learning_rate': 1.8277402440936568e-05, 'epoch': 0.21}
 21%|██▏       | 2224/10395 [6:21:15<17:37:51,  7.77s/it] 21%|██▏       | 2225/10395 [6:21:24<18:15:52,  8.05s/it]                                                         {'loss': 0.9619, 'learning_rate': 1.8275653766164377e-05, 'epoch': 0.21}
 21%|██▏       | 2225/10395 [6:21:24<18:15:52,  8.05s/it] 21%|██▏       | 2226/10395 [6:21:31<17:45:21,  7.82s/it]                                                         {'loss': 0.9837, 'learning_rate': 1.8273904288009402e-05, 'epoch': 0.21}
 21%|██▏       | 2226/10395 [6:21:31<17:45:21,  7.82s/it] 21%|██▏       | 2227/10395 [6:21:39<17:50:15,  7.86s/it]                                                         {'loss': 1.0143, 'learning_rate': 1.8272154006641475e-05, 'epoch': 0.21}
 21%|██▏       | 2227/10395 [6:21:39<17:50:15,  7.86s/it] 21%|██▏       | 2228/10395 [6:21:56<24:04:06, 10.61s/it]                                                         {'loss': 0.3572, 'learning_rate': 1.827040292223052e-05, 'epoch': 0.21}
 21%|██▏       | 2228/10395 [6:21:56<24:04:06, 10.61s/it] 21%|██▏       | 2229/10395 [6:22:04<22:30:53,  9.93s/it]                                                         {'loss': 0.9066, 'learning_rate': 1.8268651034946522e-05, 'epoch': 0.21}
 21%|██▏       | 2229/10395 [6:22:04<22:30:53,  9.93s/it] 21%|██▏       | 2230/10395 [6:22:12<21:19:33,  9.40s/it]                                                         {'loss': 0.9146, 'learning_rate': 1.826689834495955e-05, 'epoch': 0.21}
 21%|██▏       | 2230/10395 [6:22:12<21:19:33,  9.40s/it] 21%|██▏       | 2231/10395 [6:22:20<19:58:27,  8.81s/it]                                                         {'loss': 1.0027, 'learning_rate': 1.8265144852439754e-05, 'epoch': 0.21}
 21%|██▏       | 2231/10395 [6:22:20<19:58:27,  8.81s/it] 21%|██▏       | 2232/10395 [6:22:27<19:11:21,  8.46s/it]                                                         {'loss': 0.97, 'learning_rate': 1.8263390557557355e-05, 'epoch': 0.21}
 21%|██▏       | 2232/10395 [6:22:27<19:11:21,  8.46s/it] 21%|██▏       | 2233/10395 [6:22:35<18:33:27,  8.19s/it]                                                         {'loss': 1.0365, 'learning_rate': 1.8261635460482666e-05, 'epoch': 0.21}
 21%|██▏       | 2233/10395 [6:22:35<18:33:27,  8.19s/it] 21%|██▏       | 2234/10395 [6:22:42<17:38:27,  7.78s/it]                                                         {'loss': 1.0483, 'learning_rate': 1.8259879561386058e-05, 'epoch': 0.21}
 21%|██▏       | 2234/10395 [6:22:42<17:38:27,  7.78s/it] 22%|██▏       | 2235/10395 [6:22:49<17:29:20,  7.72s/it]                                                         {'loss': 1.0257, 'learning_rate': 1.8258122860437993e-05, 'epoch': 0.21}
 22%|██▏       | 2235/10395 [6:22:49<17:29:20,  7.72s/it] 22%|██▏       | 2236/10395 [6:22:57<17:34:21,  7.75s/it]                                                         {'loss': 1.0015, 'learning_rate': 1.8256365357809015e-05, 'epoch': 0.22}
 22%|██▏       | 2236/10395 [6:22:57<17:34:21,  7.75s/it] 22%|██▏       | 2237/10395 [6:23:05<17:34:50,  7.76s/it]                                                         {'loss': 0.9523, 'learning_rate': 1.8254607053669728e-05, 'epoch': 0.22}
 22%|██▏       | 2237/10395 [6:23:05<17:34:50,  7.76s/it] 22%|██▏       | 2238/10395 [6:23:13<17:30:07,  7.72s/it]                                                         {'loss': 0.9788, 'learning_rate': 1.825284794819082e-05, 'epoch': 0.22}
 22%|██▏       | 2238/10395 [6:23:13<17:30:07,  7.72s/it] 22%|██▏       | 2239/10395 [6:23:20<17:10:34,  7.58s/it]                                                         {'loss': 0.9657, 'learning_rate': 1.825108804154308e-05, 'epoch': 0.22}
 22%|██▏       | 2239/10395 [6:23:20<17:10:34,  7.58s/it] 22%|██▏       | 2240/10395 [6:23:27<17:03:03,  7.53s/it]                                                         {'loss': 0.9968, 'learning_rate': 1.824932733389734e-05, 'epoch': 0.22}
 22%|██▏       | 2240/10395 [6:23:27<17:03:03,  7.53s/it] 22%|██▏       | 2241/10395 [6:23:35<16:55:12,  7.47s/it]                                                         {'loss': 0.9583, 'learning_rate': 1.824756582542454e-05, 'epoch': 0.22}
 22%|██▏       | 2241/10395 [6:23:35<16:55:12,  7.47s/it] 22%|██▏       | 2242/10395 [6:23:42<16:53:24,  7.46s/it]                                                         {'loss': 0.9719, 'learning_rate': 1.8245803516295667e-05, 'epoch': 0.22}
 22%|██▏       | 2242/10395 [6:23:42<16:53:24,  7.46s/it] 22%|██▏       | 2243/10395 [6:23:50<17:15:47,  7.62s/it]                                                         {'loss': 0.9755, 'learning_rate': 1.824404040668181e-05, 'epoch': 0.22}
 22%|██▏       | 2243/10395 [6:23:50<17:15:47,  7.62s/it] 22%|██▏       | 2244/10395 [6:23:58<17:22:32,  7.67s/it]                                                         {'loss': 0.9092, 'learning_rate': 1.8242276496754128e-05, 'epoch': 0.22}
 22%|██▏       | 2244/10395 [6:23:58<17:22:32,  7.67s/it] 22%|██▏       | 2245/10395 [6:24:05<17:24:19,  7.69s/it]                                                         {'loss': 0.9906, 'learning_rate': 1.8240511786683858e-05, 'epoch': 0.22}
 22%|██▏       | 2245/10395 [6:24:05<17:24:19,  7.69s/it] 22%|██▏       | 2246/10395 [6:24:13<17:10:33,  7.59s/it]                                                         {'loss': 1.0109, 'learning_rate': 1.8238746276642317e-05, 'epoch': 0.22}
 22%|██▏       | 2246/10395 [6:24:13<17:10:33,  7.59s/it] 22%|██▏       | 2247/10395 [6:24:20<17:08:37,  7.57s/it]                                                         {'loss': 0.9679, 'learning_rate': 1.823697996680089e-05, 'epoch': 0.22}
 22%|██▏       | 2247/10395 [6:24:20<17:08:37,  7.57s/it] 22%|██▏       | 2248/10395 [6:24:28<17:12:27,  7.60s/it]                                                         {'loss': 0.9794, 'learning_rate': 1.8235212857331053e-05, 'epoch': 0.22}
 22%|██▏       | 2248/10395 [6:24:28<17:12:27,  7.60s/it] 22%|██▏       | 2249/10395 [6:24:36<17:39:42,  7.81s/it]                                                         {'loss': 1.0525, 'learning_rate': 1.8233444948404347e-05, 'epoch': 0.22}
 22%|██▏       | 2249/10395 [6:24:36<17:39:42,  7.81s/it] 22%|██▏       | 2250/10395 [6:24:44<17:29:22,  7.73s/it]                                                         {'loss': 0.893, 'learning_rate': 1.8231676240192402e-05, 'epoch': 0.22}
 22%|██▏       | 2250/10395 [6:24:44<17:29:22,  7.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 2251/10395 [6:26:24<80:00:01, 35.36s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.822990673286692e-05, 'epoch': 0.22}
 22%|██▏       | 2251/10395 [6:26:24<80:00:01, 35.36s/it] 22%|██▏       | 2252/10395 [6:26:31<61:11:12, 27.05s/it]                                                         {'loss': 1.0395, 'learning_rate': 1.822813642659968e-05, 'epoch': 0.22}
 22%|██▏       | 2252/10395 [6:26:31<61:11:12, 27.05s/it] 22%|██▏       | 2253/10395 [6:26:48<53:57:29, 23.86s/it]                                                         {'loss': 0.3659, 'learning_rate': 1.8226365321562536e-05, 'epoch': 0.22}
 22%|██▏       | 2253/10395 [6:26:48<53:57:29, 23.86s/it] 22%|██▏       | 2254/10395 [6:26:55<42:54:59, 18.98s/it]                                                         {'loss': 1.0265, 'learning_rate': 1.822459341792743e-05, 'epoch': 0.22}
 22%|██▏       | 2254/10395 [6:26:55<42:54:59, 18.98s/it] 22%|██▏       | 2255/10395 [6:27:03<35:01:06, 15.49s/it]                                                         {'loss': 0.8875, 'learning_rate': 1.822282071586637e-05, 'epoch': 0.22}
 22%|██▏       | 2255/10395 [6:27:03<35:01:06, 15.49s/it] 22%|██▏       | 2256/10395 [6:27:10<29:38:55, 13.11s/it]                                                         {'loss': 0.9347, 'learning_rate': 1.8221047215551446e-05, 'epoch': 0.22}
 22%|██▏       | 2256/10395 [6:27:10<29:38:55, 13.11s/it] 22%|██▏       | 2257/10395 [6:27:19<26:19:19, 11.64s/it]                                                         {'loss': 0.9546, 'learning_rate': 1.8219272917154828e-05, 'epoch': 0.22}
 22%|██▏       | 2257/10395 [6:27:19<26:19:19, 11.64s/it] 22%|██▏       | 2258/10395 [6:27:26<23:25:50, 10.37s/it]                                                         {'loss': 0.9791, 'learning_rate': 1.8217497820848758e-05, 'epoch': 0.22}
 22%|██▏       | 2258/10395 [6:27:26<23:25:50, 10.37s/it] 22%|██▏       | 2259/10395 [6:27:43<28:03:30, 12.42s/it]                                                         {'loss': 0.3514, 'learning_rate': 1.821572192680556e-05, 'epoch': 0.22}
 22%|██▏       | 2259/10395 [6:27:43<28:03:30, 12.42s/it] 22%|██▏       | 2260/10395 [6:27:51<24:48:32, 10.98s/it]                                                         {'loss': 1.0607, 'learning_rate': 1.821394523519764e-05, 'epoch': 0.22}
 22%|██▏       | 2260/10395 [6:27:51<24:48:32, 10.98s/it] 22%|██▏       | 2261/10395 [6:27:59<22:40:13, 10.03s/it]                                                         {'loss': 0.9818, 'learning_rate': 1.8212167746197464e-05, 'epoch': 0.22}
 22%|██▏       | 2261/10395 [6:27:59<22:40:13, 10.03s/it] 22%|██▏       | 2262/10395 [6:28:06<20:56:19,  9.27s/it]                                                         {'loss': 0.9706, 'learning_rate': 1.8210389459977594e-05, 'epoch': 0.22}
 22%|██▏       | 2262/10395 [6:28:06<20:56:19,  9.27s/it] 22%|██▏       | 2263/10395 [6:28:14<20:17:14,  8.98s/it]                                                         {'loss': 0.9503, 'learning_rate': 1.8208610376710664e-05, 'epoch': 0.22}
 22%|██▏       | 2263/10395 [6:28:14<20:17:14,  8.98s/it] 22%|██▏       | 2264/10395 [6:28:22<19:07:34,  8.47s/it]                                                         {'loss': 0.8981, 'learning_rate': 1.8206830496569378e-05, 'epoch': 0.22}
 22%|██▏       | 2264/10395 [6:28:22<19:07:34,  8.47s/it] 22%|██▏       | 2265/10395 [6:28:30<18:56:08,  8.38s/it]                                                         {'loss': 0.93, 'learning_rate': 1.8205049819726523e-05, 'epoch': 0.22}
 22%|██▏       | 2265/10395 [6:28:30<18:56:08,  8.38s/it] 22%|██▏       | 2266/10395 [6:28:38<18:29:42,  8.19s/it]                                                         {'loss': 0.9875, 'learning_rate': 1.820326834635497e-05, 'epoch': 0.22}
 22%|██▏       | 2266/10395 [6:28:38<18:29:42,  8.19s/it] 22%|██▏       | 2267/10395 [6:28:45<17:56:16,  7.94s/it]                                                         {'loss': 1.067, 'learning_rate': 1.8201486076627656e-05, 'epoch': 0.22}
 22%|██▏       | 2267/10395 [6:28:45<17:56:16,  7.94s/it] 22%|██▏       | 2268/10395 [6:28:54<18:49:06,  8.34s/it]                                                         {'loss': 0.8937, 'learning_rate': 1.81997030107176e-05, 'epoch': 0.22}
 22%|██▏       | 2268/10395 [6:28:54<18:49:06,  8.34s/it] 22%|██▏       | 2269/10395 [6:29:12<25:04:19, 11.11s/it]                                                         {'loss': 0.3667, 'learning_rate': 1.8197919148797894e-05, 'epoch': 0.22}
 22%|██▏       | 2269/10395 [6:29:12<25:04:19, 11.11s/it] 22%|██▏       | 2270/10395 [6:29:19<22:43:06, 10.07s/it]                                                         {'loss': 0.8656, 'learning_rate': 1.8196134491041723e-05, 'epoch': 0.22}
 22%|██▏       | 2270/10395 [6:29:19<22:43:06, 10.07s/it] 22%|██▏       | 2271/10395 [6:29:29<22:08:45,  9.81s/it]                                                         {'loss': 0.9951, 'learning_rate': 1.8194349037622324e-05, 'epoch': 0.22}
 22%|██▏       | 2271/10395 [6:29:29<22:08:45,  9.81s/it] 22%|██▏       | 2272/10395 [6:29:37<20:55:07,  9.27s/it]                                                         {'loss': 1.0107, 'learning_rate': 1.8192562788713037e-05, 'epoch': 0.22}
 22%|██▏       | 2272/10395 [6:29:37<20:55:07,  9.27s/it] 22%|██▏       | 2273/10395 [6:29:44<19:45:35,  8.76s/it]                                                         {'loss': 1.0774, 'learning_rate': 1.819077574448726e-05, 'epoch': 0.22}
 22%|██▏       | 2273/10395 [6:29:44<19:45:35,  8.76s/it] 22%|██▏       | 2274/10395 [6:29:53<19:42:01,  8.73s/it]                                                         {'loss': 0.8908, 'learning_rate': 1.8188987905118475e-05, 'epoch': 0.22}
 22%|██▏       | 2274/10395 [6:29:53<19:42:01,  8.73s/it] 22%|██▏       | 2275/10395 [6:30:00<18:38:16,  8.26s/it]                                                         {'loss': 0.9738, 'learning_rate': 1.818719927078025e-05, 'epoch': 0.22}
 22%|██▏       | 2275/10395 [6:30:00<18:38:16,  8.26s/it] 22%|██▏       | 2276/10395 [6:30:17<24:18:46, 10.78s/it]                                                         {'loss': 0.3867, 'learning_rate': 1.8185409841646212e-05, 'epoch': 0.22}
 22%|██▏       | 2276/10395 [6:30:17<24:18:46, 10.78s/it] 22%|██▏       | 2277/10395 [6:30:24<22:11:01,  9.84s/it]                                                         {'loss': 0.9672, 'learning_rate': 1.818361961789008e-05, 'epoch': 0.22}
 22%|██▏       | 2277/10395 [6:30:24<22:11:01,  9.84s/it] 22%|██▏       | 2278/10395 [6:30:32<20:49:44,  9.24s/it]                                                         {'loss': 0.9891, 'learning_rate': 1.818182859968564e-05, 'epoch': 0.22}
 22%|██▏       | 2278/10395 [6:30:32<20:49:44,  9.24s/it] 22%|██▏       | 2279/10395 [6:30:40<19:44:22,  8.76s/it]                                                         {'loss': 0.9933, 'learning_rate': 1.818003678720677e-05, 'epoch': 0.22}
 22%|██▏       | 2279/10395 [6:30:40<19:44:22,  8.76s/it] 22%|██▏       | 2280/10395 [6:30:56<25:02:16, 11.11s/it]                                                         {'loss': 0.3817, 'learning_rate': 1.8178244180627406e-05, 'epoch': 0.22}
 22%|██▏       | 2280/10395 [6:30:56<25:02:16, 11.11s/it] 22%|██▏       | 2281/10395 [6:31:04<23:00:44, 10.21s/it]                                                         {'loss': 0.8526, 'learning_rate': 1.8176450780121574e-05, 'epoch': 0.22}
 22%|██▏       | 2281/10395 [6:31:04<23:00:44, 10.21s/it] 22%|██▏       | 2282/10395 [6:31:12<21:12:00,  9.41s/it]                                                         {'loss': 1.023, 'learning_rate': 1.8174656585863376e-05, 'epoch': 0.22}
 22%|██▏       | 2282/10395 [6:31:12<21:12:00,  9.41s/it] 22%|██▏       | 2283/10395 [6:31:20<20:03:24,  8.90s/it]                                                         {'loss': 1.0527, 'learning_rate': 1.8172861598026986e-05, 'epoch': 0.22}
 22%|██▏       | 2283/10395 [6:31:20<20:03:24,  8.90s/it] 22%|██▏       | 2284/10395 [6:31:28<19:23:03,  8.60s/it]                                                         {'loss': 1.0141, 'learning_rate': 1.817106581678665e-05, 'epoch': 0.22}
 22%|██▏       | 2284/10395 [6:31:28<19:23:03,  8.60s/it] 22%|██▏       | 2285/10395 [6:31:35<18:46:16,  8.33s/it]                                                         {'loss': 1.0925, 'learning_rate': 1.816926924231672e-05, 'epoch': 0.22}
 22%|██▏       | 2285/10395 [6:31:35<18:46:16,  8.33s/it] 22%|██▏       | 2286/10395 [6:31:44<18:43:26,  8.31s/it]                                                         {'loss': 0.955, 'learning_rate': 1.8167471874791578e-05, 'epoch': 0.22}
 22%|██▏       | 2286/10395 [6:31:44<18:43:26,  8.31s/it] 22%|██▏       | 2287/10395 [6:31:52<18:42:41,  8.31s/it]                                                         {'loss': 1.0426, 'learning_rate': 1.8165673714385725e-05, 'epoch': 0.22}
 22%|██▏       | 2287/10395 [6:31:52<18:42:41,  8.31s/it] 22%|██▏       | 2288/10395 [6:32:00<18:46:31,  8.34s/it]                                                         {'loss': 0.946, 'learning_rate': 1.8163874761273717e-05, 'epoch': 0.22}
 22%|██▏       | 2288/10395 [6:32:00<18:46:31,  8.34s/it] 22%|██▏       | 2289/10395 [6:32:09<19:01:06,  8.45s/it]                                                         {'loss': 0.9536, 'learning_rate': 1.8162075015630192e-05, 'epoch': 0.22}
 22%|██▏       | 2289/10395 [6:32:09<19:01:06,  8.45s/it] 22%|██▏       | 2290/10395 [6:32:17<18:50:31,  8.37s/it]                                                         {'loss': 0.9213, 'learning_rate': 1.816027447762987e-05, 'epoch': 0.22}
 22%|██▏       | 2290/10395 [6:32:17<18:50:31,  8.37s/it] 22%|██▏       | 2291/10395 [6:32:25<18:20:43,  8.15s/it]                                                         {'loss': 0.9748, 'learning_rate': 1.8158473147447537e-05, 'epoch': 0.22}
 22%|██▏       | 2291/10395 [6:32:25<18:20:43,  8.15s/it] 22%|██▏       | 2292/10395 [6:32:32<17:38:56,  7.84s/it]                                                         {'loss': 1.0648, 'learning_rate': 1.8156671025258068e-05, 'epoch': 0.22}
 22%|██▏       | 2292/10395 [6:32:33<17:38:56,  7.84s/it] 22%|██▏       | 2293/10395 [6:32:40<17:40:29,  7.85s/it]                                                         {'loss': 0.9748, 'learning_rate': 1.8154868111236406e-05, 'epoch': 0.22}
 22%|██▏       | 2293/10395 [6:32:40<17:40:29,  7.85s/it] 22%|██▏       | 2294/10395 [6:32:48<17:44:28,  7.88s/it]                                                         {'loss': 0.9219, 'learning_rate': 1.8153064405557575e-05, 'epoch': 0.22}
 22%|██▏       | 2294/10395 [6:32:48<17:44:28,  7.88s/it] 22%|██▏       | 2295/10395 [6:32:55<17:30:56,  7.78s/it]                                                         {'loss': 1.0002, 'learning_rate': 1.8151259908396674e-05, 'epoch': 0.22}
 22%|██▏       | 2295/10395 [6:32:55<17:30:56,  7.78s/it] 22%|██▏       | 2296/10395 [6:33:03<17:20:04,  7.71s/it]                                                         {'loss': 0.8944, 'learning_rate': 1.814945461992888e-05, 'epoch': 0.22}
 22%|██▏       | 2296/10395 [6:33:03<17:20:04,  7.71s/it] 22%|██▏       | 2297/10395 [6:33:11<17:18:19,  7.69s/it]                                                         {'loss': 1.0061, 'learning_rate': 1.814764854032945e-05, 'epoch': 0.22}
 22%|██▏       | 2297/10395 [6:33:11<17:18:19,  7.69s/it] 22%|██▏       | 2298/10395 [6:33:19<17:31:58,  7.80s/it]                                                         {'loss': 0.9126, 'learning_rate': 1.8145841669773706e-05, 'epoch': 0.22}
 22%|██▏       | 2298/10395 [6:33:19<17:31:58,  7.80s/it] 22%|██▏       | 2299/10395 [6:33:27<17:43:45,  7.88s/it]                                                         {'loss': 0.9535, 'learning_rate': 1.8144034008437062e-05, 'epoch': 0.22}
 22%|██▏       | 2299/10395 [6:33:27<17:43:45,  7.88s/it] 22%|██▏       | 2300/10395 [6:33:34<17:39:23,  7.85s/it]                                                         {'loss': 1.0098, 'learning_rate': 1.8142225556495004e-05, 'epoch': 0.22}
 22%|██▏       | 2300/10395 [6:33:34<17:39:23,  7.85s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 2301/10395 [6:35:17<81:19:20, 36.17s/it]                                                         {'loss': 0.9504, 'learning_rate': 1.8140416314123087e-05, 'epoch': 0.22}
 22%|██▏       | 2301/10395 [6:35:17<81:19:20, 36.17s/it] 22%|██▏       | 2302/10395 [6:35:34<68:36:31, 30.52s/it]                                                         {'loss': 0.3984, 'learning_rate': 1.8138606281496952e-05, 'epoch': 0.22}
 22%|██▏       | 2302/10395 [6:35:34<68:36:31, 30.52s/it] 22%|██▏       | 2303/10395 [6:35:41<52:52:31, 23.52s/it]                                                         {'loss': 1.0927, 'learning_rate': 1.8136795458792308e-05, 'epoch': 0.22}
 22%|██▏       | 2303/10395 [6:35:41<52:52:31, 23.52s/it] 22%|██▏       | 2304/10395 [6:35:49<42:20:49, 18.84s/it]                                                         {'loss': 0.9219, 'learning_rate': 1.813498384618495e-05, 'epoch': 0.22}
 22%|██▏       | 2304/10395 [6:35:49<42:20:49, 18.84s/it] 22%|██▏       | 2305/10395 [6:35:59<36:06:52, 16.07s/it]                                                         {'loss': 0.9361, 'learning_rate': 1.8133171443850745e-05, 'epoch': 0.22}
 22%|██▏       | 2305/10395 [6:35:59<36:06:52, 16.07s/it] 22%|██▏       | 2306/10395 [6:36:07<31:01:04, 13.80s/it]                                                         {'loss': 1.0375, 'learning_rate': 1.813135825196564e-05, 'epoch': 0.22}
 22%|██▏       | 2306/10395 [6:36:07<31:01:04, 13.80s/it] 22%|██▏       | 2307/10395 [6:36:15<26:50:29, 11.95s/it]                                                         {'loss': 0.9153, 'learning_rate': 1.812954427070565e-05, 'epoch': 0.22}
 22%|██▏       | 2307/10395 [6:36:15<26:50:29, 11.95s/it] 22%|██▏       | 2308/10395 [6:36:22<23:52:51, 10.63s/it]                                                         {'loss': 0.9255, 'learning_rate': 1.8127729500246873e-05, 'epoch': 0.22}
 22%|██▏       | 2308/10395 [6:36:22<23:52:51, 10.63s/it] 22%|██▏       | 2309/10395 [6:36:30<21:48:51,  9.71s/it]                                                         {'loss': 0.951, 'learning_rate': 1.812591394076549e-05, 'epoch': 0.22}
 22%|██▏       | 2309/10395 [6:36:30<21:48:51,  9.71s/it] 22%|██▏       | 2310/10395 [6:36:47<26:37:47, 11.86s/it]                                                         {'loss': 0.3607, 'learning_rate': 1.812409759243774e-05, 'epoch': 0.22}
 22%|██▏       | 2310/10395 [6:36:47<26:37:47, 11.86s/it] 22%|██▏       | 2311/10395 [6:36:55<24:07:11, 10.74s/it]                                                         {'loss': 0.9336, 'learning_rate': 1.8122280455439963e-05, 'epoch': 0.22}
 22%|██▏       | 2311/10395 [6:36:55<24:07:11, 10.74s/it] 22%|██▏       | 2312/10395 [6:37:04<22:44:55, 10.13s/it]                                                         {'loss': 0.9121, 'learning_rate': 1.8120462529948555e-05, 'epoch': 0.22}
 22%|██▏       | 2312/10395 [6:37:04<22:44:55, 10.13s/it] 22%|██▏       | 2313/10395 [6:37:11<21:09:38,  9.43s/it]                                                         {'loss': 0.9398, 'learning_rate': 1.8118643816139996e-05, 'epoch': 0.22}
 22%|██▏       | 2313/10395 [6:37:11<21:09:38,  9.43s/it] 22%|██▏       | 2314/10395 [6:37:20<20:18:35,  9.05s/it]                                                         {'loss': 0.9673, 'learning_rate': 1.8116824314190847e-05, 'epoch': 0.22}
 22%|██▏       | 2314/10395 [6:37:20<20:18:35,  9.05s/it] 22%|██▏       | 2315/10395 [6:37:28<19:43:00,  8.78s/it]                                                         {'loss': 0.95, 'learning_rate': 1.811500402427774e-05, 'epoch': 0.22}
 22%|██▏       | 2315/10395 [6:37:28<19:43:00,  8.78s/it] 22%|██▏       | 2316/10395 [6:37:35<18:50:49,  8.40s/it]                                                         {'loss': 0.928, 'learning_rate': 1.8113182946577383e-05, 'epoch': 0.22}
 22%|██▏       | 2316/10395 [6:37:35<18:50:49,  8.40s/it] 22%|██▏       | 2317/10395 [6:37:43<18:07:41,  8.08s/it]                                                         {'loss': 1.0342, 'learning_rate': 1.8111361081266564e-05, 'epoch': 0.22}
 22%|██▏       | 2317/10395 [6:37:43<18:07:41,  8.08s/it] 22%|██▏       | 2318/10395 [6:37:51<18:30:29,  8.25s/it]                                                         {'loss': 0.904, 'learning_rate': 1.8109538428522144e-05, 'epoch': 0.22}
 22%|██▏       | 2318/10395 [6:37:51<18:30:29,  8.25s/it] 22%|██▏       | 2319/10395 [6:37:59<18:06:46,  8.07s/it]                                                         {'loss': 0.9855, 'learning_rate': 1.8107714988521064e-05, 'epoch': 0.22}
 22%|██▏       | 2319/10395 [6:37:59<18:06:46,  8.07s/it] 22%|██▏       | 2320/10395 [6:38:08<18:25:23,  8.21s/it]                                                         {'loss': 1.0012, 'learning_rate': 1.810589076144034e-05, 'epoch': 0.22}
 22%|██▏       | 2320/10395 [6:38:08<18:25:23,  8.21s/it] 22%|██▏       | 2321/10395 [6:38:15<17:51:09,  7.96s/it]                                                         {'loss': 1.0452, 'learning_rate': 1.810406574745706e-05, 'epoch': 0.22}
 22%|██▏       | 2321/10395 [6:38:15<17:51:09,  7.96s/it] 22%|██▏       | 2322/10395 [6:38:23<17:54:14,  7.98s/it]                                                         {'loss': 0.9861, 'learning_rate': 1.81022399467484e-05, 'epoch': 0.22}
 22%|██▏       | 2322/10395 [6:38:23<17:54:14,  7.98s/it] 22%|██▏       | 2323/10395 [6:38:31<17:58:53,  8.02s/it]                                                         {'loss': 0.9518, 'learning_rate': 1.81004133594916e-05, 'epoch': 0.22}
 22%|██▏       | 2323/10395 [6:38:31<17:58:53,  8.02s/it] 22%|██▏       | 2324/10395 [6:38:49<24:43:09, 11.03s/it]                                                         {'loss': 0.3716, 'learning_rate': 1.809858598586398e-05, 'epoch': 0.22}
 22%|██▏       | 2324/10395 [6:38:49<24:43:09, 11.03s/it] 22%|██▏       | 2325/10395 [6:38:57<22:29:07, 10.03s/it]                                                         {'loss': 0.9753, 'learning_rate': 1.8096757826042944e-05, 'epoch': 0.22}
 22%|██▏       | 2325/10395 [6:38:57<22:29:07, 10.03s/it] 22%|██▏       | 2326/10395 [6:39:04<20:52:17,  9.31s/it]                                                         {'loss': 0.9525, 'learning_rate': 1.8094928880205954e-05, 'epoch': 0.22}
 22%|██▏       | 2326/10395 [6:39:04<20:52:17,  9.31s/it] 22%|██▏       | 2327/10395 [6:39:12<19:42:18,  8.79s/it]                                                         {'loss': 0.9026, 'learning_rate': 1.809309914853057e-05, 'epoch': 0.22}
 22%|██▏       | 2327/10395 [6:39:12<19:42:18,  8.79s/it] 22%|██▏       | 2328/10395 [6:39:20<19:28:41,  8.69s/it]                                                         {'loss': 0.9611, 'learning_rate': 1.8091268631194417e-05, 'epoch': 0.22}
 22%|██▏       | 2328/10395 [6:39:20<19:28:41,  8.69s/it] 22%|██▏       | 2329/10395 [6:39:28<18:51:06,  8.41s/it]                                                         {'loss': 0.9453, 'learning_rate': 1.8089437328375193e-05, 'epoch': 0.22}
 22%|██▏       | 2329/10395 [6:39:28<18:51:06,  8.41s/it] 22%|██▏       | 2330/10395 [6:39:37<18:55:03,  8.44s/it]                                                         {'loss': 0.937, 'learning_rate': 1.8087605240250683e-05, 'epoch': 0.22}
 22%|██▏       | 2330/10395 [6:39:37<18:55:03,  8.44s/it] 22%|██▏       | 2331/10395 [6:39:44<18:11:04,  8.12s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.808577236699874e-05, 'epoch': 0.22}
 22%|██▏       | 2331/10395 [6:39:44<18:11:04,  8.12s/it] 22%|██▏       | 2332/10395 [6:39:52<17:49:33,  7.96s/it]                                                         {'loss': 1.0169, 'learning_rate': 1.8083938708797294e-05, 'epoch': 0.22}
 22%|██▏       | 2332/10395 [6:39:52<17:49:33,  7.96s/it] 22%|██▏       | 2333/10395 [6:39:59<17:31:10,  7.82s/it]                                                         {'loss': 0.9111, 'learning_rate': 1.8082104265824355e-05, 'epoch': 0.22}
 22%|██▏       | 2333/10395 [6:39:59<17:31:10,  7.82s/it] 22%|██▏       | 2334/10395 [6:40:07<17:22:45,  7.76s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.8080269038258004e-05, 'epoch': 0.22}
 22%|██▏       | 2334/10395 [6:40:07<17:22:45,  7.76s/it] 22%|██▏       | 2335/10395 [6:40:14<17:15:00,  7.70s/it]                                                         {'loss': 0.9566, 'learning_rate': 1.8078433026276402e-05, 'epoch': 0.22}
 22%|██▏       | 2335/10395 [6:40:14<17:15:00,  7.70s/it] 22%|██▏       | 2336/10395 [6:40:22<17:02:27,  7.61s/it]                                                         {'loss': 0.9545, 'learning_rate': 1.807659623005779e-05, 'epoch': 0.22}
 22%|██▏       | 2336/10395 [6:40:22<17:02:27,  7.61s/it] 22%|██▏       | 2337/10395 [6:40:30<17:10:10,  7.67s/it]                                                         {'loss': 1.037, 'learning_rate': 1.807475864978047e-05, 'epoch': 0.22}
 22%|██▏       | 2337/10395 [6:40:30<17:10:10,  7.67s/it] 22%|██▏       | 2338/10395 [6:40:37<16:53:27,  7.55s/it]                                                         {'loss': 0.9695, 'learning_rate': 1.8072920285622836e-05, 'epoch': 0.22}
 22%|██▏       | 2338/10395 [6:40:37<16:53:27,  7.55s/it] 23%|██▎       | 2339/10395 [6:40:45<17:22:17,  7.76s/it]                                                         {'loss': 0.9292, 'learning_rate': 1.8071081137763355e-05, 'epoch': 0.23}
 23%|██▎       | 2339/10395 [6:40:45<17:22:17,  7.76s/it] 23%|██▎       | 2340/10395 [6:40:53<17:20:28,  7.75s/it]                                                         {'loss': 1.048, 'learning_rate': 1.8069241206380565e-05, 'epoch': 0.23}
 23%|██▎       | 2340/10395 [6:40:53<17:20:28,  7.75s/it] 23%|██▎       | 2341/10395 [6:41:00<17:12:11,  7.69s/it]                                                         {'loss': 0.9451, 'learning_rate': 1.806740049165308e-05, 'epoch': 0.23}
 23%|██▎       | 2341/10395 [6:41:00<17:12:11,  7.69s/it] 23%|██▎       | 2342/10395 [6:41:09<17:52:15,  7.99s/it]                                                         {'loss': 0.9178, 'learning_rate': 1.80655589937596e-05, 'epoch': 0.23}
 23%|██▎       | 2342/10395 [6:41:09<17:52:15,  7.99s/it] 23%|██▎       | 2343/10395 [6:41:16<17:27:35,  7.81s/it]                                                         {'loss': 1.0821, 'learning_rate': 1.8063716712878885e-05, 'epoch': 0.23}
 23%|██▎       | 2343/10395 [6:41:16<17:27:35,  7.81s/it] 23%|██▎       | 2344/10395 [6:41:24<17:19:56,  7.75s/it]                                                         {'loss': 0.9563, 'learning_rate': 1.8061873649189788e-05, 'epoch': 0.23}
 23%|██▎       | 2344/10395 [6:41:24<17:19:56,  7.75s/it] 23%|██▎       | 2345/10395 [6:41:32<17:13:03,  7.70s/it]                                                         {'loss': 1.0514, 'learning_rate': 1.806002980287122e-05, 'epoch': 0.23}
 23%|██▎       | 2345/10395 [6:41:32<17:13:03,  7.70s/it] 23%|██▎       | 2346/10395 [6:41:39<17:18:10,  7.74s/it]                                                         {'loss': 0.9435, 'learning_rate': 1.8058185174102186e-05, 'epoch': 0.23}
 23%|██▎       | 2346/10395 [6:41:39<17:18:10,  7.74s/it] 23%|██▎       | 2347/10395 [6:41:47<17:03:09,  7.63s/it]                                                         {'loss': 1.0151, 'learning_rate': 1.8056339763061755e-05, 'epoch': 0.23}
 23%|██▎       | 2347/10395 [6:41:47<17:03:09,  7.63s/it] 23%|██▎       | 2348/10395 [6:41:55<17:14:39,  7.71s/it]                                                         {'loss': 1.0314, 'learning_rate': 1.8054493569929075e-05, 'epoch': 0.23}
 23%|██▎       | 2348/10395 [6:41:55<17:14:39,  7.71s/it] 23%|██▎       | 2349/10395 [6:42:04<18:33:03,  8.30s/it]                                                         {'loss': 0.9109, 'learning_rate': 1.8052646594883375e-05, 'epoch': 0.23}
 23%|██▎       | 2349/10395 [6:42:04<18:33:03,  8.30s/it] 23%|██▎       | 2350/10395 [6:42:12<18:18:43,  8.19s/it]                                                         {'loss': 0.903, 'learning_rate': 1.8050798838103954e-05, 'epoch': 0.23}
 23%|██▎       | 2350/10395 [6:42:12<18:18:43,  8.19s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 23%|██▎       | 2351/10395 [6:43:54<80:48:59, 36.17s/it]                                                         {'loss': 0.9487, 'learning_rate': 1.804895029977018e-05, 'epoch': 0.23}
 23%|██▎       | 2351/10395 [6:43:54<80:48:59, 36.17s/it] 23%|██▎       | 2352/10395 [6:44:01<61:23:48, 27.48s/it]                                                         {'loss': 1.0054, 'learning_rate': 1.8047100980061517e-05, 'epoch': 0.23}
 23%|██▎       | 2352/10395 [6:44:01<61:23:48, 27.48s/it] 23%|██▎       | 2353/10395 [6:44:09<48:15:01, 21.60s/it]                                                         {'loss': 0.9108, 'learning_rate': 1.8045250879157483e-05, 'epoch': 0.23}
 23%|██▎       | 2353/10395 [6:44:09<48:15:01, 21.60s/it] 23%|██▎       | 2354/10395 [6:44:17<39:08:58, 17.53s/it]                                                         {'loss': 0.9818, 'learning_rate': 1.804339999723769e-05, 'epoch': 0.23}
 23%|██▎       | 2354/10395 [6:44:17<39:08:58, 17.53s/it] 23%|██▎       | 2355/10395 [6:44:24<32:13:47, 14.43s/it]                                                         {'loss': 1.0149, 'learning_rate': 1.8041548334481813e-05, 'epoch': 0.23}
 23%|██▎       | 2355/10395 [6:44:24<32:13:47, 14.43s/it] 23%|██▎       | 2356/10395 [6:44:32<27:53:43, 12.49s/it]                                                         {'loss': 0.9566, 'learning_rate': 1.8039695891069606e-05, 'epoch': 0.23}
 23%|██▎       | 2356/10395 [6:44:32<27:53:43, 12.49s/it] 23%|██▎       | 2357/10395 [6:44:40<24:39:55, 11.05s/it]                                                         {'loss': 0.9895, 'learning_rate': 1.8037842667180907e-05, 'epoch': 0.23}
 23%|██▎       | 2357/10395 [6:44:40<24:39:55, 11.05s/it] 23%|██▎       | 2358/10395 [6:44:48<22:35:07, 10.12s/it]                                                         {'loss': 0.916, 'learning_rate': 1.8035988662995617e-05, 'epoch': 0.23}
 23%|██▎       | 2358/10395 [6:44:48<22:35:07, 10.12s/it] 23%|██▎       | 2359/10395 [6:44:55<20:59:42,  9.41s/it]                                                         {'loss': 0.9488, 'learning_rate': 1.803413387869372e-05, 'epoch': 0.23}
 23%|██▎       | 2359/10395 [6:44:55<20:59:42,  9.41s/it] 23%|██▎       | 2360/10395 [6:45:03<20:04:20,  8.99s/it]                                                         {'loss': 1.0091, 'learning_rate': 1.8032278314455273e-05, 'epoch': 0.23}
 23%|██▎       | 2360/10395 [6:45:03<20:04:20,  8.99s/it] 23%|██▎       | 2361/10395 [6:45:12<19:45:18,  8.85s/it]                                                         {'loss': 0.9792, 'learning_rate': 1.8030421970460417e-05, 'epoch': 0.23}
 23%|██▎       | 2361/10395 [6:45:12<19:45:18,  8.85s/it] 23%|██▎       | 2362/10395 [6:45:19<18:34:02,  8.32s/it]                                                         {'loss': 1.0432, 'learning_rate': 1.8028564846889355e-05, 'epoch': 0.23}
 23%|██▎       | 2362/10395 [6:45:19<18:34:02,  8.32s/it] 23%|██▎       | 2363/10395 [6:45:26<17:47:34,  7.97s/it]                                                         {'loss': 1.0653, 'learning_rate': 1.8026706943922374e-05, 'epoch': 0.23}
 23%|██▎       | 2363/10395 [6:45:26<17:47:34,  7.97s/it] 23%|██▎       | 2364/10395 [6:45:34<17:34:57,  7.88s/it]                                                         {'loss': 0.9704, 'learning_rate': 1.8024848261739837e-05, 'epoch': 0.23}
 23%|██▎       | 2364/10395 [6:45:34<17:34:57,  7.88s/it] 23%|██▎       | 2365/10395 [6:45:42<17:43:55,  7.95s/it]                                                         {'loss': 0.889, 'learning_rate': 1.802298880052218e-05, 'epoch': 0.23}
 23%|██▎       | 2365/10395 [6:45:42<17:43:55,  7.95s/it] 23%|██▎       | 2366/10395 [6:45:50<17:54:20,  8.03s/it]                                                         {'loss': 0.9343, 'learning_rate': 1.8021128560449913e-05, 'epoch': 0.23}
 23%|██▎       | 2366/10395 [6:45:50<17:54:20,  8.03s/it] 23%|██▎       | 2367/10395 [6:45:58<17:45:51,  7.97s/it]                                                         {'loss': 0.9657, 'learning_rate': 1.801926754170363e-05, 'epoch': 0.23}
 23%|██▎       | 2367/10395 [6:45:58<17:45:51,  7.97s/it] 23%|██▎       | 2368/10395 [6:46:15<23:27:35, 10.52s/it]                                                         {'loss': 0.3935, 'learning_rate': 1.8017405744463988e-05, 'epoch': 0.23}
 23%|██▎       | 2368/10395 [6:46:15<23:27:35, 10.52s/it] 23%|██▎       | 2369/10395 [6:46:22<21:31:01,  9.65s/it]                                                         {'loss': 0.9301, 'learning_rate': 1.8015543168911734e-05, 'epoch': 0.23}
 23%|██▎       | 2369/10395 [6:46:22<21:31:01,  9.65s/it] 23%|██▎       | 2370/10395 [6:46:30<20:28:29,  9.19s/it]                                                         {'loss': 0.9274, 'learning_rate': 1.8013679815227676e-05, 'epoch': 0.23}
 23%|██▎       | 2370/10395 [6:46:30<20:28:29,  9.19s/it] 23%|██▎       | 2371/10395 [6:46:37<19:07:18,  8.58s/it]                                                         {'loss': 0.9238, 'learning_rate': 1.8011815683592706e-05, 'epoch': 0.23}
 23%|██▎       | 2371/10395 [6:46:37<19:07:18,  8.58s/it] 23%|██▎       | 2372/10395 [6:46:46<18:48:45,  8.44s/it]                                                         {'loss': 0.9793, 'learning_rate': 1.800995077418779e-05, 'epoch': 0.23}
 23%|██▎       | 2372/10395 [6:46:46<18:48:45,  8.44s/it] 23%|██▎       | 2373/10395 [6:46:53<18:09:59,  8.15s/it]                                                         {'loss': 0.939, 'learning_rate': 1.8008085087193975e-05, 'epoch': 0.23}
 23%|██▎       | 2373/10395 [6:46:53<18:09:59,  8.15s/it] 23%|██▎       | 2374/10395 [6:47:01<17:47:06,  7.98s/it]                                                         {'loss': 1.0321, 'learning_rate': 1.8006218622792365e-05, 'epoch': 0.23}
 23%|██▎       | 2374/10395 [6:47:01<17:47:06,  7.98s/it] 23%|██▎       | 2375/10395 [6:47:08<17:26:49,  7.83s/it]                                                         {'loss': 0.9886, 'learning_rate': 1.8004351381164168e-05, 'epoch': 0.23}
 23%|██▎       | 2375/10395 [6:47:08<17:26:49,  7.83s/it] 23%|██▎       | 2376/10395 [6:47:16<17:09:40,  7.70s/it]                                                         {'loss': 1.0309, 'learning_rate': 1.8002483362490643e-05, 'epoch': 0.23}
 23%|██▎       | 2376/10395 [6:47:16<17:09:40,  7.70s/it] 23%|██▎       | 2377/10395 [6:47:23<17:02:35,  7.65s/it]                                                         {'loss': 1.0039, 'learning_rate': 1.800061456695313e-05, 'epoch': 0.23}
 23%|██▎       | 2377/10395 [6:47:23<17:02:35,  7.65s/it] 23%|██▎       | 2378/10395 [6:47:30<16:54:48,  7.59s/it]                                                         {'loss': 1.0069, 'learning_rate': 1.7998744994733055e-05, 'epoch': 0.23}
 23%|██▎       | 2378/10395 [6:47:30<16:54:48,  7.59s/it] 23%|██▎       | 2379/10395 [6:47:38<16:56:12,  7.61s/it]                                                         {'loss': 0.9927, 'learning_rate': 1.799687464601191e-05, 'epoch': 0.23}
 23%|██▎       | 2379/10395 [6:47:38<16:56:12,  7.61s/it] 23%|██▎       | 2380/10395 [6:47:47<17:37:18,  7.91s/it]                                                         {'loss': 0.9212, 'learning_rate': 1.7995003520971264e-05, 'epoch': 0.23}
 23%|██▎       | 2380/10395 [6:47:47<17:37:18,  7.91s/it] 23%|██▎       | 2381/10395 [6:47:54<17:19:34,  7.78s/it]                                                         {'loss': 0.982, 'learning_rate': 1.799313161979276e-05, 'epoch': 0.23}
 23%|██▎       | 2381/10395 [6:47:54<17:19:34,  7.78s/it] 23%|██▎       | 2382/10395 [6:48:02<17:28:04,  7.85s/it]                                                         {'loss': 1.001, 'learning_rate': 1.7991258942658122e-05, 'epoch': 0.23}
 23%|██▎       | 2382/10395 [6:48:02<17:28:04,  7.85s/it] 23%|██▎       | 2383/10395 [6:48:09<17:04:07,  7.67s/it]                                                         {'loss': 0.9655, 'learning_rate': 1.798938548974914e-05, 'epoch': 0.23}
 23%|██▎       | 2383/10395 [6:48:09<17:04:07,  7.67s/it] 23%|██▎       | 2384/10395 [6:48:17<17:02:31,  7.66s/it]                                                         {'loss': 0.9004, 'learning_rate': 1.798751126124769e-05, 'epoch': 0.23}
 23%|██▎       | 2384/10395 [6:48:17<17:02:31,  7.66s/it] 23%|██▎       | 2385/10395 [6:48:25<16:54:20,  7.60s/it]                                                         {'loss': 0.9757, 'learning_rate': 1.7985636257335716e-05, 'epoch': 0.23}
 23%|██▎       | 2385/10395 [6:48:25<16:54:20,  7.60s/it] 23%|██▎       | 2386/10395 [6:48:32<16:39:53,  7.49s/it]                                                         {'loss': 1.0117, 'learning_rate': 1.7983760478195238e-05, 'epoch': 0.23}
 23%|██▎       | 2386/10395 [6:48:32<16:39:53,  7.49s/it] 23%|██▎       | 2387/10395 [6:48:39<16:34:24,  7.45s/it]                                                         {'loss': 1.0158, 'learning_rate': 1.7981883924008355e-05, 'epoch': 0.23}
 23%|██▎       | 2387/10395 [6:48:39<16:34:24,  7.45s/it] 23%|██▎       | 2388/10395 [6:48:47<16:43:20,  7.52s/it]                                                         {'loss': 1.0365, 'learning_rate': 1.798000659495724e-05, 'epoch': 0.23}
 23%|██▎       | 2388/10395 [6:48:47<16:43:20,  7.52s/it] 23%|██▎       | 2389/10395 [6:48:54<16:45:16,  7.53s/it]                                                         {'loss': 0.9586, 'learning_rate': 1.7978128491224137e-05, 'epoch': 0.23}
 23%|██▎       | 2389/10395 [6:48:54<16:45:16,  7.53s/it] 23%|██▎       | 2390/10395 [6:49:02<16:58:24,  7.63s/it]                                                         {'loss': 1.0581, 'learning_rate': 1.7976249612991367e-05, 'epoch': 0.23}
 23%|██▎       | 2390/10395 [6:49:02<16:58:24,  7.63s/it] 23%|██▎       | 2391/10395 [6:49:10<17:15:13,  7.76s/it]                                                         {'loss': 1.0567, 'learning_rate': 1.7974369960441335e-05, 'epoch': 0.23}
 23%|██▎       | 2391/10395 [6:49:10<17:15:13,  7.76s/it] 23%|██▎       | 2392/10395 [6:49:18<16:55:42,  7.61s/it]                                                         {'loss': 0.9723, 'learning_rate': 1.79724895337565e-05, 'epoch': 0.23}
 23%|██▎       | 2392/10395 [6:49:18<16:55:42,  7.61s/it] 23%|██▎       | 2393/10395 [6:49:25<16:55:49,  7.62s/it]                                                         {'loss': 1.029, 'learning_rate': 1.797060833311943e-05, 'epoch': 0.23}
 23%|██▎       | 2393/10395 [6:49:25<16:55:49,  7.62s/it] 23%|██▎       | 2394/10395 [6:49:34<17:41:35,  7.96s/it]                                                         {'loss': 0.9594, 'learning_rate': 1.7968726358712728e-05, 'epoch': 0.23}
 23%|██▎       | 2394/10395 [6:49:34<17:41:35,  7.96s/it] 23%|██▎       | 2395/10395 [6:49:42<17:37:39,  7.93s/it]                                                         {'loss': 0.9659, 'learning_rate': 1.7966843610719103e-05, 'epoch': 0.23}
 23%|██▎       | 2395/10395 [6:49:42<17:37:39,  7.93s/it] 23%|██▎       | 2396/10395 [6:49:49<17:24:11,  7.83s/it]                                                         {'loss': 0.909, 'learning_rate': 1.7964960089321324e-05, 'epoch': 0.23}
 23%|██▎       | 2396/10395 [6:49:49<17:24:11,  7.83s/it] 23%|██▎       | 2397/10395 [6:49:57<17:12:45,  7.75s/it]                                                         {'loss': 1.0308, 'learning_rate': 1.796307579470224e-05, 'epoch': 0.23}
 23%|██▎       | 2397/10395 [6:49:57<17:12:45,  7.75s/it] 23%|██▎       | 2398/10395 [6:50:14<23:34:29, 10.61s/it]                                                         {'loss': 0.4548, 'learning_rate': 1.7961190727044777e-05, 'epoch': 0.23}
 23%|██▎       | 2398/10395 [6:50:14<23:34:29, 10.61s/it] 23%|██▎       | 2399/10395 [6:50:22<21:33:19,  9.70s/it]                                                         {'loss': 0.9388, 'learning_rate': 1.795930488653193e-05, 'epoch': 0.23}
 23%|██▎       | 2399/10395 [6:50:22<21:33:19,  9.70s/it] 23%|██▎       | 2400/10395 [6:50:30<20:43:09,  9.33s/it]                                                         {'loss': 0.9437, 'learning_rate': 1.7957418273346773e-05, 'epoch': 0.23}
 23%|██▎       | 2400/10395 [6:50:30<20:43:09,  9.33s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 23%|██▎       | 2401/10395 [6:52:11<81:36:44, 36.75s/it]                                                         {'loss': 0.9698, 'learning_rate': 1.795553088767246e-05, 'epoch': 0.23}
 23%|██▎       | 2401/10395 [6:52:11<81:36:44, 36.75s/it] 23%|██▎       | 2402/10395 [6:52:19<62:03:05, 27.95s/it]                                                         {'loss': 0.8911, 'learning_rate': 1.7953642729692204e-05, 'epoch': 0.23}
 23%|██▎       | 2402/10395 [6:52:19<62:03:05, 27.95s/it] 23%|██▎       | 2403/10395 [6:52:27<49:08:38, 22.14s/it]                                                         {'loss': 0.9186, 'learning_rate': 1.7951753799589312e-05, 'epoch': 0.23}
 23%|██▎       | 2403/10395 [6:52:27<49:08:38, 22.14s/it] 23%|██▎       | 2404/10395 [6:52:36<40:04:30, 18.05s/it]                                                         {'loss': 0.9112, 'learning_rate': 1.7949864097547154e-05, 'epoch': 0.23}
 23%|██▎       | 2404/10395 [6:52:36<40:04:30, 18.05s/it] 23%|██▎       | 2405/10395 [6:52:52<38:40:07, 17.42s/it]                                                         {'loss': 0.3656, 'learning_rate': 1.7947973623749178e-05, 'epoch': 0.23}
 23%|██▎       | 2405/10395 [6:52:52<38:40:07, 17.42s/it] 23%|██▎       | 2406/10395 [6:52:59<32:01:59, 14.43s/it]                                                         {'loss': 1.0045, 'learning_rate': 1.7946082378378906e-05, 'epoch': 0.23}
 23%|██▎       | 2406/10395 [6:52:59<32:01:59, 14.43s/it] 23%|██▎       | 2407/10395 [6:53:07<27:26:23, 12.37s/it]                                                         {'loss': 1.0476, 'learning_rate': 1.7944190361619937e-05, 'epoch': 0.23}
 23%|██▎       | 2407/10395 [6:53:07<27:26:23, 12.37s/it] 23%|██▎       | 2408/10395 [6:53:15<24:31:53, 11.06s/it]                                                         {'loss': 0.9226, 'learning_rate': 1.7942297573655948e-05, 'epoch': 0.23}
 23%|██▎       | 2408/10395 [6:53:15<24:31:53, 11.06s/it] 23%|██▎       | 2409/10395 [6:53:22<22:26:05, 10.11s/it]                                                         {'loss': 0.8938, 'learning_rate': 1.7940404014670678e-05, 'epoch': 0.23}
 23%|██▎       | 2409/10395 [6:53:22<22:26:05, 10.11s/it] 23%|██▎       | 2410/10395 [6:53:30<20:37:55,  9.30s/it]                                                         {'loss': 0.9794, 'learning_rate': 1.793850968484796e-05, 'epoch': 0.23}
 23%|██▎       | 2410/10395 [6:53:30<20:37:55,  9.30s/it] 23%|██▎       | 2411/10395 [6:53:38<19:36:54,  8.84s/it]                                                         {'loss': 0.8986, 'learning_rate': 1.7936614584371685e-05, 'epoch': 0.23}
 23%|██▎       | 2411/10395 [6:53:38<19:36:54,  8.84s/it] 23%|██▎       | 2412/10395 [6:53:45<18:44:11,  8.45s/it]                                                         {'loss': 0.9152, 'learning_rate': 1.7934718713425825e-05, 'epoch': 0.23}
 23%|██▎       | 2412/10395 [6:53:45<18:44:11,  8.45s/it] 23%|██▎       | 2413/10395 [6:53:53<18:01:35,  8.13s/it]                                                         {'loss': 1.049, 'learning_rate': 1.793282207219443e-05, 'epoch': 0.23}
 23%|██▎       | 2413/10395 [6:53:53<18:01:35,  8.13s/it] 23%|██▎       | 2414/10395 [6:54:01<18:02:33,  8.14s/it]                                                         {'loss': 0.9153, 'learning_rate': 1.7930924660861618e-05, 'epoch': 0.23}
 23%|██▎       | 2414/10395 [6:54:01<18:02:33,  8.14s/it] 23%|██▎       | 2415/10395 [6:54:18<23:51:42, 10.76s/it]                                                         {'loss': 0.4349, 'learning_rate': 1.792902647961159e-05, 'epoch': 0.23}
 23%|██▎       | 2415/10395 [6:54:18<23:51:42, 10.76s/it] 23%|██▎       | 2416/10395 [6:54:25<21:54:43,  9.89s/it]                                                         {'loss': 0.9926, 'learning_rate': 1.792712752862862e-05, 'epoch': 0.23}
 23%|██▎       | 2416/10395 [6:54:25<21:54:43,  9.89s/it] 23%|██▎       | 2417/10395 [6:54:34<21:02:00,  9.49s/it]                                                         {'loss': 0.9991, 'learning_rate': 1.7925227808097048e-05, 'epoch': 0.23}
 23%|██▎       | 2417/10395 [6:54:34<21:02:00,  9.49s/it] 23%|██▎       | 2418/10395 [6:54:42<19:42:46,  8.90s/it]                                                         {'loss': 0.9496, 'learning_rate': 1.7923327318201295e-05, 'epoch': 0.23}
 23%|██▎       | 2418/10395 [6:54:42<19:42:46,  8.90s/it] 23%|██▎       | 2419/10395 [6:54:49<19:05:14,  8.62s/it]                                                         {'loss': 0.9731, 'learning_rate': 1.7921426059125856e-05, 'epoch': 0.23}
 23%|██▎       | 2419/10395 [6:54:50<19:05:14,  8.62s/it] 23%|██▎       | 2420/10395 [6:54:57<18:16:32,  8.25s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.7919524031055307e-05, 'epoch': 0.23}
 23%|██▎       | 2420/10395 [6:54:57<18:16:32,  8.25s/it] 23%|██▎       | 2421/10395 [6:55:04<17:45:32,  8.02s/it]                                                         {'loss': 1.0177, 'learning_rate': 1.791762123417429e-05, 'epoch': 0.23}
 23%|██▎       | 2421/10395 [6:55:04<17:45:32,  8.02s/it] 23%|██▎       | 2422/10395 [6:55:12<17:33:39,  7.93s/it]                                                         {'loss': 0.9566, 'learning_rate': 1.791571766866752e-05, 'epoch': 0.23}
 23%|██▎       | 2422/10395 [6:55:12<17:33:39,  7.93s/it] 23%|██▎       | 2423/10395 [6:55:20<17:27:17,  7.88s/it]                                                         {'loss': 0.9967, 'learning_rate': 1.7913813334719797e-05, 'epoch': 0.23}
 23%|██▎       | 2423/10395 [6:55:20<17:27:17,  7.88s/it] 23%|██▎       | 2424/10395 [6:55:27<17:15:55,  7.80s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.7911908232515988e-05, 'epoch': 0.23}
 23%|██▎       | 2424/10395 [6:55:27<17:15:55,  7.80s/it] 23%|██▎       | 2425/10395 [6:55:35<16:53:43,  7.63s/it]                                                         {'loss': 0.9859, 'learning_rate': 1.7910002362241035e-05, 'epoch': 0.23}
 23%|██▎       | 2425/10395 [6:55:35<16:53:43,  7.63s/it] 23%|██▎       | 2426/10395 [6:55:43<17:10:42,  7.76s/it]                                                         {'loss': 0.9363, 'learning_rate': 1.7908095724079954e-05, 'epoch': 0.23}
 23%|██▎       | 2426/10395 [6:55:43<17:10:42,  7.76s/it] 23%|██▎       | 2427/10395 [6:55:50<17:02:59,  7.70s/it]                                                         {'loss': 1.0958, 'learning_rate': 1.7906188318217842e-05, 'epoch': 0.23}
 23%|██▎       | 2427/10395 [6:55:50<17:02:59,  7.70s/it] 23%|██▎       | 2428/10395 [6:55:57<16:37:57,  7.52s/it]                                                         {'loss': 1.0, 'learning_rate': 1.7904280144839862e-05, 'epoch': 0.23}
 23%|██▎       | 2428/10395 [6:55:57<16:37:57,  7.52s/it] 23%|██▎       | 2429/10395 [6:56:06<17:22:14,  7.85s/it]                                                         {'loss': 0.9028, 'learning_rate': 1.7902371204131258e-05, 'epoch': 0.23}
 23%|██▎       | 2429/10395 [6:56:06<17:22:14,  7.85s/it] 23%|██▎       | 2430/10395 [6:56:14<17:13:11,  7.78s/it]                                                         {'loss': 1.0205, 'learning_rate': 1.7900461496277345e-05, 'epoch': 0.23}
 23%|██▎       | 2430/10395 [6:56:14<17:13:11,  7.78s/it] 23%|██▎       | 2431/10395 [6:56:30<23:00:24, 10.40s/it]                                                         {'loss': 0.3734, 'learning_rate': 1.7898551021463514e-05, 'epoch': 0.23}
 23%|██▎       | 2431/10395 [6:56:30<23:00:24, 10.40s/it] 23%|██▎       | 2432/10395 [6:56:38<21:00:53,  9.50s/it]                                                         {'loss': 0.9768, 'learning_rate': 1.7896639779875226e-05, 'epoch': 0.23}
 23%|██▎       | 2432/10395 [6:56:38<21:00:53,  9.50s/it] 23%|██▎       | 2433/10395 [6:56:45<19:52:13,  8.98s/it]                                                         {'loss': 1.027, 'learning_rate': 1.7894727771698027e-05, 'epoch': 0.23}
 23%|██▎       | 2433/10395 [6:56:45<19:52:13,  8.98s/it] 23%|██▎       | 2434/10395 [6:56:53<18:47:07,  8.49s/it]                                                         {'loss': 0.9944, 'learning_rate': 1.7892814997117527e-05, 'epoch': 0.23}
 23%|██▎       | 2434/10395 [6:56:53<18:47:07,  8.49s/it] 23%|██▎       | 2435/10395 [6:57:00<18:06:13,  8.19s/it]                                                         {'loss': 0.9495, 'learning_rate': 1.789090145631941e-05, 'epoch': 0.23}
 23%|██▎       | 2435/10395 [6:57:00<18:06:13,  8.19s/it] 23%|██▎       | 2436/10395 [6:57:08<17:44:58,  8.03s/it]                                                         {'loss': 0.9451, 'learning_rate': 1.788898714948945e-05, 'epoch': 0.23}
 23%|██▎       | 2436/10395 [6:57:08<17:44:58,  8.03s/it] 23%|██▎       | 2437/10395 [6:57:16<17:54:47,  8.10s/it]                                                         {'loss': 0.9823, 'learning_rate': 1.788707207681347e-05, 'epoch': 0.23}
 23%|██▎       | 2437/10395 [6:57:16<17:54:47,  8.10s/it] 23%|██▎       | 2438/10395 [6:57:24<18:01:01,  8.15s/it]                                                         {'loss': 0.9666, 'learning_rate': 1.788515623847739e-05, 'epoch': 0.23}
 23%|██▎       | 2438/10395 [6:57:24<18:01:01,  8.15s/it] 23%|██▎       | 2439/10395 [6:57:32<17:26:13,  7.89s/it]                                                         {'loss': 0.9644, 'learning_rate': 1.788323963466719e-05, 'epoch': 0.23}
 23%|██▎       | 2439/10395 [6:57:32<17:26:13,  7.89s/it] 23%|██▎       | 2440/10395 [6:57:40<17:32:59,  7.94s/it]                                                         {'loss': 0.8844, 'learning_rate': 1.7881322265568933e-05, 'epoch': 0.23}
 23%|██▎       | 2440/10395 [6:57:40<17:32:59,  7.94s/it] 23%|██▎       | 2441/10395 [6:57:47<17:20:24,  7.85s/it]                                                         {'loss': 0.9595, 'learning_rate': 1.7879404131368757e-05, 'epoch': 0.23}
 23%|██▎       | 2441/10395 [6:57:47<17:20:24,  7.85s/it] 23%|██▎       | 2442/10395 [6:57:55<17:14:21,  7.80s/it]                                                         {'loss': 0.9748, 'learning_rate': 1.7877485232252865e-05, 'epoch': 0.23}
 23%|██▎       | 2442/10395 [6:57:55<17:14:21,  7.80s/it] 24%|██▎       | 2443/10395 [6:58:03<17:23:23,  7.87s/it]                                                         {'loss': 1.0317, 'learning_rate': 1.787556556840754e-05, 'epoch': 0.24}
 24%|██▎       | 2443/10395 [6:58:03<17:23:23,  7.87s/it] 24%|██▎       | 2444/10395 [6:58:11<17:14:04,  7.80s/it]                                                         {'loss': 0.9579, 'learning_rate': 1.787364514001914e-05, 'epoch': 0.24}
 24%|██▎       | 2444/10395 [6:58:11<17:14:04,  7.80s/it] 24%|██▎       | 2445/10395 [6:58:19<17:41:28,  8.01s/it]                                                         {'loss': 0.9584, 'learning_rate': 1.7871723947274096e-05, 'epoch': 0.24}
 24%|██▎       | 2445/10395 [6:58:19<17:41:28,  8.01s/it] 24%|██▎       | 2446/10395 [6:58:27<17:46:01,  8.05s/it]                                                         {'loss': 0.9803, 'learning_rate': 1.7869801990358913e-05, 'epoch': 0.24}
 24%|██▎       | 2446/10395 [6:58:27<17:46:01,  8.05s/it] 24%|██▎       | 2447/10395 [6:58:35<17:26:11,  7.90s/it]                                                         {'loss': 1.0235, 'learning_rate': 1.786787926946017e-05, 'epoch': 0.24}
 24%|██▎       | 2447/10395 [6:58:35<17:26:11,  7.90s/it] 24%|██▎       | 2448/10395 [6:58:43<17:33:14,  7.95s/it]                                                         {'loss': 1.0001, 'learning_rate': 1.7865955784764525e-05, 'epoch': 0.24}
 24%|██▎       | 2448/10395 [6:58:43<17:33:14,  7.95s/it] 24%|██▎       | 2449/10395 [6:58:50<17:07:04,  7.76s/it]                                                         {'loss': 0.9662, 'learning_rate': 1.7864031536458693e-05, 'epoch': 0.24}
 24%|██▎       | 2449/10395 [6:58:50<17:07:04,  7.76s/it] 24%|██▎       | 2450/10395 [6:58:58<17:14:42,  7.81s/it]                                                         {'loss': 0.9838, 'learning_rate': 1.7862106524729494e-05, 'epoch': 0.24}
 24%|██▎       | 2450/10395 [6:58:58<17:14:42,  7.81s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 24%|██▎       | 2451/10395 [7:00:39<78:50:19, 35.73s/it]                                                         {'loss': 0.9736, 'learning_rate': 1.7860180749763787e-05, 'epoch': 0.24}
 24%|██▎       | 2451/10395 [7:00:39<78:50:19, 35.73s/it] 24%|██▎       | 2452/10395 [7:00:47<60:14:28, 27.30s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.785825421174854e-05, 'epoch': 0.24}
 24%|██▎       | 2452/10395 [7:00:47<60:14:28, 27.30s/it] 24%|██▎       | 2453/10395 [7:00:56<47:59:07, 21.75s/it]                                                         {'loss': 0.9238, 'learning_rate': 1.785632691087076e-05, 'epoch': 0.24}
 24%|██▎       | 2453/10395 [7:00:56<47:59:07, 21.75s/it] 24%|██▎       | 2454/10395 [7:01:03<38:41:05, 17.54s/it]                                                         {'loss': 0.9941, 'learning_rate': 1.7854398847317555e-05, 'epoch': 0.24}
 24%|██▎       | 2454/10395 [7:01:03<38:41:05, 17.54s/it] 24%|██▎       | 2455/10395 [7:01:11<32:05:46, 14.55s/it]                                                         {'loss': 1.057, 'learning_rate': 1.7852470021276092e-05, 'epoch': 0.24}
 24%|██▎       | 2455/10395 [7:01:11<32:05:46, 14.55s/it] 24%|██▎       | 2456/10395 [7:01:27<33:20:21, 15.12s/it]                                                         {'loss': 0.3952, 'learning_rate': 1.7850540432933624e-05, 'epoch': 0.24}
 24%|██▎       | 2456/10395 [7:01:27<33:20:21, 15.12s/it] 24%|██▎       | 2457/10395 [7:01:35<28:30:43, 12.93s/it]                                                         {'loss': 0.9843, 'learning_rate': 1.7848610082477463e-05, 'epoch': 0.24}
 24%|██▎       | 2457/10395 [7:01:35<28:30:43, 12.93s/it] 24%|██▎       | 2458/10395 [7:01:43<25:05:13, 11.38s/it]                                                         {'loss': 0.9594, 'learning_rate': 1.7846678970095013e-05, 'epoch': 0.24}
 24%|██▎       | 2458/10395 [7:01:43<25:05:13, 11.38s/it] 24%|██▎       | 2459/10395 [7:01:50<22:31:26, 10.22s/it]                                                         {'loss': 0.9803, 'learning_rate': 1.7844747095973736e-05, 'epoch': 0.24}
 24%|██▎       | 2459/10395 [7:01:50<22:31:26, 10.22s/it] 24%|██▎       | 2460/10395 [7:01:59<21:28:36,  9.74s/it]                                                         {'loss': 0.8878, 'learning_rate': 1.7842814460301173e-05, 'epoch': 0.24}
 24%|██▎       | 2460/10395 [7:01:59<21:28:36,  9.74s/it] 24%|██▎       | 2461/10395 [7:02:08<21:02:23,  9.55s/it]                                                         {'loss': 0.8538, 'learning_rate': 1.7840881063264944e-05, 'epoch': 0.24}
 24%|██▎       | 2461/10395 [7:02:08<21:02:23,  9.55s/it] 24%|██▎       | 2462/10395 [7:02:26<26:37:51, 12.09s/it]                                                         {'loss': 0.3907, 'learning_rate': 1.7838946905052738e-05, 'epoch': 0.24}
 24%|██▎       | 2462/10395 [7:02:26<26:37:51, 12.09s/it] 24%|██▎       | 2463/10395 [7:02:33<23:31:10, 10.67s/it]                                                         {'loss': 0.972, 'learning_rate': 1.7837011985852315e-05, 'epoch': 0.24}
 24%|██▎       | 2463/10395 [7:02:34<23:31:10, 10.67s/it] 24%|██▎       | 2464/10395 [7:02:41<21:34:12,  9.79s/it]                                                         {'loss': 0.9832, 'learning_rate': 1.7835076305851518e-05, 'epoch': 0.24}
 24%|██▎       | 2464/10395 [7:02:41<21:34:12,  9.79s/it] 24%|██▎       | 2465/10395 [7:02:49<19:57:19,  9.06s/it]                                                         {'loss': 0.9401, 'learning_rate': 1.7833139865238257e-05, 'epoch': 0.24}
 24%|██▎       | 2465/10395 [7:02:49<19:57:19,  9.06s/it] 24%|██▎       | 2466/10395 [7:02:56<19:02:59,  8.65s/it]                                                         {'loss': 1.0148, 'learning_rate': 1.7831202664200518e-05, 'epoch': 0.24}
 24%|██▎       | 2466/10395 [7:02:56<19:02:59,  8.65s/it] 24%|██▎       | 2467/10395 [7:03:04<18:40:07,  8.48s/it]                                                         {'loss': 1.0553, 'learning_rate': 1.7829264702926358e-05, 'epoch': 0.24}
 24%|██▎       | 2467/10395 [7:03:04<18:40:07,  8.48s/it] 24%|██▎       | 2468/10395 [7:03:13<18:31:45,  8.41s/it]                                                         {'loss': 0.9841, 'learning_rate': 1.7827325981603914e-05, 'epoch': 0.24}
 24%|██▎       | 2468/10395 [7:03:13<18:31:45,  8.41s/it] 24%|██▍       | 2469/10395 [7:03:20<18:10:20,  8.25s/it]                                                         {'loss': 0.9185, 'learning_rate': 1.7825386500421386e-05, 'epoch': 0.24}
 24%|██▍       | 2469/10395 [7:03:20<18:10:20,  8.25s/it] 24%|██▍       | 2470/10395 [7:03:28<17:42:33,  8.04s/it]                                                         {'loss': 0.932, 'learning_rate': 1.7823446259567062e-05, 'epoch': 0.24}
 24%|██▍       | 2470/10395 [7:03:28<17:42:33,  8.04s/it] 24%|██▍       | 2471/10395 [7:03:36<17:42:39,  8.05s/it]                                                         {'loss': 0.9545, 'learning_rate': 1.78215052592293e-05, 'epoch': 0.24}
 24%|██▍       | 2471/10395 [7:03:36<17:42:39,  8.05s/it] 24%|██▍       | 2472/10395 [7:03:44<17:29:22,  7.95s/it]                                                         {'loss': 0.9776, 'learning_rate': 1.7819563499596516e-05, 'epoch': 0.24}
 24%|██▍       | 2472/10395 [7:03:44<17:29:22,  7.95s/it] 24%|██▍       | 2473/10395 [7:03:51<17:05:52,  7.77s/it]                                                         {'loss': 1.0268, 'learning_rate': 1.781762098085722e-05, 'epoch': 0.24}
 24%|██▍       | 2473/10395 [7:03:51<17:05:52,  7.77s/it] 24%|██▍       | 2474/10395 [7:03:59<17:19:15,  7.87s/it]                                                         {'loss': 1.0187, 'learning_rate': 1.781567770319998e-05, 'epoch': 0.24}
 24%|██▍       | 2474/10395 [7:03:59<17:19:15,  7.87s/it] 24%|██▍       | 2475/10395 [7:04:07<17:29:32,  7.95s/it]                                                         {'loss': 0.9805, 'learning_rate': 1.7813733666813456e-05, 'epoch': 0.24}
 24%|██▍       | 2475/10395 [7:04:07<17:29:32,  7.95s/it] 24%|██▍       | 2476/10395 [7:04:15<17:02:55,  7.75s/it]                                                         {'loss': 1.0079, 'learning_rate': 1.7811788871886366e-05, 'epoch': 0.24}
 24%|██▍       | 2476/10395 [7:04:15<17:02:55,  7.75s/it] 24%|██▍       | 2477/10395 [7:04:23<17:23:20,  7.91s/it]                                                         {'loss': 0.992, 'learning_rate': 1.7809843318607504e-05, 'epoch': 0.24}
 24%|██▍       | 2477/10395 [7:04:23<17:23:20,  7.91s/it] 24%|██▍       | 2478/10395 [7:04:30<17:08:39,  7.80s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.780789700716574e-05, 'epoch': 0.24}
 24%|██▍       | 2478/10395 [7:04:30<17:08:39,  7.80s/it] 24%|██▍       | 2479/10395 [7:04:39<17:47:19,  8.09s/it]                                                         {'loss': 0.8952, 'learning_rate': 1.7805949937750026e-05, 'epoch': 0.24}
 24%|██▍       | 2479/10395 [7:04:39<17:47:19,  8.09s/it] 24%|██▍       | 2480/10395 [7:04:47<17:19:08,  7.88s/it]                                                         {'loss': 0.9356, 'learning_rate': 1.780400211054937e-05, 'epoch': 0.24}
 24%|██▍       | 2480/10395 [7:04:47<17:19:08,  7.88s/it] 24%|██▍       | 2481/10395 [7:05:04<23:51:08, 10.85s/it]                                                         {'loss': 0.3921, 'learning_rate': 1.780205352575287e-05, 'epoch': 0.24}
 24%|██▍       | 2481/10395 [7:05:04<23:51:08, 10.85s/it] 24%|██▍       | 2482/10395 [7:05:13<22:09:52, 10.08s/it]                                                         {'loss': 0.9929, 'learning_rate': 1.780010418354968e-05, 'epoch': 0.24}
 24%|██▍       | 2482/10395 [7:05:13<22:09:52, 10.08s/it] 24%|██▍       | 2483/10395 [7:05:22<21:28:04,  9.77s/it]                                                         {'loss': 0.9116, 'learning_rate': 1.779815408412905e-05, 'epoch': 0.24}
 24%|██▍       | 2483/10395 [7:05:22<21:28:04,  9.77s/it] 24%|██▍       | 2484/10395 [7:05:30<20:18:46,  9.24s/it]                                                         {'loss': 0.8714, 'learning_rate': 1.7796203227680283e-05, 'epoch': 0.24}
 24%|██▍       | 2484/10395 [7:05:30<20:18:46,  9.24s/it] 24%|██▍       | 2485/10395 [7:05:37<19:05:47,  8.69s/it]                                                         {'loss': 0.8784, 'learning_rate': 1.779425161439277e-05, 'epoch': 0.24}
 24%|██▍       | 2485/10395 [7:05:37<19:05:47,  8.69s/it] 24%|██▍       | 2486/10395 [7:05:45<18:29:36,  8.42s/it]                                                         {'loss': 0.9894, 'learning_rate': 1.7792299244455965e-05, 'epoch': 0.24}
 24%|██▍       | 2486/10395 [7:05:45<18:29:36,  8.42s/it] 24%|██▍       | 2487/10395 [7:06:02<24:14:26, 11.04s/it]                                                         {'loss': 0.3875, 'learning_rate': 1.7790346118059402e-05, 'epoch': 0.24}
 24%|██▍       | 2487/10395 [7:06:02<24:14:26, 11.04s/it] 24%|██▍       | 2488/10395 [7:06:10<22:06:11, 10.06s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.7788392235392688e-05, 'epoch': 0.24}
 24%|██▍       | 2488/10395 [7:06:10<22:06:11, 10.06s/it] 24%|██▍       | 2489/10395 [7:06:18<20:43:50,  9.44s/it]                                                         {'loss': 0.9151, 'learning_rate': 1.7786437596645496e-05, 'epoch': 0.24}
 24%|██▍       | 2489/10395 [7:06:18<20:43:50,  9.44s/it] 24%|██▍       | 2490/10395 [7:06:26<19:32:14,  8.90s/it]                                                         {'loss': 0.9888, 'learning_rate': 1.7784482202007583e-05, 'epoch': 0.24}
 24%|██▍       | 2490/10395 [7:06:26<19:32:14,  8.90s/it] 24%|██▍       | 2491/10395 [7:06:33<18:30:19,  8.43s/it]                                                         {'loss': 0.9741, 'learning_rate': 1.7782526051668775e-05, 'epoch': 0.24}
 24%|██▍       | 2491/10395 [7:06:33<18:30:19,  8.43s/it] 24%|██▍       | 2492/10395 [7:06:41<17:59:54,  8.20s/it]                                                         {'loss': 1.0351, 'learning_rate': 1.7780569145818967e-05, 'epoch': 0.24}
 24%|██▍       | 2492/10395 [7:06:41<17:59:54,  8.20s/it] 24%|██▍       | 2493/10395 [7:06:49<18:00:31,  8.20s/it]                                                         {'loss': 0.9682, 'learning_rate': 1.7778611484648135e-05, 'epoch': 0.24}
 24%|██▍       | 2493/10395 [7:06:49<18:00:31,  8.20s/it] 24%|██▍       | 2494/10395 [7:06:56<17:17:02,  7.88s/it]                                                         {'loss': 0.9666, 'learning_rate': 1.7776653068346323e-05, 'epoch': 0.24}
 24%|██▍       | 2494/10395 [7:06:56<17:17:02,  7.88s/it] 24%|██▍       | 2495/10395 [7:07:04<17:11:39,  7.84s/it]                                                         {'loss': 0.9629, 'learning_rate': 1.777469389710365e-05, 'epoch': 0.24}
 24%|██▍       | 2495/10395 [7:07:04<17:11:39,  7.84s/it] 24%|██▍       | 2496/10395 [7:07:12<17:41:02,  8.06s/it]                                                         {'loss': 0.9233, 'learning_rate': 1.7772733971110305e-05, 'epoch': 0.24}
 24%|██▍       | 2496/10395 [7:07:12<17:41:02,  8.06s/it] 24%|██▍       | 2497/10395 [7:07:20<17:19:01,  7.89s/it]                                                         {'loss': 0.9962, 'learning_rate': 1.777077329055656e-05, 'epoch': 0.24}
 24%|██▍       | 2497/10395 [7:07:20<17:19:01,  7.89s/it] 24%|██▍       | 2498/10395 [7:07:27<16:48:31,  7.66s/it]                                                         {'loss': 0.9811, 'learning_rate': 1.776881185563275e-05, 'epoch': 0.24}
 24%|██▍       | 2498/10395 [7:07:27<16:48:31,  7.66s/it] 24%|██▍       | 2499/10395 [7:07:35<16:55:32,  7.72s/it]                                                         {'loss': 0.973, 'learning_rate': 1.7766849666529286e-05, 'epoch': 0.24}
 24%|██▍       | 2499/10395 [7:07:35<16:55:32,  7.72s/it] 24%|██▍       | 2500/10395 [7:07:44<18:00:40,  8.21s/it]                                                         {'loss': 0.9949, 'learning_rate': 1.7764886723436652e-05, 'epoch': 0.24}
 24%|██▍       | 2500/10395 [7:07:44<18:00:40,  8.21s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 24%|██▍       | 2501/10395 [7:09:26<79:57:46, 36.47s/it]                                                         {'loss': 0.9468, 'learning_rate': 1.776292302654541e-05, 'epoch': 0.24}
 24%|██▍       | 2501/10395 [7:09:26<79:57:46, 36.47s/it] 24%|██▍       | 2502/10395 [7:09:37<62:47:15, 28.64s/it]                                                         {'loss': 1.0025, 'learning_rate': 1.7760958576046192e-05, 'epoch': 0.24}
 24%|██▍       | 2502/10395 [7:09:37<62:47:15, 28.64s/it] 24%|██▍       | 2503/10395 [7:09:44<48:31:06, 22.13s/it]                                                         {'loss': 1.0008, 'learning_rate': 1.77589933721297e-05, 'epoch': 0.24}
 24%|██▍       | 2503/10395 [7:09:44<48:31:06, 22.13s/it] 24%|██▍       | 2504/10395 [7:09:52<39:13:11, 17.89s/it]                                                         {'loss': 0.8445, 'learning_rate': 1.7757027414986713e-05, 'epoch': 0.24}
 24%|██▍       | 2504/10395 [7:09:52<39:13:11, 17.89s/it] 24%|██▍       | 2505/10395 [7:09:59<32:23:34, 14.78s/it]                                                         {'loss': 0.9659, 'learning_rate': 1.775506070480808e-05, 'epoch': 0.24}
 24%|██▍       | 2505/10395 [7:09:59<32:23:34, 14.78s/it] 24%|██▍       | 2506/10395 [7:10:07<27:47:35, 12.68s/it]                                                         {'loss': 0.9915, 'learning_rate': 1.7753093241784727e-05, 'epoch': 0.24}
 24%|██▍       | 2506/10395 [7:10:07<27:47:35, 12.68s/it] 24%|██▍       | 2507/10395 [7:10:14<24:20:20, 11.11s/it]                                                         {'loss': 0.987, 'learning_rate': 1.7751125026107648e-05, 'epoch': 0.24}
 24%|██▍       | 2507/10395 [7:10:14<24:20:20, 11.11s/it] 24%|██▍       | 2508/10395 [7:10:22<22:01:42, 10.05s/it]                                                         {'loss': 0.8767, 'learning_rate': 1.774915605796792e-05, 'epoch': 0.24}
 24%|██▍       | 2508/10395 [7:10:22<22:01:42, 10.05s/it] 24%|██▍       | 2509/10395 [7:10:30<20:32:27,  9.38s/it]                                                         {'loss': 0.9958, 'learning_rate': 1.7747186337556677e-05, 'epoch': 0.24}
 24%|██▍       | 2509/10395 [7:10:30<20:32:27,  9.38s/it] 24%|██▍       | 2510/10395 [7:10:38<19:26:39,  8.88s/it]                                                         {'loss': 1.0118, 'learning_rate': 1.7745215865065146e-05, 'epoch': 0.24}
 24%|██▍       | 2510/10395 [7:10:38<19:26:39,  8.88s/it] 24%|██▍       | 2511/10395 [7:10:48<20:36:59,  9.41s/it]                                                         {'loss': 0.9085, 'learning_rate': 1.7743244640684605e-05, 'epoch': 0.24}
 24%|██▍       | 2511/10395 [7:10:48<20:36:59,  9.41s/it] 24%|██▍       | 2512/10395 [7:10:56<19:22:57,  8.85s/it]                                                         {'loss': 1.0068, 'learning_rate': 1.7741272664606424e-05, 'epoch': 0.24}
 24%|██▍       | 2512/10395 [7:10:56<19:22:57,  8.85s/it] 24%|██▍       | 2513/10395 [7:11:04<18:40:59,  8.53s/it]                                                         {'loss': 1.0446, 'learning_rate': 1.7739299937022038e-05, 'epoch': 0.24}
 24%|██▍       | 2513/10395 [7:11:04<18:40:59,  8.53s/it] 24%|██▍       | 2514/10395 [7:11:12<18:21:37,  8.39s/it]                                                         {'loss': 0.9422, 'learning_rate': 1.7737326458122948e-05, 'epoch': 0.24}
 24%|██▍       | 2514/10395 [7:11:12<18:21:37,  8.39s/it] 24%|██▍       | 2515/10395 [7:11:28<23:43:46, 10.84s/it]                                                         {'loss': 0.3524, 'learning_rate': 1.7735352228100743e-05, 'epoch': 0.24}
 24%|██▍       | 2515/10395 [7:11:28<23:43:46, 10.84s/it] 24%|██▍       | 2516/10395 [7:11:36<21:30:10,  9.82s/it]                                                         {'loss': 0.9726, 'learning_rate': 1.7733377247147076e-05, 'epoch': 0.24}
 24%|██▍       | 2516/10395 [7:11:36<21:30:10,  9.82s/it] 24%|██▍       | 2517/10395 [7:11:43<19:47:40,  9.05s/it]                                                         {'loss': 1.0355, 'learning_rate': 1.7731401515453667e-05, 'epoch': 0.24}
 24%|██▍       | 2517/10395 [7:11:43<19:47:40,  9.05s/it] 24%|██▍       | 2518/10395 [7:11:51<19:20:44,  8.84s/it]                                                         {'loss': 1.0351, 'learning_rate': 1.7729425033212326e-05, 'epoch': 0.24}
 24%|██▍       | 2518/10395 [7:11:51<19:20:44,  8.84s/it] 24%|██▍       | 2519/10395 [7:11:59<18:24:15,  8.41s/it]                                                         {'loss': 0.9533, 'learning_rate': 1.772744780061492e-05, 'epoch': 0.24}
 24%|██▍       | 2519/10395 [7:11:59<18:24:15,  8.41s/it] 24%|██▍       | 2520/10395 [7:12:07<18:39:09,  8.53s/it]                                                         {'loss': 0.953, 'learning_rate': 1.7725469817853394e-05, 'epoch': 0.24}
 24%|██▍       | 2520/10395 [7:12:07<18:39:09,  8.53s/it] 24%|██▍       | 2521/10395 [7:12:15<18:14:55,  8.34s/it]                                                         {'loss': 0.955, 'learning_rate': 1.7723491085119767e-05, 'epoch': 0.24}
 24%|██▍       | 2521/10395 [7:12:15<18:14:55,  8.34s/it] 24%|██▍       | 2522/10395 [7:12:23<17:40:00,  8.08s/it]                                                         {'loss': 0.9929, 'learning_rate': 1.772151160260613e-05, 'epoch': 0.24}
 24%|██▍       | 2522/10395 [7:12:23<17:40:00,  8.08s/it] 24%|██▍       | 2523/10395 [7:12:30<17:23:43,  7.96s/it]                                                         {'loss': 0.9651, 'learning_rate': 1.771953137050465e-05, 'epoch': 0.24}
 24%|██▍       | 2523/10395 [7:12:30<17:23:43,  7.96s/it] 24%|██▍       | 2524/10395 [7:12:38<17:21:49,  7.94s/it]                                                         {'loss': 1.0096, 'learning_rate': 1.771755038900756e-05, 'epoch': 0.24}
 24%|██▍       | 2524/10395 [7:12:38<17:21:49,  7.94s/it] 24%|██▍       | 2525/10395 [7:12:46<17:20:59,  7.94s/it]                                                         {'loss': 0.8814, 'learning_rate': 1.771556865830717e-05, 'epoch': 0.24}
 24%|██▍       | 2525/10395 [7:12:46<17:20:59,  7.94s/it] 24%|██▍       | 2526/10395 [7:12:54<17:07:46,  7.84s/it]                                                         {'loss': 0.9921, 'learning_rate': 1.7713586178595865e-05, 'epoch': 0.24}
 24%|██▍       | 2526/10395 [7:12:54<17:07:46,  7.84s/it] 24%|██▍       | 2527/10395 [7:13:02<17:08:33,  7.84s/it]                                                         {'loss': 1.0015, 'learning_rate': 1.7711602950066096e-05, 'epoch': 0.24}
 24%|██▍       | 2527/10395 [7:13:02<17:08:33,  7.84s/it] 24%|██▍       | 2528/10395 [7:13:09<16:44:26,  7.66s/it]                                                         {'loss': 0.9858, 'learning_rate': 1.770961897291039e-05, 'epoch': 0.24}
 24%|██▍       | 2528/10395 [7:13:09<16:44:26,  7.66s/it] 24%|██▍       | 2529/10395 [7:13:18<17:18:40,  7.92s/it]                                                         {'loss': 0.9551, 'learning_rate': 1.7707634247321355e-05, 'epoch': 0.24}
 24%|██▍       | 2529/10395 [7:13:18<17:18:40,  7.92s/it] 24%|██▍       | 2530/10395 [7:13:25<17:04:22,  7.81s/it]                                                         {'loss': 0.9958, 'learning_rate': 1.7705648773491653e-05, 'epoch': 0.24}
 24%|██▍       | 2530/10395 [7:13:25<17:04:22,  7.81s/it] 24%|██▍       | 2531/10395 [7:13:33<16:57:10,  7.76s/it]                                                         {'loss': 0.9806, 'learning_rate': 1.770366255161404e-05, 'epoch': 0.24}
 24%|██▍       | 2531/10395 [7:13:33<16:57:10,  7.76s/it] 24%|██▍       | 2532/10395 [7:13:41<16:58:56,  7.78s/it]                                                         {'loss': 0.9925, 'learning_rate': 1.7701675581881326e-05, 'epoch': 0.24}
 24%|██▍       | 2532/10395 [7:13:41<16:58:56,  7.78s/it] 24%|██▍       | 2533/10395 [7:13:49<17:18:03,  7.92s/it]                                                         {'loss': 0.9645, 'learning_rate': 1.7699687864486407e-05, 'epoch': 0.24}
 24%|██▍       | 2533/10395 [7:13:49<17:18:03,  7.92s/it] 24%|██▍       | 2534/10395 [7:13:57<17:41:44,  8.10s/it]                                                         {'loss': 0.9106, 'learning_rate': 1.7697699399622242e-05, 'epoch': 0.24}
 24%|██▍       | 2534/10395 [7:13:57<17:41:44,  8.10s/it] 24%|██▍       | 2535/10395 [7:14:05<17:23:37,  7.97s/it]                                                         {'loss': 0.9814, 'learning_rate': 1.769571018748187e-05, 'epoch': 0.24}
 24%|██▍       | 2535/10395 [7:14:05<17:23:37,  7.97s/it] 24%|██▍       | 2536/10395 [7:14:12<16:58:45,  7.78s/it]                                                         {'loss': 0.9529, 'learning_rate': 1.7693720228258402e-05, 'epoch': 0.24}
 24%|██▍       | 2536/10395 [7:14:12<16:58:45,  7.78s/it] 24%|██▍       | 2537/10395 [7:14:20<17:02:11,  7.80s/it]                                                         {'loss': 0.9752, 'learning_rate': 1.7691729522145012e-05, 'epoch': 0.24}
 24%|██▍       | 2537/10395 [7:14:20<17:02:11,  7.80s/it] 24%|██▍       | 2538/10395 [7:14:28<16:56:15,  7.76s/it]                                                         {'loss': 1.0127, 'learning_rate': 1.768973806933496e-05, 'epoch': 0.24}
 24%|██▍       | 2538/10395 [7:14:28<16:56:15,  7.76s/it] 24%|██▍       | 2539/10395 [7:14:35<16:38:17,  7.62s/it]                                                         {'loss': 0.9095, 'learning_rate': 1.7687745870021567e-05, 'epoch': 0.24}
 24%|██▍       | 2539/10395 [7:14:35<16:38:17,  7.62s/it] 24%|██▍       | 2540/10395 [7:14:53<23:24:25, 10.73s/it]                                                         {'loss': 0.3699, 'learning_rate': 1.7685752924398234e-05, 'epoch': 0.24}
 24%|██▍       | 2540/10395 [7:14:53<23:24:25, 10.73s/it] 24%|██▍       | 2541/10395 [7:15:01<21:51:26, 10.02s/it]                                                         {'loss': 1.013, 'learning_rate': 1.7683759232658432e-05, 'epoch': 0.24}
 24%|██▍       | 2541/10395 [7:15:01<21:51:26, 10.02s/it] 24%|██▍       | 2542/10395 [7:15:09<20:20:48,  9.33s/it]                                                         {'loss': 0.9529, 'learning_rate': 1.7681764794995704e-05, 'epoch': 0.24}
 24%|██▍       | 2542/10395 [7:15:09<20:20:48,  9.33s/it] 24%|██▍       | 2543/10395 [7:15:17<19:16:58,  8.84s/it]                                                         {'loss': 0.9978, 'learning_rate': 1.7679769611603665e-05, 'epoch': 0.24}
 24%|██▍       | 2543/10395 [7:15:17<19:16:58,  8.84s/it] 24%|██▍       | 2544/10395 [7:15:34<24:44:47, 11.35s/it]                                                         {'loss': 0.4089, 'learning_rate': 1.7677773682676007e-05, 'epoch': 0.24}
 24%|██▍       | 2544/10395 [7:15:34<24:44:47, 11.35s/it] 24%|██▍       | 2545/10395 [7:15:42<22:11:09, 10.17s/it]                                                         {'loss': 0.9896, 'learning_rate': 1.7675777008406485e-05, 'epoch': 0.24}
 24%|██▍       | 2545/10395 [7:15:42<22:11:09, 10.17s/it] 24%|██▍       | 2546/10395 [7:15:50<20:44:10,  9.51s/it]                                                         {'loss': 0.9407, 'learning_rate': 1.7673779588988937e-05, 'epoch': 0.24}
 24%|██▍       | 2546/10395 [7:15:50<20:44:10,  9.51s/it] 25%|██▍       | 2547/10395 [7:15:58<19:59:35,  9.17s/it]                                                         {'loss': 0.8821, 'learning_rate': 1.767178142461726e-05, 'epoch': 0.25}
 25%|██▍       | 2547/10395 [7:15:58<19:59:35,  9.17s/it] 25%|██▍       | 2548/10395 [7:16:07<19:46:45,  9.07s/it]                                                         {'loss': 0.94, 'learning_rate': 1.766978251548544e-05, 'epoch': 0.25}
 25%|██▍       | 2548/10395 [7:16:07<19:46:45,  9.07s/it] 25%|██▍       | 2549/10395 [7:16:15<19:06:09,  8.76s/it]                                                         {'loss': 0.954, 'learning_rate': 1.7667782861787524e-05, 'epoch': 0.25}
 25%|██▍       | 2549/10395 [7:16:15<19:06:09,  8.76s/it] 25%|██▍       | 2550/10395 [7:16:22<18:22:27,  8.43s/it]                                                         {'loss': 0.9699, 'learning_rate': 1.766578246371763e-05, 'epoch': 0.25}
 25%|██▍       | 2550/10395 [7:16:22<18:22:27,  8.43s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 25%|██▍       | 2551/10395 [7:18:02<78:09:41, 35.87s/it]                                                         {'loss': 1.0058, 'learning_rate': 1.7663781321469962e-05, 'epoch': 0.25}
 25%|██▍       | 2551/10395 [7:18:02<78:09:41, 35.87s/it] 25%|██▍       | 2552/10395 [7:18:10<59:26:52, 27.29s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.7661779435238776e-05, 'epoch': 0.25}
 25%|██▍       | 2552/10395 [7:18:10<59:26:52, 27.29s/it] 25%|██▍       | 2553/10395 [7:18:16<46:03:45, 21.15s/it]                                                         {'loss': 0.9702, 'learning_rate': 1.765977680521842e-05, 'epoch': 0.25}
 25%|██▍       | 2553/10395 [7:18:16<46:03:45, 21.15s/it] 25%|██▍       | 2554/10395 [7:18:33<43:21:54, 19.91s/it]                                                         {'loss': 0.3626, 'learning_rate': 1.76577734316033e-05, 'epoch': 0.25}
 25%|██▍       | 2554/10395 [7:18:33<43:21:54, 19.91s/it] 25%|██▍       | 2555/10395 [7:18:41<35:27:30, 16.28s/it]                                                         {'loss': 1.0249, 'learning_rate': 1.7655769314587897e-05, 'epoch': 0.25}
 25%|██▍       | 2555/10395 [7:18:41<35:27:30, 16.28s/it] 25%|██▍       | 2556/10395 [7:18:49<30:07:35, 13.84s/it]                                                         {'loss': 0.9554, 'learning_rate': 1.7653764454366774e-05, 'epoch': 0.25}
 25%|██▍       | 2556/10395 [7:18:49<30:07:35, 13.84s/it] 25%|██▍       | 2557/10395 [7:18:57<26:00:59, 11.95s/it]                                                         {'loss': 0.9578, 'learning_rate': 1.765175885113455e-05, 'epoch': 0.25}
 25%|██▍       | 2557/10395 [7:18:57<26:00:59, 11.95s/it] 25%|██▍       | 2558/10395 [7:19:05<23:10:37, 10.65s/it]                                                         {'loss': 1.0147, 'learning_rate': 1.764975250508593e-05, 'epoch': 0.25}
 25%|██▍       | 2558/10395 [7:19:05<23:10:37, 10.65s/it] 25%|██▍       | 2559/10395 [7:19:13<22:05:00, 10.15s/it]                                                         {'loss': 0.9217, 'learning_rate': 1.764774541641568e-05, 'epoch': 0.25}
 25%|██▍       | 2559/10395 [7:19:14<22:05:00, 10.15s/it] 25%|██▍       | 2560/10395 [7:19:21<20:14:39,  9.30s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.7645737585318653e-05, 'epoch': 0.25}
 25%|██▍       | 2560/10395 [7:19:21<20:14:39,  9.30s/it] 25%|██▍       | 2561/10395 [7:19:30<19:52:12,  9.13s/it]                                                         {'loss': 0.9273, 'learning_rate': 1.7643729011989763e-05, 'epoch': 0.25}
 25%|██▍       | 2561/10395 [7:19:30<19:52:12,  9.13s/it] 25%|██▍       | 2562/10395 [7:19:38<19:36:08,  9.01s/it]                                                         {'loss': 0.995, 'learning_rate': 1.764171969662399e-05, 'epoch': 0.25}
 25%|██▍       | 2562/10395 [7:19:38<19:36:08,  9.01s/it] 25%|██▍       | 2563/10395 [7:19:46<18:43:36,  8.61s/it]                                                         {'loss': 0.9832, 'learning_rate': 1.76397096394164e-05, 'epoch': 0.25}
 25%|██▍       | 2563/10395 [7:19:46<18:43:36,  8.61s/it] 25%|██▍       | 2564/10395 [7:19:53<17:58:36,  8.26s/it]                                                         {'loss': 1.0241, 'learning_rate': 1.7637698840562127e-05, 'epoch': 0.25}
 25%|██▍       | 2564/10395 [7:19:53<17:58:36,  8.26s/it] 25%|██▍       | 2565/10395 [7:20:01<17:35:11,  8.09s/it]                                                         {'loss': 0.9943, 'learning_rate': 1.7635687300256374e-05, 'epoch': 0.25}
 25%|██▍       | 2565/10395 [7:20:01<17:35:11,  8.09s/it] 25%|██▍       | 2566/10395 [7:20:10<18:17:56,  8.41s/it]                                                         {'loss': 0.8545, 'learning_rate': 1.763367501869441e-05, 'epoch': 0.25}
 25%|██▍       | 2566/10395 [7:20:10<18:17:56,  8.41s/it] 25%|██▍       | 2567/10395 [7:20:18<18:02:56,  8.30s/it]                                                         {'loss': 0.8985, 'learning_rate': 1.763166199607159e-05, 'epoch': 0.25}
 25%|██▍       | 2567/10395 [7:20:18<18:02:56,  8.30s/it] 25%|██▍       | 2568/10395 [7:20:25<17:17:14,  7.95s/it]                                                         {'loss': 1.0509, 'learning_rate': 1.7629648232583334e-05, 'epoch': 0.25}
 25%|██▍       | 2568/10395 [7:20:25<17:17:14,  7.95s/it] 25%|██▍       | 2569/10395 [7:20:33<17:10:15,  7.90s/it]                                                         {'loss': 1.0327, 'learning_rate': 1.762763372842513e-05, 'epoch': 0.25}
 25%|██▍       | 2569/10395 [7:20:33<17:10:15,  7.90s/it] 25%|██▍       | 2570/10395 [7:20:42<17:55:07,  8.24s/it]                                                         {'loss': 0.8848, 'learning_rate': 1.7625618483792543e-05, 'epoch': 0.25}
 25%|██▍       | 2570/10395 [7:20:42<17:55:07,  8.24s/it] 25%|██▍       | 2571/10395 [7:20:50<17:35:21,  8.09s/it]                                                         {'loss': 0.9729, 'learning_rate': 1.7623602498881217e-05, 'epoch': 0.25}
 25%|██▍       | 2571/10395 [7:20:50<17:35:21,  8.09s/it] 25%|██▍       | 2572/10395 [7:20:57<17:05:36,  7.87s/it]                                                         {'loss': 0.988, 'learning_rate': 1.7621585773886844e-05, 'epoch': 0.25}
 25%|██▍       | 2572/10395 [7:20:57<17:05:36,  7.87s/it] 25%|██▍       | 2573/10395 [7:21:05<17:16:06,  7.95s/it]                                                         {'loss': 0.903, 'learning_rate': 1.7619568309005214e-05, 'epoch': 0.25}
 25%|██▍       | 2573/10395 [7:21:05<17:16:06,  7.95s/it] 25%|██▍       | 2574/10395 [7:21:13<16:46:45,  7.72s/it]                                                         {'loss': 0.9552, 'learning_rate': 1.7617550104432175e-05, 'epoch': 0.25}
 25%|██▍       | 2574/10395 [7:21:13<16:46:45,  7.72s/it] 25%|██▍       | 2575/10395 [7:21:21<16:57:26,  7.81s/it]                                                         {'loss': 0.9151, 'learning_rate': 1.761553116036365e-05, 'epoch': 0.25}
 25%|██▍       | 2575/10395 [7:21:21<16:57:26,  7.81s/it] 25%|██▍       | 2576/10395 [7:21:38<23:25:32, 10.79s/it]                                                         {'loss': 0.3444, 'learning_rate': 1.7613511476995637e-05, 'epoch': 0.25}
 25%|██▍       | 2576/10395 [7:21:38<23:25:32, 10.79s/it] 25%|██▍       | 2577/10395 [7:21:46<21:29:30,  9.90s/it]                                                         {'loss': 0.9331, 'learning_rate': 1.76114910545242e-05, 'epoch': 0.25}
 25%|██▍       | 2577/10395 [7:21:46<21:29:30,  9.90s/it] 25%|██▍       | 2578/10395 [7:21:53<19:43:48,  9.09s/it]                                                         {'loss': 0.9867, 'learning_rate': 1.7609469893145475e-05, 'epoch': 0.25}
 25%|██▍       | 2578/10395 [7:21:53<19:43:48,  9.09s/it] 25%|██▍       | 2579/10395 [7:22:01<18:39:41,  8.60s/it]                                                         {'loss': 0.9318, 'learning_rate': 1.7607447993055676e-05, 'epoch': 0.25}
 25%|██▍       | 2579/10395 [7:22:01<18:39:41,  8.60s/it] 25%|██▍       | 2580/10395 [7:22:10<19:08:07,  8.81s/it]                                                         {'loss': 0.8905, 'learning_rate': 1.7605425354451085e-05, 'epoch': 0.25}
 25%|██▍       | 2580/10395 [7:22:10<19:08:07,  8.81s/it] 25%|██▍       | 2581/10395 [7:22:18<18:10:37,  8.37s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.760340197752805e-05, 'epoch': 0.25}
 25%|██▍       | 2581/10395 [7:22:18<18:10:37,  8.37s/it] 25%|██▍       | 2582/10395 [7:22:26<18:03:30,  8.32s/it]                                                         {'loss': 0.9269, 'learning_rate': 1.7601377862483e-05, 'epoch': 0.25}
 25%|██▍       | 2582/10395 [7:22:26<18:03:30,  8.32s/it] 25%|██▍       | 2583/10395 [7:22:33<17:37:20,  8.12s/it]                                                         {'loss': 0.9194, 'learning_rate': 1.7599353009512432e-05, 'epoch': 0.25}
 25%|██▍       | 2583/10395 [7:22:33<17:37:20,  8.12s/it] 25%|██▍       | 2584/10395 [7:22:41<17:26:28,  8.04s/it]                                                         {'loss': 0.9111, 'learning_rate': 1.7597327418812912e-05, 'epoch': 0.25}
 25%|██▍       | 2584/10395 [7:22:41<17:26:28,  8.04s/it] 25%|██▍       | 2585/10395 [7:22:49<17:13:15,  7.94s/it]                                                         {'loss': 0.862, 'learning_rate': 1.7595301090581083e-05, 'epoch': 0.25}
 25%|██▍       | 2585/10395 [7:22:49<17:13:15,  7.94s/it] 25%|██▍       | 2586/10395 [7:22:57<17:04:25,  7.87s/it]                                                         {'loss': 0.9539, 'learning_rate': 1.7593274025013657e-05, 'epoch': 0.25}
 25%|██▍       | 2586/10395 [7:22:57<17:04:25,  7.87s/it] 25%|██▍       | 2587/10395 [7:23:05<17:19:39,  7.99s/it]                                                         {'loss': 0.9233, 'learning_rate': 1.7591246222307413e-05, 'epoch': 0.25}
 25%|██▍       | 2587/10395 [7:23:05<17:19:39,  7.99s/it] 25%|██▍       | 2588/10395 [7:23:13<17:37:40,  8.13s/it]                                                         {'loss': 0.9834, 'learning_rate': 1.7589217682659208e-05, 'epoch': 0.25}
 25%|██▍       | 2588/10395 [7:23:13<17:37:40,  8.13s/it] 25%|██▍       | 2589/10395 [7:23:21<17:23:30,  8.02s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.758718840626597e-05, 'epoch': 0.25}
 25%|██▍       | 2589/10395 [7:23:21<17:23:30,  8.02s/it] 25%|██▍       | 2590/10395 [7:23:30<17:41:11,  8.16s/it]                                                         {'loss': 0.9907, 'learning_rate': 1.7585158393324696e-05, 'epoch': 0.25}
 25%|██▍       | 2590/10395 [7:23:30<17:41:11,  8.16s/it] 25%|██▍       | 2591/10395 [7:23:37<17:12:56,  7.94s/it]                                                         {'loss': 0.9364, 'learning_rate': 1.7583127644032453e-05, 'epoch': 0.25}
 25%|██▍       | 2591/10395 [7:23:37<17:12:56,  7.94s/it] 25%|██▍       | 2592/10395 [7:23:45<17:03:44,  7.87s/it]                                                         {'loss': 0.9195, 'learning_rate': 1.7581096158586386e-05, 'epoch': 0.25}
 25%|██▍       | 2592/10395 [7:23:45<17:03:44,  7.87s/it] 25%|██▍       | 2593/10395 [7:23:52<16:34:38,  7.65s/it]                                                         {'loss': 1.0392, 'learning_rate': 1.7579063937183702e-05, 'epoch': 0.25}
 25%|██▍       | 2593/10395 [7:23:52<16:34:38,  7.65s/it] 25%|██▍       | 2594/10395 [7:24:00<16:39:17,  7.69s/it]                                                         {'loss': 0.9211, 'learning_rate': 1.757703098002169e-05, 'epoch': 0.25}
 25%|██▍       | 2594/10395 [7:24:00<16:39:17,  7.69s/it] 25%|██▍       | 2595/10395 [7:24:07<16:41:56,  7.71s/it]                                                         {'loss': 0.9222, 'learning_rate': 1.75749972872977e-05, 'epoch': 0.25}
 25%|██▍       | 2595/10395 [7:24:07<16:41:56,  7.71s/it] 25%|██▍       | 2596/10395 [7:24:16<17:05:36,  7.89s/it]                                                         {'loss': 0.9684, 'learning_rate': 1.7572962859209163e-05, 'epoch': 0.25}
 25%|██▍       | 2596/10395 [7:24:16<17:05:36,  7.89s/it] 25%|██▍       | 2597/10395 [7:24:24<17:08:56,  7.92s/it]                                                         {'loss': 1.0064, 'learning_rate': 1.7570927695953574e-05, 'epoch': 0.25}
 25%|██▍       | 2597/10395 [7:24:24<17:08:56,  7.92s/it] 25%|██▍       | 2598/10395 [7:24:31<17:01:34,  7.86s/it]                                                         {'loss': 1.0066, 'learning_rate': 1.7568891797728504e-05, 'epoch': 0.25}
 25%|██▍       | 2598/10395 [7:24:31<17:01:34,  7.86s/it] 25%|██▌       | 2599/10395 [7:24:39<16:56:05,  7.82s/it]                                                         {'loss': 1.0389, 'learning_rate': 1.7566855164731594e-05, 'epoch': 0.25}
 25%|██▌       | 2599/10395 [7:24:39<16:56:05,  7.82s/it] 25%|██▌       | 2600/10395 [7:24:48<17:19:57,  8.00s/it]                                                         {'loss': 0.9899, 'learning_rate': 1.7564817797160553e-05, 'epoch': 0.25}
 25%|██▌       | 2600/10395 [7:24:48<17:19:57,  8.00s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 25%|██▌       | 2601/10395 [7:26:32<80:01:16, 36.96s/it]                                                         {'loss': 0.9774, 'learning_rate': 1.7562779695213167e-05, 'epoch': 0.25}
 25%|██▌       | 2601/10395 [7:26:32<80:01:16, 36.96s/it] 25%|██▌       | 2602/10395 [7:26:40<61:13:17, 28.28s/it]                                                         {'loss': 0.8599, 'learning_rate': 1.7560740859087292e-05, 'epoch': 0.25}
 25%|██▌       | 2602/10395 [7:26:40<61:13:17, 28.28s/it] 25%|██▌       | 2603/10395 [7:26:48<48:02:57, 22.20s/it]                                                         {'loss': 0.8391, 'learning_rate': 1.755870128898085e-05, 'epoch': 0.25}
 25%|██▌       | 2603/10395 [7:26:48<48:02:57, 22.20s/it] 25%|██▌       | 2604/10395 [7:26:56<38:36:39, 17.84s/it]                                                         {'loss': 1.0126, 'learning_rate': 1.755666098509184e-05, 'epoch': 0.25}
 25%|██▌       | 2604/10395 [7:26:56<38:36:39, 17.84s/it] 25%|██▌       | 2605/10395 [7:27:04<31:59:53, 14.79s/it]                                                         {'loss': 0.9464, 'learning_rate': 1.7554619947618328e-05, 'epoch': 0.25}
 25%|██▌       | 2605/10395 [7:27:04<31:59:53, 14.79s/it] 25%|██▌       | 2606/10395 [7:27:11<27:31:20, 12.72s/it]                                                         {'loss': 0.9224, 'learning_rate': 1.755257817675846e-05, 'epoch': 0.25}
 25%|██▌       | 2606/10395 [7:27:11<27:31:20, 12.72s/it] 25%|██▌       | 2607/10395 [7:27:19<24:04:46, 11.13s/it]                                                         {'loss': 0.9619, 'learning_rate': 1.755053567271044e-05, 'epoch': 0.25}
 25%|██▌       | 2607/10395 [7:27:19<24:04:46, 11.13s/it] 25%|██▌       | 2608/10395 [7:27:26<21:38:32, 10.01s/it]                                                         {'loss': 0.9353, 'learning_rate': 1.7548492435672553e-05, 'epoch': 0.25}
 25%|██▌       | 2608/10395 [7:27:26<21:38:32, 10.01s/it] 25%|██▌       | 2609/10395 [7:27:44<26:44:23, 12.36s/it]                                                         {'loss': 0.4165, 'learning_rate': 1.754644846584315e-05, 'epoch': 0.25}
 25%|██▌       | 2609/10395 [7:27:44<26:44:23, 12.36s/it] 25%|██▌       | 2610/10395 [7:27:52<23:42:04, 10.96s/it]                                                         {'loss': 0.9576, 'learning_rate': 1.7544403763420657e-05, 'epoch': 0.25}
 25%|██▌       | 2610/10395 [7:27:52<23:42:04, 10.96s/it] 25%|██▌       | 2611/10395 [7:28:10<28:15:21, 13.07s/it]                                                         {'loss': 0.4354, 'learning_rate': 1.7542358328603574e-05, 'epoch': 0.25}
 25%|██▌       | 2611/10395 [7:28:10<28:15:21, 13.07s/it] 25%|██▌       | 2612/10395 [7:28:17<24:36:36, 11.38s/it]                                                         {'loss': 1.0291, 'learning_rate': 1.754031216159046e-05, 'epoch': 0.25}
 25%|██▌       | 2612/10395 [7:28:17<24:36:36, 11.38s/it] 25%|██▌       | 2613/10395 [7:28:26<22:59:12, 10.63s/it]                                                         {'loss': 0.9136, 'learning_rate': 1.753826526257995e-05, 'epoch': 0.25}
 25%|██▌       | 2613/10395 [7:28:26<22:59:12, 10.63s/it] 25%|██▌       | 2614/10395 [7:28:34<21:19:51,  9.87s/it]                                                         {'loss': 0.9756, 'learning_rate': 1.7536217631770762e-05, 'epoch': 0.25}
 25%|██▌       | 2614/10395 [7:28:34<21:19:51,  9.87s/it] 25%|██▌       | 2615/10395 [7:28:43<20:36:54,  9.54s/it]                                                         {'loss': 0.87, 'learning_rate': 1.7534169269361672e-05, 'epoch': 0.25}
 25%|██▌       | 2615/10395 [7:28:43<20:36:54,  9.54s/it] 25%|██▌       | 2616/10395 [7:28:51<19:43:46,  9.13s/it]                                                         {'loss': 0.992, 'learning_rate': 1.7532120175551528e-05, 'epoch': 0.25}
 25%|██▌       | 2616/10395 [7:28:51<19:43:46,  9.13s/it] 25%|██▌       | 2617/10395 [7:29:00<19:43:50,  9.13s/it]                                                         {'loss': 1.01, 'learning_rate': 1.7530070350539254e-05, 'epoch': 0.25}
 25%|██▌       | 2617/10395 [7:29:00<19:43:50,  9.13s/it] 25%|██▌       | 2618/10395 [7:29:08<19:06:14,  8.84s/it]                                                         {'loss': 1.042, 'learning_rate': 1.7528019794523844e-05, 'epoch': 0.25}
 25%|██▌       | 2618/10395 [7:29:08<19:06:14,  8.84s/it] 25%|██▌       | 2619/10395 [7:29:16<18:31:34,  8.58s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.7525968507704356e-05, 'epoch': 0.25}
 25%|██▌       | 2619/10395 [7:29:16<18:31:34,  8.58s/it] 25%|██▌       | 2620/10395 [7:29:26<19:02:27,  8.82s/it]                                                         {'loss': 0.9736, 'learning_rate': 1.752391649027993e-05, 'epoch': 0.25}
 25%|██▌       | 2620/10395 [7:29:26<19:02:27,  8.82s/it] 25%|██▌       | 2621/10395 [7:29:33<18:09:13,  8.41s/it]                                                         {'loss': 1.0207, 'learning_rate': 1.7521863742449774e-05, 'epoch': 0.25}
 25%|██▌       | 2621/10395 [7:29:33<18:09:13,  8.41s/it] 25%|██▌       | 2622/10395 [7:29:41<17:30:52,  8.11s/it]                                                         {'loss': 0.9935, 'learning_rate': 1.7519810264413154e-05, 'epoch': 0.25}
 25%|██▌       | 2622/10395 [7:29:41<17:30:52,  8.11s/it] 25%|██▌       | 2623/10395 [7:29:48<17:16:44,  8.00s/it]                                                         {'loss': 1.008, 'learning_rate': 1.751775605636943e-05, 'epoch': 0.25}
 25%|██▌       | 2623/10395 [7:29:48<17:16:44,  8.00s/it] 25%|██▌       | 2624/10395 [7:29:56<17:04:42,  7.91s/it]                                                         {'loss': 0.9842, 'learning_rate': 1.7515701118518004e-05, 'epoch': 0.25}
 25%|██▌       | 2624/10395 [7:29:56<17:04:42,  7.91s/it] 25%|██▌       | 2625/10395 [7:30:04<16:47:07,  7.78s/it]                                                         {'loss': 0.9051, 'learning_rate': 1.751364545105838e-05, 'epoch': 0.25}
 25%|██▌       | 2625/10395 [7:30:04<16:47:07,  7.78s/it] 25%|██▌       | 2626/10395 [7:30:11<16:49:47,  7.80s/it]                                                         {'loss': 0.9774, 'learning_rate': 1.7511589054190112e-05, 'epoch': 0.25}
 25%|██▌       | 2626/10395 [7:30:11<16:49:47,  7.80s/it] 25%|██▌       | 2627/10395 [7:30:19<16:39:54,  7.72s/it]                                                         {'loss': 1.0018, 'learning_rate': 1.7509531928112832e-05, 'epoch': 0.25}
 25%|██▌       | 2627/10395 [7:30:19<16:39:54,  7.72s/it] 25%|██▌       | 2628/10395 [7:30:26<16:31:20,  7.66s/it]                                                         {'loss': 0.954, 'learning_rate': 1.750747407302624e-05, 'epoch': 0.25}
 25%|██▌       | 2628/10395 [7:30:26<16:31:20,  7.66s/it] 25%|██▌       | 2629/10395 [7:30:34<16:28:01,  7.63s/it]                                                         {'loss': 0.924, 'learning_rate': 1.750541548913011e-05, 'epoch': 0.25}
 25%|██▌       | 2629/10395 [7:30:34<16:28:01,  7.63s/it] 25%|██▌       | 2630/10395 [7:30:42<16:23:02,  7.60s/it]                                                         {'loss': 0.9784, 'learning_rate': 1.750335617662428e-05, 'epoch': 0.25}
 25%|██▌       | 2630/10395 [7:30:42<16:23:02,  7.60s/it] 25%|██▌       | 2631/10395 [7:30:49<16:27:41,  7.63s/it]                                                         {'loss': 0.9303, 'learning_rate': 1.7501296135708668e-05, 'epoch': 0.25}
 25%|██▌       | 2631/10395 [7:30:49<16:27:41,  7.63s/it] 25%|██▌       | 2632/10395 [7:30:57<16:42:57,  7.75s/it]                                                         {'loss': 0.9744, 'learning_rate': 1.7499235366583258e-05, 'epoch': 0.25}
 25%|██▌       | 2632/10395 [7:30:57<16:42:57,  7.75s/it] 25%|██▌       | 2633/10395 [7:31:05<16:35:55,  7.70s/it]                                                         {'loss': 0.9266, 'learning_rate': 1.7497173869448104e-05, 'epoch': 0.25}
 25%|██▌       | 2633/10395 [7:31:05<16:35:55,  7.70s/it] 25%|██▌       | 2634/10395 [7:31:13<16:42:11,  7.75s/it]                                                         {'loss': 0.9224, 'learning_rate': 1.7495111644503336e-05, 'epoch': 0.25}
 25%|██▌       | 2634/10395 [7:31:13<16:42:11,  7.75s/it] 25%|██▌       | 2635/10395 [7:31:20<16:40:16,  7.73s/it]                                                         {'loss': 0.8238, 'learning_rate': 1.749304869194914e-05, 'epoch': 0.25}
 25%|██▌       | 2635/10395 [7:31:20<16:40:16,  7.73s/it] 25%|██▌       | 2636/10395 [7:31:28<16:35:55,  7.70s/it]                                                         {'loss': 0.9986, 'learning_rate': 1.7490985011985795e-05, 'epoch': 0.25}
 25%|██▌       | 2636/10395 [7:31:28<16:35:55,  7.70s/it] 25%|██▌       | 2637/10395 [7:31:36<16:25:37,  7.62s/it]                                                         {'loss': 0.9745, 'learning_rate': 1.7488920604813633e-05, 'epoch': 0.25}
 25%|██▌       | 2637/10395 [7:31:36<16:25:37,  7.62s/it] 25%|██▌       | 2638/10395 [7:31:44<17:00:32,  7.89s/it]                                                         {'loss': 0.8501, 'learning_rate': 1.7486855470633058e-05, 'epoch': 0.25}
 25%|██▌       | 2638/10395 [7:31:44<17:00:32,  7.89s/it] 25%|██▌       | 2639/10395 [7:31:52<16:53:14,  7.84s/it]                                                         {'loss': 0.9387, 'learning_rate': 1.7484789609644556e-05, 'epoch': 0.25}
 25%|██▌       | 2639/10395 [7:31:52<16:53:14,  7.84s/it] 25%|██▌       | 2640/10395 [7:32:00<17:19:29,  8.04s/it]                                                         {'loss': 0.9507, 'learning_rate': 1.7482723022048675e-05, 'epoch': 0.25}
 25%|██▌       | 2640/10395 [7:32:00<17:19:29,  8.04s/it] 25%|██▌       | 2641/10395 [7:32:08<17:08:29,  7.96s/it]                                                         {'loss': 1.0438, 'learning_rate': 1.7480655708046032e-05, 'epoch': 0.25}
 25%|██▌       | 2641/10395 [7:32:08<17:08:29,  7.96s/it] 25%|██▌       | 2642/10395 [7:32:16<17:28:41,  8.12s/it]                                                         {'loss': 0.9599, 'learning_rate': 1.747858766783732e-05, 'epoch': 0.25}
 25%|██▌       | 2642/10395 [7:32:17<17:28:41,  8.12s/it] 25%|██▌       | 2643/10395 [7:32:24<17:04:10,  7.93s/it]                                                         {'loss': 0.9406, 'learning_rate': 1.74765189016233e-05, 'epoch': 0.25}
 25%|██▌       | 2643/10395 [7:32:24<17:04:10,  7.93s/it] 25%|██▌       | 2644/10395 [7:32:32<17:06:55,  7.95s/it]                                                         {'loss': 1.025, 'learning_rate': 1.7474449409604802e-05, 'epoch': 0.25}
 25%|██▌       | 2644/10395 [7:32:32<17:06:55,  7.95s/it] 25%|██▌       | 2645/10395 [7:32:40<17:00:29,  7.90s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.747237919198273e-05, 'epoch': 0.25}
 25%|██▌       | 2645/10395 [7:32:40<17:00:29,  7.90s/it] 25%|██▌       | 2646/10395 [7:32:48<16:58:32,  7.89s/it]                                                         {'loss': 0.9131, 'learning_rate': 1.747030824895805e-05, 'epoch': 0.25}
 25%|██▌       | 2646/10395 [7:32:48<16:58:32,  7.89s/it] 25%|██▌       | 2647/10395 [7:32:56<17:07:46,  7.96s/it]                                                         {'loss': 1.0673, 'learning_rate': 1.746823658073181e-05, 'epoch': 0.25}
 25%|██▌       | 2647/10395 [7:32:56<17:07:46,  7.96s/it] 25%|██▌       | 2648/10395 [7:33:03<16:52:33,  7.84s/it]                                                         {'loss': 1.0174, 'learning_rate': 1.7466164187505126e-05, 'epoch': 0.25}
 25%|██▌       | 2648/10395 [7:33:03<16:52:33,  7.84s/it] 25%|██▌       | 2649/10395 [7:33:11<16:50:47,  7.83s/it]                                                         {'loss': 0.9311, 'learning_rate': 1.7464091069479175e-05, 'epoch': 0.25}
 25%|██▌       | 2649/10395 [7:33:11<16:50:47,  7.83s/it] 25%|██▌       | 2650/10395 [7:33:19<16:40:21,  7.75s/it]                                                         {'loss': 0.9859, 'learning_rate': 1.7462017226855213e-05, 'epoch': 0.25}
 25%|██▌       | 2650/10395 [7:33:19<16:40:21,  7.75s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 26%|██▌       | 2651/10395 [7:34:59<76:10:40, 35.41s/it]                                                         {'loss': 0.943, 'learning_rate': 1.7459942659834566e-05, 'epoch': 0.26}
 26%|██▌       | 2651/10395 [7:34:59<76:10:40, 35.41s/it] 26%|██▌       | 2652/10395 [7:35:06<58:15:06, 27.08s/it]                                                         {'loss': 0.9821, 'learning_rate': 1.745786736861863e-05, 'epoch': 0.26}
 26%|██▌       | 2652/10395 [7:35:06<58:15:06, 27.08s/it] 26%|██▌       | 2653/10395 [7:35:14<45:28:05, 21.14s/it]                                                         {'loss': 1.0282, 'learning_rate': 1.7455791353408866e-05, 'epoch': 0.26}
 26%|██▌       | 2653/10395 [7:35:14<45:28:05, 21.14s/it] 26%|██▌       | 2654/10395 [7:35:21<36:37:12, 17.03s/it]                                                         {'loss': 0.87, 'learning_rate': 1.745371461440681e-05, 'epoch': 0.26}
 26%|██▌       | 2654/10395 [7:35:21<36:37:12, 17.03s/it] 26%|██▌       | 2655/10395 [7:35:29<30:38:39, 14.25s/it]                                                         {'loss': 0.9102, 'learning_rate': 1.745163715181407e-05, 'epoch': 0.26}
 26%|██▌       | 2655/10395 [7:35:29<30:38:39, 14.25s/it] 26%|██▌       | 2656/10395 [7:35:36<26:07:56, 12.16s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.7449558965832315e-05, 'epoch': 0.26}
 26%|██▌       | 2656/10395 [7:35:36<26:07:56, 12.16s/it] 26%|██▌       | 2657/10395 [7:35:43<23:02:19, 10.72s/it]                                                         {'loss': 0.9789, 'learning_rate': 1.7447480056663296e-05, 'epoch': 0.26}
 26%|██▌       | 2657/10395 [7:35:43<23:02:19, 10.72s/it] 26%|██▌       | 2658/10395 [7:35:53<22:26:08, 10.44s/it]                                                         {'loss': 0.9241, 'learning_rate': 1.744540042450883e-05, 'epoch': 0.26}
 26%|██▌       | 2658/10395 [7:35:53<22:26:08, 10.44s/it] 26%|██▌       | 2659/10395 [7:36:09<25:57:29, 12.08s/it]                                                         {'loss': 0.4086, 'learning_rate': 1.7443320069570805e-05, 'epoch': 0.26}
 26%|██▌       | 2659/10395 [7:36:09<25:57:29, 12.08s/it] 26%|██▌       | 2660/10395 [7:36:17<23:12:00, 10.80s/it]                                                         {'loss': 0.9966, 'learning_rate': 1.7441238992051167e-05, 'epoch': 0.26}
 26%|██▌       | 2660/10395 [7:36:17<23:12:00, 10.80s/it] 26%|██▌       | 2661/10395 [7:36:26<21:52:00, 10.18s/it]                                                         {'loss': 1.0257, 'learning_rate': 1.7439157192151958e-05, 'epoch': 0.26}
 26%|██▌       | 2661/10395 [7:36:26<21:52:00, 10.18s/it] 26%|██▌       | 2662/10395 [7:36:34<20:31:29,  9.56s/it]                                                         {'loss': 0.9487, 'learning_rate': 1.743707467007526e-05, 'epoch': 0.26}
 26%|██▌       | 2662/10395 [7:36:34<20:31:29,  9.56s/it] 26%|██▌       | 2663/10395 [7:36:42<19:29:04,  9.07s/it]                                                         {'loss': 0.9682, 'learning_rate': 1.7434991426023248e-05, 'epoch': 0.26}
 26%|██▌       | 2663/10395 [7:36:42<19:29:04,  9.07s/it] 26%|██▌       | 2664/10395 [7:36:50<19:07:30,  8.91s/it]                                                         {'loss': 0.9569, 'learning_rate': 1.7432907460198157e-05, 'epoch': 0.26}
 26%|██▌       | 2664/10395 [7:36:50<19:07:30,  8.91s/it] 26%|██▌       | 2665/10395 [7:36:59<18:43:40,  8.72s/it]                                                         {'loss': 1.0254, 'learning_rate': 1.7430822772802293e-05, 'epoch': 0.26}
 26%|██▌       | 2665/10395 [7:36:59<18:43:40,  8.72s/it] 26%|██▌       | 2666/10395 [7:37:06<17:48:42,  8.30s/it]                                                         {'loss': 1.0004, 'learning_rate': 1.7428737364038036e-05, 'epoch': 0.26}
 26%|██▌       | 2666/10395 [7:37:06<17:48:42,  8.30s/it] 26%|██▌       | 2667/10395 [7:37:14<17:28:55,  8.14s/it]                                                         {'loss': 1.0114, 'learning_rate': 1.742665123410783e-05, 'epoch': 0.26}
 26%|██▌       | 2667/10395 [7:37:14<17:28:55,  8.14s/it] 26%|██▌       | 2668/10395 [7:37:22<17:28:37,  8.14s/it]                                                         {'loss': 0.9172, 'learning_rate': 1.742456438321419e-05, 'epoch': 0.26}
 26%|██▌       | 2668/10395 [7:37:22<17:28:37,  8.14s/it] 26%|██▌       | 2669/10395 [7:37:30<17:26:30,  8.13s/it]                                                         {'loss': 1.0264, 'learning_rate': 1.742247681155971e-05, 'epoch': 0.26}
 26%|██▌       | 2669/10395 [7:37:30<17:26:30,  8.13s/it] 26%|██▌       | 2670/10395 [7:37:38<17:16:22,  8.05s/it]                                                         {'loss': 0.9097, 'learning_rate': 1.742038851934704e-05, 'epoch': 0.26}
 26%|██▌       | 2670/10395 [7:37:38<17:16:22,  8.05s/it] 26%|██▌       | 2671/10395 [7:37:45<17:00:29,  7.93s/it]                                                         {'loss': 0.9501, 'learning_rate': 1.7418299506778914e-05, 'epoch': 0.26}
 26%|██▌       | 2671/10395 [7:37:45<17:00:29,  7.93s/it] 26%|██▌       | 2672/10395 [7:37:54<17:33:33,  8.19s/it]                                                         {'loss': 0.8957, 'learning_rate': 1.7416209774058124e-05, 'epoch': 0.26}
 26%|██▌       | 2672/10395 [7:37:54<17:33:33,  8.19s/it] 26%|██▌       | 2673/10395 [7:38:02<17:05:14,  7.97s/it]                                                         {'loss': 0.9409, 'learning_rate': 1.7414119321387538e-05, 'epoch': 0.26}
 26%|██▌       | 2673/10395 [7:38:02<17:05:14,  7.97s/it] 26%|██▌       | 2674/10395 [7:38:10<17:14:03,  8.04s/it]                                                         {'loss': 0.9163, 'learning_rate': 1.741202814897009e-05, 'epoch': 0.26}
 26%|██▌       | 2674/10395 [7:38:10<17:14:03,  8.04s/it] 26%|██▌       | 2675/10395 [7:38:17<16:58:53,  7.92s/it]                                                         {'loss': 0.9983, 'learning_rate': 1.740993625700879e-05, 'epoch': 0.26}
 26%|██▌       | 2675/10395 [7:38:17<16:58:53,  7.92s/it] 26%|██▌       | 2676/10395 [7:38:25<16:46:29,  7.82s/it]                                                         {'loss': 1.0331, 'learning_rate': 1.740784364570671e-05, 'epoch': 0.26}
 26%|██▌       | 2676/10395 [7:38:25<16:46:29,  7.82s/it] 26%|██▌       | 2677/10395 [7:38:33<16:37:59,  7.76s/it]                                                         {'loss': 0.872, 'learning_rate': 1.7405750315267003e-05, 'epoch': 0.26}
 26%|██▌       | 2677/10395 [7:38:33<16:37:59,  7.76s/it] 26%|██▌       | 2678/10395 [7:38:40<16:36:37,  7.75s/it]                                                         {'loss': 0.972, 'learning_rate': 1.7403656265892882e-05, 'epoch': 0.26}
 26%|██▌       | 2678/10395 [7:38:40<16:36:37,  7.75s/it] 26%|██▌       | 2679/10395 [7:38:48<16:17:01,  7.60s/it]                                                         {'loss': 0.9845, 'learning_rate': 1.7401561497787632e-05, 'epoch': 0.26}
 26%|██▌       | 2679/10395 [7:38:48<16:17:01,  7.60s/it] 26%|██▌       | 2680/10395 [7:38:55<16:26:13,  7.67s/it]                                                         {'loss': 0.9186, 'learning_rate': 1.7399466011154603e-05, 'epoch': 0.26}
 26%|██▌       | 2680/10395 [7:38:55<16:26:13,  7.67s/it] 26%|██▌       | 2681/10395 [7:39:03<16:24:53,  7.66s/it]                                                         {'loss': 0.9887, 'learning_rate': 1.7397369806197234e-05, 'epoch': 0.26}
 26%|██▌       | 2681/10395 [7:39:03<16:24:53,  7.66s/it] 26%|██▌       | 2682/10395 [7:39:11<16:35:11,  7.74s/it]                                                         {'loss': 0.949, 'learning_rate': 1.739527288311901e-05, 'epoch': 0.26}
 26%|██▌       | 2682/10395 [7:39:11<16:35:11,  7.74s/it] 26%|██▌       | 2683/10395 [7:39:20<17:05:15,  7.98s/it]                                                         {'loss': 0.9909, 'learning_rate': 1.73931752421235e-05, 'epoch': 0.26}
 26%|██▌       | 2683/10395 [7:39:20<17:05:15,  7.98s/it] 26%|██▌       | 2684/10395 [7:39:28<17:15:52,  8.06s/it]                                                         {'loss': 0.8588, 'learning_rate': 1.739107688341433e-05, 'epoch': 0.26}
 26%|██▌       | 2684/10395 [7:39:28<17:15:52,  8.06s/it] 26%|██▌       | 2685/10395 [7:39:35<16:54:35,  7.90s/it]                                                         {'loss': 0.9787, 'learning_rate': 1.738897780719522e-05, 'epoch': 0.26}
 26%|██▌       | 2685/10395 [7:39:35<16:54:35,  7.90s/it] 26%|██▌       | 2686/10395 [7:39:43<16:57:43,  7.92s/it]                                                         {'loss': 0.9952, 'learning_rate': 1.738687801366993e-05, 'epoch': 0.26}
 26%|██▌       | 2686/10395 [7:39:43<16:57:43,  7.92s/it] 26%|██▌       | 2687/10395 [7:39:52<17:12:19,  8.04s/it]                                                         {'loss': 0.9815, 'learning_rate': 1.738477750304231e-05, 'epoch': 0.26}
 26%|██▌       | 2687/10395 [7:39:52<17:12:19,  8.04s/it] 26%|██▌       | 2688/10395 [7:39:59<17:02:17,  7.96s/it]                                                         {'loss': 0.9648, 'learning_rate': 1.7382676275516267e-05, 'epoch': 0.26}
 26%|██▌       | 2688/10395 [7:39:59<17:02:17,  7.96s/it] 26%|██▌       | 2689/10395 [7:40:07<16:55:18,  7.91s/it]                                                         {'loss': 0.8802, 'learning_rate': 1.7380574331295792e-05, 'epoch': 0.26}
 26%|██▌       | 2689/10395 [7:40:07<16:55:18,  7.91s/it] 26%|██▌       | 2690/10395 [7:40:15<16:51:34,  7.88s/it]                                                         {'loss': 0.9672, 'learning_rate': 1.7378471670584933e-05, 'epoch': 0.26}
 26%|██▌       | 2690/10395 [7:40:15<16:51:34,  7.88s/it] 26%|██▌       | 2691/10395 [7:40:23<16:51:55,  7.88s/it]                                                         {'loss': 0.9549, 'learning_rate': 1.737636829358781e-05, 'epoch': 0.26}
 26%|██▌       | 2691/10395 [7:40:23<16:51:55,  7.88s/it] 26%|██▌       | 2692/10395 [7:40:30<16:42:13,  7.81s/it]                                                         {'loss': 0.955, 'learning_rate': 1.7374264200508618e-05, 'epoch': 0.26}
 26%|██▌       | 2692/10395 [7:40:30<16:42:13,  7.81s/it] 26%|██▌       | 2693/10395 [7:40:38<16:36:29,  7.76s/it]                                                         {'loss': 0.9888, 'learning_rate': 1.7372159391551616e-05, 'epoch': 0.26}
 26%|██▌       | 2693/10395 [7:40:38<16:36:29,  7.76s/it] 26%|██▌       | 2694/10395 [7:40:46<16:43:48,  7.82s/it]                                                         {'loss': 0.9562, 'learning_rate': 1.7370053866921135e-05, 'epoch': 0.26}
 26%|██▌       | 2694/10395 [7:40:46<16:43:48,  7.82s/it] 26%|██▌       | 2695/10395 [7:40:56<17:50:22,  8.34s/it]                                                         {'loss': 0.9177, 'learning_rate': 1.7367947626821574e-05, 'epoch': 0.26}
 26%|██▌       | 2695/10395 [7:40:56<17:50:22,  8.34s/it] 26%|██▌       | 2696/10395 [7:41:03<17:21:08,  8.11s/it]                                                         {'loss': 0.929, 'learning_rate': 1.7365840671457405e-05, 'epoch': 0.26}
 26%|██▌       | 2696/10395 [7:41:03<17:21:08,  8.11s/it] 26%|██▌       | 2697/10395 [7:41:11<17:14:06,  8.06s/it]                                                         {'loss': 0.9053, 'learning_rate': 1.736373300103316e-05, 'epoch': 0.26}
 26%|██▌       | 2697/10395 [7:41:11<17:14:06,  8.06s/it] 26%|██▌       | 2698/10395 [7:41:22<18:59:54,  8.89s/it]                                                         {'loss': 0.9644, 'learning_rate': 1.736162461575346e-05, 'epoch': 0.26}
 26%|██▌       | 2698/10395 [7:41:22<18:59:54,  8.89s/it] 26%|██▌       | 2699/10395 [7:41:30<18:21:27,  8.59s/it]                                                         {'loss': 0.9075, 'learning_rate': 1.7359515515822963e-05, 'epoch': 0.26}
 26%|██▌       | 2699/10395 [7:41:30<18:21:27,  8.59s/it] 26%|██▌       | 2700/10395 [7:41:38<17:51:22,  8.35s/it]                                                         {'loss': 1.0292, 'learning_rate': 1.7357405701446433e-05, 'epoch': 0.26}
 26%|██▌       | 2700/10395 [7:41:38<17:51:22,  8.35s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 26%|██▌       | 2701/10395 [7:43:19<77:39:13, 36.33s/it]                                                         {'loss': 0.9753, 'learning_rate': 1.735529517282868e-05, 'epoch': 0.26}
 26%|██▌       | 2701/10395 [7:43:19<77:39:13, 36.33s/it] 26%|██▌       | 2702/10395 [7:43:27<59:14:28, 27.72s/it]                                                         {'loss': 1.0192, 'learning_rate': 1.735318393017459e-05, 'epoch': 0.26}
 26%|██▌       | 2702/10395 [7:43:27<59:14:28, 27.72s/it] 26%|██▌       | 2703/10395 [7:43:35<46:41:32, 21.85s/it]                                                         {'loss': 0.878, 'learning_rate': 1.7351071973689118e-05, 'epoch': 0.26}
 26%|██▌       | 2703/10395 [7:43:35<46:41:32, 21.85s/it] 26%|██▌       | 2704/10395 [7:43:43<37:34:32, 17.59s/it]                                                         {'loss': 0.9209, 'learning_rate': 1.7348959303577287e-05, 'epoch': 0.26}
 26%|██▌       | 2704/10395 [7:43:43<37:34:32, 17.59s/it] 26%|██▌       | 2705/10395 [7:43:50<30:57:02, 14.49s/it]                                                         {'loss': 0.9598, 'learning_rate': 1.734684592004419e-05, 'epoch': 0.26}
 26%|██▌       | 2705/10395 [7:43:50<30:57:02, 14.49s/it] 26%|██▌       | 2706/10395 [7:43:58<26:28:57, 12.40s/it]                                                         {'loss': 1.0091, 'learning_rate': 1.7344731823294996e-05, 'epoch': 0.26}
 26%|██▌       | 2706/10395 [7:43:58<26:28:57, 12.40s/it] 26%|██▌       | 2707/10395 [7:44:05<23:19:25, 10.92s/it]                                                         {'loss': 1.0387, 'learning_rate': 1.734261701353493e-05, 'epoch': 0.26}
 26%|██▌       | 2707/10395 [7:44:05<23:19:25, 10.92s/it] 26%|██▌       | 2708/10395 [7:44:13<21:37:50, 10.13s/it]                                                         {'loss': 0.9758, 'learning_rate': 1.7340501490969296e-05, 'epoch': 0.26}
 26%|██▌       | 2708/10395 [7:44:13<21:37:50, 10.13s/it] 26%|██▌       | 2709/10395 [7:44:21<20:10:03,  9.45s/it]                                                         {'loss': 0.9354, 'learning_rate': 1.733838525580346e-05, 'epoch': 0.26}
 26%|██▌       | 2709/10395 [7:44:21<20:10:03,  9.45s/it] 26%|██▌       | 2710/10395 [7:44:29<19:06:45,  8.95s/it]                                                         {'loss': 0.8767, 'learning_rate': 1.733626830824287e-05, 'epoch': 0.26}
 26%|██▌       | 2710/10395 [7:44:29<19:06:45,  8.95s/it] 26%|██▌       | 2711/10395 [7:44:37<18:17:53,  8.57s/it]                                                         {'loss': 0.9799, 'learning_rate': 1.733415064849303e-05, 'epoch': 0.26}
 26%|██▌       | 2711/10395 [7:44:37<18:17:53,  8.57s/it] 26%|██▌       | 2712/10395 [7:44:44<17:44:01,  8.31s/it]                                                         {'loss': 0.9011, 'learning_rate': 1.7332032276759515e-05, 'epoch': 0.26}
 26%|██▌       | 2712/10395 [7:44:44<17:44:01,  8.31s/it] 26%|██▌       | 2713/10395 [7:44:52<17:29:47,  8.20s/it]                                                         {'loss': 1.0089, 'learning_rate': 1.732991319324798e-05, 'epoch': 0.26}
 26%|██▌       | 2713/10395 [7:44:52<17:29:47,  8.20s/it] 26%|██▌       | 2714/10395 [7:45:00<16:57:16,  7.95s/it]                                                         {'loss': 0.9709, 'learning_rate': 1.732779339816413e-05, 'epoch': 0.26}
 26%|██▌       | 2714/10395 [7:45:00<16:57:16,  7.95s/it] 26%|██▌       | 2715/10395 [7:45:08<17:03:57,  8.00s/it]                                                         {'loss': 0.8935, 'learning_rate': 1.732567289171376e-05, 'epoch': 0.26}
 26%|██▌       | 2715/10395 [7:45:08<17:03:57,  8.00s/it] 26%|██▌       | 2716/10395 [7:45:16<17:03:12,  7.99s/it]                                                         {'loss': 0.9461, 'learning_rate': 1.7323551674102725e-05, 'epoch': 0.26}
 26%|██▌       | 2716/10395 [7:45:16<17:03:12,  7.99s/it] 26%|██▌       | 2717/10395 [7:45:24<17:02:57,  7.99s/it]                                                         {'loss': 0.9569, 'learning_rate': 1.732142974553694e-05, 'epoch': 0.26}
 26%|██▌       | 2717/10395 [7:45:24<17:02:57,  7.99s/it] 26%|██▌       | 2718/10395 [7:45:31<16:31:22,  7.75s/it]                                                         {'loss': 1.0167, 'learning_rate': 1.7319307106222402e-05, 'epoch': 0.26}
 26%|██▌       | 2718/10395 [7:45:31<16:31:22,  7.75s/it] 26%|██▌       | 2719/10395 [7:45:39<16:53:10,  7.92s/it]                                                         {'loss': 0.9657, 'learning_rate': 1.731718375636517e-05, 'epoch': 0.26}
 26%|██▌       | 2719/10395 [7:45:39<16:53:10,  7.92s/it] 26%|██▌       | 2720/10395 [7:45:47<16:44:29,  7.85s/it]                                                         {'loss': 0.9631, 'learning_rate': 1.7315059696171376e-05, 'epoch': 0.26}
 26%|██▌       | 2720/10395 [7:45:47<16:44:29,  7.85s/it] 26%|██▌       | 2721/10395 [7:45:54<16:33:14,  7.77s/it]                                                         {'loss': 1.0231, 'learning_rate': 1.731293492584722e-05, 'epoch': 0.26}
 26%|██▌       | 2721/10395 [7:45:54<16:33:14,  7.77s/it] 26%|██▌       | 2722/10395 [7:46:02<16:39:40,  7.82s/it]                                                         {'loss': 1.0206, 'learning_rate': 1.731080944559897e-05, 'epoch': 0.26}
 26%|██▌       | 2722/10395 [7:46:02<16:39:40,  7.82s/it] 26%|██▌       | 2723/10395 [7:46:10<16:50:32,  7.90s/it]                                                         {'loss': 0.9567, 'learning_rate': 1.730868325563296e-05, 'epoch': 0.26}
 26%|██▌       | 2723/10395 [7:46:10<16:50:32,  7.90s/it] 26%|██▌       | 2724/10395 [7:46:18<16:46:13,  7.87s/it]                                                         {'loss': 0.9516, 'learning_rate': 1.73065563561556e-05, 'epoch': 0.26}
 26%|██▌       | 2724/10395 [7:46:18<16:46:13,  7.87s/it] 26%|██▌       | 2725/10395 [7:46:26<16:32:58,  7.77s/it]                                                         {'loss': 0.9345, 'learning_rate': 1.730442874737336e-05, 'epoch': 0.26}
 26%|██▌       | 2725/10395 [7:46:26<16:32:58,  7.77s/it] 26%|██▌       | 2726/10395 [7:46:34<17:05:18,  8.02s/it]                                                         {'loss': 0.9945, 'learning_rate': 1.730230042949279e-05, 'epoch': 0.26}
 26%|██▌       | 2726/10395 [7:46:35<17:05:18,  8.02s/it] 26%|██▌       | 2727/10395 [7:46:42<17:03:10,  8.01s/it]                                                         {'loss': 1.0499, 'learning_rate': 1.7300171402720498e-05, 'epoch': 0.26}
 26%|██▌       | 2727/10395 [7:46:42<17:03:10,  8.01s/it] 26%|██▌       | 2728/10395 [7:46:50<16:36:52,  7.80s/it]                                                         {'loss': 1.0102, 'learning_rate': 1.729804166726317e-05, 'epoch': 0.26}
 26%|██▌       | 2728/10395 [7:46:50<16:36:52,  7.80s/it] 26%|██▋       | 2729/10395 [7:46:57<16:21:27,  7.68s/it]                                                         {'loss': 0.9636, 'learning_rate': 1.729591122332755e-05, 'epoch': 0.26}
 26%|██▋       | 2729/10395 [7:46:57<16:21:27,  7.68s/it] 26%|██▋       | 2730/10395 [7:47:05<16:38:03,  7.81s/it]                                                         {'loss': 0.9311, 'learning_rate': 1.729378007112046e-05, 'epoch': 0.26}
 26%|██▋       | 2730/10395 [7:47:05<16:38:03,  7.81s/it] 26%|██▋       | 2731/10395 [7:47:13<16:32:24,  7.77s/it]                                                         {'loss': 1.0184, 'learning_rate': 1.7291648210848785e-05, 'epoch': 0.26}
 26%|██▋       | 2731/10395 [7:47:13<16:32:24,  7.77s/it] 26%|██▋       | 2732/10395 [7:47:20<16:22:38,  7.69s/it]                                                         {'loss': 0.9898, 'learning_rate': 1.728951564271949e-05, 'epoch': 0.26}
 26%|██▋       | 2732/10395 [7:47:20<16:22:38,  7.69s/it] 26%|██▋       | 2733/10395 [7:47:28<16:25:42,  7.72s/it]                                                         {'loss': 0.995, 'learning_rate': 1.7287382366939586e-05, 'epoch': 0.26}
 26%|██▋       | 2733/10395 [7:47:28<16:25:42,  7.72s/it] 26%|██▋       | 2734/10395 [7:47:36<16:45:56,  7.88s/it]                                                         {'loss': 1.009, 'learning_rate': 1.728524838371618e-05, 'epoch': 0.26}
 26%|██▋       | 2734/10395 [7:47:36<16:45:56,  7.88s/it] 26%|██▋       | 2735/10395 [7:47:44<16:37:09,  7.81s/it]                                                         {'loss': 0.9446, 'learning_rate': 1.7283113693256433e-05, 'epoch': 0.26}
 26%|██▋       | 2735/10395 [7:47:44<16:37:09,  7.81s/it] 26%|██▋       | 2736/10395 [7:47:52<16:36:36,  7.81s/it]                                                         {'loss': 0.9401, 'learning_rate': 1.7280978295767567e-05, 'epoch': 0.26}
 26%|██▋       | 2736/10395 [7:47:52<16:36:36,  7.81s/it] 26%|██▋       | 2737/10395 [7:48:01<17:11:53,  8.08s/it]                                                         {'loss': 0.9751, 'learning_rate': 1.727884219145689e-05, 'epoch': 0.26}
 26%|██▋       | 2737/10395 [7:48:01<17:11:53,  8.08s/it] 26%|██▋       | 2738/10395 [7:48:09<17:24:03,  8.18s/it]                                                         {'loss': 0.9477, 'learning_rate': 1.7276705380531768e-05, 'epoch': 0.26}
 26%|██▋       | 2738/10395 [7:48:09<17:24:03,  8.18s/it] 26%|██▋       | 2739/10395 [7:48:17<17:03:45,  8.02s/it]                                                         {'loss': 0.9197, 'learning_rate': 1.7274567863199637e-05, 'epoch': 0.26}
 26%|██▋       | 2739/10395 [7:48:17<17:03:45,  8.02s/it] 26%|██▋       | 2740/10395 [7:48:24<16:52:10,  7.93s/it]                                                         {'loss': 0.9465, 'learning_rate': 1.7272429639668006e-05, 'epoch': 0.26}
 26%|██▋       | 2740/10395 [7:48:24<16:52:10,  7.93s/it] 26%|██▋       | 2741/10395 [7:48:32<16:24:31,  7.72s/it]                                                         {'loss': 1.0579, 'learning_rate': 1.7270290710144443e-05, 'epoch': 0.26}
 26%|██▋       | 2741/10395 [7:48:32<16:24:31,  7.72s/it] 26%|██▋       | 2742/10395 [7:48:40<16:38:04,  7.82s/it]                                                         {'loss': 0.9508, 'learning_rate': 1.7268151074836595e-05, 'epoch': 0.26}
 26%|██▋       | 2742/10395 [7:48:40<16:38:04,  7.82s/it] 26%|██▋       | 2743/10395 [7:48:48<16:57:56,  7.98s/it]                                                         {'loss': 0.9731, 'learning_rate': 1.7266010733952176e-05, 'epoch': 0.26}
 26%|██▋       | 2743/10395 [7:48:48<16:57:56,  7.98s/it] 26%|██▋       | 2744/10395 [7:48:57<17:28:52,  8.23s/it]                                                         {'loss': 0.9908, 'learning_rate': 1.7263869687698963e-05, 'epoch': 0.26}
 26%|██▋       | 2744/10395 [7:48:57<17:28:52,  8.23s/it] 26%|██▋       | 2745/10395 [7:49:14<22:55:54, 10.79s/it]                                                         {'loss': 0.4137, 'learning_rate': 1.72617279362848e-05, 'epoch': 0.26}
 26%|██▋       | 2745/10395 [7:49:14<22:55:54, 10.79s/it] 26%|██▋       | 2746/10395 [7:49:21<20:44:07,  9.76s/it]                                                         {'loss': 0.9805, 'learning_rate': 1.7259585479917608e-05, 'epoch': 0.26}
 26%|██▋       | 2746/10395 [7:49:21<20:44:07,  9.76s/it] 26%|██▋       | 2747/10395 [7:49:29<19:28:51,  9.17s/it]                                                         {'loss': 1.0115, 'learning_rate': 1.7257442318805373e-05, 'epoch': 0.26}
 26%|██▋       | 2747/10395 [7:49:29<19:28:51,  9.17s/it] 26%|██▋       | 2748/10395 [7:49:37<18:37:47,  8.77s/it]                                                         {'loss': 0.9975, 'learning_rate': 1.7255298453156147e-05, 'epoch': 0.26}
 26%|██▋       | 2748/10395 [7:49:37<18:37:47,  8.77s/it] 26%|██▋       | 2749/10395 [7:49:45<18:06:41,  8.53s/it]                                                         {'loss': 0.933, 'learning_rate': 1.725315388317805e-05, 'epoch': 0.26}
 26%|██▋       | 2749/10395 [7:49:45<18:06:41,  8.53s/it] 26%|██▋       | 2750/10395 [7:49:52<17:27:45,  8.22s/it]                                                         {'loss': 1.0059, 'learning_rate': 1.7251008609079275e-05, 'epoch': 0.26}
 26%|██▋       | 2750/10395 [7:49:52<17:27:45,  8.22s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 26%|██▋       | 2751/10395 [7:51:33<76:26:29, 36.00s/it]                                                         {'loss': 0.9689, 'learning_rate': 1.724886263106808e-05, 'epoch': 0.26}
 26%|██▋       | 2751/10395 [7:51:33<76:26:29, 36.00s/it] 26%|██▋       | 2752/10395 [7:51:40<58:16:59, 27.45s/it]                                                         {'loss': 0.969, 'learning_rate': 1.724671594935279e-05, 'epoch': 0.26}
 26%|██▋       | 2752/10395 [7:51:40<58:16:59, 27.45s/it] 26%|██▋       | 2753/10395 [7:51:48<45:34:42, 21.47s/it]                                                         {'loss': 0.9918, 'learning_rate': 1.7244568564141805e-05, 'epoch': 0.26}
 26%|██▋       | 2753/10395 [7:51:48<45:34:42, 21.47s/it] 26%|██▋       | 2754/10395 [7:51:55<36:30:28, 17.20s/it]                                                         {'loss': 0.9326, 'learning_rate': 1.7242420475643583e-05, 'epoch': 0.26}
 26%|██▋       | 2754/10395 [7:51:55<36:30:28, 17.20s/it] 27%|██▋       | 2755/10395 [7:52:12<36:24:54, 17.16s/it]                                                         {'loss': 0.4171, 'learning_rate': 1.724027168406666e-05, 'epoch': 0.27}
 27%|██▋       | 2755/10395 [7:52:12<36:24:54, 17.16s/it] 27%|██▋       | 2756/10395 [7:52:29<35:59:20, 16.96s/it]                                                         {'loss': 0.3965, 'learning_rate': 1.7238122189619632e-05, 'epoch': 0.27}
 27%|██▋       | 2756/10395 [7:52:29<35:59:20, 16.96s/it] 27%|██▋       | 2757/10395 [7:52:37<30:08:36, 14.21s/it]                                                         {'loss': 0.8834, 'learning_rate': 1.723597199251117e-05, 'epoch': 0.27}
 27%|██▋       | 2757/10395 [7:52:37<30:08:36, 14.21s/it] 27%|██▋       | 2758/10395 [7:52:44<25:54:54, 12.22s/it]                                                         {'loss': 0.9932, 'learning_rate': 1.7233821092950013e-05, 'epoch': 0.27}
 27%|██▋       | 2758/10395 [7:52:44<25:54:54, 12.22s/it] 27%|██▋       | 2759/10395 [7:52:52<23:03:33, 10.87s/it]                                                         {'loss': 0.976, 'learning_rate': 1.723166949114496e-05, 'epoch': 0.27}
 27%|██▋       | 2759/10395 [7:52:52<23:03:33, 10.87s/it] 27%|██▋       | 2760/10395 [7:52:59<20:49:27,  9.82s/it]                                                         {'loss': 0.9839, 'learning_rate': 1.722951718730489e-05, 'epoch': 0.27}
 27%|██▋       | 2760/10395 [7:52:59<20:49:27,  9.82s/it] 27%|██▋       | 2761/10395 [7:53:09<20:51:08,  9.83s/it]                                                         {'loss': 0.8943, 'learning_rate': 1.7227364181638737e-05, 'epoch': 0.27}
 27%|██▋       | 2761/10395 [7:53:09<20:51:08,  9.83s/it] 27%|██▋       | 2762/10395 [7:53:16<19:19:42,  9.12s/it]                                                         {'loss': 0.9672, 'learning_rate': 1.7225210474355516e-05, 'epoch': 0.27}
 27%|██▋       | 2762/10395 [7:53:16<19:19:42,  9.12s/it] 27%|██▋       | 2763/10395 [7:53:24<18:16:01,  8.62s/it]                                                         {'loss': 0.9623, 'learning_rate': 1.7223056065664306e-05, 'epoch': 0.27}
 27%|██▋       | 2763/10395 [7:53:24<18:16:01,  8.62s/it] 27%|██▋       | 2764/10395 [7:53:31<17:32:41,  8.28s/it]                                                         {'loss': 1.0875, 'learning_rate': 1.7220900955774244e-05, 'epoch': 0.27}
 27%|██▋       | 2764/10395 [7:53:31<17:32:41,  8.28s/it] 27%|██▋       | 2765/10395 [7:53:49<23:28:13, 11.07s/it]                                                         {'loss': 0.3995, 'learning_rate': 1.7218745144894552e-05, 'epoch': 0.27}
 27%|██▋       | 2765/10395 [7:53:49<23:28:13, 11.07s/it] 27%|██▋       | 2766/10395 [7:53:57<21:13:39, 10.02s/it]                                                         {'loss': 0.9928, 'learning_rate': 1.7216588633234507e-05, 'epoch': 0.27}
 27%|██▋       | 2766/10395 [7:53:57<21:13:39, 10.02s/it] 27%|██▋       | 2767/10395 [7:54:04<19:32:03,  9.22s/it]                                                         {'loss': 1.0373, 'learning_rate': 1.7214431421003456e-05, 'epoch': 0.27}
 27%|██▋       | 2767/10395 [7:54:04<19:32:03,  9.22s/it] 27%|██▋       | 2768/10395 [7:54:11<18:16:32,  8.63s/it]                                                         {'loss': 0.9274, 'learning_rate': 1.7212273508410822e-05, 'epoch': 0.27}
 27%|██▋       | 2768/10395 [7:54:11<18:16:32,  8.63s/it] 27%|██▋       | 2769/10395 [7:54:19<17:52:20,  8.44s/it]                                                         {'loss': 1.0849, 'learning_rate': 1.721011489566609e-05, 'epoch': 0.27}
 27%|██▋       | 2769/10395 [7:54:19<17:52:20,  8.44s/it] 27%|██▋       | 2770/10395 [7:54:37<23:58:52, 11.32s/it]                                                         {'loss': 0.3955, 'learning_rate': 1.7207955582978814e-05, 'epoch': 0.27}
 27%|██▋       | 2770/10395 [7:54:37<23:58:52, 11.32s/it] 27%|██▋       | 2771/10395 [7:54:45<21:33:22, 10.18s/it]                                                         {'loss': 0.9239, 'learning_rate': 1.720579557055861e-05, 'epoch': 0.27}
 27%|██▋       | 2771/10395 [7:54:45<21:33:22, 10.18s/it] 27%|██▋       | 2772/10395 [7:54:52<19:43:11,  9.31s/it]                                                         {'loss': 1.0338, 'learning_rate': 1.720363485861517e-05, 'epoch': 0.27}
 27%|██▋       | 2772/10395 [7:54:52<19:43:11,  9.31s/it] 27%|██▋       | 2773/10395 [7:55:01<19:46:19,  9.34s/it]                                                         {'loss': 0.9895, 'learning_rate': 1.7201473447358253e-05, 'epoch': 0.27}
 27%|██▋       | 2773/10395 [7:55:01<19:46:19,  9.34s/it] 27%|██▋       | 2774/10395 [7:55:09<18:36:59,  8.79s/it]                                                         {'loss': 1.0091, 'learning_rate': 1.7199311336997682e-05, 'epoch': 0.27}
 27%|██▋       | 2774/10395 [7:55:09<18:36:59,  8.79s/it] 27%|██▋       | 2775/10395 [7:55:16<17:43:47,  8.38s/it]                                                         {'loss': 0.9806, 'learning_rate': 1.7197148527743356e-05, 'epoch': 0.27}
 27%|██▋       | 2775/10395 [7:55:16<17:43:47,  8.38s/it] 27%|██▋       | 2776/10395 [7:55:24<17:12:38,  8.13s/it]                                                         {'loss': 0.8979, 'learning_rate': 1.7194985019805226e-05, 'epoch': 0.27}
 27%|██▋       | 2776/10395 [7:55:24<17:12:38,  8.13s/it] 27%|██▋       | 2777/10395 [7:55:31<16:51:13,  7.96s/it]                                                         {'loss': 1.0363, 'learning_rate': 1.719282081339333e-05, 'epoch': 0.27}
 27%|██▋       | 2777/10395 [7:55:31<16:51:13,  7.96s/it] 27%|██▋       | 2778/10395 [7:55:39<16:25:25,  7.76s/it]                                                         {'loss': 1.0534, 'learning_rate': 1.7190655908717757e-05, 'epoch': 0.27}
 27%|██▋       | 2778/10395 [7:55:39<16:25:25,  7.76s/it] 27%|██▋       | 2779/10395 [7:55:46<16:18:28,  7.71s/it]                                                         {'loss': 0.8426, 'learning_rate': 1.7188490305988676e-05, 'epoch': 0.27}
 27%|██▋       | 2779/10395 [7:55:46<16:18:28,  7.71s/it] 27%|██▋       | 2780/10395 [7:55:55<17:09:27,  8.11s/it]                                                         {'loss': 0.9298, 'learning_rate': 1.718632400541632e-05, 'epoch': 0.27}
 27%|██▋       | 2780/10395 [7:55:55<17:09:27,  8.11s/it] 27%|██▋       | 2781/10395 [7:56:02<16:24:23,  7.76s/it]                                                         {'loss': 1.04, 'learning_rate': 1.7184157007210984e-05, 'epoch': 0.27}
 27%|██▋       | 2781/10395 [7:56:02<16:24:23,  7.76s/it] 27%|██▋       | 2782/10395 [7:56:20<22:28:13, 10.63s/it]                                                         {'loss': 0.4097, 'learning_rate': 1.718198931158304e-05, 'epoch': 0.27}
 27%|██▋       | 2782/10395 [7:56:20<22:28:13, 10.63s/it] 27%|██▋       | 2783/10395 [7:56:27<20:35:45,  9.74s/it]                                                         {'loss': 0.9775, 'learning_rate': 1.717982091874292e-05, 'epoch': 0.27}
 27%|██▋       | 2783/10395 [7:56:27<20:35:45,  9.74s/it] 27%|██▋       | 2784/10395 [7:56:36<19:36:29,  9.27s/it]                                                         {'loss': 0.9039, 'learning_rate': 1.7177651828901136e-05, 'epoch': 0.27}
 27%|██▋       | 2784/10395 [7:56:36<19:36:29,  9.27s/it] 27%|██▋       | 2785/10395 [7:56:43<18:41:42,  8.84s/it]                                                         {'loss': 0.9334, 'learning_rate': 1.717548204226824e-05, 'epoch': 0.27}
 27%|██▋       | 2785/10395 [7:56:43<18:41:42,  8.84s/it] 27%|██▋       | 2786/10395 [7:56:52<18:21:07,  8.68s/it]                                                         {'loss': 0.8623, 'learning_rate': 1.7173311559054888e-05, 'epoch': 0.27}
 27%|██▋       | 2786/10395 [7:56:52<18:21:07,  8.68s/it] 27%|██▋       | 2787/10395 [7:56:59<17:48:03,  8.42s/it]                                                         {'loss': 1.0018, 'learning_rate': 1.717114037947178e-05, 'epoch': 0.27}
 27%|██▋       | 2787/10395 [7:56:59<17:48:03,  8.42s/it] 27%|██▋       | 2788/10395 [7:57:07<17:13:28,  8.15s/it]                                                         {'loss': 0.9416, 'learning_rate': 1.7168968503729684e-05, 'epoch': 0.27}
 27%|██▋       | 2788/10395 [7:57:07<17:13:28,  8.15s/it] 27%|██▋       | 2789/10395 [7:57:14<16:41:41,  7.90s/it]                                                         {'loss': 0.9576, 'learning_rate': 1.716679593203945e-05, 'epoch': 0.27}
 27%|██▋       | 2789/10395 [7:57:14<16:41:41,  7.90s/it] 27%|██▋       | 2790/10395 [7:57:22<16:45:31,  7.93s/it]                                                         {'loss': 0.9898, 'learning_rate': 1.716462266461198e-05, 'epoch': 0.27}
 27%|██▋       | 2790/10395 [7:57:22<16:45:31,  7.93s/it] 27%|██▋       | 2791/10395 [7:57:31<17:14:04,  8.16s/it]                                                         {'loss': 0.9372, 'learning_rate': 1.7162448701658253e-05, 'epoch': 0.27}
 27%|██▋       | 2791/10395 [7:57:31<17:14:04,  8.16s/it] 27%|██▋       | 2792/10395 [7:57:39<16:49:04,  7.96s/it]                                                         {'loss': 1.0267, 'learning_rate': 1.7160274043389315e-05, 'epoch': 0.27}
 27%|██▋       | 2792/10395 [7:57:39<16:49:04,  7.96s/it] 27%|██▋       | 2793/10395 [7:57:47<17:07:29,  8.11s/it]                                                         {'loss': 0.9995, 'learning_rate': 1.715809869001627e-05, 'epoch': 0.27}
 27%|██▋       | 2793/10395 [7:57:47<17:07:29,  8.11s/it] 27%|██▋       | 2794/10395 [7:57:55<16:48:15,  7.96s/it]                                                         {'loss': 0.9865, 'learning_rate': 1.71559226417503e-05, 'epoch': 0.27}
 27%|██▋       | 2794/10395 [7:57:55<16:48:15,  7.96s/it] 27%|██▋       | 2795/10395 [7:58:02<16:41:43,  7.91s/it]                                                         {'loss': 0.932, 'learning_rate': 1.7153745898802657e-05, 'epoch': 0.27}
 27%|██▋       | 2795/10395 [7:58:02<16:41:43,  7.91s/it] 27%|██▋       | 2796/10395 [7:58:18<21:44:48, 10.30s/it]                                                         {'loss': 0.3634, 'learning_rate': 1.715156846138465e-05, 'epoch': 0.27}
 27%|██▋       | 2796/10395 [7:58:18<21:44:48, 10.30s/it] 27%|██▋       | 2797/10395 [7:58:25<19:40:39,  9.32s/it]                                                         {'loss': 0.9592, 'learning_rate': 1.7149390329707654e-05, 'epoch': 0.27}
 27%|██▋       | 2797/10395 [7:58:25<19:40:39,  9.32s/it] 27%|██▋       | 2798/10395 [7:58:33<18:30:18,  8.77s/it]                                                         {'loss': 0.9609, 'learning_rate': 1.714721150398313e-05, 'epoch': 0.27}
 27%|██▋       | 2798/10395 [7:58:33<18:30:18,  8.77s/it] 27%|██▋       | 2799/10395 [7:58:40<17:33:46,  8.32s/it]                                                         {'loss': 1.0266, 'learning_rate': 1.7145031984422583e-05, 'epoch': 0.27}
 27%|██▋       | 2799/10395 [7:58:40<17:33:46,  8.32s/it] 27%|██▋       | 2800/10395 [7:58:48<17:32:45,  8.32s/it]                                                         {'loss': 0.9526, 'learning_rate': 1.71428517712376e-05, 'epoch': 0.27}
 27%|██▋       | 2800/10395 [7:58:48<17:32:45,  8.32s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 27%|██▋       | 2801/10395 [8:00:26<74:14:45, 35.20s/it]                                                         {'loss': 0.9392, 'learning_rate': 1.7140670864639833e-05, 'epoch': 0.27}
 27%|██▋       | 2801/10395 [8:00:26<74:14:45, 35.20s/it] 27%|██▋       | 2802/10395 [8:00:35<57:34:17, 27.30s/it]                                                         {'loss': 0.8685, 'learning_rate': 1.7138489264840997e-05, 'epoch': 0.27}
 27%|██▋       | 2802/10395 [8:00:35<57:34:17, 27.30s/it] 27%|██▋       | 2803/10395 [8:00:43<45:24:54, 21.54s/it]                                                         {'loss': 0.9837, 'learning_rate': 1.7136306972052876e-05, 'epoch': 0.27}
 27%|██▋       | 2803/10395 [8:00:43<45:24:54, 21.54s/it] 27%|██▋       | 2804/10395 [8:01:00<42:09:22, 19.99s/it]                                                         {'loss': 0.4252, 'learning_rate': 1.713412398648733e-05, 'epoch': 0.27}
 27%|██▋       | 2804/10395 [8:01:00<42:09:22, 19.99s/it] 27%|██▋       | 2805/10395 [8:01:07<34:14:13, 16.24s/it]                                                         {'loss': 0.9725, 'learning_rate': 1.7131940308356267e-05, 'epoch': 0.27}
 27%|██▋       | 2805/10395 [8:01:07<34:14:13, 16.24s/it] 27%|██▋       | 2806/10395 [8:01:15<29:14:35, 13.87s/it]                                                         {'loss': 0.9821, 'learning_rate': 1.7129755937871685e-05, 'epoch': 0.27}
 27%|██▋       | 2806/10395 [8:01:15<29:14:35, 13.87s/it] 27%|██▋       | 2807/10395 [8:01:23<25:05:19, 11.90s/it]                                                         {'loss': 0.9369, 'learning_rate': 1.712757087524563e-05, 'epoch': 0.27}
 27%|██▋       | 2807/10395 [8:01:23<25:05:19, 11.90s/it] 27%|██▋       | 2808/10395 [8:01:30<22:21:18, 10.61s/it]                                                         {'loss': 0.9061, 'learning_rate': 1.7125385120690227e-05, 'epoch': 0.27}
 27%|██▋       | 2808/10395 [8:01:30<22:21:18, 10.61s/it] 27%|██▋       | 2809/10395 [8:01:38<20:41:54,  9.82s/it]                                                         {'loss': 1.0113, 'learning_rate': 1.712319867441766e-05, 'epoch': 0.27}
 27%|██▋       | 2809/10395 [8:01:38<20:41:54,  9.82s/it] 27%|██▋       | 2810/10395 [8:01:46<19:24:08,  9.21s/it]                                                         {'loss': 0.9383, 'learning_rate': 1.7121011536640195e-05, 'epoch': 0.27}
 27%|██▋       | 2810/10395 [8:01:46<19:24:08,  9.21s/it] 27%|██▋       | 2811/10395 [8:01:54<18:19:49,  8.70s/it]                                                         {'loss': 0.9087, 'learning_rate': 1.7118823707570144e-05, 'epoch': 0.27}
 27%|██▋       | 2811/10395 [8:01:54<18:19:49,  8.70s/it] 27%|██▋       | 2812/10395 [8:02:01<17:45:50,  8.43s/it]                                                         {'loss': 0.9368, 'learning_rate': 1.7116635187419898e-05, 'epoch': 0.27}
 27%|██▋       | 2812/10395 [8:02:01<17:45:50,  8.43s/it] 27%|██▋       | 2813/10395 [8:02:09<17:03:18,  8.10s/it]                                                         {'loss': 0.8907, 'learning_rate': 1.711444597640192e-05, 'epoch': 0.27}
 27%|██▋       | 2813/10395 [8:02:09<17:03:18,  8.10s/it] 27%|██▋       | 2814/10395 [8:02:17<17:09:28,  8.15s/it]                                                         {'loss': 0.941, 'learning_rate': 1.7112256074728728e-05, 'epoch': 0.27}
 27%|██▋       | 2814/10395 [8:02:17<17:09:28,  8.15s/it] 27%|██▋       | 2815/10395 [8:02:24<16:32:43,  7.86s/it]                                                         {'loss': 0.9488, 'learning_rate': 1.7110065482612917e-05, 'epoch': 0.27}
 27%|██▋       | 2815/10395 [8:02:24<16:32:43,  7.86s/it] 27%|██▋       | 2816/10395 [8:02:32<16:34:28,  7.87s/it]                                                         {'loss': 0.9266, 'learning_rate': 1.7107874200267142e-05, 'epoch': 0.27}
 27%|██▋       | 2816/10395 [8:02:32<16:34:28,  7.87s/it] 27%|██▋       | 2817/10395 [8:02:41<17:09:02,  8.15s/it]                                                         {'loss': 0.9778, 'learning_rate': 1.7105682227904127e-05, 'epoch': 0.27}
 27%|██▋       | 2817/10395 [8:02:41<17:09:02,  8.15s/it] 27%|██▋       | 2818/10395 [8:02:49<17:02:50,  8.10s/it]                                                         {'loss': 0.9311, 'learning_rate': 1.710348956573667e-05, 'epoch': 0.27}
 27%|██▋       | 2818/10395 [8:02:49<17:02:50,  8.10s/it] 27%|██▋       | 2819/10395 [8:02:56<16:38:28,  7.91s/it]                                                         {'loss': 1.022, 'learning_rate': 1.7101296213977627e-05, 'epoch': 0.27}
 27%|██▋       | 2819/10395 [8:02:56<16:38:28,  7.91s/it] 27%|██▋       | 2820/10395 [8:03:04<16:26:47,  7.82s/it]                                                         {'loss': 0.9762, 'learning_rate': 1.7099102172839918e-05, 'epoch': 0.27}
 27%|██▋       | 2820/10395 [8:03:04<16:26:47,  7.82s/it] 27%|██▋       | 2821/10395 [8:03:11<16:07:28,  7.66s/it]                                                         {'loss': 0.973, 'learning_rate': 1.7096907442536546e-05, 'epoch': 0.27}
 27%|██▋       | 2821/10395 [8:03:11<16:07:28,  7.66s/it] 27%|██▋       | 2822/10395 [8:03:19<16:16:15,  7.73s/it]                                                         {'loss': 0.9274, 'learning_rate': 1.7094712023280562e-05, 'epoch': 0.27}
 27%|██▋       | 2822/10395 [8:03:19<16:16:15,  7.73s/it] 27%|██▋       | 2823/10395 [8:03:27<16:07:02,  7.66s/it]                                                         {'loss': 1.0226, 'learning_rate': 1.70925159152851e-05, 'epoch': 0.27}
 27%|██▋       | 2823/10395 [8:03:27<16:07:02,  7.66s/it] 27%|██▋       | 2824/10395 [8:03:35<16:25:48,  7.81s/it]                                                         {'loss': 0.9353, 'learning_rate': 1.7090319118763347e-05, 'epoch': 0.27}
 27%|██▋       | 2824/10395 [8:03:35<16:25:48,  7.81s/it] 27%|██▋       | 2825/10395 [8:03:43<16:30:44,  7.85s/it]                                                         {'loss': 0.9668, 'learning_rate': 1.7088121633928566e-05, 'epoch': 0.27}
 27%|██▋       | 2825/10395 [8:03:43<16:30:44,  7.85s/it] 27%|██▋       | 2826/10395 [8:03:50<16:02:28,  7.63s/it]                                                         {'loss': 0.9408, 'learning_rate': 1.708592346099408e-05, 'epoch': 0.27}
 27%|██▋       | 2826/10395 [8:03:50<16:02:28,  7.63s/it] 27%|██▋       | 2827/10395 [8:03:58<16:20:07,  7.77s/it]                                                         {'loss': 0.9683, 'learning_rate': 1.7083724600173295e-05, 'epoch': 0.27}
 27%|██▋       | 2827/10395 [8:03:58<16:20:07,  7.77s/it] 27%|██▋       | 2828/10395 [8:04:16<22:45:04, 10.82s/it]                                                         {'loss': 0.3662, 'learning_rate': 1.708152505167966e-05, 'epoch': 0.27}
 27%|██▋       | 2828/10395 [8:04:16<22:45:04, 10.82s/it] 27%|██▋       | 2829/10395 [8:04:23<20:39:40,  9.83s/it]                                                         {'loss': 0.9961, 'learning_rate': 1.7079324815726708e-05, 'epoch': 0.27}
 27%|██▋       | 2829/10395 [8:04:23<20:39:40,  9.83s/it] 27%|██▋       | 2830/10395 [8:04:31<19:11:12,  9.13s/it]                                                         {'loss': 1.0274, 'learning_rate': 1.7077123892528028e-05, 'epoch': 0.27}
 27%|██▋       | 2830/10395 [8:04:31<19:11:12,  9.13s/it] 27%|██▋       | 2831/10395 [8:04:38<18:06:37,  8.62s/it]                                                         {'loss': 0.9244, 'learning_rate': 1.707492228229729e-05, 'epoch': 0.27}
 27%|██▋       | 2831/10395 [8:04:38<18:06:37,  8.62s/it] 27%|██▋       | 2832/10395 [8:04:46<17:28:48,  8.32s/it]                                                         {'loss': 0.9626, 'learning_rate': 1.707271998524821e-05, 'epoch': 0.27}
 27%|██▋       | 2832/10395 [8:04:46<17:28:48,  8.32s/it] 27%|██▋       | 2833/10395 [8:04:54<17:29:40,  8.33s/it]                                                         {'loss': 0.9487, 'learning_rate': 1.707051700159459e-05, 'epoch': 0.27}
 27%|██▋       | 2833/10395 [8:04:54<17:29:40,  8.33s/it] 27%|██▋       | 2834/10395 [8:05:11<22:49:22, 10.87s/it]                                                         {'loss': 0.3739, 'learning_rate': 1.706831333155029e-05, 'epoch': 0.27}
 27%|██▋       | 2834/10395 [8:05:11<22:49:22, 10.87s/it] 27%|██▋       | 2835/10395 [8:05:18<20:36:51,  9.82s/it]                                                         {'loss': 0.9609, 'learning_rate': 1.7066108975329237e-05, 'epoch': 0.27}
 27%|██▋       | 2835/10395 [8:05:18<20:36:51,  9.82s/it] 27%|██▋       | 2836/10395 [8:05:26<18:57:15,  9.03s/it]                                                         {'loss': 0.9779, 'learning_rate': 1.7063903933145426e-05, 'epoch': 0.27}
 27%|██▋       | 2836/10395 [8:05:26<18:57:15,  9.03s/it] 27%|██▋       | 2837/10395 [8:05:34<18:20:55,  8.74s/it]                                                         {'loss': 0.9108, 'learning_rate': 1.7061698205212916e-05, 'epoch': 0.27}
 27%|██▋       | 2837/10395 [8:05:34<18:20:55,  8.74s/it] 27%|██▋       | 2838/10395 [8:05:41<17:34:57,  8.38s/it]                                                         {'loss': 1.044, 'learning_rate': 1.7059491791745833e-05, 'epoch': 0.27}
 27%|██▋       | 2838/10395 [8:05:41<17:34:57,  8.38s/it] 27%|██▋       | 2839/10395 [8:05:49<17:08:25,  8.17s/it]                                                         {'loss': 0.975, 'learning_rate': 1.7057284692958376e-05, 'epoch': 0.27}
 27%|██▋       | 2839/10395 [8:05:49<17:08:25,  8.17s/it] 27%|██▋       | 2840/10395 [8:05:56<16:41:01,  7.95s/it]                                                         {'loss': 0.9617, 'learning_rate': 1.7055076909064802e-05, 'epoch': 0.27}
 27%|██▋       | 2840/10395 [8:05:56<16:41:01,  7.95s/it] 27%|██▋       | 2841/10395 [8:06:04<16:30:27,  7.87s/it]                                                         {'loss': 0.9101, 'learning_rate': 1.7052868440279435e-05, 'epoch': 0.27}
 27%|██▋       | 2841/10395 [8:06:04<16:30:27,  7.87s/it] 27%|██▋       | 2842/10395 [8:06:12<16:26:32,  7.84s/it]                                                         {'loss': 0.9803, 'learning_rate': 1.7050659286816676e-05, 'epoch': 0.27}
 27%|██▋       | 2842/10395 [8:06:12<16:26:32,  7.84s/it] 27%|██▋       | 2843/10395 [8:06:19<15:54:20,  7.58s/it]                                                         {'loss': 1.0156, 'learning_rate': 1.7048449448890977e-05, 'epoch': 0.27}
 27%|██▋       | 2843/10395 [8:06:19<15:54:20,  7.58s/it] 27%|██▋       | 2844/10395 [8:06:26<15:45:53,  7.52s/it]                                                         {'loss': 0.8916, 'learning_rate': 1.704623892671687e-05, 'epoch': 0.27}
 27%|██▋       | 2844/10395 [8:06:26<15:45:53,  7.52s/it] 27%|██▋       | 2845/10395 [8:06:34<15:52:58,  7.57s/it]                                                         {'loss': 0.9675, 'learning_rate': 1.7044027720508948e-05, 'epoch': 0.27}
 27%|██▋       | 2845/10395 [8:06:34<15:52:58,  7.57s/it] 27%|██▋       | 2846/10395 [8:06:41<15:50:18,  7.55s/it]                                                         {'loss': 0.9714, 'learning_rate': 1.7041815830481867e-05, 'epoch': 0.27}
 27%|██▋       | 2846/10395 [8:06:41<15:50:18,  7.55s/it] 27%|██▋       | 2847/10395 [8:06:49<16:05:05,  7.67s/it]                                                         {'loss': 1.0198, 'learning_rate': 1.703960325685035e-05, 'epoch': 0.27}
 27%|██▋       | 2847/10395 [8:06:49<16:05:05,  7.67s/it] 27%|██▋       | 2848/10395 [8:06:57<16:21:32,  7.80s/it]                                                         {'loss': 0.9703, 'learning_rate': 1.7037389999829197e-05, 'epoch': 0.27}
 27%|██▋       | 2848/10395 [8:06:57<16:21:32,  7.80s/it] 27%|██▋       | 2849/10395 [8:07:05<16:30:15,  7.87s/it]                                                         {'loss': 1.0446, 'learning_rate': 1.703517605963326e-05, 'epoch': 0.27}
 27%|██▋       | 2849/10395 [8:07:05<16:30:15,  7.87s/it] 27%|██▋       | 2850/10395 [8:07:13<16:13:37,  7.74s/it]                                                         {'loss': 0.9669, 'learning_rate': 1.7032961436477468e-05, 'epoch': 0.27}
 27%|██▋       | 2850/10395 [8:07:13<16:13:37,  7.74s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 27%|██▋       | 2851/10395 [8:08:49<71:45:20, 34.24s/it]                                                         {'loss': 0.8829, 'learning_rate': 1.7030746130576805e-05, 'epoch': 0.27}
 27%|██▋       | 2851/10395 [8:08:49<71:45:20, 34.24s/it] 27%|██▋       | 2852/10395 [8:09:05<60:26:35, 28.85s/it]                                                         {'loss': 0.3529, 'learning_rate': 1.7028530142146335e-05, 'epoch': 0.27}
 27%|██▋       | 2852/10395 [8:09:05<60:26:35, 28.85s/it] 27%|██▋       | 2853/10395 [8:09:13<46:51:50, 22.37s/it]                                                         {'loss': 1.0684, 'learning_rate': 1.702631347140118e-05, 'epoch': 0.27}
 27%|██▋       | 2853/10395 [8:09:13<46:51:50, 22.37s/it] 27%|██▋       | 2854/10395 [8:09:21<37:58:04, 18.13s/it]                                                         {'loss': 0.9429, 'learning_rate': 1.7024096118556523e-05, 'epoch': 0.27}
 27%|██▋       | 2854/10395 [8:09:21<37:58:04, 18.13s/it] 27%|██▋       | 2855/10395 [8:09:28<31:14:00, 14.91s/it]                                                         {'loss': 0.9513, 'learning_rate': 1.702187808382763e-05, 'epoch': 0.27}
 27%|██▋       | 2855/10395 [8:09:28<31:14:00, 14.91s/it] 27%|██▋       | 2856/10395 [8:09:36<26:31:46, 12.67s/it]                                                         {'loss': 0.9481, 'learning_rate': 1.7019659367429815e-05, 'epoch': 0.27}
 27%|██▋       | 2856/10395 [8:09:36<26:31:46, 12.67s/it] 27%|██▋       | 2857/10395 [8:09:43<23:22:28, 11.16s/it]                                                         {'loss': 0.974, 'learning_rate': 1.7017439969578473e-05, 'epoch': 0.27}
 27%|██▋       | 2857/10395 [8:09:43<23:22:28, 11.16s/it] 27%|██▋       | 2858/10395 [8:09:51<21:31:48, 10.28s/it]                                                         {'loss': 0.9977, 'learning_rate': 1.7015219890489052e-05, 'epoch': 0.27}
 27%|██▋       | 2858/10395 [8:09:51<21:31:48, 10.28s/it] 28%|██▊       | 2859/10395 [8:09:59<19:42:23,  9.41s/it]                                                         {'loss': 0.913, 'learning_rate': 1.701299913037708e-05, 'epoch': 0.28}
 28%|██▊       | 2859/10395 [8:09:59<19:42:23,  9.41s/it] 28%|██▊       | 2860/10395 [8:10:07<18:42:14,  8.94s/it]                                                         {'loss': 0.9674, 'learning_rate': 1.7010777689458134e-05, 'epoch': 0.28}
 28%|██▊       | 2860/10395 [8:10:07<18:42:14,  8.94s/it] 28%|██▊       | 2861/10395 [8:10:15<18:19:58,  8.76s/it]                                                         {'loss': 0.9339, 'learning_rate': 1.700855556794788e-05, 'epoch': 0.28}
 28%|██▊       | 2861/10395 [8:10:15<18:19:58,  8.76s/it] 28%|██▊       | 2862/10395 [8:10:23<17:35:30,  8.41s/it]                                                         {'loss': 0.9235, 'learning_rate': 1.700633276606202e-05, 'epoch': 0.28}
 28%|██▊       | 2862/10395 [8:10:23<17:35:30,  8.41s/it] 28%|██▊       | 2863/10395 [8:10:31<17:38:51,  8.43s/it]                                                         {'loss': 0.9347, 'learning_rate': 1.700410928401635e-05, 'epoch': 0.28}
 28%|██▊       | 2863/10395 [8:10:31<17:38:51,  8.43s/it] 28%|██▊       | 2864/10395 [8:10:48<22:54:52, 10.95s/it]                                                         {'loss': 0.4075, 'learning_rate': 1.7001885122026724e-05, 'epoch': 0.28}
 28%|██▊       | 2864/10395 [8:10:48<22:54:52, 10.95s/it] 28%|██▊       | 2865/10395 [8:11:05<26:55:52, 12.88s/it]                                                         {'loss': 0.3571, 'learning_rate': 1.6999660280309047e-05, 'epoch': 0.28}
 28%|██▊       | 2865/10395 [8:11:05<26:55:52, 12.88s/it] 28%|██▊       | 2866/10395 [8:11:14<24:04:05, 11.51s/it]                                                         {'loss': 0.7888, 'learning_rate': 1.699743475907931e-05, 'epoch': 0.28}
 28%|██▊       | 2866/10395 [8:11:14<24:04:05, 11.51s/it] 28%|██▊       | 2867/10395 [8:11:22<21:51:06, 10.45s/it]                                                         {'loss': 0.9761, 'learning_rate': 1.699520855855356e-05, 'epoch': 0.28}
 28%|██▊       | 2867/10395 [8:11:22<21:51:06, 10.45s/it] 28%|██▊       | 2868/10395 [8:11:29<20:13:34,  9.67s/it]                                                         {'loss': 0.9518, 'learning_rate': 1.699298167894791e-05, 'epoch': 0.28}
 28%|██▊       | 2868/10395 [8:11:29<20:13:34,  9.67s/it] 28%|██▊       | 2869/10395 [8:11:38<19:28:35,  9.32s/it]                                                         {'loss': 1.0597, 'learning_rate': 1.699075412047855e-05, 'epoch': 0.28}
 28%|██▊       | 2869/10395 [8:11:38<19:28:35,  9.32s/it] 28%|██▊       | 2870/10395 [8:11:45<18:20:33,  8.78s/it]                                                         {'loss': 1.0048, 'learning_rate': 1.6988525883361713e-05, 'epoch': 0.28}
 28%|██▊       | 2870/10395 [8:11:45<18:20:33,  8.78s/it] 28%|██▊       | 2871/10395 [8:11:53<17:52:45,  8.55s/it]                                                         {'loss': 0.9616, 'learning_rate': 1.698629696781372e-05, 'epoch': 0.28}
 28%|██▊       | 2871/10395 [8:11:53<17:52:45,  8.55s/it] 28%|██▊       | 2872/10395 [8:12:01<17:24:38,  8.33s/it]                                                         {'loss': 0.9698, 'learning_rate': 1.6984067374050944e-05, 'epoch': 0.28}
 28%|██▊       | 2872/10395 [8:12:01<17:24:38,  8.33s/it] 28%|██▊       | 2873/10395 [8:12:09<16:48:13,  8.04s/it]                                                         {'loss': 0.9985, 'learning_rate': 1.6981837102289835e-05, 'epoch': 0.28}
 28%|██▊       | 2873/10395 [8:12:09<16:48:13,  8.04s/it] 28%|██▊       | 2874/10395 [8:12:17<16:41:55,  7.99s/it]                                                         {'loss': 0.9717, 'learning_rate': 1.69796061527469e-05, 'epoch': 0.28}
 28%|██▊       | 2874/10395 [8:12:17<16:41:55,  7.99s/it] 28%|██▊       | 2875/10395 [8:12:24<16:15:48,  7.79s/it]                                                         {'loss': 1.0011, 'learning_rate': 1.6977374525638713e-05, 'epoch': 0.28}
 28%|██▊       | 2875/10395 [8:12:24<16:15:48,  7.79s/it] 28%|██▊       | 2876/10395 [8:12:33<16:50:42,  8.07s/it]                                                         {'loss': 0.9087, 'learning_rate': 1.6975142221181923e-05, 'epoch': 0.28}
 28%|██▊       | 2876/10395 [8:12:33<16:50:42,  8.07s/it] 28%|██▊       | 2877/10395 [8:12:48<21:30:42, 10.30s/it]                                                         {'loss': 0.3771, 'learning_rate': 1.697290923959323e-05, 'epoch': 0.28}
 28%|██▊       | 2877/10395 [8:12:48<21:30:42, 10.30s/it] 28%|██▊       | 2878/10395 [8:12:57<20:49:33,  9.97s/it]                                                         {'loss': 0.833, 'learning_rate': 1.6970675581089408e-05, 'epoch': 0.28}
 28%|██▊       | 2878/10395 [8:12:57<20:49:33,  9.97s/it] 28%|██▊       | 2879/10395 [8:13:05<19:32:31,  9.36s/it]                                                         {'loss': 1.0211, 'learning_rate': 1.69684412458873e-05, 'epoch': 0.28}
 28%|██▊       | 2879/10395 [8:13:05<19:32:31,  9.36s/it] 28%|██▊       | 2880/10395 [8:13:13<18:24:38,  8.82s/it]                                                         {'loss': 1.0822, 'learning_rate': 1.69662062342038e-05, 'epoch': 0.28}
 28%|██▊       | 2880/10395 [8:13:13<18:24:38,  8.82s/it] 28%|██▊       | 2881/10395 [8:13:21<17:54:08,  8.58s/it]                                                         {'loss': 0.8901, 'learning_rate': 1.696397054625589e-05, 'epoch': 0.28}
 28%|██▊       | 2881/10395 [8:13:21<17:54:08,  8.58s/it] 28%|██▊       | 2882/10395 [8:13:29<17:26:36,  8.36s/it]                                                         {'loss': 0.9411, 'learning_rate': 1.6961734182260603e-05, 'epoch': 0.28}
 28%|██▊       | 2882/10395 [8:13:29<17:26:36,  8.36s/it] 28%|██▊       | 2883/10395 [8:13:36<16:40:13,  7.99s/it]                                                         {'loss': 1.0213, 'learning_rate': 1.695949714243504e-05, 'epoch': 0.28}
 28%|██▊       | 2883/10395 [8:13:36<16:40:13,  7.99s/it] 28%|██▊       | 2884/10395 [8:13:43<16:26:28,  7.88s/it]                                                         {'loss': 0.9824, 'learning_rate': 1.6957259426996362e-05, 'epoch': 0.28}
 28%|██▊       | 2884/10395 [8:13:43<16:26:28,  7.88s/it] 28%|██▊       | 2885/10395 [8:13:51<16:14:36,  7.79s/it]                                                         {'loss': 0.9156, 'learning_rate': 1.695502103616181e-05, 'epoch': 0.28}
 28%|██▊       | 2885/10395 [8:13:51<16:14:36,  7.79s/it] 28%|██▊       | 2886/10395 [8:13:59<16:38:17,  7.98s/it]                                                         {'loss': 0.9484, 'learning_rate': 1.6952781970148677e-05, 'epoch': 0.28}
 28%|██▊       | 2886/10395 [8:13:59<16:38:17,  7.98s/it] 28%|██▊       | 2887/10395 [8:14:08<16:54:42,  8.11s/it]                                                         {'loss': 0.9132, 'learning_rate': 1.695054222917433e-05, 'epoch': 0.28}
 28%|██▊       | 2887/10395 [8:14:08<16:54:42,  8.11s/it] 28%|██▊       | 2888/10395 [8:14:16<17:16:16,  8.28s/it]                                                         {'loss': 0.9499, 'learning_rate': 1.6948301813456196e-05, 'epoch': 0.28}
 28%|██▊       | 2888/10395 [8:14:16<17:16:16,  8.28s/it] 28%|██▊       | 2889/10395 [8:14:24<16:50:04,  8.07s/it]                                                         {'loss': 0.9868, 'learning_rate': 1.694606072321177e-05, 'epoch': 0.28}
 28%|██▊       | 2889/10395 [8:14:24<16:50:04,  8.07s/it] 28%|██▊       | 2890/10395 [8:14:32<16:35:04,  7.96s/it]                                                         {'loss': 0.9538, 'learning_rate': 1.6943818958658616e-05, 'epoch': 0.28}
 28%|██▊       | 2890/10395 [8:14:32<16:35:04,  7.96s/it] 28%|██▊       | 2891/10395 [8:14:39<16:12:23,  7.77s/it]                                                         {'loss': 1.0514, 'learning_rate': 1.6941576520014355e-05, 'epoch': 0.28}
 28%|██▊       | 2891/10395 [8:14:39<16:12:23,  7.77s/it] 28%|██▊       | 2892/10395 [8:14:47<16:09:47,  7.76s/it]                                                         {'loss': 0.9405, 'learning_rate': 1.6939333407496678e-05, 'epoch': 0.28}
 28%|██▊       | 2892/10395 [8:14:47<16:09:47,  7.76s/it] 28%|██▊       | 2893/10395 [8:14:54<15:59:19,  7.67s/it]                                                         {'loss': 0.9033, 'learning_rate': 1.693708962132334e-05, 'epoch': 0.28}
 28%|██▊       | 2893/10395 [8:14:54<15:59:19,  7.67s/it] 28%|██▊       | 2894/10395 [8:15:10<20:58:29, 10.07s/it]                                                         {'loss': 0.3485, 'learning_rate': 1.693484516171217e-05, 'epoch': 0.28}
 28%|██▊       | 2894/10395 [8:15:10<20:58:29, 10.07s/it] 28%|██▊       | 2895/10395 [8:15:18<19:27:17,  9.34s/it]                                                         {'loss': 1.0655, 'learning_rate': 1.6932600028881053e-05, 'epoch': 0.28}
 28%|██▊       | 2895/10395 [8:15:18<19:27:17,  9.34s/it] 28%|██▊       | 2896/10395 [8:15:25<18:04:04,  8.67s/it]                                                         {'loss': 0.898, 'learning_rate': 1.6930354223047936e-05, 'epoch': 0.28}
 28%|██▊       | 2896/10395 [8:15:25<18:04:04,  8.67s/it] 28%|██▊       | 2897/10395 [8:15:42<23:40:54, 11.37s/it]                                                         {'loss': 0.397, 'learning_rate': 1.6928107744430847e-05, 'epoch': 0.28}
 28%|██▊       | 2897/10395 [8:15:42<23:40:54, 11.37s/it] 28%|██▊       | 2898/10395 [8:15:51<21:50:17, 10.49s/it]                                                         {'loss': 0.9821, 'learning_rate': 1.692586059324786e-05, 'epoch': 0.28}
 28%|██▊       | 2898/10395 [8:15:51<21:50:17, 10.49s/it] 28%|██▊       | 2899/10395 [8:15:58<20:04:29,  9.64s/it]                                                         {'loss': 0.8821, 'learning_rate': 1.692361276971713e-05, 'epoch': 0.28}
 28%|██▊       | 2899/10395 [8:15:58<20:04:29,  9.64s/it] 28%|██▊       | 2900/10395 [8:16:06<18:41:12,  8.98s/it]                                                         {'loss': 0.9269, 'learning_rate': 1.692136427405686e-05, 'epoch': 0.28}
 28%|██▊       | 2900/10395 [8:16:06<18:41:12,  8.98s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 28%|██▊       | 2901/10395 [8:17:44<74:04:27, 35.58s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.6919115106485346e-05, 'epoch': 0.28}
 28%|██▊       | 2901/10395 [8:17:44<74:04:27, 35.58s/it] 28%|██▊       | 2902/10395 [8:17:51<56:16:41, 27.04s/it]                                                         {'loss': 1.0409, 'learning_rate': 1.6916865267220922e-05, 'epoch': 0.28}
 28%|██▊       | 2902/10395 [8:17:51<56:16:41, 27.04s/it] 28%|██▊       | 2903/10395 [8:17:58<43:58:22, 21.13s/it]                                                         {'loss': 0.9821, 'learning_rate': 1.6914614756481995e-05, 'epoch': 0.28}
 28%|██▊       | 2903/10395 [8:17:58<43:58:22, 21.13s/it] 28%|██▊       | 2904/10395 [8:18:06<35:29:14, 17.05s/it]                                                         {'loss': 0.9784, 'learning_rate': 1.691236357448705e-05, 'epoch': 0.28}
 28%|██▊       | 2904/10395 [8:18:06<35:29:14, 17.05s/it] 28%|██▊       | 2905/10395 [8:18:14<29:56:01, 14.39s/it]                                                         {'loss': 0.9828, 'learning_rate': 1.6910111721454617e-05, 'epoch': 0.28}
 28%|██▊       | 2905/10395 [8:18:14<29:56:01, 14.39s/it] 28%|██▊       | 2906/10395 [8:18:21<25:32:09, 12.28s/it]                                                         {'loss': 0.9846, 'learning_rate': 1.6907859197603306e-05, 'epoch': 0.28}
 28%|██▊       | 2906/10395 [8:18:21<25:32:09, 12.28s/it] 28%|██▊       | 2907/10395 [8:18:29<22:54:47, 11.02s/it]                                                         {'loss': 0.9024, 'learning_rate': 1.6905606003151785e-05, 'epoch': 0.28}
 28%|██▊       | 2907/10395 [8:18:29<22:54:47, 11.02s/it] 28%|██▊       | 2908/10395 [8:18:37<20:46:18,  9.99s/it]                                                         {'loss': 0.8916, 'learning_rate': 1.6903352138318793e-05, 'epoch': 0.28}
 28%|██▊       | 2908/10395 [8:18:37<20:46:18,  9.99s/it] 28%|██▊       | 2909/10395 [8:18:44<19:06:24,  9.19s/it]                                                         {'loss': 0.9276, 'learning_rate': 1.6901097603323125e-05, 'epoch': 0.28}
 28%|██▊       | 2909/10395 [8:18:44<19:06:24,  9.19s/it] 28%|██▊       | 2910/10395 [8:18:52<18:10:18,  8.74s/it]                                                         {'loss': 1.0113, 'learning_rate': 1.689884239838365e-05, 'epoch': 0.28}
 28%|██▊       | 2910/10395 [8:18:52<18:10:18,  8.74s/it] 28%|██▊       | 2911/10395 [8:18:59<17:28:36,  8.41s/it]                                                         {'loss': 0.9441, 'learning_rate': 1.68965865237193e-05, 'epoch': 0.28}
 28%|██▊       | 2911/10395 [8:18:59<17:28:36,  8.41s/it] 28%|██▊       | 2912/10395 [8:19:07<16:50:38,  8.10s/it]                                                         {'loss': 1.0796, 'learning_rate': 1.6894329979549068e-05, 'epoch': 0.28}
 28%|██▊       | 2912/10395 [8:19:07<16:50:38,  8.10s/it] 28%|██▊       | 2913/10395 [8:19:15<16:54:04,  8.13s/it]                                                         {'loss': 0.9533, 'learning_rate': 1.6892072766092014e-05, 'epoch': 0.28}
 28%|██▊       | 2913/10395 [8:19:15<16:54:04,  8.13s/it] 28%|██▊       | 2914/10395 [8:19:23<16:37:52,  8.00s/it]                                                         {'loss': 0.9685, 'learning_rate': 1.6889814883567264e-05, 'epoch': 0.28}
 28%|██▊       | 2914/10395 [8:19:23<16:37:52,  8.00s/it] 28%|██▊       | 2915/10395 [8:19:30<16:07:17,  7.76s/it]                                                         {'loss': 0.9048, 'learning_rate': 1.688755633219401e-05, 'epoch': 0.28}
 28%|██▊       | 2915/10395 [8:19:30<16:07:17,  7.76s/it] 28%|██▊       | 2916/10395 [8:19:38<16:03:48,  7.73s/it]                                                         {'loss': 0.9512, 'learning_rate': 1.6885297112191504e-05, 'epoch': 0.28}
 28%|██▊       | 2916/10395 [8:19:38<16:03:48,  7.73s/it] 28%|██▊       | 2917/10395 [8:19:45<15:44:03,  7.57s/it]                                                         {'loss': 1.0577, 'learning_rate': 1.688303722377907e-05, 'epoch': 0.28}
 28%|██▊       | 2917/10395 [8:19:45<15:44:03,  7.57s/it] 28%|██▊       | 2918/10395 [8:19:52<15:31:45,  7.48s/it]                                                         {'loss': 0.9216, 'learning_rate': 1.688077666717609e-05, 'epoch': 0.28}
 28%|██▊       | 2918/10395 [8:19:52<15:31:45,  7.48s/it] 28%|██▊       | 2919/10395 [8:19:59<15:22:08,  7.40s/it]                                                         {'loss': 0.8469, 'learning_rate': 1.687851544260202e-05, 'epoch': 0.28}
 28%|██▊       | 2919/10395 [8:19:59<15:22:08,  7.40s/it] 28%|██▊       | 2920/10395 [8:20:07<15:36:18,  7.52s/it]                                                         {'loss': 0.8997, 'learning_rate': 1.687625355027636e-05, 'epoch': 0.28}
 28%|██▊       | 2920/10395 [8:20:07<15:36:18,  7.52s/it] 28%|██▊       | 2921/10395 [8:20:24<21:38:42, 10.43s/it]                                                         {'loss': 0.3995, 'learning_rate': 1.687399099041871e-05, 'epoch': 0.28}
 28%|██▊       | 2921/10395 [8:20:24<21:38:42, 10.43s/it] 28%|██▊       | 2922/10395 [8:20:33<20:23:34,  9.82s/it]                                                         {'loss': 0.9233, 'learning_rate': 1.6871727763248697e-05, 'epoch': 0.28}
 28%|██▊       | 2922/10395 [8:20:33<20:23:34,  9.82s/it] 28%|██▊       | 2923/10395 [8:20:41<19:13:50,  9.27s/it]                                                         {'loss': 0.9657, 'learning_rate': 1.6869463868986046e-05, 'epoch': 0.28}
 28%|██▊       | 2923/10395 [8:20:41<19:13:50,  9.27s/it] 28%|██▊       | 2924/10395 [8:20:48<18:21:56,  8.85s/it]                                                         {'loss': 0.9446, 'learning_rate': 1.6867199307850514e-05, 'epoch': 0.28}
 28%|██▊       | 2924/10395 [8:20:48<18:21:56,  8.85s/it] 28%|██▊       | 2925/10395 [8:20:57<17:55:13,  8.64s/it]                                                         {'loss': 0.9556, 'learning_rate': 1.6864934080061955e-05, 'epoch': 0.28}
 28%|██▊       | 2925/10395 [8:20:57<17:55:13,  8.64s/it] 28%|██▊       | 2926/10395 [8:21:04<17:15:40,  8.32s/it]                                                         {'loss': 0.8399, 'learning_rate': 1.686266818584026e-05, 'epoch': 0.28}
 28%|██▊       | 2926/10395 [8:21:04<17:15:40,  8.32s/it] 28%|██▊       | 2927/10395 [8:21:12<16:42:14,  8.05s/it]                                                         {'loss': 0.8893, 'learning_rate': 1.686040162540541e-05, 'epoch': 0.28}
 28%|██▊       | 2927/10395 [8:21:12<16:42:14,  8.05s/it] 28%|██▊       | 2928/10395 [8:21:19<16:30:59,  7.96s/it]                                                         {'loss': 0.9425, 'learning_rate': 1.6858134398977428e-05, 'epoch': 0.28}
 28%|██▊       | 2928/10395 [8:21:19<16:30:59,  7.96s/it] 28%|██▊       | 2929/10395 [8:21:27<16:30:22,  7.96s/it]                                                         {'loss': 0.8609, 'learning_rate': 1.6855866506776413e-05, 'epoch': 0.28}
 28%|██▊       | 2929/10395 [8:21:27<16:30:22,  7.96s/it] 28%|██▊       | 2930/10395 [8:21:36<16:42:09,  8.05s/it]                                                         {'loss': 0.9669, 'learning_rate': 1.685359794902253e-05, 'epoch': 0.28}
 28%|██▊       | 2930/10395 [8:21:36<16:42:09,  8.05s/it] 28%|██▊       | 2931/10395 [8:21:51<21:01:22, 10.14s/it]                                                         {'loss': 0.3559, 'learning_rate': 1.6851328725936003e-05, 'epoch': 0.28}
 28%|██▊       | 2931/10395 [8:21:51<21:01:22, 10.14s/it] 28%|██▊       | 2932/10395 [8:21:58<19:20:28,  9.33s/it]                                                         {'loss': 1.0359, 'learning_rate': 1.6849058837737126e-05, 'epoch': 0.28}
 28%|██▊       | 2932/10395 [8:21:58<19:20:28,  9.33s/it] 28%|██▊       | 2933/10395 [8:22:06<18:31:11,  8.93s/it]                                                         {'loss': 0.9592, 'learning_rate': 1.6846788284646252e-05, 'epoch': 0.28}
 28%|██▊       | 2933/10395 [8:22:06<18:31:11,  8.93s/it] 28%|██▊       | 2934/10395 [8:22:14<17:37:26,  8.50s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.6844517066883806e-05, 'epoch': 0.28}
 28%|██▊       | 2934/10395 [8:22:14<17:37:26,  8.50s/it] 28%|██▊       | 2935/10395 [8:22:22<17:43:43,  8.56s/it]                                                         {'loss': 0.9882, 'learning_rate': 1.6842245184670268e-05, 'epoch': 0.28}
 28%|██▊       | 2935/10395 [8:22:22<17:43:43,  8.56s/it] 28%|██▊       | 2936/10395 [8:22:30<17:03:21,  8.23s/it]                                                         {'loss': 0.9075, 'learning_rate': 1.6839972638226188e-05, 'epoch': 0.28}
 28%|██▊       | 2936/10395 [8:22:30<17:03:21,  8.23s/it] 28%|██▊       | 2937/10395 [8:22:37<16:32:05,  7.98s/it]                                                         {'loss': 0.9386, 'learning_rate': 1.683769942777218e-05, 'epoch': 0.28}
 28%|██▊       | 2937/10395 [8:22:37<16:32:05,  7.98s/it] 28%|██▊       | 2938/10395 [8:22:45<16:11:55,  7.82s/it]                                                         {'loss': 0.9337, 'learning_rate': 1.683542555352893e-05, 'epoch': 0.28}
 28%|██▊       | 2938/10395 [8:22:45<16:11:55,  7.82s/it] 28%|██▊       | 2939/10395 [8:22:52<16:07:57,  7.79s/it]                                                         {'loss': 0.9693, 'learning_rate': 1.683315101571717e-05, 'epoch': 0.28}
 28%|██▊       | 2939/10395 [8:22:52<16:07:57,  7.79s/it] 28%|██▊       | 2940/10395 [8:23:00<16:08:01,  7.79s/it]                                                         {'loss': 1.0664, 'learning_rate': 1.683087581455771e-05, 'epoch': 0.28}
 28%|██▊       | 2940/10395 [8:23:00<16:08:01,  7.79s/it] 28%|██▊       | 2941/10395 [8:23:09<16:40:04,  8.05s/it]                                                         {'loss': 0.8843, 'learning_rate': 1.6828599950271428e-05, 'epoch': 0.28}
 28%|██▊       | 2941/10395 [8:23:09<16:40:04,  8.05s/it] 28%|██▊       | 2942/10395 [8:23:18<17:35:43,  8.50s/it]                                                         {'loss': 0.8755, 'learning_rate': 1.6826323423079257e-05, 'epoch': 0.28}
 28%|██▊       | 2942/10395 [8:23:18<17:35:43,  8.50s/it] 28%|██▊       | 2943/10395 [8:23:26<17:00:48,  8.22s/it]                                                         {'loss': 0.9836, 'learning_rate': 1.682404623320219e-05, 'epoch': 0.28}
 28%|██▊       | 2943/10395 [8:23:26<17:00:48,  8.22s/it] 28%|██▊       | 2944/10395 [8:23:33<16:31:12,  7.98s/it]                                                         {'loss': 0.9577, 'learning_rate': 1.6821768380861302e-05, 'epoch': 0.28}
 28%|██▊       | 2944/10395 [8:23:33<16:31:12,  7.98s/it] 28%|██▊       | 2945/10395 [8:23:41<16:11:13,  7.82s/it]                                                         {'loss': 0.9741, 'learning_rate': 1.6819489866277716e-05, 'epoch': 0.28}
 28%|██▊       | 2945/10395 [8:23:41<16:11:13,  7.82s/it] 28%|██▊       | 2946/10395 [8:23:48<16:04:47,  7.77s/it]                                                         {'loss': 0.8597, 'learning_rate': 1.6817210689672626e-05, 'epoch': 0.28}
 28%|██▊       | 2946/10395 [8:23:48<16:04:47,  7.77s/it] 28%|██▊       | 2947/10395 [8:23:57<16:26:58,  7.95s/it]                                                         {'loss': 0.95, 'learning_rate': 1.6814930851267295e-05, 'epoch': 0.28}
 28%|██▊       | 2947/10395 [8:23:57<16:26:58,  7.95s/it] 28%|██▊       | 2948/10395 [8:24:05<16:25:43,  7.94s/it]                                                         {'loss': 0.9117, 'learning_rate': 1.6812650351283038e-05, 'epoch': 0.28}
 28%|██▊       | 2948/10395 [8:24:05<16:25:43,  7.94s/it] 28%|██▊       | 2949/10395 [8:24:22<22:00:57, 10.64s/it]                                                         {'loss': 0.3826, 'learning_rate': 1.6810369189941242e-05, 'epoch': 0.28}
 28%|██▊       | 2949/10395 [8:24:22<22:00:57, 10.64s/it] 28%|██▊       | 2950/10395 [8:24:29<20:07:10,  9.73s/it]                                                         {'loss': 0.8937, 'learning_rate': 1.680808736746336e-05, 'epoch': 0.28}
 28%|██▊       | 2950/10395 [8:24:29<20:07:10,  9.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 28%|██▊       | 2951/10395 [8:26:11<76:56:56, 37.21s/it]                                                         {'loss': 1.0068, 'learning_rate': 1.6805804884070905e-05, 'epoch': 0.28}
 28%|██▊       | 2951/10395 [8:26:11<76:56:56, 37.21s/it] 28%|██▊       | 2952/10395 [8:26:18<58:15:53, 28.18s/it]                                                         {'loss': 0.9042, 'learning_rate': 1.6803521739985455e-05, 'epoch': 0.28}
 28%|██▊       | 2952/10395 [8:26:18<58:15:53, 28.18s/it] 28%|██▊       | 2953/10395 [8:26:25<45:18:12, 21.92s/it]                                                         {'loss': 0.9623, 'learning_rate': 1.6801237935428657e-05, 'epoch': 0.28}
 28%|██▊       | 2953/10395 [8:26:25<45:18:12, 21.92s/it] 28%|██▊       | 2954/10395 [8:26:34<37:15:09, 18.02s/it]                                                         {'loss': 0.8772, 'learning_rate': 1.6798953470622213e-05, 'epoch': 0.28}
 28%|██▊       | 2954/10395 [8:26:34<37:15:09, 18.02s/it] 28%|██▊       | 2955/10395 [8:26:41<30:44:44, 14.88s/it]                                                         {'loss': 0.9471, 'learning_rate': 1.6796668345787896e-05, 'epoch': 0.28}
 28%|██▊       | 2955/10395 [8:26:41<30:44:44, 14.88s/it] 28%|██▊       | 2956/10395 [8:26:49<26:27:03, 12.80s/it]                                                         {'loss': 0.9304, 'learning_rate': 1.6794382561147537e-05, 'epoch': 0.28}
 28%|██▊       | 2956/10395 [8:26:49<26:27:03, 12.80s/it] 28%|██▊       | 2957/10395 [8:26:57<23:22:42, 11.32s/it]                                                         {'loss': 0.863, 'learning_rate': 1.6792096116923043e-05, 'epoch': 0.28}
 28%|██▊       | 2957/10395 [8:26:57<23:22:42, 11.32s/it] 28%|██▊       | 2958/10395 [8:27:04<20:50:06, 10.09s/it]                                                         {'loss': 0.9606, 'learning_rate': 1.678980901333637e-05, 'epoch': 0.28}
 28%|██▊       | 2958/10395 [8:27:04<20:50:06, 10.09s/it] 28%|██▊       | 2959/10395 [8:27:12<19:24:30,  9.40s/it]                                                         {'loss': 0.9374, 'learning_rate': 1.678752125060955e-05, 'epoch': 0.28}
 28%|██▊       | 2959/10395 [8:27:12<19:24:30,  9.40s/it] 28%|██▊       | 2960/10395 [8:27:21<18:56:24,  9.17s/it]                                                         {'loss': 0.8846, 'learning_rate': 1.678523282896467e-05, 'epoch': 0.28}
 28%|██▊       | 2960/10395 [8:27:21<18:56:24,  9.17s/it] 28%|██▊       | 2961/10395 [8:27:28<17:58:14,  8.70s/it]                                                         {'loss': 0.9421, 'learning_rate': 1.6782943748623886e-05, 'epoch': 0.28}
 28%|██▊       | 2961/10395 [8:27:28<17:58:14,  8.70s/it] 28%|██▊       | 2962/10395 [8:27:37<17:41:30,  8.57s/it]                                                         {'loss': 0.9094, 'learning_rate': 1.6780654009809422e-05, 'epoch': 0.28}
 28%|██▊       | 2962/10395 [8:27:37<17:41:30,  8.57s/it] 29%|██▊       | 2963/10395 [8:27:45<17:40:22,  8.56s/it]                                                         {'loss': 0.9321, 'learning_rate': 1.6778363612743553e-05, 'epoch': 0.29}
 29%|██▊       | 2963/10395 [8:27:45<17:40:22,  8.56s/it] 29%|██▊       | 2964/10395 [8:27:53<17:11:57,  8.33s/it]                                                         {'loss': 0.9871, 'learning_rate': 1.6776072557648634e-05, 'epoch': 0.29}
 29%|██▊       | 2964/10395 [8:27:53<17:11:57,  8.33s/it] 29%|██▊       | 2965/10395 [8:28:01<16:44:52,  8.11s/it]                                                         {'loss': 0.9651, 'learning_rate': 1.677378084474707e-05, 'epoch': 0.29}
 29%|██▊       | 2965/10395 [8:28:01<16:44:52,  8.11s/it] 29%|██▊       | 2966/10395 [8:28:08<16:14:51,  7.87s/it]                                                         {'loss': 1.0377, 'learning_rate': 1.6771488474261334e-05, 'epoch': 0.29}
 29%|██▊       | 2966/10395 [8:28:08<16:14:51,  7.87s/it] 29%|██▊       | 2967/10395 [8:28:16<16:08:50,  7.83s/it]                                                         {'loss': 1.0045, 'learning_rate': 1.676919544641397e-05, 'epoch': 0.29}
 29%|██▊       | 2967/10395 [8:28:16<16:08:50,  7.83s/it] 29%|██▊       | 2968/10395 [8:28:24<16:30:04,  8.00s/it]                                                         {'loss': 0.9514, 'learning_rate': 1.6766901761427583e-05, 'epoch': 0.29}
 29%|██▊       | 2968/10395 [8:28:24<16:30:04,  8.00s/it] 29%|██▊       | 2969/10395 [8:28:32<16:31:20,  8.01s/it]                                                         {'loss': 0.9099, 'learning_rate': 1.6764607419524825e-05, 'epoch': 0.29}
 29%|██▊       | 2969/10395 [8:28:32<16:31:20,  8.01s/it] 29%|██▊       | 2970/10395 [8:28:40<16:20:43,  7.93s/it]                                                         {'loss': 0.9648, 'learning_rate': 1.6762312420928436e-05, 'epoch': 0.29}
 29%|██▊       | 2970/10395 [8:28:40<16:20:43,  7.93s/it] 29%|██▊       | 2971/10395 [8:28:47<16:02:39,  7.78s/it]                                                         {'loss': 0.9779, 'learning_rate': 1.6760016765861213e-05, 'epoch': 0.29}
 29%|██▊       | 2971/10395 [8:28:47<16:02:39,  7.78s/it] 29%|██▊       | 2972/10395 [8:28:55<15:49:09,  7.67s/it]                                                         {'loss': 0.8859, 'learning_rate': 1.675772045454601e-05, 'epoch': 0.29}
 29%|██▊       | 2972/10395 [8:28:55<15:49:09,  7.67s/it] 29%|██▊       | 2973/10395 [8:29:02<15:52:54,  7.70s/it]                                                         {'loss': 0.8623, 'learning_rate': 1.675542348720574e-05, 'epoch': 0.29}
 29%|██▊       | 2973/10395 [8:29:03<15:52:54,  7.70s/it] 29%|██▊       | 2974/10395 [8:29:10<15:46:09,  7.65s/it]                                                         {'loss': 0.9845, 'learning_rate': 1.6753125864063397e-05, 'epoch': 0.29}
 29%|██▊       | 2974/10395 [8:29:10<15:46:09,  7.65s/it] 29%|██▊       | 2975/10395 [8:29:18<15:50:22,  7.68s/it]                                                         {'loss': 0.9748, 'learning_rate': 1.675082758534203e-05, 'epoch': 0.29}
 29%|██▊       | 2975/10395 [8:29:18<15:50:22,  7.68s/it] 29%|██▊       | 2976/10395 [8:29:26<16:16:05,  7.89s/it]                                                         {'loss': 0.9922, 'learning_rate': 1.674852865126474e-05, 'epoch': 0.29}
 29%|██▊       | 2976/10395 [8:29:26<16:16:05,  7.89s/it] 29%|██▊       | 2977/10395 [8:29:33<15:53:28,  7.71s/it]                                                         {'loss': 0.9341, 'learning_rate': 1.6746229062054716e-05, 'epoch': 0.29}
 29%|██▊       | 2977/10395 [8:29:33<15:53:28,  7.71s/it] 29%|██▊       | 2978/10395 [8:29:50<21:38:47, 10.51s/it]                                                         {'loss': 0.3454, 'learning_rate': 1.6743928817935194e-05, 'epoch': 0.29}
 29%|██▊       | 2978/10395 [8:29:50<21:38:47, 10.51s/it] 29%|██▊       | 2979/10395 [8:29:58<19:53:44,  9.66s/it]                                                         {'loss': 0.9429, 'learning_rate': 1.6741627919129467e-05, 'epoch': 0.29}
 29%|██▊       | 2979/10395 [8:29:58<19:53:44,  9.66s/it] 29%|██▊       | 2980/10395 [8:30:06<18:32:46,  9.00s/it]                                                         {'loss': 0.9925, 'learning_rate': 1.673932636586091e-05, 'epoch': 0.29}
 29%|██▊       | 2980/10395 [8:30:06<18:32:46,  9.00s/it] 29%|██▊       | 2981/10395 [8:30:13<17:36:17,  8.55s/it]                                                         {'loss': 1.021, 'learning_rate': 1.6737024158352957e-05, 'epoch': 0.29}
 29%|██▊       | 2981/10395 [8:30:13<17:36:17,  8.55s/it] 29%|██▊       | 2982/10395 [8:30:21<17:07:32,  8.32s/it]                                                         {'loss': 0.9546, 'learning_rate': 1.673472129682909e-05, 'epoch': 0.29}
 29%|██▊       | 2982/10395 [8:30:21<17:07:32,  8.32s/it] 29%|██▊       | 2983/10395 [8:30:29<16:56:56,  8.23s/it]                                                         {'loss': 1.0552, 'learning_rate': 1.6732417781512874e-05, 'epoch': 0.29}
 29%|██▊       | 2983/10395 [8:30:29<16:56:56,  8.23s/it] 29%|██▊       | 2984/10395 [8:30:38<17:28:55,  8.49s/it]                                                         {'loss': 0.9301, 'learning_rate': 1.673011361262793e-05, 'epoch': 0.29}
 29%|██▊       | 2984/10395 [8:30:38<17:28:55,  8.49s/it] 29%|██▊       | 2985/10395 [8:30:45<16:50:22,  8.18s/it]                                                         {'loss': 0.9262, 'learning_rate': 1.6727808790397934e-05, 'epoch': 0.29}
 29%|██▊       | 2985/10395 [8:30:45<16:50:22,  8.18s/it] 29%|██▊       | 2986/10395 [8:30:53<16:25:27,  7.98s/it]                                                         {'loss': 0.9363, 'learning_rate': 1.672550331504664e-05, 'epoch': 0.29}
 29%|██▊       | 2986/10395 [8:30:53<16:25:27,  7.98s/it] 29%|██▊       | 2987/10395 [8:31:01<16:08:02,  7.84s/it]                                                         {'loss': 0.9898, 'learning_rate': 1.6723197186797854e-05, 'epoch': 0.29}
 29%|██▊       | 2987/10395 [8:31:01<16:08:02,  7.84s/it] 29%|██▊       | 2988/10395 [8:31:08<15:58:07,  7.76s/it]                                                         {'loss': 0.9079, 'learning_rate': 1.6720890405875458e-05, 'epoch': 0.29}
 29%|██▊       | 2988/10395 [8:31:09<15:58:07,  7.76s/it] 29%|██▉       | 2989/10395 [8:31:17<16:36:11,  8.07s/it]                                                         {'loss': 0.9441, 'learning_rate': 1.6718582972503382e-05, 'epoch': 0.29}
 29%|██▉       | 2989/10395 [8:31:17<16:36:11,  8.07s/it] 29%|██▉       | 2990/10395 [8:31:25<16:34:51,  8.06s/it]                                                         {'loss': 0.968, 'learning_rate': 1.6716274886905624e-05, 'epoch': 0.29}
 29%|██▉       | 2990/10395 [8:31:25<16:34:51,  8.06s/it] 29%|██▉       | 2991/10395 [8:31:34<16:53:41,  8.21s/it]                                                         {'loss': 0.988, 'learning_rate': 1.6713966149306257e-05, 'epoch': 0.29}
 29%|██▉       | 2991/10395 [8:31:34<16:53:41,  8.21s/it] 29%|██▉       | 2992/10395 [8:31:43<17:31:15,  8.52s/it]                                                         {'loss': 0.9468, 'learning_rate': 1.6711656759929403e-05, 'epoch': 0.29}
 29%|██▉       | 2992/10395 [8:31:43<17:31:15,  8.52s/it] 29%|██▉       | 2993/10395 [8:31:52<17:47:48,  8.66s/it]                                                         {'loss': 0.9139, 'learning_rate': 1.6709346718999254e-05, 'epoch': 0.29}
 29%|██▉       | 2993/10395 [8:31:52<17:47:48,  8.66s/it] 29%|██▉       | 2994/10395 [8:31:59<17:11:19,  8.36s/it]                                                         {'loss': 1.0302, 'learning_rate': 1.670703602674006e-05, 'epoch': 0.29}
 29%|██▉       | 2994/10395 [8:31:59<17:11:19,  8.36s/it] 29%|██▉       | 2995/10395 [8:32:07<16:50:57,  8.20s/it]                                                         {'loss': 1.0003, 'learning_rate': 1.6704724683376148e-05, 'epoch': 0.29}
 29%|██▉       | 2995/10395 [8:32:07<16:50:57,  8.20s/it] 29%|██▉       | 2996/10395 [8:32:15<16:27:19,  8.01s/it]                                                         {'loss': 0.9296, 'learning_rate': 1.6702412689131885e-05, 'epoch': 0.29}
 29%|██▉       | 2996/10395 [8:32:15<16:27:19,  8.01s/it] 29%|██▉       | 2997/10395 [8:32:32<21:56:21, 10.68s/it]                                                         {'loss': 0.4013, 'learning_rate': 1.6700100044231728e-05, 'epoch': 0.29}
 29%|██▉       | 2997/10395 [8:32:32<21:56:21, 10.68s/it] 29%|██▉       | 2998/10395 [8:32:39<20:05:03,  9.77s/it]                                                         {'loss': 1.0243, 'learning_rate': 1.6697786748900172e-05, 'epoch': 0.29}
 29%|██▉       | 2998/10395 [8:32:39<20:05:03,  9.77s/it] 29%|██▉       | 2999/10395 [8:32:47<18:39:29,  9.08s/it]                                                         {'loss': 0.9916, 'learning_rate': 1.6695472803361795e-05, 'epoch': 0.29}
 29%|██▉       | 2999/10395 [8:32:47<18:39:29,  9.08s/it] 29%|██▉       | 3000/10395 [8:32:55<17:54:46,  8.72s/it]                                                         {'loss': 0.9256, 'learning_rate': 1.6693158207841224e-05, 'epoch': 0.29}
 29%|██▉       | 3000/10395 [8:32:55<17:54:46,  8.72s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 29%|██▉       | 3001/10395 [8:34:34<73:32:03, 35.80s/it]                                                         {'loss': 1.0173, 'learning_rate': 1.669084296256316e-05, 'epoch': 0.29}
 29%|██▉       | 3001/10395 [8:34:34<73:32:03, 35.80s/it] 29%|██▉       | 3002/10395 [8:34:41<55:58:56, 27.26s/it]                                                         {'loss': 0.9644, 'learning_rate': 1.6688527067752355e-05, 'epoch': 0.29}
 29%|██▉       | 3002/10395 [8:34:41<55:58:56, 27.26s/it] 29%|██▉       | 3003/10395 [8:34:49<44:09:34, 21.51s/it]                                                         {'loss': 0.8621, 'learning_rate': 1.668621052363364e-05, 'epoch': 0.29}
 29%|██▉       | 3003/10395 [8:34:49<44:09:34, 21.51s/it] 29%|██▉       | 3004/10395 [8:34:56<35:26:36, 17.26s/it]                                                         {'loss': 0.9739, 'learning_rate': 1.6683893330431895e-05, 'epoch': 0.29}
 29%|██▉       | 3004/10395 [8:34:56<35:26:36, 17.26s/it] 29%|██▉       | 3005/10395 [8:35:04<29:36:35, 14.42s/it]                                                         {'loss': 0.9239, 'learning_rate': 1.6681575488372067e-05, 'epoch': 0.29}
 29%|██▉       | 3005/10395 [8:35:04<29:36:35, 14.42s/it] 29%|██▉       | 3006/10395 [8:35:13<26:12:02, 12.77s/it]                                                         {'loss': 0.9263, 'learning_rate': 1.667925699767917e-05, 'epoch': 0.29}
 29%|██▉       | 3006/10395 [8:35:13<26:12:02, 12.77s/it] 29%|██▉       | 3007/10395 [8:35:21<23:03:29, 11.24s/it]                                                         {'loss': 0.951, 'learning_rate': 1.6676937858578278e-05, 'epoch': 0.29}
 29%|██▉       | 3007/10395 [8:35:21<23:03:29, 11.24s/it] 29%|██▉       | 3008/10395 [8:35:28<20:43:44, 10.10s/it]                                                         {'loss': 0.946, 'learning_rate': 1.667461807129453e-05, 'epoch': 0.29}
 29%|██▉       | 3008/10395 [8:35:28<20:43:44, 10.10s/it] 29%|██▉       | 3009/10395 [8:35:37<20:06:43,  9.80s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.6672297636053118e-05, 'epoch': 0.29}
 29%|██▉       | 3009/10395 [8:35:37<20:06:43,  9.80s/it] 29%|██▉       | 3010/10395 [8:35:44<18:24:04,  8.97s/it]                                                         {'loss': 1.0223, 'learning_rate': 1.6669976553079313e-05, 'epoch': 0.29}
 29%|██▉       | 3010/10395 [8:35:44<18:24:04,  8.97s/it] 29%|██▉       | 3011/10395 [8:35:52<17:24:19,  8.49s/it]                                                         {'loss': 0.8784, 'learning_rate': 1.666765482259844e-05, 'epoch': 0.29}
 29%|██▉       | 3011/10395 [8:35:52<17:24:19,  8.49s/it] 29%|██▉       | 3012/10395 [8:36:10<23:27:06, 11.44s/it]                                                         {'loss': 0.4776, 'learning_rate': 1.666533244483588e-05, 'epoch': 0.29}
 29%|██▉       | 3012/10395 [8:36:10<23:27:06, 11.44s/it] 29%|██▉       | 3013/10395 [8:36:19<21:39:29, 10.56s/it]                                                         {'loss': 0.962, 'learning_rate': 1.6663009420017097e-05, 'epoch': 0.29}
 29%|██▉       | 3013/10395 [8:36:19<21:39:29, 10.56s/it] 29%|██▉       | 3014/10395 [8:36:26<19:54:56,  9.71s/it]                                                         {'loss': 0.9858, 'learning_rate': 1.6660685748367592e-05, 'epoch': 0.29}
 29%|██▉       | 3014/10395 [8:36:26<19:54:56,  9.71s/it] 29%|██▉       | 3015/10395 [8:36:35<19:26:38,  9.48s/it]                                                         {'loss': 0.9488, 'learning_rate': 1.6658361430112956e-05, 'epoch': 0.29}
 29%|██▉       | 3015/10395 [8:36:35<19:26:38,  9.48s/it] 29%|██▉       | 3016/10395 [8:36:43<18:39:43,  9.10s/it]                                                         {'loss': 0.9675, 'learning_rate': 1.6656036465478814e-05, 'epoch': 0.29}
 29%|██▉       | 3016/10395 [8:36:43<18:39:43,  9.10s/it] 29%|██▉       | 3017/10395 [8:36:51<17:39:39,  8.62s/it]                                                         {'loss': 1.0166, 'learning_rate': 1.6653710854690877e-05, 'epoch': 0.29}
 29%|██▉       | 3017/10395 [8:36:51<17:39:39,  8.62s/it] 29%|██▉       | 3018/10395 [8:36:59<17:13:03,  8.40s/it]                                                         {'loss': 0.9737, 'learning_rate': 1.665138459797491e-05, 'epoch': 0.29}
 29%|██▉       | 3018/10395 [8:36:59<17:13:03,  8.40s/it] 29%|██▉       | 3019/10395 [8:37:07<17:03:55,  8.33s/it]                                                         {'loss': 0.9648, 'learning_rate': 1.6649057695556746e-05, 'epoch': 0.29}
 29%|██▉       | 3019/10395 [8:37:07<17:03:55,  8.33s/it] 29%|██▉       | 3020/10395 [8:37:15<16:34:10,  8.09s/it]                                                         {'loss': 0.9386, 'learning_rate': 1.664673014766226e-05, 'epoch': 0.29}
 29%|██▉       | 3020/10395 [8:37:15<16:34:10,  8.09s/it] 29%|██▉       | 3021/10395 [8:37:23<16:44:40,  8.17s/it]                                                         {'loss': 0.9815, 'learning_rate': 1.6644401954517426e-05, 'epoch': 0.29}
 29%|██▉       | 3021/10395 [8:37:23<16:44:40,  8.17s/it] 29%|██▉       | 3022/10395 [8:37:30<16:09:00,  7.89s/it]                                                         {'loss': 0.9778, 'learning_rate': 1.6642073116348243e-05, 'epoch': 0.29}
 29%|██▉       | 3022/10395 [8:37:30<16:09:00,  7.89s/it] 29%|██▉       | 3023/10395 [8:37:38<15:52:44,  7.75s/it]                                                         {'loss': 0.984, 'learning_rate': 1.6639743633380796e-05, 'epoch': 0.29}
 29%|██▉       | 3023/10395 [8:37:38<15:52:44,  7.75s/it] 29%|██▉       | 3024/10395 [8:37:45<15:55:37,  7.78s/it]                                                         {'loss': 0.9829, 'learning_rate': 1.6637413505841225e-05, 'epoch': 0.29}
 29%|██▉       | 3024/10395 [8:37:45<15:55:37,  7.78s/it] 29%|██▉       | 3025/10395 [8:37:54<16:09:25,  7.89s/it]                                                         {'loss': 0.9953, 'learning_rate': 1.663508273395574e-05, 'epoch': 0.29}
 29%|██▉       | 3025/10395 [8:37:54<16:09:25,  7.89s/it] 29%|██▉       | 3026/10395 [8:38:01<15:59:07,  7.81s/it]                                                         {'loss': 1.0878, 'learning_rate': 1.66327513179506e-05, 'epoch': 0.29}
 29%|██▉       | 3026/10395 [8:38:01<15:59:07,  7.81s/it] 29%|██▉       | 3027/10395 [8:38:09<16:01:39,  7.83s/it]                                                         {'loss': 0.9564, 'learning_rate': 1.6630419258052136e-05, 'epoch': 0.29}
 29%|██▉       | 3027/10395 [8:38:09<16:01:39,  7.83s/it] 29%|██▉       | 3028/10395 [8:38:17<15:55:33,  7.78s/it]                                                         {'loss': 0.9886, 'learning_rate': 1.6628086554486737e-05, 'epoch': 0.29}
 29%|██▉       | 3028/10395 [8:38:17<15:55:33,  7.78s/it] 29%|██▉       | 3029/10395 [8:38:24<15:52:35,  7.76s/it]                                                         {'loss': 0.9533, 'learning_rate': 1.6625753207480863e-05, 'epoch': 0.29}
 29%|██▉       | 3029/10395 [8:38:24<15:52:35,  7.76s/it] 29%|██▉       | 3030/10395 [8:38:32<15:48:41,  7.73s/it]                                                         {'loss': 1.0294, 'learning_rate': 1.6623419217261026e-05, 'epoch': 0.29}
 29%|██▉       | 3030/10395 [8:38:32<15:48:41,  7.73s/it] 29%|██▉       | 3031/10395 [8:38:40<15:39:32,  7.66s/it]                                                         {'loss': 0.9665, 'learning_rate': 1.6621084584053807e-05, 'epoch': 0.29}
 29%|██▉       | 3031/10395 [8:38:40<15:39:32,  7.66s/it] 29%|██▉       | 3032/10395 [8:38:49<16:32:37,  8.09s/it]                                                         {'loss': 0.9271, 'learning_rate': 1.6618749308085847e-05, 'epoch': 0.29}
 29%|██▉       | 3032/10395 [8:38:49<16:32:37,  8.09s/it] 29%|██▉       | 3033/10395 [8:38:58<17:05:06,  8.35s/it]                                                         {'loss': 0.9033, 'learning_rate': 1.6616413389583844e-05, 'epoch': 0.29}
 29%|██▉       | 3033/10395 [8:38:58<17:05:06,  8.35s/it] 29%|██▉       | 3034/10395 [8:39:06<17:15:34,  8.44s/it]                                                         {'loss': 0.9293, 'learning_rate': 1.661407682877457e-05, 'epoch': 0.29}
 29%|██▉       | 3034/10395 [8:39:06<17:15:34,  8.44s/it] 29%|██▉       | 3035/10395 [8:39:16<17:46:49,  8.70s/it]                                                         {'loss': 0.8847, 'learning_rate': 1.6611739625884854e-05, 'epoch': 0.29}
 29%|██▉       | 3035/10395 [8:39:16<17:46:49,  8.70s/it] 29%|██▉       | 3036/10395 [8:39:25<18:07:44,  8.87s/it]                                                         {'loss': 0.8031, 'learning_rate': 1.6609401781141583e-05, 'epoch': 0.29}
 29%|██▉       | 3036/10395 [8:39:25<18:07:44,  8.87s/it] 29%|██▉       | 3037/10395 [8:39:32<17:06:29,  8.37s/it]                                                         {'loss': 1.031, 'learning_rate': 1.6607063294771712e-05, 'epoch': 0.29}
 29%|██▉       | 3037/10395 [8:39:32<17:06:29,  8.37s/it] 29%|██▉       | 3038/10395 [8:39:41<17:26:40,  8.54s/it]                                                         {'loss': 0.8499, 'learning_rate': 1.6604724167002255e-05, 'epoch': 0.29}
 29%|██▉       | 3038/10395 [8:39:41<17:26:40,  8.54s/it] 29%|██▉       | 3039/10395 [8:39:49<16:52:51,  8.26s/it]                                                         {'loss': 1.0005, 'learning_rate': 1.660238439806029e-05, 'epoch': 0.29}
 29%|██▉       | 3039/10395 [8:39:49<16:52:51,  8.26s/it] 29%|██▉       | 3040/10395 [8:40:06<22:38:22, 11.08s/it]                                                         {'loss': 0.4059, 'learning_rate': 1.6600043988172954e-05, 'epoch': 0.29}
 29%|██▉       | 3040/10395 [8:40:06<22:38:22, 11.08s/it] 29%|██▉       | 3041/10395 [8:40:14<20:30:28, 10.04s/it]                                                         {'loss': 0.9557, 'learning_rate': 1.6597702937567458e-05, 'epoch': 0.29}
 29%|██▉       | 3041/10395 [8:40:14<20:30:28, 10.04s/it] 29%|██▉       | 3042/10395 [8:40:21<18:52:29,  9.24s/it]                                                         {'loss': 1.042, 'learning_rate': 1.6595361246471057e-05, 'epoch': 0.29}
 29%|██▉       | 3042/10395 [8:40:21<18:52:29,  9.24s/it] 29%|██▉       | 3043/10395 [8:40:29<17:48:29,  8.72s/it]                                                         {'loss': 0.9027, 'learning_rate': 1.659301891511108e-05, 'epoch': 0.29}
 29%|██▉       | 3043/10395 [8:40:29<17:48:29,  8.72s/it] 29%|██▉       | 3044/10395 [8:40:38<17:55:52,  8.78s/it]                                                         {'loss': 0.9002, 'learning_rate': 1.659067594371492e-05, 'epoch': 0.29}
 29%|██▉       | 3044/10395 [8:40:38<17:55:52,  8.78s/it] 29%|██▉       | 3045/10395 [8:40:45<17:12:47,  8.43s/it]                                                         {'loss': 0.9506, 'learning_rate': 1.658833233251002e-05, 'epoch': 0.29}
 29%|██▉       | 3045/10395 [8:40:45<17:12:47,  8.43s/it] 29%|██▉       | 3046/10395 [8:40:53<16:46:08,  8.21s/it]                                                         {'loss': 0.8876, 'learning_rate': 1.6585988081723898e-05, 'epoch': 0.29}
 29%|██▉       | 3046/10395 [8:40:53<16:46:08,  8.21s/it] 29%|██▉       | 3047/10395 [8:41:01<16:31:34,  8.10s/it]                                                         {'loss': 1.0559, 'learning_rate': 1.6583643191584124e-05, 'epoch': 0.29}
 29%|██▉       | 3047/10395 [8:41:01<16:31:34,  8.10s/it] 29%|██▉       | 3048/10395 [8:41:08<16:07:10,  7.90s/it]                                                         {'loss': 0.9579, 'learning_rate': 1.6581297662318343e-05, 'epoch': 0.29}
 29%|██▉       | 3048/10395 [8:41:08<16:07:10,  7.90s/it] 29%|██▉       | 3049/10395 [8:41:16<16:02:30,  7.86s/it]                                                         {'loss': 0.9392, 'learning_rate': 1.6578951494154245e-05, 'epoch': 0.29}
 29%|██▉       | 3049/10395 [8:41:16<16:02:30,  7.86s/it] 29%|██▉       | 3050/10395 [8:41:24<16:03:15,  7.87s/it]                                                         {'loss': 0.9506, 'learning_rate': 1.6576604687319597e-05, 'epoch': 0.29}
 29%|██▉       | 3050/10395 [8:41:24<16:03:15,  7.87s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 29%|██▉       | 3051/10395 [8:43:02<71:14:46, 34.92s/it]                                                         {'loss': 0.9879, 'learning_rate': 1.657425724204222e-05, 'epoch': 0.29}
 29%|██▉       | 3051/10395 [8:43:02<71:14:46, 34.92s/it] 29%|██▉       | 3052/10395 [8:43:18<59:41:31, 29.26s/it]                                                         {'loss': 0.3757, 'learning_rate': 1.657190915855e-05, 'epoch': 0.29}
 29%|██▉       | 3052/10395 [8:43:18<59:41:31, 29.26s/it] 29%|██▉       | 3053/10395 [8:43:27<47:14:55, 23.17s/it]                                                         {'loss': 0.9876, 'learning_rate': 1.6569560437070883e-05, 'epoch': 0.29}
 29%|██▉       | 3053/10395 [8:43:27<47:14:55, 23.17s/it] 29%|██▉       | 3054/10395 [8:43:34<37:32:56, 18.41s/it]                                                         {'loss': 0.9405, 'learning_rate': 1.6567211077832878e-05, 'epoch': 0.29}
 29%|██▉       | 3054/10395 [8:43:34<37:32:56, 18.41s/it] 29%|██▉       | 3055/10395 [8:43:42<30:56:52, 15.18s/it]                                                         {'loss': 0.8654, 'learning_rate': 1.6564861081064053e-05, 'epoch': 0.29}
 29%|██▉       | 3055/10395 [8:43:42<30:56:52, 15.18s/it] 29%|██▉       | 3056/10395 [8:43:50<26:30:14, 13.00s/it]                                                         {'loss': 0.8989, 'learning_rate': 1.6562510446992548e-05, 'epoch': 0.29}
 29%|██▉       | 3056/10395 [8:43:50<26:30:14, 13.00s/it] 29%|██▉       | 3057/10395 [8:43:58<23:39:24, 11.61s/it]                                                         {'loss': 0.8989, 'learning_rate': 1.656015917584655e-05, 'epoch': 0.29}
 29%|██▉       | 3057/10395 [8:43:58<23:39:24, 11.61s/it] 29%|██▉       | 3058/10395 [8:44:06<21:09:37, 10.38s/it]                                                         {'loss': 0.958, 'learning_rate': 1.655780726785432e-05, 'epoch': 0.29}
 29%|██▉       | 3058/10395 [8:44:06<21:09:37, 10.38s/it] 29%|██▉       | 3059/10395 [8:44:13<19:15:10,  9.45s/it]                                                         {'loss': 0.883, 'learning_rate': 1.6555454723244176e-05, 'epoch': 0.29}
 29%|██▉       | 3059/10395 [8:44:13<19:15:10,  9.45s/it] 29%|██▉       | 3060/10395 [8:44:30<24:00:17, 11.78s/it]                                                         {'loss': 0.3976, 'learning_rate': 1.655310154224449e-05, 'epoch': 0.29}
 29%|██▉       | 3060/10395 [8:44:30<24:00:17, 11.78s/it] 29%|██▉       | 3061/10395 [8:44:38<21:18:10, 10.46s/it]                                                         {'loss': 1.0043, 'learning_rate': 1.6550747725083716e-05, 'epoch': 0.29}
 29%|██▉       | 3061/10395 [8:44:38<21:18:10, 10.46s/it] 29%|██▉       | 3062/10395 [8:44:45<19:38:54,  9.65s/it]                                                         {'loss': 0.9782, 'learning_rate': 1.654839327199035e-05, 'epoch': 0.29}
 29%|██▉       | 3062/10395 [8:44:45<19:38:54,  9.65s/it] 29%|██▉       | 3063/10395 [8:44:53<18:18:29,  8.99s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.654603818319296e-05, 'epoch': 0.29}
 29%|██▉       | 3063/10395 [8:44:53<18:18:29,  8.99s/it] 29%|██▉       | 3064/10395 [8:45:02<18:13:20,  8.95s/it]                                                         {'loss': 0.8945, 'learning_rate': 1.654368245892017e-05, 'epoch': 0.29}
 29%|██▉       | 3064/10395 [8:45:02<18:13:20,  8.95s/it] 29%|██▉       | 3065/10395 [8:45:11<18:31:55,  9.10s/it]                                                         {'loss': 0.9341, 'learning_rate': 1.6541326099400673e-05, 'epoch': 0.29}
 29%|██▉       | 3065/10395 [8:45:11<18:31:55,  9.10s/it] 29%|██▉       | 3066/10395 [8:45:18<17:27:49,  8.58s/it]                                                         {'loss': 0.9306, 'learning_rate': 1.6538969104863215e-05, 'epoch': 0.29}
 29%|██▉       | 3066/10395 [8:45:18<17:27:49,  8.58s/it] 30%|██▉       | 3067/10395 [8:45:26<16:57:20,  8.33s/it]                                                         {'loss': 0.8644, 'learning_rate': 1.6536611475536613e-05, 'epoch': 0.3}
 30%|██▉       | 3067/10395 [8:45:26<16:57:20,  8.33s/it] 30%|██▉       | 3068/10395 [8:45:34<16:54:09,  8.30s/it]                                                         {'loss': 1.0023, 'learning_rate': 1.6534253211649735e-05, 'epoch': 0.3}
 30%|██▉       | 3068/10395 [8:45:34<16:54:09,  8.30s/it] 30%|██▉       | 3069/10395 [8:45:42<16:26:51,  8.08s/it]                                                         {'loss': 0.8987, 'learning_rate': 1.6531894313431522e-05, 'epoch': 0.3}
 30%|██▉       | 3069/10395 [8:45:42<16:26:51,  8.08s/it] 30%|██▉       | 3070/10395 [8:45:59<21:40:59, 10.66s/it]                                                         {'loss': 0.3567, 'learning_rate': 1.6529534781110966e-05, 'epoch': 0.3}
 30%|██▉       | 3070/10395 [8:45:59<21:40:59, 10.66s/it] 30%|██▉       | 3071/10395 [8:46:06<19:45:20,  9.71s/it]                                                         {'loss': 0.9696, 'learning_rate': 1.6527174614917126e-05, 'epoch': 0.3}
 30%|██▉       | 3071/10395 [8:46:06<19:45:20,  9.71s/it] 30%|██▉       | 3072/10395 [8:46:15<19:00:24,  9.34s/it]                                                         {'loss': 0.8882, 'learning_rate': 1.6524813815079124e-05, 'epoch': 0.3}
 30%|██▉       | 3072/10395 [8:46:15<19:00:24,  9.34s/it] 30%|██▉       | 3073/10395 [8:46:33<24:09:58, 11.88s/it]                                                         {'loss': 0.3994, 'learning_rate': 1.652245238182614e-05, 'epoch': 0.3}
 30%|██▉       | 3073/10395 [8:46:33<24:09:58, 11.88s/it] 30%|██▉       | 3074/10395 [8:46:41<21:52:54, 10.76s/it]                                                         {'loss': 0.8708, 'learning_rate': 1.652009031538742e-05, 'epoch': 0.3}
 30%|██▉       | 3074/10395 [8:46:41<21:52:54, 10.76s/it] 30%|██▉       | 3075/10395 [8:46:48<19:56:41,  9.81s/it]                                                         {'loss': 1.0308, 'learning_rate': 1.6517727615992263e-05, 'epoch': 0.3}
 30%|██▉       | 3075/10395 [8:46:48<19:56:41,  9.81s/it] 30%|██▉       | 3076/10395 [8:46:55<18:16:38,  8.99s/it]                                                         {'loss': 1.0387, 'learning_rate': 1.6515364283870037e-05, 'epoch': 0.3}
 30%|██▉       | 3076/10395 [8:46:55<18:16:38,  8.99s/it] 30%|██▉       | 3077/10395 [8:47:03<17:25:38,  8.57s/it]                                                         {'loss': 0.9706, 'learning_rate': 1.651300031925017e-05, 'epoch': 0.3}
 30%|██▉       | 3077/10395 [8:47:03<17:25:38,  8.57s/it] 30%|██▉       | 3078/10395 [8:47:11<17:17:16,  8.51s/it]                                                         {'loss': 0.9925, 'learning_rate': 1.6510635722362152e-05, 'epoch': 0.3}
 30%|██▉       | 3078/10395 [8:47:11<17:17:16,  8.51s/it] 30%|██▉       | 3079/10395 [8:47:19<16:43:01,  8.23s/it]                                                         {'loss': 1.0272, 'learning_rate': 1.650827049343553e-05, 'epoch': 0.3}
 30%|██▉       | 3079/10395 [8:47:19<16:43:01,  8.23s/it] 30%|██▉       | 3080/10395 [8:47:26<16:17:09,  8.01s/it]                                                         {'loss': 0.9365, 'learning_rate': 1.6505904632699915e-05, 'epoch': 0.3}
 30%|██▉       | 3080/10395 [8:47:26<16:17:09,  8.01s/it] 30%|██▉       | 3081/10395 [8:47:34<16:16:01,  8.01s/it]                                                         {'loss': 0.992, 'learning_rate': 1.6503538140384984e-05, 'epoch': 0.3}
 30%|██▉       | 3081/10395 [8:47:34<16:16:01,  8.01s/it] 30%|██▉       | 3082/10395 [8:47:41<15:43:42,  7.74s/it]                                                         {'loss': 0.97, 'learning_rate': 1.650117101672047e-05, 'epoch': 0.3}
 30%|██▉       | 3082/10395 [8:47:41<15:43:42,  7.74s/it] 30%|██▉       | 3083/10395 [8:47:50<16:00:13,  7.88s/it]                                                         {'loss': 1.01, 'learning_rate': 1.6498803261936164e-05, 'epoch': 0.3}
 30%|██▉       | 3083/10395 [8:47:50<16:00:13,  7.88s/it] 30%|██▉       | 3084/10395 [8:48:00<17:25:54,  8.58s/it]                                                         {'loss': 0.8554, 'learning_rate': 1.6496434876261926e-05, 'epoch': 0.3}
 30%|██▉       | 3084/10395 [8:48:00<17:25:54,  8.58s/it] 30%|██▉       | 3085/10395 [8:48:08<17:07:13,  8.43s/it]                                                         {'loss': 1.01, 'learning_rate': 1.649406585992767e-05, 'epoch': 0.3}
 30%|██▉       | 3085/10395 [8:48:08<17:07:13,  8.43s/it] 30%|██▉       | 3086/10395 [8:48:15<16:26:36,  8.10s/it]                                                         {'loss': 1.0091, 'learning_rate': 1.6491696213163386e-05, 'epoch': 0.3}
 30%|██▉       | 3086/10395 [8:48:15<16:26:36,  8.10s/it] 30%|██▉       | 3087/10395 [8:48:33<22:05:43, 10.88s/it]                                                         {'loss': 0.4084, 'learning_rate': 1.64893259361991e-05, 'epoch': 0.3}
 30%|██▉       | 3087/10395 [8:48:33<22:05:43, 10.88s/it] 30%|██▉       | 3088/10395 [8:48:40<20:01:45,  9.87s/it]                                                         {'loss': 0.994, 'learning_rate': 1.648695502926492e-05, 'epoch': 0.3}
 30%|██▉       | 3088/10395 [8:48:40<20:01:45,  9.87s/it] 30%|██▉       | 3089/10395 [8:48:48<18:46:06,  9.25s/it]                                                         {'loss': 0.9676, 'learning_rate': 1.6484583492591013e-05, 'epoch': 0.3}
 30%|██▉       | 3089/10395 [8:48:48<18:46:06,  9.25s/it] 30%|██▉       | 3090/10395 [8:48:55<17:40:49,  8.71s/it]                                                         {'loss': 0.9211, 'learning_rate': 1.6482211326407595e-05, 'epoch': 0.3}
 30%|██▉       | 3090/10395 [8:48:55<17:40:49,  8.71s/it] 30%|██▉       | 3091/10395 [8:49:05<18:19:00,  9.03s/it]                                                         {'loss': 0.9336, 'learning_rate': 1.6479838530944952e-05, 'epoch': 0.3}
 30%|██▉       | 3091/10395 [8:49:05<18:19:00,  9.03s/it] 30%|██▉       | 3092/10395 [8:49:13<17:21:02,  8.55s/it]                                                         {'loss': 0.9714, 'learning_rate': 1.6477465106433434e-05, 'epoch': 0.3}
 30%|██▉       | 3092/10395 [8:49:13<17:21:02,  8.55s/it] 30%|██▉       | 3093/10395 [8:49:20<16:35:42,  8.18s/it]                                                         {'loss': 0.9579, 'learning_rate': 1.6475091053103446e-05, 'epoch': 0.3}
 30%|██▉       | 3093/10395 [8:49:20<16:35:42,  8.18s/it] 30%|██▉       | 3094/10395 [8:49:28<16:35:21,  8.18s/it]                                                         {'loss': 0.9165, 'learning_rate': 1.6472716371185456e-05, 'epoch': 0.3}
 30%|██▉       | 3094/10395 [8:49:28<16:35:21,  8.18s/it] 30%|██▉       | 3095/10395 [8:49:36<16:33:42,  8.17s/it]                                                         {'loss': 1.0036, 'learning_rate': 1.6470341060909993e-05, 'epoch': 0.3}
 30%|██▉       | 3095/10395 [8:49:36<16:33:42,  8.17s/it] 30%|██▉       | 3096/10395 [8:49:44<16:14:06,  8.01s/it]                                                         {'loss': 0.9819, 'learning_rate': 1.646796512250765e-05, 'epoch': 0.3}
 30%|██▉       | 3096/10395 [8:49:44<16:14:06,  8.01s/it] 30%|██▉       | 3097/10395 [8:49:53<17:01:11,  8.40s/it]                                                         {'loss': 0.9351, 'learning_rate': 1.6465588556209068e-05, 'epoch': 0.3}
 30%|██▉       | 3097/10395 [8:49:53<17:01:11,  8.40s/it] 30%|██▉       | 3098/10395 [8:50:01<16:26:08,  8.11s/it]                                                         {'loss': 0.8732, 'learning_rate': 1.646321136224497e-05, 'epoch': 0.3}
 30%|██▉       | 3098/10395 [8:50:01<16:26:08,  8.11s/it] 30%|██▉       | 3099/10395 [8:50:08<15:59:10,  7.89s/it]                                                         {'loss': 0.9697, 'learning_rate': 1.6460833540846123e-05, 'epoch': 0.3}
 30%|██▉       | 3099/10395 [8:50:08<15:59:10,  7.89s/it] 30%|██▉       | 3100/10395 [8:50:16<15:50:00,  7.81s/it]                                                         {'loss': 1.0101, 'learning_rate': 1.6458455092243367e-05, 'epoch': 0.3}
 30%|██▉       | 3100/10395 [8:50:16<15:50:00,  7.81s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 30%|██▉       | 3101/10395 [8:51:55<71:14:29, 35.16s/it]                                                         {'loss': 0.9195, 'learning_rate': 1.6456076016667587e-05, 'epoch': 0.3}
 30%|██▉       | 3101/10395 [8:51:55<71:14:29, 35.16s/it] 30%|██▉       | 3102/10395 [8:52:11<59:56:18, 29.59s/it]                                                         {'loss': 0.4004, 'learning_rate': 1.6453696314349746e-05, 'epoch': 0.3}
 30%|██▉       | 3102/10395 [8:52:11<59:56:18, 29.59s/it] 30%|██▉       | 3103/10395 [8:52:19<46:50:24, 23.12s/it]                                                         {'loss': 0.8798, 'learning_rate': 1.645131598552086e-05, 'epoch': 0.3}
 30%|██▉       | 3103/10395 [8:52:19<46:50:24, 23.12s/it] 30%|██▉       | 3104/10395 [8:52:27<37:43:25, 18.63s/it]                                                         {'loss': 0.8739, 'learning_rate': 1.6448935030412003e-05, 'epoch': 0.3}
 30%|██▉       | 3104/10395 [8:52:27<37:43:25, 18.63s/it] 30%|██▉       | 3105/10395 [8:52:35<30:47:43, 15.21s/it]                                                         {'loss': 0.9017, 'learning_rate': 1.6446553449254316e-05, 'epoch': 0.3}
 30%|██▉       | 3105/10395 [8:52:35<30:47:43, 15.21s/it] 30%|██▉       | 3106/10395 [8:52:42<26:14:36, 12.96s/it]                                                         {'loss': 0.9, 'learning_rate': 1.6444171242278994e-05, 'epoch': 0.3}
 30%|██▉       | 3106/10395 [8:52:42<26:14:36, 12.96s/it] 30%|██▉       | 3107/10395 [8:52:50<22:58:24, 11.35s/it]                                                         {'loss': 0.9787, 'learning_rate': 1.6441788409717304e-05, 'epoch': 0.3}
 30%|██▉       | 3107/10395 [8:52:50<22:58:24, 11.35s/it] 30%|██▉       | 3108/10395 [8:52:58<20:45:59, 10.26s/it]                                                         {'loss': 0.9296, 'learning_rate': 1.6439404951800557e-05, 'epoch': 0.3}
 30%|██▉       | 3108/10395 [8:52:58<20:45:59, 10.26s/it] 30%|██▉       | 3109/10395 [8:53:05<19:13:17,  9.50s/it]                                                         {'loss': 0.9065, 'learning_rate': 1.643702086876014e-05, 'epoch': 0.3}
 30%|██▉       | 3109/10395 [8:53:05<19:13:17,  9.50s/it] 30%|██▉       | 3110/10395 [8:53:14<18:29:44,  9.14s/it]                                                         {'loss': 0.9046, 'learning_rate': 1.643463616082749e-05, 'epoch': 0.3}
 30%|██▉       | 3110/10395 [8:53:14<18:29:44,  9.14s/it] 30%|██▉       | 3111/10395 [8:53:21<17:31:18,  8.66s/it]                                                         {'loss': 0.9627, 'learning_rate': 1.6432250828234117e-05, 'epoch': 0.3}
 30%|██▉       | 3111/10395 [8:53:21<17:31:18,  8.66s/it]WARNING: tokenization mismatch: 1 vs. 64. (ignored)
 30%|██▉       | 3112/10395 [8:53:29<17:16:01,  8.54s/it]                                                         {'loss': 0.9248, 'learning_rate': 1.6429864871211575e-05, 'epoch': 0.3}
 30%|██▉       | 3112/10395 [8:53:29<17:16:01,  8.54s/it] 30%|██▉       | 3113/10395 [8:53:38<16:58:28,  8.39s/it]                                                         {'loss': 0.9372, 'learning_rate': 1.6427478289991495e-05, 'epoch': 0.3}
 30%|██▉       | 3113/10395 [8:53:38<16:58:28,  8.39s/it] 30%|██▉       | 3114/10395 [8:53:46<17:16:37,  8.54s/it]                                                         {'loss': 0.8863, 'learning_rate': 1.6425091084805557e-05, 'epoch': 0.3}
 30%|██▉       | 3114/10395 [8:53:46<17:16:37,  8.54s/it] 30%|██▉       | 3115/10395 [8:53:54<16:36:13,  8.21s/it]                                                         {'loss': 0.942, 'learning_rate': 1.642270325588551e-05, 'epoch': 0.3}
 30%|██▉       | 3115/10395 [8:53:54<16:36:13,  8.21s/it] 30%|██▉       | 3116/10395 [8:54:02<16:47:29,  8.30s/it]                                                         {'loss': 0.946, 'learning_rate': 1.6420314803463152e-05, 'epoch': 0.3}
 30%|██▉       | 3116/10395 [8:54:02<16:47:29,  8.30s/it] 30%|██▉       | 3117/10395 [8:54:11<16:49:50,  8.33s/it]                                                         {'loss': 0.8263, 'learning_rate': 1.6417925727770355e-05, 'epoch': 0.3}
 30%|██▉       | 3117/10395 [8:54:11<16:49:50,  8.33s/it] 30%|██▉       | 3118/10395 [8:54:18<16:18:02,  8.06s/it]                                                         {'loss': 0.9971, 'learning_rate': 1.6415536029039045e-05, 'epoch': 0.3}
 30%|██▉       | 3118/10395 [8:54:18<16:18:02,  8.06s/it] 30%|███       | 3119/10395 [8:54:26<15:55:57,  7.88s/it]                                                         {'loss': 0.9757, 'learning_rate': 1.64131457075012e-05, 'epoch': 0.3}
 30%|███       | 3119/10395 [8:54:26<15:55:57,  7.88s/it] 30%|███       | 3120/10395 [8:54:33<15:35:28,  7.72s/it]                                                         {'loss': 0.9158, 'learning_rate': 1.6410754763388884e-05, 'epoch': 0.3}
 30%|███       | 3120/10395 [8:54:33<15:35:28,  7.72s/it] 30%|███       | 3121/10395 [8:54:41<16:00:17,  7.92s/it]                                                         {'loss': 0.9464, 'learning_rate': 1.640836319693419e-05, 'epoch': 0.3}
 30%|███       | 3121/10395 [8:54:41<16:00:17,  7.92s/it] 30%|███       | 3122/10395 [8:54:49<15:57:54,  7.90s/it]                                                         {'loss': 0.978, 'learning_rate': 1.640597100836929e-05, 'epoch': 0.3}
 30%|███       | 3122/10395 [8:54:49<15:57:54,  7.90s/it] 30%|███       | 3123/10395 [8:54:57<15:47:52,  7.82s/it]                                                         {'loss': 0.9824, 'learning_rate': 1.640357819792642e-05, 'epoch': 0.3}
 30%|███       | 3123/10395 [8:54:57<15:47:52,  7.82s/it] 30%|███       | 3124/10395 [8:55:05<15:54:55,  7.88s/it]                                                         {'loss': 0.9802, 'learning_rate': 1.640118476583786e-05, 'epoch': 0.3}
 30%|███       | 3124/10395 [8:55:05<15:54:55,  7.88s/it] 30%|███       | 3125/10395 [8:55:13<15:47:50,  7.82s/it]                                                         {'loss': 0.9183, 'learning_rate': 1.6398790712335964e-05, 'epoch': 0.3}
 30%|███       | 3125/10395 [8:55:13<15:47:50,  7.82s/it] 30%|███       | 3126/10395 [8:55:20<15:44:06,  7.79s/it]                                                         {'loss': 0.8971, 'learning_rate': 1.639639603765314e-05, 'epoch': 0.3}
 30%|███       | 3126/10395 [8:55:20<15:44:06,  7.79s/it] 30%|███       | 3127/10395 [8:55:29<16:05:21,  7.97s/it]                                                         {'loss': 0.9946, 'learning_rate': 1.6394000742021854e-05, 'epoch': 0.3}
 30%|███       | 3127/10395 [8:55:29<16:05:21,  7.97s/it] 30%|███       | 3128/10395 [8:55:36<15:45:14,  7.80s/it]                                                         {'loss': 0.9455, 'learning_rate': 1.6391604825674644e-05, 'epoch': 0.3}
 30%|███       | 3128/10395 [8:55:36<15:45:14,  7.80s/it] 30%|███       | 3129/10395 [8:55:44<15:40:47,  7.77s/it]                                                         {'loss': 0.9255, 'learning_rate': 1.6389208288844094e-05, 'epoch': 0.3}
 30%|███       | 3129/10395 [8:55:44<15:40:47,  7.77s/it] 30%|███       | 3130/10395 [8:55:52<16:05:13,  7.97s/it]                                                         {'loss': 0.9508, 'learning_rate': 1.638681113176286e-05, 'epoch': 0.3}
 30%|███       | 3130/10395 [8:55:52<16:05:13,  7.97s/it] 30%|███       | 3131/10395 [8:56:00<15:47:20,  7.82s/it]                                                         {'loss': 0.9804, 'learning_rate': 1.6384413354663643e-05, 'epoch': 0.3}
 30%|███       | 3131/10395 [8:56:00<15:47:20,  7.82s/it] 30%|███       | 3132/10395 [8:56:07<15:37:43,  7.75s/it]                                                         {'loss': 0.9291, 'learning_rate': 1.6382014957779227e-05, 'epoch': 0.3}
 30%|███       | 3132/10395 [8:56:07<15:37:43,  7.75s/it] 30%|███       | 3133/10395 [8:56:15<15:45:11,  7.81s/it]                                                         {'loss': 0.999, 'learning_rate': 1.637961594134244e-05, 'epoch': 0.3}
 30%|███       | 3133/10395 [8:56:15<15:45:11,  7.81s/it] 30%|███       | 3134/10395 [8:56:31<20:44:21, 10.28s/it]                                                         {'loss': 0.373, 'learning_rate': 1.6377216305586167e-05, 'epoch': 0.3}
 30%|███       | 3134/10395 [8:56:31<20:44:21, 10.28s/it] 30%|███       | 3135/10395 [8:56:39<19:10:58,  9.51s/it]                                                         {'loss': 0.9901, 'learning_rate': 1.6374816050743357e-05, 'epoch': 0.3}
 30%|███       | 3135/10395 [8:56:39<19:10:58,  9.51s/it] 30%|███       | 3136/10395 [8:56:48<18:52:14,  9.36s/it]                                                         {'loss': 1.0303, 'learning_rate': 1.6372415177047037e-05, 'epoch': 0.3}
 30%|███       | 3136/10395 [8:56:48<18:52:14,  9.36s/it] 30%|███       | 3137/10395 [8:56:56<18:02:03,  8.95s/it]                                                         {'loss': 0.9392, 'learning_rate': 1.6370013684730267e-05, 'epoch': 0.3}
 30%|███       | 3137/10395 [8:56:56<18:02:03,  8.95s/it] 30%|███       | 3138/10395 [8:57:04<17:13:12,  8.54s/it]                                                         {'loss': 0.9085, 'learning_rate': 1.636761157402618e-05, 'epoch': 0.3}
 30%|███       | 3138/10395 [8:57:04<17:13:12,  8.54s/it] 30%|███       | 3139/10395 [8:57:11<16:35:32,  8.23s/it]                                                         {'loss': 0.9515, 'learning_rate': 1.636520884516797e-05, 'epoch': 0.3}
 30%|███       | 3139/10395 [8:57:11<16:35:32,  8.23s/it] 30%|███       | 3140/10395 [8:57:19<16:29:28,  8.18s/it]                                                         {'loss': 0.8999, 'learning_rate': 1.6362805498388886e-05, 'epoch': 0.3}
 30%|███       | 3140/10395 [8:57:19<16:29:28,  8.18s/it] 30%|███       | 3141/10395 [8:57:28<16:54:49,  8.39s/it]                                                         {'loss': 0.8866, 'learning_rate': 1.6360401533922244e-05, 'epoch': 0.3}
 30%|███       | 3141/10395 [8:57:28<16:54:49,  8.39s/it] 30%|███       | 3142/10395 [8:57:45<22:06:50, 10.98s/it]                                                         {'loss': 0.4041, 'learning_rate': 1.6357996952001414e-05, 'epoch': 0.3}
 30%|███       | 3142/10395 [8:57:45<22:06:50, 10.98s/it] 30%|███       | 3143/10395 [8:57:53<20:20:52, 10.10s/it]                                                         {'loss': 0.921, 'learning_rate': 1.6355591752859826e-05, 'epoch': 0.3}
 30%|███       | 3143/10395 [8:57:53<20:20:52, 10.10s/it] 30%|███       | 3144/10395 [8:58:01<18:59:00,  9.42s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.6353185936730972e-05, 'epoch': 0.3}
 30%|███       | 3144/10395 [8:58:01<18:59:00,  9.42s/it] 30%|███       | 3145/10395 [8:58:08<17:39:31,  8.77s/it]                                                         {'loss': 0.9249, 'learning_rate': 1.6350779503848403e-05, 'epoch': 0.3}
 30%|███       | 3145/10395 [8:58:08<17:39:31,  8.77s/it] 30%|███       | 3146/10395 [8:58:16<16:58:40,  8.43s/it]                                                         {'loss': 1.0824, 'learning_rate': 1.6348372454445734e-05, 'epoch': 0.3}
 30%|███       | 3146/10395 [8:58:16<16:58:40,  8.43s/it] 30%|███       | 3147/10395 [8:58:23<16:30:04,  8.20s/it]                                                         {'loss': 0.9319, 'learning_rate': 1.634596478875663e-05, 'epoch': 0.3}
 30%|███       | 3147/10395 [8:58:24<16:30:04,  8.20s/it] 30%|███       | 3148/10395 [8:58:31<16:18:25,  8.10s/it]                                                         {'loss': 0.9676, 'learning_rate': 1.6343556507014827e-05, 'epoch': 0.3}
 30%|███       | 3148/10395 [8:58:31<16:18:25,  8.10s/it] 30%|███       | 3149/10395 [8:58:39<16:10:47,  8.04s/it]                                                         {'loss': 0.9588, 'learning_rate': 1.6341147609454114e-05, 'epoch': 0.3}
 30%|███       | 3149/10395 [8:58:39<16:10:47,  8.04s/it] 30%|███       | 3150/10395 [8:58:47<15:42:09,  7.80s/it]                                                         {'loss': 0.9523, 'learning_rate': 1.6338738096308345e-05, 'epoch': 0.3}
 30%|███       | 3150/10395 [8:58:47<15:42:09,  7.80s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 30%|███       | 3151/10395 [9:00:24<69:54:58, 34.75s/it]                                                         {'loss': 0.926, 'learning_rate': 1.6336327967811428e-05, 'epoch': 0.3}
 30%|███       | 3151/10395 [9:00:24<69:54:58, 34.75s/it] 30%|███       | 3152/10395 [9:00:32<53:48:57, 26.75s/it]                                                         {'loss': 0.9292, 'learning_rate': 1.6333917224197332e-05, 'epoch': 0.3}
 30%|███       | 3152/10395 [9:00:32<53:48:57, 26.75s/it] 30%|███       | 3153/10395 [9:00:39<41:53:58, 20.83s/it]                                                         {'loss': 0.9664, 'learning_rate': 1.6331505865700084e-05, 'epoch': 0.3}
 30%|███       | 3153/10395 [9:00:39<41:53:58, 20.83s/it] 30%|███       | 3154/10395 [9:00:47<34:04:49, 16.94s/it]                                                         {'loss': 0.9278, 'learning_rate': 1.632909389255378e-05, 'epoch': 0.3}
 30%|███       | 3154/10395 [9:00:47<34:04:49, 16.94s/it] 30%|███       | 3155/10395 [9:00:55<28:22:52, 14.11s/it]                                                         {'loss': 1.0114, 'learning_rate': 1.6326681304992565e-05, 'epoch': 0.3}
 30%|███       | 3155/10395 [9:00:55<28:22:52, 14.11s/it] 30%|███       | 3156/10395 [9:01:02<24:33:19, 12.21s/it]                                                         {'loss': 0.8796, 'learning_rate': 1.6324268103250648e-05, 'epoch': 0.3}
 30%|███       | 3156/10395 [9:01:02<24:33:19, 12.21s/it] 30%|███       | 3157/10395 [9:01:10<21:57:29, 10.92s/it]                                                         {'loss': 0.916, 'learning_rate': 1.63218542875623e-05, 'epoch': 0.3}
 30%|███       | 3157/10395 [9:01:10<21:57:29, 10.92s/it] 30%|███       | 3158/10395 [9:01:18<19:42:32,  9.80s/it]                                                         {'loss': 0.9369, 'learning_rate': 1.631943985816185e-05, 'epoch': 0.3}
 30%|███       | 3158/10395 [9:01:18<19:42:32,  9.80s/it] 30%|███       | 3159/10395 [9:01:25<18:29:37,  9.20s/it]                                                         {'loss': 1.0008, 'learning_rate': 1.631702481528368e-05, 'epoch': 0.3}
 30%|███       | 3159/10395 [9:01:25<18:29:37,  9.20s/it] 30%|███       | 3160/10395 [9:01:34<17:53:31,  8.90s/it]                                                         {'loss': 0.9524, 'learning_rate': 1.631460915916224e-05, 'epoch': 0.3}
 30%|███       | 3160/10395 [9:01:34<17:53:31,  8.90s/it] 30%|███       | 3161/10395 [9:01:42<17:26:33,  8.68s/it]                                                         {'loss': 0.937, 'learning_rate': 1.631219289003204e-05, 'epoch': 0.3}
 30%|███       | 3161/10395 [9:01:42<17:26:33,  8.68s/it] 30%|███       | 3162/10395 [9:01:49<16:46:06,  8.35s/it]                                                         {'loss': 0.9317, 'learning_rate': 1.6309776008127642e-05, 'epoch': 0.3}
 30%|███       | 3162/10395 [9:01:49<16:46:06,  8.35s/it] 30%|███       | 3163/10395 [9:01:57<16:12:53,  8.07s/it]                                                         {'loss': 0.8507, 'learning_rate': 1.630735851368367e-05, 'epoch': 0.3}
 30%|███       | 3163/10395 [9:01:57<16:12:53,  8.07s/it] 30%|███       | 3164/10395 [9:02:04<15:54:20,  7.92s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.6304940406934818e-05, 'epoch': 0.3}
 30%|███       | 3164/10395 [9:02:04<15:54:20,  7.92s/it] 30%|███       | 3165/10395 [9:02:12<15:37:49,  7.78s/it]                                                         {'loss': 0.973, 'learning_rate': 1.6302521688115823e-05, 'epoch': 0.3}
 30%|███       | 3165/10395 [9:02:12<15:37:49,  7.78s/it] 30%|███       | 3166/10395 [9:02:20<16:12:11,  8.07s/it]                                                         {'loss': 0.955, 'learning_rate': 1.6300102357461492e-05, 'epoch': 0.3}
 30%|███       | 3166/10395 [9:02:20<16:12:11,  8.07s/it] 30%|███       | 3167/10395 [9:02:30<17:06:25,  8.52s/it]                                                         {'loss': 0.8849, 'learning_rate': 1.6297682415206683e-05, 'epoch': 0.3}
 30%|███       | 3167/10395 [9:02:30<17:06:25,  8.52s/it] 30%|███       | 3168/10395 [9:02:37<16:21:45,  8.15s/it]                                                         {'loss': 1.0076, 'learning_rate': 1.6295261861586328e-05, 'epoch': 0.3}
 30%|███       | 3168/10395 [9:02:37<16:21:45,  8.15s/it] 30%|███       | 3169/10395 [9:02:54<21:38:18, 10.78s/it]                                                         {'loss': 0.3687, 'learning_rate': 1.6292840696835405e-05, 'epoch': 0.3}
 30%|███       | 3169/10395 [9:02:54<21:38:18, 10.78s/it] 30%|███       | 3170/10395 [9:03:02<19:40:43,  9.81s/it]                                                         {'loss': 1.092, 'learning_rate': 1.6290418921188952e-05, 'epoch': 0.3}
 30%|███       | 3170/10395 [9:03:02<19:40:43,  9.81s/it] 31%|███       | 3171/10395 [9:03:09<18:23:07,  9.16s/it]                                                         {'loss': 0.9429, 'learning_rate': 1.628799653488207e-05, 'epoch': 0.31}
 31%|███       | 3171/10395 [9:03:09<18:23:07,  9.16s/it] 31%|███       | 3172/10395 [9:03:17<17:16:05,  8.61s/it]                                                         {'loss': 0.9066, 'learning_rate': 1.6285573538149926e-05, 'epoch': 0.31}
 31%|███       | 3172/10395 [9:03:17<17:16:05,  8.61s/it] 31%|███       | 3173/10395 [9:03:25<17:07:35,  8.54s/it]                                                         {'loss': 0.9377, 'learning_rate': 1.628314993122774e-05, 'epoch': 0.31}
 31%|███       | 3173/10395 [9:03:25<17:07:35,  8.54s/it] 31%|███       | 3174/10395 [9:03:32<16:15:54,  8.11s/it]                                                         {'loss': 1.0399, 'learning_rate': 1.628072571435078e-05, 'epoch': 0.31}
 31%|███       | 3174/10395 [9:03:32<16:15:54,  8.11s/it]WARNING: tokenization mismatch: 1 vs. 1419. (ignored)
 31%|███       | 3175/10395 [9:03:40<16:13:46,  8.09s/it]                                                         {'loss': 1.0216, 'learning_rate': 1.6278300887754388e-05, 'epoch': 0.31}
 31%|███       | 3175/10395 [9:03:40<16:13:46,  8.09s/it] 31%|███       | 3176/10395 [9:03:48<16:01:47,  7.99s/it]                                                         {'loss': 0.9444, 'learning_rate': 1.6275875451673962e-05, 'epoch': 0.31}
 31%|███       | 3176/10395 [9:03:48<16:01:47,  7.99s/it] 31%|███       | 3177/10395 [9:04:05<21:38:54, 10.80s/it]                                                         {'loss': 0.4131, 'learning_rate': 1.6273449406344964e-05, 'epoch': 0.31}
 31%|███       | 3177/10395 [9:04:05<21:38:54, 10.80s/it] 31%|███       | 3178/10395 [9:04:14<20:11:25, 10.07s/it]                                                         {'loss': 0.8857, 'learning_rate': 1.6271022752002902e-05, 'epoch': 0.31}
 31%|███       | 3178/10395 [9:04:14<20:11:25, 10.07s/it] 31%|███       | 3179/10395 [9:04:22<19:19:09,  9.64s/it]                                                         {'loss': 0.8337, 'learning_rate': 1.6268595488883353e-05, 'epoch': 0.31}
 31%|███       | 3179/10395 [9:04:22<19:19:09,  9.64s/it] 31%|███       | 3180/10395 [9:04:30<18:09:39,  9.06s/it]                                                         {'loss': 0.916, 'learning_rate': 1.6266167617221948e-05, 'epoch': 0.31}
 31%|███       | 3180/10395 [9:04:30<18:09:39,  9.06s/it] 31%|███       | 3181/10395 [9:04:37<16:58:49,  8.47s/it]                                                         {'loss': 0.9584, 'learning_rate': 1.6263739137254382e-05, 'epoch': 0.31}
 31%|███       | 3181/10395 [9:04:37<16:58:49,  8.47s/it] 31%|███       | 3182/10395 [9:04:45<16:23:54,  8.18s/it]                                                         {'loss': 0.9451, 'learning_rate': 1.626131004921641e-05, 'epoch': 0.31}
 31%|███       | 3182/10395 [9:04:45<16:23:54,  8.18s/it] 31%|███       | 3183/10395 [9:04:53<16:44:57,  8.36s/it]                                                         {'loss': 0.876, 'learning_rate': 1.6258880353343832e-05, 'epoch': 0.31}
 31%|███       | 3183/10395 [9:04:53<16:44:57,  8.36s/it] 31%|███       | 3184/10395 [9:05:01<16:28:40,  8.23s/it]                                                         {'loss': 0.9273, 'learning_rate': 1.625645004987253e-05, 'epoch': 0.31}
 31%|███       | 3184/10395 [9:05:01<16:28:40,  8.23s/it] 31%|███       | 3185/10395 [9:05:19<22:16:42, 11.12s/it]                                                         {'loss': 0.3905, 'learning_rate': 1.6254019139038425e-05, 'epoch': 0.31}
 31%|███       | 3185/10395 [9:05:19<22:16:42, 11.12s/it] 31%|███       | 3186/10395 [9:05:37<26:03:54, 13.02s/it]                                                         {'loss': 0.3719, 'learning_rate': 1.6251587621077506e-05, 'epoch': 0.31}
 31%|███       | 3186/10395 [9:05:37<26:03:54, 13.02s/it] 31%|███       | 3187/10395 [9:05:45<23:18:54, 11.64s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.6249155496225823e-05, 'epoch': 0.31}
 31%|███       | 3187/10395 [9:05:45<23:18:54, 11.64s/it] 31%|███       | 3188/10395 [9:05:52<20:40:04, 10.32s/it]                                                         {'loss': 1.0127, 'learning_rate': 1.624672276471948e-05, 'epoch': 0.31}
 31%|███       | 3188/10395 [9:05:52<20:40:04, 10.32s/it] 31%|███       | 3189/10395 [9:06:00<19:16:21,  9.63s/it]                                                         {'loss': 0.9276, 'learning_rate': 1.6244289426794636e-05, 'epoch': 0.31}
 31%|███       | 3189/10395 [9:06:00<19:16:21,  9.63s/it] 31%|███       | 3190/10395 [9:06:08<18:07:54,  9.06s/it]                                                         {'loss': 0.9414, 'learning_rate': 1.624185548268752e-05, 'epoch': 0.31}
 31%|███       | 3190/10395 [9:06:08<18:07:54,  9.06s/it] 31%|███       | 3191/10395 [9:06:15<17:06:35,  8.55s/it]                                                         {'loss': 0.953, 'learning_rate': 1.6239420932634412e-05, 'epoch': 0.31}
 31%|███       | 3191/10395 [9:06:15<17:06:35,  8.55s/it] 31%|███       | 3192/10395 [9:06:24<16:49:47,  8.41s/it]                                                         {'loss': 0.8946, 'learning_rate': 1.6236985776871656e-05, 'epoch': 0.31}
 31%|███       | 3192/10395 [9:06:24<16:49:47,  8.41s/it] 31%|███       | 3193/10395 [9:06:31<16:17:41,  8.15s/it]                                                         {'loss': 0.9518, 'learning_rate': 1.6234550015635647e-05, 'epoch': 0.31}
 31%|███       | 3193/10395 [9:06:31<16:17:41,  8.15s/it] 31%|███       | 3194/10395 [9:06:39<15:54:40,  7.95s/it]                                                         {'loss': 0.9209, 'learning_rate': 1.6232113649162848e-05, 'epoch': 0.31}
 31%|███       | 3194/10395 [9:06:39<15:54:40,  7.95s/it] 31%|███       | 3195/10395 [9:06:46<15:45:19,  7.88s/it]                                                         {'loss': 0.9722, 'learning_rate': 1.6229676677689773e-05, 'epoch': 0.31}
 31%|███       | 3195/10395 [9:06:46<15:45:19,  7.88s/it] 31%|███       | 3196/10395 [9:06:54<15:29:52,  7.75s/it]                                                         {'loss': 0.9277, 'learning_rate': 1.6227239101452998e-05, 'epoch': 0.31}
 31%|███       | 3196/10395 [9:06:54<15:29:52,  7.75s/it] 31%|███       | 3197/10395 [9:07:01<15:08:01,  7.57s/it]                                                         {'loss': 0.906, 'learning_rate': 1.622480092068916e-05, 'epoch': 0.31}
 31%|███       | 3197/10395 [9:07:01<15:08:01,  7.57s/it] 31%|███       | 3198/10395 [9:07:10<15:46:17,  7.89s/it]                                                         {'loss': 0.9553, 'learning_rate': 1.622236213563495e-05, 'epoch': 0.31}
 31%|███       | 3198/10395 [9:07:10<15:46:17,  7.89s/it] 31%|███       | 3199/10395 [9:07:18<16:12:09,  8.11s/it]                                                         {'loss': 0.9769, 'learning_rate': 1.6219922746527125e-05, 'epoch': 0.31}
 31%|███       | 3199/10395 [9:07:18<16:12:09,  8.11s/it] 31%|███       | 3200/10395 [9:07:36<21:53:06, 10.95s/it]                                                         {'loss': 0.4084, 'learning_rate': 1.621748275360249e-05, 'epoch': 0.31}
 31%|███       | 3200/10395 [9:07:36<21:53:06, 10.95s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 31%|███       | 3201/10395 [9:09:13<73:44:01, 36.90s/it]                                                         {'loss': 0.9051, 'learning_rate': 1.621504215709791e-05, 'epoch': 0.31}
 31%|███       | 3201/10395 [9:09:13<73:44:01, 36.90s/it] 31%|███       | 3202/10395 [9:09:22<56:47:11, 28.42s/it]                                                         {'loss': 0.8617, 'learning_rate': 1.6212600957250322e-05, 'epoch': 0.31}
 31%|███       | 3202/10395 [9:09:22<56:47:11, 28.42s/it] 31%|███       | 3203/10395 [9:09:29<44:18:25, 22.18s/it]                                                         {'loss': 0.9562, 'learning_rate': 1.6210159154296715e-05, 'epoch': 0.31}
 31%|███       | 3203/10395 [9:09:29<44:18:25, 22.18s/it] 31%|███       | 3204/10395 [9:09:37<35:45:41, 17.90s/it]                                                         {'loss': 0.9038, 'learning_rate': 1.6207716748474122e-05, 'epoch': 0.31}
 31%|███       | 3204/10395 [9:09:37<35:45:41, 17.90s/it] 31%|███       | 3205/10395 [9:09:45<29:48:34, 14.93s/it]                                                         {'loss': 0.8854, 'learning_rate': 1.6205273740019657e-05, 'epoch': 0.31}
 31%|███       | 3205/10395 [9:09:45<29:48:34, 14.93s/it] 31%|███       | 3206/10395 [9:09:53<25:21:56, 12.70s/it]                                                         {'loss': 0.8895, 'learning_rate': 1.6202830129170477e-05, 'epoch': 0.31}
 31%|███       | 3206/10395 [9:09:53<25:21:56, 12.70s/it] 31%|███       | 3207/10395 [9:10:00<22:12:47, 11.13s/it]                                                         {'loss': 0.9011, 'learning_rate': 1.6200385916163803e-05, 'epoch': 0.31}
 31%|███       | 3207/10395 [9:10:00<22:12:47, 11.13s/it] 31%|███       | 3208/10395 [9:10:08<19:54:13,  9.97s/it]                                                         {'loss': 0.9747, 'learning_rate': 1.6197941101236912e-05, 'epoch': 0.31}
 31%|███       | 3208/10395 [9:10:08<19:54:13,  9.97s/it] 31%|███       | 3209/10395 [9:10:16<18:43:58,  9.38s/it]                                                         {'loss': 0.9516, 'learning_rate': 1.6195495684627147e-05, 'epoch': 0.31}
 31%|███       | 3209/10395 [9:10:16<18:43:58,  9.38s/it] 31%|███       | 3210/10395 [9:10:32<23:01:47, 11.54s/it]                                                         {'loss': 0.3333, 'learning_rate': 1.61930496665719e-05, 'epoch': 0.31}
 31%|███       | 3210/10395 [9:10:32<23:01:47, 11.54s/it] 31%|███       | 3211/10395 [9:10:39<20:29:21, 10.27s/it]                                                         {'loss': 0.9702, 'learning_rate': 1.6190603047308625e-05, 'epoch': 0.31}
 31%|███       | 3211/10395 [9:10:39<20:29:21, 10.27s/it] 31%|███       | 3212/10395 [9:10:47<18:52:43,  9.46s/it]                                                         {'loss': 0.8859, 'learning_rate': 1.6188155827074837e-05, 'epoch': 0.31}
 31%|███       | 3212/10395 [9:10:47<18:52:43,  9.46s/it] 31%|███       | 3213/10395 [9:10:55<17:47:16,  8.92s/it]                                                         {'loss': 0.9592, 'learning_rate': 1.618570800610811e-05, 'epoch': 0.31}
 31%|███       | 3213/10395 [9:10:55<17:47:16,  8.92s/it] 31%|███       | 3214/10395 [9:11:02<16:54:19,  8.48s/it]                                                         {'loss': 0.9672, 'learning_rate': 1.618325958464606e-05, 'epoch': 0.31}
 31%|███       | 3214/10395 [9:11:02<16:54:19,  8.48s/it] 31%|███       | 3215/10395 [9:11:11<17:23:17,  8.72s/it]                                                         {'loss': 0.9042, 'learning_rate': 1.6180810562926387e-05, 'epoch': 0.31}
 31%|███       | 3215/10395 [9:11:11<17:23:17,  8.72s/it] 31%|███       | 3216/10395 [9:11:29<22:38:17, 11.35s/it]                                                         {'loss': 0.3769, 'learning_rate': 1.6178360941186834e-05, 'epoch': 0.31}
 31%|███       | 3216/10395 [9:11:29<22:38:17, 11.35s/it] 31%|███       | 3217/10395 [9:11:36<20:17:30, 10.18s/it]                                                         {'loss': 0.8826, 'learning_rate': 1.6175910719665205e-05, 'epoch': 0.31}
 31%|███       | 3217/10395 [9:11:36<20:17:30, 10.18s/it] 31%|███       | 3218/10395 [9:11:44<18:42:05,  9.38s/it]                                                         {'loss': 0.9987, 'learning_rate': 1.617345989859936e-05, 'epoch': 0.31}
 31%|███       | 3218/10395 [9:11:44<18:42:05,  9.38s/it] 31%|███       | 3219/10395 [9:11:52<17:49:20,  8.94s/it]                                                         {'loss': 0.952, 'learning_rate': 1.6171008478227216e-05, 'epoch': 0.31}
 31%|███       | 3219/10395 [9:11:52<17:49:20,  8.94s/it] 31%|███       | 3220/10395 [9:12:00<17:08:01,  8.60s/it]                                                         {'loss': 0.9525, 'learning_rate': 1.6168556458786762e-05, 'epoch': 0.31}
 31%|███       | 3220/10395 [9:12:00<17:08:01,  8.60s/it] 31%|███       | 3221/10395 [9:12:09<17:38:33,  8.85s/it]                                                         {'loss': 0.8804, 'learning_rate': 1.6166103840516027e-05, 'epoch': 0.31}
 31%|███       | 3221/10395 [9:12:09<17:38:33,  8.85s/it] 31%|███       | 3222/10395 [9:12:17<17:20:07,  8.70s/it]                                                         {'loss': 0.918, 'learning_rate': 1.616365062365311e-05, 'epoch': 0.31}
 31%|███       | 3222/10395 [9:12:17<17:20:07,  8.70s/it] 31%|███       | 3223/10395 [9:12:25<16:39:35,  8.36s/it]                                                         {'loss': 0.9957, 'learning_rate': 1.6161196808436162e-05, 'epoch': 0.31}
 31%|███       | 3223/10395 [9:12:25<16:39:35,  8.36s/it] 31%|███       | 3224/10395 [9:12:33<16:16:13,  8.17s/it]                                                         {'loss': 0.9565, 'learning_rate': 1.615874239510339e-05, 'epoch': 0.31}
 31%|███       | 3224/10395 [9:12:33<16:16:13,  8.17s/it] 31%|███       | 3225/10395 [9:12:41<16:05:22,  8.08s/it]                                                         {'loss': 0.9787, 'learning_rate': 1.6156287383893073e-05, 'epoch': 0.31}
 31%|███       | 3225/10395 [9:12:41<16:05:22,  8.08s/it] 31%|███       | 3226/10395 [9:12:48<15:47:02,  7.93s/it]                                                         {'loss': 0.8777, 'learning_rate': 1.615383177504353e-05, 'epoch': 0.31}
 31%|███       | 3226/10395 [9:12:48<15:47:02,  7.93s/it] 31%|███       | 3227/10395 [9:12:56<15:52:05,  7.97s/it]                                                         {'loss': 0.8998, 'learning_rate': 1.6151375568793152e-05, 'epoch': 0.31}
 31%|███       | 3227/10395 [9:12:56<15:52:05,  7.97s/it] 31%|███       | 3228/10395 [9:13:14<21:30:53, 10.81s/it]                                                         {'loss': 0.4384, 'learning_rate': 1.6148918765380377e-05, 'epoch': 0.31}
 31%|███       | 3228/10395 [9:13:14<21:30:53, 10.81s/it] 31%|███       | 3229/10395 [9:13:21<19:46:41,  9.94s/it]                                                         {'loss': 1.0065, 'learning_rate': 1.6146461365043708e-05, 'epoch': 0.31}
 31%|███       | 3229/10395 [9:13:21<19:46:41,  9.94s/it] 31%|███       | 3230/10395 [9:13:30<19:09:38,  9.63s/it]                                                         {'loss': 0.9441, 'learning_rate': 1.6144003368021706e-05, 'epoch': 0.31}
 31%|███       | 3230/10395 [9:13:30<19:09:38,  9.63s/it] 31%|███       | 3231/10395 [9:13:38<17:56:57,  9.02s/it]                                                         {'loss': 0.9296, 'learning_rate': 1.6141544774552987e-05, 'epoch': 0.31}
 31%|███       | 3231/10395 [9:13:38<17:56:57,  9.02s/it] 31%|███       | 3232/10395 [9:13:45<16:59:36,  8.54s/it]                                                         {'loss': 0.9892, 'learning_rate': 1.6139085584876225e-05, 'epoch': 0.31}
 31%|███       | 3232/10395 [9:13:45<16:59:36,  8.54s/it] 31%|███       | 3233/10395 [9:14:01<21:16:57, 10.70s/it]                                                         {'loss': 0.3563, 'learning_rate': 1.613662579923015e-05, 'epoch': 0.31}
 31%|███       | 3233/10395 [9:14:01<21:16:57, 10.70s/it] 31%|███       | 3234/10395 [9:14:09<19:22:57,  9.74s/it]                                                         {'loss': 0.9917, 'learning_rate': 1.6134165417853563e-05, 'epoch': 0.31}
 31%|███       | 3234/10395 [9:14:09<19:22:57,  9.74s/it] 31%|███       | 3235/10395 [9:14:16<18:03:43,  9.08s/it]                                                         {'loss': 0.9879, 'learning_rate': 1.6131704440985303e-05, 'epoch': 0.31}
 31%|███       | 3235/10395 [9:14:16<18:03:43,  9.08s/it] 31%|███       | 3236/10395 [9:14:24<17:25:16,  8.76s/it]                                                         {'loss': 1.0435, 'learning_rate': 1.6129242868864283e-05, 'epoch': 0.31}
 31%|███       | 3236/10395 [9:14:24<17:25:16,  8.76s/it] 31%|███       | 3237/10395 [9:14:32<16:51:44,  8.48s/it]                                                         {'loss': 0.9931, 'learning_rate': 1.6126780701729458e-05, 'epoch': 0.31}
 31%|███       | 3237/10395 [9:14:32<16:51:44,  8.48s/it] 31%|███       | 3238/10395 [9:14:40<16:24:03,  8.25s/it]                                                         {'loss': 1.0041, 'learning_rate': 1.6124317939819854e-05, 'epoch': 0.31}
 31%|███       | 3238/10395 [9:14:40<16:24:03,  8.25s/it] 31%|███       | 3239/10395 [9:14:47<15:51:35,  7.98s/it]                                                         {'loss': 0.9318, 'learning_rate': 1.612185458337456e-05, 'epoch': 0.31}
 31%|███       | 3239/10395 [9:14:47<15:51:35,  7.98s/it] 31%|███       | 3240/10395 [9:14:56<16:14:18,  8.17s/it]                                                         {'loss': 0.939, 'learning_rate': 1.61193906326327e-05, 'epoch': 0.31}
 31%|███       | 3240/10395 [9:14:56<16:14:18,  8.17s/it] 31%|███       | 3241/10395 [9:15:03<15:58:07,  8.04s/it]                                                         {'loss': 0.924, 'learning_rate': 1.6116926087833477e-05, 'epoch': 0.31}
 31%|███       | 3241/10395 [9:15:03<15:58:07,  8.04s/it] 31%|███       | 3242/10395 [9:15:12<16:08:38,  8.13s/it]                                                         {'loss': 0.9776, 'learning_rate': 1.6114460949216136e-05, 'epoch': 0.31}
 31%|███       | 3242/10395 [9:15:12<16:08:38,  8.13s/it] 31%|███       | 3243/10395 [9:15:19<15:36:53,  7.86s/it]                                                         {'loss': 1.0277, 'learning_rate': 1.611199521702e-05, 'epoch': 0.31}
 31%|███       | 3243/10395 [9:15:20<15:36:53,  7.86s/it] 31%|███       | 3244/10395 [9:15:28<15:58:55,  8.05s/it]                                                         {'loss': 0.9706, 'learning_rate': 1.6109528891484425e-05, 'epoch': 0.31}
 31%|███       | 3244/10395 [9:15:28<15:58:55,  8.05s/it] 31%|███       | 3245/10395 [9:15:35<15:54:15,  8.01s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.6107061972848843e-05, 'epoch': 0.31}
 31%|███       | 3245/10395 [9:15:35<15:54:15,  8.01s/it] 31%|███       | 3246/10395 [9:15:43<15:50:20,  7.98s/it]                                                         {'loss': 0.8518, 'learning_rate': 1.6104594461352733e-05, 'epoch': 0.31}
 31%|███       | 3246/10395 [9:15:43<15:50:20,  7.98s/it] 31%|███       | 3247/10395 [9:15:53<17:07:12,  8.62s/it]                                                         {'loss': 0.9661, 'learning_rate': 1.6102126357235645e-05, 'epoch': 0.31}
 31%|███       | 3247/10395 [9:15:53<17:07:12,  8.62s/it] 31%|███       | 3248/10395 [9:16:02<16:51:03,  8.49s/it]                                                         {'loss': 0.9481, 'learning_rate': 1.6099657660737165e-05, 'epoch': 0.31}
 31%|███       | 3248/10395 [9:16:02<16:51:03,  8.49s/it] 31%|███▏      | 3249/10395 [9:16:10<16:37:39,  8.38s/it]                                                         {'loss': 0.8958, 'learning_rate': 1.6097188372096955e-05, 'epoch': 0.31}
 31%|███▏      | 3249/10395 [9:16:10<16:37:39,  8.38s/it] 31%|███▏      | 3250/10395 [9:16:17<16:06:47,  8.12s/it]                                                         {'loss': 0.9329, 'learning_rate': 1.6094718491554727e-05, 'epoch': 0.31}
 31%|███▏      | 3250/10395 [9:16:17<16:06:47,  8.12s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 31%|███▏      | 3251/10395 [9:17:56<70:17:55, 35.42s/it]                                                         {'loss': 0.9394, 'learning_rate': 1.6092248019350254e-05, 'epoch': 0.31}
 31%|███▏      | 3251/10395 [9:17:56<70:17:55, 35.42s/it] 31%|███▏      | 3252/10395 [9:18:04<53:58:58, 27.21s/it]                                                         {'loss': 0.991, 'learning_rate': 1.6089776955723362e-05, 'epoch': 0.31}
 31%|███▏      | 3252/10395 [9:18:04<53:58:58, 27.21s/it] 31%|███▏      | 3253/10395 [9:18:12<42:21:04, 21.35s/it]                                                         {'loss': 0.9898, 'learning_rate': 1.6087305300913934e-05, 'epoch': 0.31}
 31%|███▏      | 3253/10395 [9:18:12<42:21:04, 21.35s/it] 31%|███▏      | 3254/10395 [9:18:20<34:29:10, 17.39s/it]                                                         {'loss': 0.9828, 'learning_rate': 1.6084833055161922e-05, 'epoch': 0.31}
 31%|███▏      | 3254/10395 [9:18:20<34:29:10, 17.39s/it] 31%|███▏      | 3255/10395 [9:18:27<28:24:50, 14.33s/it]                                                         {'loss': 1.0122, 'learning_rate': 1.6082360218707316e-05, 'epoch': 0.31}
 31%|███▏      | 3255/10395 [9:18:27<28:24:50, 14.33s/it] 31%|███▏      | 3256/10395 [9:18:36<24:49:56, 12.52s/it]                                                         {'loss': 0.9439, 'learning_rate': 1.6079886791790177e-05, 'epoch': 0.31}
 31%|███▏      | 3256/10395 [9:18:36<24:49:56, 12.52s/it] 31%|███▏      | 3257/10395 [9:18:43<21:49:05, 11.00s/it]                                                         {'loss': 0.9669, 'learning_rate': 1.6077412774650623e-05, 'epoch': 0.31}
 31%|███▏      | 3257/10395 [9:18:43<21:49:05, 11.00s/it] 31%|███▏      | 3258/10395 [9:18:51<20:09:00, 10.16s/it]                                                         {'loss': 0.8898, 'learning_rate': 1.6074938167528827e-05, 'epoch': 0.31}
 31%|███▏      | 3258/10395 [9:18:51<20:09:00, 10.16s/it] 31%|███▏      | 3259/10395 [9:19:00<18:56:51,  9.56s/it]                                                         {'loss': 0.8805, 'learning_rate': 1.6072462970665014e-05, 'epoch': 0.31}
 31%|███▏      | 3259/10395 [9:19:00<18:56:51,  9.56s/it] 31%|███▏      | 3260/10395 [9:19:17<23:35:22, 11.90s/it]                                                         {'loss': 0.3911, 'learning_rate': 1.6069987184299473e-05, 'epoch': 0.31}
 31%|███▏      | 3260/10395 [9:19:17<23:35:22, 11.90s/it] 31%|███▏      | 3261/10395 [9:19:26<21:48:21, 11.00s/it]                                                         {'loss': 0.9405, 'learning_rate': 1.6067510808672545e-05, 'epoch': 0.31}
 31%|███▏      | 3261/10395 [9:19:26<21:48:21, 11.00s/it] 31%|███▏      | 3262/10395 [9:19:34<19:50:08, 10.01s/it]                                                         {'loss': 0.9178, 'learning_rate': 1.6065033844024635e-05, 'epoch': 0.31}
 31%|███▏      | 3262/10395 [9:19:34<19:50:08, 10.01s/it] 31%|███▏      | 3263/10395 [9:19:41<18:25:16,  9.30s/it]                                                         {'loss': 0.9605, 'learning_rate': 1.6062556290596202e-05, 'epoch': 0.31}
 31%|███▏      | 3263/10395 [9:19:41<18:25:16,  9.30s/it] 31%|███▏      | 3264/10395 [9:19:49<17:21:17,  8.76s/it]                                                         {'loss': 1.0036, 'learning_rate': 1.606007814862776e-05, 'epoch': 0.31}
 31%|███▏      | 3264/10395 [9:19:49<17:21:17,  8.76s/it] 31%|███▏      | 3265/10395 [9:19:56<16:22:33,  8.27s/it]                                                         {'loss': 0.9574, 'learning_rate': 1.605759941835988e-05, 'epoch': 0.31}
 31%|███▏      | 3265/10395 [9:19:56<16:22:33,  8.27s/it] 31%|███▏      | 3266/10395 [9:20:04<16:28:22,  8.32s/it]                                                         {'loss': 0.9886, 'learning_rate': 1.6055120100033195e-05, 'epoch': 0.31}
 31%|███▏      | 3266/10395 [9:20:04<16:28:22,  8.32s/it] 31%|███▏      | 3267/10395 [9:20:12<16:08:37,  8.15s/it]                                                         {'loss': 0.9778, 'learning_rate': 1.605264019388839e-05, 'epoch': 0.31}
 31%|███▏      | 3267/10395 [9:20:12<16:08:37,  8.15s/it] 31%|███▏      | 3268/10395 [9:20:20<15:58:20,  8.07s/it]                                                         {'loss': 0.8869, 'learning_rate': 1.6050159700166208e-05, 'epoch': 0.31}
 31%|███▏      | 3268/10395 [9:20:20<15:58:20,  8.07s/it] 31%|███▏      | 3269/10395 [9:20:28<16:04:24,  8.12s/it]                                                         {'loss': 0.9633, 'learning_rate': 1.6047678619107456e-05, 'epoch': 0.31}
 31%|███▏      | 3269/10395 [9:20:28<16:04:24,  8.12s/it] 31%|███▏      | 3270/10395 [9:20:35<15:23:50,  7.78s/it]                                                         {'loss': 0.8921, 'learning_rate': 1.6045196950952983e-05, 'epoch': 0.31}
 31%|███▏      | 3270/10395 [9:20:35<15:23:50,  7.78s/it] 31%|███▏      | 3271/10395 [9:20:43<15:29:31,  7.83s/it]                                                         {'loss': 0.9123, 'learning_rate': 1.604271469594371e-05, 'epoch': 0.31}
 31%|███▏      | 3271/10395 [9:20:43<15:29:31,  7.83s/it] 31%|███▏      | 3272/10395 [9:20:51<15:30:27,  7.84s/it]                                                         {'loss': 0.9857, 'learning_rate': 1.604023185432061e-05, 'epoch': 0.31}
 31%|███▏      | 3272/10395 [9:20:51<15:30:27,  7.84s/it] 31%|███▏      | 3273/10395 [9:20:59<15:22:13,  7.77s/it]                                                         {'loss': 0.9187, 'learning_rate': 1.6037748426324705e-05, 'epoch': 0.31}
 31%|███▏      | 3273/10395 [9:20:59<15:22:13,  7.77s/it] 31%|███▏      | 3274/10395 [9:21:06<15:03:36,  7.61s/it]                                                         {'loss': 0.9331, 'learning_rate': 1.6035264412197088e-05, 'epoch': 0.31}
 31%|███▏      | 3274/10395 [9:21:06<15:03:36,  7.61s/it] 32%|███▏      | 3275/10395 [9:21:13<14:55:46,  7.55s/it]                                                         {'loss': 0.9646, 'learning_rate': 1.60327798121789e-05, 'epoch': 0.32}
 32%|███▏      | 3275/10395 [9:21:13<14:55:46,  7.55s/it] 32%|███▏      | 3276/10395 [9:21:21<14:56:09,  7.55s/it]                                                         {'loss': 0.9635, 'learning_rate': 1.603029462651134e-05, 'epoch': 0.32}
 32%|███▏      | 3276/10395 [9:21:21<14:56:09,  7.55s/it] 32%|███▏      | 3277/10395 [9:21:29<15:33:31,  7.87s/it]                                                         {'loss': 0.9541, 'learning_rate': 1.602780885543566e-05, 'epoch': 0.32}
 32%|███▏      | 3277/10395 [9:21:29<15:33:31,  7.87s/it] 32%|███▏      | 3278/10395 [9:21:38<16:19:05,  8.25s/it]                                                         {'loss': 1.0338, 'learning_rate': 1.6025322499193186e-05, 'epoch': 0.32}
 32%|███▏      | 3278/10395 [9:21:38<16:19:05,  8.25s/it] 32%|███▏      | 3279/10395 [9:21:56<21:34:10, 10.91s/it]                                                         {'loss': 0.4189, 'learning_rate': 1.6022835558025273e-05, 'epoch': 0.32}
 32%|███▏      | 3279/10395 [9:21:56<21:34:10, 10.91s/it] 32%|███▏      | 3280/10395 [9:22:03<19:37:40,  9.93s/it]                                                         {'loss': 0.9346, 'learning_rate': 1.6020348032173362e-05, 'epoch': 0.32}
 32%|███▏      | 3280/10395 [9:22:03<19:37:40,  9.93s/it] 32%|███▏      | 3281/10395 [9:22:10<17:57:48,  9.09s/it]                                                         {'loss': 0.9889, 'learning_rate': 1.6017859921878922e-05, 'epoch': 0.32}
 32%|███▏      | 3281/10395 [9:22:10<17:57:48,  9.09s/it] 32%|███▏      | 3282/10395 [9:22:18<17:23:10,  8.80s/it]                                                         {'loss': 0.8814, 'learning_rate': 1.6015371227383504e-05, 'epoch': 0.32}
 32%|███▏      | 3282/10395 [9:22:18<17:23:10,  8.80s/it] 32%|███▏      | 3283/10395 [9:22:26<16:33:40,  8.38s/it]                                                         {'loss': 0.8987, 'learning_rate': 1.6012881948928702e-05, 'epoch': 0.32}
 32%|███▏      | 3283/10395 [9:22:26<16:33:40,  8.38s/it] 32%|███▏      | 3284/10395 [9:22:33<16:00:11,  8.10s/it]                                                         {'loss': 0.8933, 'learning_rate': 1.601039208675617e-05, 'epoch': 0.32}
 32%|███▏      | 3284/10395 [9:22:33<16:00:11,  8.10s/it] 32%|███▏      | 3285/10395 [9:22:41<15:37:47,  7.91s/it]                                                         {'loss': 1.0023, 'learning_rate': 1.600790164110762e-05, 'epoch': 0.32}
 32%|███▏      | 3285/10395 [9:22:41<15:37:47,  7.91s/it] 32%|███▏      | 3286/10395 [9:22:48<15:28:48,  7.84s/it]                                                         {'loss': 0.9939, 'learning_rate': 1.6005410612224814e-05, 'epoch': 0.32}
 32%|███▏      | 3286/10395 [9:22:48<15:28:48,  7.84s/it] 32%|███▏      | 3287/10395 [9:22:56<15:06:25,  7.65s/it]                                                         {'loss': 0.9981, 'learning_rate': 1.600291900034958e-05, 'epoch': 0.32}
 32%|███▏      | 3287/10395 [9:22:56<15:06:25,  7.65s/it] 32%|███▏      | 3288/10395 [9:23:03<14:59:34,  7.59s/it]                                                         {'loss': 0.9366, 'learning_rate': 1.6000426805723802e-05, 'epoch': 0.32}
 32%|███▏      | 3288/10395 [9:23:03<14:59:34,  7.59s/it] 32%|███▏      | 3289/10395 [9:23:19<19:55:23, 10.09s/it]                                                         {'loss': 0.3978, 'learning_rate': 1.599793402858941e-05, 'epoch': 0.32}
 32%|███▏      | 3289/10395 [9:23:19<19:55:23, 10.09s/it] 32%|███▏      | 3290/10395 [9:23:26<18:04:22,  9.16s/it]                                                         {'loss': 1.0004, 'learning_rate': 1.5995440669188397e-05, 'epoch': 0.32}
 32%|███▏      | 3290/10395 [9:23:26<18:04:22,  9.16s/it] 32%|███▏      | 3291/10395 [9:23:34<17:19:34,  8.78s/it]                                                         {'loss': 0.9207, 'learning_rate': 1.599294672776282e-05, 'epoch': 0.32}
 32%|███▏      | 3291/10395 [9:23:34<17:19:34,  8.78s/it] 32%|███▏      | 3292/10395 [9:23:41<16:32:51,  8.39s/it]                                                         {'loss': 0.9988, 'learning_rate': 1.599045220455478e-05, 'epoch': 0.32}
 32%|███▏      | 3292/10395 [9:23:41<16:32:51,  8.39s/it] 32%|███▏      | 3293/10395 [9:23:49<16:11:24,  8.21s/it]                                                         {'loss': 0.9353, 'learning_rate': 1.5987957099806444e-05, 'epoch': 0.32}
 32%|███▏      | 3293/10395 [9:23:49<16:11:24,  8.21s/it] 32%|███▏      | 3294/10395 [9:23:58<16:20:20,  8.28s/it]                                                         {'loss': 1.0121, 'learning_rate': 1.5985461413760028e-05, 'epoch': 0.32}
 32%|███▏      | 3294/10395 [9:23:58<16:20:20,  8.28s/it] 32%|███▏      | 3295/10395 [9:24:06<16:06:01,  8.16s/it]                                                         {'loss': 1.0701, 'learning_rate': 1.598296514665781e-05, 'epoch': 0.32}
 32%|███▏      | 3295/10395 [9:24:06<16:06:01,  8.16s/it] 32%|███▏      | 3296/10395 [9:24:23<21:23:58, 10.85s/it]                                                         {'loss': 0.4149, 'learning_rate': 1.5980468298742117e-05, 'epoch': 0.32}
 32%|███▏      | 3296/10395 [9:24:23<21:23:58, 10.85s/it] 32%|███▏      | 3297/10395 [9:24:30<19:07:24,  9.70s/it]                                                         {'loss': 0.9988, 'learning_rate': 1.5977970870255345e-05, 'epoch': 0.32}
 32%|███▏      | 3297/10395 [9:24:30<19:07:24,  9.70s/it] 32%|███▏      | 3298/10395 [9:24:38<18:24:51,  9.34s/it]                                                         {'loss': 0.9554, 'learning_rate': 1.5975472861439937e-05, 'epoch': 0.32}
 32%|███▏      | 3298/10395 [9:24:38<18:24:51,  9.34s/it] 32%|███▏      | 3299/10395 [9:24:55<22:33:24, 11.44s/it]                                                         {'loss': 0.361, 'learning_rate': 1.597297427253839e-05, 'epoch': 0.32}
 32%|███▏      | 3299/10395 [9:24:55<22:33:24, 11.44s/it] 32%|███▏      | 3300/10395 [9:25:03<20:30:47, 10.41s/it]                                                         {'loss': 0.9311, 'learning_rate': 1.5970475103793266e-05, 'epoch': 0.32}
 32%|███▏      | 3300/10395 [9:25:03<20:30:47, 10.41s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 32%|███▏      | 3301/10395 [9:26:40<71:44:30, 36.41s/it]                                                         {'loss': 0.9065, 'learning_rate': 1.596797535544718e-05, 'epoch': 0.32}
 32%|███▏      | 3301/10395 [9:26:40<71:44:30, 36.41s/it] 32%|███▏      | 3302/10395 [9:26:47<54:46:20, 27.80s/it]                                                         {'loss': 0.952, 'learning_rate': 1.59654750277428e-05, 'epoch': 0.32}
 32%|███▏      | 3302/10395 [9:26:47<54:46:20, 27.80s/it] 32%|███▏      | 3303/10395 [9:26:55<42:55:07, 21.79s/it]                                                         {'loss': 0.9169, 'learning_rate': 1.596297412092285e-05, 'epoch': 0.32}
 32%|███▏      | 3303/10395 [9:26:55<42:55:07, 21.79s/it] 32%|███▏      | 3304/10395 [9:27:03<34:37:02, 17.57s/it]                                                         {'loss': 0.8685, 'learning_rate': 1.5960472635230117e-05, 'epoch': 0.32}
 32%|███▏      | 3304/10395 [9:27:03<34:37:02, 17.57s/it] 32%|███▏      | 3305/10395 [9:27:10<28:31:22, 14.48s/it]                                                         {'loss': 0.8881, 'learning_rate': 1.5957970570907437e-05, 'epoch': 0.32}
 32%|███▏      | 3305/10395 [9:27:10<28:31:22, 14.48s/it] 32%|███▏      | 3306/10395 [9:27:18<24:39:11, 12.52s/it]                                                         {'loss': 0.9953, 'learning_rate': 1.5955467928197704e-05, 'epoch': 0.32}
 32%|███▏      | 3306/10395 [9:27:18<24:39:11, 12.52s/it] 32%|███▏      | 3307/10395 [9:27:26<21:54:07, 11.12s/it]                                                         {'loss': 0.9614, 'learning_rate': 1.5952964707343875e-05, 'epoch': 0.32}
 32%|███▏      | 3307/10395 [9:27:26<21:54:07, 11.12s/it] 32%|███▏      | 3308/10395 [9:27:44<25:52:15, 13.14s/it]                                                         {'loss': 0.4225, 'learning_rate': 1.5950460908588952e-05, 'epoch': 0.32}
 32%|███▏      | 3308/10395 [9:27:44<25:52:15, 13.14s/it] 32%|███▏      | 3309/10395 [9:27:52<23:11:09, 11.78s/it]                                                         {'loss': 0.9173, 'learning_rate': 1.5947956532176e-05, 'epoch': 0.32}
 32%|███▏      | 3309/10395 [9:27:52<23:11:09, 11.78s/it] 32%|███▏      | 3310/10395 [9:28:00<20:38:49, 10.49s/it]                                                         {'loss': 0.9266, 'learning_rate': 1.594545157834814e-05, 'epoch': 0.32}
 32%|███▏      | 3310/10395 [9:28:00<20:38:49, 10.49s/it] 32%|███▏      | 3311/10395 [9:28:08<18:58:39,  9.64s/it]                                                         {'loss': 0.9411, 'learning_rate': 1.5942946047348547e-05, 'epoch': 0.32}
 32%|███▏      | 3311/10395 [9:28:08<18:58:39,  9.64s/it] 32%|███▏      | 3312/10395 [9:28:16<18:16:27,  9.29s/it]                                                         {'loss': 0.9903, 'learning_rate': 1.5940439939420448e-05, 'epoch': 0.32}
 32%|███▏      | 3312/10395 [9:28:16<18:16:27,  9.29s/it] 32%|███▏      | 3313/10395 [9:28:24<17:49:46,  9.06s/it]                                                         {'loss': 0.9106, 'learning_rate': 1.593793325480714e-05, 'epoch': 0.32}
 32%|███▏      | 3313/10395 [9:28:25<17:49:46,  9.06s/it] 32%|███▏      | 3314/10395 [9:28:32<17:04:02,  8.68s/it]                                                         {'loss': 1.0339, 'learning_rate': 1.5935425993751957e-05, 'epoch': 0.32}
 32%|███▏      | 3314/10395 [9:28:32<17:04:02,  8.68s/it] 32%|███▏      | 3315/10395 [9:28:40<16:29:06,  8.38s/it]                                                         {'loss': 0.8963, 'learning_rate': 1.5932918156498306e-05, 'epoch': 0.32}
 32%|███▏      | 3315/10395 [9:28:40<16:29:06,  8.38s/it] 32%|███▏      | 3316/10395 [9:28:47<15:52:10,  8.07s/it]                                                         {'loss': 1.0659, 'learning_rate': 1.5930409743289636e-05, 'epoch': 0.32}
 32%|███▏      | 3316/10395 [9:28:47<15:52:10,  8.07s/it] 32%|███▏      | 3317/10395 [9:28:56<15:56:52,  8.11s/it]                                                         {'loss': 0.9446, 'learning_rate': 1.592790075436946e-05, 'epoch': 0.32}
 32%|███▏      | 3317/10395 [9:28:56<15:56:52,  8.11s/it] 32%|███▏      | 3318/10395 [9:29:03<15:30:59,  7.89s/it]                                                         {'loss': 0.9525, 'learning_rate': 1.592539118998135e-05, 'epoch': 0.32}
 32%|███▏      | 3318/10395 [9:29:03<15:30:59,  7.89s/it] 32%|███▏      | 3319/10395 [9:29:10<15:15:21,  7.76s/it]                                                         {'loss': 0.9525, 'learning_rate': 1.5922881050368927e-05, 'epoch': 0.32}
 32%|███▏      | 3319/10395 [9:29:10<15:15:21,  7.76s/it] 32%|███▏      | 3320/10395 [9:29:18<15:08:58,  7.71s/it]                                                         {'loss': 0.9986, 'learning_rate': 1.5920370335775867e-05, 'epoch': 0.32}
 32%|███▏      | 3320/10395 [9:29:18<15:08:58,  7.71s/it] 32%|███▏      | 3321/10395 [9:29:26<15:04:37,  7.67s/it]                                                         {'loss': 0.946, 'learning_rate': 1.5917859046445906e-05, 'epoch': 0.32}
 32%|███▏      | 3321/10395 [9:29:26<15:04:37,  7.67s/it] 32%|███▏      | 3322/10395 [9:29:33<15:04:26,  7.67s/it]                                                         {'loss': 0.9276, 'learning_rate': 1.5915347182622833e-05, 'epoch': 0.32}
 32%|███▏      | 3322/10395 [9:29:33<15:04:26,  7.67s/it] 32%|███▏      | 3323/10395 [9:29:41<15:06:23,  7.69s/it]                                                         {'loss': 0.9682, 'learning_rate': 1.59128347445505e-05, 'epoch': 0.32}
 32%|███▏      | 3323/10395 [9:29:41<15:06:23,  7.69s/it] 32%|███▏      | 3324/10395 [9:29:49<15:19:27,  7.80s/it]                                                         {'loss': 0.917, 'learning_rate': 1.5910321732472805e-05, 'epoch': 0.32}
 32%|███▏      | 3324/10395 [9:29:49<15:19:27,  7.80s/it] 32%|███▏      | 3325/10395 [9:29:58<15:56:15,  8.12s/it]                                                         {'loss': 0.8926, 'learning_rate': 1.5907808146633708e-05, 'epoch': 0.32}
 32%|███▏      | 3325/10395 [9:29:58<15:56:15,  8.12s/it] 32%|███▏      | 3326/10395 [9:30:05<15:33:03,  7.92s/it]                                                         {'loss': 0.9002, 'learning_rate': 1.5905293987277218e-05, 'epoch': 0.32}
 32%|███▏      | 3326/10395 [9:30:05<15:33:03,  7.92s/it] 32%|███▏      | 3327/10395 [9:30:14<15:52:40,  8.09s/it]                                                         {'loss': 0.9914, 'learning_rate': 1.590277925464741e-05, 'epoch': 0.32}
 32%|███▏      | 3327/10395 [9:30:14<15:52:40,  8.09s/it] 32%|███▏      | 3328/10395 [9:30:23<16:20:06,  8.32s/it]                                                         {'loss': 0.9319, 'learning_rate': 1.590026394898841e-05, 'epoch': 0.32}
 32%|███▏      | 3328/10395 [9:30:23<16:20:06,  8.32s/it] 32%|███▏      | 3329/10395 [9:30:30<15:56:13,  8.12s/it]                                                         {'loss': 0.9575, 'learning_rate': 1.5897748070544387e-05, 'epoch': 0.32}
 32%|███▏      | 3329/10395 [9:30:30<15:56:13,  8.12s/it] 32%|███▏      | 3330/10395 [9:30:38<15:52:17,  8.09s/it]                                                         {'loss': 0.9641, 'learning_rate': 1.5895231619559588e-05, 'epoch': 0.32}
 32%|███▏      | 3330/10395 [9:30:39<15:52:17,  8.09s/it] 32%|███▏      | 3331/10395 [9:30:48<16:44:29,  8.53s/it]                                                         {'loss': 0.9463, 'learning_rate': 1.5892714596278302e-05, 'epoch': 0.32}
 32%|███▏      | 3331/10395 [9:30:48<16:44:29,  8.53s/it] 32%|███▏      | 3332/10395 [9:30:55<16:00:19,  8.16s/it]                                                         {'loss': 1.0215, 'learning_rate': 1.5890197000944873e-05, 'epoch': 0.32}
 32%|███▏      | 3332/10395 [9:30:55<16:00:19,  8.16s/it] 32%|███▏      | 3333/10395 [9:31:05<17:05:07,  8.71s/it]                                                         {'loss': 0.8653, 'learning_rate': 1.588767883380371e-05, 'epoch': 0.32}
 32%|███▏      | 3333/10395 [9:31:05<17:05:07,  8.71s/it] 32%|███▏      | 3334/10395 [9:31:13<16:45:24,  8.54s/it]                                                         {'loss': 0.9338, 'learning_rate': 1.5885160095099264e-05, 'epoch': 0.32}
 32%|███▏      | 3334/10395 [9:31:13<16:45:24,  8.54s/it] 32%|███▏      | 3335/10395 [9:31:21<16:02:24,  8.18s/it]                                                         {'loss': 0.9676, 'learning_rate': 1.588264078507606e-05, 'epoch': 0.32}
 32%|███▏      | 3335/10395 [9:31:21<16:02:24,  8.18s/it] 32%|███▏      | 3336/10395 [9:31:28<15:37:59,  7.97s/it]                                                         {'loss': 1.0166, 'learning_rate': 1.5880120903978652e-05, 'epoch': 0.32}
 32%|███▏      | 3336/10395 [9:31:28<15:37:59,  7.97s/it] 32%|███▏      | 3337/10395 [9:31:35<15:14:35,  7.77s/it]                                                         {'loss': 0.9997, 'learning_rate': 1.5877600452051677e-05, 'epoch': 0.32}
 32%|███▏      | 3337/10395 [9:31:35<15:14:35,  7.77s/it] 32%|███▏      | 3338/10395 [9:31:44<15:51:13,  8.09s/it]                                                         {'loss': 0.9498, 'learning_rate': 1.587507942953981e-05, 'epoch': 0.32}
 32%|███▏      | 3338/10395 [9:31:44<15:51:13,  8.09s/it] 32%|███▏      | 3339/10395 [9:31:52<15:42:29,  8.01s/it]                                                         {'loss': 0.9479, 'learning_rate': 1.587255783668779e-05, 'epoch': 0.32}
 32%|███▏      | 3339/10395 [9:31:52<15:42:29,  8.01s/it] 32%|███▏      | 3340/10395 [9:32:00<15:51:52,  8.10s/it]                                                         {'loss': 0.9536, 'learning_rate': 1.5870035673740396e-05, 'epoch': 0.32}
 32%|███▏      | 3340/10395 [9:32:00<15:51:52,  8.10s/it] 32%|███▏      | 3341/10395 [9:32:08<15:30:46,  7.92s/it]                                                         {'loss': 0.8715, 'learning_rate': 1.586751294094249e-05, 'epoch': 0.32}
 32%|███▏      | 3341/10395 [9:32:08<15:30:46,  7.92s/it] 32%|███▏      | 3342/10395 [9:32:16<15:21:01,  7.84s/it]                                                         {'loss': 0.9003, 'learning_rate': 1.5864989638538967e-05, 'epoch': 0.32}
 32%|███▏      | 3342/10395 [9:32:16<15:21:01,  7.84s/it] 32%|███▏      | 3343/10395 [9:32:24<15:25:53,  7.88s/it]                                                         {'loss': 0.9329, 'learning_rate': 1.586246576677478e-05, 'epoch': 0.32}
 32%|███▏      | 3343/10395 [9:32:24<15:25:53,  7.88s/it] 32%|███▏      | 3344/10395 [9:32:31<15:15:55,  7.79s/it]                                                         {'loss': 0.9756, 'learning_rate': 1.5859941325894946e-05, 'epoch': 0.32}
 32%|███▏      | 3344/10395 [9:32:31<15:15:55,  7.79s/it] 32%|███▏      | 3345/10395 [9:32:39<15:11:49,  7.76s/it]                                                         {'loss': 0.9771, 'learning_rate': 1.585741631614453e-05, 'epoch': 0.32}
 32%|███▏      | 3345/10395 [9:32:39<15:11:49,  7.76s/it] 32%|███▏      | 3346/10395 [9:32:47<15:16:16,  7.80s/it]                                                         {'loss': 0.894, 'learning_rate': 1.5854890737768657e-05, 'epoch': 0.32}
 32%|███▏      | 3346/10395 [9:32:47<15:16:16,  7.80s/it] 32%|███▏      | 3347/10395 [9:32:54<14:58:35,  7.65s/it]                                                         {'loss': 1.0391, 'learning_rate': 1.58523645910125e-05, 'epoch': 0.32}
 32%|███▏      | 3347/10395 [9:32:54<14:58:35,  7.65s/it] 32%|███▏      | 3348/10395 [9:33:03<15:46:49,  8.06s/it]                                                         {'loss': 0.9184, 'learning_rate': 1.5849837876121295e-05, 'epoch': 0.32}
 32%|███▏      | 3348/10395 [9:33:03<15:46:49,  8.06s/it] 32%|███▏      | 3349/10395 [9:33:12<16:29:16,  8.42s/it]                                                         {'loss': 0.9438, 'learning_rate': 1.5847310593340336e-05, 'epoch': 0.32}
 32%|███▏      | 3349/10395 [9:33:12<16:29:16,  8.42s/it] 32%|███▏      | 3350/10395 [9:33:20<15:59:13,  8.17s/it]                                                         {'loss': 1.0018, 'learning_rate': 1.5844782742914958e-05, 'epoch': 0.32}
 32%|███▏      | 3350/10395 [9:33:20<15:59:13,  8.17s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 32%|███▏      | 3351/10395 [9:35:00<70:07:47, 35.84s/it]                                                         {'loss': 0.9304, 'learning_rate': 1.5842254325090557e-05, 'epoch': 0.32}
 32%|███▏      | 3351/10395 [9:35:00<70:07:47, 35.84s/it] 32%|███▏      | 3352/10395 [9:35:08<53:50:41, 27.52s/it]                                                         {'loss': 0.9656, 'learning_rate': 1.5839725340112594e-05, 'epoch': 0.32}
 32%|███▏      | 3352/10395 [9:35:08<53:50:41, 27.52s/it] 32%|███▏      | 3353/10395 [9:35:16<42:07:56, 21.54s/it]                                                         {'loss': 0.9394, 'learning_rate': 1.5837195788226578e-05, 'epoch': 0.32}
 32%|███▏      | 3353/10395 [9:35:16<42:07:56, 21.54s/it] 32%|███▏      | 3354/10395 [9:35:23<33:50:24, 17.30s/it]                                                         {'loss': 0.9826, 'learning_rate': 1.5834665669678065e-05, 'epoch': 0.32}
 32%|███▏      | 3354/10395 [9:35:23<33:50:24, 17.30s/it] 32%|███▏      | 3355/10395 [9:35:31<28:21:58, 14.51s/it]                                                         {'loss': 0.8854, 'learning_rate': 1.5832134984712678e-05, 'epoch': 0.32}
 32%|███▏      | 3355/10395 [9:35:31<28:21:58, 14.51s/it] 32%|███▏      | 3356/10395 [9:35:39<24:32:14, 12.55s/it]                                                         {'loss': 0.8923, 'learning_rate': 1.582960373357609e-05, 'epoch': 0.32}
 32%|███▏      | 3356/10395 [9:35:39<24:32:14, 12.55s/it] 32%|███▏      | 3357/10395 [9:35:48<22:00:15, 11.26s/it]                                                         {'loss': 1.0185, 'learning_rate': 1.582707191651403e-05, 'epoch': 0.32}
 32%|███▏      | 3357/10395 [9:35:48<22:00:15, 11.26s/it] 32%|███▏      | 3358/10395 [9:35:56<20:27:00, 10.46s/it]                                                         {'loss': 0.9276, 'learning_rate': 1.582453953377228e-05, 'epoch': 0.32}
 32%|███▏      | 3358/10395 [9:35:56<20:27:00, 10.46s/it] 32%|███▏      | 3359/10395 [9:36:03<18:26:27,  9.44s/it]                                                         {'loss': 0.9769, 'learning_rate': 1.582200658559668e-05, 'epoch': 0.32}
 32%|███▏      | 3359/10395 [9:36:03<18:26:27,  9.44s/it] 32%|███▏      | 3360/10395 [9:36:12<17:58:16,  9.20s/it]                                                         {'loss': 0.9153, 'learning_rate': 1.5819473072233123e-05, 'epoch': 0.32}
 32%|███▏      | 3360/10395 [9:36:12<17:58:16,  9.20s/it] 32%|███▏      | 3361/10395 [9:36:20<17:10:29,  8.79s/it]                                                         {'loss': 1.023, 'learning_rate': 1.5816938993927554e-05, 'epoch': 0.32}
 32%|███▏      | 3361/10395 [9:36:20<17:10:29,  8.79s/it] 32%|███▏      | 3362/10395 [9:36:27<16:18:51,  8.35s/it]                                                         {'loss': 0.8864, 'learning_rate': 1.5814404350925984e-05, 'epoch': 0.32}
 32%|███▏      | 3362/10395 [9:36:27<16:18:51,  8.35s/it] 32%|███▏      | 3363/10395 [9:36:35<15:51:59,  8.12s/it]                                                         {'loss': 0.9906, 'learning_rate': 1.5811869143474458e-05, 'epoch': 0.32}
 32%|███▏      | 3363/10395 [9:36:35<15:51:59,  8.12s/it] 32%|███▏      | 3364/10395 [9:36:42<15:24:35,  7.89s/it]                                                         {'loss': 1.076, 'learning_rate': 1.58093333718191e-05, 'epoch': 0.32}
 32%|███▏      | 3364/10395 [9:36:42<15:24:35,  7.89s/it] 32%|███▏      | 3365/10395 [9:36:49<15:10:39,  7.77s/it]                                                         {'loss': 0.9609, 'learning_rate': 1.5806797036206072e-05, 'epoch': 0.32}
 32%|███▏      | 3365/10395 [9:36:49<15:10:39,  7.77s/it] 32%|███▏      | 3366/10395 [9:36:57<15:13:28,  7.80s/it]                                                         {'loss': 0.8968, 'learning_rate': 1.5804260136881596e-05, 'epoch': 0.32}
 32%|███▏      | 3366/10395 [9:36:57<15:13:28,  7.80s/it] 32%|███▏      | 3367/10395 [9:37:05<15:24:02,  7.89s/it]                                                         {'loss': 0.9193, 'learning_rate': 1.580172267409195e-05, 'epoch': 0.32}
 32%|███▏      | 3367/10395 [9:37:05<15:24:02,  7.89s/it] 32%|███▏      | 3368/10395 [9:37:13<15:23:29,  7.89s/it]                                                         {'loss': 0.9934, 'learning_rate': 1.5799184648083464e-05, 'epoch': 0.32}
 32%|███▏      | 3368/10395 [9:37:13<15:23:29,  7.89s/it] 32%|███▏      | 3369/10395 [9:37:20<14:57:23,  7.66s/it]                                                         {'loss': 0.9915, 'learning_rate': 1.5796646059102527e-05, 'epoch': 0.32}
 32%|███▏      | 3369/10395 [9:37:20<14:57:23,  7.66s/it] 32%|███▏      | 3370/10395 [9:37:28<15:08:30,  7.76s/it]                                                         {'loss': 0.9138, 'learning_rate': 1.5794106907395576e-05, 'epoch': 0.32}
 32%|███▏      | 3370/10395 [9:37:28<15:08:30,  7.76s/it] 32%|███▏      | 3371/10395 [9:37:36<14:59:18,  7.68s/it]                                                         {'loss': 0.942, 'learning_rate': 1.579156719320911e-05, 'epoch': 0.32}
 32%|███▏      | 3371/10395 [9:37:36<14:59:18,  7.68s/it] 32%|███▏      | 3372/10395 [9:37:43<14:45:32,  7.57s/it]                                                         {'loss': 0.9055, 'learning_rate': 1.5789026916789677e-05, 'epoch': 0.32}
 32%|███▏      | 3372/10395 [9:37:43<14:45:32,  7.57s/it] 32%|███▏      | 3373/10395 [9:37:51<14:37:36,  7.50s/it]                                                         {'loss': 0.9579, 'learning_rate': 1.5786486078383884e-05, 'epoch': 0.32}
 32%|███▏      | 3373/10395 [9:37:51<14:37:36,  7.50s/it] 32%|███▏      | 3374/10395 [9:38:00<15:47:36,  8.10s/it]                                                         {'loss': 0.9358, 'learning_rate': 1.5783944678238387e-05, 'epoch': 0.32}
 32%|███▏      | 3374/10395 [9:38:00<15:47:36,  8.10s/it] 32%|███▏      | 3375/10395 [9:38:08<15:57:43,  8.19s/it]                                                         {'loss': 0.9113, 'learning_rate': 1.5781402716599902e-05, 'epoch': 0.32}
 32%|███▏      | 3375/10395 [9:38:08<15:57:43,  8.19s/it] 32%|███▏      | 3376/10395 [9:38:17<16:08:13,  8.28s/it]                                                         {'loss': 0.8793, 'learning_rate': 1.5778860193715195e-05, 'epoch': 0.32}
 32%|███▏      | 3376/10395 [9:38:17<16:08:13,  8.28s/it] 32%|███▏      | 3377/10395 [9:38:24<15:37:37,  8.02s/it]                                                         {'loss': 0.9135, 'learning_rate': 1.5776317109831086e-05, 'epoch': 0.32}
 32%|███▏      | 3377/10395 [9:38:24<15:37:37,  8.02s/it] 32%|███▏      | 3378/10395 [9:38:32<15:24:26,  7.90s/it]                                                         {'loss': 0.9611, 'learning_rate': 1.577377346519446e-05, 'epoch': 0.32}
 32%|███▏      | 3378/10395 [9:38:32<15:24:26,  7.90s/it] 33%|███▎      | 3379/10395 [9:38:39<15:10:02,  7.78s/it]                                                         {'loss': 1.0147, 'learning_rate': 1.577122926005225e-05, 'epoch': 0.33}
 33%|███▎      | 3379/10395 [9:38:40<15:10:02,  7.78s/it] 33%|███▎      | 3380/10395 [9:38:49<16:14:47,  8.34s/it]                                                         {'loss': 0.8526, 'learning_rate': 1.576868449465143e-05, 'epoch': 0.33}
 33%|███▎      | 3380/10395 [9:38:49<16:14:47,  8.34s/it] 33%|███▎      | 3381/10395 [9:39:07<21:43:06, 11.15s/it]                                                         {'loss': 0.3909, 'learning_rate': 1.5766139169239044e-05, 'epoch': 0.33}
 33%|███▎      | 3381/10395 [9:39:07<21:43:06, 11.15s/it] 33%|███▎      | 3382/10395 [9:39:17<21:08:24, 10.85s/it]                                                         {'loss': 0.897, 'learning_rate': 1.5763593284062192e-05, 'epoch': 0.33}
 33%|███▎      | 3382/10395 [9:39:17<21:08:24, 10.85s/it] 33%|███▎      | 3383/10395 [9:39:25<19:36:19, 10.07s/it]                                                         {'loss': 0.9558, 'learning_rate': 1.5761046839368024e-05, 'epoch': 0.33}
 33%|███▎      | 3383/10395 [9:39:25<19:36:19, 10.07s/it] 33%|███▎      | 3384/10395 [9:39:32<17:57:44,  9.22s/it]                                                         {'loss': 0.9009, 'learning_rate': 1.575849983540374e-05, 'epoch': 0.33}
 33%|███▎      | 3384/10395 [9:39:32<17:57:44,  9.22s/it] 33%|███▎      | 3385/10395 [9:39:41<17:28:51,  8.98s/it]                                                         {'loss': 0.9188, 'learning_rate': 1.5755952272416595e-05, 'epoch': 0.33}
 33%|███▎      | 3385/10395 [9:39:41<17:28:51,  8.98s/it] 33%|███▎      | 3386/10395 [9:39:49<16:44:07,  8.60s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.575340415065391e-05, 'epoch': 0.33}
 33%|███▎      | 3386/10395 [9:39:49<16:44:07,  8.60s/it] 33%|███▎      | 3387/10395 [9:39:56<16:11:23,  8.32s/it]                                                         {'loss': 0.9472, 'learning_rate': 1.575085547036304e-05, 'epoch': 0.33}
 33%|███▎      | 3387/10395 [9:39:56<16:11:23,  8.32s/it]WARNING: tokenization mismatch: 1 vs. 1473. (ignored)
 33%|███▎      | 3388/10395 [9:40:03<15:33:04,  7.99s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.574830623179141e-05, 'epoch': 0.33}
 33%|███▎      | 3388/10395 [9:40:03<15:33:04,  7.99s/it] 33%|███▎      | 3389/10395 [9:40:11<15:15:26,  7.84s/it]                                                         {'loss': 0.9463, 'learning_rate': 1.5745756435186494e-05, 'epoch': 0.33}
 33%|███▎      | 3389/10395 [9:40:11<15:15:26,  7.84s/it] 33%|███▎      | 3390/10395 [9:40:28<20:51:14, 10.72s/it]                                                         {'loss': 0.4056, 'learning_rate': 1.5743206080795825e-05, 'epoch': 0.33}
 33%|███▎      | 3390/10395 [9:40:28<20:51:14, 10.72s/it] 33%|███▎      | 3391/10395 [9:40:37<19:25:29,  9.98s/it]                                                         {'loss': 1.0518, 'learning_rate': 1.5740655168866982e-05, 'epoch': 0.33}
 33%|███▎      | 3391/10395 [9:40:37<19:25:29,  9.98s/it] 33%|███▎      | 3392/10395 [9:40:45<18:20:11,  9.43s/it]                                                         {'loss': 0.9739, 'learning_rate': 1.57381036996476e-05, 'epoch': 0.33}
 33%|███▎      | 3392/10395 [9:40:45<18:20:11,  9.43s/it] 33%|███▎      | 3393/10395 [9:40:53<17:21:56,  8.93s/it]                                                         {'loss': 0.9146, 'learning_rate': 1.573555167338538e-05, 'epoch': 0.33}
 33%|███▎      | 3393/10395 [9:40:53<17:21:56,  8.93s/it] 33%|███▎      | 3394/10395 [9:41:01<17:03:07,  8.77s/it]                                                         {'loss': 0.9269, 'learning_rate': 1.5732999090328055e-05, 'epoch': 0.33}
 33%|███▎      | 3394/10395 [9:41:01<17:03:07,  8.77s/it] 33%|███▎      | 3395/10395 [9:41:08<16:12:10,  8.33s/it]                                                         {'loss': 0.8872, 'learning_rate': 1.5730445950723435e-05, 'epoch': 0.33}
 33%|███▎      | 3395/10395 [9:41:08<16:12:10,  8.33s/it] 33%|███▎      | 3396/10395 [9:41:16<16:06:47,  8.29s/it]                                                         {'loss': 0.9711, 'learning_rate': 1.5727892254819363e-05, 'epoch': 0.33}
 33%|███▎      | 3396/10395 [9:41:16<16:06:47,  8.29s/it] 33%|███▎      | 3397/10395 [9:41:24<15:44:30,  8.10s/it]                                                         {'loss': 0.8443, 'learning_rate': 1.5725338002863755e-05, 'epoch': 0.33}
 33%|███▎      | 3397/10395 [9:41:24<15:44:30,  8.10s/it] 33%|███▎      | 3398/10395 [9:41:31<15:18:22,  7.88s/it]                                                         {'loss': 0.8982, 'learning_rate': 1.5722783195104568e-05, 'epoch': 0.33}
 33%|███▎      | 3398/10395 [9:41:31<15:18:22,  7.88s/it] 33%|███▎      | 3399/10395 [9:41:39<14:59:51,  7.72s/it]                                                         {'loss': 0.9063, 'learning_rate': 1.5720227831789816e-05, 'epoch': 0.33}
 33%|███▎      | 3399/10395 [9:41:39<14:59:51,  7.72s/it] 33%|███▎      | 3400/10395 [9:41:47<15:13:55,  7.84s/it]                                                         {'loss': 1.0737, 'learning_rate': 1.5717671913167573e-05, 'epoch': 0.33}
 33%|███▎      | 3400/10395 [9:41:47<15:13:55,  7.84s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 3401/10395 [9:43:23<66:37:44, 34.30s/it]                                                         {'loss': 0.8226, 'learning_rate': 1.5715115439485958e-05, 'epoch': 0.33}
 33%|███▎      | 3401/10395 [9:43:23<66:37:44, 34.30s/it] 33%|███▎      | 3402/10395 [9:43:31<51:03:35, 26.29s/it]                                                         {'loss': 0.9237, 'learning_rate': 1.5712558410993147e-05, 'epoch': 0.33}
 33%|███▎      | 3402/10395 [9:43:31<51:03:35, 26.29s/it] 33%|███▎      | 3403/10395 [9:43:39<40:31:39, 20.87s/it]                                                         {'loss': 0.9382, 'learning_rate': 1.5710000827937376e-05, 'epoch': 0.33}
 33%|███▎      | 3403/10395 [9:43:39<40:31:39, 20.87s/it] 33%|███▎      | 3404/10395 [9:43:46<32:38:08, 16.81s/it]                                                         {'loss': 0.9746, 'learning_rate': 1.5707442690566924e-05, 'epoch': 0.33}
 33%|███▎      | 3404/10395 [9:43:46<32:38:08, 16.81s/it] 33%|███▎      | 3405/10395 [9:43:54<27:12:00, 14.01s/it]                                                         {'loss': 0.9273, 'learning_rate': 1.5704883999130137e-05, 'epoch': 0.33}
 33%|███▎      | 3405/10395 [9:43:54<27:12:00, 14.01s/it] 33%|███▎      | 3406/10395 [9:44:02<23:39:50, 12.19s/it]                                                         {'loss': 1.0042, 'learning_rate': 1.57023247538754e-05, 'epoch': 0.33}
 33%|███▎      | 3406/10395 [9:44:02<23:39:50, 12.19s/it] 33%|███▎      | 3407/10395 [9:44:09<20:58:56, 10.81s/it]                                                         {'loss': 0.9867, 'learning_rate': 1.5699764955051163e-05, 'epoch': 0.33}
 33%|███▎      | 3407/10395 [9:44:09<20:58:56, 10.81s/it] 33%|███▎      | 3408/10395 [9:44:17<19:19:37,  9.96s/it]                                                         {'loss': 0.9268, 'learning_rate': 1.5697204602905926e-05, 'epoch': 0.33}
 33%|███▎      | 3408/10395 [9:44:17<19:19:37,  9.96s/it] 33%|███▎      | 3409/10395 [9:44:25<18:12:41,  9.38s/it]                                                         {'loss': 0.9278, 'learning_rate': 1.5694643697688236e-05, 'epoch': 0.33}
 33%|███▎      | 3409/10395 [9:44:25<18:12:41,  9.38s/it] 33%|███▎      | 3410/10395 [9:44:33<17:18:16,  8.92s/it]                                                         {'loss': 0.994, 'learning_rate': 1.569208223964671e-05, 'epoch': 0.33}
 33%|███▎      | 3410/10395 [9:44:33<17:18:16,  8.92s/it] 33%|███▎      | 3411/10395 [9:44:42<17:08:48,  8.84s/it]                                                         {'loss': 0.9713, 'learning_rate': 1.5689520229030002e-05, 'epoch': 0.33}
 33%|███▎      | 3411/10395 [9:44:42<17:08:48,  8.84s/it] 33%|███▎      | 3412/10395 [9:44:49<16:22:51,  8.45s/it]                                                         {'loss': 0.9892, 'learning_rate': 1.568695766608683e-05, 'epoch': 0.33}
 33%|███▎      | 3412/10395 [9:44:49<16:22:51,  8.45s/it] 33%|███▎      | 3413/10395 [9:44:58<16:21:27,  8.43s/it]                                                         {'loss': 0.9446, 'learning_rate': 1.5684394551065956e-05, 'epoch': 0.33}
 33%|███▎      | 3413/10395 [9:44:58<16:21:27,  8.43s/it] 33%|███▎      | 3414/10395 [9:45:05<15:35:50,  8.04s/it]                                                         {'loss': 0.9257, 'learning_rate': 1.5681830884216215e-05, 'epoch': 0.33}
 33%|███▎      | 3414/10395 [9:45:05<15:35:50,  8.04s/it] 33%|███▎      | 3415/10395 [9:45:12<15:05:27,  7.78s/it]                                                         {'loss': 0.9941, 'learning_rate': 1.567926666578647e-05, 'epoch': 0.33}
 33%|███▎      | 3415/10395 [9:45:12<15:05:27,  7.78s/it] 33%|███▎      | 3416/10395 [9:45:20<15:31:15,  8.01s/it]                                                         {'loss': 0.9719, 'learning_rate': 1.5676701896025656e-05, 'epoch': 0.33}
 33%|███▎      | 3416/10395 [9:45:20<15:31:15,  8.01s/it] 33%|███▎      | 3417/10395 [9:45:28<15:09:30,  7.82s/it]                                                         {'loss': 0.9639, 'learning_rate': 1.567413657518275e-05, 'epoch': 0.33}
 33%|███▎      | 3417/10395 [9:45:28<15:09:30,  7.82s/it] 33%|███▎      | 3418/10395 [9:45:36<15:09:50,  7.82s/it]                                                         {'loss': 1.0328, 'learning_rate': 1.5671570703506788e-05, 'epoch': 0.33}
 33%|███▎      | 3418/10395 [9:45:36<15:09:50,  7.82s/it] 33%|███▎      | 3419/10395 [9:45:43<15:06:15,  7.79s/it]                                                         {'loss': 0.9104, 'learning_rate': 1.5669004281246868e-05, 'epoch': 0.33}
 33%|███▎      | 3419/10395 [9:45:43<15:06:15,  7.79s/it] 33%|███▎      | 3420/10395 [9:45:50<14:43:13,  7.60s/it]                                                         {'loss': 0.9946, 'learning_rate': 1.5666437308652122e-05, 'epoch': 0.33}
 33%|███▎      | 3420/10395 [9:45:50<14:43:13,  7.60s/it] 33%|███▎      | 3421/10395 [9:45:58<14:54:12,  7.69s/it]                                                         {'loss': 0.9927, 'learning_rate': 1.5663869785971754e-05, 'epoch': 0.33}
 33%|███▎      | 3421/10395 [9:45:58<14:54:12,  7.69s/it] 33%|███▎      | 3422/10395 [9:46:06<14:57:13,  7.72s/it]                                                         {'loss': 0.9627, 'learning_rate': 1.5661301713455013e-05, 'epoch': 0.33}
 33%|███▎      | 3422/10395 [9:46:06<14:57:13,  7.72s/it] 33%|███▎      | 3423/10395 [9:46:13<14:38:00,  7.56s/it]                                                         {'loss': 0.9411, 'learning_rate': 1.5658733091351195e-05, 'epoch': 0.33}
 33%|███▎      | 3423/10395 [9:46:13<14:38:00,  7.56s/it] 33%|███▎      | 3424/10395 [9:46:31<20:36:21, 10.64s/it]                                                         {'loss': 0.4542, 'learning_rate': 1.5656163919909666e-05, 'epoch': 0.33}
 33%|███▎      | 3424/10395 [9:46:31<20:36:21, 10.64s/it] 33%|███▎      | 3425/10395 [9:46:40<19:31:29, 10.08s/it]                                                         {'loss': 0.9814, 'learning_rate': 1.565359419937983e-05, 'epoch': 0.33}
 33%|███▎      | 3425/10395 [9:46:40<19:31:29, 10.08s/it] 33%|███▎      | 3426/10395 [9:46:48<18:19:44,  9.47s/it]                                                         {'loss': 0.9444, 'learning_rate': 1.565102393001115e-05, 'epoch': 0.33}
 33%|███▎      | 3426/10395 [9:46:48<18:19:44,  9.47s/it] 33%|███▎      | 3427/10395 [9:46:55<17:10:03,  8.87s/it]                                                         {'loss': 0.9266, 'learning_rate': 1.564845311205314e-05, 'epoch': 0.33}
 33%|███▎      | 3427/10395 [9:46:55<17:10:03,  8.87s/it] 33%|███▎      | 3428/10395 [9:47:05<17:33:16,  9.07s/it]                                                         {'loss': 0.9269, 'learning_rate': 1.564588174575538e-05, 'epoch': 0.33}
 33%|███▎      | 3428/10395 [9:47:05<17:33:16,  9.07s/it] 33%|███▎      | 3429/10395 [9:47:13<16:40:51,  8.62s/it]                                                         {'loss': 0.8994, 'learning_rate': 1.5643309831367477e-05, 'epoch': 0.33}
 33%|███▎      | 3429/10395 [9:47:13<16:40:51,  8.62s/it] 33%|███▎      | 3430/10395 [9:47:20<15:57:31,  8.25s/it]                                                         {'loss': 0.9078, 'learning_rate': 1.5640737369139122e-05, 'epoch': 0.33}
 33%|███▎      | 3430/10395 [9:47:20<15:57:31,  8.25s/it] 33%|███▎      | 3431/10395 [9:47:28<15:32:19,  8.03s/it]                                                         {'loss': 0.9348, 'learning_rate': 1.5638164359320033e-05, 'epoch': 0.33}
 33%|███▎      | 3431/10395 [9:47:28<15:32:19,  8.03s/it] 33%|███▎      | 3432/10395 [9:47:35<15:29:16,  8.01s/it]                                                         {'loss': 0.9801, 'learning_rate': 1.563559080216e-05, 'epoch': 0.33}
 33%|███▎      | 3432/10395 [9:47:35<15:29:16,  8.01s/it] 33%|███▎      | 3433/10395 [9:47:43<15:10:44,  7.85s/it]                                                         {'loss': 0.9761, 'learning_rate': 1.563301669790885e-05, 'epoch': 0.33}
 33%|███▎      | 3433/10395 [9:47:43<15:10:44,  7.85s/it] 33%|███▎      | 3434/10395 [9:47:51<15:15:44,  7.89s/it]                                                         {'loss': 0.8746, 'learning_rate': 1.5630442046816484e-05, 'epoch': 0.33}
 33%|███▎      | 3434/10395 [9:47:51<15:15:44,  7.89s/it] 33%|███▎      | 3435/10395 [9:47:59<15:05:20,  7.80s/it]                                                         {'loss': 0.9373, 'learning_rate': 1.5627866849132837e-05, 'epoch': 0.33}
 33%|███▎      | 3435/10395 [9:47:59<15:05:20,  7.80s/it] 33%|███▎      | 3436/10395 [9:48:08<16:00:07,  8.28s/it]                                                         {'loss': 0.9002, 'learning_rate': 1.5625291105107895e-05, 'epoch': 0.33}
 33%|███▎      | 3436/10395 [9:48:08<16:00:07,  8.28s/it] 33%|███▎      | 3437/10395 [9:48:16<15:52:22,  8.21s/it]                                                         {'loss': 0.9114, 'learning_rate': 1.5622714814991717e-05, 'epoch': 0.33}
 33%|███▎      | 3437/10395 [9:48:16<15:52:22,  8.21s/it] 33%|███▎      | 3438/10395 [9:48:24<15:44:23,  8.14s/it]                                                         {'loss': 1.0316, 'learning_rate': 1.5620137979034403e-05, 'epoch': 0.33}
 33%|███▎      | 3438/10395 [9:48:24<15:44:23,  8.14s/it] 33%|███▎      | 3439/10395 [9:48:31<15:21:56,  7.95s/it]                                                         {'loss': 0.9934, 'learning_rate': 1.5617560597486102e-05, 'epoch': 0.33}
 33%|███▎      | 3439/10395 [9:48:31<15:21:56,  7.95s/it] 33%|███▎      | 3440/10395 [9:48:39<15:03:09,  7.79s/it]                                                         {'loss': 0.9981, 'learning_rate': 1.5614982670597024e-05, 'epoch': 0.33}
 33%|███▎      | 3440/10395 [9:48:39<15:03:09,  7.79s/it] 33%|███▎      | 3441/10395 [9:48:48<15:40:31,  8.11s/it]                                                         {'loss': 0.8791, 'learning_rate': 1.561240419861743e-05, 'epoch': 0.33}
 33%|███▎      | 3441/10395 [9:48:48<15:40:31,  8.11s/it] 33%|███▎      | 3442/10395 [9:48:55<15:12:46,  7.88s/it]                                                         {'loss': 0.9608, 'learning_rate': 1.5609825181797627e-05, 'epoch': 0.33}
 33%|███▎      | 3442/10395 [9:48:55<15:12:46,  7.88s/it] 33%|███▎      | 3443/10395 [9:49:03<15:23:47,  7.97s/it]                                                         {'loss': 0.9801, 'learning_rate': 1.5607245620387983e-05, 'epoch': 0.33}
 33%|███▎      | 3443/10395 [9:49:03<15:23:47,  7.97s/it] 33%|███▎      | 3444/10395 [9:49:11<15:19:07,  7.93s/it]                                                         {'loss': 0.8693, 'learning_rate': 1.560466551463892e-05, 'epoch': 0.33}
 33%|███▎      | 3444/10395 [9:49:11<15:19:07,  7.93s/it] 33%|███▎      | 3445/10395 [9:49:19<15:10:17,  7.86s/it]                                                         {'loss': 0.9867, 'learning_rate': 1.5602084864800904e-05, 'epoch': 0.33}
 33%|███▎      | 3445/10395 [9:49:19<15:10:17,  7.86s/it] 33%|███▎      | 3446/10395 [9:49:26<14:48:20,  7.67s/it]                                                         {'loss': 1.0224, 'learning_rate': 1.5599503671124462e-05, 'epoch': 0.33}
 33%|███▎      | 3446/10395 [9:49:26<14:48:20,  7.67s/it] 33%|███▎      | 3447/10395 [9:49:44<20:48:08, 10.78s/it]                                                         {'loss': 0.3954, 'learning_rate': 1.5596921933860167e-05, 'epoch': 0.33}
 33%|███▎      | 3447/10395 [9:49:44<20:48:08, 10.78s/it] 33%|███▎      | 3448/10395 [9:49:52<19:02:57,  9.87s/it]                                                         {'loss': 1.0721, 'learning_rate': 1.559433965325865e-05, 'epoch': 0.33}
 33%|███▎      | 3448/10395 [9:49:52<19:02:57,  9.87s/it] 33%|███▎      | 3449/10395 [9:50:00<18:00:57,  9.34s/it]                                                         {'loss': 0.9886, 'learning_rate': 1.5591756829570602e-05, 'epoch': 0.33}
 33%|███▎      | 3449/10395 [9:50:00<18:00:57,  9.34s/it] 33%|███▎      | 3450/10395 [9:50:08<17:01:26,  8.82s/it]                                                         {'loss': 0.9809, 'learning_rate': 1.5589173463046745e-05, 'epoch': 0.33}
 33%|███▎      | 3450/10395 [9:50:08<17:01:26,  8.82s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 3451/10395 [9:51:46<68:53:30, 35.72s/it]                                                         {'loss': 0.9954, 'learning_rate': 1.5586589553937874e-05, 'epoch': 0.33}
 33%|███▎      | 3451/10395 [9:51:46<68:53:30, 35.72s/it] 33%|███▎      | 3452/10395 [9:51:54<52:52:37, 27.42s/it]                                                         {'loss': 0.985, 'learning_rate': 1.5584005102494828e-05, 'epoch': 0.33}
 33%|███▎      | 3452/10395 [9:51:54<52:52:37, 27.42s/it] 33%|███▎      | 3453/10395 [9:52:02<41:28:37, 21.51s/it]                                                         {'loss': 0.8772, 'learning_rate': 1.55814201089685e-05, 'epoch': 0.33}
 33%|███▎      | 3453/10395 [9:52:02<41:28:37, 21.51s/it] 33%|███▎      | 3454/10395 [9:52:09<33:19:34, 17.28s/it]                                                         {'loss': 1.0289, 'learning_rate': 1.5578834573609835e-05, 'epoch': 0.33}
 33%|███▎      | 3454/10395 [9:52:09<33:19:34, 17.28s/it] 33%|███▎      | 3455/10395 [9:52:16<27:28:52, 14.26s/it]                                                         {'loss': 0.8933, 'learning_rate': 1.5576248496669827e-05, 'epoch': 0.33}
 33%|███▎      | 3455/10395 [9:52:16<27:28:52, 14.26s/it] 33%|███▎      | 3456/10395 [9:52:24<23:27:48, 12.17s/it]                                                         {'loss': 0.9941, 'learning_rate': 1.557366187839954e-05, 'epoch': 0.33}
 33%|███▎      | 3456/10395 [9:52:24<23:27:48, 12.17s/it] 33%|███▎      | 3457/10395 [9:52:32<20:59:18, 10.89s/it]                                                         {'loss': 0.8031, 'learning_rate': 1.557107471905006e-05, 'epoch': 0.33}
 33%|███▎      | 3457/10395 [9:52:32<20:59:18, 10.89s/it] 33%|███▎      | 3458/10395 [9:52:40<19:16:16, 10.00s/it]                                                         {'loss': 0.92, 'learning_rate': 1.5568487018872558e-05, 'epoch': 0.33}
 33%|███▎      | 3458/10395 [9:52:40<19:16:16, 10.00s/it] 33%|███▎      | 3459/10395 [9:52:58<23:55:54, 12.42s/it]                                                         {'loss': 0.4209, 'learning_rate': 1.5565898778118236e-05, 'epoch': 0.33}
 33%|███▎      | 3459/10395 [9:52:58<23:55:54, 12.42s/it] 33%|███▎      | 3460/10395 [9:53:05<20:58:07, 10.88s/it]                                                         {'loss': 1.0347, 'learning_rate': 1.5563309997038354e-05, 'epoch': 0.33}
 33%|███▎      | 3460/10395 [9:53:05<20:58:07, 10.88s/it] 33%|███▎      | 3461/10395 [9:53:13<19:27:15, 10.10s/it]                                                         {'loss': 0.9575, 'learning_rate': 1.5560720675884224e-05, 'epoch': 0.33}
 33%|███▎      | 3461/10395 [9:53:13<19:27:15, 10.10s/it] 33%|███▎      | 3462/10395 [9:53:21<18:21:26,  9.53s/it]                                                         {'loss': 0.9662, 'learning_rate': 1.5558130814907215e-05, 'epoch': 0.33}
 33%|███▎      | 3462/10395 [9:53:21<18:21:26,  9.53s/it] 33%|███▎      | 3463/10395 [9:53:38<22:35:24, 11.73s/it]                                                         {'loss': 0.3862, 'learning_rate': 1.5555540414358746e-05, 'epoch': 0.33}
 33%|███▎      | 3463/10395 [9:53:38<22:35:24, 11.73s/it] 33%|███▎      | 3464/10395 [9:53:48<21:16:18, 11.05s/it]                                                         {'loss': 0.8386, 'learning_rate': 1.5552949474490285e-05, 'epoch': 0.33}
 33%|███▎      | 3464/10395 [9:53:48<21:16:18, 11.05s/it] 33%|███▎      | 3465/10395 [9:54:04<24:06:37, 12.52s/it]                                                         {'loss': 0.4017, 'learning_rate': 1.5550357995553353e-05, 'epoch': 0.33}
 33%|███▎      | 3465/10395 [9:54:04<24:06:37, 12.52s/it] 33%|███▎      | 3466/10395 [9:54:12<21:26:16, 11.14s/it]                                                         {'loss': 0.8619, 'learning_rate': 1.554776597779953e-05, 'epoch': 0.33}
 33%|███▎      | 3466/10395 [9:54:12<21:26:16, 11.14s/it] 33%|███▎      | 3467/10395 [9:54:19<19:17:50, 10.03s/it]                                                         {'loss': 0.9287, 'learning_rate': 1.5545173421480445e-05, 'epoch': 0.33}
 33%|███▎      | 3467/10395 [9:54:19<19:17:50, 10.03s/it] 33%|███▎      | 3468/10395 [9:54:27<18:07:57,  9.42s/it]                                                         {'loss': 0.8578, 'learning_rate': 1.554258032684777e-05, 'epoch': 0.33}
 33%|███▎      | 3468/10395 [9:54:27<18:07:57,  9.42s/it] 33%|███▎      | 3469/10395 [9:54:35<17:08:25,  8.91s/it]                                                         {'loss': 0.9094, 'learning_rate': 1.5539986694153243e-05, 'epoch': 0.33}
 33%|███▎      | 3469/10395 [9:54:35<17:08:25,  8.91s/it] 33%|███▎      | 3470/10395 [9:54:43<16:32:22,  8.60s/it]                                                         {'loss': 0.9764, 'learning_rate': 1.5537392523648646e-05, 'epoch': 0.33}
 33%|███▎      | 3470/10395 [9:54:43<16:32:22,  8.60s/it] 33%|███▎      | 3471/10395 [9:54:50<15:57:50,  8.30s/it]                                                         {'loss': 0.9639, 'learning_rate': 1.5534797815585813e-05, 'epoch': 0.33}
 33%|███▎      | 3471/10395 [9:54:50<15:57:50,  8.30s/it] 33%|███▎      | 3472/10395 [9:54:57<15:20:57,  7.98s/it]                                                         {'loss': 0.9291, 'learning_rate': 1.553220257021664e-05, 'epoch': 0.33}
 33%|███▎      | 3472/10395 [9:54:57<15:20:57,  7.98s/it] 33%|███▎      | 3473/10395 [9:55:05<15:09:49,  7.89s/it]                                                         {'loss': 1.0153, 'learning_rate': 1.5529606787793063e-05, 'epoch': 0.33}
 33%|███▎      | 3473/10395 [9:55:05<15:09:49,  7.89s/it] 33%|███▎      | 3474/10395 [9:55:13<14:58:39,  7.79s/it]                                                         {'loss': 0.9905, 'learning_rate': 1.552701046856708e-05, 'epoch': 0.33}
 33%|███▎      | 3474/10395 [9:55:13<14:58:39,  7.79s/it] 33%|███▎      | 3475/10395 [9:55:20<14:50:08,  7.72s/it]                                                         {'loss': 0.9274, 'learning_rate': 1.5524413612790725e-05, 'epoch': 0.33}
 33%|███▎      | 3475/10395 [9:55:20<14:50:08,  7.72s/it] 33%|███▎      | 3476/10395 [9:55:30<16:10:25,  8.42s/it]                                                         {'loss': 0.8933, 'learning_rate': 1.5521816220716106e-05, 'epoch': 0.33}
 33%|███▎      | 3476/10395 [9:55:30<16:10:25,  8.42s/it] 33%|███▎      | 3477/10395 [9:55:38<15:51:01,  8.25s/it]                                                         {'loss': 0.9691, 'learning_rate': 1.551921829259537e-05, 'epoch': 0.33}
 33%|███▎      | 3477/10395 [9:55:38<15:51:01,  8.25s/it] 33%|███▎      | 3478/10395 [9:55:46<15:22:19,  8.00s/it]                                                         {'loss': 1.0046, 'learning_rate': 1.5516619828680713e-05, 'epoch': 0.33}
 33%|███▎      | 3478/10395 [9:55:46<15:22:19,  8.00s/it] 33%|███▎      | 3479/10395 [9:55:53<15:05:07,  7.85s/it]                                                         {'loss': 0.9284, 'learning_rate': 1.5514020829224394e-05, 'epoch': 0.33}
 33%|███▎      | 3479/10395 [9:55:53<15:05:07,  7.85s/it] 33%|███▎      | 3480/10395 [9:56:01<15:18:14,  7.97s/it]                                                         {'loss': 0.9891, 'learning_rate': 1.5511421294478715e-05, 'epoch': 0.33}
 33%|███▎      | 3480/10395 [9:56:01<15:18:14,  7.97s/it] 33%|███▎      | 3481/10395 [9:56:10<15:46:55,  8.22s/it]                                                         {'loss': 0.9956, 'learning_rate': 1.5508821224696035e-05, 'epoch': 0.33}
 33%|███▎      | 3481/10395 [9:56:10<15:46:55,  8.22s/it] 33%|███▎      | 3482/10395 [9:56:18<15:28:14,  8.06s/it]                                                         {'loss': 0.9793, 'learning_rate': 1.5506220620128764e-05, 'epoch': 0.33}
 33%|███▎      | 3482/10395 [9:56:18<15:28:14,  8.06s/it] 34%|███▎      | 3483/10395 [9:56:25<15:14:33,  7.94s/it]                                                         {'loss': 0.9451, 'learning_rate': 1.550361948102936e-05, 'epoch': 0.34}
 34%|███▎      | 3483/10395 [9:56:25<15:14:33,  7.94s/it] 34%|███▎      | 3484/10395 [9:56:33<15:18:47,  7.98s/it]                                                         {'loss': 0.896, 'learning_rate': 1.5501017807650343e-05, 'epoch': 0.34}
 34%|███▎      | 3484/10395 [9:56:34<15:18:47,  7.98s/it] 34%|███▎      | 3485/10395 [9:56:51<20:57:57, 10.92s/it]                                                         {'loss': 0.4005, 'learning_rate': 1.549841560024427e-05, 'epoch': 0.34}
 34%|███▎      | 3485/10395 [9:56:51<20:57:57, 10.92s/it] 34%|███▎      | 3486/10395 [9:56:59<19:06:33,  9.96s/it]                                                         {'loss': 0.9478, 'learning_rate': 1.549581285906376e-05, 'epoch': 0.34}
 34%|███▎      | 3486/10395 [9:56:59<19:06:33,  9.96s/it] 34%|███▎      | 3487/10395 [9:57:07<18:09:02,  9.46s/it]                                                         {'loss': 0.9343, 'learning_rate': 1.549320958436148e-05, 'epoch': 0.34}
 34%|███▎      | 3487/10395 [9:57:07<18:09:02,  9.46s/it] 34%|███▎      | 3488/10395 [9:57:15<17:04:37,  8.90s/it]                                                         {'loss': 1.0763, 'learning_rate': 1.5490605776390156e-05, 'epoch': 0.34}
 34%|███▎      | 3488/10395 [9:57:15<17:04:37,  8.90s/it] 34%|███▎      | 3489/10395 [9:57:23<16:37:49,  8.67s/it]                                                         {'loss': 0.9129, 'learning_rate': 1.548800143540256e-05, 'epoch': 0.34}
 34%|███▎      | 3489/10395 [9:57:23<16:37:49,  8.67s/it] 34%|███▎      | 3490/10395 [9:57:31<16:09:16,  8.42s/it]                                                         {'loss': 0.9754, 'learning_rate': 1.5485396561651503e-05, 'epoch': 0.34}
 34%|███▎      | 3490/10395 [9:57:31<16:09:16,  8.42s/it] 34%|███▎      | 3491/10395 [9:57:48<21:05:35, 11.00s/it]                                                         {'loss': 0.3888, 'learning_rate': 1.5482791155389877e-05, 'epoch': 0.34}
 34%|███▎      | 3491/10395 [9:57:48<21:05:35, 11.00s/it] 34%|███▎      | 3492/10395 [9:57:56<19:22:16, 10.10s/it]                                                         {'loss': 0.9877, 'learning_rate': 1.54801852168706e-05, 'epoch': 0.34}
 34%|███▎      | 3492/10395 [9:57:56<19:22:16, 10.10s/it] 34%|███▎      | 3493/10395 [9:58:04<18:14:01,  9.51s/it]                                                         {'loss': 1.0615, 'learning_rate': 1.5477578746346655e-05, 'epoch': 0.34}
 34%|███▎      | 3493/10395 [9:58:04<18:14:01,  9.51s/it] 34%|███▎      | 3494/10395 [9:58:12<17:10:37,  8.96s/it]                                                         {'loss': 0.9474, 'learning_rate': 1.547497174407107e-05, 'epoch': 0.34}
 34%|███▎      | 3494/10395 [9:58:12<17:10:37,  8.96s/it] 34%|███▎      | 3495/10395 [9:58:20<16:34:46,  8.65s/it]                                                         {'loss': 0.9348, 'learning_rate': 1.5472364210296928e-05, 'epoch': 0.34}
 34%|███▎      | 3495/10395 [9:58:20<16:34:46,  8.65s/it] 34%|███▎      | 3496/10395 [9:58:27<15:53:13,  8.29s/it]                                                         {'loss': 1.0167, 'learning_rate': 1.546975614527736e-05, 'epoch': 0.34}
 34%|███▎      | 3496/10395 [9:58:27<15:53:13,  8.29s/it] 34%|███▎      | 3497/10395 [9:58:36<16:01:40,  8.36s/it]                                                         {'loss': 0.9469, 'learning_rate': 1.5467147549265564e-05, 'epoch': 0.34}
 34%|███▎      | 3497/10395 [9:58:36<16:01:40,  8.36s/it] 34%|███▎      | 3498/10395 [9:58:43<15:29:22,  8.09s/it]                                                         {'loss': 1.0245, 'learning_rate': 1.5464538422514757e-05, 'epoch': 0.34}
 34%|███▎      | 3498/10395 [9:58:43<15:29:22,  8.09s/it] 34%|███▎      | 3499/10395 [9:58:51<15:38:40,  8.17s/it]                                                         {'loss': 0.9414, 'learning_rate': 1.5461928765278244e-05, 'epoch': 0.34}
 34%|███▎      | 3499/10395 [9:58:51<15:38:40,  8.17s/it] 34%|███▎      | 3500/10395 [9:59:08<20:43:29, 10.82s/it]                                                         {'loss': 0.3772, 'learning_rate': 1.5459318577809355e-05, 'epoch': 0.34}
 34%|███▎      | 3500/10395 [9:59:08<20:43:29, 10.82s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 34%|███▎      | 3501/10395 [10:00:48<71:26:41, 37.31s/it]                                                          {'loss': 0.9451, 'learning_rate': 1.5456707860361485e-05, 'epoch': 0.34}
 34%|███▎      | 3501/10395 [10:00:48<71:26:41, 37.31s/it] 34%|███▎      | 3502/10395 [10:00:55<54:29:00, 28.45s/it]                                                          {'loss': 1.0063, 'learning_rate': 1.5454096613188076e-05, 'epoch': 0.34}
 34%|███▎      | 3502/10395 [10:00:55<54:29:00, 28.45s/it] 34%|███▎      | 3503/10395 [10:01:13<48:09:41, 25.16s/it]                                                          {'loss': 0.4108, 'learning_rate': 1.5451484836542626e-05, 'epoch': 0.34}
 34%|███▎      | 3503/10395 [10:01:13<48:09:41, 25.16s/it] 34%|███▎      | 3504/10395 [10:01:20<38:05:17, 19.90s/it]                                                          {'loss': 0.9467, 'learning_rate': 1.5448872530678678e-05, 'epoch': 0.34}
 34%|███▎      | 3504/10395 [10:01:20<38:05:17, 19.90s/it] 34%|███▎      | 3505/10395 [10:01:28<30:55:50, 16.16s/it]                                                          {'loss': 0.9858, 'learning_rate': 1.544625969584983e-05, 'epoch': 0.34}
 34%|███▎      | 3505/10395 [10:01:28<30:55:50, 16.16s/it] 34%|███▎      | 3506/10395 [10:01:36<26:11:07, 13.68s/it]                                                          {'loss': 0.918, 'learning_rate': 1.5443646332309726e-05, 'epoch': 0.34}
 34%|███▎      | 3506/10395 [10:01:36<26:11:07, 13.68s/it] 34%|███▎      | 3507/10395 [10:01:43<22:40:39, 11.85s/it]                                                          {'loss': 0.9489, 'learning_rate': 1.544103244031207e-05, 'epoch': 0.34}
 34%|███▎      | 3507/10395 [10:01:43<22:40:39, 11.85s/it] 34%|███▎      | 3508/10395 [10:01:51<20:24:59, 10.67s/it]                                                          {'loss': 0.9307, 'learning_rate': 1.5438418020110616e-05, 'epoch': 0.34}
 34%|███▎      | 3508/10395 [10:01:51<20:24:59, 10.67s/it] 34%|███▍      | 3509/10395 [10:01:59<18:38:01,  9.74s/it]                                                          {'loss': 0.9604, 'learning_rate': 1.543580307195916e-05, 'epoch': 0.34}
 34%|███▍      | 3509/10395 [10:01:59<18:38:01,  9.74s/it] 34%|███▍      | 3510/10395 [10:02:06<17:15:32,  9.02s/it]                                                          {'loss': 0.9679, 'learning_rate': 1.5433187596111557e-05, 'epoch': 0.34}
 34%|███▍      | 3510/10395 [10:02:06<17:15:32,  9.02s/it] 34%|███▍      | 3511/10395 [10:02:14<16:40:50,  8.72s/it]                                                          {'loss': 0.9778, 'learning_rate': 1.5430571592821712e-05, 'epoch': 0.34}
 34%|███▍      | 3511/10395 [10:02:14<16:40:50,  8.72s/it] 34%|███▍      | 3512/10395 [10:02:22<15:59:28,  8.36s/it]                                                          {'loss': 0.9991, 'learning_rate': 1.5427955062343586e-05, 'epoch': 0.34}
 34%|███▍      | 3512/10395 [10:02:22<15:59:28,  8.36s/it] 34%|███▍      | 3513/10395 [10:02:29<15:38:52,  8.19s/it]                                                          {'loss': 0.9849, 'learning_rate': 1.542533800493118e-05, 'epoch': 0.34}
 34%|███▍      | 3513/10395 [10:02:29<15:38:52,  8.19s/it] 34%|███▍      | 3514/10395 [10:02:38<15:36:33,  8.17s/it]                                                          {'loss': 0.9786, 'learning_rate': 1.5422720420838554e-05, 'epoch': 0.34}
 34%|███▍      | 3514/10395 [10:02:38<15:36:33,  8.17s/it] 34%|███▍      | 3515/10395 [10:02:54<20:29:45, 10.72s/it]                                                          {'loss': 0.3138, 'learning_rate': 1.5420102310319818e-05, 'epoch': 0.34}
 34%|███▍      | 3515/10395 [10:02:54<20:29:45, 10.72s/it] 34%|███▍      | 3516/10395 [10:03:04<19:41:59, 10.31s/it]                                                          {'loss': 1.0297, 'learning_rate': 1.541748367362913e-05, 'epoch': 0.34}
 34%|███▍      | 3516/10395 [10:03:04<19:41:59, 10.31s/it] 34%|███▍      | 3517/10395 [10:03:12<18:48:36,  9.85s/it]                                                          {'loss': 0.8963, 'learning_rate': 1.541486451102071e-05, 'epoch': 0.34}
 34%|███▍      | 3517/10395 [10:03:12<18:48:36,  9.85s/it] 34%|███▍      | 3518/10395 [10:03:20<17:26:22,  9.13s/it]                                                          {'loss': 1.0039, 'learning_rate': 1.541224482274881e-05, 'epoch': 0.34}
 34%|███▍      | 3518/10395 [10:03:20<17:26:22,  9.13s/it] 34%|███▍      | 3519/10395 [10:03:28<17:04:33,  8.94s/it]                                                          {'loss': 0.8631, 'learning_rate': 1.540962460906775e-05, 'epoch': 0.34}
 34%|███▍      | 3519/10395 [10:03:28<17:04:33,  8.94s/it] 34%|███▍      | 3520/10395 [10:03:37<16:44:35,  8.77s/it]                                                          {'loss': 0.9419, 'learning_rate': 1.5407003870231894e-05, 'epoch': 0.34}
 34%|███▍      | 3520/10395 [10:03:37<16:44:35,  8.77s/it] 34%|███▍      | 3521/10395 [10:03:45<16:24:45,  8.60s/it]                                                          {'loss': 0.9477, 'learning_rate': 1.5404382606495657e-05, 'epoch': 0.34}
 34%|███▍      | 3521/10395 [10:03:45<16:24:45,  8.60s/it] 34%|███▍      | 3522/10395 [10:03:53<15:58:55,  8.37s/it]                                                          {'loss': 0.9495, 'learning_rate': 1.5401760818113504e-05, 'epoch': 0.34}
 34%|███▍      | 3522/10395 [10:03:53<15:58:55,  8.37s/it] 34%|███▍      | 3523/10395 [10:04:10<21:14:00, 11.12s/it]                                                          {'loss': 0.4157, 'learning_rate': 1.5399138505339958e-05, 'epoch': 0.34}
 34%|███▍      | 3523/10395 [10:04:10<21:14:00, 11.12s/it] 34%|███▍      | 3524/10395 [10:04:18<19:06:00, 10.01s/it]                                                          {'loss': 0.935, 'learning_rate': 1.539651566842958e-05, 'epoch': 0.34}
 34%|███▍      | 3524/10395 [10:04:18<19:06:00, 10.01s/it] 34%|███▍      | 3525/10395 [10:04:36<23:47:01, 12.46s/it]                                                          {'loss': 0.3794, 'learning_rate': 1.5393892307636996e-05, 'epoch': 0.34}
 34%|███▍      | 3525/10395 [10:04:36<23:47:01, 12.46s/it] 34%|███▍      | 3526/10395 [10:04:44<21:08:09, 11.08s/it]                                                          {'loss': 0.9698, 'learning_rate': 1.5391268423216873e-05, 'epoch': 0.34}
 34%|███▍      | 3526/10395 [10:04:44<21:08:09, 11.08s/it] 34%|███▍      | 3527/10395 [10:04:52<19:18:35, 10.12s/it]                                                          {'loss': 0.9781, 'learning_rate': 1.5388644015423932e-05, 'epoch': 0.34}
 34%|███▍      | 3527/10395 [10:04:52<19:18:35, 10.12s/it] 34%|███▍      | 3528/10395 [10:04:59<17:56:28,  9.41s/it]                                                          {'loss': 0.9737, 'learning_rate': 1.5386019084512946e-05, 'epoch': 0.34}
 34%|███▍      | 3528/10395 [10:04:59<17:56:28,  9.41s/it] 34%|███▍      | 3529/10395 [10:05:07<16:46:52,  8.80s/it]                                                          {'loss': 0.9427, 'learning_rate': 1.5383393630738737e-05, 'epoch': 0.34}
 34%|███▍      | 3529/10395 [10:05:07<16:46:52,  8.80s/it] 34%|███▍      | 3530/10395 [10:05:16<16:47:20,  8.80s/it]                                                          {'loss': 0.961, 'learning_rate': 1.538076765435618e-05, 'epoch': 0.34}
 34%|███▍      | 3530/10395 [10:05:16<16:47:20,  8.80s/it] 34%|███▍      | 3531/10395 [10:05:23<15:54:30,  8.34s/it]                                                          {'loss': 1.0126, 'learning_rate': 1.5378141155620196e-05, 'epoch': 0.34}
 34%|███▍      | 3531/10395 [10:05:23<15:54:30,  8.34s/it] 34%|███▍      | 3532/10395 [10:05:30<15:24:06,  8.08s/it]                                                          {'loss': 0.9148, 'learning_rate': 1.537551413478576e-05, 'epoch': 0.34}
 34%|███▍      | 3532/10395 [10:05:30<15:24:06,  8.08s/it] 34%|███▍      | 3533/10395 [10:05:40<16:33:22,  8.69s/it]                                                          {'loss': 0.8911, 'learning_rate': 1.5372886592107904e-05, 'epoch': 0.34}
 34%|███▍      | 3533/10395 [10:05:40<16:33:22,  8.69s/it] 34%|███▍      | 3534/10395 [10:05:49<16:17:28,  8.55s/it]                                                          {'loss': 0.9789, 'learning_rate': 1.5370258527841696e-05, 'epoch': 0.34}
 34%|███▍      | 3534/10395 [10:05:49<16:17:28,  8.55s/it] 34%|███▍      | 3535/10395 [10:05:56<15:22:03,  8.06s/it]                                                          {'loss': 1.0133, 'learning_rate': 1.536762994224227e-05, 'epoch': 0.34}
 34%|███▍      | 3535/10395 [10:05:56<15:22:03,  8.06s/it] 34%|███▍      | 3536/10395 [10:06:04<15:42:45,  8.25s/it]                                                          {'loss': 0.9753, 'learning_rate': 1.5365000835564798e-05, 'epoch': 0.34}
 34%|███▍      | 3536/10395 [10:06:04<15:42:45,  8.25s/it] 34%|███▍      | 3537/10395 [10:06:12<15:20:14,  8.05s/it]                                                          {'loss': 0.9172, 'learning_rate': 1.5362371208064507e-05, 'epoch': 0.34}
 34%|███▍      | 3537/10395 [10:06:12<15:20:14,  8.05s/it] 34%|███▍      | 3538/10395 [10:06:19<15:00:48,  7.88s/it]                                                          {'loss': 0.9368, 'learning_rate': 1.5359741059996682e-05, 'epoch': 0.34}
 34%|███▍      | 3538/10395 [10:06:19<15:00:48,  7.88s/it] 34%|███▍      | 3539/10395 [10:06:27<14:58:37,  7.86s/it]                                                          {'loss': 0.9199, 'learning_rate': 1.5357110391616647e-05, 'epoch': 0.34}
 34%|███▍      | 3539/10395 [10:06:27<14:58:37,  7.86s/it] 34%|███▍      | 3540/10395 [10:06:45<20:26:37, 10.74s/it]                                                          {'loss': 0.3984, 'learning_rate': 1.5354479203179785e-05, 'epoch': 0.34}
 34%|███▍      | 3540/10395 [10:06:45<20:26:37, 10.74s/it] 34%|███▍      | 3541/10395 [10:06:53<18:58:15,  9.96s/it]                                                          {'loss': 0.8438, 'learning_rate': 1.5351847494941524e-05, 'epoch': 0.34}
 34%|███▍      | 3541/10395 [10:06:53<18:58:15,  9.96s/it] 34%|███▍      | 3542/10395 [10:07:00<17:39:15,  9.27s/it]                                                          {'loss': 0.9177, 'learning_rate': 1.5349215267157346e-05, 'epoch': 0.34}
 34%|███▍      | 3542/10395 [10:07:00<17:39:15,  9.27s/it] 34%|███▍      | 3543/10395 [10:07:10<17:33:31,  9.23s/it]                                                          {'loss': 0.9839, 'learning_rate': 1.5346582520082777e-05, 'epoch': 0.34}
 34%|███▍      | 3543/10395 [10:07:10<17:33:31,  9.23s/it] 34%|███▍      | 3544/10395 [10:07:17<16:36:43,  8.73s/it]                                                          {'loss': 0.9772, 'learning_rate': 1.5343949253973408e-05, 'epoch': 0.34}
 34%|███▍      | 3544/10395 [10:07:17<16:36:43,  8.73s/it] 34%|███▍      | 3545/10395 [10:07:25<15:52:32,  8.34s/it]                                                          {'loss': 1.0188, 'learning_rate': 1.534131546908486e-05, 'epoch': 0.34}
 34%|███▍      | 3545/10395 [10:07:25<15:52:32,  8.34s/it] 34%|███▍      | 3546/10395 [10:07:33<16:02:39,  8.43s/it]                                                          {'loss': 0.8904, 'learning_rate': 1.5338681165672825e-05, 'epoch': 0.34}
 34%|███▍      | 3546/10395 [10:07:33<16:02:39,  8.43s/it] 34%|███▍      | 3547/10395 [10:07:40<15:20:13,  8.06s/it]                                                          {'loss': 0.956, 'learning_rate': 1.533604634399303e-05, 'epoch': 0.34}
 34%|███▍      | 3547/10395 [10:07:40<15:20:13,  8.06s/it] 34%|███▍      | 3548/10395 [10:07:48<15:09:37,  7.97s/it]                                                          {'loss': 0.9581, 'learning_rate': 1.533341100430126e-05, 'epoch': 0.34}
 34%|███▍      | 3548/10395 [10:07:48<15:09:37,  7.97s/it] 34%|███▍      | 3549/10395 [10:08:05<20:00:28, 10.52s/it]                                                          {'loss': 0.375, 'learning_rate': 1.5330775146853345e-05, 'epoch': 0.34}
 34%|███▍      | 3549/10395 [10:08:05<20:00:28, 10.52s/it] 34%|███▍      | 3550/10395 [10:08:13<18:47:59,  9.89s/it]                                                          {'loss': 0.9303, 'learning_rate': 1.532813877190517e-05, 'epoch': 0.34}
 34%|███▍      | 3550/10395 [10:08:13<18:47:59,  9.89s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 34%|███▍      | 3551/10395 [10:09:55<71:25:15, 37.57s/it]                                                          {'loss': 0.8132, 'learning_rate': 1.532550187971267e-05, 'epoch': 0.34}
 34%|███▍      | 3551/10395 [10:09:55<71:25:15, 37.57s/it] 34%|███▍      | 3552/10395 [10:10:03<54:21:08, 28.59s/it]                                                          {'loss': 0.9472, 'learning_rate': 1.5322864470531834e-05, 'epoch': 0.34}
 34%|███▍      | 3552/10395 [10:10:03<54:21:08, 28.59s/it] 34%|███▍      | 3553/10395 [10:10:10<42:17:40, 22.25s/it]                                                          {'loss': 0.8673, 'learning_rate': 1.5320226544618682e-05, 'epoch': 0.34}
 34%|███▍      | 3553/10395 [10:10:10<42:17:40, 22.25s/it] 34%|███▍      | 3554/10395 [10:10:21<35:35:57, 18.73s/it]                                                          {'loss': 0.9052, 'learning_rate': 1.5317588102229312e-05, 'epoch': 0.34}
 34%|███▍      | 3554/10395 [10:10:21<35:35:57, 18.73s/it] 34%|███▍      | 3555/10395 [10:10:29<29:18:17, 15.42s/it]                                                          {'loss': 0.9136, 'learning_rate': 1.5314949143619853e-05, 'epoch': 0.34}
 34%|███▍      | 3555/10395 [10:10:29<29:18:17, 15.42s/it] 34%|███▍      | 3556/10395 [10:10:47<30:46:23, 16.20s/it]                                                          {'loss': 0.3737, 'learning_rate': 1.5312309669046487e-05, 'epoch': 0.34}
 34%|███▍      | 3556/10395 [10:10:47<30:46:23, 16.20s/it] 34%|███▍      | 3557/10395 [10:10:55<26:06:31, 13.75s/it]                                                          {'loss': 0.975, 'learning_rate': 1.530966967876545e-05, 'epoch': 0.34}
 34%|███▍      | 3557/10395 [10:10:55<26:06:31, 13.75s/it] 34%|███▍      | 3558/10395 [10:11:13<28:39:16, 15.09s/it]                                                          {'loss': 0.3864, 'learning_rate': 1.5307029173033026e-05, 'epoch': 0.34}
 34%|███▍      | 3558/10395 [10:11:13<28:39:16, 15.09s/it] 34%|███▍      | 3559/10395 [10:11:22<25:17:14, 13.32s/it]                                                          {'loss': 0.8422, 'learning_rate': 1.5304388152105554e-05, 'epoch': 0.34}
 34%|███▍      | 3559/10395 [10:11:22<25:17:14, 13.32s/it] 34%|███▍      | 3560/10395 [10:11:29<21:47:31, 11.48s/it]                                                          {'loss': 0.9513, 'learning_rate': 1.5301746616239416e-05, 'epoch': 0.34}
 34%|███▍      | 3560/10395 [10:11:29<21:47:31, 11.48s/it] 34%|███▍      | 3561/10395 [10:11:37<20:00:08, 10.54s/it]                                                          {'loss': 0.9934, 'learning_rate': 1.5299104565691047e-05, 'epoch': 0.34}
 34%|███▍      | 3561/10395 [10:11:37<20:00:08, 10.54s/it] 34%|███▍      | 3562/10395 [10:11:47<19:11:43, 10.11s/it]                                                          {'loss': 0.9173, 'learning_rate': 1.5296462000716926e-05, 'epoch': 0.34}
 34%|███▍      | 3562/10395 [10:11:47<19:11:43, 10.11s/it] 34%|███▍      | 3563/10395 [10:12:05<23:42:51, 12.50s/it]                                                          {'loss': 0.3875, 'learning_rate': 1.5293818921573597e-05, 'epoch': 0.34}
 34%|███▍      | 3563/10395 [10:12:05<23:42:51, 12.50s/it] 34%|███▍      | 3564/10395 [10:12:12<20:49:08, 10.97s/it]                                                          {'loss': 1.0411, 'learning_rate': 1.5291175328517638e-05, 'epoch': 0.34}
 34%|███▍      | 3564/10395 [10:12:12<20:49:08, 10.97s/it] 34%|███▍      | 3565/10395 [10:12:20<19:00:57, 10.02s/it]                                                          {'loss': 0.9868, 'learning_rate': 1.5288531221805687e-05, 'epoch': 0.34}
 34%|███▍      | 3565/10395 [10:12:20<19:00:57, 10.02s/it] 34%|███▍      | 3566/10395 [10:12:28<17:45:10,  9.36s/it]                                                          {'loss': 0.9246, 'learning_rate': 1.528588660169443e-05, 'epoch': 0.34}
 34%|███▍      | 3566/10395 [10:12:28<17:45:10,  9.36s/it] 34%|███▍      | 3567/10395 [10:12:36<16:56:17,  8.93s/it]                                                          {'loss': 0.9096, 'learning_rate': 1.528324146844059e-05, 'epoch': 0.34}
 34%|███▍      | 3567/10395 [10:12:36<16:56:17,  8.93s/it] 34%|███▍      | 3568/10395 [10:12:44<16:28:45,  8.69s/it]                                                          {'loss': 0.9015, 'learning_rate': 1.528059582230096e-05, 'epoch': 0.34}
 34%|███▍      | 3568/10395 [10:12:44<16:28:45,  8.69s/it] 34%|███▍      | 3569/10395 [10:12:52<16:01:43,  8.45s/it]                                                          {'loss': 0.9635, 'learning_rate': 1.5277949663532376e-05, 'epoch': 0.34}
 34%|███▍      | 3569/10395 [10:12:52<16:01:43,  8.45s/it] 34%|███▍      | 3570/10395 [10:12:59<15:24:44,  8.13s/it]                                                          {'loss': 0.9691, 'learning_rate': 1.5275302992391717e-05, 'epoch': 0.34}
 34%|███▍      | 3570/10395 [10:12:59<15:24:44,  8.13s/it] 34%|███▍      | 3571/10395 [10:13:08<15:54:13,  8.39s/it]                                                          {'loss': 0.9443, 'learning_rate': 1.5272655809135914e-05, 'epoch': 0.34}
 34%|███▍      | 3571/10395 [10:13:08<15:54:13,  8.39s/it] 34%|███▍      | 3572/10395 [10:13:16<15:38:54,  8.26s/it]                                                          {'loss': 0.8737, 'learning_rate': 1.5270008114021954e-05, 'epoch': 0.34}
 34%|███▍      | 3572/10395 [10:13:16<15:38:54,  8.26s/it] 34%|███▍      | 3573/10395 [10:13:24<15:29:09,  8.17s/it]                                                          {'loss': 0.8513, 'learning_rate': 1.526735990730687e-05, 'epoch': 0.34}
 34%|███▍      | 3573/10395 [10:13:24<15:29:09,  8.17s/it] 34%|███▍      | 3574/10395 [10:13:31<14:58:01,  7.90s/it]                                                          {'loss': 0.9762, 'learning_rate': 1.5264711189247743e-05, 'epoch': 0.34}
 34%|███▍      | 3574/10395 [10:13:31<14:58:01,  7.90s/it] 34%|███▍      | 3575/10395 [10:13:38<14:33:50,  7.69s/it]                                                          {'loss': 1.0006, 'learning_rate': 1.5262061960101702e-05, 'epoch': 0.34}
 34%|███▍      | 3575/10395 [10:13:38<14:33:50,  7.69s/it] 34%|███▍      | 3576/10395 [10:13:46<14:31:16,  7.67s/it]                                                          {'loss': 0.9278, 'learning_rate': 1.525941222012593e-05, 'epoch': 0.34}
 34%|███▍      | 3576/10395 [10:13:46<14:31:16,  7.67s/it] 34%|███▍      | 3577/10395 [10:13:54<14:40:09,  7.75s/it]                                                          {'loss': 0.856, 'learning_rate': 1.5256761969577665e-05, 'epoch': 0.34}
 34%|███▍      | 3577/10395 [10:13:54<14:40:09,  7.75s/it] 34%|███▍      | 3578/10395 [10:14:12<20:22:10, 10.76s/it]                                                          {'loss': 0.3869, 'learning_rate': 1.5254111208714175e-05, 'epoch': 0.34}
 34%|███▍      | 3578/10395 [10:14:12<20:22:10, 10.76s/it] 34%|███▍      | 3579/10395 [10:14:19<18:24:06,  9.72s/it]                                                          {'loss': 0.9649, 'learning_rate': 1.52514599377928e-05, 'epoch': 0.34}
 34%|███▍      | 3579/10395 [10:14:19<18:24:06,  9.72s/it] 34%|███▍      | 3580/10395 [10:14:37<23:01:11, 12.16s/it]                                                          {'loss': 0.43, 'learning_rate': 1.5248808157070916e-05, 'epoch': 0.34}
 34%|███▍      | 3580/10395 [10:14:37<23:01:11, 12.16s/it] 34%|███▍      | 3581/10395 [10:14:45<20:31:08, 10.84s/it]                                                          {'loss': 0.9126, 'learning_rate': 1.5246155866805954e-05, 'epoch': 0.34}
 34%|███▍      | 3581/10395 [10:14:45<20:31:08, 10.84s/it] 34%|███▍      | 3582/10395 [10:14:52<18:34:11,  9.81s/it]                                                          {'loss': 1.0383, 'learning_rate': 1.5243503067255389e-05, 'epoch': 0.34}
 34%|███▍      | 3582/10395 [10:14:52<18:34:11,  9.81s/it] 34%|███▍      | 3583/10395 [10:14:59<17:09:55,  9.07s/it]                                                          {'loss': 1.0262, 'learning_rate': 1.5240849758676754e-05, 'epoch': 0.34}
 34%|███▍      | 3583/10395 [10:14:59<17:09:55,  9.07s/it] 34%|███▍      | 3584/10395 [10:15:07<16:21:09,  8.64s/it]                                                          {'loss': 0.9242, 'learning_rate': 1.5238195941327622e-05, 'epoch': 0.34}
 34%|███▍      | 3584/10395 [10:15:07<16:21:09,  8.64s/it] 34%|███▍      | 3585/10395 [10:15:15<15:40:22,  8.29s/it]                                                          {'loss': 0.9555, 'learning_rate': 1.5235541615465628e-05, 'epoch': 0.34}
 34%|███▍      | 3585/10395 [10:15:15<15:40:22,  8.29s/it] 34%|███▍      | 3586/10395 [10:15:22<15:21:39,  8.12s/it]                                                          {'loss': 0.9206, 'learning_rate': 1.5232886781348435e-05, 'epoch': 0.34}
 34%|███▍      | 3586/10395 [10:15:22<15:21:39,  8.12s/it] 35%|███▍      | 3587/10395 [10:15:33<16:34:49,  8.77s/it]                                                          {'loss': 0.9174, 'learning_rate': 1.5230231439233778e-05, 'epoch': 0.35}
 35%|███▍      | 3587/10395 [10:15:33<16:34:49,  8.77s/it] 35%|███▍      | 3588/10395 [10:15:41<16:08:07,  8.53s/it]                                                          {'loss': 0.9731, 'learning_rate': 1.5227575589379433e-05, 'epoch': 0.35}
 35%|███▍      | 3588/10395 [10:15:41<16:08:07,  8.53s/it] 35%|███▍      | 3589/10395 [10:15:48<15:45:05,  8.33s/it]                                                          {'loss': 0.9122, 'learning_rate': 1.522491923204322e-05, 'epoch': 0.35}
 35%|███▍      | 3589/10395 [10:15:48<15:45:05,  8.33s/it] 35%|███▍      | 3590/10395 [10:15:56<15:32:16,  8.22s/it]                                                          {'loss': 0.8726, 'learning_rate': 1.5222262367483012e-05, 'epoch': 0.35}
 35%|███▍      | 3590/10395 [10:15:56<15:32:16,  8.22s/it] 35%|███▍      | 3591/10395 [10:16:05<15:51:11,  8.39s/it]                                                          {'loss': 0.8723, 'learning_rate': 1.5219604995956732e-05, 'epoch': 0.35}
 35%|███▍      | 3591/10395 [10:16:05<15:51:11,  8.39s/it] 35%|███▍      | 3592/10395 [10:16:13<15:43:58,  8.33s/it]                                                          {'loss': 0.9517, 'learning_rate': 1.5216947117722355e-05, 'epoch': 0.35}
 35%|███▍      | 3592/10395 [10:16:13<15:43:58,  8.33s/it] 35%|███▍      | 3593/10395 [10:16:23<16:24:59,  8.69s/it]                                                          {'loss': 0.8256, 'learning_rate': 1.5214288733037903e-05, 'epoch': 0.35}
 35%|███▍      | 3593/10395 [10:16:23<16:24:59,  8.69s/it] 35%|███▍      | 3594/10395 [10:16:30<15:32:31,  8.23s/it]                                                          {'loss': 0.9296, 'learning_rate': 1.5211629842161442e-05, 'epoch': 0.35}
 35%|███▍      | 3594/10395 [10:16:30<15:32:31,  8.23s/it] 35%|███▍      | 3595/10395 [10:16:40<16:34:27,  8.77s/it]                                                          {'loss': 0.9597, 'learning_rate': 1.520897044535109e-05, 'epoch': 0.35}
 35%|███▍      | 3595/10395 [10:16:40<16:34:27,  8.77s/it] 35%|███▍      | 3596/10395 [10:16:48<16:05:40,  8.52s/it]                                                          {'loss': 0.8582, 'learning_rate': 1.5206310542865023e-05, 'epoch': 0.35}
 35%|███▍      | 3596/10395 [10:16:48<16:05:40,  8.52s/it] 35%|███▍      | 3597/10395 [10:16:57<16:12:51,  8.59s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.5203650134961454e-05, 'epoch': 0.35}
 35%|███▍      | 3597/10395 [10:16:57<16:12:51,  8.59s/it] 35%|███▍      | 3598/10395 [10:17:05<16:06:22,  8.53s/it]                                                          {'loss': 0.9126, 'learning_rate': 1.520098922189865e-05, 'epoch': 0.35}
 35%|███▍      | 3598/10395 [10:17:05<16:06:22,  8.53s/it] 35%|███▍      | 3599/10395 [10:17:13<15:36:34,  8.27s/it]                                                          {'loss': 0.9616, 'learning_rate': 1.5198327803934925e-05, 'epoch': 0.35}
 35%|███▍      | 3599/10395 [10:17:13<15:36:34,  8.27s/it] 35%|███▍      | 3600/10395 [10:17:20<14:54:37,  7.90s/it]                                                          {'loss': 1.0649, 'learning_rate': 1.5195665881328646e-05, 'epoch': 0.35}
 35%|███▍      | 3600/10395 [10:17:20<14:54:37,  7.90s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 35%|███▍      | 3601/10395 [10:18:59<66:51:42, 35.43s/it]                                                          {'loss': 0.9235, 'learning_rate': 1.5193003454338229e-05, 'epoch': 0.35}
 35%|███▍      | 3601/10395 [10:18:59<66:51:42, 35.43s/it] 35%|███▍      | 3602/10395 [10:19:07<50:52:49, 26.96s/it]                                                          {'loss': 1.0171, 'learning_rate': 1.5190340523222132e-05, 'epoch': 0.35}
 35%|███▍      | 3602/10395 [10:19:07<50:52:49, 26.96s/it] 35%|███▍      | 3603/10395 [10:19:14<39:45:10, 21.07s/it]                                                          {'loss': 1.0202, 'learning_rate': 1.5187677088238869e-05, 'epoch': 0.35}
 35%|███▍      | 3603/10395 [10:19:14<39:45:10, 21.07s/it] 35%|███▍      | 3604/10395 [10:19:22<32:07:41, 17.03s/it]                                                          {'loss': 0.9205, 'learning_rate': 1.5185013149646998e-05, 'epoch': 0.35}
 35%|███▍      | 3604/10395 [10:19:22<32:07:41, 17.03s/it] 35%|███▍      | 3605/10395 [10:19:30<27:06:28, 14.37s/it]                                                          {'loss': 0.9894, 'learning_rate': 1.5182348707705135e-05, 'epoch': 0.35}
 35%|███▍      | 3605/10395 [10:19:30<27:06:28, 14.37s/it] 35%|███▍      | 3606/10395 [10:19:37<23:06:30, 12.25s/it]                                                          {'loss': 0.9241, 'learning_rate': 1.5179683762671933e-05, 'epoch': 0.35}
 35%|███▍      | 3606/10395 [10:19:37<23:06:30, 12.25s/it] 35%|███▍      | 3607/10395 [10:19:45<20:41:41, 10.98s/it]                                                          {'loss': 1.0072, 'learning_rate': 1.51770183148061e-05, 'epoch': 0.35}
 35%|███▍      | 3607/10395 [10:19:45<20:41:41, 10.98s/it] 35%|███▍      | 3608/10395 [10:19:53<18:48:53,  9.98s/it]                                                          {'loss': 0.8798, 'learning_rate': 1.5174352364366391e-05, 'epoch': 0.35}
 35%|███▍      | 3608/10395 [10:19:53<18:48:53,  9.98s/it] 35%|███▍      | 3609/10395 [10:20:00<17:28:20,  9.27s/it]                                                          {'loss': 0.9844, 'learning_rate': 1.5171685911611613e-05, 'epoch': 0.35}
 35%|███▍      | 3609/10395 [10:20:00<17:28:20,  9.27s/it] 35%|███▍      | 3610/10395 [10:20:08<16:19:16,  8.66s/it]                                                          {'loss': 1.0637, 'learning_rate': 1.5169018956800619e-05, 'epoch': 0.35}
 35%|███▍      | 3610/10395 [10:20:08<16:19:16,  8.66s/it] 35%|███▍      | 3611/10395 [10:20:15<15:34:13,  8.26s/it]                                                          {'loss': 0.904, 'learning_rate': 1.5166351500192309e-05, 'epoch': 0.35}
 35%|███▍      | 3611/10395 [10:20:15<15:34:13,  8.26s/it] 35%|███▍      | 3612/10395 [10:20:23<15:14:39,  8.09s/it]                                                          {'loss': 0.9142, 'learning_rate': 1.516368354204564e-05, 'epoch': 0.35}
 35%|███▍      | 3612/10395 [10:20:23<15:14:39,  8.09s/it] 35%|███▍      | 3613/10395 [10:20:31<15:09:09,  8.04s/it]                                                          {'loss': 0.9552, 'learning_rate': 1.5161015082619606e-05, 'epoch': 0.35}
 35%|███▍      | 3613/10395 [10:20:31<15:09:09,  8.04s/it] 35%|███▍      | 3614/10395 [10:20:48<20:29:22, 10.88s/it]                                                          {'loss': 0.354, 'learning_rate': 1.5158346122173253e-05, 'epoch': 0.35}
 35%|███▍      | 3614/10395 [10:20:48<20:29:22, 10.88s/it] 35%|███▍      | 3615/10395 [10:20:57<19:17:06, 10.24s/it]                                                          {'loss': 0.9257, 'learning_rate': 1.5155676660965686e-05, 'epoch': 0.35}
 35%|███▍      | 3615/10395 [10:20:57<19:17:06, 10.24s/it] 35%|███▍      | 3616/10395 [10:21:05<18:19:10,  9.73s/it]                                                          {'loss': 0.9541, 'learning_rate': 1.5153006699256046e-05, 'epoch': 0.35}
 35%|███▍      | 3616/10395 [10:21:05<18:19:10,  9.73s/it] 35%|███▍      | 3617/10395 [10:21:13<17:04:33,  9.07s/it]                                                          {'loss': 0.9225, 'learning_rate': 1.5150336237303527e-05, 'epoch': 0.35}
 35%|███▍      | 3617/10395 [10:21:13<17:04:33,  9.07s/it] 35%|███▍      | 3618/10395 [10:21:21<16:38:17,  8.84s/it]                                                          {'loss': 0.9131, 'learning_rate': 1.5147665275367374e-05, 'epoch': 0.35}
 35%|███▍      | 3618/10395 [10:21:21<16:38:17,  8.84s/it] 35%|███▍      | 3619/10395 [10:21:28<15:39:47,  8.32s/it]                                                          {'loss': 0.9725, 'learning_rate': 1.5144993813706874e-05, 'epoch': 0.35}
 35%|███▍      | 3619/10395 [10:21:28<15:39:47,  8.32s/it] 35%|███▍      | 3620/10395 [10:21:36<15:21:56,  8.16s/it]                                                          {'loss': 0.9305, 'learning_rate': 1.514232185258137e-05, 'epoch': 0.35}
 35%|███▍      | 3620/10395 [10:21:36<15:21:56,  8.16s/it] 35%|███▍      | 3621/10395 [10:21:44<15:06:20,  8.03s/it]                                                          {'loss': 0.8959, 'learning_rate': 1.513964939225025e-05, 'epoch': 0.35}
 35%|███▍      | 3621/10395 [10:21:44<15:06:20,  8.03s/it] 35%|███▍      | 3622/10395 [10:21:51<14:36:06,  7.76s/it]                                                          {'loss': 1.026, 'learning_rate': 1.5136976432972951e-05, 'epoch': 0.35}
 35%|███▍      | 3622/10395 [10:21:51<14:36:06,  7.76s/it] 35%|███▍      | 3623/10395 [10:21:58<14:27:40,  7.69s/it]                                                          {'loss': 0.9661, 'learning_rate': 1.5134302975008957e-05, 'epoch': 0.35}
 35%|███▍      | 3623/10395 [10:21:58<14:27:40,  7.69s/it] 35%|███▍      | 3624/10395 [10:22:06<14:23:53,  7.66s/it]                                                          {'loss': 1.0422, 'learning_rate': 1.5131629018617803e-05, 'epoch': 0.35}
 35%|███▍      | 3624/10395 [10:22:06<14:23:53,  7.66s/it] 35%|███▍      | 3625/10395 [10:22:14<14:21:45,  7.64s/it]                                                          {'loss': 0.962, 'learning_rate': 1.5128954564059068e-05, 'epoch': 0.35}
 35%|███▍      | 3625/10395 [10:22:14<14:21:45,  7.64s/it] 35%|███▍      | 3626/10395 [10:22:21<14:17:25,  7.60s/it]                                                          {'loss': 0.948, 'learning_rate': 1.5126279611592388e-05, 'epoch': 0.35}
 35%|███▍      | 3626/10395 [10:22:21<14:17:25,  7.60s/it] 35%|███▍      | 3627/10395 [10:22:28<14:03:29,  7.48s/it]                                                          {'loss': 0.9546, 'learning_rate': 1.5123604161477436e-05, 'epoch': 0.35}
 35%|███▍      | 3627/10395 [10:22:28<14:03:29,  7.48s/it] 35%|███▍      | 3628/10395 [10:22:37<14:33:08,  7.74s/it]                                                          {'loss': 0.9588, 'learning_rate': 1.5120928213973942e-05, 'epoch': 0.35}
 35%|███▍      | 3628/10395 [10:22:37<14:33:08,  7.74s/it] 35%|███▍      | 3629/10395 [10:22:44<14:28:26,  7.70s/it]                                                          {'loss': 0.9611, 'learning_rate': 1.511825176934168e-05, 'epoch': 0.35}
 35%|███▍      | 3629/10395 [10:22:44<14:28:26,  7.70s/it] 35%|███▍      | 3630/10395 [10:22:53<14:59:28,  7.98s/it]                                                          {'loss': 0.8507, 'learning_rate': 1.5115574827840475e-05, 'epoch': 0.35}
 35%|███▍      | 3630/10395 [10:22:53<14:59:28,  7.98s/it] 35%|███▍      | 3631/10395 [10:23:02<15:52:09,  8.45s/it]                                                          {'loss': 0.9278, 'learning_rate': 1.5112897389730197e-05, 'epoch': 0.35}
 35%|███▍      | 3631/10395 [10:23:02<15:52:09,  8.45s/it] 35%|███▍      | 3632/10395 [10:23:10<15:08:53,  8.06s/it]                                                          {'loss': 0.937, 'learning_rate': 1.511021945527077e-05, 'epoch': 0.35}
 35%|███▍      | 3632/10395 [10:23:10<15:08:53,  8.06s/it] 35%|███▍      | 3633/10395 [10:23:17<14:50:22,  7.90s/it]                                                          {'loss': 0.9508, 'learning_rate': 1.5107541024722152e-05, 'epoch': 0.35}
 35%|███▍      | 3633/10395 [10:23:17<14:50:22,  7.90s/it] 35%|███▍      | 3634/10395 [10:23:25<14:52:04,  7.92s/it]                                                          {'loss': 1.0379, 'learning_rate': 1.510486209834437e-05, 'epoch': 0.35}
 35%|███▍      | 3634/10395 [10:23:25<14:52:04,  7.92s/it] 35%|███▍      | 3635/10395 [10:23:32<14:34:19,  7.76s/it]                                                          {'loss': 0.9506, 'learning_rate': 1.5102182676397484e-05, 'epoch': 0.35}
 35%|███▍      | 3635/10395 [10:23:32<14:34:19,  7.76s/it] 35%|███▍      | 3636/10395 [10:23:48<19:13:52, 10.24s/it]                                                          {'loss': 0.4156, 'learning_rate': 1.5099502759141609e-05, 'epoch': 0.35}
 35%|███▍      | 3636/10395 [10:23:48<19:13:52, 10.24s/it] 35%|███▍      | 3637/10395 [10:23:57<18:07:09,  9.65s/it]                                                          {'loss': 0.8802, 'learning_rate': 1.5096822346836901e-05, 'epoch': 0.35}
 35%|███▍      | 3637/10395 [10:23:57<18:07:09,  9.65s/it] 35%|███▍      | 3638/10395 [10:24:04<16:45:51,  8.93s/it]                                                          {'loss': 0.9265, 'learning_rate': 1.5094141439743572e-05, 'epoch': 0.35}
 35%|███▍      | 3638/10395 [10:24:04<16:45:51,  8.93s/it] 35%|███▌      | 3639/10395 [10:24:12<15:58:50,  8.52s/it]                                                          {'loss': 0.9817, 'learning_rate': 1.5091460038121878e-05, 'epoch': 0.35}
 35%|███▌      | 3639/10395 [10:24:12<15:58:50,  8.52s/it] 35%|███▌      | 3640/10395 [10:24:19<15:33:01,  8.29s/it]                                                          {'loss': 0.9752, 'learning_rate': 1.508877814223213e-05, 'epoch': 0.35}
 35%|███▌      | 3640/10395 [10:24:19<15:33:01,  8.29s/it] 35%|███▌      | 3641/10395 [10:24:27<15:13:30,  8.12s/it]                                                          {'loss': 0.9796, 'learning_rate': 1.5086095752334666e-05, 'epoch': 0.35}
 35%|███▌      | 3641/10395 [10:24:27<15:13:30,  8.12s/it] 35%|███▌      | 3642/10395 [10:24:35<14:58:01,  7.98s/it]                                                          {'loss': 0.9206, 'learning_rate': 1.5083412868689899e-05, 'epoch': 0.35}
 35%|███▌      | 3642/10395 [10:24:35<14:58:01,  7.98s/it] 35%|███▌      | 3643/10395 [10:24:42<14:50:34,  7.91s/it]                                                          {'loss': 0.9551, 'learning_rate': 1.5080729491558277e-05, 'epoch': 0.35}
 35%|███▌      | 3643/10395 [10:24:42<14:50:34,  7.91s/it] 35%|███▌      | 3644/10395 [10:24:50<14:38:21,  7.81s/it]                                                          {'loss': 0.9037, 'learning_rate': 1.507804562120029e-05, 'epoch': 0.35}
 35%|███▌      | 3644/10395 [10:24:50<14:38:21,  7.81s/it] 35%|███▌      | 3645/10395 [10:24:58<14:40:03,  7.82s/it]                                                          {'loss': 0.9067, 'learning_rate': 1.5075361257876484e-05, 'epoch': 0.35}
 35%|███▌      | 3645/10395 [10:24:58<14:40:03,  7.82s/it] 35%|███▌      | 3646/10395 [10:25:06<14:39:34,  7.82s/it]                                                          {'loss': 0.9172, 'learning_rate': 1.5072676401847456e-05, 'epoch': 0.35}
 35%|███▌      | 3646/10395 [10:25:06<14:39:34,  7.82s/it] 35%|███▌      | 3647/10395 [10:25:13<14:20:18,  7.65s/it]                                                          {'loss': 0.935, 'learning_rate': 1.5069991053373847e-05, 'epoch': 0.35}
 35%|███▌      | 3647/10395 [10:25:13<14:20:18,  7.65s/it] 35%|███▌      | 3648/10395 [10:25:22<15:01:05,  8.01s/it]                                                          {'loss': 0.9193, 'learning_rate': 1.5067305212716332e-05, 'epoch': 0.35}
 35%|███▌      | 3648/10395 [10:25:22<15:01:05,  8.01s/it] 35%|███▌      | 3649/10395 [10:25:29<14:42:13,  7.85s/it]                                                          {'loss': 0.9822, 'learning_rate': 1.5064618880135661e-05, 'epoch': 0.35}
 35%|███▌      | 3649/10395 [10:25:29<14:42:13,  7.85s/it] 35%|███▌      | 3650/10395 [10:25:38<15:02:15,  8.03s/it]                                                          {'loss': 0.8887, 'learning_rate': 1.5061932055892614e-05, 'epoch': 0.35}
 35%|███▌      | 3650/10395 [10:25:38<15:02:15,  8.03s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 35%|███▌      | 3651/10395 [10:27:18<66:45:40, 35.64s/it]                                                          {'loss': 0.9707, 'learning_rate': 1.505924474024802e-05, 'epoch': 0.35}
 35%|███▌      | 3651/10395 [10:27:18<66:45:40, 35.64s/it] 35%|███▌      | 3652/10395 [10:27:27<51:38:07, 27.57s/it]                                                          {'loss': 0.9169, 'learning_rate': 1.5056556933462756e-05, 'epoch': 0.35}
 35%|███▌      | 3652/10395 [10:27:27<51:38:07, 27.57s/it] 35%|███▌      | 3653/10395 [10:27:34<40:34:29, 21.67s/it]                                                          {'loss': 0.9369, 'learning_rate': 1.505386863579775e-05, 'epoch': 0.35}
 35%|███▌      | 3653/10395 [10:27:34<40:34:29, 21.67s/it] 35%|███▌      | 3654/10395 [10:27:42<32:34:11, 17.39s/it]                                                          {'loss': 0.9463, 'learning_rate': 1.5051179847513979e-05, 'epoch': 0.35}
 35%|███▌      | 3654/10395 [10:27:42<32:34:11, 17.39s/it] 35%|███▌      | 3655/10395 [10:27:49<26:58:49, 14.41s/it]                                                          {'loss': 0.9962, 'learning_rate': 1.5048490568872465e-05, 'epoch': 0.35}
 35%|███▌      | 3655/10395 [10:27:49<26:58:49, 14.41s/it] 35%|███▌      | 3656/10395 [10:27:59<24:19:36, 13.00s/it]                                                          {'loss': 0.955, 'learning_rate': 1.5045800800134269e-05, 'epoch': 0.35}
 35%|███▌      | 3656/10395 [10:27:59<24:19:36, 13.00s/it] 35%|███▌      | 3657/10395 [10:28:09<22:39:45, 12.11s/it]                                                          {'loss': 0.8266, 'learning_rate': 1.5043110541560519e-05, 'epoch': 0.35}
 35%|███▌      | 3657/10395 [10:28:09<22:39:45, 12.11s/it] 35%|███▌      | 3658/10395 [10:28:17<20:11:09, 10.79s/it]                                                          {'loss': 0.9482, 'learning_rate': 1.5040419793412375e-05, 'epoch': 0.35}
 35%|███▌      | 3658/10395 [10:28:17<20:11:09, 10.79s/it] 35%|███▌      | 3659/10395 [10:28:25<18:59:23, 10.15s/it]                                                          {'loss': 0.8588, 'learning_rate': 1.5037728555951047e-05, 'epoch': 0.35}
 35%|███▌      | 3659/10395 [10:28:25<18:59:23, 10.15s/it] 35%|███▌      | 3660/10395 [10:28:33<17:47:13,  9.51s/it]                                                          {'loss': 0.8655, 'learning_rate': 1.5035036829437797e-05, 'epoch': 0.35}
 35%|███▌      | 3660/10395 [10:28:33<17:47:13,  9.51s/it] 35%|███▌      | 3661/10395 [10:28:41<16:39:41,  8.91s/it]                                                          {'loss': 0.8292, 'learning_rate': 1.503234461413393e-05, 'epoch': 0.35}
 35%|███▌      | 3661/10395 [10:28:41<16:39:41,  8.91s/it] 35%|███▌      | 3662/10395 [10:28:49<16:08:44,  8.63s/it]                                                          {'loss': 0.8634, 'learning_rate': 1.5029651910300806e-05, 'epoch': 0.35}
 35%|███▌      | 3662/10395 [10:28:49<16:08:44,  8.63s/it] 35%|███▌      | 3663/10395 [10:28:57<16:05:24,  8.60s/it]                                                          {'loss': 0.9816, 'learning_rate': 1.5026958718199823e-05, 'epoch': 0.35}
 35%|███▌      | 3663/10395 [10:28:57<16:05:24,  8.60s/it] 35%|███▌      | 3664/10395 [10:29:05<15:28:59,  8.28s/it]                                                          {'loss': 0.981, 'learning_rate': 1.5024265038092422e-05, 'epoch': 0.35}
 35%|███▌      | 3664/10395 [10:29:05<15:28:59,  8.28s/it] 35%|███▌      | 3665/10395 [10:29:22<20:23:38, 10.91s/it]                                                          {'loss': 0.3966, 'learning_rate': 1.5021570870240117e-05, 'epoch': 0.35}
 35%|███▌      | 3665/10395 [10:29:22<20:23:38, 10.91s/it] 35%|███▌      | 3666/10395 [10:29:31<19:07:42, 10.23s/it]                                                          {'loss': 0.9726, 'learning_rate': 1.5018876214904441e-05, 'epoch': 0.35}
 35%|███▌      | 3666/10395 [10:29:31<19:07:42, 10.23s/it] 35%|███▌      | 3667/10395 [10:29:48<22:53:40, 12.25s/it]                                                          {'loss': 0.3881, 'learning_rate': 1.5016181072346986e-05, 'epoch': 0.35}
 35%|███▌      | 3667/10395 [10:29:48<22:53:40, 12.25s/it] 35%|███▌      | 3668/10395 [10:29:56<20:36:28, 11.03s/it]                                                          {'loss': 0.9918, 'learning_rate': 1.5013485442829389e-05, 'epoch': 0.35}
 35%|███▌      | 3668/10395 [10:29:56<20:36:28, 11.03s/it] 35%|███▌      | 3669/10395 [10:30:14<24:31:08, 13.12s/it]                                                          {'loss': 0.4034, 'learning_rate': 1.5010789326613347e-05, 'epoch': 0.35}
 35%|███▌      | 3669/10395 [10:30:14<24:31:08, 13.12s/it] 35%|███▌      | 3670/10395 [10:30:21<21:23:40, 11.45s/it]                                                          {'loss': 0.8227, 'learning_rate': 1.5008092723960579e-05, 'epoch': 0.35}
 35%|███▌      | 3670/10395 [10:30:21<21:23:40, 11.45s/it] 35%|███▌      | 3671/10395 [10:30:29<19:18:11, 10.33s/it]                                                          {'loss': 0.9686, 'learning_rate': 1.5005395635132873e-05, 'epoch': 0.35}
 35%|███▌      | 3671/10395 [10:30:29<19:18:11, 10.33s/it] 35%|███▌      | 3672/10395 [10:30:37<17:41:31,  9.47s/it]                                                          {'loss': 0.9393, 'learning_rate': 1.5002698060392056e-05, 'epoch': 0.35}
 35%|███▌      | 3672/10395 [10:30:37<17:41:31,  9.47s/it] 35%|███▌      | 3673/10395 [10:30:45<17:21:28,  9.30s/it]                                                          {'loss': 0.9646, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.35}
 35%|███▌      | 3673/10395 [10:30:45<17:21:28,  9.30s/it] 35%|███▌      | 3674/10395 [10:30:54<16:59:44,  9.10s/it]                                                          {'loss': 0.8464, 'learning_rate': 1.4997301454218634e-05, 'epoch': 0.35}
 35%|███▌      | 3674/10395 [10:30:54<16:59:44,  9.10s/it] 35%|███▌      | 3675/10395 [10:31:01<16:02:45,  8.60s/it]                                                          {'loss': 1.0445, 'learning_rate': 1.4994602423309919e-05, 'epoch': 0.35}
 35%|███▌      | 3675/10395 [10:31:01<16:02:45,  8.60s/it] 35%|███▌      | 3676/10395 [10:31:10<16:11:21,  8.67s/it]                                                          {'loss': 0.9437, 'learning_rate': 1.4991902907535872e-05, 'epoch': 0.35}
 35%|███▌      | 3676/10395 [10:31:10<16:11:21,  8.67s/it] 35%|███▌      | 3677/10395 [10:31:18<15:21:37,  8.23s/it]                                                          {'loss': 1.0372, 'learning_rate': 1.4989202907158562e-05, 'epoch': 0.35}
 35%|███▌      | 3677/10395 [10:31:18<15:21:37,  8.23s/it] 35%|███▌      | 3678/10395 [10:31:26<15:36:53,  8.37s/it]                                                          {'loss': 0.8184, 'learning_rate': 1.4986502422440095e-05, 'epoch': 0.35}
 35%|███▌      | 3678/10395 [10:31:26<15:36:53,  8.37s/it] 35%|███▌      | 3679/10395 [10:31:34<15:03:41,  8.07s/it]                                                          {'loss': 0.936, 'learning_rate': 1.4983801453642628e-05, 'epoch': 0.35}
 35%|███▌      | 3679/10395 [10:31:34<15:03:41,  8.07s/it] 35%|███▌      | 3680/10395 [10:31:41<14:54:22,  7.99s/it]                                                          {'loss': 0.9872, 'learning_rate': 1.4981100001028365e-05, 'epoch': 0.35}
 35%|███▌      | 3680/10395 [10:31:41<14:54:22,  7.99s/it] 35%|███▌      | 3681/10395 [10:31:49<14:31:04,  7.78s/it]                                                          {'loss': 0.9216, 'learning_rate': 1.497839806485956e-05, 'epoch': 0.35}
 35%|███▌      | 3681/10395 [10:31:49<14:31:04,  7.78s/it] 35%|███▌      | 3682/10395 [10:31:57<14:49:26,  7.95s/it]                                                          {'loss': 0.8271, 'learning_rate': 1.4975695645398512e-05, 'epoch': 0.35}
 35%|███▌      | 3682/10395 [10:31:57<14:49:26,  7.95s/it] 35%|███▌      | 3683/10395 [10:32:04<14:30:56,  7.79s/it]                                                          {'loss': 0.9742, 'learning_rate': 1.497299274290756e-05, 'epoch': 0.35}
 35%|███▌      | 3683/10395 [10:32:04<14:30:56,  7.79s/it] 35%|███▌      | 3684/10395 [10:32:12<14:31:18,  7.79s/it]                                                          {'loss': 0.9453, 'learning_rate': 1.4970289357649104e-05, 'epoch': 0.35}
 35%|███▌      | 3684/10395 [10:32:12<14:31:18,  7.79s/it] 35%|███▌      | 3685/10395 [10:32:20<14:34:30,  7.82s/it]                                                          {'loss': 0.9138, 'learning_rate': 1.4967585489885574e-05, 'epoch': 0.35}
 35%|███▌      | 3685/10395 [10:32:20<14:34:30,  7.82s/it] 35%|███▌      | 3686/10395 [10:32:28<14:37:52,  7.85s/it]                                                          {'loss': 0.9521, 'learning_rate': 1.4964881139879464e-05, 'epoch': 0.35}
 35%|███▌      | 3686/10395 [10:32:28<14:37:52,  7.85s/it] 35%|███▌      | 3687/10395 [10:32:36<14:31:39,  7.80s/it]                                                          {'loss': 0.8149, 'learning_rate': 1.49621763078933e-05, 'epoch': 0.35}
 35%|███▌      | 3687/10395 [10:32:36<14:31:39,  7.80s/it] 35%|███▌      | 3688/10395 [10:32:44<14:31:11,  7.79s/it]                                                          {'loss': 1.0217, 'learning_rate': 1.4959470994189666e-05, 'epoch': 0.35}
 35%|███▌      | 3688/10395 [10:32:44<14:31:11,  7.79s/it] 35%|███▌      | 3689/10395 [10:32:52<14:51:13,  7.97s/it]                                                          {'loss': 1.0022, 'learning_rate': 1.4956765199031189e-05, 'epoch': 0.35}
 35%|███▌      | 3689/10395 [10:32:52<14:51:13,  7.97s/it] 35%|███▌      | 3690/10395 [10:33:00<14:39:57,  7.87s/it]                                                          {'loss': 0.9092, 'learning_rate': 1.4954058922680535e-05, 'epoch': 0.35}
 35%|███▌      | 3690/10395 [10:33:00<14:39:57,  7.87s/it] 36%|███▌      | 3691/10395 [10:33:08<14:47:22,  7.94s/it]                                                          {'loss': 0.9015, 'learning_rate': 1.4951352165400428e-05, 'epoch': 0.36}
 36%|███▌      | 3691/10395 [10:33:08<14:47:22,  7.94s/it] 36%|███▌      | 3692/10395 [10:33:15<14:24:52,  7.74s/it]                                                          {'loss': 1.02, 'learning_rate': 1.4948644927453635e-05, 'epoch': 0.36}
 36%|███▌      | 3692/10395 [10:33:15<14:24:52,  7.74s/it] 36%|███▌      | 3693/10395 [10:33:23<14:19:03,  7.69s/it]                                                          {'loss': 0.8586, 'learning_rate': 1.494593720910297e-05, 'epoch': 0.36}
 36%|███▌      | 3693/10395 [10:33:23<14:19:03,  7.69s/it] 36%|███▌      | 3694/10395 [10:33:30<14:14:33,  7.65s/it]                                                          {'loss': 0.9344, 'learning_rate': 1.4943229010611287e-05, 'epoch': 0.36}
 36%|███▌      | 3694/10395 [10:33:30<14:14:33,  7.65s/it] 36%|███▌      | 3695/10395 [10:33:37<14:01:57,  7.54s/it]                                                          {'loss': 0.9772, 'learning_rate': 1.4940520332241494e-05, 'epoch': 0.36}
 36%|███▌      | 3695/10395 [10:33:37<14:01:57,  7.54s/it] 36%|███▌      | 3696/10395 [10:33:45<14:07:57,  7.59s/it]                                                          {'loss': 1.0049, 'learning_rate': 1.4937811174256549e-05, 'epoch': 0.36}
 36%|███▌      | 3696/10395 [10:33:45<14:07:57,  7.59s/it] 36%|███▌      | 3697/10395 [10:33:52<13:57:58,  7.51s/it]                                                          {'loss': 0.9723, 'learning_rate': 1.4935101536919445e-05, 'epoch': 0.36}
 36%|███▌      | 3697/10395 [10:33:52<13:57:58,  7.51s/it] 36%|███▌      | 3698/10395 [10:34:00<14:18:35,  7.69s/it]                                                          {'loss': 0.9448, 'learning_rate': 1.493239142049323e-05, 'epoch': 0.36}
 36%|███▌      | 3698/10395 [10:34:00<14:18:35,  7.69s/it] 36%|███▌      | 3699/10395 [10:34:08<14:20:13,  7.71s/it]                                                          {'loss': 0.9529, 'learning_rate': 1.4929680825241e-05, 'epoch': 0.36}
 36%|███▌      | 3699/10395 [10:34:08<14:20:13,  7.71s/it] 36%|███▌      | 3700/10395 [10:34:18<15:27:24,  8.31s/it]                                                          {'loss': 0.9279, 'learning_rate': 1.4926969751425885e-05, 'epoch': 0.36}
 36%|███▌      | 3700/10395 [10:34:18<15:27:24,  8.31s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 36%|███▌      | 3701/10395 [10:35:59<67:27:20, 36.28s/it]                                                          {'loss': 0.9544, 'learning_rate': 1.492425819931108e-05, 'epoch': 0.36}
 36%|███▌      | 3701/10395 [10:35:59<67:27:20, 36.28s/it] 36%|███▌      | 3702/10395 [10:36:07<51:13:41, 27.55s/it]                                                          {'loss': 0.8342, 'learning_rate': 1.4921546169159808e-05, 'epoch': 0.36}
 36%|███▌      | 3702/10395 [10:36:07<51:13:41, 27.55s/it] 36%|███▌      | 3703/10395 [10:36:14<40:08:33, 21.59s/it]                                                          {'loss': 0.9663, 'learning_rate': 1.4918833661235354e-05, 'epoch': 0.36}
 36%|███▌      | 3703/10395 [10:36:14<40:08:33, 21.59s/it] 36%|███▌      | 3704/10395 [10:36:22<32:04:50, 17.26s/it]                                                          {'loss': 1.0083, 'learning_rate': 1.491612067580104e-05, 'epoch': 0.36}
 36%|███▌      | 3704/10395 [10:36:22<32:04:50, 17.26s/it] 36%|███▌      | 3705/10395 [10:36:39<32:21:23, 17.41s/it]                                                          {'loss': 0.422, 'learning_rate': 1.4913407213120235e-05, 'epoch': 0.36}
 36%|███▌      | 3705/10395 [10:36:39<32:21:23, 17.41s/it] 36%|███▌      | 3706/10395 [10:36:47<26:55:03, 14.49s/it]                                                          {'loss': 1.0682, 'learning_rate': 1.4910693273456358e-05, 'epoch': 0.36}
 36%|███▌      | 3706/10395 [10:36:47<26:55:03, 14.49s/it] 36%|███▌      | 3707/10395 [10:36:54<23:01:35, 12.39s/it]                                                          {'loss': 0.9135, 'learning_rate': 1.4907978857072873e-05, 'epoch': 0.36}
 36%|███▌      | 3707/10395 [10:36:54<23:01:35, 12.39s/it] 36%|███▌      | 3708/10395 [10:37:02<20:30:40, 11.04s/it]                                                          {'loss': 1.0576, 'learning_rate': 1.490526396423329e-05, 'epoch': 0.36}
 36%|███▌      | 3708/10395 [10:37:02<20:30:40, 11.04s/it] 36%|███▌      | 3709/10395 [10:37:10<18:27:39,  9.94s/it]                                                          {'loss': 0.9921, 'learning_rate': 1.4902548595201163e-05, 'epoch': 0.36}
 36%|███▌      | 3709/10395 [10:37:10<18:27:39,  9.94s/it] 36%|███▌      | 3710/10395 [10:37:18<17:37:00,  9.49s/it]                                                          {'loss': 0.8966, 'learning_rate': 1.4899832750240094e-05, 'epoch': 0.36}
 36%|███▌      | 3710/10395 [10:37:18<17:37:00,  9.49s/it] 36%|███▌      | 3711/10395 [10:37:27<17:13:47,  9.28s/it]                                                          {'loss': 1.0362, 'learning_rate': 1.4897116429613734e-05, 'epoch': 0.36}
 36%|███▌      | 3711/10395 [10:37:27<17:13:47,  9.28s/it] 36%|███▌      | 3712/10395 [10:37:34<16:15:16,  8.76s/it]                                                          {'loss': 0.9086, 'learning_rate': 1.4894399633585774e-05, 'epoch': 0.36}
 36%|███▌      | 3712/10395 [10:37:34<16:15:16,  8.76s/it] 36%|███▌      | 3713/10395 [10:37:42<15:27:05,  8.32s/it]                                                          {'loss': 0.9963, 'learning_rate': 1.489168236241996e-05, 'epoch': 0.36}
 36%|███▌      | 3713/10395 [10:37:42<15:27:05,  8.32s/it] 36%|███▌      | 3714/10395 [10:37:50<15:22:56,  8.29s/it]                                                          {'loss': 0.9675, 'learning_rate': 1.4888964616380073e-05, 'epoch': 0.36}
 36%|███▌      | 3714/10395 [10:37:50<15:22:56,  8.29s/it] 36%|███▌      | 3715/10395 [10:37:58<15:08:24,  8.16s/it]                                                          {'loss': 0.9529, 'learning_rate': 1.4886246395729952e-05, 'epoch': 0.36}
 36%|███▌      | 3715/10395 [10:37:58<15:08:24,  8.16s/it] 36%|███▌      | 3716/10395 [10:38:05<14:40:50,  7.91s/it]                                                          {'loss': 0.9374, 'learning_rate': 1.4883527700733469e-05, 'epoch': 0.36}
 36%|███▌      | 3716/10395 [10:38:05<14:40:50,  7.91s/it] 36%|███▌      | 3717/10395 [10:38:14<14:54:04,  8.03s/it]                                                          {'loss': 0.9497, 'learning_rate': 1.4880808531654554e-05, 'epoch': 0.36}
 36%|███▌      | 3717/10395 [10:38:14<14:54:04,  8.03s/it] 36%|███▌      | 3718/10395 [10:38:21<14:47:03,  7.97s/it]                                                          {'loss': 0.9699, 'learning_rate': 1.4878088888757178e-05, 'epoch': 0.36}
 36%|███▌      | 3718/10395 [10:38:21<14:47:03,  7.97s/it] 36%|███▌      | 3719/10395 [10:38:29<14:29:34,  7.82s/it]                                                          {'loss': 0.9415, 'learning_rate': 1.4875368772305358e-05, 'epoch': 0.36}
 36%|███▌      | 3719/10395 [10:38:29<14:29:34,  7.82s/it] 36%|███▌      | 3720/10395 [10:38:36<14:18:03,  7.71s/it]                                                          {'loss': 0.9131, 'learning_rate': 1.4872648182563154e-05, 'epoch': 0.36}
 36%|███▌      | 3720/10395 [10:38:36<14:18:03,  7.71s/it] 36%|███▌      | 3721/10395 [10:38:44<14:17:22,  7.71s/it]                                                          {'loss': 0.968, 'learning_rate': 1.486992711979468e-05, 'epoch': 0.36}
 36%|███▌      | 3721/10395 [10:38:44<14:17:22,  7.71s/it] 36%|███▌      | 3722/10395 [10:38:52<14:15:00,  7.69s/it]                                                          {'loss': 0.9076, 'learning_rate': 1.4867205584264087e-05, 'epoch': 0.36}
 36%|███▌      | 3722/10395 [10:38:52<14:15:00,  7.69s/it] 36%|███▌      | 3723/10395 [10:39:00<14:24:08,  7.77s/it]                                                          {'loss': 0.9679, 'learning_rate': 1.4864483576235577e-05, 'epoch': 0.36}
 36%|███▌      | 3723/10395 [10:39:00<14:24:08,  7.77s/it] 36%|███▌      | 3724/10395 [10:39:08<14:42:14,  7.94s/it]                                                          {'loss': 0.9806, 'learning_rate': 1.4861761095973399e-05, 'epoch': 0.36}
 36%|███▌      | 3724/10395 [10:39:08<14:42:14,  7.94s/it] 36%|███▌      | 3725/10395 [10:39:15<14:22:36,  7.76s/it]                                                          {'loss': 1.013, 'learning_rate': 1.485903814374184e-05, 'epoch': 0.36}
 36%|███▌      | 3725/10395 [10:39:15<14:22:36,  7.76s/it] 36%|███▌      | 3726/10395 [10:39:23<14:09:48,  7.65s/it]                                                          {'loss': 0.9279, 'learning_rate': 1.4856314719805243e-05, 'epoch': 0.36}
 36%|███▌      | 3726/10395 [10:39:23<14:09:48,  7.65s/it] 36%|███▌      | 3727/10395 [10:39:30<13:56:41,  7.53s/it]                                                          {'loss': 0.8355, 'learning_rate': 1.485359082442799e-05, 'epoch': 0.36}
 36%|███▌      | 3727/10395 [10:39:30<13:56:41,  7.53s/it] 36%|███▌      | 3728/10395 [10:39:38<14:29:28,  7.82s/it]                                                          {'loss': 0.9281, 'learning_rate': 1.4850866457874516e-05, 'epoch': 0.36}
 36%|███▌      | 3728/10395 [10:39:38<14:29:28,  7.82s/it] 36%|███▌      | 3729/10395 [10:39:46<14:28:50,  7.82s/it]                                                          {'loss': 0.8515, 'learning_rate': 1.4848141620409289e-05, 'epoch': 0.36}
 36%|███▌      | 3729/10395 [10:39:46<14:28:50,  7.82s/it] 36%|███▌      | 3730/10395 [10:39:54<14:34:08,  7.87s/it]                                                          {'loss': 0.9816, 'learning_rate': 1.4845416312296833e-05, 'epoch': 0.36}
 36%|███▌      | 3730/10395 [10:39:54<14:34:08,  7.87s/it] 36%|███▌      | 3731/10395 [10:40:02<14:35:18,  7.88s/it]                                                          {'loss': 0.9227, 'learning_rate': 1.4842690533801717e-05, 'epoch': 0.36}
 36%|███▌      | 3731/10395 [10:40:02<14:35:18,  7.88s/it] 36%|███▌      | 3732/10395 [10:40:10<14:43:10,  7.95s/it]                                                          {'loss': 0.9425, 'learning_rate': 1.4839964285188556e-05, 'epoch': 0.36}
 36%|███▌      | 3732/10395 [10:40:10<14:43:10,  7.95s/it] 36%|███▌      | 3733/10395 [10:40:17<14:16:51,  7.72s/it]                                                          {'loss': 0.9096, 'learning_rate': 1.4837237566722e-05, 'epoch': 0.36}
 36%|███▌      | 3733/10395 [10:40:17<14:16:51,  7.72s/it] 36%|███▌      | 3734/10395 [10:40:25<14:07:42,  7.64s/it]                                                          {'loss': 1.0201, 'learning_rate': 1.4834510378666762e-05, 'epoch': 0.36}
 36%|███▌      | 3734/10395 [10:40:25<14:07:42,  7.64s/it] 36%|███▌      | 3735/10395 [10:40:33<14:20:34,  7.75s/it]                                                          {'loss': 0.9231, 'learning_rate': 1.483178272128759e-05, 'epoch': 0.36}
 36%|███▌      | 3735/10395 [10:40:33<14:20:34,  7.75s/it] 36%|███▌      | 3736/10395 [10:40:41<14:18:41,  7.74s/it]                                                          {'loss': 0.9526, 'learning_rate': 1.4829054594849273e-05, 'epoch': 0.36}
 36%|███▌      | 3736/10395 [10:40:41<14:18:41,  7.74s/it] 36%|███▌      | 3737/10395 [10:40:48<14:05:22,  7.62s/it]                                                          {'loss': 0.9453, 'learning_rate': 1.4826325999616655e-05, 'epoch': 0.36}
 36%|███▌      | 3737/10395 [10:40:48<14:05:22,  7.62s/it] 36%|███▌      | 3738/10395 [10:40:56<14:05:42,  7.62s/it]                                                          {'loss': 0.8985, 'learning_rate': 1.4823596935854625e-05, 'epoch': 0.36}
 36%|███▌      | 3738/10395 [10:40:56<14:05:42,  7.62s/it] 36%|███▌      | 3739/10395 [10:41:03<14:15:55,  7.72s/it]                                                          {'loss': 0.9877, 'learning_rate': 1.4820867403828115e-05, 'epoch': 0.36}
 36%|███▌      | 3739/10395 [10:41:03<14:15:55,  7.72s/it] 36%|███▌      | 3740/10395 [10:41:11<14:12:05,  7.68s/it]                                                          {'loss': 0.9537, 'learning_rate': 1.4818137403802096e-05, 'epoch': 0.36}
 36%|███▌      | 3740/10395 [10:41:11<14:12:05,  7.68s/it] 36%|███▌      | 3741/10395 [10:41:19<14:09:56,  7.66s/it]                                                          {'loss': 0.9994, 'learning_rate': 1.4815406936041592e-05, 'epoch': 0.36}
 36%|███▌      | 3741/10395 [10:41:19<14:09:56,  7.66s/it] 36%|███▌      | 3742/10395 [10:41:34<18:35:15, 10.06s/it]                                                          {'loss': 0.3974, 'learning_rate': 1.4812676000811677e-05, 'epoch': 0.36}
 36%|███▌      | 3742/10395 [10:41:34<18:35:15, 10.06s/it] 36%|███▌      | 3743/10395 [10:41:42<17:29:14,  9.46s/it]                                                          {'loss': 0.9223, 'learning_rate': 1.4809944598377461e-05, 'epoch': 0.36}
 36%|███▌      | 3743/10395 [10:41:42<17:29:14,  9.46s/it] 36%|███▌      | 3744/10395 [10:41:50<16:30:10,  8.93s/it]                                                          {'loss': 0.987, 'learning_rate': 1.48072127290041e-05, 'epoch': 0.36}
 36%|███▌      | 3744/10395 [10:41:50<16:30:10,  8.93s/it] 36%|███▌      | 3745/10395 [10:41:58<16:02:10,  8.68s/it]                                                          {'loss': 0.9823, 'learning_rate': 1.48044803929568e-05, 'epoch': 0.36}
 36%|███▌      | 3745/10395 [10:41:58<16:02:10,  8.68s/it] 36%|███▌      | 3746/10395 [10:42:06<15:33:07,  8.42s/it]                                                          {'loss': 0.9548, 'learning_rate': 1.4801747590500814e-05, 'epoch': 0.36}
 36%|███▌      | 3746/10395 [10:42:06<15:33:07,  8.42s/it] 36%|███▌      | 3747/10395 [10:42:13<14:57:01,  8.10s/it]                                                          {'loss': 0.9799, 'learning_rate': 1.4799014321901431e-05, 'epoch': 0.36}
 36%|███▌      | 3747/10395 [10:42:13<14:57:01,  8.10s/it] 36%|███▌      | 3748/10395 [10:42:21<14:57:27,  8.10s/it]                                                          {'loss': 0.9498, 'learning_rate': 1.4796280587423991e-05, 'epoch': 0.36}
 36%|███▌      | 3748/10395 [10:42:21<14:57:27,  8.10s/it] 36%|███▌      | 3749/10395 [10:42:28<14:21:45,  7.78s/it]                                                          {'loss': 0.9517, 'learning_rate': 1.4793546387333883e-05, 'epoch': 0.36}
 36%|███▌      | 3749/10395 [10:42:28<14:21:45,  7.78s/it] 36%|███▌      | 3750/10395 [10:42:36<14:12:13,  7.69s/it]                                                          {'loss': 0.916, 'learning_rate': 1.4790811721896539e-05, 'epoch': 0.36}
 36%|███▌      | 3750/10395 [10:42:36<14:12:13,  7.69s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 36%|███▌      | 3751/10395 [10:44:17<65:58:59, 35.75s/it]                                                          {'loss': 0.9996, 'learning_rate': 1.4788076591377427e-05, 'epoch': 0.36}
 36%|███▌      | 3751/10395 [10:44:17<65:58:59, 35.75s/it] 36%|███▌      | 3752/10395 [10:44:25<50:31:08, 27.38s/it]                                                          {'loss': 0.8907, 'learning_rate': 1.4785340996042072e-05, 'epoch': 0.36}
 36%|███▌      | 3752/10395 [10:44:25<50:31:08, 27.38s/it] 36%|███▌      | 3753/10395 [10:44:33<39:53:17, 21.62s/it]                                                          {'loss': 0.8752, 'learning_rate': 1.478260493615604e-05, 'epoch': 0.36}
 36%|███▌      | 3753/10395 [10:44:33<39:53:17, 21.62s/it] 36%|███▌      | 3754/10395 [10:44:41<32:21:09, 17.54s/it]                                                          {'loss': 0.8439, 'learning_rate': 1.4779868411984943e-05, 'epoch': 0.36}
 36%|███▌      | 3754/10395 [10:44:41<32:21:09, 17.54s/it] 36%|███▌      | 3755/10395 [10:44:49<26:49:47, 14.55s/it]                                                          {'loss': 0.9996, 'learning_rate': 1.4777131423794435e-05, 'epoch': 0.36}
 36%|███▌      | 3755/10395 [10:44:49<26:49:47, 14.55s/it] 36%|███▌      | 3756/10395 [10:44:56<22:49:16, 12.37s/it]                                                          {'loss': 0.9949, 'learning_rate': 1.4774393971850214e-05, 'epoch': 0.36}
 36%|███▌      | 3756/10395 [10:44:56<22:49:16, 12.37s/it] 36%|███▌      | 3757/10395 [10:45:05<20:41:29, 11.22s/it]                                                          {'loss': 0.9776, 'learning_rate': 1.4771656056418031e-05, 'epoch': 0.36}
 36%|███▌      | 3757/10395 [10:45:05<20:41:29, 11.22s/it] 36%|███▌      | 3758/10395 [10:45:12<18:28:23, 10.02s/it]                                                          {'loss': 0.9712, 'learning_rate': 1.4768917677763677e-05, 'epoch': 0.36}
 36%|███▌      | 3758/10395 [10:45:12<18:28:23, 10.02s/it] 36%|███▌      | 3759/10395 [10:45:19<16:58:51,  9.21s/it]                                                          {'loss': 0.9773, 'learning_rate': 1.4766178836152983e-05, 'epoch': 0.36}
 36%|███▌      | 3759/10395 [10:45:19<16:58:51,  9.21s/it] 36%|███▌      | 3760/10395 [10:45:27<16:20:27,  8.87s/it]                                                          {'loss': 1.03, 'learning_rate': 1.4763439531851833e-05, 'epoch': 0.36}
 36%|███▌      | 3760/10395 [10:45:27<16:20:27,  8.87s/it] 36%|███▌      | 3761/10395 [10:45:35<15:46:44,  8.56s/it]                                                          {'loss': 0.9046, 'learning_rate': 1.4760699765126157e-05, 'epoch': 0.36}
 36%|███▌      | 3761/10395 [10:45:35<15:46:44,  8.56s/it] 36%|███▌      | 3762/10395 [10:45:43<15:34:58,  8.46s/it]                                                          {'loss': 0.9835, 'learning_rate': 1.4757959536241917e-05, 'epoch': 0.36}
 36%|███▌      | 3762/10395 [10:45:43<15:34:58,  8.46s/it] 36%|███▌      | 3763/10395 [10:45:51<15:12:08,  8.25s/it]                                                          {'loss': 0.9689, 'learning_rate': 1.4755218845465133e-05, 'epoch': 0.36}
 36%|███▌      | 3763/10395 [10:45:51<15:12:08,  8.25s/it] 36%|███▌      | 3764/10395 [10:45:59<14:54:51,  8.10s/it]                                                          {'loss': 0.9855, 'learning_rate': 1.4752477693061865e-05, 'epoch': 0.36}
 36%|███▌      | 3764/10395 [10:45:59<14:54:51,  8.10s/it] 36%|███▌      | 3765/10395 [10:46:06<14:39:38,  7.96s/it]                                                          {'loss': 0.9197, 'learning_rate': 1.4749736079298222e-05, 'epoch': 0.36}
 36%|███▌      | 3765/10395 [10:46:06<14:39:38,  7.96s/it] 36%|███▌      | 3766/10395 [10:46:25<20:15:45, 11.00s/it]                                                          {'loss': 0.4153, 'learning_rate': 1.474699400444035e-05, 'epoch': 0.36}
 36%|███▌      | 3766/10395 [10:46:25<20:15:45, 11.00s/it] 36%|███▌      | 3767/10395 [10:46:32<18:21:50,  9.97s/it]                                                          {'loss': 0.9298, 'learning_rate': 1.4744251468754443e-05, 'epoch': 0.36}
 36%|███▌      | 3767/10395 [10:46:32<18:21:50,  9.97s/it] 36%|███▌      | 3768/10395 [10:46:41<17:31:06,  9.52s/it]                                                          {'loss': 0.8958, 'learning_rate': 1.4741508472506743e-05, 'epoch': 0.36}
 36%|███▌      | 3768/10395 [10:46:41<17:31:06,  9.52s/it] 36%|███▋      | 3769/10395 [10:46:48<16:34:28,  9.01s/it]                                                          {'loss': 0.9515, 'learning_rate': 1.4738765015963531e-05, 'epoch': 0.36}
 36%|███▋      | 3769/10395 [10:46:48<16:34:28,  9.01s/it] 36%|███▋      | 3770/10395 [10:46:56<15:52:55,  8.63s/it]                                                          {'loss': 0.9442, 'learning_rate': 1.473602109939114e-05, 'epoch': 0.36}
 36%|███▋      | 3770/10395 [10:46:56<15:52:55,  8.63s/it] 36%|███▋      | 3771/10395 [10:47:07<16:52:03,  9.17s/it]                                                          {'loss': 0.8232, 'learning_rate': 1.4733276723055941e-05, 'epoch': 0.36}
 36%|███▋      | 3771/10395 [10:47:07<16:52:03,  9.17s/it] 36%|███▋      | 3772/10395 [10:47:15<16:29:26,  8.96s/it]                                                          {'loss': 0.9835, 'learning_rate': 1.4730531887224353e-05, 'epoch': 0.36}
 36%|███▋      | 3772/10395 [10:47:15<16:29:26,  8.96s/it] 36%|███▋      | 3773/10395 [10:47:23<15:55:03,  8.65s/it]                                                          {'loss': 0.8889, 'learning_rate': 1.4727786592162839e-05, 'epoch': 0.36}
 36%|███▋      | 3773/10395 [10:47:23<15:55:03,  8.65s/it] 36%|███▋      | 3774/10395 [10:47:30<15:16:44,  8.31s/it]                                                          {'loss': 0.96, 'learning_rate': 1.4725040838137905e-05, 'epoch': 0.36}
 36%|███▋      | 3774/10395 [10:47:30<15:16:44,  8.31s/it] 36%|███▋      | 3775/10395 [10:47:38<14:56:23,  8.12s/it]                                                          {'loss': 0.9353, 'learning_rate': 1.4722294625416104e-05, 'epoch': 0.36}
 36%|███▋      | 3775/10395 [10:47:38<14:56:23,  8.12s/it] 36%|███▋      | 3776/10395 [10:47:46<14:32:11,  7.91s/it]                                                          {'loss': 0.9146, 'learning_rate': 1.4719547954264032e-05, 'epoch': 0.36}
 36%|███▋      | 3776/10395 [10:47:46<14:32:11,  7.91s/it] 36%|███▋      | 3777/10395 [10:47:55<15:16:51,  8.31s/it]                                                          {'loss': 0.8934, 'learning_rate': 1.4716800824948331e-05, 'epoch': 0.36}
 36%|███▋      | 3777/10395 [10:47:55<15:16:51,  8.31s/it] 36%|███▋      | 3778/10395 [10:48:02<14:43:34,  8.01s/it]                                                          {'loss': 0.9459, 'learning_rate': 1.4714053237735685e-05, 'epoch': 0.36}
 36%|███▋      | 3778/10395 [10:48:02<14:43:34,  8.01s/it] 36%|███▋      | 3779/10395 [10:48:11<15:10:04,  8.25s/it]                                                          {'loss': 0.9404, 'learning_rate': 1.4711305192892826e-05, 'epoch': 0.36}
 36%|███▋      | 3779/10395 [10:48:11<15:10:04,  8.25s/it] 36%|███▋      | 3780/10395 [10:48:20<15:27:50,  8.42s/it]                                                          {'loss': 0.8869, 'learning_rate': 1.4708556690686526e-05, 'epoch': 0.36}
 36%|███▋      | 3780/10395 [10:48:20<15:27:50,  8.42s/it] 36%|███▋      | 3781/10395 [10:48:27<15:03:41,  8.20s/it]                                                          {'loss': 0.8898, 'learning_rate': 1.4705807731383605e-05, 'epoch': 0.36}
 36%|███▋      | 3781/10395 [10:48:27<15:03:41,  8.20s/it] 36%|███▋      | 3782/10395 [10:48:35<14:47:45,  8.05s/it]                                                          {'loss': 0.9172, 'learning_rate': 1.4703058315250926e-05, 'epoch': 0.36}
 36%|███▋      | 3782/10395 [10:48:35<14:47:45,  8.05s/it] 36%|███▋      | 3783/10395 [10:48:43<14:30:16,  7.90s/it]                                                          {'loss': 0.9105, 'learning_rate': 1.4700308442555395e-05, 'epoch': 0.36}
 36%|███▋      | 3783/10395 [10:48:43<14:30:16,  7.90s/it] 36%|███▋      | 3784/10395 [10:48:51<14:32:12,  7.92s/it]                                                          {'loss': 0.997, 'learning_rate': 1.4697558113563965e-05, 'epoch': 0.36}
 36%|███▋      | 3784/10395 [10:48:51<14:32:12,  7.92s/it] 36%|███▋      | 3785/10395 [10:48:58<14:18:31,  7.79s/it]                                                          {'loss': 1.0101, 'learning_rate': 1.4694807328543634e-05, 'epoch': 0.36}
 36%|███▋      | 3785/10395 [10:48:58<14:18:31,  7.79s/it] 36%|███▋      | 3786/10395 [10:49:07<14:42:42,  8.01s/it]                                                          {'loss': 0.9047, 'learning_rate': 1.4692056087761439e-05, 'epoch': 0.36}
 36%|███▋      | 3786/10395 [10:49:07<14:42:42,  8.01s/it] 36%|███▋      | 3787/10395 [10:49:15<14:40:05,  7.99s/it]                                                          {'loss': 0.9751, 'learning_rate': 1.4689304391484467e-05, 'epoch': 0.36}
 36%|███▋      | 3787/10395 [10:49:15<14:40:05,  7.99s/it] 36%|███▋      | 3788/10395 [10:49:23<14:59:36,  8.17s/it]                                                          {'loss': 0.8821, 'learning_rate': 1.4686552239979846e-05, 'epoch': 0.36}
 36%|███▋      | 3788/10395 [10:49:23<14:59:36,  8.17s/it] 36%|███▋      | 3789/10395 [10:49:31<14:33:08,  7.93s/it]                                                          {'loss': 0.9316, 'learning_rate': 1.4683799633514748e-05, 'epoch': 0.36}
 36%|███▋      | 3789/10395 [10:49:31<14:33:08,  7.93s/it] 36%|███▋      | 3790/10395 [10:49:38<14:21:24,  7.83s/it]                                                          {'loss': 0.9715, 'learning_rate': 1.468104657235639e-05, 'epoch': 0.36}
 36%|███▋      | 3790/10395 [10:49:38<14:21:24,  7.83s/it] 36%|███▋      | 3791/10395 [10:49:46<14:16:56,  7.79s/it]                                                          {'loss': 0.9493, 'learning_rate': 1.4678293056772035e-05, 'epoch': 0.36}
 36%|███▋      | 3791/10395 [10:49:46<14:16:56,  7.79s/it] 36%|███▋      | 3792/10395 [10:49:53<13:56:08,  7.60s/it]                                                          {'loss': 1.0553, 'learning_rate': 1.4675539087028987e-05, 'epoch': 0.36}
 36%|███▋      | 3792/10395 [10:49:53<13:56:08,  7.60s/it] 36%|███▋      | 3793/10395 [10:50:01<14:15:55,  7.78s/it]                                                          {'loss': 0.915, 'learning_rate': 1.4672784663394597e-05, 'epoch': 0.36}
 36%|███▋      | 3793/10395 [10:50:01<14:15:55,  7.78s/it] 36%|███▋      | 3794/10395 [10:50:09<14:00:17,  7.64s/it]                                                          {'loss': 0.924, 'learning_rate': 1.4670029786136257e-05, 'epoch': 0.36}
 36%|███▋      | 3794/10395 [10:50:09<14:00:17,  7.64s/it] 37%|███▋      | 3795/10395 [10:50:16<14:08:58,  7.72s/it]                                                          {'loss': 0.9239, 'learning_rate': 1.4667274455521405e-05, 'epoch': 0.37}
 37%|███▋      | 3795/10395 [10:50:16<14:08:58,  7.72s/it] 37%|███▋      | 3796/10395 [10:50:24<14:09:06,  7.72s/it]                                                          {'loss': 0.9064, 'learning_rate': 1.4664518671817525e-05, 'epoch': 0.37}
 37%|███▋      | 3796/10395 [10:50:24<14:09:06,  7.72s/it] 37%|███▋      | 3797/10395 [10:50:32<14:03:57,  7.67s/it]                                                          {'loss': 0.9154, 'learning_rate': 1.4661762435292138e-05, 'epoch': 0.37}
 37%|███▋      | 3797/10395 [10:50:32<14:03:57,  7.67s/it] 37%|███▋      | 3798/10395 [10:50:39<13:55:51,  7.60s/it]                                                          {'loss': 1.0084, 'learning_rate': 1.4659005746212816e-05, 'epoch': 0.37}
 37%|███▋      | 3798/10395 [10:50:39<13:55:51,  7.60s/it] 37%|███▋      | 3799/10395 [10:50:47<13:58:27,  7.63s/it]                                                          {'loss': 1.015, 'learning_rate': 1.4656248604847174e-05, 'epoch': 0.37}
 37%|███▋      | 3799/10395 [10:50:47<13:58:27,  7.63s/it] 37%|███▋      | 3800/10395 [10:50:54<13:52:30,  7.57s/it]                                                          {'loss': 0.912, 'learning_rate': 1.4653491011462866e-05, 'epoch': 0.37}
 37%|███▋      | 3800/10395 [10:50:54<13:52:30,  7.57s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 37%|███▋      | 3801/10395 [10:52:35<64:49:28, 35.39s/it]                                                          {'loss': 1.0343, 'learning_rate': 1.4650732966327598e-05, 'epoch': 0.37}
 37%|███▋      | 3801/10395 [10:52:35<64:49:28, 35.39s/it] 37%|███▋      | 3802/10395 [10:52:42<49:35:45, 27.08s/it]                                                          {'loss': 0.9293, 'learning_rate': 1.464797446970911e-05, 'epoch': 0.37}
 37%|███▋      | 3802/10395 [10:52:42<49:35:45, 27.08s/it] 37%|███▋      | 3803/10395 [10:52:51<39:18:09, 21.46s/it]                                                          {'loss': 0.9013, 'learning_rate': 1.4645215521875194e-05, 'epoch': 0.37}
 37%|███▋      | 3803/10395 [10:52:51<39:18:09, 21.46s/it] 37%|███▋      | 3804/10395 [10:52:58<31:47:21, 17.36s/it]                                                          {'loss': 1.0109, 'learning_rate': 1.464245612309368e-05, 'epoch': 0.37}
 37%|███▋      | 3804/10395 [10:52:58<31:47:21, 17.36s/it] 37%|███▋      | 3805/10395 [10:53:07<26:54:20, 14.70s/it]                                                          {'loss': 0.7966, 'learning_rate': 1.463969627363245e-05, 'epoch': 0.37}
 37%|███▋      | 3805/10395 [10:53:07<26:54:20, 14.70s/it] 37%|███▋      | 3806/10395 [10:53:24<28:16:04, 15.44s/it]                                                          {'loss': 0.3983, 'learning_rate': 1.4636935973759418e-05, 'epoch': 0.37}
 37%|███▋      | 3806/10395 [10:53:24<28:16:04, 15.44s/it] 37%|███▋      | 3807/10395 [10:53:41<28:49:07, 15.75s/it]                                                          {'loss': 0.4203, 'learning_rate': 1.4634175223742553e-05, 'epoch': 0.37}
 37%|███▋      | 3807/10395 [10:53:41<28:49:07, 15.75s/it] 37%|███▋      | 3808/10395 [10:53:50<25:13:31, 13.79s/it]                                                          {'loss': 0.9477, 'learning_rate': 1.463141402384986e-05, 'epoch': 0.37}
 37%|███▋      | 3808/10395 [10:53:50<25:13:31, 13.79s/it] 37%|███▋      | 3809/10395 [10:53:57<21:47:12, 11.91s/it]                                                          {'loss': 0.9269, 'learning_rate': 1.462865237434939e-05, 'epoch': 0.37}
 37%|███▋      | 3809/10395 [10:53:57<21:47:12, 11.91s/it] 37%|███▋      | 3810/10395 [10:54:05<19:25:09, 10.62s/it]                                                          {'loss': 0.9455, 'learning_rate': 1.4625890275509237e-05, 'epoch': 0.37}
 37%|███▋      | 3810/10395 [10:54:05<19:25:09, 10.62s/it] 37%|███▋      | 3811/10395 [10:54:13<17:48:46,  9.74s/it]                                                          {'loss': 0.937, 'learning_rate': 1.4623127727597545e-05, 'epoch': 0.37}
 37%|███▋      | 3811/10395 [10:54:13<17:48:46,  9.74s/it] 37%|███▋      | 3812/10395 [10:54:20<16:39:45,  9.11s/it]                                                          {'loss': 0.9337, 'learning_rate': 1.4620364730882492e-05, 'epoch': 0.37}
 37%|███▋      | 3812/10395 [10:54:20<16:39:45,  9.11s/it] 37%|███▋      | 3813/10395 [10:54:29<16:28:14,  9.01s/it]                                                          {'loss': 0.879, 'learning_rate': 1.4617601285632308e-05, 'epoch': 0.37}
 37%|███▋      | 3813/10395 [10:54:29<16:28:14,  9.01s/it] 37%|███▋      | 3814/10395 [10:54:37<15:41:42,  8.59s/it]                                                          {'loss': 0.951, 'learning_rate': 1.4614837392115254e-05, 'epoch': 0.37}
 37%|███▋      | 3814/10395 [10:54:37<15:41:42,  8.59s/it] 37%|███▋      | 3815/10395 [10:54:54<20:18:36, 11.11s/it]                                                          {'loss': 0.3823, 'learning_rate': 1.4612073050599649e-05, 'epoch': 0.37}
 37%|███▋      | 3815/10395 [10:54:54<20:18:36, 11.11s/it] 37%|███▋      | 3816/10395 [10:55:01<18:23:42, 10.07s/it]                                                          {'loss': 0.9, 'learning_rate': 1.460930826135385e-05, 'epoch': 0.37}
 37%|███▋      | 3816/10395 [10:55:01<18:23:42, 10.07s/it] 37%|███▋      | 3817/10395 [10:55:09<17:16:26,  9.45s/it]                                                          {'loss': 0.9198, 'learning_rate': 1.460654302464625e-05, 'epoch': 0.37}
 37%|███▋      | 3817/10395 [10:55:09<17:16:26,  9.45s/it] 37%|███▋      | 3818/10395 [10:55:17<16:15:38,  8.90s/it]                                                          {'loss': 0.9248, 'learning_rate': 1.4603777340745305e-05, 'epoch': 0.37}
 37%|███▋      | 3818/10395 [10:55:17<16:15:38,  8.90s/it] 37%|███▋      | 3819/10395 [10:55:24<15:17:51,  8.37s/it]                                                          {'loss': 0.8918, 'learning_rate': 1.4601011209919489e-05, 'epoch': 0.37}
 37%|███▋      | 3819/10395 [10:55:24<15:17:51,  8.37s/it] 37%|███▋      | 3820/10395 [10:55:31<14:42:53,  8.06s/it]                                                          {'loss': 0.9579, 'learning_rate': 1.4598244632437339e-05, 'epoch': 0.37}
 37%|███▋      | 3820/10395 [10:55:31<14:42:53,  8.06s/it] 37%|███▋      | 3821/10395 [10:55:39<14:30:39,  7.95s/it]                                                          {'loss': 0.9498, 'learning_rate': 1.4595477608567426e-05, 'epoch': 0.37}
 37%|███▋      | 3821/10395 [10:55:39<14:30:39,  7.95s/it] 37%|███▋      | 3822/10395 [10:55:47<14:21:31,  7.86s/it]                                                          {'loss': 0.8979, 'learning_rate': 1.4592710138578365e-05, 'epoch': 0.37}
 37%|███▋      | 3822/10395 [10:55:47<14:21:31,  7.86s/it] 37%|███▋      | 3823/10395 [10:55:54<14:18:59,  7.84s/it]                                                          {'loss': 0.9901, 'learning_rate': 1.4589942222738822e-05, 'epoch': 0.37}
 37%|███▋      | 3823/10395 [10:55:54<14:18:59,  7.84s/it] 37%|███▋      | 3824/10395 [10:56:02<14:11:35,  7.78s/it]                                                          {'loss': 0.941, 'learning_rate': 1.4587173861317498e-05, 'epoch': 0.37}
 37%|███▋      | 3824/10395 [10:56:02<14:11:35,  7.78s/it] 37%|███▋      | 3825/10395 [10:56:09<13:50:19,  7.58s/it]                                                          {'loss': 0.9358, 'learning_rate': 1.4584405054583133e-05, 'epoch': 0.37}
 37%|███▋      | 3825/10395 [10:56:09<13:50:19,  7.58s/it] 37%|███▋      | 3826/10395 [10:56:17<14:07:34,  7.74s/it]                                                          {'loss': 0.8692, 'learning_rate': 1.4581635802804526e-05, 'epoch': 0.37}
 37%|███▋      | 3826/10395 [10:56:17<14:07:34,  7.74s/it] 37%|███▋      | 3827/10395 [10:56:27<15:17:46,  8.38s/it]                                                          {'loss': 0.9036, 'learning_rate': 1.4578866106250507e-05, 'epoch': 0.37}
 37%|███▋      | 3827/10395 [10:56:27<15:17:46,  8.38s/it] 37%|███▋      | 3828/10395 [10:56:36<15:19:35,  8.40s/it]                                                          {'loss': 0.9319, 'learning_rate': 1.457609596518995e-05, 'epoch': 0.37}
 37%|███▋      | 3828/10395 [10:56:36<15:19:35,  8.40s/it] 37%|███▋      | 3829/10395 [10:56:43<14:54:30,  8.17s/it]                                                          {'loss': 1.0259, 'learning_rate': 1.4573325379891775e-05, 'epoch': 0.37}
 37%|███▋      | 3829/10395 [10:56:43<14:54:30,  8.17s/it] 37%|███▋      | 3830/10395 [10:56:51<14:37:27,  8.02s/it]                                                          {'loss': 0.8954, 'learning_rate': 1.4570554350624943e-05, 'epoch': 0.37}
 37%|███▋      | 3830/10395 [10:56:51<14:37:27,  8.02s/it] 37%|███▋      | 3831/10395 [10:56:59<14:35:02,  8.00s/it]                                                          {'loss': 0.9245, 'learning_rate': 1.4567782877658467e-05, 'epoch': 0.37}
 37%|███▋      | 3831/10395 [10:56:59<14:35:02,  8.00s/it] 37%|███▋      | 3832/10395 [10:57:07<14:21:33,  7.88s/it]                                                          {'loss': 1.0008, 'learning_rate': 1.456501096126139e-05, 'epoch': 0.37}
 37%|███▋      | 3832/10395 [10:57:07<14:21:33,  7.88s/it] 37%|███▋      | 3833/10395 [10:57:25<19:53:14, 10.91s/it]                                                          {'loss': 0.4335, 'learning_rate': 1.45622386017028e-05, 'epoch': 0.37}
 37%|███▋      | 3833/10395 [10:57:25<19:53:14, 10.91s/it] 37%|███▋      | 3834/10395 [10:57:32<18:01:17,  9.89s/it]                                                          {'loss': 0.9381, 'learning_rate': 1.455946579925184e-05, 'epoch': 0.37}
 37%|███▋      | 3834/10395 [10:57:32<18:01:17,  9.89s/it] 37%|███▋      | 3835/10395 [10:57:41<17:30:34,  9.61s/it]                                                          {'loss': 0.8912, 'learning_rate': 1.4556692554177684e-05, 'epoch': 0.37}
 37%|███▋      | 3835/10395 [10:57:41<17:30:34,  9.61s/it] 37%|███▋      | 3836/10395 [10:57:49<16:38:37,  9.14s/it]                                                          {'loss': 0.9178, 'learning_rate': 1.4553918866749552e-05, 'epoch': 0.37}
 37%|███▋      | 3836/10395 [10:57:49<16:38:37,  9.14s/it] 37%|███▋      | 3837/10395 [10:57:59<17:00:18,  9.33s/it]                                                          {'loss': 0.8437, 'learning_rate': 1.4551144737236707e-05, 'epoch': 0.37}
 37%|███▋      | 3837/10395 [10:57:59<17:00:18,  9.33s/it] 37%|███▋      | 3838/10395 [10:58:06<16:05:13,  8.83s/it]                                                          {'loss': 0.9082, 'learning_rate': 1.454837016590846e-05, 'epoch': 0.37}
 37%|███▋      | 3838/10395 [10:58:06<16:05:13,  8.83s/it] 37%|███▋      | 3839/10395 [10:58:15<15:52:14,  8.71s/it]                                                          {'loss': 0.8443, 'learning_rate': 1.4545595153034154e-05, 'epoch': 0.37}
 37%|███▋      | 3839/10395 [10:58:15<15:52:14,  8.71s/it] 37%|███▋      | 3840/10395 [10:58:22<15:13:11,  8.36s/it]                                                          {'loss': 0.9228, 'learning_rate': 1.4542819698883184e-05, 'epoch': 0.37}
 37%|███▋      | 3840/10395 [10:58:22<15:13:11,  8.36s/it] 37%|███▋      | 3841/10395 [10:58:30<14:42:34,  8.08s/it]                                                          {'loss': 1.065, 'learning_rate': 1.4540043803724983e-05, 'epoch': 0.37}
 37%|███▋      | 3841/10395 [10:58:30<14:42:34,  8.08s/it] 37%|███▋      | 3842/10395 [10:58:38<14:36:11,  8.02s/it]                                                          {'loss': 0.9656, 'learning_rate': 1.453726746782904e-05, 'epoch': 0.37}
 37%|███▋      | 3842/10395 [10:58:38<14:36:11,  8.02s/it] 37%|███▋      | 3843/10395 [10:58:45<14:07:51,  7.76s/it]                                                          {'loss': 0.8909, 'learning_rate': 1.4534490691464862e-05, 'epoch': 0.37}
 37%|███▋      | 3843/10395 [10:58:45<14:07:51,  7.76s/it] 37%|███▋      | 3844/10395 [10:58:52<13:57:04,  7.67s/it]                                                          {'loss': 0.9854, 'learning_rate': 1.4531713474902018e-05, 'epoch': 0.37}
 37%|███▋      | 3844/10395 [10:58:52<13:57:04,  7.67s/it] 37%|███▋      | 3845/10395 [10:59:01<14:22:17,  7.90s/it]                                                          {'loss': 0.8908, 'learning_rate': 1.4528935818410113e-05, 'epoch': 0.37}
 37%|███▋      | 3845/10395 [10:59:01<14:22:17,  7.90s/it] 37%|███▋      | 3846/10395 [10:59:09<14:36:39,  8.03s/it]                                                          {'loss': 0.8552, 'learning_rate': 1.45261577222588e-05, 'epoch': 0.37}
 37%|███▋      | 3846/10395 [10:59:09<14:36:39,  8.03s/it] 37%|███▋      | 3847/10395 [10:59:17<14:16:17,  7.85s/it]                                                          {'loss': 0.9683, 'learning_rate': 1.4523379186717767e-05, 'epoch': 0.37}
 37%|███▋      | 3847/10395 [10:59:17<14:16:17,  7.85s/it] 37%|███▋      | 3848/10395 [10:59:24<14:12:47,  7.82s/it]                                                          {'loss': 0.9277, 'learning_rate': 1.452060021205675e-05, 'epoch': 0.37}
 37%|███▋      | 3848/10395 [10:59:24<14:12:47,  7.82s/it] 37%|███▋      | 3849/10395 [10:59:34<15:04:50,  8.29s/it]                                                          {'loss': 0.9959, 'learning_rate': 1.4517820798545524e-05, 'epoch': 0.37}
 37%|███▋      | 3849/10395 [10:59:34<15:04:50,  8.29s/it] 37%|███▋      | 3850/10395 [10:59:52<20:17:25, 11.16s/it]                                                          {'loss': 0.3701, 'learning_rate': 1.4515040946453907e-05, 'epoch': 0.37}
 37%|███▋      | 3850/10395 [10:59:52<20:17:25, 11.16s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 37%|███▋      | 3851/10395 [11:01:32<69:10:26, 38.05s/it]                                                          {'loss': 0.9238, 'learning_rate': 1.4512260656051767e-05, 'epoch': 0.37}
 37%|███▋      | 3851/10395 [11:01:32<69:10:26, 38.05s/it] 37%|███▋      | 3852/10395 [11:01:40<52:28:58, 28.88s/it]                                                          {'loss': 0.9372, 'learning_rate': 1.4509479927609001e-05, 'epoch': 0.37}
 37%|███▋      | 3852/10395 [11:01:40<52:28:58, 28.88s/it] 37%|███▋      | 3853/10395 [11:01:48<41:19:28, 22.74s/it]                                                          {'loss': 0.9522, 'learning_rate': 1.4506698761395566e-05, 'epoch': 0.37}
 37%|███▋      | 3853/10395 [11:01:48<41:19:28, 22.74s/it] 37%|███▋      | 3854/10395 [11:01:56<33:03:09, 18.19s/it]                                                          {'loss': 0.9822, 'learning_rate': 1.4503917157681444e-05, 'epoch': 0.37}
 37%|███▋      | 3854/10395 [11:01:56<33:03:09, 18.19s/it] 37%|███▋      | 3855/10395 [11:02:03<27:06:10, 14.92s/it]                                                          {'loss': 0.8694, 'learning_rate': 1.450113511673667e-05, 'epoch': 0.37}
 37%|███▋      | 3855/10395 [11:02:03<27:06:10, 14.92s/it] 37%|███▋      | 3856/10395 [11:02:11<23:08:45, 12.74s/it]                                                          {'loss': 0.9065, 'learning_rate': 1.4498352638831312e-05, 'epoch': 0.37}
 37%|███▋      | 3856/10395 [11:02:11<23:08:45, 12.74s/it] 37%|███▋      | 3857/10395 [11:02:18<20:09:07, 11.10s/it]                                                          {'loss': 0.9784, 'learning_rate': 1.44955697242355e-05, 'epoch': 0.37}
 37%|███▋      | 3857/10395 [11:02:18<20:09:07, 11.10s/it] 37%|███▋      | 3858/10395 [11:02:25<18:09:10, 10.00s/it]                                                          {'loss': 0.9955, 'learning_rate': 1.4492786373219382e-05, 'epoch': 0.37}
 37%|███▋      | 3858/10395 [11:02:25<18:09:10, 10.00s/it] 37%|███▋      | 3859/10395 [11:02:34<17:08:51,  9.44s/it]                                                          {'loss': 0.9386, 'learning_rate': 1.4490002586053167e-05, 'epoch': 0.37}
 37%|███▋      | 3859/10395 [11:02:34<17:08:51,  9.44s/it] 37%|███▋      | 3860/10395 [11:02:42<16:26:49,  9.06s/it]                                                          {'loss': 0.9152, 'learning_rate': 1.4487218363007096e-05, 'epoch': 0.37}
 37%|███▋      | 3860/10395 [11:02:42<16:26:49,  9.06s/it] 37%|███▋      | 3861/10395 [11:02:49<15:32:48,  8.57s/it]                                                          {'loss': 0.9408, 'learning_rate': 1.4484433704351453e-05, 'epoch': 0.37}
 37%|███▋      | 3861/10395 [11:02:49<15:32:48,  8.57s/it] 37%|███▋      | 3862/10395 [11:02:57<15:02:51,  8.29s/it]                                                          {'loss': 0.9562, 'learning_rate': 1.4481648610356572e-05, 'epoch': 0.37}
 37%|███▋      | 3862/10395 [11:02:57<15:02:51,  8.29s/it] 37%|███▋      | 3863/10395 [11:03:04<14:37:20,  8.06s/it]                                                          {'loss': 0.9708, 'learning_rate': 1.4478863081292818e-05, 'epoch': 0.37}
 37%|███▋      | 3863/10395 [11:03:04<14:37:20,  8.06s/it] 37%|███▋      | 3864/10395 [11:03:12<14:13:48,  7.84s/it]                                                          {'loss': 0.9995, 'learning_rate': 1.4476077117430609e-05, 'epoch': 0.37}
 37%|███▋      | 3864/10395 [11:03:12<14:13:48,  7.84s/it] 37%|███▋      | 3865/10395 [11:03:21<14:56:37,  8.24s/it]                                                          {'loss': 0.9525, 'learning_rate': 1.44732907190404e-05, 'epoch': 0.37}
 37%|███▋      | 3865/10395 [11:03:21<14:56:37,  8.24s/it] 37%|███▋      | 3866/10395 [11:03:29<15:01:46,  8.29s/it]                                                          {'loss': 0.8883, 'learning_rate': 1.4470503886392686e-05, 'epoch': 0.37}
 37%|███▋      | 3866/10395 [11:03:29<15:01:46,  8.29s/it] 37%|███▋      | 3867/10395 [11:03:37<14:37:33,  8.07s/it]                                                          {'loss': 0.8981, 'learning_rate': 1.446771661975801e-05, 'epoch': 0.37}
 37%|███▋      | 3867/10395 [11:03:37<14:37:33,  8.07s/it] 37%|███▋      | 3868/10395 [11:03:45<14:35:14,  8.05s/it]                                                          {'loss': 0.9101, 'learning_rate': 1.4464928919406948e-05, 'epoch': 0.37}
 37%|███▋      | 3868/10395 [11:03:45<14:35:14,  8.05s/it] 37%|███▋      | 3869/10395 [11:03:52<14:09:03,  7.81s/it]                                                          {'loss': 0.9451, 'learning_rate': 1.4462140785610132e-05, 'epoch': 0.37}
 37%|███▋      | 3869/10395 [11:03:52<14:09:03,  7.81s/it] 37%|███▋      | 3870/10395 [11:04:10<19:23:46, 10.70s/it]                                                          {'loss': 0.4209, 'learning_rate': 1.4459352218638226e-05, 'epoch': 0.37}
 37%|███▋      | 3870/10395 [11:04:10<19:23:46, 10.70s/it] 37%|███▋      | 3871/10395 [11:04:17<17:39:04,  9.74s/it]                                                          {'loss': 0.9929, 'learning_rate': 1.4456563218761929e-05, 'epoch': 0.37}
 37%|███▋      | 3871/10395 [11:04:17<17:39:04,  9.74s/it] 37%|███▋      | 3872/10395 [11:04:25<16:30:18,  9.11s/it]                                                          {'loss': 0.9636, 'learning_rate': 1.4453773786252006e-05, 'epoch': 0.37}
 37%|███▋      | 3872/10395 [11:04:25<16:30:18,  9.11s/it] 37%|███▋      | 3873/10395 [11:04:32<15:41:27,  8.66s/it]                                                          {'loss': 1.0441, 'learning_rate': 1.4450983921379238e-05, 'epoch': 0.37}
 37%|███▋      | 3873/10395 [11:04:32<15:41:27,  8.66s/it] 37%|███▋      | 3874/10395 [11:04:40<15:03:38,  8.31s/it]                                                          {'loss': 1.0476, 'learning_rate': 1.4448193624414461e-05, 'epoch': 0.37}
 37%|███▋      | 3874/10395 [11:04:40<15:03:38,  8.31s/it] 37%|███▋      | 3875/10395 [11:04:47<14:30:42,  8.01s/it]                                                          {'loss': 1.02, 'learning_rate': 1.4445402895628555e-05, 'epoch': 0.37}
 37%|███▋      | 3875/10395 [11:04:47<14:30:42,  8.01s/it] 37%|███▋      | 3876/10395 [11:04:56<14:55:13,  8.24s/it]                                                          {'loss': 0.8851, 'learning_rate': 1.4442611735292435e-05, 'epoch': 0.37}
 37%|███▋      | 3876/10395 [11:04:56<14:55:13,  8.24s/it] 37%|███▋      | 3877/10395 [11:05:04<14:51:22,  8.21s/it]                                                          {'loss': 0.93, 'learning_rate': 1.4439820143677064e-05, 'epoch': 0.37}
 37%|███▋      | 3877/10395 [11:05:04<14:51:22,  8.21s/it] 37%|███▋      | 3878/10395 [11:05:12<14:38:15,  8.09s/it]                                                          {'loss': 0.9311, 'learning_rate': 1.443702812105344e-05, 'epoch': 0.37}
 37%|███▋      | 3878/10395 [11:05:12<14:38:15,  8.09s/it] 37%|███▋      | 3879/10395 [11:05:19<14:17:24,  7.90s/it]                                                          {'loss': 0.9137, 'learning_rate': 1.4434235667692607e-05, 'epoch': 0.37}
 37%|███▋      | 3879/10395 [11:05:19<14:17:24,  7.90s/it] 37%|███▋      | 3880/10395 [11:05:27<14:15:15,  7.88s/it]                                                          {'loss': 0.9044, 'learning_rate': 1.4431442783865652e-05, 'epoch': 0.37}
 37%|███▋      | 3880/10395 [11:05:27<14:15:15,  7.88s/it] 37%|███▋      | 3881/10395 [11:05:34<13:58:29,  7.72s/it]                                                          {'loss': 1.0166, 'learning_rate': 1.44286494698437e-05, 'epoch': 0.37}
 37%|███▋      | 3881/10395 [11:05:34<13:58:29,  7.72s/it] 37%|███▋      | 3882/10395 [11:05:42<13:48:55,  7.64s/it]                                                          {'loss': 0.9087, 'learning_rate': 1.4425855725897924e-05, 'epoch': 0.37}
 37%|███▋      | 3882/10395 [11:05:42<13:48:55,  7.64s/it] 37%|███▋      | 3883/10395 [11:05:49<13:39:27,  7.55s/it]                                                          {'loss': 1.0482, 'learning_rate': 1.4423061552299531e-05, 'epoch': 0.37}
 37%|███▋      | 3883/10395 [11:05:49<13:39:27,  7.55s/it] 37%|███▋      | 3884/10395 [11:05:57<13:37:37,  7.53s/it]                                                          {'loss': 0.9605, 'learning_rate': 1.4420266949319777e-05, 'epoch': 0.37}
 37%|███▋      | 3884/10395 [11:05:57<13:37:37,  7.53s/it] 37%|███▋      | 3885/10395 [11:06:04<13:38:05,  7.54s/it]                                                          {'loss': 0.9905, 'learning_rate': 1.441747191722995e-05, 'epoch': 0.37}
 37%|███▋      | 3885/10395 [11:06:04<13:38:05,  7.54s/it] 37%|███▋      | 3886/10395 [11:06:12<13:43:13,  7.59s/it]                                                          {'loss': 0.928, 'learning_rate': 1.441467645630139e-05, 'epoch': 0.37}
 37%|███▋      | 3886/10395 [11:06:12<13:43:13,  7.59s/it] 37%|███▋      | 3887/10395 [11:06:20<14:03:46,  7.78s/it]                                                          {'loss': 0.9723, 'learning_rate': 1.4411880566805477e-05, 'epoch': 0.37}
 37%|███▋      | 3887/10395 [11:06:20<14:03:46,  7.78s/it] 37%|███▋      | 3888/10395 [11:06:27<13:39:32,  7.56s/it]                                                          {'loss': 0.941, 'learning_rate': 1.4409084249013623e-05, 'epoch': 0.37}
 37%|███▋      | 3888/10395 [11:06:27<13:39:32,  7.56s/it] 37%|███▋      | 3889/10395 [11:06:35<13:49:25,  7.65s/it]                                                          {'loss': 0.9289, 'learning_rate': 1.4406287503197294e-05, 'epoch': 0.37}
 37%|███▋      | 3889/10395 [11:06:35<13:49:25,  7.65s/it] 37%|███▋      | 3890/10395 [11:06:43<13:42:34,  7.59s/it]                                                          {'loss': 0.9301, 'learning_rate': 1.4403490329627992e-05, 'epoch': 0.37}
 37%|███▋      | 3890/10395 [11:06:43<13:42:34,  7.59s/it] 37%|███▋      | 3891/10395 [11:06:50<13:35:33,  7.52s/it]                                                          {'loss': 1.0013, 'learning_rate': 1.4400692728577257e-05, 'epoch': 0.37}
 37%|███▋      | 3891/10395 [11:06:50<13:35:33,  7.52s/it] 37%|███▋      | 3892/10395 [11:06:58<13:40:52,  7.57s/it]                                                          {'loss': 0.9699, 'learning_rate': 1.4397894700316676e-05, 'epoch': 0.37}
 37%|███▋      | 3892/10395 [11:06:58<13:40:52,  7.57s/it] 37%|███▋      | 3893/10395 [11:07:05<13:43:36,  7.60s/it]                                                          {'loss': 0.9994, 'learning_rate': 1.4395096245117878e-05, 'epoch': 0.37}
 37%|███▋      | 3893/10395 [11:07:05<13:43:36,  7.60s/it] 37%|███▋      | 3894/10395 [11:07:14<14:08:47,  7.83s/it]                                                          {'loss': 0.925, 'learning_rate': 1.4392297363252525e-05, 'epoch': 0.37}
 37%|███▋      | 3894/10395 [11:07:14<14:08:47,  7.83s/it] 37%|███▋      | 3895/10395 [11:07:22<14:15:21,  7.90s/it]                                                          {'loss': 0.9417, 'learning_rate': 1.4389498054992333e-05, 'epoch': 0.37}
 37%|███▋      | 3895/10395 [11:07:22<14:15:21,  7.90s/it] 37%|███▋      | 3896/10395 [11:07:29<14:06:29,  7.82s/it]                                                          {'loss': 1.0248, 'learning_rate': 1.4386698320609052e-05, 'epoch': 0.37}
 37%|███▋      | 3896/10395 [11:07:29<14:06:29,  7.82s/it] 37%|███▋      | 3897/10395 [11:07:37<14:02:46,  7.78s/it]                                                          {'loss': 0.9494, 'learning_rate': 1.438389816037447e-05, 'epoch': 0.37}
 37%|███▋      | 3897/10395 [11:07:37<14:02:46,  7.78s/it] 37%|███▋      | 3898/10395 [11:07:44<13:48:17,  7.65s/it]                                                          {'loss': 0.9525, 'learning_rate': 1.4381097574560423e-05, 'epoch': 0.37}
 37%|███▋      | 3898/10395 [11:07:44<13:48:17,  7.65s/it] 38%|███▊      | 3899/10395 [11:07:52<14:01:11,  7.77s/it]                                                          {'loss': 0.8944, 'learning_rate': 1.4378296563438785e-05, 'epoch': 0.38}
 38%|███▊      | 3899/10395 [11:07:52<14:01:11,  7.77s/it] 38%|███▊      | 3900/10395 [11:08:01<14:22:32,  7.97s/it]                                                          {'loss': 0.9071, 'learning_rate': 1.4375495127281474e-05, 'epoch': 0.38}
 38%|███▊      | 3900/10395 [11:08:01<14:22:32,  7.97s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 38%|███▊      | 3901/10395 [11:09:41<64:24:50, 35.71s/it]                                                          {'loss': 0.948, 'learning_rate': 1.4372693266360448e-05, 'epoch': 0.38}
 38%|███▊      | 3901/10395 [11:09:41<64:24:50, 35.71s/it] 38%|███▊      | 3902/10395 [11:09:49<49:28:19, 27.43s/it]                                                          {'loss': 0.9097, 'learning_rate': 1.4369890980947703e-05, 'epoch': 0.38}
 38%|███▊      | 3902/10395 [11:09:49<49:28:19, 27.43s/it] 38%|███▊      | 3903/10395 [11:09:57<38:29:01, 21.34s/it]                                                          {'loss': 1.0406, 'learning_rate': 1.4367088271315279e-05, 'epoch': 0.38}
 38%|███▊      | 3903/10395 [11:09:57<38:29:01, 21.34s/it] 38%|███▊      | 3904/10395 [11:10:07<32:40:02, 18.12s/it]                                                          {'loss': 0.9104, 'learning_rate': 1.4364285137735263e-05, 'epoch': 0.38}
 38%|███▊      | 3904/10395 [11:10:07<32:40:02, 18.12s/it] 38%|███▊      | 3905/10395 [11:10:15<26:59:55, 14.98s/it]                                                          {'loss': 1.0187, 'learning_rate': 1.4361481580479767e-05, 'epoch': 0.38}
 38%|███▊      | 3905/10395 [11:10:15<26:59:55, 14.98s/it] 38%|███▊      | 3906/10395 [11:10:22<22:58:24, 12.75s/it]                                                          {'loss': 0.9513, 'learning_rate': 1.4358677599820961e-05, 'epoch': 0.38}
 38%|███▊      | 3906/10395 [11:10:22<22:58:24, 12.75s/it] 38%|███▊      | 3907/10395 [11:10:30<20:26:33, 11.34s/it]                                                          {'loss': 0.8902, 'learning_rate': 1.4355873196031048e-05, 'epoch': 0.38}
 38%|███▊      | 3907/10395 [11:10:30<20:26:33, 11.34s/it] 38%|███▊      | 3908/10395 [11:10:47<23:32:24, 13.06s/it]                                                          {'loss': 0.4142, 'learning_rate': 1.4353068369382275e-05, 'epoch': 0.38}
 38%|███▊      | 3908/10395 [11:10:47<23:32:24, 13.06s/it] 38%|███▊      | 3909/10395 [11:10:57<21:33:25, 11.97s/it]                                                          {'loss': 0.9238, 'learning_rate': 1.4350263120146925e-05, 'epoch': 0.38}
 38%|███▊      | 3909/10395 [11:10:57<21:33:25, 11.97s/it] 38%|███▊      | 3910/10395 [11:11:04<19:09:04, 10.63s/it]                                                          {'loss': 0.9757, 'learning_rate': 1.4347457448597328e-05, 'epoch': 0.38}
 38%|███▊      | 3910/10395 [11:11:04<19:09:04, 10.63s/it] 38%|███▊      | 3911/10395 [11:11:12<17:28:40,  9.70s/it]                                                          {'loss': 0.9458, 'learning_rate': 1.4344651355005855e-05, 'epoch': 0.38}
 38%|███▊      | 3911/10395 [11:11:12<17:28:40,  9.70s/it] 38%|███▊      | 3912/10395 [11:11:19<16:11:51,  8.99s/it]                                                          {'loss': 0.913, 'learning_rate': 1.4341844839644913e-05, 'epoch': 0.38}
 38%|███▊      | 3912/10395 [11:11:19<16:11:51,  8.99s/it] 38%|███▊      | 3913/10395 [11:11:27<15:37:25,  8.68s/it]                                                          {'loss': 0.8946, 'learning_rate': 1.4339037902786952e-05, 'epoch': 0.38}
 38%|███▊      | 3913/10395 [11:11:27<15:37:25,  8.68s/it] 38%|███▊      | 3914/10395 [11:11:35<15:15:48,  8.48s/it]                                                          {'loss': 0.9505, 'learning_rate': 1.433623054470446e-05, 'epoch': 0.38}
 38%|███▊      | 3914/10395 [11:11:35<15:15:48,  8.48s/it] 38%|███▊      | 3915/10395 [11:11:43<14:38:32,  8.13s/it]                                                          {'loss': 0.9364, 'learning_rate': 1.433342276566998e-05, 'epoch': 0.38}
 38%|███▊      | 3915/10395 [11:11:43<14:38:32,  8.13s/it] 38%|███▊      | 3916/10395 [11:11:50<14:25:35,  8.02s/it]                                                          {'loss': 0.8997, 'learning_rate': 1.4330614565956073e-05, 'epoch': 0.38}
 38%|███▊      | 3916/10395 [11:11:50<14:25:35,  8.02s/it] 38%|███▊      | 3917/10395 [11:11:59<14:40:01,  8.15s/it]                                                          {'loss': 0.8121, 'learning_rate': 1.432780594583536e-05, 'epoch': 0.38}
 38%|███▊      | 3917/10395 [11:11:59<14:40:01,  8.15s/it] 38%|███▊      | 3918/10395 [11:12:07<14:41:31,  8.17s/it]                                                          {'loss': 0.8606, 'learning_rate': 1.4324996905580493e-05, 'epoch': 0.38}
 38%|███▊      | 3918/10395 [11:12:07<14:41:31,  8.17s/it] 38%|███▊      | 3919/10395 [11:12:15<14:34:09,  8.10s/it]                                                          {'loss': 0.9905, 'learning_rate': 1.4322187445464172e-05, 'epoch': 0.38}
 38%|███▊      | 3919/10395 [11:12:15<14:34:09,  8.10s/it] 38%|███▊      | 3920/10395 [11:12:23<14:21:08,  7.98s/it]                                                          {'loss': 0.9988, 'learning_rate': 1.4319377565759129e-05, 'epoch': 0.38}
 38%|███▊      | 3920/10395 [11:12:23<14:21:08,  7.98s/it] 38%|███▊      | 3921/10395 [11:12:30<14:01:24,  7.80s/it]                                                          {'loss': 0.9439, 'learning_rate': 1.4316567266738142e-05, 'epoch': 0.38}
 38%|███▊      | 3921/10395 [11:12:30<14:01:24,  7.80s/it] 38%|███▊      | 3922/10395 [11:12:37<13:46:34,  7.66s/it]                                                          {'loss': 0.9529, 'learning_rate': 1.431375654867403e-05, 'epoch': 0.38}
 38%|███▊      | 3922/10395 [11:12:37<13:46:34,  7.66s/it] 38%|███▊      | 3923/10395 [11:12:46<14:08:39,  7.87s/it]                                                          {'loss': 0.9701, 'learning_rate': 1.4310945411839652e-05, 'epoch': 0.38}
 38%|███▊      | 3923/10395 [11:12:46<14:08:39,  7.87s/it] 38%|███▊      | 3924/10395 [11:12:53<14:04:29,  7.83s/it]                                                          {'loss': 0.9702, 'learning_rate': 1.4308133856507905e-05, 'epoch': 0.38}
 38%|███▊      | 3924/10395 [11:12:53<14:04:29,  7.83s/it] 38%|███▊      | 3925/10395 [11:13:11<19:19:42, 10.75s/it]                                                          {'loss': 0.3615, 'learning_rate': 1.4305321882951726e-05, 'epoch': 0.38}
 38%|███▊      | 3925/10395 [11:13:11<19:19:42, 10.75s/it] 38%|███▊      | 3926/10395 [11:13:18<17:32:55,  9.77s/it]                                                          {'loss': 0.9125, 'learning_rate': 1.4302509491444103e-05, 'epoch': 0.38}
 38%|███▊      | 3926/10395 [11:13:18<17:32:55,  9.77s/it] 38%|███▊      | 3927/10395 [11:13:26<16:20:50,  9.10s/it]                                                          {'loss': 0.9348, 'learning_rate': 1.4299696682258053e-05, 'epoch': 0.38}
 38%|███▊      | 3927/10395 [11:13:27<16:20:50,  9.10s/it] 38%|███▊      | 3928/10395 [11:13:36<16:46:25,  9.34s/it]                                                          {'loss': 0.8778, 'learning_rate': 1.4296883455666636e-05, 'epoch': 0.38}
 38%|███▊      | 3928/10395 [11:13:36<16:46:25,  9.34s/it] 38%|███▊      | 3929/10395 [11:13:43<15:40:09,  8.72s/it]                                                          {'loss': 1.0772, 'learning_rate': 1.4294069811942955e-05, 'epoch': 0.38}
 38%|███▊      | 3929/10395 [11:13:43<15:40:09,  8.72s/it] 38%|███▊      | 3930/10395 [11:13:50<14:55:24,  8.31s/it]                                                          {'loss': 0.9855, 'learning_rate': 1.4291255751360158e-05, 'epoch': 0.38}
 38%|███▊      | 3930/10395 [11:13:51<14:55:24,  8.31s/it] 38%|███▊      | 3931/10395 [11:13:59<15:01:34,  8.37s/it]                                                          {'loss': 0.9676, 'learning_rate': 1.4288441274191418e-05, 'epoch': 0.38}
 38%|███▊      | 3931/10395 [11:13:59<15:01:34,  8.37s/it] 38%|███▊      | 3932/10395 [11:14:06<14:29:54,  8.08s/it]                                                          {'loss': 0.915, 'learning_rate': 1.4285626380709965e-05, 'epoch': 0.38}
 38%|███▊      | 3932/10395 [11:14:06<14:29:54,  8.08s/it] 38%|███▊      | 3933/10395 [11:14:14<14:09:49,  7.89s/it]                                                          {'loss': 0.9817, 'learning_rate': 1.428281107118906e-05, 'epoch': 0.38}
 38%|███▊      | 3933/10395 [11:14:14<14:09:49,  7.89s/it] 38%|███▊      | 3934/10395 [11:14:22<14:08:39,  7.88s/it]                                                          {'loss': 0.8875, 'learning_rate': 1.4279995345902013e-05, 'epoch': 0.38}
 38%|███▊      | 3934/10395 [11:14:22<14:08:39,  7.88s/it] 38%|███▊      | 3935/10395 [11:14:29<13:56:34,  7.77s/it]                                                          {'loss': 0.9221, 'learning_rate': 1.4277179205122163e-05, 'epoch': 0.38}
 38%|███▊      | 3935/10395 [11:14:29<13:56:34,  7.77s/it] 38%|███▊      | 3936/10395 [11:14:37<14:03:40,  7.84s/it]                                                          {'loss': 0.9553, 'learning_rate': 1.4274362649122892e-05, 'epoch': 0.38}
 38%|███▊      | 3936/10395 [11:14:37<14:03:40,  7.84s/it] 38%|███▊      | 3937/10395 [11:14:45<14:03:58,  7.84s/it]                                                          {'loss': 1.0217, 'learning_rate': 1.4271545678177634e-05, 'epoch': 0.38}
 38%|███▊      | 3937/10395 [11:14:45<14:03:58,  7.84s/it] 38%|███▊      | 3938/10395 [11:14:52<13:50:15,  7.71s/it]                                                          {'loss': 0.9407, 'learning_rate': 1.4268728292559846e-05, 'epoch': 0.38}
 38%|███▊      | 3938/10395 [11:14:52<13:50:15,  7.71s/it] 38%|███▊      | 3939/10395 [11:15:01<14:01:25,  7.82s/it]                                                          {'loss': 0.8765, 'learning_rate': 1.4265910492543041e-05, 'epoch': 0.38}
 38%|███▊      | 3939/10395 [11:15:01<14:01:25,  7.82s/it] 38%|███▊      | 3940/10395 [11:15:09<14:17:34,  7.97s/it]                                                          {'loss': 0.9269, 'learning_rate': 1.4263092278400758e-05, 'epoch': 0.38}
 38%|███▊      | 3940/10395 [11:15:09<14:17:34,  7.97s/it] 38%|███▊      | 3941/10395 [11:15:17<14:06:59,  7.87s/it]                                                          {'loss': 0.8727, 'learning_rate': 1.426027365040659e-05, 'epoch': 0.38}
 38%|███▊      | 3941/10395 [11:15:17<14:06:59,  7.87s/it] 38%|███▊      | 3942/10395 [11:15:33<18:41:23, 10.43s/it]                                                          {'loss': 0.3589, 'learning_rate': 1.425745460883416e-05, 'epoch': 0.38}
 38%|███▊      | 3942/10395 [11:15:33<18:41:23, 10.43s/it] 38%|███▊      | 3943/10395 [11:15:40<17:09:34,  9.57s/it]                                                          {'loss': 0.9938, 'learning_rate': 1.4254635153957132e-05, 'epoch': 0.38}
 38%|███▊      | 3943/10395 [11:15:40<17:09:34,  9.57s/it] 38%|███▊      | 3944/10395 [11:15:58<21:09:24, 11.81s/it]                                                          {'loss': 0.397, 'learning_rate': 1.425181528604922e-05, 'epoch': 0.38}
 38%|███▊      | 3944/10395 [11:15:58<21:09:24, 11.81s/it] 38%|███▊      | 3945/10395 [11:16:14<23:52:40, 13.33s/it]                                                          {'loss': 0.3724, 'learning_rate': 1.4248995005384163e-05, 'epoch': 0.38}
 38%|███▊      | 3945/10395 [11:16:14<23:52:40, 13.33s/it] 38%|███▊      | 3946/10395 [11:16:22<20:41:47, 11.55s/it]                                                          {'loss': 1.0428, 'learning_rate': 1.4246174312235751e-05, 'epoch': 0.38}
 38%|███▊      | 3946/10395 [11:16:22<20:41:47, 11.55s/it] 38%|███▊      | 3947/10395 [11:16:30<18:51:06, 10.53s/it]                                                          {'loss': 0.9472, 'learning_rate': 1.424335320687781e-05, 'epoch': 0.38}
 38%|███▊      | 3947/10395 [11:16:30<18:51:06, 10.53s/it] 38%|███▊      | 3948/10395 [11:16:38<17:18:41,  9.67s/it]                                                          {'loss': 0.9846, 'learning_rate': 1.424053168958421e-05, 'epoch': 0.38}
 38%|███▊      | 3948/10395 [11:16:38<17:18:41,  9.67s/it] 38%|███▊      | 3949/10395 [11:16:46<16:29:53,  9.21s/it]                                                          {'loss': 0.9275, 'learning_rate': 1.4237709760628855e-05, 'epoch': 0.38}
 38%|███▊      | 3949/10395 [11:16:46<16:29:53,  9.21s/it] 38%|███▊      | 3950/10395 [11:16:53<15:41:16,  8.76s/it]                                                          {'loss': 0.9164, 'learning_rate': 1.4234887420285693e-05, 'epoch': 0.38}
 38%|███▊      | 3950/10395 [11:16:53<15:41:16,  8.76s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 38%|███▊      | 3951/10395 [11:18:37<66:32:22, 37.17s/it]                                                          {'loss': 0.8906, 'learning_rate': 1.423206466882871e-05, 'epoch': 0.38}
 38%|███▊      | 3951/10395 [11:18:37<66:32:22, 37.17s/it] 38%|███▊      | 3952/10395 [11:18:44<50:30:02, 28.22s/it]                                                          {'loss': 0.9439, 'learning_rate': 1.4229241506531933e-05, 'epoch': 0.38}
 38%|███▊      | 3952/10395 [11:18:44<50:30:02, 28.22s/it] 38%|███▊      | 3953/10395 [11:18:53<40:00:36, 22.36s/it]                                                          {'loss': 0.8352, 'learning_rate': 1.4226417933669427e-05, 'epoch': 0.38}
 38%|███▊      | 3953/10395 [11:18:53<40:00:36, 22.36s/it] 38%|███▊      | 3954/10395 [11:19:01<32:11:48, 18.00s/it]                                                          {'loss': 0.9635, 'learning_rate': 1.42235939505153e-05, 'epoch': 0.38}
 38%|███▊      | 3954/10395 [11:19:01<32:11:48, 18.00s/it] 38%|███▊      | 3955/10395 [11:19:10<27:19:28, 15.27s/it]                                                          {'loss': 0.9205, 'learning_rate': 1.42207695573437e-05, 'epoch': 0.38}
 38%|███▊      | 3955/10395 [11:19:10<27:19:28, 15.27s/it] 38%|███▊      | 3956/10395 [11:19:17<22:55:10, 12.81s/it]                                                          {'loss': 0.9885, 'learning_rate': 1.4217944754428809e-05, 'epoch': 0.38}
 38%|███▊      | 3956/10395 [11:19:17<22:55:10, 12.81s/it] 38%|███▊      | 3957/10395 [11:19:24<20:07:08, 11.25s/it]                                                          {'loss': 0.8622, 'learning_rate': 1.4215119542044858e-05, 'epoch': 0.38}
 38%|███▊      | 3957/10395 [11:19:24<20:07:08, 11.25s/it] 38%|███▊      | 3958/10395 [11:19:32<18:08:32, 10.15s/it]                                                          {'loss': 0.9614, 'learning_rate': 1.4212293920466106e-05, 'epoch': 0.38}
 38%|███▊      | 3958/10395 [11:19:32<18:08:32, 10.15s/it] 38%|███▊      | 3959/10395 [11:19:40<16:56:18,  9.47s/it]                                                          {'loss': 0.9411, 'learning_rate': 1.4209467889966863e-05, 'epoch': 0.38}
 38%|███▊      | 3959/10395 [11:19:40<16:56:18,  9.47s/it] 38%|███▊      | 3960/10395 [11:19:47<15:50:14,  8.86s/it]                                                          {'loss': 0.8706, 'learning_rate': 1.4206641450821474e-05, 'epoch': 0.38}
 38%|███▊      | 3960/10395 [11:19:47<15:50:14,  8.86s/it] 38%|███▊      | 3961/10395 [11:19:55<15:04:50,  8.44s/it]                                                          {'loss': 0.9741, 'learning_rate': 1.4203814603304322e-05, 'epoch': 0.38}
 38%|███▊      | 3961/10395 [11:19:55<15:04:50,  8.44s/it] 38%|███▊      | 3962/10395 [11:20:02<14:32:54,  8.14s/it]                                                          {'loss': 1.0242, 'learning_rate': 1.4200987347689835e-05, 'epoch': 0.38}
 38%|███▊      | 3962/10395 [11:20:02<14:32:54,  8.14s/it] 38%|███▊      | 3963/10395 [11:20:10<14:19:48,  8.02s/it]                                                          {'loss': 1.0415, 'learning_rate': 1.4198159684252468e-05, 'epoch': 0.38}
 38%|███▊      | 3963/10395 [11:20:10<14:19:48,  8.02s/it] 38%|███▊      | 3964/10395 [11:20:18<14:07:38,  7.91s/it]                                                          {'loss': 1.0129, 'learning_rate': 1.4195331613266734e-05, 'epoch': 0.38}
 38%|███▊      | 3964/10395 [11:20:18<14:07:38,  7.91s/it] 38%|███▊      | 3965/10395 [11:20:25<13:54:00,  7.78s/it]                                                          {'loss': 0.9781, 'learning_rate': 1.4192503135007172e-05, 'epoch': 0.38}
 38%|███▊      | 3965/10395 [11:20:25<13:54:00,  7.78s/it] 38%|███▊      | 3966/10395 [11:20:34<14:31:18,  8.13s/it]                                                          {'loss': 0.9296, 'learning_rate': 1.4189674249748364e-05, 'epoch': 0.38}
 38%|███▊      | 3966/10395 [11:20:34<14:31:18,  8.13s/it] 38%|███▊      | 3967/10395 [11:20:51<19:20:24, 10.83s/it]                                                          {'loss': 0.4068, 'learning_rate': 1.4186844957764934e-05, 'epoch': 0.38}
 38%|███▊      | 3967/10395 [11:20:51<19:20:24, 10.83s/it] 38%|███▊      | 3968/10395 [11:20:59<17:30:45,  9.81s/it]                                                          {'loss': 1.0009, 'learning_rate': 1.4184015259331544e-05, 'epoch': 0.38}
 38%|███▊      | 3968/10395 [11:20:59<17:30:45,  9.81s/it] 38%|███▊      | 3969/10395 [11:21:05<15:58:38,  8.95s/it]                                                          {'loss': 0.9407, 'learning_rate': 1.4181185154722892e-05, 'epoch': 0.38}
 38%|███▊      | 3969/10395 [11:21:05<15:58:38,  8.95s/it] 38%|███▊      | 3970/10395 [11:21:14<15:29:23,  8.68s/it]                                                          {'loss': 0.8649, 'learning_rate': 1.417835464421372e-05, 'epoch': 0.38}
 38%|███▊      | 3970/10395 [11:21:14<15:29:23,  8.68s/it] 38%|███▊      | 3971/10395 [11:21:22<15:08:06,  8.48s/it]                                                          {'loss': 0.8878, 'learning_rate': 1.4175523728078811e-05, 'epoch': 0.38}
 38%|███▊      | 3971/10395 [11:21:22<15:08:06,  8.48s/it] 38%|███▊      | 3972/10395 [11:21:29<14:42:13,  8.24s/it]                                                          {'loss': 0.9161, 'learning_rate': 1.4172692406592981e-05, 'epoch': 0.38}
 38%|███▊      | 3972/10395 [11:21:29<14:42:13,  8.24s/it] 38%|███▊      | 3973/10395 [11:21:37<14:27:49,  8.11s/it]                                                          {'loss': 0.9231, 'learning_rate': 1.4169860680031086e-05, 'epoch': 0.38}
 38%|███▊      | 3973/10395 [11:21:37<14:27:49,  8.11s/it] 38%|███▊      | 3974/10395 [11:21:45<14:26:19,  8.10s/it]                                                          {'loss': 0.8892, 'learning_rate': 1.4167028548668031e-05, 'epoch': 0.38}
 38%|███▊      | 3974/10395 [11:21:45<14:26:19,  8.10s/it] 38%|███▊      | 3975/10395 [11:21:52<14:03:43,  7.89s/it]                                                          {'loss': 0.9409, 'learning_rate': 1.4164196012778745e-05, 'epoch': 0.38}
 38%|███▊      | 3975/10395 [11:21:52<14:03:43,  7.89s/it] 38%|███▊      | 3976/10395 [11:22:09<18:45:32, 10.52s/it]                                                          {'loss': 0.3989, 'learning_rate': 1.4161363072638215e-05, 'epoch': 0.38}
 38%|███▊      | 3976/10395 [11:22:09<18:45:32, 10.52s/it] 38%|███▊      | 3977/10395 [11:22:16<17:02:12,  9.56s/it]                                                          {'loss': 1.0075, 'learning_rate': 1.4158529728521447e-05, 'epoch': 0.38}
 38%|███▊      | 3977/10395 [11:22:16<17:02:12,  9.56s/it] 38%|███▊      | 3978/10395 [11:22:25<16:20:39,  9.17s/it]                                                          {'loss': 0.8717, 'learning_rate': 1.4155695980703502e-05, 'epoch': 0.38}
 38%|███▊      | 3978/10395 [11:22:25<16:20:39,  9.17s/it] 38%|███▊      | 3979/10395 [11:22:42<20:30:57, 11.51s/it]                                                          {'loss': 0.3939, 'learning_rate': 1.4152861829459468e-05, 'epoch': 0.38}
 38%|███▊      | 3979/10395 [11:22:42<20:30:57, 11.51s/it] 38%|███▊      | 3980/10395 [11:22:49<18:19:11, 10.28s/it]                                                          {'loss': 0.92, 'learning_rate': 1.4150027275064484e-05, 'epoch': 0.38}
 38%|███▊      | 3980/10395 [11:22:49<18:19:11, 10.28s/it] 38%|███▊      | 3981/10395 [11:22:57<17:10:01,  9.64s/it]                                                          {'loss': 0.8916, 'learning_rate': 1.4147192317793721e-05, 'epoch': 0.38}
 38%|███▊      | 3981/10395 [11:22:57<17:10:01,  9.64s/it] 38%|███▊      | 3982/10395 [11:23:05<15:56:11,  8.95s/it]                                                          {'loss': 0.9499, 'learning_rate': 1.4144356957922394e-05, 'epoch': 0.38}
 38%|███▊      | 3982/10395 [11:23:05<15:56:11,  8.95s/it] 38%|███▊      | 3983/10395 [11:23:12<15:11:28,  8.53s/it]                                                          {'loss': 0.8655, 'learning_rate': 1.4141521195725745e-05, 'epoch': 0.38}
 38%|███▊      | 3983/10395 [11:23:12<15:11:28,  8.53s/it] 38%|███▊      | 3984/10395 [11:23:20<14:46:26,  8.30s/it]                                                          {'loss': 1.0217, 'learning_rate': 1.413868503147907e-05, 'epoch': 0.38}
 38%|███▊      | 3984/10395 [11:23:20<14:46:26,  8.30s/it] 38%|███▊      | 3985/10395 [11:23:27<14:18:39,  8.04s/it]                                                          {'loss': 0.8942, 'learning_rate': 1.41358484654577e-05, 'epoch': 0.38}
 38%|███▊      | 3985/10395 [11:23:27<14:18:39,  8.04s/it] 38%|███▊      | 3986/10395 [11:23:34<13:44:56,  7.72s/it]                                                          {'loss': 1.0256, 'learning_rate': 1.4133011497936995e-05, 'epoch': 0.38}
 38%|███▊      | 3986/10395 [11:23:34<13:44:56,  7.72s/it] 38%|███▊      | 3987/10395 [11:23:42<13:38:23,  7.66s/it]                                                          {'loss': 0.9351, 'learning_rate': 1.4130174129192367e-05, 'epoch': 0.38}
 38%|███▊      | 3987/10395 [11:23:42<13:38:23,  7.66s/it] 38%|███▊      | 3988/10395 [11:23:52<14:58:15,  8.41s/it]                                                          {'loss': 0.9368, 'learning_rate': 1.412733635949926e-05, 'epoch': 0.38}
 38%|███▊      | 3988/10395 [11:23:52<14:58:15,  8.41s/it] 38%|███▊      | 3989/10395 [11:24:00<14:55:23,  8.39s/it]                                                          {'loss': 0.9498, 'learning_rate': 1.4124498189133163e-05, 'epoch': 0.38}
 38%|███▊      | 3989/10395 [11:24:00<14:55:23,  8.39s/it] 38%|███▊      | 3990/10395 [11:24:08<14:27:31,  8.13s/it]                                                          {'loss': 0.9828, 'learning_rate': 1.4121659618369591e-05, 'epoch': 0.38}
 38%|███▊      | 3990/10395 [11:24:08<14:27:31,  8.13s/it] 38%|███▊      | 3991/10395 [11:24:15<13:56:28,  7.84s/it]                                                          {'loss': 1.0178, 'learning_rate': 1.4118820647484115e-05, 'epoch': 0.38}
 38%|███▊      | 3991/10395 [11:24:15<13:56:28,  7.84s/it] 38%|███▊      | 3992/10395 [11:24:23<14:04:15,  7.91s/it]                                                          {'loss': 0.9429, 'learning_rate': 1.4115981276752332e-05, 'epoch': 0.38}
 38%|███▊      | 3992/10395 [11:24:23<14:04:15,  7.91s/it] 38%|███▊      | 3993/10395 [11:24:31<13:56:57,  7.84s/it]                                                          {'loss': 0.9094, 'learning_rate': 1.411314150644988e-05, 'epoch': 0.38}
 38%|███▊      | 3993/10395 [11:24:31<13:56:57,  7.84s/it] 38%|███▊      | 3994/10395 [11:24:39<13:56:39,  7.84s/it]                                                          {'loss': 0.938, 'learning_rate': 1.411030133685244e-05, 'epoch': 0.38}
 38%|███▊      | 3994/10395 [11:24:39<13:56:39,  7.84s/it] 38%|███▊      | 3995/10395 [11:24:48<14:51:51,  8.36s/it]                                                          {'loss': 0.8529, 'learning_rate': 1.4107460768235734e-05, 'epoch': 0.38}
 38%|███▊      | 3995/10395 [11:24:48<14:51:51,  8.36s/it] 38%|███▊      | 3996/10395 [11:24:56<14:28:18,  8.14s/it]                                                          {'loss': 0.9318, 'learning_rate': 1.4104619800875514e-05, 'epoch': 0.38}
 38%|███▊      | 3996/10395 [11:24:56<14:28:18,  8.14s/it] 38%|███▊      | 3997/10395 [11:25:13<19:16:58, 10.85s/it]                                                          {'loss': 0.4054, 'learning_rate': 1.4101778435047574e-05, 'epoch': 0.38}
 38%|███▊      | 3997/10395 [11:25:13<19:16:58, 10.85s/it] 38%|███▊      | 3998/10395 [11:25:22<18:15:20, 10.27s/it]                                                          {'loss': 0.9544, 'learning_rate': 1.4098936671027747e-05, 'epoch': 0.38}
 38%|███▊      | 3998/10395 [11:25:22<18:15:20, 10.27s/it] 38%|███▊      | 3999/10395 [11:25:30<17:01:24,  9.58s/it]                                                          {'loss': 0.986, 'learning_rate': 1.4096094509091911e-05, 'epoch': 0.38}
 38%|███▊      | 3999/10395 [11:25:30<17:01:24,  9.58s/it] 38%|███▊      | 4000/10395 [11:25:38<16:08:05,  9.08s/it]                                                          {'loss': 0.9282, 'learning_rate': 1.4093251949515972e-05, 'epoch': 0.38}
 38%|███▊      | 4000/10395 [11:25:38<16:08:05,  9.08s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 38%|███▊      | 4001/10395 [11:27:30<70:58:06, 39.96s/it]                                                          {'loss': 0.3817, 'learning_rate': 1.4090408992575881e-05, 'epoch': 0.38}
 38%|███▊      | 4001/10395 [11:27:30<70:58:06, 39.96s/it] 38%|███▊      | 4002/10395 [11:27:47<58:57:54, 33.20s/it]                                                          {'loss': 0.3833, 'learning_rate': 1.4087565638547625e-05, 'epoch': 0.38}
 38%|███▊      | 4002/10395 [11:27:47<58:57:54, 33.20s/it] 39%|███▊      | 4003/10395 [11:27:55<45:19:35, 25.53s/it]                                                          {'loss': 0.9259, 'learning_rate': 1.4084721887707234e-05, 'epoch': 0.39}
 39%|███▊      | 4003/10395 [11:27:55<45:19:35, 25.53s/it] 39%|███▊      | 4004/10395 [11:28:03<35:55:18, 20.23s/it]                                                          {'loss': 0.9411, 'learning_rate': 1.4081877740330772e-05, 'epoch': 0.39}
 39%|███▊      | 4004/10395 [11:28:03<35:55:18, 20.23s/it] 39%|███▊      | 4005/10395 [11:28:20<34:33:18, 19.47s/it]                                                          {'loss': 0.4171, 'learning_rate': 1.4079033196694339e-05, 'epoch': 0.39}
 39%|███▊      | 4005/10395 [11:28:20<34:33:18, 19.47s/it] 39%|███▊      | 4006/10395 [11:28:27<27:56:09, 15.74s/it]                                                          {'loss': 0.9445, 'learning_rate': 1.4076188257074079e-05, 'epoch': 0.39}
 39%|███▊      | 4006/10395 [11:28:27<27:56:09, 15.74s/it] 39%|███▊      | 4007/10395 [11:28:36<24:14:11, 13.66s/it]                                                          {'loss': 0.855, 'learning_rate': 1.4073342921746177e-05, 'epoch': 0.39}
 39%|███▊      | 4007/10395 [11:28:36<24:14:11, 13.66s/it] 39%|███▊      | 4008/10395 [11:28:44<20:59:53, 11.84s/it]                                                          {'loss': 0.9696, 'learning_rate': 1.407049719098685e-05, 'epoch': 0.39}
 39%|███▊      | 4008/10395 [11:28:44<20:59:53, 11.84s/it] 39%|███▊      | 4009/10395 [11:28:52<18:49:22, 10.61s/it]                                                          {'loss': 0.8911, 'learning_rate': 1.4067651065072353e-05, 'epoch': 0.39}
 39%|███▊      | 4009/10395 [11:28:52<18:49:22, 10.61s/it] 39%|███▊      | 4010/10395 [11:28:59<17:08:42,  9.67s/it]                                                          {'loss': 0.9296, 'learning_rate': 1.4064804544278978e-05, 'epoch': 0.39}
 39%|███▊      | 4010/10395 [11:28:59<17:08:42,  9.67s/it] 39%|███▊      | 4011/10395 [11:29:07<16:13:22,  9.15s/it]                                                          {'loss': 1.0101, 'learning_rate': 1.4061957628883072e-05, 'epoch': 0.39}
 39%|███▊      | 4011/10395 [11:29:07<16:13:22,  9.15s/it] 39%|███▊      | 4012/10395 [11:29:17<16:27:58,  9.29s/it]                                                          {'loss': 0.9921, 'learning_rate': 1.4059110319160998e-05, 'epoch': 0.39}
 39%|███▊      | 4012/10395 [11:29:17<16:27:58,  9.29s/it] 39%|███▊      | 4013/10395 [11:29:25<15:52:17,  8.95s/it]                                                          {'loss': 0.8787, 'learning_rate': 1.4056262615389168e-05, 'epoch': 0.39}
 39%|███▊      | 4013/10395 [11:29:25<15:52:17,  8.95s/it] 39%|███▊      | 4014/10395 [11:29:32<15:05:12,  8.51s/it]                                                          {'loss': 0.998, 'learning_rate': 1.4053414517844028e-05, 'epoch': 0.39}
 39%|███▊      | 4014/10395 [11:29:32<15:05:12,  8.51s/it] 39%|███▊      | 4015/10395 [11:29:40<14:41:37,  8.29s/it]                                                          {'loss': 0.922, 'learning_rate': 1.4050566026802073e-05, 'epoch': 0.39}
 39%|███▊      | 4015/10395 [11:29:40<14:41:37,  8.29s/it] 39%|███▊      | 4016/10395 [11:29:58<19:48:01, 11.17s/it]                                                          {'loss': 0.4335, 'learning_rate': 1.4047717142539823e-05, 'epoch': 0.39}
 39%|███▊      | 4016/10395 [11:29:58<19:48:01, 11.17s/it] 39%|███▊      | 4017/10395 [11:30:05<17:46:08, 10.03s/it]                                                          {'loss': 0.9575, 'learning_rate': 1.4044867865333843e-05, 'epoch': 0.39}
 39%|███▊      | 4017/10395 [11:30:05<17:46:08, 10.03s/it] 39%|███▊      | 4018/10395 [11:30:13<16:24:09,  9.26s/it]                                                          {'loss': 0.9981, 'learning_rate': 1.4042018195460733e-05, 'epoch': 0.39}
 39%|███▊      | 4018/10395 [11:30:13<16:24:09,  9.26s/it] 39%|███▊      | 4019/10395 [11:30:20<15:34:12,  8.79s/it]                                                          {'loss': 0.9771, 'learning_rate': 1.4039168133197136e-05, 'epoch': 0.39}
 39%|███▊      | 4019/10395 [11:30:20<15:34:12,  8.79s/it] 39%|███▊      | 4020/10395 [11:30:28<14:47:21,  8.35s/it]                                                          {'loss': 0.9562, 'learning_rate': 1.4036317678819729e-05, 'epoch': 0.39}
 39%|███▊      | 4020/10395 [11:30:28<14:47:21,  8.35s/it] 39%|███▊      | 4021/10395 [11:30:35<14:18:00,  8.08s/it]                                                          {'loss': 0.9216, 'learning_rate': 1.4033466832605224e-05, 'epoch': 0.39}
 39%|███▊      | 4021/10395 [11:30:35<14:18:00,  8.08s/it] 39%|███▊      | 4022/10395 [11:30:42<13:45:20,  7.77s/it]                                                          {'loss': 0.9624, 'learning_rate': 1.4030615594830383e-05, 'epoch': 0.39}
 39%|███▊      | 4022/10395 [11:30:42<13:45:20,  7.77s/it] 39%|███▊      | 4023/10395 [11:30:53<15:11:54,  8.59s/it]                                                          {'loss': 0.8465, 'learning_rate': 1.4027763965771993e-05, 'epoch': 0.39}
 39%|███▊      | 4023/10395 [11:30:53<15:11:54,  8.59s/it] 39%|███▊      | 4024/10395 [11:31:01<14:45:10,  8.34s/it]                                                          {'loss': 0.9364, 'learning_rate': 1.402491194570688e-05, 'epoch': 0.39}
 39%|███▊      | 4024/10395 [11:31:01<14:45:10,  8.34s/it] 39%|███▊      | 4025/10395 [11:31:10<15:34:52,  8.81s/it]                                                          {'loss': 0.9327, 'learning_rate': 1.4022059534911918e-05, 'epoch': 0.39}
 39%|███▊      | 4025/10395 [11:31:10<15:34:52,  8.81s/it] 39%|███▊      | 4026/10395 [11:31:18<14:49:19,  8.38s/it]                                                          {'loss': 0.9446, 'learning_rate': 1.4019206733664016e-05, 'epoch': 0.39}
 39%|███▊      | 4026/10395 [11:31:18<14:49:19,  8.38s/it] 39%|███▊      | 4027/10395 [11:31:26<14:36:51,  8.26s/it]                                                          {'loss': 0.9802, 'learning_rate': 1.4016353542240111e-05, 'epoch': 0.39}
 39%|███▊      | 4027/10395 [11:31:26<14:36:51,  8.26s/it] 39%|███▊      | 4028/10395 [11:31:33<13:59:33,  7.91s/it]                                                          {'loss': 0.9502, 'learning_rate': 1.4013499960917187e-05, 'epoch': 0.39}
 39%|███▊      | 4028/10395 [11:31:33<13:59:33,  7.91s/it] 39%|███▉      | 4029/10395 [11:31:49<18:25:09, 10.42s/it]                                                          {'loss': 0.3784, 'learning_rate': 1.4010645989972262e-05, 'epoch': 0.39}
 39%|███▉      | 4029/10395 [11:31:49<18:25:09, 10.42s/it] 39%|███▉      | 4030/10395 [11:31:57<16:54:33,  9.56s/it]                                                          {'loss': 0.9214, 'learning_rate': 1.4007791629682396e-05, 'epoch': 0.39}
 39%|███▉      | 4030/10395 [11:31:57<16:54:33,  9.56s/it] 39%|███▉      | 4031/10395 [11:32:05<16:06:44,  9.11s/it]                                                          {'loss': 0.9166, 'learning_rate': 1.4004936880324685e-05, 'epoch': 0.39}
 39%|███▉      | 4031/10395 [11:32:05<16:06:44,  9.11s/it] 39%|███▉      | 4032/10395 [11:32:13<15:49:49,  8.96s/it]                                                          {'loss': 0.9334, 'learning_rate': 1.400208174217626e-05, 'epoch': 0.39}
 39%|███▉      | 4032/10395 [11:32:13<15:49:49,  8.96s/it] 39%|███▉      | 4033/10395 [11:32:22<15:48:56,  8.95s/it]                                                          {'loss': 0.8911, 'learning_rate': 1.3999226215514288e-05, 'epoch': 0.39}
 39%|███▉      | 4033/10395 [11:32:22<15:48:56,  8.95s/it] 39%|███▉      | 4034/10395 [11:32:30<15:00:14,  8.49s/it]                                                          {'loss': 0.9309, 'learning_rate': 1.3996370300615984e-05, 'epoch': 0.39}
 39%|███▉      | 4034/10395 [11:32:30<15:00:14,  8.49s/it] 39%|███▉      | 4035/10395 [11:32:37<14:17:59,  8.09s/it]                                                          {'loss': 1.0328, 'learning_rate': 1.3993513997758592e-05, 'epoch': 0.39}
 39%|███▉      | 4035/10395 [11:32:37<14:17:59,  8.09s/it] 39%|███▉      | 4036/10395 [11:32:44<13:59:03,  7.92s/it]                                                          {'loss': 0.9739, 'learning_rate': 1.3990657307219396e-05, 'epoch': 0.39}
 39%|███▉      | 4036/10395 [11:32:44<13:59:03,  7.92s/it] 39%|███▉      | 4037/10395 [11:32:53<14:25:10,  8.16s/it]                                                          {'loss': 0.9252, 'learning_rate': 1.3987800229275713e-05, 'epoch': 0.39}
 39%|███▉      | 4037/10395 [11:32:53<14:25:10,  8.16s/it] 39%|███▉      | 4038/10395 [11:33:02<14:45:14,  8.36s/it]                                                          {'loss': 0.9104, 'learning_rate': 1.398494276420491e-05, 'epoch': 0.39}
 39%|███▉      | 4038/10395 [11:33:02<14:45:14,  8.36s/it] 39%|███▉      | 4039/10395 [11:33:09<14:12:20,  8.05s/it]                                                          {'loss': 0.9528, 'learning_rate': 1.3982084912284377e-05, 'epoch': 0.39}
 39%|███▉      | 4039/10395 [11:33:09<14:12:20,  8.05s/it] 39%|███▉      | 4040/10395 [11:33:17<14:11:24,  8.04s/it]                                                          {'loss': 0.908, 'learning_rate': 1.3979226673791551e-05, 'epoch': 0.39}
 39%|███▉      | 4040/10395 [11:33:17<14:11:24,  8.04s/it] 39%|███▉      | 4041/10395 [11:33:25<13:57:54,  7.91s/it]                                                          {'loss': 0.8794, 'learning_rate': 1.3976368049003903e-05, 'epoch': 0.39}
 39%|███▉      | 4041/10395 [11:33:25<13:57:54,  7.91s/it] 39%|███▉      | 4042/10395 [11:33:32<13:37:42,  7.72s/it]                                                          {'loss': 0.9523, 'learning_rate': 1.3973509038198942e-05, 'epoch': 0.39}
 39%|███▉      | 4042/10395 [11:33:32<13:37:42,  7.72s/it] 39%|███▉      | 4043/10395 [11:33:39<13:17:45,  7.54s/it]                                                          {'loss': 1.0159, 'learning_rate': 1.3970649641654217e-05, 'epoch': 0.39}
 39%|███▉      | 4043/10395 [11:33:39<13:17:45,  7.54s/it] 39%|███▉      | 4044/10395 [11:33:47<13:28:48,  7.64s/it]                                                          {'loss': 0.8419, 'learning_rate': 1.3967789859647308e-05, 'epoch': 0.39}
 39%|███▉      | 4044/10395 [11:33:47<13:28:48,  7.64s/it] 39%|███▉      | 4045/10395 [11:33:55<13:23:24,  7.59s/it]                                                          {'loss': 1.0064, 'learning_rate': 1.396492969245584e-05, 'epoch': 0.39}
 39%|███▉      | 4045/10395 [11:33:55<13:23:24,  7.59s/it] 39%|███▉      | 4046/10395 [11:34:03<13:45:14,  7.80s/it]                                                          {'loss': 0.9288, 'learning_rate': 1.3962069140357467e-05, 'epoch': 0.39}
 39%|███▉      | 4046/10395 [11:34:03<13:45:14,  7.80s/it] 39%|███▉      | 4047/10395 [11:34:10<13:28:46,  7.64s/it]                                                          {'loss': 0.9839, 'learning_rate': 1.3959208203629892e-05, 'epoch': 0.39}
 39%|███▉      | 4047/10395 [11:34:10<13:28:46,  7.64s/it] 39%|███▉      | 4048/10395 [11:34:18<13:40:34,  7.76s/it]                                                          {'loss': 0.908, 'learning_rate': 1.3956346882550846e-05, 'epoch': 0.39}
 39%|███▉      | 4048/10395 [11:34:18<13:40:34,  7.76s/it] 39%|███▉      | 4049/10395 [11:34:27<14:08:59,  8.03s/it]                                                          {'loss': 0.8666, 'learning_rate': 1.3953485177398098e-05, 'epoch': 0.39}
 39%|███▉      | 4049/10395 [11:34:27<14:08:59,  8.03s/it] 39%|███▉      | 4050/10395 [11:34:43<18:24:41, 10.45s/it]                                                          {'loss': 0.3573, 'learning_rate': 1.395062308844946e-05, 'epoch': 0.39}
 39%|███▉      | 4050/10395 [11:34:43<18:24:41, 10.45s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 39%|███▉      | 4051/10395 [11:36:24<66:16:30, 37.61s/it]                                                          {'loss': 0.9724, 'learning_rate': 1.394776061598277e-05, 'epoch': 0.39}
 39%|███▉      | 4051/10395 [11:36:24<66:16:30, 37.61s/it] 39%|███▉      | 4052/10395 [11:36:31<50:18:07, 28.55s/it]                                                          {'loss': 0.9357, 'learning_rate': 1.3944897760275922e-05, 'epoch': 0.39}
 39%|███▉      | 4052/10395 [11:36:31<50:18:07, 28.55s/it] 39%|███▉      | 4053/10395 [11:36:39<39:15:16, 22.28s/it]                                                          {'loss': 0.9867, 'learning_rate': 1.3942034521606824e-05, 'epoch': 0.39}
 39%|███▉      | 4053/10395 [11:36:39<39:15:16, 22.28s/it] 39%|███▉      | 4054/10395 [11:36:47<31:35:19, 17.93s/it]                                                          {'loss': 0.8125, 'learning_rate': 1.3939170900253442e-05, 'epoch': 0.39}
 39%|███▉      | 4054/10395 [11:36:47<31:35:19, 17.93s/it] 39%|███▉      | 4055/10395 [11:36:54<26:06:58, 14.83s/it]                                                          {'loss': 0.9827, 'learning_rate': 1.3936306896493768e-05, 'epoch': 0.39}
 39%|███▉      | 4055/10395 [11:36:54<26:06:58, 14.83s/it] 39%|███▉      | 4056/10395 [11:37:02<22:14:10, 12.63s/it]                                                          {'loss': 0.9193, 'learning_rate': 1.393344251060583e-05, 'epoch': 0.39}
 39%|███▉      | 4056/10395 [11:37:02<22:14:10, 12.63s/it] 39%|███▉      | 4057/10395 [11:37:10<19:37:13, 11.14s/it]                                                          {'loss': 0.9375, 'learning_rate': 1.3930577742867699e-05, 'epoch': 0.39}
 39%|███▉      | 4057/10395 [11:37:10<19:37:13, 11.14s/it] 39%|███▉      | 4058/10395 [11:37:17<17:48:57, 10.12s/it]                                                          {'loss': 0.9432, 'learning_rate': 1.392771259355748e-05, 'epoch': 0.39}
 39%|███▉      | 4058/10395 [11:37:17<17:48:57, 10.12s/it] 39%|███▉      | 4059/10395 [11:37:25<16:20:40,  9.29s/it]                                                          {'loss': 0.9474, 'learning_rate': 1.3924847062953318e-05, 'epoch': 0.39}
 39%|███▉      | 4059/10395 [11:37:25<16:20:40,  9.29s/it] 39%|███▉      | 4060/10395 [11:37:32<15:32:16,  8.83s/it]                                                          {'loss': 0.9956, 'learning_rate': 1.392198115133339e-05, 'epoch': 0.39}
 39%|███▉      | 4060/10395 [11:37:32<15:32:16,  8.83s/it] 39%|███▉      | 4061/10395 [11:37:49<19:45:56, 11.23s/it]                                                          {'loss': 0.3616, 'learning_rate': 1.3919114858975912e-05, 'epoch': 0.39}
 39%|███▉      | 4061/10395 [11:37:49<19:45:56, 11.23s/it] 39%|███▉      | 4062/10395 [11:37:57<17:40:59, 10.05s/it]                                                          {'loss': 0.9732, 'learning_rate': 1.3916248186159143e-05, 'epoch': 0.39}
 39%|███▉      | 4062/10395 [11:37:57<17:40:59, 10.05s/it] 39%|███▉      | 4063/10395 [11:38:04<16:23:57,  9.32s/it]                                                          {'loss': 0.9505, 'learning_rate': 1.3913381133161363e-05, 'epoch': 0.39}
 39%|███▉      | 4063/10395 [11:38:04<16:23:57,  9.32s/it] 39%|███▉      | 4064/10395 [11:38:12<15:43:34,  8.94s/it]                                                          {'loss': 0.9583, 'learning_rate': 1.3910513700260908e-05, 'epoch': 0.39}
 39%|███▉      | 4064/10395 [11:38:12<15:43:34,  8.94s/it] 39%|███▉      | 4065/10395 [11:38:20<15:02:18,  8.55s/it]                                                          {'loss': 0.9694, 'learning_rate': 1.3907645887736138e-05, 'epoch': 0.39}
 39%|███▉      | 4065/10395 [11:38:20<15:02:18,  8.55s/it] 39%|███▉      | 4066/10395 [11:38:28<14:52:59,  8.47s/it]                                                          {'loss': 0.9062, 'learning_rate': 1.390477769586546e-05, 'epoch': 0.39}
 39%|███▉      | 4066/10395 [11:38:28<14:52:59,  8.47s/it] 39%|███▉      | 4067/10395 [11:38:36<14:22:45,  8.18s/it]                                                          {'loss': 0.9176, 'learning_rate': 1.3901909124927305e-05, 'epoch': 0.39}
 39%|███▉      | 4067/10395 [11:38:36<14:22:45,  8.18s/it] 39%|███▉      | 4068/10395 [11:38:43<13:59:07,  7.96s/it]                                                          {'loss': 0.9406, 'learning_rate': 1.3899040175200152e-05, 'epoch': 0.39}
 39%|███▉      | 4068/10395 [11:38:43<13:59:07,  7.96s/it] 39%|███▉      | 4069/10395 [11:38:50<13:36:28,  7.74s/it]                                                          {'loss': 0.9433, 'learning_rate': 1.3896170846962508e-05, 'epoch': 0.39}
 39%|███▉      | 4069/10395 [11:38:50<13:36:28,  7.74s/it] 39%|███▉      | 4070/10395 [11:38:58<13:26:17,  7.65s/it]                                                          {'loss': 0.9987, 'learning_rate': 1.3893301140492929e-05, 'epoch': 0.39}
 39%|███▉      | 4070/10395 [11:38:58<13:26:17,  7.65s/it] 39%|███▉      | 4071/10395 [11:39:05<13:27:27,  7.66s/it]                                                          {'loss': 0.9999, 'learning_rate': 1.3890431056069991e-05, 'epoch': 0.39}
 39%|███▉      | 4071/10395 [11:39:05<13:27:27,  7.66s/it] 39%|███▉      | 4072/10395 [11:39:14<13:58:22,  7.96s/it]                                                          {'loss': 0.9215, 'learning_rate': 1.3887560593972323e-05, 'epoch': 0.39}
 39%|███▉      | 4072/10395 [11:39:14<13:58:22,  7.96s/it] 39%|███▉      | 4073/10395 [11:39:23<14:13:57,  8.10s/it]                                                          {'loss': 0.9194, 'learning_rate': 1.388468975447858e-05, 'epoch': 0.39}
 39%|███▉      | 4073/10395 [11:39:23<14:13:57,  8.10s/it] 39%|███▉      | 4074/10395 [11:39:30<13:53:16,  7.91s/it]                                                          {'loss': 1.03, 'learning_rate': 1.3881818537867455e-05, 'epoch': 0.39}
 39%|███▉      | 4074/10395 [11:39:30<13:53:16,  7.91s/it] 39%|███▉      | 4075/10395 [11:39:38<13:40:49,  7.79s/it]                                                          {'loss': 0.9526, 'learning_rate': 1.3878946944417682e-05, 'epoch': 0.39}
 39%|███▉      | 4075/10395 [11:39:38<13:40:49,  7.79s/it] 39%|███▉      | 4076/10395 [11:39:45<13:41:00,  7.80s/it]                                                          {'loss': 0.8974, 'learning_rate': 1.3876074974408029e-05, 'epoch': 0.39}
 39%|███▉      | 4076/10395 [11:39:45<13:41:00,  7.80s/it] 39%|███▉      | 4077/10395 [11:39:53<13:22:11,  7.62s/it]                                                          {'loss': 1.0206, 'learning_rate': 1.3873202628117306e-05, 'epoch': 0.39}
 39%|███▉      | 4077/10395 [11:39:53<13:22:11,  7.62s/it] 39%|███▉      | 4078/10395 [11:40:00<13:29:25,  7.69s/it]                                                          {'loss': 0.9614, 'learning_rate': 1.3870329905824345e-05, 'epoch': 0.39}
 39%|███▉      | 4078/10395 [11:40:00<13:29:25,  7.69s/it] 39%|███▉      | 4079/10395 [11:40:08<13:18:20,  7.58s/it]                                                          {'loss': 0.9201, 'learning_rate': 1.3867456807808024e-05, 'epoch': 0.39}
 39%|███▉      | 4079/10395 [11:40:08<13:18:20,  7.58s/it] 39%|███▉      | 4080/10395 [11:40:15<13:06:00,  7.47s/it]                                                          {'loss': 0.9425, 'learning_rate': 1.3864583334347263e-05, 'epoch': 0.39}
 39%|███▉      | 4080/10395 [11:40:15<13:06:00,  7.47s/it] 39%|███▉      | 4081/10395 [11:40:23<13:19:27,  7.60s/it]                                                          {'loss': 0.9163, 'learning_rate': 1.3861709485721016e-05, 'epoch': 0.39}
 39%|███▉      | 4081/10395 [11:40:23<13:19:27,  7.60s/it] 39%|███▉      | 4082/10395 [11:40:30<13:11:58,  7.53s/it]                                                          {'loss': 0.7946, 'learning_rate': 1.3858835262208259e-05, 'epoch': 0.39}
 39%|███▉      | 4082/10395 [11:40:30<13:11:58,  7.53s/it] 39%|███▉      | 4083/10395 [11:40:38<13:33:19,  7.73s/it]                                                          {'loss': 0.926, 'learning_rate': 1.3855960664088022e-05, 'epoch': 0.39}
 39%|███▉      | 4083/10395 [11:40:38<13:33:19,  7.73s/it] 39%|███▉      | 4084/10395 [11:40:47<13:54:11,  7.93s/it]                                                          {'loss': 0.9521, 'learning_rate': 1.3853085691639364e-05, 'epoch': 0.39}
 39%|███▉      | 4084/10395 [11:40:47<13:54:11,  7.93s/it] 39%|███▉      | 4085/10395 [11:40:54<13:45:30,  7.85s/it]                                                          {'loss': 0.9511, 'learning_rate': 1.3850210345141383e-05, 'epoch': 0.39}
 39%|███▉      | 4085/10395 [11:40:54<13:45:30,  7.85s/it] 39%|███▉      | 4086/10395 [11:41:02<13:46:40,  7.86s/it]                                                          {'loss': 0.9164, 'learning_rate': 1.3847334624873205e-05, 'epoch': 0.39}
 39%|███▉      | 4086/10395 [11:41:02<13:46:40,  7.86s/it] 39%|███▉      | 4087/10395 [11:41:10<13:49:39,  7.89s/it]                                                          {'loss': 0.9562, 'learning_rate': 1.3844458531114006e-05, 'epoch': 0.39}
 39%|███▉      | 4087/10395 [11:41:10<13:49:39,  7.89s/it] 39%|███▉      | 4088/10395 [11:41:18<13:38:22,  7.79s/it]                                                          {'loss': 0.9482, 'learning_rate': 1.3841582064142993e-05, 'epoch': 0.39}
 39%|███▉      | 4088/10395 [11:41:18<13:38:22,  7.79s/it] 39%|███▉      | 4089/10395 [11:41:26<13:34:17,  7.75s/it]                                                          {'loss': 0.9124, 'learning_rate': 1.3838705224239397e-05, 'epoch': 0.39}
 39%|███▉      | 4089/10395 [11:41:26<13:34:17,  7.75s/it] 39%|███▉      | 4090/10395 [11:41:35<14:15:12,  8.14s/it]                                                          {'loss': 0.9201, 'learning_rate': 1.38358280116825e-05, 'epoch': 0.39}
 39%|███▉      | 4090/10395 [11:41:35<14:15:12,  8.14s/it] 39%|███▉      | 4091/10395 [11:41:42<13:58:36,  7.98s/it]                                                          {'loss': 0.9333, 'learning_rate': 1.383295042675162e-05, 'epoch': 0.39}
 39%|███▉      | 4091/10395 [11:41:42<13:58:36,  7.98s/it] 39%|███▉      | 4092/10395 [11:41:49<13:33:57,  7.75s/it]                                                          {'loss': 0.9895, 'learning_rate': 1.3830072469726105e-05, 'epoch': 0.39}
 39%|███▉      | 4092/10395 [11:41:49<13:33:57,  7.75s/it] 39%|███▉      | 4093/10395 [11:41:58<13:57:08,  7.97s/it]                                                          {'loss': 0.8918, 'learning_rate': 1.382719414088534e-05, 'epoch': 0.39}
 39%|███▉      | 4093/10395 [11:41:58<13:57:08,  7.97s/it] 39%|███▉      | 4094/10395 [11:42:06<13:50:46,  7.91s/it]                                                          {'loss': 0.9541, 'learning_rate': 1.3824315440508742e-05, 'epoch': 0.39}
 39%|███▉      | 4094/10395 [11:42:06<13:50:46,  7.91s/it] 39%|███▉      | 4095/10395 [11:42:13<13:32:33,  7.74s/it]                                                          {'loss': 0.9461, 'learning_rate': 1.3821436368875779e-05, 'epoch': 0.39}
 39%|███▉      | 4095/10395 [11:42:13<13:32:33,  7.74s/it] 39%|███▉      | 4096/10395 [11:42:21<13:27:38,  7.69s/it]                                                          {'loss': 0.9893, 'learning_rate': 1.3818556926265935e-05, 'epoch': 0.39}
 39%|███▉      | 4096/10395 [11:42:21<13:27:38,  7.69s/it] 39%|███▉      | 4097/10395 [11:42:29<13:50:05,  7.91s/it]                                                          {'loss': 0.8787, 'learning_rate': 1.3815677112958748e-05, 'epoch': 0.39}
 39%|███▉      | 4097/10395 [11:42:29<13:50:05,  7.91s/it] 39%|███▉      | 4098/10395 [11:42:38<14:20:23,  8.20s/it]                                                          {'loss': 0.9387, 'learning_rate': 1.3812796929233776e-05, 'epoch': 0.39}
 39%|███▉      | 4098/10395 [11:42:38<14:20:23,  8.20s/it] 39%|███▉      | 4099/10395 [11:42:55<19:00:06, 10.87s/it]                                                          {'loss': 0.3795, 'learning_rate': 1.3809916375370633e-05, 'epoch': 0.39}
 39%|███▉      | 4099/10395 [11:42:55<19:00:06, 10.87s/it] 39%|███▉      | 4100/10395 [11:43:03<17:23:38,  9.95s/it]                                                          {'loss': 0.9304, 'learning_rate': 1.3807035451648948e-05, 'epoch': 0.39}
 39%|███▉      | 4100/10395 [11:43:03<17:23:38,  9.95s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 39%|███▉      | 4101/10395 [11:44:43<64:36:59, 36.96s/it]                                                          {'loss': 0.9024, 'learning_rate': 1.3804154158348395e-05, 'epoch': 0.39}
 39%|███▉      | 4101/10395 [11:44:43<64:36:59, 36.96s/it] 39%|███▉      | 4102/10395 [11:44:51<49:19:38, 28.22s/it]                                                          {'loss': 0.9725, 'learning_rate': 1.3801272495748683e-05, 'epoch': 0.39}
 39%|███▉      | 4102/10395 [11:44:51<49:19:38, 28.22s/it] 39%|███▉      | 4103/10395 [11:45:00<39:22:30, 22.53s/it]                                                          {'loss': 0.9082, 'learning_rate': 1.3798390464129568e-05, 'epoch': 0.39}
 39%|███▉      | 4103/10395 [11:45:00<39:22:30, 22.53s/it] 39%|███▉      | 4104/10395 [11:45:08<31:56:05, 18.27s/it]                                                          {'loss': 0.8743, 'learning_rate': 1.3795508063770819e-05, 'epoch': 0.39}
 39%|███▉      | 4104/10395 [11:45:08<31:56:05, 18.27s/it] 39%|███▉      | 4105/10395 [11:45:16<26:19:27, 15.07s/it]                                                          {'loss': 0.9314, 'learning_rate': 1.379262529495226e-05, 'epoch': 0.39}
 39%|███▉      | 4105/10395 [11:45:16<26:19:27, 15.07s/it] 39%|███▉      | 4106/10395 [11:45:23<22:25:40, 12.84s/it]                                                          {'loss': 0.9521, 'learning_rate': 1.3789742157953741e-05, 'epoch': 0.39}
 39%|███▉      | 4106/10395 [11:45:23<22:25:40, 12.84s/it] 40%|███▉      | 4107/10395 [11:45:31<19:39:52, 11.26s/it]                                                          {'loss': 0.8955, 'learning_rate': 1.3786858653055154e-05, 'epoch': 0.4}
 40%|███▉      | 4107/10395 [11:45:31<19:39:52, 11.26s/it] 40%|███▉      | 4108/10395 [11:45:38<17:36:42, 10.08s/it]                                                          {'loss': 1.0676, 'learning_rate': 1.3783974780536418e-05, 'epoch': 0.4}
 40%|███▉      | 4108/10395 [11:45:38<17:36:42, 10.08s/it] 40%|███▉      | 4109/10395 [11:45:47<16:42:34,  9.57s/it]                                                          {'loss': 0.9339, 'learning_rate': 1.37810905406775e-05, 'epoch': 0.4}
 40%|███▉      | 4109/10395 [11:45:47<16:42:34,  9.57s/it] 40%|███▉      | 4110/10395 [11:45:54<15:41:26,  8.99s/it]                                                          {'loss': 0.9017, 'learning_rate': 1.377820593375839e-05, 'epoch': 0.4}
 40%|███▉      | 4110/10395 [11:45:54<15:41:26,  8.99s/it] 40%|███▉      | 4111/10395 [11:46:02<14:53:38,  8.53s/it]                                                          {'loss': 0.9741, 'learning_rate': 1.3775320960059123e-05, 'epoch': 0.4}
 40%|███▉      | 4111/10395 [11:46:02<14:53:38,  8.53s/it] 40%|███▉      | 4112/10395 [11:46:09<14:18:47,  8.20s/it]                                                          {'loss': 0.9854, 'learning_rate': 1.3772435619859766e-05, 'epoch': 0.4}
 40%|███▉      | 4112/10395 [11:46:09<14:18:47,  8.20s/it] 40%|███▉      | 4113/10395 [11:46:17<13:57:37,  8.00s/it]                                                          {'loss': 0.9704, 'learning_rate': 1.3769549913440422e-05, 'epoch': 0.4}
 40%|███▉      | 4113/10395 [11:46:17<13:57:37,  8.00s/it] 40%|███▉      | 4114/10395 [11:46:34<18:49:03, 10.79s/it]                                                          {'loss': 0.4409, 'learning_rate': 1.3766663841081225e-05, 'epoch': 0.4}
 40%|███▉      | 4114/10395 [11:46:34<18:49:03, 10.79s/it] 40%|███▉      | 4115/10395 [11:46:43<17:46:21, 10.19s/it]                                                          {'loss': 0.8528, 'learning_rate': 1.376377740306235e-05, 'epoch': 0.4}
 40%|███▉      | 4115/10395 [11:46:43<17:46:21, 10.19s/it] 40%|███▉      | 4116/10395 [11:46:51<16:35:14,  9.51s/it]                                                          {'loss': 0.9886, 'learning_rate': 1.3760890599664012e-05, 'epoch': 0.4}
 40%|███▉      | 4116/10395 [11:46:51<16:35:14,  9.51s/it] 40%|███▉      | 4117/10395 [11:46:59<15:52:30,  9.10s/it]                                                          {'loss': 0.9418, 'learning_rate': 1.375800343116645e-05, 'epoch': 0.4}
 40%|███▉      | 4117/10395 [11:46:59<15:52:30,  9.10s/it] 40%|███▉      | 4118/10395 [11:47:16<20:08:53, 11.56s/it]                                                          {'loss': 0.4113, 'learning_rate': 1.3755115897849946e-05, 'epoch': 0.4}
 40%|███▉      | 4118/10395 [11:47:16<20:08:53, 11.56s/it] 40%|███▉      | 4119/10395 [11:47:24<18:08:31, 10.41s/it]                                                          {'loss': 0.967, 'learning_rate': 1.3752227999994816e-05, 'epoch': 0.4}
 40%|███▉      | 4119/10395 [11:47:24<18:08:31, 10.41s/it] 40%|███▉      | 4120/10395 [11:47:32<16:53:03,  9.69s/it]                                                          {'loss': 0.9667, 'learning_rate': 1.374933973788141e-05, 'epoch': 0.4}
 40%|███▉      | 4120/10395 [11:47:32<16:53:03,  9.69s/it] 40%|███▉      | 4121/10395 [11:47:40<16:02:47,  9.21s/it]                                                          {'loss': 0.8901, 'learning_rate': 1.3746451111790113e-05, 'epoch': 0.4}
 40%|███▉      | 4121/10395 [11:47:40<16:02:47,  9.21s/it] 40%|███▉      | 4122/10395 [11:47:47<15:07:37,  8.68s/it]                                                          {'loss': 0.9309, 'learning_rate': 1.374356212200135e-05, 'epoch': 0.4}
 40%|███▉      | 4122/10395 [11:47:47<15:07:37,  8.68s/it] 40%|███▉      | 4123/10395 [11:47:55<14:28:17,  8.31s/it]                                                          {'loss': 0.9604, 'learning_rate': 1.3740672768795576e-05, 'epoch': 0.4}
 40%|███▉      | 4123/10395 [11:47:55<14:28:17,  8.31s/it] 40%|███▉      | 4124/10395 [11:48:12<19:07:27, 10.98s/it]                                                          {'loss': 0.4017, 'learning_rate': 1.3737783052453284e-05, 'epoch': 0.4}
 40%|███▉      | 4124/10395 [11:48:12<19:07:27, 10.98s/it] 40%|███▉      | 4125/10395 [11:48:21<18:06:19, 10.40s/it]                                                          {'loss': 0.9187, 'learning_rate': 1.3734892973254998e-05, 'epoch': 0.4}
 40%|███▉      | 4125/10395 [11:48:21<18:06:19, 10.40s/it] 40%|███▉      | 4126/10395 [11:48:29<16:43:43,  9.61s/it]                                                          {'loss': 0.9256, 'learning_rate': 1.3732002531481287e-05, 'epoch': 0.4}
 40%|███▉      | 4126/10395 [11:48:29<16:43:43,  9.61s/it] 40%|███▉      | 4127/10395 [11:48:37<15:50:04,  9.09s/it]                                                          {'loss': 0.8885, 'learning_rate': 1.3729111727412744e-05, 'epoch': 0.4}
 40%|███▉      | 4127/10395 [11:48:37<15:50:04,  9.09s/it] 40%|███▉      | 4128/10395 [11:48:45<15:19:07,  8.80s/it]                                                          {'loss': 0.9491, 'learning_rate': 1.3726220561330004e-05, 'epoch': 0.4}
 40%|███▉      | 4128/10395 [11:48:45<15:19:07,  8.80s/it] 40%|███▉      | 4129/10395 [11:48:53<14:49:19,  8.52s/it]                                                          {'loss': 0.9061, 'learning_rate': 1.3723329033513735e-05, 'epoch': 0.4}
 40%|███▉      | 4129/10395 [11:48:53<14:49:19,  8.52s/it] 40%|███▉      | 4130/10395 [11:49:00<14:20:59,  8.25s/it]                                                          {'loss': 0.9651, 'learning_rate': 1.372043714424464e-05, 'epoch': 0.4}
 40%|███▉      | 4130/10395 [11:49:00<14:20:59,  8.25s/it] 40%|███▉      | 4131/10395 [11:49:08<14:12:42,  8.17s/it]                                                          {'loss': 0.9374, 'learning_rate': 1.3717544893803458e-05, 'epoch': 0.4}
 40%|███▉      | 4131/10395 [11:49:08<14:12:42,  8.17s/it] 40%|███▉      | 4132/10395 [11:49:16<14:09:49,  8.14s/it]                                                          {'loss': 0.8843, 'learning_rate': 1.3714652282470961e-05, 'epoch': 0.4}
 40%|███▉      | 4132/10395 [11:49:16<14:09:49,  8.14s/it] 40%|███▉      | 4133/10395 [11:49:24<13:57:02,  8.02s/it]                                                          {'loss': 0.9352, 'learning_rate': 1.3711759310527961e-05, 'epoch': 0.4}
 40%|███▉      | 4133/10395 [11:49:24<13:57:02,  8.02s/it] 40%|███▉      | 4134/10395 [11:49:32<13:43:39,  7.89s/it]                                                          {'loss': 0.9134, 'learning_rate': 1.3708865978255298e-05, 'epoch': 0.4}
 40%|███▉      | 4134/10395 [11:49:32<13:43:39,  7.89s/it] 40%|███▉      | 4135/10395 [11:49:40<13:48:31,  7.94s/it]                                                          {'loss': 0.8757, 'learning_rate': 1.3705972285933851e-05, 'epoch': 0.4}
 40%|███▉      | 4135/10395 [11:49:40<13:48:31,  7.94s/it] 40%|███▉      | 4136/10395 [11:49:48<14:04:00,  8.09s/it]                                                          {'loss': 0.9253, 'learning_rate': 1.3703078233844534e-05, 'epoch': 0.4}
 40%|███▉      | 4136/10395 [11:49:48<14:04:00,  8.09s/it] 40%|███▉      | 4137/10395 [11:49:58<14:55:55,  8.59s/it]                                                          {'loss': 0.8941, 'learning_rate': 1.3700183822268296e-05, 'epoch': 0.4}
 40%|███▉      | 4137/10395 [11:49:58<14:55:55,  8.59s/it] 40%|███▉      | 4138/10395 [11:50:06<14:27:01,  8.31s/it]                                                          {'loss': 0.9502, 'learning_rate': 1.369728905148612e-05, 'epoch': 0.4}
 40%|███▉      | 4138/10395 [11:50:06<14:27:01,  8.31s/it] 40%|███▉      | 4139/10395 [11:50:13<13:56:46,  8.03s/it]                                                          {'loss': 0.9385, 'learning_rate': 1.3694393921779024e-05, 'epoch': 0.4}
 40%|███▉      | 4139/10395 [11:50:13<13:56:46,  8.03s/it] 40%|███▉      | 4140/10395 [11:50:21<13:53:03,  7.99s/it]                                                          {'loss': 0.9436, 'learning_rate': 1.369149843342806e-05, 'epoch': 0.4}
 40%|███▉      | 4140/10395 [11:50:21<13:53:03,  7.99s/it] 40%|███▉      | 4141/10395 [11:50:29<13:55:35,  8.02s/it]                                                          {'loss': 0.9758, 'learning_rate': 1.3688602586714319e-05, 'epoch': 0.4}
 40%|███▉      | 4141/10395 [11:50:29<13:55:35,  8.02s/it] 40%|███▉      | 4142/10395 [11:50:36<13:38:44,  7.86s/it]                                                          {'loss': 0.9215, 'learning_rate': 1.368570638191892e-05, 'epoch': 0.4}
 40%|███▉      | 4142/10395 [11:50:36<13:38:44,  7.86s/it] 40%|███▉      | 4143/10395 [11:50:45<13:43:47,  7.91s/it]                                                          {'loss': 0.9731, 'learning_rate': 1.3682809819323023e-05, 'epoch': 0.4}
 40%|███▉      | 4143/10395 [11:50:45<13:43:47,  7.91s/it] 40%|███▉      | 4144/10395 [11:51:01<18:26:20, 10.62s/it]                                                          {'loss': 0.3733, 'learning_rate': 1.3679912899207817e-05, 'epoch': 0.4}
 40%|███▉      | 4144/10395 [11:51:01<18:26:20, 10.62s/it] 40%|███▉      | 4145/10395 [11:51:09<16:37:20,  9.57s/it]                                                          {'loss': 1.0559, 'learning_rate': 1.3677015621854533e-05, 'epoch': 0.4}
 40%|███▉      | 4145/10395 [11:51:09<16:37:20,  9.57s/it] 40%|███▉      | 4146/10395 [11:51:17<15:52:33,  9.15s/it]                                                          {'loss': 0.9607, 'learning_rate': 1.3674117987544429e-05, 'epoch': 0.4}
 40%|███▉      | 4146/10395 [11:51:17<15:52:33,  9.15s/it] 40%|███▉      | 4147/10395 [11:51:24<15:08:41,  8.73s/it]                                                          {'loss': 0.8959, 'learning_rate': 1.3671219996558805e-05, 'epoch': 0.4}
 40%|███▉      | 4147/10395 [11:51:24<15:08:41,  8.73s/it] 40%|███▉      | 4148/10395 [11:51:32<14:39:36,  8.45s/it]                                                          {'loss': 0.9114, 'learning_rate': 1.3668321649178983e-05, 'epoch': 0.4}
 40%|███▉      | 4148/10395 [11:51:32<14:39:36,  8.45s/it] 40%|███▉      | 4149/10395 [11:51:40<14:17:51,  8.24s/it]                                                          {'loss': 1.0751, 'learning_rate': 1.3665422945686339e-05, 'epoch': 0.4}
 40%|███▉      | 4149/10395 [11:51:40<14:17:51,  8.24s/it] 40%|███▉      | 4150/10395 [11:51:48<13:53:15,  8.01s/it]                                                          {'loss': 0.9541, 'learning_rate': 1.3662523886362267e-05, 'epoch': 0.4}
 40%|███▉      | 4150/10395 [11:51:48<13:53:15,  8.01s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 40%|███▉      | 4151/10395 [11:53:38<67:09:28, 38.72s/it]                                                          {'loss': 0.3807, 'learning_rate': 1.3659624471488206e-05, 'epoch': 0.4}
 40%|███▉      | 4151/10395 [11:53:38<67:09:28, 38.72s/it] 40%|███▉      | 4152/10395 [11:53:45<50:50:43, 29.32s/it]                                                          {'loss': 0.9207, 'learning_rate': 1.3656724701345616e-05, 'epoch': 0.4}
 40%|███▉      | 4152/10395 [11:53:45<50:50:43, 29.32s/it] 40%|███▉      | 4153/10395 [11:53:53<39:46:56, 22.94s/it]                                                          {'loss': 0.935, 'learning_rate': 1.3653824576216011e-05, 'epoch': 0.4}
 40%|███▉      | 4153/10395 [11:53:53<39:46:56, 22.94s/it] 40%|███▉      | 4154/10395 [11:54:03<32:37:56, 18.82s/it]                                                          {'loss': 0.928, 'learning_rate': 1.3650924096380927e-05, 'epoch': 0.4}
 40%|███▉      | 4154/10395 [11:54:03<32:37:56, 18.82s/it] 40%|███▉      | 4155/10395 [11:54:11<27:06:41, 15.64s/it]                                                          {'loss': 0.985, 'learning_rate': 1.3648023262121925e-05, 'epoch': 0.4}
 40%|███▉      | 4155/10395 [11:54:11<27:06:41, 15.64s/it] 40%|███▉      | 4156/10395 [11:54:28<27:56:39, 16.12s/it]                                                          {'loss': 0.4025, 'learning_rate': 1.3645122073720628e-05, 'epoch': 0.4}
 40%|███▉      | 4156/10395 [11:54:28<27:56:39, 16.12s/it] 40%|███▉      | 4157/10395 [11:54:36<23:32:11, 13.58s/it]                                                          {'loss': 0.9558, 'learning_rate': 1.3642220531458667e-05, 'epoch': 0.4}
 40%|███▉      | 4157/10395 [11:54:36<23:32:11, 13.58s/it] 40%|████      | 4158/10395 [11:54:43<20:27:14, 11.81s/it]                                                          {'loss': 0.9755, 'learning_rate': 1.3639318635617722e-05, 'epoch': 0.4}
 40%|████      | 4158/10395 [11:54:43<20:27:14, 11.81s/it] 40%|████      | 4159/10395 [11:54:51<18:21:37, 10.60s/it]                                                          {'loss': 0.918, 'learning_rate': 1.3636416386479498e-05, 'epoch': 0.4}
 40%|████      | 4159/10395 [11:54:51<18:21:37, 10.60s/it] 40%|████      | 4160/10395 [11:54:59<17:10:01,  9.91s/it]                                                          {'loss': 0.9031, 'learning_rate': 1.3633513784325744e-05, 'epoch': 0.4}
 40%|████      | 4160/10395 [11:54:59<17:10:01,  9.91s/it] 40%|████      | 4161/10395 [11:55:08<16:36:15,  9.59s/it]                                                          {'loss': 0.9091, 'learning_rate': 1.3630610829438235e-05, 'epoch': 0.4}
 40%|████      | 4161/10395 [11:55:08<16:36:15,  9.59s/it] 40%|████      | 4162/10395 [11:55:16<15:49:32,  9.14s/it]                                                          {'loss': 0.944, 'learning_rate': 1.3627707522098792e-05, 'epoch': 0.4}
 40%|████      | 4162/10395 [11:55:16<15:49:32,  9.14s/it] 40%|████      | 4163/10395 [11:55:25<15:20:53,  8.87s/it]                                                          {'loss': 0.9182, 'learning_rate': 1.3624803862589246e-05, 'epoch': 0.4}
 40%|████      | 4163/10395 [11:55:25<15:20:53,  8.87s/it] 40%|████      | 4164/10395 [11:55:33<14:55:54,  8.63s/it]                                                          {'loss': 0.9014, 'learning_rate': 1.3621899851191494e-05, 'epoch': 0.4}
 40%|████      | 4164/10395 [11:55:33<14:55:54,  8.63s/it] 40%|████      | 4165/10395 [11:55:40<14:22:18,  8.30s/it]                                                          {'loss': 0.9963, 'learning_rate': 1.3618995488187443e-05, 'epoch': 0.4}
 40%|████      | 4165/10395 [11:55:40<14:22:18,  8.30s/it] 40%|████      | 4166/10395 [11:55:48<13:57:18,  8.07s/it]                                                          {'loss': 0.9481, 'learning_rate': 1.361609077385904e-05, 'epoch': 0.4}
 40%|████      | 4166/10395 [11:55:48<13:57:18,  8.07s/it] 40%|████      | 4167/10395 [11:55:56<14:03:47,  8.13s/it]                                                          {'loss': 0.9257, 'learning_rate': 1.3613185708488275e-05, 'epoch': 0.4}
 40%|████      | 4167/10395 [11:55:56<14:03:47,  8.13s/it] 40%|████      | 4168/10395 [11:56:04<13:47:25,  7.97s/it]                                                          {'loss': 0.9312, 'learning_rate': 1.3610280292357163e-05, 'epoch': 0.4}
 40%|████      | 4168/10395 [11:56:04<13:47:25,  7.97s/it] 40%|████      | 4169/10395 [11:56:11<13:39:18,  7.90s/it]                                                          {'loss': 0.9645, 'learning_rate': 1.3607374525747758e-05, 'epoch': 0.4}
 40%|████      | 4169/10395 [11:56:11<13:39:18,  7.90s/it] 40%|████      | 4170/10395 [11:56:19<13:18:53,  7.70s/it]                                                          {'loss': 0.9261, 'learning_rate': 1.360446840894214e-05, 'epoch': 0.4}
 40%|████      | 4170/10395 [11:56:19<13:18:53,  7.70s/it] 40%|████      | 4171/10395 [11:56:26<13:14:34,  7.66s/it]                                                          {'loss': 0.9423, 'learning_rate': 1.360156194222243e-05, 'epoch': 0.4}
 40%|████      | 4171/10395 [11:56:26<13:14:34,  7.66s/it] 40%|████      | 4172/10395 [11:56:44<18:22:54, 10.63s/it]                                                          {'loss': 0.4021, 'learning_rate': 1.3598655125870783e-05, 'epoch': 0.4}
 40%|████      | 4172/10395 [11:56:44<18:22:54, 10.63s/it] 40%|████      | 4173/10395 [11:56:51<16:39:58,  9.64s/it]                                                          {'loss': 0.9543, 'learning_rate': 1.3595747960169393e-05, 'epoch': 0.4}
 40%|████      | 4173/10395 [11:56:51<16:39:58,  9.64s/it] 40%|████      | 4174/10395 [11:56:59<15:58:14,  9.24s/it]                                                          {'loss': 0.9609, 'learning_rate': 1.359284044540047e-05, 'epoch': 0.4}
 40%|████      | 4174/10395 [11:56:59<15:58:14,  9.24s/it] 40%|████      | 4175/10395 [11:57:07<15:18:18,  8.86s/it]                                                          {'loss': 0.938, 'learning_rate': 1.3589932581846275e-05, 'epoch': 0.4}
 40%|████      | 4175/10395 [11:57:07<15:18:18,  8.86s/it] 40%|████      | 4176/10395 [11:57:16<15:12:09,  8.80s/it]                                                          {'loss': 0.9928, 'learning_rate': 1.3587024369789097e-05, 'epoch': 0.4}
 40%|████      | 4176/10395 [11:57:16<15:12:09,  8.80s/it] 40%|████      | 4177/10395 [11:57:24<14:48:34,  8.57s/it]                                                          {'loss': 0.8217, 'learning_rate': 1.358411580951126e-05, 'epoch': 0.4}
 40%|████      | 4177/10395 [11:57:24<14:48:34,  8.57s/it] 40%|████      | 4178/10395 [11:57:31<14:07:21,  8.18s/it]                                                          {'loss': 0.9737, 'learning_rate': 1.3581206901295119e-05, 'epoch': 0.4}
 40%|████      | 4178/10395 [11:57:31<14:07:21,  8.18s/it] 40%|████      | 4179/10395 [11:57:39<13:52:30,  8.04s/it]                                                          {'loss': 1.0248, 'learning_rate': 1.3578297645423062e-05, 'epoch': 0.4}
 40%|████      | 4179/10395 [11:57:39<13:52:30,  8.04s/it] 40%|████      | 4180/10395 [11:57:47<13:47:02,  7.98s/it]                                                          {'loss': 0.9007, 'learning_rate': 1.357538804217752e-05, 'epoch': 0.4}
 40%|████      | 4180/10395 [11:57:47<13:47:02,  7.98s/it] 40%|████      | 4181/10395 [11:57:55<13:39:16,  7.91s/it]                                                          {'loss': 0.9377, 'learning_rate': 1.3572478091840946e-05, 'epoch': 0.4}
 40%|████      | 4181/10395 [11:57:55<13:39:16,  7.91s/it] 40%|████      | 4182/10395 [11:58:02<13:26:00,  7.78s/it]                                                          {'loss': 0.9371, 'learning_rate': 1.3569567794695835e-05, 'epoch': 0.4}
 40%|████      | 4182/10395 [11:58:02<13:26:00,  7.78s/it] 40%|████      | 4183/10395 [11:58:10<13:20:37,  7.73s/it]                                                          {'loss': 0.9559, 'learning_rate': 1.3566657151024706e-05, 'epoch': 0.4}
 40%|████      | 4183/10395 [11:58:10<13:20:37,  7.73s/it] 40%|████      | 4184/10395 [11:58:27<18:16:11, 10.59s/it]                                                          {'loss': 0.4296, 'learning_rate': 1.356374616111013e-05, 'epoch': 0.4}
 40%|████      | 4184/10395 [11:58:27<18:16:11, 10.59s/it] 40%|████      | 4185/10395 [11:58:36<17:18:23, 10.03s/it]                                                          {'loss': 1.0005, 'learning_rate': 1.3560834825234689e-05, 'epoch': 0.4}
 40%|████      | 4185/10395 [11:58:36<17:18:23, 10.03s/it] 40%|████      | 4186/10395 [11:58:43<16:00:39,  9.28s/it]                                                          {'loss': 0.9422, 'learning_rate': 1.355792314368101e-05, 'epoch': 0.4}
 40%|████      | 4186/10395 [11:58:43<16:00:39,  9.28s/it] 40%|████      | 4187/10395 [11:58:50<14:53:52,  8.64s/it]                                                          {'loss': 0.9403, 'learning_rate': 1.3555011116731758e-05, 'epoch': 0.4}
 40%|████      | 4187/10395 [11:58:50<14:53:52,  8.64s/it] 40%|████      | 4188/10395 [11:58:58<14:14:36,  8.26s/it]                                                          {'loss': 0.9735, 'learning_rate': 1.3552098744669624e-05, 'epoch': 0.4}
 40%|████      | 4188/10395 [11:58:58<14:14:36,  8.26s/it] 40%|████      | 4189/10395 [11:59:06<14:08:16,  8.20s/it]                                                          {'loss': 0.9918, 'learning_rate': 1.3549186027777335e-05, 'epoch': 0.4}
 40%|████      | 4189/10395 [11:59:06<14:08:16,  8.20s/it] 40%|████      | 4190/10395 [11:59:21<17:56:23, 10.41s/it]                                                          {'loss': 0.3529, 'learning_rate': 1.3546272966337647e-05, 'epoch': 0.4}
 40%|████      | 4190/10395 [11:59:21<17:56:23, 10.41s/it] 40%|████      | 4191/10395 [11:59:29<16:46:21,  9.73s/it]                                                          {'loss': 0.9379, 'learning_rate': 1.3543359560633365e-05, 'epoch': 0.4}
 40%|████      | 4191/10395 [11:59:29<16:46:21,  9.73s/it] 40%|████      | 4192/10395 [11:59:37<15:34:15,  9.04s/it]                                                          {'loss': 0.8882, 'learning_rate': 1.3540445810947305e-05, 'epoch': 0.4}
 40%|████      | 4192/10395 [11:59:37<15:34:15,  9.04s/it] 40%|████      | 4193/10395 [11:59:45<15:13:38,  8.84s/it]                                                          {'loss': 0.899, 'learning_rate': 1.3537531717562332e-05, 'epoch': 0.4}
 40%|████      | 4193/10395 [11:59:45<15:13:38,  8.84s/it] 40%|████      | 4194/10395 [11:59:54<14:55:35,  8.67s/it]                                                          {'loss': 0.8818, 'learning_rate': 1.3534617280761334e-05, 'epoch': 0.4}
 40%|████      | 4194/10395 [11:59:54<14:55:35,  8.67s/it] 40%|████      | 4195/10395 [12:00:01<14:29:32,  8.41s/it]                                                          {'loss': 0.9169, 'learning_rate': 1.3531702500827253e-05, 'epoch': 0.4}
 40%|████      | 4195/10395 [12:00:01<14:29:32,  8.41s/it] 40%|████      | 4196/10395 [12:00:09<14:09:07,  8.22s/it]                                                          {'loss': 1.0219, 'learning_rate': 1.3528787378043038e-05, 'epoch': 0.4}
 40%|████      | 4196/10395 [12:00:09<14:09:07,  8.22s/it] 40%|████      | 4197/10395 [12:00:17<13:43:35,  7.97s/it]                                                          {'loss': 0.9298, 'learning_rate': 1.3525871912691683e-05, 'epoch': 0.4}
 40%|████      | 4197/10395 [12:00:17<13:43:35,  7.97s/it] 40%|████      | 4198/10395 [12:00:24<13:39:13,  7.93s/it]                                                          {'loss': 0.9183, 'learning_rate': 1.352295610505622e-05, 'epoch': 0.4}
 40%|████      | 4198/10395 [12:00:24<13:39:13,  7.93s/it] 40%|████      | 4199/10395 [12:00:32<13:36:37,  7.91s/it]                                                          {'loss': 0.9394, 'learning_rate': 1.3520039955419706e-05, 'epoch': 0.4}
 40%|████      | 4199/10395 [12:00:32<13:36:37,  7.91s/it] 40%|████      | 4200/10395 [12:00:40<13:32:59,  7.87s/it]                                                          {'loss': 0.9159, 'learning_rate': 1.3517123464065234e-05, 'epoch': 0.4}
 40%|████      | 4200/10395 [12:00:40<13:32:59,  7.87s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 40%|████      | 4201/10395 [12:02:21<61:30:31, 35.75s/it]                                                          {'loss': 0.9582, 'learning_rate': 1.3514206631275934e-05, 'epoch': 0.4}
 40%|████      | 4201/10395 [12:02:21<61:30:31, 35.75s/it] 40%|████      | 4202/10395 [12:02:28<46:48:09, 27.21s/it]                                                          {'loss': 0.9755, 'learning_rate': 1.3511289457334964e-05, 'epoch': 0.4}
 40%|████      | 4202/10395 [12:02:28<46:48:09, 27.21s/it] 40%|████      | 4203/10395 [12:02:37<37:06:37, 21.58s/it]                                                          {'loss': 0.94, 'learning_rate': 1.3508371942525516e-05, 'epoch': 0.4}
 40%|████      | 4203/10395 [12:02:37<37:06:37, 21.58s/it] 40%|████      | 4204/10395 [12:02:44<29:56:43, 17.41s/it]                                                          {'loss': 0.9328, 'learning_rate': 1.3505454087130819e-05, 'epoch': 0.4}
 40%|████      | 4204/10395 [12:02:44<29:56:43, 17.41s/it] 40%|████      | 4205/10395 [12:02:52<24:52:26, 14.47s/it]                                                          {'loss': 0.8983, 'learning_rate': 1.3502535891434127e-05, 'epoch': 0.4}
 40%|████      | 4205/10395 [12:02:52<24:52:26, 14.47s/it] 40%|████      | 4206/10395 [12:03:00<21:27:26, 12.48s/it]                                                          {'loss': 0.9365, 'learning_rate': 1.3499617355718739e-05, 'epoch': 0.4}
 40%|████      | 4206/10395 [12:03:00<21:27:26, 12.48s/it] 40%|████      | 4207/10395 [12:03:07<18:55:21, 11.01s/it]                                                          {'loss': 0.9256, 'learning_rate': 1.3496698480267976e-05, 'epoch': 0.4}
 40%|████      | 4207/10395 [12:03:07<18:55:21, 11.01s/it] 40%|████      | 4208/10395 [12:03:15<17:18:30, 10.07s/it]                                                          {'loss': 0.9173, 'learning_rate': 1.3493779265365197e-05, 'epoch': 0.4}
 40%|████      | 4208/10395 [12:03:15<17:18:30, 10.07s/it] 40%|████      | 4209/10395 [12:03:23<16:08:22,  9.39s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.3490859711293794e-05, 'epoch': 0.4}
 40%|████      | 4209/10395 [12:03:23<16:08:22,  9.39s/it] 41%|████      | 4210/10395 [12:03:30<15:09:16,  8.82s/it]                                                          {'loss': 0.8605, 'learning_rate': 1.3487939818337185e-05, 'epoch': 0.4}
 41%|████      | 4210/10395 [12:03:30<15:09:16,  8.82s/it] 41%|████      | 4211/10395 [12:03:38<14:24:10,  8.38s/it]                                                          {'loss': 0.9277, 'learning_rate': 1.3485019586778838e-05, 'epoch': 0.41}
 41%|████      | 4211/10395 [12:03:38<14:24:10,  8.38s/it] 41%|████      | 4212/10395 [12:03:46<14:17:34,  8.32s/it]                                                          {'loss': 0.9234, 'learning_rate': 1.3482099016902234e-05, 'epoch': 0.41}
 41%|████      | 4212/10395 [12:03:46<14:17:34,  8.32s/it] 41%|████      | 4213/10395 [12:03:54<14:23:44,  8.38s/it]                                                          {'loss': 0.8714, 'learning_rate': 1.34791781089909e-05, 'epoch': 0.41}
 41%|████      | 4213/10395 [12:03:54<14:23:44,  8.38s/it] 41%|████      | 4214/10395 [12:04:03<14:21:07,  8.36s/it]                                                          {'loss': 0.9045, 'learning_rate': 1.3476256863328392e-05, 'epoch': 0.41}
 41%|████      | 4214/10395 [12:04:03<14:21:07,  8.36s/it] 41%|████      | 4215/10395 [12:04:10<13:41:24,  7.97s/it]                                                          {'loss': 1.0411, 'learning_rate': 1.3473335280198295e-05, 'epoch': 0.41}
 41%|████      | 4215/10395 [12:04:10<13:41:24,  7.97s/it] 41%|████      | 4216/10395 [12:04:17<13:22:14,  7.79s/it]                                                          {'loss': 0.9979, 'learning_rate': 1.3470413359884231e-05, 'epoch': 0.41}
 41%|████      | 4216/10395 [12:04:17<13:22:14,  7.79s/it] 41%|████      | 4217/10395 [12:04:26<13:47:57,  8.04s/it]                                                          {'loss': 0.914, 'learning_rate': 1.3467491102669854e-05, 'epoch': 0.41}
 41%|████      | 4217/10395 [12:04:26<13:47:57,  8.04s/it] 41%|████      | 4218/10395 [12:04:33<13:31:22,  7.88s/it]                                                          {'loss': 0.932, 'learning_rate': 1.3464568508838852e-05, 'epoch': 0.41}
 41%|████      | 4218/10395 [12:04:33<13:31:22,  7.88s/it] 41%|████      | 4219/10395 [12:04:41<13:22:44,  7.80s/it]                                                          {'loss': 0.8629, 'learning_rate': 1.3461645578674942e-05, 'epoch': 0.41}
 41%|████      | 4219/10395 [12:04:41<13:22:44,  7.80s/it] 41%|████      | 4220/10395 [12:04:57<17:33:49, 10.24s/it]                                                          {'loss': 0.3685, 'learning_rate': 1.3458722312461876e-05, 'epoch': 0.41}
 41%|████      | 4220/10395 [12:04:57<17:33:49, 10.24s/it] 41%|████      | 4221/10395 [12:05:05<16:13:20,  9.46s/it]                                                          {'loss': 1.0266, 'learning_rate': 1.345579871048344e-05, 'epoch': 0.41}
 41%|████      | 4221/10395 [12:05:05<16:13:20,  9.46s/it] 41%|████      | 4222/10395 [12:05:12<14:57:19,  8.72s/it]                                                          {'loss': 0.9655, 'learning_rate': 1.3452874773023452e-05, 'epoch': 0.41}
 41%|████      | 4222/10395 [12:05:12<14:57:19,  8.72s/it] 41%|████      | 4223/10395 [12:05:20<14:54:27,  8.70s/it]                                                          {'loss': 0.9546, 'learning_rate': 1.3449950500365759e-05, 'epoch': 0.41}
 41%|████      | 4223/10395 [12:05:20<14:54:27,  8.70s/it] 41%|████      | 4224/10395 [12:05:29<14:44:40,  8.60s/it]                                                          {'loss': 0.965, 'learning_rate': 1.3447025892794243e-05, 'epoch': 0.41}
 41%|████      | 4224/10395 [12:05:29<14:44:40,  8.60s/it] 41%|████      | 4225/10395 [12:05:36<14:15:48,  8.32s/it]                                                          {'loss': 0.9512, 'learning_rate': 1.344410095059282e-05, 'epoch': 0.41}
 41%|████      | 4225/10395 [12:05:36<14:15:48,  8.32s/it] 41%|████      | 4226/10395 [12:05:44<13:58:11,  8.15s/it]                                                          {'loss': 0.9164, 'learning_rate': 1.3441175674045437e-05, 'epoch': 0.41}
 41%|████      | 4226/10395 [12:05:44<13:58:11,  8.15s/it] 41%|████      | 4227/10395 [12:05:52<13:46:48,  8.04s/it]                                                          {'loss': 0.9748, 'learning_rate': 1.3438250063436074e-05, 'epoch': 0.41}
 41%|████      | 4227/10395 [12:05:52<13:46:48,  8.04s/it] 41%|████      | 4228/10395 [12:05:59<13:29:34,  7.88s/it]                                                          {'loss': 0.9645, 'learning_rate': 1.343532411904874e-05, 'epoch': 0.41}
 41%|████      | 4228/10395 [12:05:59<13:29:34,  7.88s/it] 41%|████      | 4229/10395 [12:06:08<14:04:04,  8.21s/it]                                                          {'loss': 0.8319, 'learning_rate': 1.3432397841167483e-05, 'epoch': 0.41}
 41%|████      | 4229/10395 [12:06:08<14:04:04,  8.21s/it] 41%|████      | 4230/10395 [12:06:16<13:38:21,  7.96s/it]                                                          {'loss': 0.9559, 'learning_rate': 1.3429471230076381e-05, 'epoch': 0.41}
 41%|████      | 4230/10395 [12:06:16<13:38:21,  7.96s/it] 41%|████      | 4231/10395 [12:06:24<14:00:51,  8.18s/it]                                                          {'loss': 0.8977, 'learning_rate': 1.342654428605954e-05, 'epoch': 0.41}
 41%|████      | 4231/10395 [12:06:24<14:00:51,  8.18s/it] 41%|████      | 4232/10395 [12:06:32<13:52:27,  8.10s/it]                                                          {'loss': 0.9447, 'learning_rate': 1.34236170094011e-05, 'epoch': 0.41}
 41%|████      | 4232/10395 [12:06:32<13:52:27,  8.10s/it] 41%|████      | 4233/10395 [12:06:40<13:49:12,  8.07s/it]                                                          {'loss': 0.9865, 'learning_rate': 1.3420689400385239e-05, 'epoch': 0.41}
 41%|████      | 4233/10395 [12:06:40<13:49:12,  8.07s/it] 41%|████      | 4234/10395 [12:06:48<13:33:29,  7.92s/it]                                                          {'loss': 1.0139, 'learning_rate': 1.3417761459296159e-05, 'epoch': 0.41}
 41%|████      | 4234/10395 [12:06:48<13:33:29,  7.92s/it] 41%|████      | 4235/10395 [12:06:55<13:22:30,  7.82s/it]                                                          {'loss': 0.9089, 'learning_rate': 1.3414833186418104e-05, 'epoch': 0.41}
 41%|████      | 4235/10395 [12:06:55<13:22:30,  7.82s/it] 41%|████      | 4236/10395 [12:07:03<13:25:37,  7.85s/it]                                                          {'loss': 0.9929, 'learning_rate': 1.3411904582035336e-05, 'epoch': 0.41}
 41%|████      | 4236/10395 [12:07:03<13:25:37,  7.85s/it] 41%|████      | 4237/10395 [12:07:11<13:28:33,  7.88s/it]                                                          {'loss': 0.9089, 'learning_rate': 1.3408975646432164e-05, 'epoch': 0.41}
 41%|████      | 4237/10395 [12:07:11<13:28:33,  7.88s/it] 41%|████      | 4238/10395 [12:07:19<13:14:24,  7.74s/it]                                                          {'loss': 0.8852, 'learning_rate': 1.340604637989292e-05, 'epoch': 0.41}
 41%|████      | 4238/10395 [12:07:19<13:14:24,  7.74s/it] 41%|████      | 4239/10395 [12:07:26<13:16:30,  7.76s/it]                                                          {'loss': 1.0017, 'learning_rate': 1.3403116782701977e-05, 'epoch': 0.41}
 41%|████      | 4239/10395 [12:07:26<13:16:30,  7.76s/it] 41%|████      | 4240/10395 [12:07:34<13:15:18,  7.75s/it]                                                          {'loss': 0.9068, 'learning_rate': 1.3400186855143726e-05, 'epoch': 0.41}
 41%|████      | 4240/10395 [12:07:34<13:15:18,  7.75s/it] 41%|████      | 4241/10395 [12:07:43<13:51:47,  8.11s/it]                                                          {'loss': 0.9158, 'learning_rate': 1.3397256597502602e-05, 'epoch': 0.41}
 41%|████      | 4241/10395 [12:07:43<13:51:47,  8.11s/it] 41%|████      | 4242/10395 [12:07:51<13:39:37,  7.99s/it]                                                          {'loss': 0.9113, 'learning_rate': 1.3394326010063067e-05, 'epoch': 0.41}
 41%|████      | 4242/10395 [12:07:51<13:39:37,  7.99s/it] 41%|████      | 4243/10395 [12:07:59<13:37:14,  7.97s/it]                                                          {'loss': 0.8858, 'learning_rate': 1.3391395093109619e-05, 'epoch': 0.41}
 41%|████      | 4243/10395 [12:07:59<13:37:14,  7.97s/it] 41%|████      | 4244/10395 [12:08:06<13:18:42,  7.79s/it]                                                          {'loss': 0.9734, 'learning_rate': 1.3388463846926778e-05, 'epoch': 0.41}
 41%|████      | 4244/10395 [12:08:06<13:18:42,  7.79s/it] 41%|████      | 4245/10395 [12:08:14<13:19:33,  7.80s/it]                                                          {'loss': 0.9021, 'learning_rate': 1.338553227179911e-05, 'epoch': 0.41}
 41%|████      | 4245/10395 [12:08:14<13:19:33,  7.80s/it] 41%|████      | 4246/10395 [12:08:31<17:56:40, 10.51s/it]                                                          {'loss': 0.3796, 'learning_rate': 1.3382600368011207e-05, 'epoch': 0.41}
 41%|████      | 4246/10395 [12:08:31<17:56:40, 10.51s/it] 41%|████      | 4247/10395 [12:08:39<16:34:09,  9.70s/it]                                                          {'loss': 1.0144, 'learning_rate': 1.3379668135847687e-05, 'epoch': 0.41}
 41%|████      | 4247/10395 [12:08:39<16:34:09,  9.70s/it] 41%|████      | 4248/10395 [12:08:47<16:02:21,  9.39s/it]                                                          {'loss': 0.99, 'learning_rate': 1.3376735575593202e-05, 'epoch': 0.41}
 41%|████      | 4248/10395 [12:08:47<16:02:21,  9.39s/it] 41%|████      | 4249/10395 [12:08:55<15:10:41,  8.89s/it]                                                          {'loss': 0.9373, 'learning_rate': 1.3373802687532448e-05, 'epoch': 0.41}
 41%|████      | 4249/10395 [12:08:55<15:10:41,  8.89s/it] 41%|████      | 4250/10395 [12:09:03<14:32:33,  8.52s/it]                                                          {'loss': 0.8461, 'learning_rate': 1.3370869471950142e-05, 'epoch': 0.41}
 41%|████      | 4250/10395 [12:09:03<14:32:33,  8.52s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 41%|████      | 4251/10395 [12:10:44<62:06:07, 36.39s/it]                                                          {'loss': 0.9138, 'learning_rate': 1.3367935929131028e-05, 'epoch': 0.41}
 41%|████      | 4251/10395 [12:10:44<62:06:07, 36.39s/it] 41%|████      | 4252/10395 [12:11:02<52:40:58, 30.87s/it]                                                          {'loss': 0.4258, 'learning_rate': 1.3365002059359888e-05, 'epoch': 0.41}
 41%|████      | 4252/10395 [12:11:02<52:40:58, 30.87s/it] 41%|████      | 4253/10395 [12:11:10<40:48:14, 23.92s/it]                                                          {'loss': 0.9457, 'learning_rate': 1.3362067862921546e-05, 'epoch': 0.41}
 41%|████      | 4253/10395 [12:11:10<40:48:14, 23.92s/it] 41%|████      | 4254/10395 [12:11:18<32:39:16, 19.14s/it]                                                          {'loss': 0.9334, 'learning_rate': 1.3359133340100836e-05, 'epoch': 0.41}
 41%|████      | 4254/10395 [12:11:18<32:39:16, 19.14s/it] 41%|████      | 4255/10395 [12:11:26<26:47:46, 15.71s/it]                                                          {'loss': 0.9443, 'learning_rate': 1.335619849118264e-05, 'epoch': 0.41}
 41%|████      | 4255/10395 [12:11:26<26:47:46, 15.71s/it] 41%|████      | 4256/10395 [12:11:33<22:34:45, 13.24s/it]                                                          {'loss': 0.8962, 'learning_rate': 1.3353263316451865e-05, 'epoch': 0.41}
 41%|████      | 4256/10395 [12:11:33<22:34:45, 13.24s/it] 41%|████      | 4257/10395 [12:11:40<19:27:40, 11.41s/it]                                                          {'loss': 0.8948, 'learning_rate': 1.3350327816193457e-05, 'epoch': 0.41}
 41%|████      | 4257/10395 [12:11:40<19:27:40, 11.41s/it] 41%|████      | 4258/10395 [12:11:48<17:40:25, 10.37s/it]                                                          {'loss': 0.8994, 'learning_rate': 1.3347391990692384e-05, 'epoch': 0.41}
 41%|████      | 4258/10395 [12:11:48<17:40:25, 10.37s/it] 41%|████      | 4259/10395 [12:11:56<16:26:50,  9.65s/it]                                                          {'loss': 0.9108, 'learning_rate': 1.3344455840233647e-05, 'epoch': 0.41}
 41%|████      | 4259/10395 [12:11:56<16:26:50,  9.65s/it] 41%|████      | 4260/10395 [12:12:04<15:39:20,  9.19s/it]                                                          {'loss': 0.9011, 'learning_rate': 1.3341519365102286e-05, 'epoch': 0.41}
 41%|████      | 4260/10395 [12:12:04<15:39:20,  9.19s/it] 41%|████      | 4261/10395 [12:12:12<14:45:04,  8.66s/it]                                                          {'loss': 0.961, 'learning_rate': 1.333858256558337e-05, 'epoch': 0.41}
 41%|████      | 4261/10395 [12:12:12<14:45:04,  8.66s/it] 41%|████      | 4262/10395 [12:12:20<14:23:37,  8.45s/it]                                                          {'loss': 0.9026, 'learning_rate': 1.3335645441961986e-05, 'epoch': 0.41}
 41%|████      | 4262/10395 [12:12:20<14:23:37,  8.45s/it] 41%|████      | 4263/10395 [12:12:27<13:47:02,  8.09s/it]                                                          {'loss': 0.901, 'learning_rate': 1.3332707994523273e-05, 'epoch': 0.41}
 41%|████      | 4263/10395 [12:12:27<13:47:02,  8.09s/it] 41%|████      | 4264/10395 [12:12:36<14:08:02,  8.30s/it]                                                          {'loss': 0.9596, 'learning_rate': 1.3329770223552392e-05, 'epoch': 0.41}
 41%|████      | 4264/10395 [12:12:36<14:08:02,  8.30s/it] 41%|████      | 4265/10395 [12:12:43<13:54:18,  8.17s/it]                                                          {'loss': 0.9098, 'learning_rate': 1.3326832129334533e-05, 'epoch': 0.41}
 41%|████      | 4265/10395 [12:12:43<13:54:18,  8.17s/it] 41%|████      | 4266/10395 [12:12:50<13:17:28,  7.81s/it]                                                          {'loss': 1.0986, 'learning_rate': 1.3323893712154918e-05, 'epoch': 0.41}
 41%|████      | 4266/10395 [12:12:50<13:17:28,  7.81s/it] 41%|████      | 4267/10395 [12:12:58<13:07:25,  7.71s/it]                                                          {'loss': 1.0103, 'learning_rate': 1.3320954972298806e-05, 'epoch': 0.41}
 41%|████      | 4267/10395 [12:12:58<13:07:25,  7.71s/it] 41%|████      | 4268/10395 [12:13:05<13:02:15,  7.66s/it]                                                          {'loss': 0.8808, 'learning_rate': 1.3318015910051483e-05, 'epoch': 0.41}
 41%|████      | 4268/10395 [12:13:06<13:02:15,  7.66s/it] 41%|████      | 4269/10395 [12:13:14<13:34:05,  7.97s/it]                                                          {'loss': 0.9504, 'learning_rate': 1.3315076525698264e-05, 'epoch': 0.41}
 41%|████      | 4269/10395 [12:13:14<13:34:05,  7.97s/it] 41%|████      | 4270/10395 [12:13:22<13:16:34,  7.80s/it]                                                          {'loss': 0.8928, 'learning_rate': 1.3312136819524503e-05, 'epoch': 0.41}
 41%|████      | 4270/10395 [12:13:22<13:16:34,  7.80s/it] 41%|████      | 4271/10395 [12:13:29<13:17:24,  7.81s/it]                                                          {'loss': 0.952, 'learning_rate': 1.3309196791815574e-05, 'epoch': 0.41}
 41%|████      | 4271/10395 [12:13:29<13:17:24,  7.81s/it] 41%|████      | 4272/10395 [12:13:37<13:04:31,  7.69s/it]                                                          {'loss': 1.0687, 'learning_rate': 1.3306256442856897e-05, 'epoch': 0.41}
 41%|████      | 4272/10395 [12:13:37<13:04:31,  7.69s/it] 41%|████      | 4273/10395 [12:13:45<13:08:58,  7.73s/it]                                                          {'loss': 0.9188, 'learning_rate': 1.3303315772933907e-05, 'epoch': 0.41}
 41%|████      | 4273/10395 [12:13:45<13:08:58,  7.73s/it] 41%|████      | 4274/10395 [12:13:52<13:07:17,  7.72s/it]                                                          {'loss': 0.9382, 'learning_rate': 1.3300374782332081e-05, 'epoch': 0.41}
 41%|████      | 4274/10395 [12:13:52<13:07:17,  7.72s/it] 41%|████      | 4275/10395 [12:14:00<13:02:52,  7.68s/it]                                                          {'loss': 0.9094, 'learning_rate': 1.3297433471336923e-05, 'epoch': 0.41}
 41%|████      | 4275/10395 [12:14:00<13:02:52,  7.68s/it] 41%|████      | 4276/10395 [12:14:08<13:31:17,  7.96s/it]                                                          {'loss': 0.9514, 'learning_rate': 1.3294491840233975e-05, 'epoch': 0.41}
 41%|████      | 4276/10395 [12:14:08<13:31:17,  7.96s/it] 41%|████      | 4277/10395 [12:14:16<13:24:07,  7.89s/it]                                                          {'loss': 0.9466, 'learning_rate': 1.3291549889308794e-05, 'epoch': 0.41}
 41%|████      | 4277/10395 [12:14:16<13:24:07,  7.89s/it] 41%|████      | 4278/10395 [12:14:24<13:11:39,  7.77s/it]                                                          {'loss': 0.926, 'learning_rate': 1.3288607618846987e-05, 'epoch': 0.41}
 41%|████      | 4278/10395 [12:14:24<13:11:39,  7.77s/it] 41%|████      | 4279/10395 [12:14:31<13:11:48,  7.77s/it]                                                          {'loss': 0.9148, 'learning_rate': 1.3285665029134177e-05, 'epoch': 0.41}
 41%|████      | 4279/10395 [12:14:31<13:11:48,  7.77s/it] 41%|████      | 4280/10395 [12:14:39<13:19:00,  7.84s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.3282722120456031e-05, 'epoch': 0.41}
 41%|████      | 4280/10395 [12:14:39<13:19:00,  7.84s/it] 41%|████      | 4281/10395 [12:14:47<13:13:10,  7.78s/it]                                                          {'loss': 0.9435, 'learning_rate': 1.3279778893098237e-05, 'epoch': 0.41}
 41%|████      | 4281/10395 [12:14:47<13:13:10,  7.78s/it] 41%|████      | 4282/10395 [12:15:05<18:16:06, 10.76s/it]                                                          {'loss': 0.4016, 'learning_rate': 1.3276835347346513e-05, 'epoch': 0.41}
 41%|████      | 4282/10395 [12:15:05<18:16:06, 10.76s/it] 41%|████      | 4283/10395 [12:15:12<16:38:22,  9.80s/it]                                                          {'loss': 0.8685, 'learning_rate': 1.327389148348662e-05, 'epoch': 0.41}
 41%|████      | 4283/10395 [12:15:12<16:38:22,  9.80s/it] 41%|████      | 4284/10395 [12:15:21<16:06:38,  9.49s/it]                                                          {'loss': 0.878, 'learning_rate': 1.3270947301804336e-05, 'epoch': 0.41}
 41%|████      | 4284/10395 [12:15:21<16:06:38,  9.49s/it] 41%|████      | 4285/10395 [12:15:29<15:12:00,  8.96s/it]                                                          {'loss': 0.9369, 'learning_rate': 1.3268002802585477e-05, 'epoch': 0.41}
 41%|████      | 4285/10395 [12:15:29<15:12:00,  8.96s/it] 41%|████      | 4286/10395 [12:15:37<14:58:00,  8.82s/it]                                                          {'loss': 0.9232, 'learning_rate': 1.3265057986115893e-05, 'epoch': 0.41}
 41%|████      | 4286/10395 [12:15:37<14:58:00,  8.82s/it] 41%|████      | 4287/10395 [12:15:44<14:05:59,  8.31s/it]                                                          {'loss': 0.9549, 'learning_rate': 1.3262112852681455e-05, 'epoch': 0.41}
 41%|████      | 4287/10395 [12:15:44<14:05:59,  8.31s/it] 41%|████▏     | 4288/10395 [12:15:53<13:58:31,  8.24s/it]                                                          {'loss': 0.9814, 'learning_rate': 1.3259167402568075e-05, 'epoch': 0.41}
 41%|████▏     | 4288/10395 [12:15:53<13:58:31,  8.24s/it] 41%|████▏     | 4289/10395 [12:16:01<13:50:00,  8.16s/it]                                                          {'loss': 0.8306, 'learning_rate': 1.3256221636061683e-05, 'epoch': 0.41}
 41%|████▏     | 4289/10395 [12:16:01<13:50:00,  8.16s/it] 41%|████▏     | 4290/10395 [12:16:08<13:41:29,  8.07s/it]                                                          {'loss': 0.9512, 'learning_rate': 1.3253275553448257e-05, 'epoch': 0.41}
 41%|████▏     | 4290/10395 [12:16:08<13:41:29,  8.07s/it] 41%|████▏     | 4291/10395 [12:16:17<13:42:46,  8.09s/it]                                                          {'loss': 0.876, 'learning_rate': 1.3250329155013792e-05, 'epoch': 0.41}
 41%|████▏     | 4291/10395 [12:16:17<13:42:46,  8.09s/it] 41%|████▏     | 4292/10395 [12:16:25<13:55:09,  8.21s/it]                                                          {'loss': 0.9108, 'learning_rate': 1.3247382441044318e-05, 'epoch': 0.41}
 41%|████▏     | 4292/10395 [12:16:25<13:55:09,  8.21s/it] 41%|████▏     | 4293/10395 [12:16:33<13:42:58,  8.09s/it]                                                          {'loss': 1.0122, 'learning_rate': 1.3244435411825898e-05, 'epoch': 0.41}
 41%|████▏     | 4293/10395 [12:16:33<13:42:58,  8.09s/it] 41%|████▏     | 4294/10395 [12:16:41<13:50:05,  8.16s/it]                                                          {'loss': 0.8579, 'learning_rate': 1.324148806764462e-05, 'epoch': 0.41}
 41%|████▏     | 4294/10395 [12:16:41<13:50:05,  8.16s/it] 41%|████▏     | 4295/10395 [12:16:49<13:32:13,  7.99s/it]                                                          {'loss': 0.9521, 'learning_rate': 1.323854040878661e-05, 'epoch': 0.41}
 41%|████▏     | 4295/10395 [12:16:49<13:32:13,  7.99s/it] 41%|████▏     | 4296/10395 [12:16:56<13:14:38,  7.82s/it]                                                          {'loss': 0.8941, 'learning_rate': 1.3235592435538013e-05, 'epoch': 0.41}
 41%|████▏     | 4296/10395 [12:16:56<13:14:38,  7.82s/it] 41%|████▏     | 4297/10395 [12:17:04<13:22:46,  7.90s/it]                                                          {'loss': 1.0467, 'learning_rate': 1.3232644148185019e-05, 'epoch': 0.41}
 41%|████▏     | 4297/10395 [12:17:04<13:22:46,  7.90s/it] 41%|████▏     | 4298/10395 [12:17:12<13:23:36,  7.91s/it]                                                          {'loss': 0.9183, 'learning_rate': 1.3229695547013841e-05, 'epoch': 0.41}
 41%|████▏     | 4298/10395 [12:17:12<13:23:36,  7.91s/it] 41%|████▏     | 4299/10395 [12:17:20<13:10:26,  7.78s/it]                                                          {'loss': 0.9184, 'learning_rate': 1.3226746632310721e-05, 'epoch': 0.41}
 41%|████▏     | 4299/10395 [12:17:20<13:10:26,  7.78s/it] 41%|████▏     | 4300/10395 [12:17:27<13:04:43,  7.72s/it]                                                          {'loss': 1.0055, 'learning_rate': 1.322379740436193e-05, 'epoch': 0.41}
 41%|████▏     | 4300/10395 [12:17:27<13:04:43,  7.72s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 41%|████▏     | 4301/10395 [12:19:15<63:51:54, 37.73s/it]                                                          {'loss': 0.3868, 'learning_rate': 1.3220847863453781e-05, 'epoch': 0.41}
 41%|████▏     | 4301/10395 [12:19:15<63:51:54, 37.73s/it] 41%|████▏     | 4302/10395 [12:19:24<49:01:53, 28.97s/it]                                                          {'loss': 0.9782, 'learning_rate': 1.3217898009872601e-05, 'epoch': 0.41}
 41%|████▏     | 4302/10395 [12:19:24<49:01:53, 28.97s/it] 41%|████▏     | 4303/10395 [12:19:31<37:57:30, 22.43s/it]                                                          {'loss': 0.9338, 'learning_rate': 1.3214947843904761e-05, 'epoch': 0.41}
 41%|████▏     | 4303/10395 [12:19:31<37:57:30, 22.43s/it] 41%|████▏     | 4304/10395 [12:19:39<30:39:18, 18.12s/it]                                                          {'loss': 0.985, 'learning_rate': 1.3211997365836652e-05, 'epoch': 0.41}
 41%|████▏     | 4304/10395 [12:19:39<30:39:18, 18.12s/it] 41%|████▏     | 4305/10395 [12:19:46<25:12:07, 14.90s/it]                                                          {'loss': 1.0016, 'learning_rate': 1.3209046575954707e-05, 'epoch': 0.41}
 41%|████▏     | 4305/10395 [12:19:46<25:12:07, 14.90s/it] 41%|████▏     | 4306/10395 [12:19:53<21:16:07, 12.57s/it]                                                          {'loss': 0.946, 'learning_rate': 1.3206095474545376e-05, 'epoch': 0.41}
 41%|████▏     | 4306/10395 [12:19:53<21:16:07, 12.57s/it] 41%|████▏     | 4307/10395 [12:20:01<18:51:12, 11.15s/it]                                                          {'loss': 0.8651, 'learning_rate': 1.3203144061895146e-05, 'epoch': 0.41}
 41%|████▏     | 4307/10395 [12:20:01<18:51:12, 11.15s/it] 41%|████▏     | 4308/10395 [12:20:09<17:25:48, 10.31s/it]                                                          {'loss': 0.9702, 'learning_rate': 1.3200192338290538e-05, 'epoch': 0.41}
 41%|████▏     | 4308/10395 [12:20:09<17:25:48, 10.31s/it] 41%|████▏     | 4309/10395 [12:20:18<16:18:13,  9.64s/it]                                                          {'loss': 0.9357, 'learning_rate': 1.3197240304018094e-05, 'epoch': 0.41}
 41%|████▏     | 4309/10395 [12:20:18<16:18:13,  9.64s/it] 41%|████▏     | 4310/10395 [12:20:25<15:18:56,  9.06s/it]                                                          {'loss': 0.9488, 'learning_rate': 1.3194287959364396e-05, 'epoch': 0.41}
 41%|████▏     | 4310/10395 [12:20:25<15:18:56,  9.06s/it] 41%|████▏     | 4311/10395 [12:20:33<14:28:05,  8.56s/it]                                                          {'loss': 0.9615, 'learning_rate': 1.3191335304616049e-05, 'epoch': 0.41}
 41%|████▏     | 4311/10395 [12:20:33<14:28:05,  8.56s/it] 41%|████▏     | 4312/10395 [12:20:41<14:12:16,  8.41s/it]                                                          {'loss': 0.9392, 'learning_rate': 1.3188382340059693e-05, 'epoch': 0.41}
 41%|████▏     | 4312/10395 [12:20:41<14:12:16,  8.41s/it] 41%|████▏     | 4313/10395 [12:20:49<13:57:44,  8.26s/it]                                                          {'loss': 0.9449, 'learning_rate': 1.3185429065981988e-05, 'epoch': 0.41}
 41%|████▏     | 4313/10395 [12:20:49<13:57:44,  8.26s/it] 42%|████▏     | 4314/10395 [12:20:56<13:25:25,  7.95s/it]                                                          {'loss': 1.0246, 'learning_rate': 1.3182475482669639e-05, 'epoch': 0.41}
 42%|████▏     | 4314/10395 [12:20:56<13:25:25,  7.95s/it] 42%|████▏     | 4315/10395 [12:21:03<13:11:38,  7.81s/it]                                                          {'loss': 0.9463, 'learning_rate': 1.317952159040937e-05, 'epoch': 0.42}
 42%|████▏     | 4315/10395 [12:21:03<13:11:38,  7.81s/it] 42%|████▏     | 4316/10395 [12:21:11<13:06:11,  7.76s/it]                                                          {'loss': 0.9983, 'learning_rate': 1.3176567389487941e-05, 'epoch': 0.42}
 42%|████▏     | 4316/10395 [12:21:11<13:06:11,  7.76s/it] 42%|████▏     | 4317/10395 [12:21:19<13:14:49,  7.85s/it]                                                          {'loss': 0.8542, 'learning_rate': 1.3173612880192137e-05, 'epoch': 0.42}
 42%|████▏     | 4317/10395 [12:21:19<13:14:49,  7.85s/it] 42%|████▏     | 4318/10395 [12:21:27<13:07:12,  7.77s/it]                                                          {'loss': 0.9818, 'learning_rate': 1.3170658062808778e-05, 'epoch': 0.42}
 42%|████▏     | 4318/10395 [12:21:27<13:07:12,  7.77s/it] 42%|████▏     | 4319/10395 [12:21:34<13:03:58,  7.74s/it]                                                          {'loss': 0.909, 'learning_rate': 1.316770293762471e-05, 'epoch': 0.42}
 42%|████▏     | 4319/10395 [12:21:34<13:03:58,  7.74s/it] 42%|████▏     | 4320/10395 [12:21:42<12:55:21,  7.66s/it]                                                          {'loss': 0.9201, 'learning_rate': 1.316474750492681e-05, 'epoch': 0.42}
 42%|████▏     | 4320/10395 [12:21:42<12:55:21,  7.66s/it] 42%|████▏     | 4321/10395 [12:21:59<17:53:06, 10.60s/it]                                                          {'loss': 0.4227, 'learning_rate': 1.3161791765001982e-05, 'epoch': 0.42}
 42%|████▏     | 4321/10395 [12:21:59<17:53:06, 10.60s/it] 42%|████▏     | 4322/10395 [12:22:07<16:20:54,  9.69s/it]                                                          {'loss': 0.937, 'learning_rate': 1.3158835718137171e-05, 'epoch': 0.42}
 42%|████▏     | 4322/10395 [12:22:07<16:20:54,  9.69s/it] 42%|████▏     | 4323/10395 [12:22:15<15:22:17,  9.11s/it]                                                          {'loss': 0.886, 'learning_rate': 1.315587936461934e-05, 'epoch': 0.42}
 42%|████▏     | 4323/10395 [12:22:15<15:22:17,  9.11s/it] 42%|████▏     | 4324/10395 [12:22:23<14:56:42,  8.86s/it]                                                          {'loss': 0.9184, 'learning_rate': 1.3152922704735477e-05, 'epoch': 0.42}
 42%|████▏     | 4324/10395 [12:22:23<14:56:42,  8.86s/it] 42%|████▏     | 4325/10395 [12:22:31<14:40:37,  8.70s/it]                                                          {'loss': 0.8812, 'learning_rate': 1.3149965738772621e-05, 'epoch': 0.42}
 42%|████▏     | 4325/10395 [12:22:31<14:40:37,  8.70s/it] 42%|████▏     | 4326/10395 [12:22:39<14:03:38,  8.34s/it]                                                          {'loss': 0.9326, 'learning_rate': 1.3147008467017824e-05, 'epoch': 0.42}
 42%|████▏     | 4326/10395 [12:22:39<14:03:38,  8.34s/it] 42%|████▏     | 4327/10395 [12:22:47<13:49:43,  8.20s/it]                                                          {'loss': 1.03, 'learning_rate': 1.3144050889758168e-05, 'epoch': 0.42}
 42%|████▏     | 4327/10395 [12:22:47<13:49:43,  8.20s/it] 42%|████▏     | 4328/10395 [12:22:54<13:26:01,  7.97s/it]                                                          {'loss': 0.9333, 'learning_rate': 1.314109300728077e-05, 'epoch': 0.42}
 42%|████▏     | 4328/10395 [12:22:54<13:26:01,  7.97s/it] 42%|████▏     | 4329/10395 [12:23:02<13:28:05,  7.99s/it]                                                          {'loss': 0.913, 'learning_rate': 1.3138134819872775e-05, 'epoch': 0.42}
 42%|████▏     | 4329/10395 [12:23:02<13:28:05,  7.99s/it] 42%|████▏     | 4330/10395 [12:23:19<18:00:11, 10.69s/it]                                                          {'loss': 0.3494, 'learning_rate': 1.3135176327821358e-05, 'epoch': 0.42}
 42%|████▏     | 4330/10395 [12:23:19<18:00:11, 10.69s/it] 42%|████▏     | 4331/10395 [12:23:26<16:12:50,  9.63s/it]                                                          {'loss': 0.9792, 'learning_rate': 1.3132217531413725e-05, 'epoch': 0.42}
 42%|████▏     | 4331/10395 [12:23:26<16:12:50,  9.63s/it] 42%|████▏     | 4332/10395 [12:23:34<15:18:47,  9.09s/it]                                                          {'loss': 0.9649, 'learning_rate': 1.3129258430937104e-05, 'epoch': 0.42}
 42%|████▏     | 4332/10395 [12:23:34<15:18:47,  9.09s/it] 42%|████▏     | 4333/10395 [12:23:44<15:42:57,  9.33s/it]                                                          {'loss': 0.8903, 'learning_rate': 1.3126299026678764e-05, 'epoch': 0.42}
 42%|████▏     | 4333/10395 [12:23:44<15:42:57,  9.33s/it] 42%|████▏     | 4334/10395 [12:23:52<15:12:49,  9.04s/it]                                                          {'loss': 0.9647, 'learning_rate': 1.3123339318925997e-05, 'epoch': 0.42}
 42%|████▏     | 4334/10395 [12:23:52<15:12:49,  9.04s/it] 42%|████▏     | 4335/10395 [12:24:00<14:28:15,  8.60s/it]                                                          {'loss': 1.0121, 'learning_rate': 1.3120379307966124e-05, 'epoch': 0.42}
 42%|████▏     | 4335/10395 [12:24:00<14:28:15,  8.60s/it] 42%|████▏     | 4336/10395 [12:24:08<14:02:00,  8.34s/it]                                                          {'loss': 0.8554, 'learning_rate': 1.311741899408649e-05, 'epoch': 0.42}
 42%|████▏     | 4336/10395 [12:24:08<14:02:00,  8.34s/it] 42%|████▏     | 4337/10395 [12:24:15<13:46:12,  8.18s/it]                                                          {'loss': 0.9678, 'learning_rate': 1.3114458377574489e-05, 'epoch': 0.42}
 42%|████▏     | 4337/10395 [12:24:15<13:46:12,  8.18s/it] 42%|████▏     | 4338/10395 [12:24:23<13:35:48,  8.08s/it]                                                          {'loss': 0.9594, 'learning_rate': 1.3111497458717521e-05, 'epoch': 0.42}
 42%|████▏     | 4338/10395 [12:24:23<13:35:48,  8.08s/it] 42%|████▏     | 4339/10395 [12:24:31<13:15:55,  7.89s/it]                                                          {'loss': 0.9306, 'learning_rate': 1.310853623780303e-05, 'epoch': 0.42}
 42%|████▏     | 4339/10395 [12:24:31<13:15:55,  7.89s/it] 42%|████▏     | 4340/10395 [12:24:38<13:10:52,  7.84s/it]                                                          {'loss': 0.9214, 'learning_rate': 1.3105574715118481e-05, 'epoch': 0.42}
 42%|████▏     | 4340/10395 [12:24:38<13:10:52,  7.84s/it] 42%|████▏     | 4341/10395 [12:24:46<13:02:42,  7.76s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.3102612890951379e-05, 'epoch': 0.42}
 42%|████▏     | 4341/10395 [12:24:46<13:02:42,  7.76s/it] 42%|████▏     | 4342/10395 [12:24:54<13:00:43,  7.74s/it]                                                          {'loss': 0.8795, 'learning_rate': 1.3099650765589246e-05, 'epoch': 0.42}
 42%|████▏     | 4342/10395 [12:24:54<13:00:43,  7.74s/it] 42%|████▏     | 4343/10395 [12:25:02<13:19:16,  7.92s/it]                                                          {'loss': 0.8789, 'learning_rate': 1.3096688339319644e-05, 'epoch': 0.42}
 42%|████▏     | 4343/10395 [12:25:02<13:19:16,  7.92s/it] 42%|████▏     | 4344/10395 [12:25:10<13:26:19,  8.00s/it]                                                          {'loss': 0.9219, 'learning_rate': 1.309372561243015e-05, 'epoch': 0.42}
 42%|████▏     | 4344/10395 [12:25:10<13:26:19,  8.00s/it] 42%|████▏     | 4345/10395 [12:25:18<13:12:59,  7.86s/it]                                                          {'loss': 0.9242, 'learning_rate': 1.309076258520839e-05, 'epoch': 0.42}
 42%|████▏     | 4345/10395 [12:25:18<13:12:59,  7.86s/it] 42%|████▏     | 4346/10395 [12:25:26<13:21:47,  7.95s/it]                                                          {'loss': 0.9112, 'learning_rate': 1.3087799257942e-05, 'epoch': 0.42}
 42%|████▏     | 4346/10395 [12:25:26<13:21:47,  7.95s/it] 42%|████▏     | 4347/10395 [12:25:33<13:11:32,  7.85s/it]                                                          {'loss': 0.9895, 'learning_rate': 1.3084835630918657e-05, 'epoch': 0.42}
 42%|████▏     | 4347/10395 [12:25:33<13:11:32,  7.85s/it] 42%|████▏     | 4348/10395 [12:25:41<13:01:47,  7.76s/it]                                                          {'loss': 0.8874, 'learning_rate': 1.3081871704426063e-05, 'epoch': 0.42}
 42%|████▏     | 4348/10395 [12:25:41<13:01:47,  7.76s/it] 42%|████▏     | 4349/10395 [12:25:49<12:59:43,  7.74s/it]                                                          {'loss': 0.8986, 'learning_rate': 1.3078907478751951e-05, 'epoch': 0.42}
 42%|████▏     | 4349/10395 [12:25:49<12:59:43,  7.74s/it] 42%|████▏     | 4350/10395 [12:25:57<13:21:52,  7.96s/it]                                                          {'loss': 0.8711, 'learning_rate': 1.3075942954184082e-05, 'epoch': 0.42}
 42%|████▏     | 4350/10395 [12:25:57<13:21:52,  7.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 42%|████▏     | 4351/10395 [12:27:38<59:56:23, 35.70s/it]                                                          {'loss': 0.9165, 'learning_rate': 1.3072978131010244e-05, 'epoch': 0.42}
 42%|████▏     | 4351/10395 [12:27:38<59:56:23, 35.70s/it] 42%|████▏     | 4352/10395 [12:27:46<46:10:29, 27.51s/it]                                                          {'loss': 0.8552, 'learning_rate': 1.307001300951825e-05, 'epoch': 0.42}
 42%|████▏     | 4352/10395 [12:27:46<46:10:29, 27.51s/it] 42%|████▏     | 4353/10395 [12:27:54<36:26:51, 21.72s/it]                                                          {'loss': 0.97, 'learning_rate': 1.306704758999596e-05, 'epoch': 0.42}
 42%|████▏     | 4353/10395 [12:27:54<36:26:51, 21.72s/it] 42%|████▏     | 4354/10395 [12:28:10<33:35:18, 20.02s/it]                                                          {'loss': 0.4069, 'learning_rate': 1.3064081872731245e-05, 'epoch': 0.42}
 42%|████▏     | 4354/10395 [12:28:10<33:35:18, 20.02s/it] 42%|████▏     | 4355/10395 [12:28:18<27:13:19, 16.23s/it]                                                          {'loss': 0.9001, 'learning_rate': 1.3061115858012006e-05, 'epoch': 0.42}
 42%|████▏     | 4355/10395 [12:28:18<27:13:19, 16.23s/it] 42%|████▏     | 4356/10395 [12:28:25<22:41:27, 13.53s/it]                                                          {'loss': 0.9306, 'learning_rate': 1.3058149546126182e-05, 'epoch': 0.42}
 42%|████▏     | 4356/10395 [12:28:25<22:41:27, 13.53s/it] 42%|████▏     | 4357/10395 [12:28:33<19:53:08, 11.86s/it]                                                          {'loss': 0.9609, 'learning_rate': 1.3055182937361737e-05, 'epoch': 0.42}
 42%|████▏     | 4357/10395 [12:28:33<19:53:08, 11.86s/it] 42%|████▏     | 4358/10395 [12:28:51<22:49:21, 13.61s/it]                                                          {'loss': 0.3781, 'learning_rate': 1.305221603200666e-05, 'epoch': 0.42}
 42%|████▏     | 4358/10395 [12:28:51<22:49:21, 13.61s/it] 42%|████▏     | 4359/10395 [12:28:58<19:42:20, 11.75s/it]                                                          {'loss': 0.9195, 'learning_rate': 1.304924883034897e-05, 'epoch': 0.42}
 42%|████▏     | 4359/10395 [12:28:58<19:42:20, 11.75s/it] 42%|████▏     | 4360/10395 [12:29:06<17:39:28, 10.53s/it]                                                          {'loss': 0.9262, 'learning_rate': 1.3046281332676727e-05, 'epoch': 0.42}
 42%|████▏     | 4360/10395 [12:29:06<17:39:28, 10.53s/it] 42%|████▏     | 4361/10395 [12:29:13<16:08:49,  9.63s/it]                                                          {'loss': 0.907, 'learning_rate': 1.3043313539278e-05, 'epoch': 0.42}
 42%|████▏     | 4361/10395 [12:29:13<16:08:49,  9.63s/it] 42%|████▏     | 4362/10395 [12:29:21<15:08:03,  9.03s/it]                                                          {'loss': 0.8763, 'learning_rate': 1.3040345450440897e-05, 'epoch': 0.42}
 42%|████▏     | 4362/10395 [12:29:21<15:08:03,  9.03s/it] 42%|████▏     | 4363/10395 [12:29:37<18:45:42, 11.20s/it]                                                          {'loss': 0.3668, 'learning_rate': 1.3037377066453552e-05, 'epoch': 0.42}
 42%|████▏     | 4363/10395 [12:29:37<18:45:42, 11.20s/it] 42%|████▏     | 4364/10395 [12:29:45<17:02:32, 10.17s/it]                                                          {'loss': 0.9736, 'learning_rate': 1.3034408387604135e-05, 'epoch': 0.42}
 42%|████▏     | 4364/10395 [12:29:45<17:02:32, 10.17s/it] 42%|████▏     | 4365/10395 [12:29:52<15:34:00,  9.29s/it]                                                          {'loss': 0.9773, 'learning_rate': 1.3031439414180838e-05, 'epoch': 0.42}
 42%|████▏     | 4365/10395 [12:29:52<15:34:00,  9.29s/it] 42%|████▏     | 4366/10395 [12:29:59<14:26:10,  8.62s/it]                                                          {'loss': 0.95, 'learning_rate': 1.3028470146471878e-05, 'epoch': 0.42}
 42%|████▏     | 4366/10395 [12:29:59<14:26:10,  8.62s/it] 42%|████▏     | 4367/10395 [12:30:07<14:02:25,  8.39s/it]                                                          {'loss': 0.8748, 'learning_rate': 1.302550058476551e-05, 'epoch': 0.42}
 42%|████▏     | 4367/10395 [12:30:07<14:02:25,  8.39s/it] 42%|████▏     | 4368/10395 [12:30:14<13:30:42,  8.07s/it]                                                          {'loss': 0.9408, 'learning_rate': 1.302253072935001e-05, 'epoch': 0.42}
 42%|████▏     | 4368/10395 [12:30:14<13:30:42,  8.07s/it] 42%|████▏     | 4369/10395 [12:30:22<13:15:35,  7.92s/it]                                                          {'loss': 0.8445, 'learning_rate': 1.3019560580513684e-05, 'epoch': 0.42}
 42%|████▏     | 4369/10395 [12:30:22<13:15:35,  7.92s/it] 42%|████▏     | 4370/10395 [12:30:30<13:17:14,  7.94s/it]                                                          {'loss': 0.9139, 'learning_rate': 1.3016590138544874e-05, 'epoch': 0.42}
 42%|████▏     | 4370/10395 [12:30:30<13:17:14,  7.94s/it] 42%|████▏     | 4371/10395 [12:30:37<13:06:19,  7.83s/it]                                                          {'loss': 0.9324, 'learning_rate': 1.3013619403731936e-05, 'epoch': 0.42}
 42%|████▏     | 4371/10395 [12:30:37<13:06:19,  7.83s/it] 42%|████▏     | 4372/10395 [12:30:46<13:19:49,  7.97s/it]                                                          {'loss': 0.8397, 'learning_rate': 1.3010648376363266e-05, 'epoch': 0.42}
 42%|████▏     | 4372/10395 [12:30:46<13:19:49,  7.97s/it] 42%|████▏     | 4373/10395 [12:30:53<13:11:15,  7.88s/it]                                                          {'loss': 0.9657, 'learning_rate': 1.3007677056727289e-05, 'epoch': 0.42}
 42%|████▏     | 4373/10395 [12:30:53<13:11:15,  7.88s/it] 42%|████▏     | 4374/10395 [12:31:11<17:55:45, 10.72s/it]                                                          {'loss': 0.4022, 'learning_rate': 1.3004705445112449e-05, 'epoch': 0.42}
 42%|████▏     | 4374/10395 [12:31:11<17:55:45, 10.72s/it] 42%|████▏     | 4375/10395 [12:31:19<16:28:53,  9.86s/it]                                                          {'loss': 0.9576, 'learning_rate': 1.3001733541807225e-05, 'epoch': 0.42}
 42%|████▏     | 4375/10395 [12:31:19<16:28:53,  9.86s/it] 42%|████▏     | 4376/10395 [12:31:27<15:53:11,  9.50s/it]                                                          {'loss': 0.9109, 'learning_rate': 1.2998761347100124e-05, 'epoch': 0.42}
 42%|████▏     | 4376/10395 [12:31:27<15:53:11,  9.50s/it] 42%|████▏     | 4377/10395 [12:31:36<15:23:36,  9.21s/it]                                                          {'loss': 0.9161, 'learning_rate': 1.299578886127968e-05, 'epoch': 0.42}
 42%|████▏     | 4377/10395 [12:31:36<15:23:36,  9.21s/it] 42%|████▏     | 4378/10395 [12:31:45<15:23:42,  9.21s/it]                                                          {'loss': 0.8777, 'learning_rate': 1.2992816084634454e-05, 'epoch': 0.42}
 42%|████▏     | 4378/10395 [12:31:45<15:23:42,  9.21s/it] 42%|████▏     | 4379/10395 [12:31:53<14:56:45,  8.94s/it]                                                          {'loss': 0.9122, 'learning_rate': 1.298984301745304e-05, 'epoch': 0.42}
 42%|████▏     | 4379/10395 [12:31:53<14:56:45,  8.94s/it] 42%|████▏     | 4380/10395 [12:32:02<14:41:40,  8.79s/it]                                                          {'loss': 0.9035, 'learning_rate': 1.2986869660024052e-05, 'epoch': 0.42}
 42%|████▏     | 4380/10395 [12:32:02<14:41:40,  8.79s/it] 42%|████▏     | 4381/10395 [12:32:10<14:10:52,  8.49s/it]                                                          {'loss': 0.8941, 'learning_rate': 1.2983896012636143e-05, 'epoch': 0.42}
 42%|████▏     | 4381/10395 [12:32:10<14:10:52,  8.49s/it] 42%|████▏     | 4382/10395 [12:32:18<14:02:43,  8.41s/it]                                                          {'loss': 0.8064, 'learning_rate': 1.2980922075577987e-05, 'epoch': 0.42}
 42%|████▏     | 4382/10395 [12:32:18<14:02:43,  8.41s/it] 42%|████▏     | 4383/10395 [12:32:25<13:42:43,  8.21s/it]                                                          {'loss': 0.8948, 'learning_rate': 1.2977947849138283e-05, 'epoch': 0.42}
 42%|████▏     | 4383/10395 [12:32:25<13:42:43,  8.21s/it] 42%|████▏     | 4384/10395 [12:32:33<13:29:46,  8.08s/it]                                                          {'loss': 0.8843, 'learning_rate': 1.2974973333605767e-05, 'epoch': 0.42}
 42%|████▏     | 4384/10395 [12:32:33<13:29:46,  8.08s/it] 42%|████▏     | 4385/10395 [12:32:42<13:38:40,  8.17s/it]                                                          {'loss': 0.8718, 'learning_rate': 1.2971998529269198e-05, 'epoch': 0.42}
 42%|████▏     | 4385/10395 [12:32:42<13:38:40,  8.17s/it] 42%|████▏     | 4386/10395 [12:32:49<13:22:24,  8.01s/it]                                                          {'loss': 0.9173, 'learning_rate': 1.2969023436417363e-05, 'epoch': 0.42}
 42%|████▏     | 4386/10395 [12:32:49<13:22:24,  8.01s/it] 42%|████▏     | 4387/10395 [12:32:57<13:02:02,  7.81s/it]                                                          {'loss': 0.9219, 'learning_rate': 1.2966048055339077e-05, 'epoch': 0.42}
 42%|████▏     | 4387/10395 [12:32:57<13:02:02,  7.81s/it] 42%|████▏     | 4388/10395 [12:33:04<13:00:31,  7.80s/it]                                                          {'loss': 0.9848, 'learning_rate': 1.2963072386323185e-05, 'epoch': 0.42}
 42%|████▏     | 4388/10395 [12:33:04<13:00:31,  7.80s/it] 42%|████▏     | 4389/10395 [12:33:12<12:41:42,  7.61s/it]                                                          {'loss': 0.9317, 'learning_rate': 1.2960096429658557e-05, 'epoch': 0.42}
 42%|████▏     | 4389/10395 [12:33:12<12:41:42,  7.61s/it] 42%|████▏     | 4390/10395 [12:33:19<12:46:38,  7.66s/it]                                                          {'loss': 0.944, 'learning_rate': 1.2957120185634094e-05, 'epoch': 0.42}
 42%|████▏     | 4390/10395 [12:33:19<12:46:38,  7.66s/it] 42%|████▏     | 4391/10395 [12:33:30<14:26:58,  8.66s/it]                                                          {'loss': 0.8182, 'learning_rate': 1.2954143654538723e-05, 'epoch': 0.42}
 42%|████▏     | 4391/10395 [12:33:30<14:26:58,  8.66s/it] 42%|████▏     | 4392/10395 [12:33:38<13:52:03,  8.32s/it]                                                          {'loss': 0.951, 'learning_rate': 1.2951166836661397e-05, 'epoch': 0.42}
 42%|████▏     | 4392/10395 [12:33:38<13:52:03,  8.32s/it] 42%|████▏     | 4393/10395 [12:33:45<13:17:23,  7.97s/it]                                                          {'loss': 0.9771, 'learning_rate': 1.2948189732291104e-05, 'epoch': 0.42}
 42%|████▏     | 4393/10395 [12:33:45<13:17:23,  7.97s/it] 42%|████▏     | 4394/10395 [12:33:52<13:01:54,  7.82s/it]                                                          {'loss': 0.9064, 'learning_rate': 1.2945212341716849e-05, 'epoch': 0.42}
 42%|████▏     | 4394/10395 [12:33:52<13:01:54,  7.82s/it] 42%|████▏     | 4395/10395 [12:34:00<12:52:47,  7.73s/it]                                                          {'loss': 0.9225, 'learning_rate': 1.2942234665227675e-05, 'epoch': 0.42}
 42%|████▏     | 4395/10395 [12:34:00<12:52:47,  7.73s/it] 42%|████▏     | 4396/10395 [12:34:09<13:17:00,  7.97s/it]                                                          {'loss': 0.8981, 'learning_rate': 1.2939256703112649e-05, 'epoch': 0.42}
 42%|████▏     | 4396/10395 [12:34:09<13:17:00,  7.97s/it] 42%|████▏     | 4397/10395 [12:34:16<13:12:40,  7.93s/it]                                                          {'loss': 0.9854, 'learning_rate': 1.2936278455660862e-05, 'epoch': 0.42}
 42%|████▏     | 4397/10395 [12:34:16<13:12:40,  7.93s/it] 42%|████▏     | 4398/10395 [12:34:24<13:06:34,  7.87s/it]                                                          {'loss': 0.9233, 'learning_rate': 1.2933299923161437e-05, 'epoch': 0.42}
 42%|████▏     | 4398/10395 [12:34:24<13:06:34,  7.87s/it] 42%|████▏     | 4399/10395 [12:34:33<13:26:50,  8.07s/it]                                                          {'loss': 0.8998, 'learning_rate': 1.2930321105903524e-05, 'epoch': 0.42}
 42%|████▏     | 4399/10395 [12:34:33<13:26:50,  8.07s/it] 42%|████▏     | 4400/10395 [12:34:40<12:58:50,  7.79s/it]                                                          {'loss': 1.0059, 'learning_rate': 1.2927342004176305e-05, 'epoch': 0.42}
 42%|████▏     | 4400/10395 [12:34:40<12:58:50,  7.79s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 42%|████▏     | 4401/10395 [12:36:22<60:01:02, 36.05s/it]                                                          {'loss': 0.9717, 'learning_rate': 1.2924362618268971e-05, 'epoch': 0.42}
 42%|████▏     | 4401/10395 [12:36:22<60:01:02, 36.05s/it] 42%|████▏     | 4402/10395 [12:36:31<46:26:10, 27.89s/it]                                                          {'loss': 0.9106, 'learning_rate': 1.2921382948470769e-05, 'epoch': 0.42}
 42%|████▏     | 4402/10395 [12:36:31<46:26:10, 27.89s/it] 42%|████▏     | 4403/10395 [12:36:38<36:19:09, 21.82s/it]                                                          {'loss': 0.9244, 'learning_rate': 1.2918402995070954e-05, 'epoch': 0.42}
 42%|████▏     | 4403/10395 [12:36:38<36:19:09, 21.82s/it] 42%|████▏     | 4404/10395 [12:36:46<29:23:56, 17.67s/it]                                                          {'loss': 0.9053, 'learning_rate': 1.2915422758358811e-05, 'epoch': 0.42}
 42%|████▏     | 4404/10395 [12:36:46<29:23:56, 17.67s/it] 42%|████▏     | 4405/10395 [12:36:55<24:47:32, 14.90s/it]                                                          {'loss': 0.8837, 'learning_rate': 1.2912442238623655e-05, 'epoch': 0.42}
 42%|████▏     | 4405/10395 [12:36:55<24:47:32, 14.90s/it] 42%|████▏     | 4406/10395 [12:37:02<21:05:25, 12.68s/it]                                                          {'loss': 1.0366, 'learning_rate': 1.2909461436154833e-05, 'epoch': 0.42}
 42%|████▏     | 4406/10395 [12:37:02<21:05:25, 12.68s/it] 42%|████▏     | 4407/10395 [12:37:10<18:50:08, 11.32s/it]                                                          {'loss': 0.8816, 'learning_rate': 1.2906480351241713e-05, 'epoch': 0.42}
 42%|████▏     | 4407/10395 [12:37:10<18:50:08, 11.32s/it] 42%|████▏     | 4408/10395 [12:37:18<16:50:52, 10.13s/it]                                                          {'loss': 0.9477, 'learning_rate': 1.2903498984173692e-05, 'epoch': 0.42}
 42%|████▏     | 4408/10395 [12:37:18<16:50:52, 10.13s/it] 42%|████▏     | 4409/10395 [12:37:25<15:36:50,  9.39s/it]                                                          {'loss': 0.9882, 'learning_rate': 1.290051733524019e-05, 'epoch': 0.42}
 42%|████▏     | 4409/10395 [12:37:25<15:36:50,  9.39s/it] 42%|████▏     | 4410/10395 [12:37:34<14:59:42,  9.02s/it]                                                          {'loss': 0.9733, 'learning_rate': 1.2897535404730667e-05, 'epoch': 0.42}
 42%|████▏     | 4410/10395 [12:37:34<14:59:42,  9.02s/it] 42%|████▏     | 4411/10395 [12:37:41<14:03:51,  8.46s/it]                                                          {'loss': 0.9307, 'learning_rate': 1.28945531929346e-05, 'epoch': 0.42}
 42%|████▏     | 4411/10395 [12:37:41<14:03:51,  8.46s/it] 42%|████▏     | 4412/10395 [12:37:48<13:34:31,  8.17s/it]                                                          {'loss': 0.9103, 'learning_rate': 1.2891570700141496e-05, 'epoch': 0.42}
 42%|████▏     | 4412/10395 [12:37:48<13:34:31,  8.17s/it] 42%|████▏     | 4413/10395 [12:37:57<13:54:17,  8.37s/it]                                                          {'loss': 0.8441, 'learning_rate': 1.2888587926640881e-05, 'epoch': 0.42}
 42%|████▏     | 4413/10395 [12:37:57<13:54:17,  8.37s/it] 42%|████▏     | 4414/10395 [12:38:05<13:38:07,  8.21s/it]                                                          {'loss': 0.9114, 'learning_rate': 1.2885604872722328e-05, 'epoch': 0.42}
 42%|████▏     | 4414/10395 [12:38:05<13:38:07,  8.21s/it] 42%|████▏     | 4415/10395 [12:38:12<13:18:26,  8.01s/it]                                                          {'loss': 0.9812, 'learning_rate': 1.2882621538675422e-05, 'epoch': 0.42}
 42%|████▏     | 4415/10395 [12:38:12<13:18:26,  8.01s/it] 42%|████▏     | 4416/10395 [12:38:20<12:59:25,  7.82s/it]                                                          {'loss': 0.9904, 'learning_rate': 1.2879637924789775e-05, 'epoch': 0.42}
 42%|████▏     | 4416/10395 [12:38:20<12:59:25,  7.82s/it] 42%|████▏     | 4417/10395 [12:38:27<12:52:53,  7.76s/it]                                                          {'loss': 0.975, 'learning_rate': 1.287665403135503e-05, 'epoch': 0.42}
 42%|████▏     | 4417/10395 [12:38:27<12:52:53,  7.76s/it] 43%|████▎     | 4418/10395 [12:38:35<12:54:43,  7.78s/it]                                                          {'loss': 0.9889, 'learning_rate': 1.2873669858660858e-05, 'epoch': 0.42}
 43%|████▎     | 4418/10395 [12:38:35<12:54:43,  7.78s/it] 43%|████▎     | 4419/10395 [12:38:43<12:47:37,  7.71s/it]                                                          {'loss': 0.9484, 'learning_rate': 1.2870685406996964e-05, 'epoch': 0.43}
 43%|████▎     | 4419/10395 [12:38:43<12:47:37,  7.71s/it] 43%|████▎     | 4420/10395 [12:38:51<13:06:51,  7.90s/it]                                                          {'loss': 0.9429, 'learning_rate': 1.2867700676653062e-05, 'epoch': 0.43}
 43%|████▎     | 4420/10395 [12:38:51<13:06:51,  7.90s/it] 43%|████▎     | 4421/10395 [12:38:59<13:20:36,  8.04s/it]                                                          {'loss': 0.8601, 'learning_rate': 1.2864715667918901e-05, 'epoch': 0.43}
 43%|████▎     | 4421/10395 [12:38:59<13:20:36,  8.04s/it] 43%|████▎     | 4422/10395 [12:39:07<13:10:35,  7.94s/it]                                                          {'loss': 0.9561, 'learning_rate': 1.2861730381084275e-05, 'epoch': 0.43}
 43%|████▎     | 4422/10395 [12:39:07<13:10:35,  7.94s/it] 43%|████▎     | 4423/10395 [12:39:17<13:58:25,  8.42s/it]                                                          {'loss': 0.8438, 'learning_rate': 1.2858744816438972e-05, 'epoch': 0.43}
 43%|████▎     | 4423/10395 [12:39:17<13:58:25,  8.42s/it] 43%|████▎     | 4424/10395 [12:39:25<14:04:45,  8.49s/it]                                                          {'loss': 0.896, 'learning_rate': 1.2855758974272832e-05, 'epoch': 0.43}
 43%|████▎     | 4424/10395 [12:39:25<14:04:45,  8.49s/it] 43%|████▎     | 4425/10395 [12:39:32<13:10:10,  7.94s/it]                                                          {'loss': 0.9763, 'learning_rate': 1.2852772854875715e-05, 'epoch': 0.43}
 43%|████▎     | 4425/10395 [12:39:32<13:10:10,  7.94s/it] 43%|████▎     | 4426/10395 [12:39:50<18:15:13, 11.01s/it]                                                          {'loss': 0.4086, 'learning_rate': 1.2849786458537507e-05, 'epoch': 0.43}
 43%|████▎     | 4426/10395 [12:39:50<18:15:13, 11.01s/it] 43%|████▎     | 4427/10395 [12:39:59<17:15:12, 10.41s/it]                                                          {'loss': 0.8206, 'learning_rate': 1.284679978554812e-05, 'epoch': 0.43}
 43%|████▎     | 4427/10395 [12:39:59<17:15:12, 10.41s/it] 43%|████▎     | 4428/10395 [12:40:07<16:10:13,  9.76s/it]                                                          {'loss': 0.9424, 'learning_rate': 1.2843812836197488e-05, 'epoch': 0.43}
 43%|████▎     | 4428/10395 [12:40:07<16:10:13,  9.76s/it] 43%|████▎     | 4429/10395 [12:40:15<15:17:54,  9.23s/it]                                                          {'loss': 0.9103, 'learning_rate': 1.2840825610775586e-05, 'epoch': 0.43}
 43%|████▎     | 4429/10395 [12:40:15<15:17:54,  9.23s/it] 43%|████▎     | 4430/10395 [12:40:23<14:15:23,  8.60s/it]                                                          {'loss': 0.9567, 'learning_rate': 1.2837838109572407e-05, 'epoch': 0.43}
 43%|████▎     | 4430/10395 [12:40:23<14:15:23,  8.60s/it] 43%|████▎     | 4431/10395 [12:40:31<13:57:37,  8.43s/it]                                                          {'loss': 0.9616, 'learning_rate': 1.2834850332877968e-05, 'epoch': 0.43}
 43%|████▎     | 4431/10395 [12:40:31<13:57:37,  8.43s/it] 43%|████▎     | 4432/10395 [12:40:38<13:31:15,  8.16s/it]                                                          {'loss': 0.9565, 'learning_rate': 1.2831862280982314e-05, 'epoch': 0.43}
 43%|████▎     | 4432/10395 [12:40:38<13:31:15,  8.16s/it] 43%|████▎     | 4433/10395 [12:40:46<13:27:12,  8.12s/it]                                                          {'loss': 0.9642, 'learning_rate': 1.2828873954175523e-05, 'epoch': 0.43}
 43%|████▎     | 4433/10395 [12:40:46<13:27:12,  8.12s/it] 43%|████▎     | 4434/10395 [12:40:54<13:32:37,  8.18s/it]                                                          {'loss': 0.9036, 'learning_rate': 1.2825885352747695e-05, 'epoch': 0.43}
 43%|████▎     | 4434/10395 [12:40:54<13:32:37,  8.18s/it] 43%|████▎     | 4435/10395 [12:41:11<17:31:13, 10.58s/it]                                                          {'loss': 0.3766, 'learning_rate': 1.2822896476988957e-05, 'epoch': 0.43}
 43%|████▎     | 4435/10395 [12:41:11<17:31:13, 10.58s/it] 43%|████▎     | 4436/10395 [12:41:19<16:31:48,  9.99s/it]                                                          {'loss': 0.8508, 'learning_rate': 1.2819907327189457e-05, 'epoch': 0.43}
 43%|████▎     | 4436/10395 [12:41:19<16:31:48,  9.99s/it] 43%|████▎     | 4437/10395 [12:41:27<15:16:07,  9.23s/it]                                                          {'loss': 0.9704, 'learning_rate': 1.2816917903639386e-05, 'epoch': 0.43}
 43%|████▎     | 4437/10395 [12:41:27<15:16:07,  9.23s/it] 43%|████▎     | 4438/10395 [12:41:35<14:49:51,  8.96s/it]                                                          {'loss': 0.9168, 'learning_rate': 1.281392820662894e-05, 'epoch': 0.43}
 43%|████▎     | 4438/10395 [12:41:35<14:49:51,  8.96s/it] 43%|████▎     | 4439/10395 [12:41:42<14:02:06,  8.48s/it]                                                          {'loss': 0.9001, 'learning_rate': 1.2810938236448358e-05, 'epoch': 0.43}
 43%|████▎     | 4439/10395 [12:41:42<14:02:06,  8.48s/it] 43%|████▎     | 4440/10395 [12:41:51<13:58:22,  8.45s/it]                                                          {'loss': 0.9031, 'learning_rate': 1.2807947993387898e-05, 'epoch': 0.43}
 43%|████▎     | 4440/10395 [12:41:51<13:58:22,  8.45s/it] 43%|████▎     | 4441/10395 [12:41:58<13:33:44,  8.20s/it]                                                          {'loss': 0.9227, 'learning_rate': 1.2804957477737849e-05, 'epoch': 0.43}
 43%|████▎     | 4441/10395 [12:41:58<13:33:44,  8.20s/it] 43%|████▎     | 4442/10395 [12:42:06<13:16:06,  8.02s/it]                                                          {'loss': 0.9156, 'learning_rate': 1.2801966689788523e-05, 'epoch': 0.43}
 43%|████▎     | 4442/10395 [12:42:06<13:16:06,  8.02s/it] 43%|████▎     | 4443/10395 [12:42:15<13:43:29,  8.30s/it]                                                          {'loss': 0.8816, 'learning_rate': 1.2798975629830258e-05, 'epoch': 0.43}
 43%|████▎     | 4443/10395 [12:42:15<13:43:29,  8.30s/it] 43%|████▎     | 4444/10395 [12:42:23<13:49:29,  8.36s/it]                                                          {'loss': 0.9797, 'learning_rate': 1.2795984298153416e-05, 'epoch': 0.43}
 43%|████▎     | 4444/10395 [12:42:23<13:49:29,  8.36s/it] 43%|████▎     | 4445/10395 [12:42:31<13:24:44,  8.12s/it]                                                          {'loss': 0.8802, 'learning_rate': 1.27929926950484e-05, 'epoch': 0.43}
 43%|████▎     | 4445/10395 [12:42:31<13:24:44,  8.12s/it] 43%|████▎     | 4446/10395 [12:42:39<13:07:00,  7.94s/it]                                                          {'loss': 0.9596, 'learning_rate': 1.2790000820805618e-05, 'epoch': 0.43}
 43%|████▎     | 4446/10395 [12:42:39<13:07:00,  7.94s/it] 43%|████▎     | 4447/10395 [12:42:46<12:41:20,  7.68s/it]                                                          {'loss': 1.0048, 'learning_rate': 1.2787008675715523e-05, 'epoch': 0.43}
 43%|████▎     | 4447/10395 [12:42:46<12:41:20,  7.68s/it] 43%|████▎     | 4448/10395 [12:42:53<12:30:44,  7.57s/it]                                                          {'loss': 0.9642, 'learning_rate': 1.2784016260068577e-05, 'epoch': 0.43}
 43%|████▎     | 4448/10395 [12:42:53<12:30:44,  7.57s/it] 43%|████▎     | 4449/10395 [12:43:00<12:25:47,  7.53s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.2781023574155283e-05, 'epoch': 0.43}
 43%|████▎     | 4449/10395 [12:43:00<12:25:47,  7.53s/it] 43%|████▎     | 4450/10395 [12:43:18<17:38:53, 10.69s/it]                                                          {'loss': 0.3835, 'learning_rate': 1.2778030618266164e-05, 'epoch': 0.43}
 43%|████▎     | 4450/10395 [12:43:18<17:38:53, 10.69s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 43%|████▎     | 4451/10395 [12:45:03<64:07:54, 38.84s/it]                                                          {'loss': 0.8646, 'learning_rate': 1.2775037392691769e-05, 'epoch': 0.43}
 43%|████▎     | 4451/10395 [12:45:03<64:07:54, 38.84s/it] 43%|████▎     | 4452/10395 [12:45:11<48:49:08, 29.57s/it]                                                          {'loss': 0.8982, 'learning_rate': 1.2772043897722672e-05, 'epoch': 0.43}
 43%|████▎     | 4452/10395 [12:45:11<48:49:08, 29.57s/it] 43%|████▎     | 4453/10395 [12:45:18<37:40:36, 22.83s/it]                                                          {'loss': 0.9335, 'learning_rate': 1.276905013364948e-05, 'epoch': 0.43}
 43%|████▎     | 4453/10395 [12:45:18<37:40:36, 22.83s/it] 43%|████▎     | 4454/10395 [12:45:26<30:20:07, 18.38s/it]                                                          {'loss': 0.9433, 'learning_rate': 1.2766056100762818e-05, 'epoch': 0.43}
 43%|████▎     | 4454/10395 [12:45:26<30:20:07, 18.38s/it] 43%|████▎     | 4455/10395 [12:45:35<25:27:14, 15.43s/it]                                                          {'loss': 0.9386, 'learning_rate': 1.2763061799353342e-05, 'epoch': 0.43}
 43%|████▎     | 4455/10395 [12:45:35<25:27:14, 15.43s/it] 43%|████▎     | 4456/10395 [12:45:45<22:52:14, 13.86s/it]                                                          {'loss': 0.9112, 'learning_rate': 1.276006722971173e-05, 'epoch': 0.43}
 43%|████▎     | 4456/10395 [12:45:45<22:52:14, 13.86s/it] 43%|████▎     | 4457/10395 [12:45:53<20:05:21, 12.18s/it]                                                          {'loss': 0.9188, 'learning_rate': 1.2757072392128689e-05, 'epoch': 0.43}
 43%|████▎     | 4457/10395 [12:45:53<20:05:21, 12.18s/it] 43%|████▎     | 4458/10395 [12:46:01<18:08:34, 11.00s/it]                                                          {'loss': 0.8707, 'learning_rate': 1.2754077286894953e-05, 'epoch': 0.43}
 43%|████▎     | 4458/10395 [12:46:01<18:08:34, 11.00s/it] 43%|████▎     | 4459/10395 [12:46:10<16:54:23, 10.25s/it]                                                          {'loss': 0.9207, 'learning_rate': 1.2751081914301277e-05, 'epoch': 0.43}
 43%|████▎     | 4459/10395 [12:46:10<16:54:23, 10.25s/it] 43%|████▎     | 4460/10395 [12:46:18<16:05:02,  9.76s/it]                                                          {'loss': 0.9068, 'learning_rate': 1.2748086274638452e-05, 'epoch': 0.43}
 43%|████▎     | 4460/10395 [12:46:18<16:05:02,  9.76s/it] 43%|████▎     | 4461/10395 [12:46:26<15:11:57,  9.22s/it]                                                          {'loss': 0.908, 'learning_rate': 1.274509036819728e-05, 'epoch': 0.43}
 43%|████▎     | 4461/10395 [12:46:26<15:11:57,  9.22s/it] 43%|████▎     | 4462/10395 [12:46:34<14:36:56,  8.87s/it]                                                          {'loss': 0.8872, 'learning_rate': 1.2742094195268604e-05, 'epoch': 0.43}
 43%|████▎     | 4462/10395 [12:46:34<14:36:56,  8.87s/it] 43%|████▎     | 4463/10395 [12:46:43<14:32:34,  8.83s/it]                                                          {'loss': 0.8834, 'learning_rate': 1.2739097756143285e-05, 'epoch': 0.43}
 43%|████▎     | 4463/10395 [12:46:43<14:32:34,  8.83s/it] 43%|████▎     | 4464/10395 [12:46:50<13:47:07,  8.37s/it]                                                          {'loss': 0.9537, 'learning_rate': 1.2736101051112207e-05, 'epoch': 0.43}
 43%|████▎     | 4464/10395 [12:46:50<13:47:07,  8.37s/it] 43%|████▎     | 4465/10395 [12:47:08<18:24:00, 11.17s/it]                                                          {'loss': 0.3407, 'learning_rate': 1.2733104080466285e-05, 'epoch': 0.43}
 43%|████▎     | 4465/10395 [12:47:08<18:24:00, 11.17s/it] 43%|████▎     | 4466/10395 [12:47:16<16:35:10, 10.07s/it]                                                          {'loss': 0.9509, 'learning_rate': 1.2730106844496461e-05, 'epoch': 0.43}
 43%|████▎     | 4466/10395 [12:47:16<16:35:10, 10.07s/it] 43%|████▎     | 4467/10395 [12:47:24<15:33:06,  9.44s/it]                                                          {'loss': 0.9101, 'learning_rate': 1.2727109343493698e-05, 'epoch': 0.43}
 43%|████▎     | 4467/10395 [12:47:24<15:33:06,  9.44s/it] 43%|████▎     | 4468/10395 [12:47:31<14:42:42,  8.94s/it]                                                          {'loss': 0.9479, 'learning_rate': 1.2724111577748987e-05, 'epoch': 0.43}
 43%|████▎     | 4468/10395 [12:47:31<14:42:42,  8.94s/it] 43%|████▎     | 4469/10395 [12:47:48<18:25:16, 11.19s/it]                                                          {'loss': 0.3875, 'learning_rate': 1.2721113547553347e-05, 'epoch': 0.43}
 43%|████▎     | 4469/10395 [12:47:48<18:25:16, 11.19s/it] 43%|████▎     | 4470/10395 [12:47:55<16:35:29, 10.08s/it]                                                          {'loss': 0.8841, 'learning_rate': 1.271811525319782e-05, 'epoch': 0.43}
 43%|████▎     | 4470/10395 [12:47:55<16:35:29, 10.08s/it] 43%|████▎     | 4471/10395 [12:48:03<15:31:45,  9.44s/it]                                                          {'loss': 0.8646, 'learning_rate': 1.271511669497347e-05, 'epoch': 0.43}
 43%|████▎     | 4471/10395 [12:48:03<15:31:45,  9.44s/it] 43%|████▎     | 4472/10395 [12:48:11<14:34:50,  8.86s/it]                                                          {'loss': 0.9476, 'learning_rate': 1.2712117873171394e-05, 'epoch': 0.43}
 43%|████▎     | 4472/10395 [12:48:11<14:34:50,  8.86s/it] 43%|████▎     | 4473/10395 [12:48:19<14:10:13,  8.61s/it]                                                          {'loss': 0.9418, 'learning_rate': 1.2709118788082713e-05, 'epoch': 0.43}
 43%|████▎     | 4473/10395 [12:48:19<14:10:13,  8.61s/it] 43%|████▎     | 4474/10395 [12:48:26<13:19:13,  8.10s/it]                                                          {'loss': 0.9899, 'learning_rate': 1.2706119439998568e-05, 'epoch': 0.43}
 43%|████▎     | 4474/10395 [12:48:26<13:19:13,  8.10s/it] 43%|████▎     | 4475/10395 [12:48:33<13:02:29,  7.93s/it]                                                          {'loss': 0.9352, 'learning_rate': 1.2703119829210131e-05, 'epoch': 0.43}
 43%|████▎     | 4475/10395 [12:48:33<13:02:29,  7.93s/it] 43%|████▎     | 4476/10395 [12:48:41<12:46:27,  7.77s/it]                                                          {'loss': 0.9432, 'learning_rate': 1.2700119956008597e-05, 'epoch': 0.43}
 43%|████▎     | 4476/10395 [12:48:41<12:46:27,  7.77s/it] 43%|████▎     | 4477/10395 [12:48:49<13:11:59,  8.03s/it]                                                          {'loss': 0.8289, 'learning_rate': 1.2697119820685189e-05, 'epoch': 0.43}
 43%|████▎     | 4477/10395 [12:48:49<13:11:59,  8.03s/it] 43%|████▎     | 4478/10395 [12:48:57<13:10:00,  8.01s/it]                                                          {'loss': 0.889, 'learning_rate': 1.269411942353115e-05, 'epoch': 0.43}
 43%|████▎     | 4478/10395 [12:48:57<13:10:00,  8.01s/it] 43%|████▎     | 4479/10395 [12:49:06<13:32:07,  8.24s/it]                                                          {'loss': 0.7813, 'learning_rate': 1.2691118764837758e-05, 'epoch': 0.43}
 43%|████▎     | 4479/10395 [12:49:06<13:32:07,  8.24s/it] 43%|████▎     | 4480/10395 [12:49:13<13:07:33,  7.99s/it]                                                          {'loss': 0.9921, 'learning_rate': 1.2688117844896306e-05, 'epoch': 0.43}
 43%|████▎     | 4480/10395 [12:49:13<13:07:33,  7.99s/it] 43%|████▎     | 4481/10395 [12:49:21<12:48:28,  7.80s/it]                                                          {'loss': 1.0165, 'learning_rate': 1.2685116663998118e-05, 'epoch': 0.43}
 43%|████▎     | 4481/10395 [12:49:21<12:48:28,  7.80s/it] 43%|████▎     | 4482/10395 [12:49:29<12:53:48,  7.85s/it]                                                          {'loss': 0.8834, 'learning_rate': 1.2682115222434541e-05, 'epoch': 0.43}
 43%|████▎     | 4482/10395 [12:49:29<12:53:48,  7.85s/it] 43%|████▎     | 4483/10395 [12:49:37<13:13:04,  8.05s/it]                                                          {'loss': 0.9253, 'learning_rate': 1.2679113520496951e-05, 'epoch': 0.43}
 43%|████▎     | 4483/10395 [12:49:37<13:13:04,  8.05s/it] 43%|████▎     | 4484/10395 [12:49:45<13:00:59,  7.93s/it]                                                          {'loss': 0.8652, 'learning_rate': 1.2676111558476744e-05, 'epoch': 0.43}
 43%|████▎     | 4484/10395 [12:49:45<13:00:59,  7.93s/it] 43%|████▎     | 4485/10395 [12:49:52<12:51:30,  7.83s/it]                                                          {'loss': 0.9499, 'learning_rate': 1.2673109336665353e-05, 'epoch': 0.43}
 43%|████▎     | 4485/10395 [12:49:52<12:51:30,  7.83s/it] 43%|████▎     | 4486/10395 [12:50:01<13:09:11,  8.01s/it]                                                          {'loss': 0.8875, 'learning_rate': 1.2670106855354211e-05, 'epoch': 0.43}
 43%|████▎     | 4486/10395 [12:50:01<13:09:11,  8.01s/it] 43%|████▎     | 4487/10395 [12:50:09<13:04:22,  7.97s/it]                                                          {'loss': 0.9267, 'learning_rate': 1.2667104114834805e-05, 'epoch': 0.43}
 43%|████▎     | 4487/10395 [12:50:09<13:04:22,  7.97s/it] 43%|████▎     | 4488/10395 [12:50:17<13:06:59,  7.99s/it]                                                          {'loss': 0.8755, 'learning_rate': 1.2664101115398633e-05, 'epoch': 0.43}
 43%|████▎     | 4488/10395 [12:50:17<13:06:59,  7.99s/it] 43%|████▎     | 4489/10395 [12:50:25<13:02:29,  7.95s/it]                                                          {'loss': 0.8497, 'learning_rate': 1.2661097857337216e-05, 'epoch': 0.43}
 43%|████▎     | 4489/10395 [12:50:25<13:02:29,  7.95s/it] 43%|████▎     | 4490/10395 [12:50:42<17:31:10, 10.68s/it]                                                          {'loss': 0.3767, 'learning_rate': 1.2658094340942105e-05, 'epoch': 0.43}
 43%|████▎     | 4490/10395 [12:50:42<17:31:10, 10.68s/it] 43%|████▎     | 4491/10395 [12:50:49<15:51:10,  9.67s/it]                                                          {'loss': 0.9389, 'learning_rate': 1.2655090566504877e-05, 'epoch': 0.43}
 43%|████▎     | 4491/10395 [12:50:49<15:51:10,  9.67s/it] 43%|████▎     | 4492/10395 [12:50:57<14:47:01,  9.02s/it]                                                          {'loss': 0.9272, 'learning_rate': 1.2652086534317132e-05, 'epoch': 0.43}
 43%|████▎     | 4492/10395 [12:50:57<14:47:01,  9.02s/it] 43%|████▎     | 4493/10395 [12:51:05<14:19:35,  8.74s/it]                                                          {'loss': 0.8726, 'learning_rate': 1.2649082244670493e-05, 'epoch': 0.43}
 43%|████▎     | 4493/10395 [12:51:05<14:19:35,  8.74s/it] 43%|████▎     | 4494/10395 [12:51:12<13:49:37,  8.44s/it]                                                          {'loss': 0.9003, 'learning_rate': 1.264607769785661e-05, 'epoch': 0.43}
 43%|████▎     | 4494/10395 [12:51:12<13:49:37,  8.44s/it] 43%|████▎     | 4495/10395 [12:51:20<13:20:36,  8.14s/it]                                                          {'loss': 1.0048, 'learning_rate': 1.2643072894167157e-05, 'epoch': 0.43}
 43%|████▎     | 4495/10395 [12:51:20<13:20:36,  8.14s/it] 43%|████▎     | 4496/10395 [12:51:27<12:48:55,  7.82s/it]                                                          {'loss': 0.875, 'learning_rate': 1.2640067833893839e-05, 'epoch': 0.43}
 43%|████▎     | 4496/10395 [12:51:27<12:48:55,  7.82s/it] 43%|████▎     | 4497/10395 [12:51:34<12:28:56,  7.62s/it]                                                          {'loss': 0.909, 'learning_rate': 1.2637062517328373e-05, 'epoch': 0.43}
 43%|████▎     | 4497/10395 [12:51:34<12:28:56,  7.62s/it] 43%|████▎     | 4498/10395 [12:51:42<12:31:23,  7.65s/it]                                                          {'loss': 0.9187, 'learning_rate': 1.2634056944762519e-05, 'epoch': 0.43}
 43%|████▎     | 4498/10395 [12:51:42<12:31:23,  7.65s/it] 43%|████▎     | 4499/10395 [12:51:49<12:23:32,  7.57s/it]                                                          {'loss': 0.8586, 'learning_rate': 1.2631051116488043e-05, 'epoch': 0.43}
 43%|████▎     | 4499/10395 [12:51:49<12:23:32,  7.57s/it] 43%|████▎     | 4500/10395 [12:51:57<12:31:19,  7.65s/it]                                                          {'loss': 0.9896, 'learning_rate': 1.262804503279675e-05, 'epoch': 0.43}
 43%|████▎     | 4500/10395 [12:51:57<12:31:19,  7.65s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 43%|████▎     | 4501/10395 [12:53:45<61:58:32, 37.85s/it]                                                          {'loss': 0.3992, 'learning_rate': 1.2625038693980454e-05, 'epoch': 0.43}
 43%|████▎     | 4501/10395 [12:53:45<61:58:32, 37.85s/it] 43%|████▎     | 4502/10395 [12:53:52<46:49:13, 28.60s/it]                                                          {'loss': 0.9617, 'learning_rate': 1.2622032100331017e-05, 'epoch': 0.43}
 43%|████▎     | 4502/10395 [12:53:52<46:49:13, 28.60s/it] 43%|████▎     | 4503/10395 [12:54:01<36:52:50, 22.53s/it]                                                          {'loss': 0.8971, 'learning_rate': 1.261902525214031e-05, 'epoch': 0.43}
 43%|████▎     | 4503/10395 [12:54:01<36:52:50, 22.53s/it] 43%|████▎     | 4504/10395 [12:54:08<29:34:04, 18.07s/it]                                                          {'loss': 0.9964, 'learning_rate': 1.2616018149700222e-05, 'epoch': 0.43}
 43%|████▎     | 4504/10395 [12:54:08<29:34:04, 18.07s/it] 43%|████▎     | 4505/10395 [12:54:17<24:45:42, 15.13s/it]                                                          {'loss': 0.8732, 'learning_rate': 1.2613010793302683e-05, 'epoch': 0.43}
 43%|████▎     | 4505/10395 [12:54:17<24:45:42, 15.13s/it] 43%|████▎     | 4506/10395 [12:54:27<22:33:41, 13.79s/it]                                                          {'loss': 0.894, 'learning_rate': 1.2610003183239643e-05, 'epoch': 0.43}
 43%|████▎     | 4506/10395 [12:54:27<22:33:41, 13.79s/it] 43%|████▎     | 4507/10395 [12:54:35<19:32:50, 11.95s/it]                                                          {'loss': 0.9611, 'learning_rate': 1.2606995319803072e-05, 'epoch': 0.43}
 43%|████▎     | 4507/10395 [12:54:35<19:32:50, 11.95s/it] 43%|████▎     | 4508/10395 [12:54:53<22:22:29, 13.68s/it]                                                          {'loss': 0.412, 'learning_rate': 1.2603987203284966e-05, 'epoch': 0.43}
 43%|████▎     | 4508/10395 [12:54:53<22:22:29, 13.68s/it] 43%|████▎     | 4509/10395 [12:55:01<19:31:15, 11.94s/it]                                                          {'loss': 0.9449, 'learning_rate': 1.2600978833977344e-05, 'epoch': 0.43}
 43%|████▎     | 4509/10395 [12:55:01<19:31:15, 11.94s/it] 43%|████▎     | 4510/10395 [12:55:09<17:59:54, 11.01s/it]                                                          {'loss': 0.8371, 'learning_rate': 1.2597970212172256e-05, 'epoch': 0.43}
 43%|████▎     | 4510/10395 [12:55:09<17:59:54, 11.01s/it] 43%|████▎     | 4511/10395 [12:55:18<16:41:54, 10.22s/it]                                                          {'loss': 0.9783, 'learning_rate': 1.2594961338161777e-05, 'epoch': 0.43}
 43%|████▎     | 4511/10395 [12:55:18<16:41:54, 10.22s/it] 43%|████▎     | 4512/10395 [12:55:26<15:42:31,  9.61s/it]                                                          {'loss': 0.9202, 'learning_rate': 1.2591952212237992e-05, 'epoch': 0.43}
 43%|████▎     | 4512/10395 [12:55:26<15:42:31,  9.61s/it] 43%|████▎     | 4513/10395 [12:55:33<14:40:55,  8.99s/it]                                                          {'loss': 0.8782, 'learning_rate': 1.2588942834693023e-05, 'epoch': 0.43}
 43%|████▎     | 4513/10395 [12:55:33<14:40:55,  8.99s/it] 43%|████▎     | 4514/10395 [12:55:41<14:03:52,  8.61s/it]                                                          {'loss': 0.9727, 'learning_rate': 1.2585933205819023e-05, 'epoch': 0.43}
 43%|████▎     | 4514/10395 [12:55:41<14:03:52,  8.61s/it] 43%|████▎     | 4515/10395 [12:55:49<13:33:01,  8.30s/it]                                                          {'loss': 0.9371, 'learning_rate': 1.258292332590815e-05, 'epoch': 0.43}
 43%|████▎     | 4515/10395 [12:55:49<13:33:01,  8.30s/it] 43%|████▎     | 4516/10395 [12:55:57<13:22:14,  8.19s/it]                                                          {'loss': 0.9765, 'learning_rate': 1.25799131952526e-05, 'epoch': 0.43}
 43%|████▎     | 4516/10395 [12:55:57<13:22:14,  8.19s/it] 43%|████▎     | 4517/10395 [12:56:04<13:07:08,  8.03s/it]                                                          {'loss': 0.9546, 'learning_rate': 1.2576902814144588e-05, 'epoch': 0.43}
 43%|████▎     | 4517/10395 [12:56:04<13:07:08,  8.03s/it] 43%|████▎     | 4518/10395 [12:56:12<13:04:44,  8.01s/it]                                                          {'loss': 0.9409, 'learning_rate': 1.2573892182876361e-05, 'epoch': 0.43}
 43%|████▎     | 4518/10395 [12:56:12<13:04:44,  8.01s/it] 43%|████▎     | 4519/10395 [12:56:20<12:46:47,  7.83s/it]                                                          {'loss': 0.9337, 'learning_rate': 1.2570881301740181e-05, 'epoch': 0.43}
 43%|████▎     | 4519/10395 [12:56:20<12:46:47,  7.83s/it] 43%|████▎     | 4520/10395 [12:56:28<12:53:20,  7.90s/it]                                                          {'loss': 0.8968, 'learning_rate': 1.2567870171028337e-05, 'epoch': 0.43}
 43%|████▎     | 4520/10395 [12:56:28<12:53:20,  7.90s/it] 43%|████▎     | 4521/10395 [12:56:37<13:31:11,  8.29s/it]                                                          {'loss': 0.9287, 'learning_rate': 1.2564858791033143e-05, 'epoch': 0.43}
 43%|████▎     | 4521/10395 [12:56:37<13:31:11,  8.29s/it] 44%|████▎     | 4522/10395 [12:56:44<12:59:17,  7.96s/it]                                                          {'loss': 0.9171, 'learning_rate': 1.2561847162046943e-05, 'epoch': 0.43}
 44%|████▎     | 4522/10395 [12:56:44<12:59:17,  7.96s/it] 44%|████▎     | 4523/10395 [12:56:53<13:13:09,  8.10s/it]                                                          {'loss': 0.9323, 'learning_rate': 1.2558835284362093e-05, 'epoch': 0.44}
 44%|████▎     | 4523/10395 [12:56:53<13:13:09,  8.10s/it] 44%|████▎     | 4524/10395 [12:57:01<13:28:55,  8.27s/it]                                                          {'loss': 0.9428, 'learning_rate': 1.2555823158270982e-05, 'epoch': 0.44}
 44%|████▎     | 4524/10395 [12:57:01<13:28:55,  8.27s/it] 44%|████▎     | 4525/10395 [12:57:09<13:17:31,  8.15s/it]                                                          {'loss': 0.9213, 'learning_rate': 1.2552810784066019e-05, 'epoch': 0.44}
 44%|████▎     | 4525/10395 [12:57:09<13:17:31,  8.15s/it] 44%|████▎     | 4526/10395 [12:57:17<13:19:17,  8.17s/it]                                                          {'loss': 0.9076, 'learning_rate': 1.2549798162039642e-05, 'epoch': 0.44}
 44%|████▎     | 4526/10395 [12:57:17<13:19:17,  8.17s/it] 44%|████▎     | 4527/10395 [12:57:26<13:24:05,  8.22s/it]                                                          {'loss': 0.9445, 'learning_rate': 1.2546785292484307e-05, 'epoch': 0.44}
 44%|████▎     | 4527/10395 [12:57:26<13:24:05,  8.22s/it] 44%|████▎     | 4528/10395 [12:57:34<13:24:21,  8.23s/it]                                                          {'loss': 0.9479, 'learning_rate': 1.2543772175692497e-05, 'epoch': 0.44}
 44%|████▎     | 4528/10395 [12:57:34<13:24:21,  8.23s/it] 44%|████▎     | 4529/10395 [12:57:41<13:02:53,  8.01s/it]                                                          {'loss': 0.9313, 'learning_rate': 1.2540758811956725e-05, 'epoch': 0.44}
 44%|████▎     | 4529/10395 [12:57:41<13:02:53,  8.01s/it] 44%|████▎     | 4530/10395 [12:57:49<12:47:06,  7.85s/it]                                                          {'loss': 0.9896, 'learning_rate': 1.2537745201569516e-05, 'epoch': 0.44}
 44%|████▎     | 4530/10395 [12:57:49<12:47:06,  7.85s/it] 44%|████▎     | 4531/10395 [12:57:56<12:32:33,  7.70s/it]                                                          {'loss': 0.928, 'learning_rate': 1.2534731344823423e-05, 'epoch': 0.44}
 44%|████▎     | 4531/10395 [12:57:56<12:32:33,  7.70s/it] 44%|████▎     | 4532/10395 [12:58:05<12:49:48,  7.88s/it]                                                          {'loss': 0.9209, 'learning_rate': 1.2531717242011027e-05, 'epoch': 0.44}
 44%|████▎     | 4532/10395 [12:58:05<12:49:48,  7.88s/it] 44%|████▎     | 4533/10395 [12:58:14<13:40:06,  8.39s/it]                                                          {'loss': 0.9363, 'learning_rate': 1.2528702893424938e-05, 'epoch': 0.44}
 44%|████▎     | 4533/10395 [12:58:14<13:40:06,  8.39s/it] 44%|████▎     | 4534/10395 [12:58:31<17:55:01, 11.01s/it]                                                          {'loss': 0.3919, 'learning_rate': 1.2525688299357773e-05, 'epoch': 0.44}
 44%|████▎     | 4534/10395 [12:58:31<17:55:01, 11.01s/it] 44%|████▎     | 4535/10395 [12:58:39<16:14:13,  9.97s/it]                                                          {'loss': 0.9722, 'learning_rate': 1.2522673460102184e-05, 'epoch': 0.44}
 44%|████▎     | 4535/10395 [12:58:39<16:14:13,  9.97s/it] 44%|████▎     | 4536/10395 [12:58:47<15:10:55,  9.33s/it]                                                          {'loss': 0.8467, 'learning_rate': 1.2519658375950845e-05, 'epoch': 0.44}
 44%|████▎     | 4536/10395 [12:58:47<15:10:55,  9.33s/it] 44%|████▎     | 4537/10395 [12:58:54<14:20:32,  8.81s/it]                                                          {'loss': 0.9093, 'learning_rate': 1.2516643047196458e-05, 'epoch': 0.44}
 44%|████▎     | 4537/10395 [12:58:54<14:20:32,  8.81s/it] 44%|████▎     | 4538/10395 [12:59:02<13:43:10,  8.43s/it]                                                          {'loss': 0.9061, 'learning_rate': 1.251362747413174e-05, 'epoch': 0.44}
 44%|████▎     | 4538/10395 [12:59:02<13:43:10,  8.43s/it] 44%|████▎     | 4539/10395 [12:59:09<13:17:52,  8.17s/it]                                                          {'loss': 0.9149, 'learning_rate': 1.251061165704944e-05, 'epoch': 0.44}
 44%|████▎     | 4539/10395 [12:59:09<13:17:52,  8.17s/it] 44%|████▎     | 4540/10395 [12:59:18<13:17:48,  8.18s/it]                                                          {'loss': 1.0181, 'learning_rate': 1.2507595596242326e-05, 'epoch': 0.44}
 44%|████▎     | 4540/10395 [12:59:18<13:17:48,  8.18s/it] 44%|████▎     | 4541/10395 [12:59:25<12:52:43,  7.92s/it]                                                          {'loss': 0.9364, 'learning_rate': 1.2504579292003189e-05, 'epoch': 0.44}
 44%|████▎     | 4541/10395 [12:59:25<12:52:43,  7.92s/it] 44%|████▎     | 4542/10395 [12:59:32<12:34:52,  7.74s/it]                                                          {'loss': 1.0318, 'learning_rate': 1.2501562744624846e-05, 'epoch': 0.44}
 44%|████▎     | 4542/10395 [12:59:32<12:34:52,  7.74s/it] 44%|████▎     | 4543/10395 [12:59:39<12:16:45,  7.55s/it]                                                          {'loss': 0.9434, 'learning_rate': 1.249854595440014e-05, 'epoch': 0.44}
 44%|████▎     | 4543/10395 [12:59:39<12:16:45,  7.55s/it] 44%|████▎     | 4544/10395 [12:59:47<12:12:19,  7.51s/it]                                                          {'loss': 0.9638, 'learning_rate': 1.249552892162193e-05, 'epoch': 0.44}
 44%|████▎     | 4544/10395 [12:59:47<12:12:19,  7.51s/it] 44%|████▎     | 4545/10395 [12:59:54<12:05:19,  7.44s/it]                                                          {'loss': 0.9778, 'learning_rate': 1.2492511646583108e-05, 'epoch': 0.44}
 44%|████▎     | 4545/10395 [12:59:54<12:05:19,  7.44s/it] 44%|████▎     | 4546/10395 [13:00:02<12:14:46,  7.54s/it]                                                          {'loss': 0.9873, 'learning_rate': 1.2489494129576578e-05, 'epoch': 0.44}
 44%|████▎     | 4546/10395 [13:00:02<12:14:46,  7.54s/it] 44%|████▎     | 4547/10395 [13:00:11<12:52:48,  7.93s/it]                                                          {'loss': 0.9094, 'learning_rate': 1.248647637089528e-05, 'epoch': 0.44}
 44%|████▎     | 4547/10395 [13:00:11<12:52:48,  7.93s/it] 44%|████▍     | 4548/10395 [13:00:18<12:44:47,  7.85s/it]                                                          {'loss': 0.9187, 'learning_rate': 1.2483458370832171e-05, 'epoch': 0.44}
 44%|████▍     | 4548/10395 [13:00:18<12:44:47,  7.85s/it] 44%|████▍     | 4549/10395 [13:00:26<12:42:37,  7.83s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.2480440129680229e-05, 'epoch': 0.44}
 44%|████▍     | 4549/10395 [13:00:26<12:42:37,  7.83s/it] 44%|████▍     | 4550/10395 [13:00:34<12:58:18,  7.99s/it]                                                          {'loss': 0.8562, 'learning_rate': 1.2477421647732459e-05, 'epoch': 0.44}
 44%|████▍     | 4550/10395 [13:00:34<12:58:18,  7.99s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 4551/10395 [13:02:24<62:19:33, 38.39s/it]                                                          {'loss': 0.4324, 'learning_rate': 1.247440292528189e-05, 'epoch': 0.44}
 44%|████▍     | 4551/10395 [13:02:24<62:19:33, 38.39s/it] 44%|████▍     | 4552/10395 [13:02:31<47:07:36, 29.04s/it]                                                          {'loss': 0.9384, 'learning_rate': 1.2471383962621575e-05, 'epoch': 0.44}
 44%|████▍     | 4552/10395 [13:02:31<47:07:36, 29.04s/it] 44%|████▍     | 4553/10395 [13:02:39<36:51:53, 22.72s/it]                                                          {'loss': 0.8588, 'learning_rate': 1.2468364760044585e-05, 'epoch': 0.44}
 44%|████▍     | 4553/10395 [13:02:39<36:51:53, 22.72s/it] 44%|████▍     | 4554/10395 [13:02:47<29:48:33, 18.37s/it]                                                          {'loss': 0.8306, 'learning_rate': 1.2465345317844018e-05, 'epoch': 0.44}
 44%|████▍     | 4554/10395 [13:02:47<29:48:33, 18.37s/it] 44%|████▍     | 4555/10395 [13:03:04<28:59:49, 17.87s/it]                                                          {'loss': 0.4434, 'learning_rate': 1.2462325636312996e-05, 'epoch': 0.44}
 44%|████▍     | 4555/10395 [13:03:04<28:59:49, 17.87s/it] 44%|████▍     | 4556/10395 [13:03:12<24:26:20, 15.07s/it]                                                          {'loss': 0.8748, 'learning_rate': 1.2459305715744665e-05, 'epoch': 0.44}
 44%|████▍     | 4556/10395 [13:03:12<24:26:20, 15.07s/it] 44%|████▍     | 4557/10395 [13:03:20<20:39:34, 12.74s/it]                                                          {'loss': 0.974, 'learning_rate': 1.2456285556432188e-05, 'epoch': 0.44}
 44%|████▍     | 4557/10395 [13:03:20<20:39:34, 12.74s/it] 44%|████▍     | 4558/10395 [13:03:28<18:29:48, 11.41s/it]                                                          {'loss': 0.9481, 'learning_rate': 1.2453265158668762e-05, 'epoch': 0.44}
 44%|████▍     | 4558/10395 [13:03:28<18:29:48, 11.41s/it] 44%|████▍     | 4559/10395 [13:03:35<16:24:55, 10.13s/it]                                                          {'loss': 0.9402, 'learning_rate': 1.2450244522747595e-05, 'epoch': 0.44}
 44%|████▍     | 4559/10395 [13:03:35<16:24:55, 10.13s/it] 44%|████▍     | 4560/10395 [13:03:42<15:03:25,  9.29s/it]                                                          {'loss': 0.9626, 'learning_rate': 1.2447223648961924e-05, 'epoch': 0.44}
 44%|████▍     | 4560/10395 [13:03:42<15:03:25,  9.29s/it] 44%|████▍     | 4561/10395 [13:03:51<14:27:42,  8.92s/it]                                                          {'loss': 0.8393, 'learning_rate': 1.2444202537605012e-05, 'epoch': 0.44}
 44%|████▍     | 4561/10395 [13:03:51<14:27:42,  8.92s/it] 44%|████▍     | 4562/10395 [13:03:59<14:16:10,  8.81s/it]                                                          {'loss': 0.9104, 'learning_rate': 1.2441181188970144e-05, 'epoch': 0.44}
 44%|████▍     | 4562/10395 [13:03:59<14:16:10,  8.81s/it] 44%|████▍     | 4563/10395 [13:04:16<18:27:05, 11.39s/it]                                                          {'loss': 0.4339, 'learning_rate': 1.243815960335062e-05, 'epoch': 0.44}
 44%|████▍     | 4563/10395 [13:04:16<18:27:05, 11.39s/it] 44%|████▍     | 4564/10395 [13:04:24<16:48:08, 10.37s/it]                                                          {'loss': 0.9198, 'learning_rate': 1.2435137781039772e-05, 'epoch': 0.44}
 44%|████▍     | 4564/10395 [13:04:25<16:48:08, 10.37s/it] 44%|████▍     | 4565/10395 [13:04:33<15:39:56,  9.67s/it]                                                          {'loss': 1.0034, 'learning_rate': 1.2432115722330953e-05, 'epoch': 0.44}
 44%|████▍     | 4565/10395 [13:04:33<15:39:56,  9.67s/it] 44%|████▍     | 4566/10395 [13:04:40<14:41:34,  9.07s/it]                                                          {'loss': 0.8586, 'learning_rate': 1.2429093427517537e-05, 'epoch': 0.44}
 44%|████▍     | 4566/10395 [13:04:40<14:41:34,  9.07s/it] 44%|████▍     | 4567/10395 [13:04:49<14:41:10,  9.07s/it]                                                          {'loss': 0.8685, 'learning_rate': 1.242607089689292e-05, 'epoch': 0.44}
 44%|████▍     | 4567/10395 [13:04:49<14:41:10,  9.07s/it] 44%|████▍     | 4568/10395 [13:04:57<14:05:22,  8.70s/it]                                                          {'loss': 0.986, 'learning_rate': 1.242304813075053e-05, 'epoch': 0.44}
 44%|████▍     | 4568/10395 [13:04:57<14:05:22,  8.70s/it] 44%|████▍     | 4569/10395 [13:05:06<14:20:44,  8.86s/it]                                                          {'loss': 0.894, 'learning_rate': 1.2420025129383803e-05, 'epoch': 0.44}
 44%|████▍     | 4569/10395 [13:05:06<14:20:44,  8.86s/it] 44%|████▍     | 4570/10395 [13:05:14<13:48:27,  8.53s/it]                                                          {'loss': 0.8102, 'learning_rate': 1.2417001893086207e-05, 'epoch': 0.44}
 44%|████▍     | 4570/10395 [13:05:14<13:48:27,  8.53s/it] 44%|████▍     | 4571/10395 [13:05:22<13:24:26,  8.29s/it]                                                          {'loss': 0.9729, 'learning_rate': 1.2413978422151231e-05, 'epoch': 0.44}
 44%|████▍     | 4571/10395 [13:05:22<13:24:26,  8.29s/it] 44%|████▍     | 4572/10395 [13:05:29<13:04:11,  8.08s/it]                                                          {'loss': 0.9701, 'learning_rate': 1.2410954716872392e-05, 'epoch': 0.44}
 44%|████▍     | 4572/10395 [13:05:29<13:04:11,  8.08s/it] 44%|████▍     | 4573/10395 [13:05:37<12:57:26,  8.01s/it]                                                          {'loss': 0.9219, 'learning_rate': 1.240793077754322e-05, 'epoch': 0.44}
 44%|████▍     | 4573/10395 [13:05:37<12:57:26,  8.01s/it] 44%|████▍     | 4574/10395 [13:05:45<12:41:57,  7.85s/it]                                                          {'loss': 0.917, 'learning_rate': 1.2404906604457272e-05, 'epoch': 0.44}
 44%|████▍     | 4574/10395 [13:05:45<12:41:57,  7.85s/it] 44%|████▍     | 4575/10395 [13:05:53<12:48:26,  7.92s/it]                                                          {'loss': 0.9497, 'learning_rate': 1.2401882197908133e-05, 'epoch': 0.44}
 44%|████▍     | 4575/10395 [13:05:53<12:48:26,  7.92s/it] 44%|████▍     | 4576/10395 [13:06:00<12:28:37,  7.72s/it]                                                          {'loss': 0.9089, 'learning_rate': 1.2398857558189401e-05, 'epoch': 0.44}
 44%|████▍     | 4576/10395 [13:06:00<12:28:37,  7.72s/it] 44%|████▍     | 4577/10395 [13:06:07<12:13:12,  7.56s/it]                                                          {'loss': 0.9413, 'learning_rate': 1.2395832685594707e-05, 'epoch': 0.44}
 44%|████▍     | 4577/10395 [13:06:07<12:13:12,  7.56s/it] 44%|████▍     | 4578/10395 [13:06:15<12:25:05,  7.69s/it]                                                          {'loss': 0.8919, 'learning_rate': 1.2392807580417689e-05, 'epoch': 0.44}
 44%|████▍     | 4578/10395 [13:06:15<12:25:05,  7.69s/it] 44%|████▍     | 4579/10395 [13:06:23<12:24:48,  7.68s/it]                                                          {'loss': 0.9299, 'learning_rate': 1.2389782242952031e-05, 'epoch': 0.44}
 44%|████▍     | 4579/10395 [13:06:23<12:24:48,  7.68s/it] 44%|████▍     | 4580/10395 [13:06:31<12:28:58,  7.73s/it]                                                          {'loss': 0.907, 'learning_rate': 1.2386756673491415e-05, 'epoch': 0.44}
 44%|████▍     | 4580/10395 [13:06:31<12:28:58,  7.73s/it] 44%|████▍     | 4581/10395 [13:06:38<12:20:36,  7.64s/it]                                                          {'loss': 0.9031, 'learning_rate': 1.2383730872329566e-05, 'epoch': 0.44}
 44%|████▍     | 4581/10395 [13:06:38<12:20:36,  7.64s/it] 44%|████▍     | 4582/10395 [13:06:46<12:34:48,  7.79s/it]                                                          {'loss': 0.9285, 'learning_rate': 1.2380704839760216e-05, 'epoch': 0.44}
 44%|████▍     | 4582/10395 [13:06:46<12:34:48,  7.79s/it] 44%|████▍     | 4583/10395 [13:06:55<12:55:20,  8.00s/it]                                                          {'loss': 0.8623, 'learning_rate': 1.2377678576077128e-05, 'epoch': 0.44}
 44%|████▍     | 4583/10395 [13:06:55<12:55:20,  8.00s/it] 44%|████▍     | 4584/10395 [13:07:02<12:38:05,  7.83s/it]                                                          {'loss': 0.9625, 'learning_rate': 1.2374652081574086e-05, 'epoch': 0.44}
 44%|████▍     | 4584/10395 [13:07:02<12:38:05,  7.83s/it] 44%|████▍     | 4585/10395 [13:07:09<12:19:07,  7.63s/it]                                                          {'loss': 1.0539, 'learning_rate': 1.2371625356544894e-05, 'epoch': 0.44}
 44%|████▍     | 4585/10395 [13:07:09<12:19:07,  7.63s/it] 44%|████▍     | 4586/10395 [13:07:17<12:18:07,  7.62s/it]                                                          {'loss': 0.9388, 'learning_rate': 1.2368598401283378e-05, 'epoch': 0.44}
 44%|████▍     | 4586/10395 [13:07:17<12:18:07,  7.62s/it] 44%|████▍     | 4587/10395 [13:07:25<12:27:41,  7.72s/it]                                                          {'loss': 0.914, 'learning_rate': 1.2365571216083393e-05, 'epoch': 0.44}
 44%|████▍     | 4587/10395 [13:07:25<12:27:41,  7.72s/it] 44%|████▍     | 4588/10395 [13:07:33<12:22:30,  7.67s/it]                                                          {'loss': 1.0193, 'learning_rate': 1.236254380123881e-05, 'epoch': 0.44}
 44%|████▍     | 4588/10395 [13:07:33<12:22:30,  7.67s/it] 44%|████▍     | 4589/10395 [13:07:40<12:23:05,  7.68s/it]                                                          {'loss': 0.881, 'learning_rate': 1.2359516157043525e-05, 'epoch': 0.44}
 44%|████▍     | 4589/10395 [13:07:40<12:23:05,  7.68s/it] 44%|████▍     | 4590/10395 [13:07:57<16:58:40, 10.53s/it]                                                          {'loss': 0.3946, 'learning_rate': 1.2356488283791448e-05, 'epoch': 0.44}
 44%|████▍     | 4590/10395 [13:07:57<16:58:40, 10.53s/it] 44%|████▍     | 4591/10395 [13:08:14<20:00:22, 12.41s/it]                                                          {'loss': 0.4312, 'learning_rate': 1.2353460181776528e-05, 'epoch': 0.44}
 44%|████▍     | 4591/10395 [13:08:14<20:00:22, 12.41s/it] 44%|████▍     | 4592/10395 [13:08:30<21:26:33, 13.30s/it]                                                          {'loss': 0.3622, 'learning_rate': 1.2350431851292726e-05, 'epoch': 0.44}
 44%|████▍     | 4592/10395 [13:08:30<21:26:33, 13.30s/it] 44%|████▍     | 4593/10395 [13:08:39<19:19:58, 12.00s/it]                                                          {'loss': 0.9338, 'learning_rate': 1.2347403292634016e-05, 'epoch': 0.44}
 44%|████▍     | 4593/10395 [13:08:39<19:19:58, 12.00s/it] 44%|████▍     | 4594/10395 [13:08:46<17:10:20, 10.66s/it]                                                          {'loss': 0.9443, 'learning_rate': 1.2344374506094416e-05, 'epoch': 0.44}
 44%|████▍     | 4594/10395 [13:08:46<17:10:20, 10.66s/it] 44%|████▍     | 4595/10395 [13:08:55<16:07:16, 10.01s/it]                                                          {'loss': 0.9721, 'learning_rate': 1.2341345491967948e-05, 'epoch': 0.44}
 44%|████▍     | 4595/10395 [13:08:55<16:07:16, 10.01s/it] 44%|████▍     | 4596/10395 [13:09:02<14:59:32,  9.31s/it]                                                          {'loss': 0.9878, 'learning_rate': 1.2338316250548665e-05, 'epoch': 0.44}
 44%|████▍     | 4596/10395 [13:09:02<14:59:32,  9.31s/it] 44%|████▍     | 4597/10395 [13:09:11<14:37:05,  9.08s/it]                                                          {'loss': 0.8755, 'learning_rate': 1.2335286782130634e-05, 'epoch': 0.44}
 44%|████▍     | 4597/10395 [13:09:11<14:37:05,  9.08s/it] 44%|████▍     | 4598/10395 [13:09:18<13:54:35,  8.64s/it]                                                          {'loss': 0.9247, 'learning_rate': 1.233225708700795e-05, 'epoch': 0.44}
 44%|████▍     | 4598/10395 [13:09:18<13:54:35,  8.64s/it] 44%|████▍     | 4599/10395 [13:09:26<13:36:52,  8.46s/it]                                                          {'loss': 0.8754, 'learning_rate': 1.232922716547474e-05, 'epoch': 0.44}
 44%|████▍     | 4599/10395 [13:09:26<13:36:52,  8.46s/it] 44%|████▍     | 4600/10395 [13:09:34<13:06:57,  8.15s/it]                                                          {'loss': 0.8993, 'learning_rate': 1.232619701782513e-05, 'epoch': 0.44}
 44%|████▍     | 4600/10395 [13:09:34<13:06:57,  8.15s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 4601/10395 [13:11:14<57:24:11, 35.67s/it]                                                          {'loss': 0.8876, 'learning_rate': 1.2323166644353282e-05, 'epoch': 0.44}
 44%|████▍     | 4601/10395 [13:11:14<57:24:11, 35.67s/it] 44%|████▍     | 4602/10395 [13:11:22<44:08:30, 27.43s/it]                                                          {'loss': 0.9196, 'learning_rate': 1.2320136045353384e-05, 'epoch': 0.44}
 44%|████▍     | 4602/10395 [13:11:22<44:08:30, 27.43s/it] 44%|████▍     | 4603/10395 [13:11:30<34:39:39, 21.54s/it]                                                          {'loss': 0.8781, 'learning_rate': 1.2317105221119638e-05, 'epoch': 0.44}
 44%|████▍     | 4603/10395 [13:11:30<34:39:39, 21.54s/it] 44%|████▍     | 4604/10395 [13:11:37<27:46:38, 17.27s/it]                                                          {'loss': 0.8929, 'learning_rate': 1.2314074171946267e-05, 'epoch': 0.44}
 44%|████▍     | 4604/10395 [13:11:37<27:46:38, 17.27s/it] 44%|████▍     | 4605/10395 [13:11:45<23:04:29, 14.35s/it]                                                          {'loss': 0.9298, 'learning_rate': 1.2311042898127519e-05, 'epoch': 0.44}
 44%|████▍     | 4605/10395 [13:11:45<23:04:29, 14.35s/it] 44%|████▍     | 4606/10395 [13:11:53<19:59:50, 12.44s/it]                                                          {'loss': 0.885, 'learning_rate': 1.2308011399957668e-05, 'epoch': 0.44}
 44%|████▍     | 4606/10395 [13:11:53<19:59:50, 12.44s/it] 44%|████▍     | 4607/10395 [13:12:01<17:50:45, 11.10s/it]                                                          {'loss': 0.9014, 'learning_rate': 1.2304979677731001e-05, 'epoch': 0.44}
 44%|████▍     | 4607/10395 [13:12:01<17:50:45, 11.10s/it] 44%|████▍     | 4608/10395 [13:12:08<15:57:39,  9.93s/it]                                                          {'loss': 0.9799, 'learning_rate': 1.2301947731741834e-05, 'epoch': 0.44}
 44%|████▍     | 4608/10395 [13:12:08<15:57:39,  9.93s/it] 44%|████▍     | 4609/10395 [13:12:16<15:13:15,  9.47s/it]                                                          {'loss': 0.8835, 'learning_rate': 1.2298915562284497e-05, 'epoch': 0.44}
 44%|████▍     | 4609/10395 [13:12:16<15:13:15,  9.47s/it] 44%|████▍     | 4610/10395 [13:12:24<14:11:58,  8.84s/it]                                                          {'loss': 0.8508, 'learning_rate': 1.2295883169653356e-05, 'epoch': 0.44}
 44%|████▍     | 4610/10395 [13:12:24<14:11:58,  8.84s/it] 44%|████▍     | 4611/10395 [13:12:31<13:40:01,  8.51s/it]                                                          {'loss': 0.935, 'learning_rate': 1.229285055414278e-05, 'epoch': 0.44}
 44%|████▍     | 4611/10395 [13:12:31<13:40:01,  8.51s/it] 44%|████▍     | 4612/10395 [13:12:39<13:28:30,  8.39s/it]                                                          {'loss': 0.9026, 'learning_rate': 1.228981771604717e-05, 'epoch': 0.44}
 44%|████▍     | 4612/10395 [13:12:39<13:28:30,  8.39s/it] 44%|████▍     | 4613/10395 [13:12:56<17:35:50, 10.96s/it]                                                          {'loss': 0.4013, 'learning_rate': 1.228678465566095e-05, 'epoch': 0.44}
 44%|████▍     | 4613/10395 [13:12:56<17:35:50, 10.96s/it] 44%|████▍     | 4614/10395 [13:13:04<15:55:43,  9.92s/it]                                                          {'loss': 0.9267, 'learning_rate': 1.2283751373278565e-05, 'epoch': 0.44}
 44%|████▍     | 4614/10395 [13:13:04<15:55:43,  9.92s/it] 44%|████▍     | 4615/10395 [13:13:21<19:12:34, 11.96s/it]                                                          {'loss': 0.3616, 'learning_rate': 1.2280717869194476e-05, 'epoch': 0.44}
 44%|████▍     | 4615/10395 [13:13:21<19:12:34, 11.96s/it] 44%|████▍     | 4616/10395 [13:13:28<17:02:17, 10.61s/it]                                                          {'loss': 0.9372, 'learning_rate': 1.227768414370317e-05, 'epoch': 0.44}
 44%|████▍     | 4616/10395 [13:13:28<17:02:17, 10.61s/it] 44%|████▍     | 4617/10395 [13:13:36<15:53:20,  9.90s/it]                                                          {'loss': 0.9419, 'learning_rate': 1.2274650197099154e-05, 'epoch': 0.44}
 44%|████▍     | 4617/10395 [13:13:36<15:53:20,  9.90s/it] 44%|████▍     | 4618/10395 [13:13:45<15:08:16,  9.43s/it]                                                          {'loss': 0.9455, 'learning_rate': 1.2271616029676958e-05, 'epoch': 0.44}
 44%|████▍     | 4618/10395 [13:13:45<15:08:16,  9.43s/it] 44%|████▍     | 4619/10395 [13:13:53<14:35:04,  9.09s/it]                                                          {'loss': 0.8598, 'learning_rate': 1.2268581641731134e-05, 'epoch': 0.44}
 44%|████▍     | 4619/10395 [13:13:53<14:35:04,  9.09s/it] 44%|████▍     | 4620/10395 [13:14:00<13:40:57,  8.53s/it]                                                          {'loss': 0.9464, 'learning_rate': 1.226554703355625e-05, 'epoch': 0.44}
 44%|████▍     | 4620/10395 [13:14:00<13:40:57,  8.53s/it] 44%|████▍     | 4621/10395 [13:14:08<13:26:18,  8.38s/it]                                                          {'loss': 0.8574, 'learning_rate': 1.2262512205446904e-05, 'epoch': 0.44}
 44%|████▍     | 4621/10395 [13:14:08<13:26:18,  8.38s/it] 44%|████▍     | 4622/10395 [13:14:26<17:57:43, 11.20s/it]                                                          {'loss': 0.4278, 'learning_rate': 1.2259477157697706e-05, 'epoch': 0.44}
 44%|████▍     | 4622/10395 [13:14:26<17:57:43, 11.20s/it] 44%|████▍     | 4623/10395 [13:14:35<17:10:12, 10.71s/it]                                                          {'loss': 0.9545, 'learning_rate': 1.2256441890603294e-05, 'epoch': 0.44}
 44%|████▍     | 4623/10395 [13:14:35<17:10:12, 10.71s/it] 44%|████▍     | 4624/10395 [13:14:43<15:43:06,  9.81s/it]                                                          {'loss': 0.9768, 'learning_rate': 1.2253406404458326e-05, 'epoch': 0.44}
 44%|████▍     | 4624/10395 [13:14:43<15:43:06,  9.81s/it] 44%|████▍     | 4625/10395 [13:14:51<14:43:25,  9.19s/it]                                                          {'loss': 0.9047, 'learning_rate': 1.225037069955748e-05, 'epoch': 0.44}
 44%|████▍     | 4625/10395 [13:14:51<14:43:25,  9.19s/it] 45%|████▍     | 4626/10395 [13:14:58<13:55:12,  8.69s/it]                                                          {'loss': 0.9161, 'learning_rate': 1.2247334776195457e-05, 'epoch': 0.45}
 45%|████▍     | 4626/10395 [13:14:58<13:55:12,  8.69s/it] 45%|████▍     | 4627/10395 [13:15:07<13:50:43,  8.64s/it]                                                          {'loss': 0.8829, 'learning_rate': 1.2244298634666973e-05, 'epoch': 0.45}
 45%|████▍     | 4627/10395 [13:15:07<13:50:43,  8.64s/it] 45%|████▍     | 4628/10395 [13:15:14<13:10:59,  8.23s/it]                                                          {'loss': 0.8519, 'learning_rate': 1.2241262275266777e-05, 'epoch': 0.45}
 45%|████▍     | 4628/10395 [13:15:14<13:10:59,  8.23s/it] 45%|████▍     | 4629/10395 [13:15:22<12:47:25,  7.99s/it]                                                          {'loss': 0.9802, 'learning_rate': 1.2238225698289626e-05, 'epoch': 0.45}
 45%|████▍     | 4629/10395 [13:15:22<12:47:25,  7.99s/it] 45%|████▍     | 4630/10395 [13:15:30<12:47:19,  7.99s/it]                                                          {'loss': 0.9184, 'learning_rate': 1.2235188904030309e-05, 'epoch': 0.45}
 45%|████▍     | 4630/10395 [13:15:30<12:47:19,  7.99s/it] 45%|████▍     | 4631/10395 [13:15:38<12:49:55,  8.01s/it]                                                          {'loss': 0.9315, 'learning_rate': 1.223215189278363e-05, 'epoch': 0.45}
 45%|████▍     | 4631/10395 [13:15:38<12:49:55,  8.01s/it] 45%|████▍     | 4632/10395 [13:15:47<13:20:59,  8.34s/it]                                                          {'loss': 0.909, 'learning_rate': 1.2229114664844415e-05, 'epoch': 0.45}
 45%|████▍     | 4632/10395 [13:15:47<13:20:59,  8.34s/it] 45%|████▍     | 4633/10395 [13:15:55<13:25:37,  8.39s/it]                                                          {'loss': 0.8472, 'learning_rate': 1.2226077220507511e-05, 'epoch': 0.45}
 45%|████▍     | 4633/10395 [13:15:55<13:25:37,  8.39s/it] 45%|████▍     | 4634/10395 [13:16:03<12:59:14,  8.12s/it]                                                          {'loss': 0.9212, 'learning_rate': 1.2223039560067788e-05, 'epoch': 0.45}
 45%|████▍     | 4634/10395 [13:16:03<12:59:14,  8.12s/it] 45%|████▍     | 4635/10395 [13:16:11<12:56:27,  8.09s/it]                                                          {'loss': 0.9828, 'learning_rate': 1.2220001683820135e-05, 'epoch': 0.45}
 45%|████▍     | 4635/10395 [13:16:11<12:56:27,  8.09s/it] 45%|████▍     | 4636/10395 [13:16:18<12:37:42,  7.89s/it]                                                          {'loss': 0.9752, 'learning_rate': 1.2216963592059466e-05, 'epoch': 0.45}
 45%|████▍     | 4636/10395 [13:16:18<12:37:42,  7.89s/it] 45%|████▍     | 4637/10395 [13:16:26<12:32:33,  7.84s/it]                                                          {'loss': 0.9478, 'learning_rate': 1.2213925285080706e-05, 'epoch': 0.45}
 45%|████▍     | 4637/10395 [13:16:26<12:32:33,  7.84s/it] 45%|████▍     | 4638/10395 [13:16:33<12:17:01,  7.68s/it]                                                          {'loss': 0.9304, 'learning_rate': 1.2210886763178808e-05, 'epoch': 0.45}
 45%|████▍     | 4638/10395 [13:16:33<12:17:01,  7.68s/it] 45%|████▍     | 4639/10395 [13:16:41<12:20:06,  7.71s/it]                                                          {'loss': 0.9362, 'learning_rate': 1.2207848026648752e-05, 'epoch': 0.45}
 45%|████▍     | 4639/10395 [13:16:41<12:20:06,  7.71s/it] 45%|████▍     | 4640/10395 [13:16:58<16:38:43, 10.41s/it]                                                          {'loss': 0.4552, 'learning_rate': 1.2204809075785527e-05, 'epoch': 0.45}
 45%|████▍     | 4640/10395 [13:16:58<16:38:43, 10.41s/it] 45%|████▍     | 4641/10395 [13:17:06<15:35:28,  9.75s/it]                                                          {'loss': 0.9451, 'learning_rate': 1.2201769910884147e-05, 'epoch': 0.45}
 45%|████▍     | 4641/10395 [13:17:06<15:35:28,  9.75s/it] 45%|████▍     | 4642/10395 [13:17:15<15:01:10,  9.40s/it]                                                          {'loss': 0.8928, 'learning_rate': 1.219873053223965e-05, 'epoch': 0.45}
 45%|████▍     | 4642/10395 [13:17:15<15:01:10,  9.40s/it] 45%|████▍     | 4643/10395 [13:17:22<14:07:10,  8.84s/it]                                                          {'loss': 0.9998, 'learning_rate': 1.2195690940147093e-05, 'epoch': 0.45}
 45%|████▍     | 4643/10395 [13:17:22<14:07:10,  8.84s/it] 45%|████▍     | 4644/10395 [13:17:31<14:15:31,  8.93s/it]                                                          {'loss': 0.9247, 'learning_rate': 1.2192651134901549e-05, 'epoch': 0.45}
 45%|████▍     | 4644/10395 [13:17:31<14:15:31,  8.93s/it] 45%|████▍     | 4645/10395 [13:17:49<18:30:20, 11.59s/it]                                                          {'loss': 0.3871, 'learning_rate': 1.2189611116798121e-05, 'epoch': 0.45}
 45%|████▍     | 4645/10395 [13:17:49<18:30:20, 11.59s/it] 45%|████▍     | 4646/10395 [13:17:56<16:27:51, 10.31s/it]                                                          {'loss': 0.8859, 'learning_rate': 1.2186570886131923e-05, 'epoch': 0.45}
 45%|████▍     | 4646/10395 [13:17:56<16:27:51, 10.31s/it] 45%|████▍     | 4647/10395 [13:18:04<15:03:39,  9.43s/it]                                                          {'loss': 0.943, 'learning_rate': 1.2183530443198097e-05, 'epoch': 0.45}
 45%|████▍     | 4647/10395 [13:18:04<15:03:39,  9.43s/it] 45%|████▍     | 4648/10395 [13:18:11<14:03:10,  8.80s/it]                                                          {'loss': 1.0113, 'learning_rate': 1.2180489788291803e-05, 'epoch': 0.45}
 45%|████▍     | 4648/10395 [13:18:11<14:03:10,  8.80s/it] 45%|████▍     | 4649/10395 [13:18:18<13:20:28,  8.36s/it]                                                          {'loss': 0.9348, 'learning_rate': 1.217744892170822e-05, 'epoch': 0.45}
 45%|████▍     | 4649/10395 [13:18:18<13:20:28,  8.36s/it] 45%|████▍     | 4650/10395 [13:18:27<13:34:54,  8.51s/it]                                                          {'loss': 0.8646, 'learning_rate': 1.217440784374255e-05, 'epoch': 0.45}
 45%|████▍     | 4650/10395 [13:18:27<13:34:54,  8.51s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 45%|████▍     | 4651/10395 [13:20:09<58:09:50, 36.45s/it]                                                          {'loss': 0.9372, 'learning_rate': 1.2171366554690009e-05, 'epoch': 0.45}
 45%|████▍     | 4651/10395 [13:20:09<58:09:50, 36.45s/it] 45%|████▍     | 4652/10395 [13:20:17<44:36:37, 27.96s/it]                                                          {'loss': 0.8974, 'learning_rate': 1.2168325054845844e-05, 'epoch': 0.45}
 45%|████▍     | 4652/10395 [13:20:17<44:36:37, 27.96s/it] 45%|████▍     | 4653/10395 [13:20:27<35:44:00, 22.40s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.2165283344505319e-05, 'epoch': 0.45}
 45%|████▍     | 4653/10395 [13:20:27<35:44:00, 22.40s/it] 45%|████▍     | 4654/10395 [13:20:35<28:58:22, 18.17s/it]                                                          {'loss': 0.9127, 'learning_rate': 1.2162241423963715e-05, 'epoch': 0.45}
 45%|████▍     | 4654/10395 [13:20:35<28:58:22, 18.17s/it] 45%|████▍     | 4655/10395 [13:20:42<23:53:08, 14.98s/it]                                                          {'loss': 0.9123, 'learning_rate': 1.2159199293516331e-05, 'epoch': 0.45}
 45%|████▍     | 4655/10395 [13:20:42<23:53:08, 14.98s/it] 45%|████▍     | 4656/10395 [13:20:50<20:29:12, 12.85s/it]                                                          {'loss': 0.9298, 'learning_rate': 1.2156156953458494e-05, 'epoch': 0.45}
 45%|████▍     | 4656/10395 [13:20:50<20:29:12, 12.85s/it] 45%|████▍     | 4657/10395 [13:20:58<18:08:11, 11.38s/it]                                                          {'loss': 0.9472, 'learning_rate': 1.2153114404085549e-05, 'epoch': 0.45}
 45%|████▍     | 4657/10395 [13:20:58<18:08:11, 11.38s/it] 45%|████▍     | 4658/10395 [13:21:05<16:05:59, 10.10s/it]                                                          {'loss': 0.9284, 'learning_rate': 1.215007164569286e-05, 'epoch': 0.45}
 45%|████▍     | 4658/10395 [13:21:05<16:05:59, 10.10s/it] 45%|████▍     | 4659/10395 [13:21:13<14:42:54,  9.24s/it]                                                          {'loss': 0.9687, 'learning_rate': 1.2147028678575808e-05, 'epoch': 0.45}
 45%|████▍     | 4659/10395 [13:21:13<14:42:54,  9.24s/it] 45%|████▍     | 4660/10395 [13:21:20<13:59:53,  8.79s/it]                                                          {'loss': 0.9663, 'learning_rate': 1.2143985503029801e-05, 'epoch': 0.45}
 45%|████▍     | 4660/10395 [13:21:20<13:59:53,  8.79s/it] 45%|████▍     | 4661/10395 [13:21:28<13:23:18,  8.41s/it]                                                          {'loss': 0.9151, 'learning_rate': 1.2140942119350263e-05, 'epoch': 0.45}
 45%|████▍     | 4661/10395 [13:21:28<13:23:18,  8.41s/it] 45%|████▍     | 4662/10395 [13:21:36<13:21:02,  8.38s/it]                                                          {'loss': 1.0256, 'learning_rate': 1.2137898527832639e-05, 'epoch': 0.45}
 45%|████▍     | 4662/10395 [13:21:36<13:21:02,  8.38s/it] 45%|████▍     | 4663/10395 [13:21:44<13:10:51,  8.28s/it]                                                          {'loss': 0.9203, 'learning_rate': 1.2134854728772395e-05, 'epoch': 0.45}
 45%|████▍     | 4663/10395 [13:21:44<13:10:51,  8.28s/it] 45%|████▍     | 4664/10395 [13:21:52<12:56:37,  8.13s/it]                                                          {'loss': 0.9645, 'learning_rate': 1.2131810722465016e-05, 'epoch': 0.45}
 45%|████▍     | 4664/10395 [13:21:52<12:56:37,  8.13s/it] 45%|████▍     | 4665/10395 [13:22:00<13:01:11,  8.18s/it]                                                          {'loss': 0.8314, 'learning_rate': 1.212876650920601e-05, 'epoch': 0.45}
 45%|████▍     | 4665/10395 [13:22:00<13:01:11,  8.18s/it] 45%|████▍     | 4666/10395 [13:22:07<12:31:41,  7.87s/it]                                                          {'loss': 1.0253, 'learning_rate': 1.2125722089290895e-05, 'epoch': 0.45}
 45%|████▍     | 4666/10395 [13:22:07<12:31:41,  7.87s/it] 45%|████▍     | 4667/10395 [13:22:15<12:19:46,  7.75s/it]                                                          {'loss': 0.9628, 'learning_rate': 1.2122677463015226e-05, 'epoch': 0.45}
 45%|████▍     | 4667/10395 [13:22:15<12:19:46,  7.75s/it] 45%|████▍     | 4668/10395 [13:22:22<12:17:03,  7.72s/it]                                                          {'loss': 1.0034, 'learning_rate': 1.2119632630674565e-05, 'epoch': 0.45}
 45%|████▍     | 4668/10395 [13:22:22<12:17:03,  7.72s/it] 45%|████▍     | 4669/10395 [13:22:30<12:08:14,  7.63s/it]                                                          {'loss': 0.9634, 'learning_rate': 1.21165875925645e-05, 'epoch': 0.45}
 45%|████▍     | 4669/10395 [13:22:30<12:08:14,  7.63s/it] 45%|████▍     | 4670/10395 [13:22:38<12:17:41,  7.73s/it]                                                          {'loss': 0.9496, 'learning_rate': 1.2113542348980629e-05, 'epoch': 0.45}
 45%|████▍     | 4670/10395 [13:22:38<12:17:41,  7.73s/it] 45%|████▍     | 4671/10395 [13:22:46<12:40:13,  7.97s/it]                                                          {'loss': 0.8014, 'learning_rate': 1.2110496900218588e-05, 'epoch': 0.45}
 45%|████▍     | 4671/10395 [13:22:46<12:40:13,  7.97s/it] 45%|████▍     | 4672/10395 [13:22:54<12:34:40,  7.91s/it]                                                          {'loss': 1.0121, 'learning_rate': 1.2107451246574018e-05, 'epoch': 0.45}
 45%|████▍     | 4672/10395 [13:22:54<12:34:40,  7.91s/it] 45%|████▍     | 4673/10395 [13:23:02<12:38:36,  7.95s/it]                                                          {'loss': 0.9148, 'learning_rate': 1.2104405388342584e-05, 'epoch': 0.45}
 45%|████▍     | 4673/10395 [13:23:02<12:38:36,  7.95s/it] 45%|████▍     | 4674/10395 [13:23:10<12:37:53,  7.95s/it]                                                          {'loss': 0.9767, 'learning_rate': 1.2101359325819968e-05, 'epoch': 0.45}
 45%|████▍     | 4674/10395 [13:23:10<12:37:53,  7.95s/it] 45%|████▍     | 4675/10395 [13:23:17<12:18:08,  7.74s/it]                                                          {'loss': 0.9481, 'learning_rate': 1.2098313059301882e-05, 'epoch': 0.45}
 45%|████▍     | 4675/10395 [13:23:17<12:18:08,  7.74s/it] 45%|████▍     | 4676/10395 [13:23:25<12:09:49,  7.66s/it]                                                          {'loss': 0.8631, 'learning_rate': 1.2095266589084052e-05, 'epoch': 0.45}
 45%|████▍     | 4676/10395 [13:23:25<12:09:49,  7.66s/it] 45%|████▍     | 4677/10395 [13:23:33<12:24:06,  7.81s/it]                                                          {'loss': 0.8114, 'learning_rate': 1.2092219915462216e-05, 'epoch': 0.45}
 45%|████▍     | 4677/10395 [13:23:33<12:24:06,  7.81s/it] 45%|████▌     | 4678/10395 [13:23:41<12:32:54,  7.90s/it]                                                          {'loss': 0.99, 'learning_rate': 1.208917303873214e-05, 'epoch': 0.45}
 45%|████▌     | 4678/10395 [13:23:41<12:32:54,  7.90s/it] 45%|████▌     | 4679/10395 [13:23:49<12:30:49,  7.88s/it]                                                          {'loss': 0.9319, 'learning_rate': 1.2086125959189613e-05, 'epoch': 0.45}
 45%|████▌     | 4679/10395 [13:23:49<12:30:49,  7.88s/it] 45%|████▌     | 4680/10395 [13:23:56<12:14:11,  7.71s/it]                                                          {'loss': 0.9564, 'learning_rate': 1.2083078677130435e-05, 'epoch': 0.45}
 45%|████▌     | 4680/10395 [13:23:56<12:14:11,  7.71s/it] 45%|████▌     | 4681/10395 [13:24:04<12:08:22,  7.65s/it]                                                          {'loss': 0.9033, 'learning_rate': 1.208003119285043e-05, 'epoch': 0.45}
 45%|████▌     | 4681/10395 [13:24:04<12:08:22,  7.65s/it] 45%|████▌     | 4682/10395 [13:24:12<12:16:56,  7.74s/it]                                                          {'loss': 0.9086, 'learning_rate': 1.207698350664544e-05, 'epoch': 0.45}
 45%|████▌     | 4682/10395 [13:24:12<12:16:56,  7.74s/it] 45%|████▌     | 4683/10395 [13:24:20<12:31:54,  7.90s/it]                                                          {'loss': 0.8703, 'learning_rate': 1.2073935618811335e-05, 'epoch': 0.45}
 45%|████▌     | 4683/10395 [13:24:20<12:31:54,  7.90s/it] 45%|████▌     | 4684/10395 [13:24:31<13:45:36,  8.67s/it]                                                          {'loss': 0.9182, 'learning_rate': 1.2070887529643989e-05, 'epoch': 0.45}
 45%|████▌     | 4684/10395 [13:24:31<13:45:36,  8.67s/it] 45%|████▌     | 4685/10395 [13:24:38<13:15:14,  8.36s/it]                                                          {'loss': 0.9336, 'learning_rate': 1.2067839239439306e-05, 'epoch': 0.45}
 45%|████▌     | 4685/10395 [13:24:38<13:15:14,  8.36s/it] 45%|████▌     | 4686/10395 [13:24:46<12:56:36,  8.16s/it]                                                          {'loss': 0.9223, 'learning_rate': 1.2064790748493208e-05, 'epoch': 0.45}
 45%|████▌     | 4686/10395 [13:24:46<12:56:36,  8.16s/it] 45%|████▌     | 4687/10395 [13:24:53<12:25:42,  7.84s/it]                                                          {'loss': 0.9827, 'learning_rate': 1.206174205710164e-05, 'epoch': 0.45}
 45%|████▌     | 4687/10395 [13:24:53<12:25:42,  7.84s/it] 45%|████▌     | 4688/10395 [13:25:01<12:27:12,  7.86s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.2058693165560558e-05, 'epoch': 0.45}
 45%|████▌     | 4688/10395 [13:25:01<12:27:12,  7.86s/it] 45%|████▌     | 4689/10395 [13:25:09<12:47:01,  8.07s/it]                                                          {'loss': 0.8467, 'learning_rate': 1.2055644074165941e-05, 'epoch': 0.45}
 45%|████▌     | 4689/10395 [13:25:09<12:47:01,  8.07s/it] 45%|████▌     | 4690/10395 [13:25:17<12:39:00,  7.98s/it]                                                          {'loss': 0.9674, 'learning_rate': 1.205259478321379e-05, 'epoch': 0.45}
 45%|████▌     | 4690/10395 [13:25:17<12:39:00,  7.98s/it] 45%|████▌     | 4691/10395 [13:25:25<12:45:14,  8.05s/it]                                                          {'loss': 0.9381, 'learning_rate': 1.2049545293000127e-05, 'epoch': 0.45}
 45%|████▌     | 4691/10395 [13:25:25<12:45:14,  8.05s/it] 45%|████▌     | 4692/10395 [13:25:34<12:49:23,  8.09s/it]                                                          {'loss': 0.9692, 'learning_rate': 1.2046495603820984e-05, 'epoch': 0.45}
 45%|████▌     | 4692/10395 [13:25:34<12:49:23,  8.09s/it] 45%|████▌     | 4693/10395 [13:25:41<12:29:56,  7.89s/it]                                                          {'loss': 0.9487, 'learning_rate': 1.2043445715972424e-05, 'epoch': 0.45}
 45%|████▌     | 4693/10395 [13:25:41<12:29:56,  7.89s/it] 45%|████▌     | 4694/10395 [13:25:48<12:13:46,  7.72s/it]                                                          {'loss': 0.9492, 'learning_rate': 1.2040395629750518e-05, 'epoch': 0.45}
 45%|████▌     | 4694/10395 [13:25:48<12:13:46,  7.72s/it] 45%|████▌     | 4695/10395 [13:25:56<12:06:12,  7.64s/it]                                                          {'loss': 0.9053, 'learning_rate': 1.2037345345451368e-05, 'epoch': 0.45}
 45%|████▌     | 4695/10395 [13:25:56<12:06:12,  7.64s/it] 45%|████▌     | 4696/10395 [13:26:03<12:03:47,  7.62s/it]                                                          {'loss': 0.8635, 'learning_rate': 1.2034294863371082e-05, 'epoch': 0.45}
 45%|████▌     | 4696/10395 [13:26:03<12:03:47,  7.62s/it] 45%|████▌     | 4697/10395 [13:26:21<16:41:16, 10.54s/it]                                                          {'loss': 0.3671, 'learning_rate': 1.2031244183805797e-05, 'epoch': 0.45}
 45%|████▌     | 4697/10395 [13:26:21<16:41:16, 10.54s/it] 45%|████▌     | 4698/10395 [13:26:29<15:26:58,  9.76s/it]                                                          {'loss': 0.8589, 'learning_rate': 1.2028193307051671e-05, 'epoch': 0.45}
 45%|████▌     | 4698/10395 [13:26:29<15:26:58,  9.76s/it] 45%|████▌     | 4699/10395 [13:26:36<14:21:42,  9.08s/it]                                                          {'loss': 0.8962, 'learning_rate': 1.2025142233404875e-05, 'epoch': 0.45}
 45%|████▌     | 4699/10395 [13:26:36<14:21:42,  9.08s/it] 45%|████▌     | 4700/10395 [13:26:44<13:43:29,  8.68s/it]                                                          {'loss': 0.91, 'learning_rate': 1.2022090963161595e-05, 'epoch': 0.45}
 45%|████▌     | 4700/10395 [13:26:44<13:43:29,  8.68s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 45%|████▌     | 4701/10395 [13:28:19<54:43:52, 34.60s/it]                                                          {'loss': 0.8845, 'learning_rate': 1.2019039496618044e-05, 'epoch': 0.45}
 45%|████▌     | 4701/10395 [13:28:19<54:43:52, 34.60s/it] 45%|████▌     | 4702/10395 [13:28:27<41:56:40, 26.52s/it]                                                          {'loss': 0.8756, 'learning_rate': 1.2015987834070457e-05, 'epoch': 0.45}
 45%|████▌     | 4702/10395 [13:28:27<41:56:40, 26.52s/it] 45%|████▌     | 4703/10395 [13:28:34<33:00:57, 20.88s/it]                                                          {'loss': 0.9547, 'learning_rate': 1.2012935975815076e-05, 'epoch': 0.45}
 45%|████▌     | 4703/10395 [13:28:34<33:00:57, 20.88s/it] 45%|████▌     | 4704/10395 [13:28:50<30:41:52, 19.42s/it]                                                          {'loss': 0.3977, 'learning_rate': 1.2009883922148173e-05, 'epoch': 0.45}
 45%|████▌     | 4704/10395 [13:28:50<30:41:52, 19.42s/it] 45%|████▌     | 4705/10395 [13:28:58<25:09:49, 15.92s/it]                                                          {'loss': 0.9116, 'learning_rate': 1.2006831673366034e-05, 'epoch': 0.45}
 45%|████▌     | 4705/10395 [13:28:58<25:09:49, 15.92s/it] 45%|████▌     | 4706/10395 [13:29:06<21:30:30, 13.61s/it]                                                          {'loss': 0.8949, 'learning_rate': 1.2003779229764967e-05, 'epoch': 0.45}
 45%|████▌     | 4706/10395 [13:29:06<21:30:30, 13.61s/it] 45%|████▌     | 4707/10395 [13:29:14<18:34:46, 11.76s/it]                                                          {'loss': 0.9024, 'learning_rate': 1.2000726591641293e-05, 'epoch': 0.45}
 45%|████▌     | 4707/10395 [13:29:14<18:34:46, 11.76s/it] 45%|████▌     | 4708/10395 [13:29:22<16:46:04, 10.61s/it]                                                          {'loss': 0.9169, 'learning_rate': 1.1997673759291357e-05, 'epoch': 0.45}
 45%|████▌     | 4708/10395 [13:29:22<16:46:04, 10.61s/it] 45%|████▌     | 4709/10395 [13:29:30<15:27:47,  9.79s/it]                                                          {'loss': 1.0143, 'learning_rate': 1.1994620733011521e-05, 'epoch': 0.45}
 45%|████▌     | 4709/10395 [13:29:30<15:27:47,  9.79s/it] 45%|████▌     | 4710/10395 [13:29:46<18:49:57, 11.93s/it]                                                          {'loss': 0.4292, 'learning_rate': 1.1991567513098168e-05, 'epoch': 0.45}
 45%|████▌     | 4710/10395 [13:29:46<18:49:57, 11.93s/it] 45%|████▌     | 4711/10395 [13:29:55<17:11:06, 10.88s/it]                                                          {'loss': 0.8604, 'learning_rate': 1.1988514099847697e-05, 'epoch': 0.45}
 45%|████▌     | 4711/10395 [13:29:55<17:11:06, 10.88s/it] 45%|████▌     | 4712/10395 [13:30:03<15:38:36,  9.91s/it]                                                          {'loss': 0.9343, 'learning_rate': 1.1985460493556525e-05, 'epoch': 0.45}
 45%|████▌     | 4712/10395 [13:30:03<15:38:36,  9.91s/it] 45%|████▌     | 4713/10395 [13:30:11<14:45:51,  9.35s/it]                                                          {'loss': 0.9167, 'learning_rate': 1.1982406694521091e-05, 'epoch': 0.45}
 45%|████▌     | 4713/10395 [13:30:11<14:45:51,  9.35s/it] 45%|████▌     | 4714/10395 [13:30:19<14:16:05,  9.04s/it]                                                          {'loss': 0.937, 'learning_rate': 1.1979352703037854e-05, 'epoch': 0.45}
 45%|████▌     | 4714/10395 [13:30:19<14:16:05,  9.04s/it] 45%|████▌     | 4715/10395 [13:30:28<14:13:14,  9.01s/it]                                                          {'loss': 0.8649, 'learning_rate': 1.1976298519403284e-05, 'epoch': 0.45}
 45%|████▌     | 4715/10395 [13:30:28<14:13:14,  9.01s/it] 45%|████▌     | 4716/10395 [13:30:36<13:35:51,  8.62s/it]                                                          {'loss': 0.8827, 'learning_rate': 1.1973244143913879e-05, 'epoch': 0.45}
 45%|████▌     | 4716/10395 [13:30:36<13:35:51,  8.62s/it] 45%|████▌     | 4717/10395 [13:30:52<17:30:40, 11.10s/it]                                                          {'loss': 0.3536, 'learning_rate': 1.1970189576866148e-05, 'epoch': 0.45}
 45%|████▌     | 4717/10395 [13:30:52<17:30:40, 11.10s/it] 45%|████▌     | 4718/10395 [13:31:00<15:52:09, 10.06s/it]                                                          {'loss': 0.8798, 'learning_rate': 1.1967134818556625e-05, 'epoch': 0.45}
 45%|████▌     | 4718/10395 [13:31:00<15:52:09, 10.06s/it] 45%|████▌     | 4719/10395 [13:31:08<14:40:48,  9.31s/it]                                                          {'loss': 0.9552, 'learning_rate': 1.1964079869281855e-05, 'epoch': 0.45}
 45%|████▌     | 4719/10395 [13:31:08<14:40:48,  9.31s/it] 45%|████▌     | 4720/10395 [13:31:15<13:40:50,  8.68s/it]                                                          {'loss': 0.8872, 'learning_rate': 1.196102472933841e-05, 'epoch': 0.45}
 45%|████▌     | 4720/10395 [13:31:15<13:40:50,  8.68s/it] 45%|████▌     | 4721/10395 [13:31:22<13:03:06,  8.28s/it]                                                          {'loss': 0.9106, 'learning_rate': 1.1957969399022874e-05, 'epoch': 0.45}
 45%|████▌     | 4721/10395 [13:31:22<13:03:06,  8.28s/it] 45%|████▌     | 4722/10395 [13:31:30<12:41:08,  8.05s/it]                                                          {'loss': 0.8854, 'learning_rate': 1.1954913878631855e-05, 'epoch': 0.45}
 45%|████▌     | 4722/10395 [13:31:30<12:41:08,  8.05s/it] 45%|████▌     | 4723/10395 [13:31:38<12:40:40,  8.05s/it]                                                          {'loss': 0.8245, 'learning_rate': 1.1951858168461972e-05, 'epoch': 0.45}
 45%|████▌     | 4723/10395 [13:31:38<12:40:40,  8.05s/it] 45%|████▌     | 4724/10395 [13:31:45<12:09:43,  7.72s/it]                                                          {'loss': 0.9411, 'learning_rate': 1.1948802268809869e-05, 'epoch': 0.45}
 45%|████▌     | 4724/10395 [13:31:45<12:09:43,  7.72s/it] 45%|████▌     | 4725/10395 [13:32:02<16:53:01, 10.72s/it]                                                          {'loss': 0.3837, 'learning_rate': 1.1945746179972208e-05, 'epoch': 0.45}
 45%|████▌     | 4725/10395 [13:32:02<16:53:01, 10.72s/it] 45%|████▌     | 4726/10395 [13:32:10<15:27:46,  9.82s/it]                                                          {'loss': 0.9571, 'learning_rate': 1.1942689902245665e-05, 'epoch': 0.45}
 45%|████▌     | 4726/10395 [13:32:10<15:27:46,  9.82s/it] 45%|████▌     | 4727/10395 [13:32:18<14:35:21,  9.27s/it]                                                          {'loss': 0.9264, 'learning_rate': 1.193963343592694e-05, 'epoch': 0.45}
 45%|████▌     | 4727/10395 [13:32:18<14:35:21,  9.27s/it] 45%|████▌     | 4728/10395 [13:32:26<13:55:41,  8.85s/it]                                                          {'loss': 0.9162, 'learning_rate': 1.1936576781312743e-05, 'epoch': 0.45}
 45%|████▌     | 4728/10395 [13:32:26<13:55:41,  8.85s/it] 45%|████▌     | 4729/10395 [13:32:34<13:22:56,  8.50s/it]                                                          {'loss': 0.9497, 'learning_rate': 1.1933519938699814e-05, 'epoch': 0.45}
 45%|████▌     | 4729/10395 [13:32:34<13:22:56,  8.50s/it] 46%|████▌     | 4730/10395 [13:32:41<12:42:51,  8.08s/it]                                                          {'loss': 0.9746, 'learning_rate': 1.1930462908384899e-05, 'epoch': 0.46}
 46%|████▌     | 4730/10395 [13:32:41<12:42:51,  8.08s/it] 46%|████▌     | 4731/10395 [13:32:49<12:35:37,  8.00s/it]                                                          {'loss': 0.9675, 'learning_rate': 1.1927405690664769e-05, 'epoch': 0.46}
 46%|████▌     | 4731/10395 [13:32:49<12:35:37,  8.00s/it] 46%|████▌     | 4732/10395 [13:32:56<12:28:10,  7.93s/it]                                                          {'loss': 0.928, 'learning_rate': 1.1924348285836216e-05, 'epoch': 0.46}
 46%|████▌     | 4732/10395 [13:32:56<12:28:10,  7.93s/it] 46%|████▌     | 4733/10395 [13:33:04<12:22:21,  7.87s/it]                                                          {'loss': 0.8925, 'learning_rate': 1.1921290694196042e-05, 'epoch': 0.46}
 46%|████▌     | 4733/10395 [13:33:04<12:22:21,  7.87s/it] 46%|████▌     | 4734/10395 [13:33:12<12:12:45,  7.77s/it]                                                          {'loss': 0.93, 'learning_rate': 1.1918232916041075e-05, 'epoch': 0.46}
 46%|████▌     | 4734/10395 [13:33:12<12:12:45,  7.77s/it] 46%|████▌     | 4735/10395 [13:33:19<11:58:26,  7.62s/it]                                                          {'loss': 0.9041, 'learning_rate': 1.1915174951668153e-05, 'epoch': 0.46}
 46%|████▌     | 4735/10395 [13:33:19<11:58:26,  7.62s/it] 46%|████▌     | 4736/10395 [13:33:27<12:13:32,  7.78s/it]                                                          {'loss': 0.9234, 'learning_rate': 1.191211680137414e-05, 'epoch': 0.46}
 46%|████▌     | 4736/10395 [13:33:27<12:13:32,  7.78s/it] 46%|████▌     | 4737/10395 [13:33:35<12:23:15,  7.88s/it]                                                          {'loss': 0.869, 'learning_rate': 1.1909058465455917e-05, 'epoch': 0.46}
 46%|████▌     | 4737/10395 [13:33:35<12:23:15,  7.88s/it] 46%|████▌     | 4738/10395 [13:33:43<12:22:04,  7.87s/it]                                                          {'loss': 0.9705, 'learning_rate': 1.1905999944210376e-05, 'epoch': 0.46}
 46%|████▌     | 4738/10395 [13:33:43<12:22:04,  7.87s/it] 46%|████▌     | 4739/10395 [13:33:50<12:09:23,  7.74s/it]                                                          {'loss': 0.9594, 'learning_rate': 1.1902941237934433e-05, 'epoch': 0.46}
 46%|████▌     | 4739/10395 [13:33:50<12:09:23,  7.74s/it] 46%|████▌     | 4740/10395 [13:33:58<12:04:01,  7.68s/it]                                                          {'loss': 0.8372, 'learning_rate': 1.1899882346925022e-05, 'epoch': 0.46}
 46%|████▌     | 4740/10395 [13:33:58<12:04:01,  7.68s/it] 46%|████▌     | 4741/10395 [13:34:06<11:59:11,  7.63s/it]                                                          {'loss': 0.8424, 'learning_rate': 1.1896823271479092e-05, 'epoch': 0.46}
 46%|████▌     | 4741/10395 [13:34:06<11:59:11,  7.63s/it] 46%|████▌     | 4742/10395 [13:34:14<12:14:48,  7.80s/it]                                                          {'loss': 0.9504, 'learning_rate': 1.1893764011893616e-05, 'epoch': 0.46}
 46%|████▌     | 4742/10395 [13:34:14<12:14:48,  7.80s/it] 46%|████▌     | 4743/10395 [13:34:22<12:40:15,  8.07s/it]                                                          {'loss': 0.8116, 'learning_rate': 1.1890704568465572e-05, 'epoch': 0.46}
 46%|████▌     | 4743/10395 [13:34:22<12:40:15,  8.07s/it] 46%|████▌     | 4744/10395 [13:34:32<13:16:55,  8.46s/it]                                                          {'loss': 0.9098, 'learning_rate': 1.188764494149197e-05, 'epoch': 0.46}
 46%|████▌     | 4744/10395 [13:34:32<13:16:55,  8.46s/it] 46%|████▌     | 4745/10395 [13:34:39<12:41:54,  8.09s/it]                                                          {'loss': 0.8142, 'learning_rate': 1.1884585131269831e-05, 'epoch': 0.46}
 46%|████▌     | 4745/10395 [13:34:39<12:41:54,  8.09s/it] 46%|████▌     | 4746/10395 [13:34:48<13:12:37,  8.42s/it]                                                          {'loss': 0.8972, 'learning_rate': 1.1881525138096198e-05, 'epoch': 0.46}
 46%|████▌     | 4746/10395 [13:34:48<13:12:37,  8.42s/it] 46%|████▌     | 4747/10395 [13:34:55<12:39:03,  8.06s/it]                                                          {'loss': 0.9567, 'learning_rate': 1.1878464962268122e-05, 'epoch': 0.46}
 46%|████▌     | 4747/10395 [13:34:55<12:39:03,  8.06s/it] 46%|████▌     | 4748/10395 [13:35:05<13:14:10,  8.44s/it]                                                          {'loss': 0.8331, 'learning_rate': 1.187540460408268e-05, 'epoch': 0.46}
 46%|████▌     | 4748/10395 [13:35:05<13:14:10,  8.44s/it] 46%|████▌     | 4749/10395 [13:35:12<12:50:24,  8.19s/it]                                                          {'loss': 0.9341, 'learning_rate': 1.1872344063836972e-05, 'epoch': 0.46}
 46%|████▌     | 4749/10395 [13:35:12<12:50:24,  8.19s/it] 46%|████▌     | 4750/10395 [13:35:20<12:30:33,  7.98s/it]                                                          {'loss': 0.9099, 'learning_rate': 1.1869283341828101e-05, 'epoch': 0.46}
 46%|████▌     | 4750/10395 [13:35:20<12:30:33,  7.98s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 46%|████▌     | 4751/10395 [13:37:02<56:36:48, 36.11s/it]                                                          {'loss': 0.9868, 'learning_rate': 1.1866222438353196e-05, 'epoch': 0.46}
 46%|████▌     | 4751/10395 [13:37:02<56:36:48, 36.11s/it] 46%|████▌     | 4752/10395 [13:37:19<47:49:48, 30.51s/it]                                                          {'loss': 0.3884, 'learning_rate': 1.1863161353709407e-05, 'epoch': 0.46}
 46%|████▌     | 4752/10395 [13:37:19<47:49:48, 30.51s/it] 46%|████▌     | 4753/10395 [13:37:28<37:31:24, 23.94s/it]                                                          {'loss': 0.9152, 'learning_rate': 1.1860100088193897e-05, 'epoch': 0.46}
 46%|████▌     | 4753/10395 [13:37:28<37:31:24, 23.94s/it] 46%|████▌     | 4754/10395 [13:37:36<29:59:47, 19.14s/it]                                                          {'loss': 0.8986, 'learning_rate': 1.1857038642103845e-05, 'epoch': 0.46}
 46%|████▌     | 4754/10395 [13:37:36<29:59:47, 19.14s/it] 46%|████▌     | 4755/10395 [13:37:44<24:58:01, 15.94s/it]                                                          {'loss': 0.8986, 'learning_rate': 1.1853977015736445e-05, 'epoch': 0.46}
 46%|████▌     | 4755/10395 [13:37:44<24:58:01, 15.94s/it] 46%|████▌     | 4756/10395 [13:37:52<21:24:11, 13.66s/it]                                                          {'loss': 0.9276, 'learning_rate': 1.1850915209388923e-05, 'epoch': 0.46}
 46%|████▌     | 4756/10395 [13:37:52<21:24:11, 13.66s/it] 46%|████▌     | 4757/10395 [13:38:01<19:10:18, 12.24s/it]                                                          {'loss': 0.8866, 'learning_rate': 1.1847853223358507e-05, 'epoch': 0.46}
 46%|████▌     | 4757/10395 [13:38:01<19:10:18, 12.24s/it] 46%|████▌     | 4758/10395 [13:38:09<17:03:15, 10.89s/it]                                                          {'loss': 0.955, 'learning_rate': 1.1844791057942448e-05, 'epoch': 0.46}
 46%|████▌     | 4758/10395 [13:38:09<17:03:15, 10.89s/it] 46%|████▌     | 4759/10395 [13:38:17<15:42:31, 10.03s/it]                                                          {'loss': 0.9004, 'learning_rate': 1.1841728713438015e-05, 'epoch': 0.46}
 46%|████▌     | 4759/10395 [13:38:17<15:42:31, 10.03s/it] 46%|████▌     | 4760/10395 [13:38:35<19:31:09, 12.47s/it]                                                          {'loss': 0.4552, 'learning_rate': 1.1838666190142496e-05, 'epoch': 0.46}
 46%|████▌     | 4760/10395 [13:38:35<19:31:09, 12.47s/it] 46%|████▌     | 4761/10395 [13:38:43<17:03:52, 10.90s/it]                                                          {'loss': 0.9376, 'learning_rate': 1.1835603488353194e-05, 'epoch': 0.46}
 46%|████▌     | 4761/10395 [13:38:43<17:03:52, 10.90s/it] 46%|████▌     | 4762/10395 [13:38:51<15:46:23, 10.08s/it]                                                          {'loss': 0.8675, 'learning_rate': 1.1832540608367421e-05, 'epoch': 0.46}
 46%|████▌     | 4762/10395 [13:38:51<15:46:23, 10.08s/it] 46%|████▌     | 4763/10395 [13:38:59<14:47:37,  9.46s/it]                                                          {'loss': 0.9376, 'learning_rate': 1.182947755048253e-05, 'epoch': 0.46}
 46%|████▌     | 4763/10395 [13:38:59<14:47:37,  9.46s/it] 46%|████▌     | 4764/10395 [13:39:06<13:53:28,  8.88s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.1826414314995867e-05, 'epoch': 0.46}
 46%|████▌     | 4764/10395 [13:39:06<13:53:28,  8.88s/it] 46%|████▌     | 4765/10395 [13:39:14<13:28:42,  8.62s/it]                                                          {'loss': 0.9083, 'learning_rate': 1.1823350902204802e-05, 'epoch': 0.46}
 46%|████▌     | 4765/10395 [13:39:14<13:28:42,  8.62s/it] 46%|████▌     | 4766/10395 [13:39:22<13:09:32,  8.42s/it]                                                          {'loss': 0.8822, 'learning_rate': 1.1820287312406726e-05, 'epoch': 0.46}
 46%|████▌     | 4766/10395 [13:39:22<13:09:32,  8.42s/it] 46%|████▌     | 4767/10395 [13:39:30<12:44:18,  8.15s/it]                                                          {'loss': 0.9107, 'learning_rate': 1.1817223545899052e-05, 'epoch': 0.46}
 46%|████▌     | 4767/10395 [13:39:30<12:44:18,  8.15s/it] 46%|████▌     | 4768/10395 [13:39:37<12:32:13,  8.02s/it]                                                          {'loss': 0.9624, 'learning_rate': 1.18141596029792e-05, 'epoch': 0.46}
 46%|████▌     | 4768/10395 [13:39:37<12:32:13,  8.02s/it] 46%|████▌     | 4769/10395 [13:39:45<12:19:43,  7.89s/it]                                                          {'loss': 0.8978, 'learning_rate': 1.181109548394461e-05, 'epoch': 0.46}
 46%|████▌     | 4769/10395 [13:39:45<12:19:43,  7.89s/it] 46%|████▌     | 4770/10395 [13:39:53<12:11:09,  7.80s/it]                                                          {'loss': 0.9144, 'learning_rate': 1.1808031189092737e-05, 'epoch': 0.46}
 46%|████▌     | 4770/10395 [13:39:53<12:11:09,  7.80s/it] 46%|████▌     | 4771/10395 [13:40:00<12:05:40,  7.74s/it]                                                          {'loss': 0.9052, 'learning_rate': 1.1804966718721062e-05, 'epoch': 0.46}
 46%|████▌     | 4771/10395 [13:40:00<12:05:40,  7.74s/it] 46%|████▌     | 4772/10395 [13:40:08<12:00:10,  7.68s/it]                                                          {'loss': 0.9156, 'learning_rate': 1.1801902073127078e-05, 'epoch': 0.46}
 46%|████▌     | 4772/10395 [13:40:08<12:00:10,  7.68s/it] 46%|████▌     | 4773/10395 [13:40:15<11:59:15,  7.68s/it]                                                          {'loss': 0.953, 'learning_rate': 1.179883725260829e-05, 'epoch': 0.46}
 46%|████▌     | 4773/10395 [13:40:15<11:59:15,  7.68s/it] 46%|████▌     | 4774/10395 [13:40:23<12:01:44,  7.70s/it]                                                          {'loss': 0.9794, 'learning_rate': 1.1795772257462224e-05, 'epoch': 0.46}
 46%|████▌     | 4774/10395 [13:40:23<12:01:44,  7.70s/it] 46%|████▌     | 4775/10395 [13:40:33<13:09:06,  8.42s/it]                                                          {'loss': 0.8504, 'learning_rate': 1.1792707087986426e-05, 'epoch': 0.46}
 46%|████▌     | 4775/10395 [13:40:33<13:09:06,  8.42s/it] 46%|████▌     | 4776/10395 [13:40:42<13:11:02,  8.45s/it]                                                          {'loss': 0.9902, 'learning_rate': 1.1789641744478455e-05, 'epoch': 0.46}
 46%|████▌     | 4776/10395 [13:40:42<13:11:02,  8.45s/it] 46%|████▌     | 4777/10395 [13:40:50<12:51:00,  8.23s/it]                                                          {'loss': 0.8998, 'learning_rate': 1.1786576227235888e-05, 'epoch': 0.46}
 46%|████▌     | 4777/10395 [13:40:50<12:51:00,  8.23s/it] 46%|████▌     | 4778/10395 [13:40:57<12:32:12,  8.04s/it]                                                          {'loss': 0.9551, 'learning_rate': 1.1783510536556314e-05, 'epoch': 0.46}
 46%|████▌     | 4778/10395 [13:40:57<12:32:12,  8.04s/it] 46%|████▌     | 4779/10395 [13:41:05<12:30:23,  8.02s/it]                                                          {'loss': 0.9099, 'learning_rate': 1.1780444672737357e-05, 'epoch': 0.46}
 46%|████▌     | 4779/10395 [13:41:05<12:30:23,  8.02s/it] 46%|████▌     | 4780/10395 [13:41:12<12:12:42,  7.83s/it]                                                          {'loss': 0.9341, 'learning_rate': 1.1777378636076634e-05, 'epoch': 0.46}
 46%|████▌     | 4780/10395 [13:41:12<12:12:42,  7.83s/it] 46%|████▌     | 4781/10395 [13:41:20<12:11:16,  7.82s/it]                                                          {'loss': 0.9159, 'learning_rate': 1.1774312426871788e-05, 'epoch': 0.46}
 46%|████▌     | 4781/10395 [13:41:20<12:11:16,  7.82s/it] 46%|████▌     | 4782/10395 [13:41:28<12:08:23,  7.79s/it]                                                          {'loss': 0.948, 'learning_rate': 1.177124604542048e-05, 'epoch': 0.46}
 46%|████▌     | 4782/10395 [13:41:28<12:08:23,  7.79s/it] 46%|████▌     | 4783/10395 [13:41:35<12:00:55,  7.71s/it]                                                          {'loss': 1.0304, 'learning_rate': 1.17681794920204e-05, 'epoch': 0.46}
 46%|████▌     | 4783/10395 [13:41:35<12:00:55,  7.71s/it] 46%|████▌     | 4784/10395 [13:41:43<12:02:25,  7.73s/it]                                                          {'loss': 0.9193, 'learning_rate': 1.176511276696923e-05, 'epoch': 0.46}
 46%|████▌     | 4784/10395 [13:41:43<12:02:25,  7.73s/it] 46%|████▌     | 4785/10395 [13:41:51<11:55:16,  7.65s/it]                                                          {'loss': 0.8781, 'learning_rate': 1.1762045870564683e-05, 'epoch': 0.46}
 46%|████▌     | 4785/10395 [13:41:51<11:55:16,  7.65s/it] 46%|████▌     | 4786/10395 [13:41:58<11:50:22,  7.60s/it]                                                          {'loss': 0.9702, 'learning_rate': 1.1758978803104489e-05, 'epoch': 0.46}
 46%|████▌     | 4786/10395 [13:41:58<11:50:22,  7.60s/it] 46%|████▌     | 4787/10395 [13:42:06<11:56:47,  7.67s/it]                                                          {'loss': 0.8694, 'learning_rate': 1.1755911564886392e-05, 'epoch': 0.46}
 46%|████▌     | 4787/10395 [13:42:06<11:56:47,  7.67s/it] 46%|████▌     | 4788/10395 [13:42:14<11:54:02,  7.64s/it]                                                          {'loss': 0.9526, 'learning_rate': 1.1752844156208152e-05, 'epoch': 0.46}
 46%|████▌     | 4788/10395 [13:42:14<11:54:02,  7.64s/it] 46%|████▌     | 4789/10395 [13:42:21<11:46:57,  7.57s/it]                                                          {'loss': 0.9054, 'learning_rate': 1.1749776577367547e-05, 'epoch': 0.46}
 46%|████▌     | 4789/10395 [13:42:21<11:46:57,  7.57s/it] 46%|████▌     | 4790/10395 [13:42:38<16:20:35, 10.50s/it]                                                          {'loss': 0.3658, 'learning_rate': 1.1746708828662372e-05, 'epoch': 0.46}
 46%|████▌     | 4790/10395 [13:42:38<16:20:35, 10.50s/it] 46%|████▌     | 4791/10395 [13:42:46<14:58:17,  9.62s/it]                                                          {'loss': 0.8885, 'learning_rate': 1.1743640910390437e-05, 'epoch': 0.46}
 46%|████▌     | 4791/10395 [13:42:46<14:58:17,  9.62s/it] 46%|████▌     | 4792/10395 [13:42:53<13:56:09,  8.95s/it]                                                          {'loss': 1.0232, 'learning_rate': 1.1740572822849568e-05, 'epoch': 0.46}
 46%|████▌     | 4792/10395 [13:42:53<13:56:09,  8.95s/it] 46%|████▌     | 4793/10395 [13:43:01<13:33:56,  8.72s/it]                                                          {'loss': 0.9845, 'learning_rate': 1.1737504566337608e-05, 'epoch': 0.46}
 46%|████▌     | 4793/10395 [13:43:01<13:33:56,  8.72s/it] 46%|████▌     | 4794/10395 [13:43:10<13:21:35,  8.59s/it]                                                          {'loss': 0.9267, 'learning_rate': 1.1734436141152419e-05, 'epoch': 0.46}
 46%|████▌     | 4794/10395 [13:43:10<13:21:35,  8.59s/it] 46%|████▌     | 4795/10395 [13:43:17<12:52:23,  8.28s/it]                                                          {'loss': 0.8484, 'learning_rate': 1.1731367547591876e-05, 'epoch': 0.46}
 46%|████▌     | 4795/10395 [13:43:17<12:52:23,  8.28s/it] 46%|████▌     | 4796/10395 [13:43:25<12:25:31,  7.99s/it]                                                          {'loss': 0.9192, 'learning_rate': 1.1728298785953871e-05, 'epoch': 0.46}
 46%|████▌     | 4796/10395 [13:43:25<12:25:31,  7.99s/it] 46%|████▌     | 4797/10395 [13:43:33<12:44:12,  8.19s/it]                                                          {'loss': 0.8868, 'learning_rate': 1.1725229856536313e-05, 'epoch': 0.46}
 46%|████▌     | 4797/10395 [13:43:33<12:44:12,  8.19s/it] 46%|████▌     | 4798/10395 [13:43:41<12:30:03,  8.04s/it]                                                          {'loss': 0.8731, 'learning_rate': 1.1722160759637126e-05, 'epoch': 0.46}
 46%|████▌     | 4798/10395 [13:43:41<12:30:03,  8.04s/it] 46%|████▌     | 4799/10395 [13:43:49<12:18:54,  7.92s/it]                                                          {'loss': 0.8829, 'learning_rate': 1.1719091495554255e-05, 'epoch': 0.46}
 46%|████▌     | 4799/10395 [13:43:49<12:18:54,  7.92s/it] 46%|████▌     | 4800/10395 [13:43:57<12:22:20,  7.96s/it]                                                          {'loss': 0.8193, 'learning_rate': 1.1716022064585655e-05, 'epoch': 0.46}
 46%|████▌     | 4800/10395 [13:43:57<12:22:20,  7.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 46%|████▌     | 4801/10395 [13:45:38<55:41:46, 35.84s/it]                                                          {'loss': 0.9454, 'learning_rate': 1.1712952467029301e-05, 'epoch': 0.46}
 46%|████▌     | 4801/10395 [13:45:38<55:41:46, 35.84s/it] 46%|████▌     | 4802/10395 [13:45:45<42:18:17, 27.23s/it]                                                          {'loss': 0.9439, 'learning_rate': 1.170988270318318e-05, 'epoch': 0.46}
 46%|████▌     | 4802/10395 [13:45:45<42:18:17, 27.23s/it] 46%|████▌     | 4803/10395 [13:45:52<32:58:01, 21.22s/it]                                                          {'loss': 0.8326, 'learning_rate': 1.1706812773345301e-05, 'epoch': 0.46}
 46%|████▌     | 4803/10395 [13:45:52<32:58:01, 21.22s/it] 46%|████▌     | 4804/10395 [13:45:59<26:33:23, 17.10s/it]                                                          {'loss': 0.878, 'learning_rate': 1.1703742677813685e-05, 'epoch': 0.46}
 46%|████▌     | 4804/10395 [13:45:59<26:33:23, 17.10s/it] 46%|████▌     | 4805/10395 [13:46:09<22:56:19, 14.77s/it]                                                          {'loss': 0.8287, 'learning_rate': 1.1700672416886372e-05, 'epoch': 0.46}
 46%|████▌     | 4805/10395 [13:46:09<22:56:19, 14.77s/it] 46%|████▌     | 4806/10395 [13:46:17<19:53:01, 12.81s/it]                                                          {'loss': 0.916, 'learning_rate': 1.1697601990861416e-05, 'epoch': 0.46}
 46%|████▌     | 4806/10395 [13:46:17<19:53:01, 12.81s/it] 46%|████▌     | 4807/10395 [13:46:25<17:29:21, 11.27s/it]                                                          {'loss': 0.9817, 'learning_rate': 1.1694531400036884e-05, 'epoch': 0.46}
 46%|████▌     | 4807/10395 [13:46:25<17:29:21, 11.27s/it] 46%|████▋     | 4808/10395 [13:46:32<15:45:47, 10.16s/it]                                                          {'loss': 0.9041, 'learning_rate': 1.1691460644710866e-05, 'epoch': 0.46}
 46%|████▋     | 4808/10395 [13:46:32<15:45:47, 10.16s/it] 46%|████▋     | 4809/10395 [13:46:41<15:02:27,  9.69s/it]                                                          {'loss': 0.8357, 'learning_rate': 1.1688389725181464e-05, 'epoch': 0.46}
 46%|████▋     | 4809/10395 [13:46:41<15:02:27,  9.69s/it] 46%|████▋     | 4810/10395 [13:46:50<14:54:03,  9.60s/it]                                                          {'loss': 0.9238, 'learning_rate': 1.1685318641746795e-05, 'epoch': 0.46}
 46%|████▋     | 4810/10395 [13:46:50<14:54:03,  9.60s/it] 46%|████▋     | 4811/10395 [13:46:58<14:12:20,  9.16s/it]                                                          {'loss': 0.8949, 'learning_rate': 1.1682247394704993e-05, 'epoch': 0.46}
 46%|████▋     | 4811/10395 [13:46:58<14:12:20,  9.16s/it] 46%|████▋     | 4812/10395 [13:47:06<13:23:52,  8.64s/it]                                                          {'loss': 1.0375, 'learning_rate': 1.167917598435421e-05, 'epoch': 0.46}
 46%|████▋     | 4812/10395 [13:47:06<13:23:52,  8.64s/it] 46%|████▋     | 4813/10395 [13:47:13<12:41:25,  8.18s/it]                                                          {'loss': 1.0094, 'learning_rate': 1.167610441099261e-05, 'epoch': 0.46}
 46%|████▋     | 4813/10395 [13:47:13<12:41:25,  8.18s/it] 46%|████▋     | 4814/10395 [13:47:22<12:59:51,  8.38s/it]                                                          {'loss': 0.9225, 'learning_rate': 1.1673032674918376e-05, 'epoch': 0.46}
 46%|████▋     | 4814/10395 [13:47:22<12:59:51,  8.38s/it] 46%|████▋     | 4815/10395 [13:47:29<12:35:52,  8.13s/it]                                                          {'loss': 0.9152, 'learning_rate': 1.1669960776429706e-05, 'epoch': 0.46}
 46%|████▋     | 4815/10395 [13:47:29<12:35:52,  8.13s/it] 46%|████▋     | 4816/10395 [13:47:38<12:41:52,  8.19s/it]                                                          {'loss': 0.8704, 'learning_rate': 1.1666888715824812e-05, 'epoch': 0.46}
 46%|████▋     | 4816/10395 [13:47:38<12:41:52,  8.19s/it] 46%|████▋     | 4817/10395 [13:47:45<12:28:32,  8.05s/it]                                                          {'loss': 0.9032, 'learning_rate': 1.1663816493401924e-05, 'epoch': 0.46}
 46%|████▋     | 4817/10395 [13:47:45<12:28:32,  8.05s/it] 46%|████▋     | 4818/10395 [13:47:54<12:33:20,  8.10s/it]                                                          {'loss': 0.9191, 'learning_rate': 1.1660744109459283e-05, 'epoch': 0.46}
 46%|████▋     | 4818/10395 [13:47:54<12:33:20,  8.10s/it] 46%|████▋     | 4819/10395 [13:48:01<12:10:12,  7.86s/it]                                                          {'loss': 0.9122, 'learning_rate': 1.165767156429516e-05, 'epoch': 0.46}
 46%|████▋     | 4819/10395 [13:48:01<12:10:12,  7.86s/it] 46%|████▋     | 4820/10395 [13:48:09<12:23:06,  8.00s/it]                                                          {'loss': 0.9109, 'learning_rate': 1.1654598858207815e-05, 'epoch': 0.46}
 46%|████▋     | 4820/10395 [13:48:09<12:23:06,  8.00s/it] 46%|████▋     | 4821/10395 [13:48:17<12:25:48,  8.03s/it]                                                          {'loss': 0.8739, 'learning_rate': 1.1651525991495553e-05, 'epoch': 0.46}
 46%|████▋     | 4821/10395 [13:48:17<12:25:48,  8.03s/it] 46%|████▋     | 4822/10395 [13:48:25<12:25:26,  8.03s/it]                                                          {'loss': 0.9664, 'learning_rate': 1.1648452964456678e-05, 'epoch': 0.46}
 46%|████▋     | 4822/10395 [13:48:25<12:25:26,  8.03s/it] 46%|████▋     | 4823/10395 [13:48:34<12:53:11,  8.33s/it]                                                          {'loss': 0.8358, 'learning_rate': 1.1645379777389513e-05, 'epoch': 0.46}
 46%|████▋     | 4823/10395 [13:48:34<12:53:11,  8.33s/it] 46%|████▋     | 4824/10395 [13:48:43<13:07:46,  8.48s/it]                                                          {'loss': 0.9496, 'learning_rate': 1.1642306430592392e-05, 'epoch': 0.46}
 46%|████▋     | 4824/10395 [13:48:43<13:07:46,  8.48s/it] 46%|████▋     | 4825/10395 [13:48:51<12:38:26,  8.17s/it]                                                          {'loss': 0.8412, 'learning_rate': 1.1639232924363675e-05, 'epoch': 0.46}
 46%|████▋     | 4825/10395 [13:48:51<12:38:26,  8.17s/it] 46%|████▋     | 4826/10395 [13:48:59<12:49:04,  8.29s/it]                                                          {'loss': 0.9415, 'learning_rate': 1.1636159259001726e-05, 'epoch': 0.46}
 46%|████▋     | 4826/10395 [13:48:59<12:49:04,  8.29s/it] 46%|████▋     | 4827/10395 [13:49:07<12:33:48,  8.12s/it]                                                          {'loss': 0.9872, 'learning_rate': 1.1633085434804939e-05, 'epoch': 0.46}
 46%|████▋     | 4827/10395 [13:49:07<12:33:48,  8.12s/it] 46%|████▋     | 4828/10395 [13:49:15<12:34:43,  8.13s/it]                                                          {'loss': 0.9162, 'learning_rate': 1.1630011452071701e-05, 'epoch': 0.46}
 46%|████▋     | 4828/10395 [13:49:15<12:34:43,  8.13s/it] 46%|████▋     | 4829/10395 [13:49:22<12:13:26,  7.91s/it]                                                          {'loss': 0.8988, 'learning_rate': 1.1626937311100438e-05, 'epoch': 0.46}
 46%|████▋     | 4829/10395 [13:49:22<12:13:26,  7.91s/it] 46%|████▋     | 4830/10395 [13:49:30<11:59:24,  7.76s/it]                                                          {'loss': 0.8669, 'learning_rate': 1.1623863012189576e-05, 'epoch': 0.46}
 46%|████▋     | 4830/10395 [13:49:30<11:59:24,  7.76s/it] 46%|████▋     | 4831/10395 [13:49:37<11:49:54,  7.66s/it]                                                          {'loss': 0.9206, 'learning_rate': 1.1620788555637563e-05, 'epoch': 0.46}
 46%|████▋     | 4831/10395 [13:49:37<11:49:54,  7.66s/it] 46%|████▋     | 4832/10395 [13:49:45<11:55:00,  7.71s/it]                                                          {'loss': 0.8611, 'learning_rate': 1.161771394174286e-05, 'epoch': 0.46}
 46%|████▋     | 4832/10395 [13:49:45<11:55:00,  7.71s/it] 46%|████▋     | 4833/10395 [13:49:52<11:42:42,  7.58s/it]                                                          {'loss': 0.8929, 'learning_rate': 1.1614639170803947e-05, 'epoch': 0.46}
 46%|████▋     | 4833/10395 [13:49:52<11:42:42,  7.58s/it] 47%|████▋     | 4834/10395 [13:50:01<11:59:27,  7.76s/it]                                                          {'loss': 0.8739, 'learning_rate': 1.1611564243119314e-05, 'epoch': 0.47}
 47%|████▋     | 4834/10395 [13:50:01<11:59:27,  7.76s/it] 47%|████▋     | 4835/10395 [13:50:08<12:00:11,  7.77s/it]                                                          {'loss': 0.9012, 'learning_rate': 1.1608489158987463e-05, 'epoch': 0.47}
 47%|████▋     | 4835/10395 [13:50:08<12:00:11,  7.77s/it] 47%|████▋     | 4836/10395 [13:50:16<11:59:12,  7.76s/it]                                                          {'loss': 0.9185, 'learning_rate': 1.1605413918706927e-05, 'epoch': 0.47}
 47%|████▋     | 4836/10395 [13:50:16<11:59:12,  7.76s/it] 47%|████▋     | 4837/10395 [13:50:24<12:13:16,  7.92s/it]                                                          {'loss': 0.9139, 'learning_rate': 1.1602338522576238e-05, 'epoch': 0.47}
 47%|████▋     | 4837/10395 [13:50:24<12:13:16,  7.92s/it] 47%|████▋     | 4838/10395 [13:50:33<12:19:24,  7.98s/it]                                                          {'loss': 0.9034, 'learning_rate': 1.159926297089395e-05, 'epoch': 0.47}
 47%|████▋     | 4838/10395 [13:50:33<12:19:24,  7.98s/it] 47%|████▋     | 4839/10395 [13:50:41<12:45:27,  8.27s/it]                                                          {'loss': 0.8783, 'learning_rate': 1.1596187263958626e-05, 'epoch': 0.47}
 47%|████▋     | 4839/10395 [13:50:41<12:45:27,  8.27s/it] 47%|████▋     | 4840/10395 [13:50:49<12:31:54,  8.12s/it]                                                          {'loss': 0.8969, 'learning_rate': 1.1593111402068857e-05, 'epoch': 0.47}
 47%|████▋     | 4840/10395 [13:50:49<12:31:54,  8.12s/it] 47%|████▋     | 4841/10395 [13:51:06<16:42:51, 10.83s/it]                                                          {'loss': 0.3852, 'learning_rate': 1.159003538552324e-05, 'epoch': 0.47}
 47%|████▋     | 4841/10395 [13:51:06<16:42:51, 10.83s/it] 47%|████▋     | 4842/10395 [13:51:15<15:39:42, 10.15s/it]                                                          {'loss': 0.8223, 'learning_rate': 1.1586959214620384e-05, 'epoch': 0.47}
 47%|████▋     | 4842/10395 [13:51:15<15:39:42, 10.15s/it] 47%|████▋     | 4843/10395 [13:51:24<15:13:36,  9.87s/it]                                                          {'loss': 0.8548, 'learning_rate': 1.1583882889658913e-05, 'epoch': 0.47}
 47%|████▋     | 4843/10395 [13:51:24<15:13:36,  9.87s/it] 47%|████▋     | 4844/10395 [13:51:32<14:29:51,  9.40s/it]                                                          {'loss': 0.8865, 'learning_rate': 1.1580806410937481e-05, 'epoch': 0.47}
 47%|████▋     | 4844/10395 [13:51:32<14:29:51,  9.40s/it] 47%|████▋     | 4845/10395 [13:51:40<13:40:24,  8.87s/it]                                                          {'loss': 0.9143, 'learning_rate': 1.1577729778754743e-05, 'epoch': 0.47}
 47%|████▋     | 4845/10395 [13:51:40<13:40:24,  8.87s/it] 47%|████▋     | 4846/10395 [13:51:47<12:57:59,  8.41s/it]                                                          {'loss': 0.9456, 'learning_rate': 1.1574652993409368e-05, 'epoch': 0.47}
 47%|████▋     | 4846/10395 [13:51:47<12:57:59,  8.41s/it] 47%|████▋     | 4847/10395 [13:51:56<13:08:28,  8.53s/it]                                                          {'loss': 0.9305, 'learning_rate': 1.157157605520004e-05, 'epoch': 0.47}
 47%|████▋     | 4847/10395 [13:51:56<13:08:28,  8.53s/it] 47%|████▋     | 4848/10395 [13:52:05<13:15:16,  8.60s/it]                                                          {'loss': 0.8613, 'learning_rate': 1.1568498964425472e-05, 'epoch': 0.47}
 47%|████▋     | 4848/10395 [13:52:05<13:15:16,  8.60s/it] 47%|████▋     | 4849/10395 [13:52:13<12:57:29,  8.41s/it]                                                          {'loss': 0.9565, 'learning_rate': 1.1565421721384378e-05, 'epoch': 0.47}
 47%|████▋     | 4849/10395 [13:52:13<12:57:29,  8.41s/it] 47%|████▋     | 4850/10395 [13:52:21<12:47:39,  8.31s/it]                                                          {'loss': 0.9146, 'learning_rate': 1.1562344326375487e-05, 'epoch': 0.47}
 47%|████▋     | 4850/10395 [13:52:21<12:47:39,  8.31s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 47%|████▋     | 4851/10395 [13:54:03<56:00:43, 36.37s/it]                                                          {'loss': 0.93, 'learning_rate': 1.1559266779697545e-05, 'epoch': 0.47}
 47%|████▋     | 4851/10395 [13:54:03<56:00:43, 36.37s/it] 47%|████▋     | 4852/10395 [13:54:10<42:41:09, 27.72s/it]                                                          {'loss': 0.9694, 'learning_rate': 1.155618908164932e-05, 'epoch': 0.47}
 47%|████▋     | 4852/10395 [13:54:10<42:41:09, 27.72s/it] 47%|████▋     | 4853/10395 [13:54:18<33:09:13, 21.54s/it]                                                          {'loss': 1.0054, 'learning_rate': 1.1553111232529583e-05, 'epoch': 0.47}
 47%|████▋     | 4853/10395 [13:54:18<33:09:13, 21.54s/it] 47%|████▋     | 4854/10395 [13:54:25<26:39:16, 17.32s/it]                                                          {'loss': 0.903, 'learning_rate': 1.1550033232637126e-05, 'epoch': 0.47}
 47%|████▋     | 4854/10395 [13:54:25<26:39:16, 17.32s/it] 47%|████▋     | 4855/10395 [13:54:33<22:15:37, 14.47s/it]                                                          {'loss': 0.9004, 'learning_rate': 1.1546955082270752e-05, 'epoch': 0.47}
 47%|████▋     | 4855/10395 [13:54:33<22:15:37, 14.47s/it] 47%|████▋     | 4856/10395 [13:54:40<18:53:45, 12.28s/it]                                                          {'loss': 0.989, 'learning_rate': 1.1543876781729291e-05, 'epoch': 0.47}
 47%|████▋     | 4856/10395 [13:54:40<18:53:45, 12.28s/it] 47%|████▋     | 4857/10395 [13:54:49<17:16:46, 11.23s/it]                                                          {'loss': 0.944, 'learning_rate': 1.154079833131157e-05, 'epoch': 0.47}
 47%|████▋     | 4857/10395 [13:54:49<17:16:46, 11.23s/it] 47%|████▋     | 4858/10395 [13:54:56<15:36:47, 10.15s/it]                                                          {'loss': 0.9165, 'learning_rate': 1.1537719731316437e-05, 'epoch': 0.47}
 47%|████▋     | 4858/10395 [13:54:56<15:36:47, 10.15s/it] 47%|████▋     | 4859/10395 [13:55:04<14:18:39,  9.31s/it]                                                          {'loss': 0.876, 'learning_rate': 1.1534640982042758e-05, 'epoch': 0.47}
 47%|████▋     | 4859/10395 [13:55:04<14:18:39,  9.31s/it] 47%|████▋     | 4860/10395 [13:55:11<13:25:40,  8.73s/it]                                                          {'loss': 0.8635, 'learning_rate': 1.1531562083789413e-05, 'epoch': 0.47}
 47%|████▋     | 4860/10395 [13:55:11<13:25:40,  8.73s/it] 47%|████▋     | 4861/10395 [13:55:19<12:59:15,  8.45s/it]                                                          {'loss': 0.838, 'learning_rate': 1.1528483036855296e-05, 'epoch': 0.47}
 47%|████▋     | 4861/10395 [13:55:19<12:59:15,  8.45s/it] 47%|████▋     | 4862/10395 [13:55:27<12:34:15,  8.18s/it]                                                          {'loss': 0.9523, 'learning_rate': 1.1525403841539311e-05, 'epoch': 0.47}
 47%|████▋     | 4862/10395 [13:55:27<12:34:15,  8.18s/it] 47%|████▋     | 4863/10395 [13:55:33<12:00:48,  7.82s/it]                                                          {'loss': 0.9528, 'learning_rate': 1.152232449814038e-05, 'epoch': 0.47}
 47%|████▋     | 4863/10395 [13:55:33<12:00:48,  7.82s/it] 47%|████▋     | 4864/10395 [13:55:42<12:30:25,  8.14s/it]                                                          {'loss': 0.9156, 'learning_rate': 1.151924500695744e-05, 'epoch': 0.47}
 47%|████▋     | 4864/10395 [13:55:42<12:30:25,  8.14s/it] 47%|████▋     | 4865/10395 [13:55:50<12:18:02,  8.01s/it]                                                          {'loss': 0.8865, 'learning_rate': 1.1516165368289442e-05, 'epoch': 0.47}
 47%|████▋     | 4865/10395 [13:55:50<12:18:02,  8.01s/it] 47%|████▋     | 4866/10395 [13:55:59<12:35:52,  8.20s/it]                                                          {'loss': 0.8787, 'learning_rate': 1.1513085582435349e-05, 'epoch': 0.47}
 47%|████▋     | 4866/10395 [13:55:59<12:35:52,  8.20s/it] 47%|████▋     | 4867/10395 [13:56:07<12:24:40,  8.08s/it]                                                          {'loss': 0.9092, 'learning_rate': 1.1510005649694142e-05, 'epoch': 0.47}
 47%|████▋     | 4867/10395 [13:56:07<12:24:40,  8.08s/it] 47%|████▋     | 4868/10395 [13:56:14<11:57:20,  7.79s/it]                                                          {'loss': 0.8589, 'learning_rate': 1.1506925570364814e-05, 'epoch': 0.47}
 47%|████▋     | 4868/10395 [13:56:14<11:57:20,  7.79s/it] 47%|████▋     | 4869/10395 [13:56:22<12:00:05,  7.82s/it]                                                          {'loss': 0.954, 'learning_rate': 1.1503845344746372e-05, 'epoch': 0.47}
 47%|████▋     | 4869/10395 [13:56:22<12:00:05,  7.82s/it] 47%|████▋     | 4870/10395 [13:56:29<12:00:06,  7.82s/it]                                                          {'loss': 1.0243, 'learning_rate': 1.1500764973137835e-05, 'epoch': 0.47}
 47%|████▋     | 4870/10395 [13:56:29<12:00:06,  7.82s/it] 47%|████▋     | 4871/10395 [13:56:37<12:00:33,  7.83s/it]                                                          {'loss': 0.9849, 'learning_rate': 1.1497684455838244e-05, 'epoch': 0.47}
 47%|████▋     | 4871/10395 [13:56:37<12:00:33,  7.83s/it] 47%|████▋     | 4872/10395 [13:56:45<11:48:13,  7.69s/it]                                                          {'loss': 0.8873, 'learning_rate': 1.1494603793146646e-05, 'epoch': 0.47}
 47%|████▋     | 4872/10395 [13:56:45<11:48:13,  7.69s/it] 47%|████▋     | 4873/10395 [13:56:52<11:34:45,  7.55s/it]                                                          {'loss': 0.9455, 'learning_rate': 1.1491522985362106e-05, 'epoch': 0.47}
 47%|████▋     | 4873/10395 [13:56:52<11:34:45,  7.55s/it] 47%|████▋     | 4874/10395 [13:56:59<11:27:42,  7.47s/it]                                                          {'loss': 0.8968, 'learning_rate': 1.1488442032783702e-05, 'epoch': 0.47}
 47%|████▋     | 4874/10395 [13:56:59<11:27:42,  7.47s/it] 47%|████▋     | 4875/10395 [13:57:07<11:41:05,  7.62s/it]                                                          {'loss': 0.8308, 'learning_rate': 1.1485360935710528e-05, 'epoch': 0.47}
 47%|████▋     | 4875/10395 [13:57:07<11:41:05,  7.62s/it] 47%|████▋     | 4876/10395 [13:57:14<11:34:19,  7.55s/it]                                                          {'loss': 0.8713, 'learning_rate': 1.1482279694441684e-05, 'epoch': 0.47}
 47%|████▋     | 4876/10395 [13:57:14<11:34:19,  7.55s/it] 47%|████▋     | 4877/10395 [13:57:22<11:27:32,  7.48s/it]                                                          {'loss': 0.9555, 'learning_rate': 1.1479198309276298e-05, 'epoch': 0.47}
 47%|████▋     | 4877/10395 [13:57:22<11:27:32,  7.48s/it] 47%|████▋     | 4878/10395 [13:57:29<11:32:32,  7.53s/it]                                                          {'loss': 0.9054, 'learning_rate': 1.1476116780513502e-05, 'epoch': 0.47}
 47%|████▋     | 4878/10395 [13:57:29<11:32:32,  7.53s/it] 47%|████▋     | 4879/10395 [13:57:37<11:33:31,  7.54s/it]                                                          {'loss': 0.8735, 'learning_rate': 1.1473035108452441e-05, 'epoch': 0.47}
 47%|████▋     | 4879/10395 [13:57:37<11:33:31,  7.54s/it] 47%|████▋     | 4880/10395 [13:57:54<15:49:43, 10.33s/it]                                                          {'loss': 0.4263, 'learning_rate': 1.1469953293392282e-05, 'epoch': 0.47}
 47%|████▋     | 4880/10395 [13:57:54<15:49:43, 10.33s/it] 47%|████▋     | 4881/10395 [13:58:01<14:31:01,  9.48s/it]                                                          {'loss': 0.9558, 'learning_rate': 1.1466871335632197e-05, 'epoch': 0.47}
 47%|████▋     | 4881/10395 [13:58:01<14:31:01,  9.48s/it] 47%|████▋     | 4882/10395 [13:58:09<13:38:22,  8.91s/it]                                                          {'loss': 0.9256, 'learning_rate': 1.1463789235471378e-05, 'epoch': 0.47}
 47%|████▋     | 4882/10395 [13:58:09<13:38:22,  8.91s/it] 47%|████▋     | 4883/10395 [13:58:17<13:11:46,  8.62s/it]                                                          {'loss': 0.898, 'learning_rate': 1.1460706993209028e-05, 'epoch': 0.47}
 47%|████▋     | 4883/10395 [13:58:17<13:11:46,  8.62s/it] 47%|████▋     | 4884/10395 [13:58:24<12:45:17,  8.33s/it]                                                          {'loss': 0.947, 'learning_rate': 1.1457624609144365e-05, 'epoch': 0.47}
 47%|████▋     | 4884/10395 [13:58:24<12:45:17,  8.33s/it] 47%|████▋     | 4885/10395 [13:58:33<12:48:24,  8.37s/it]                                                          {'loss': 0.8643, 'learning_rate': 1.1454542083576619e-05, 'epoch': 0.47}
 47%|████▋     | 4885/10395 [13:58:33<12:48:24,  8.37s/it] 47%|████▋     | 4886/10395 [13:58:41<12:28:01,  8.15s/it]                                                          {'loss': 0.9681, 'learning_rate': 1.1451459416805035e-05, 'epoch': 0.47}
 47%|████▋     | 4886/10395 [13:58:41<12:28:01,  8.15s/it] 47%|████▋     | 4887/10395 [13:58:48<12:07:12,  7.92s/it]                                                          {'loss': 0.9395, 'learning_rate': 1.1448376609128875e-05, 'epoch': 0.47}
 47%|████▋     | 4887/10395 [13:58:48<12:07:12,  7.92s/it] 47%|████▋     | 4888/10395 [13:58:55<11:56:35,  7.81s/it]                                                          {'loss': 0.9281, 'learning_rate': 1.1445293660847407e-05, 'epoch': 0.47}
 47%|████▋     | 4888/10395 [13:58:55<11:56:35,  7.81s/it] 47%|████▋     | 4889/10395 [13:59:03<11:44:37,  7.68s/it]                                                          {'loss': 0.9588, 'learning_rate': 1.1442210572259922e-05, 'epoch': 0.47}
 47%|████▋     | 4889/10395 [13:59:03<11:44:37,  7.68s/it] 47%|████▋     | 4890/10395 [13:59:19<15:43:02, 10.28s/it]                                                          {'loss': 0.3765, 'learning_rate': 1.1439127343665715e-05, 'epoch': 0.47}
 47%|████▋     | 4890/10395 [13:59:19<15:43:02, 10.28s/it] 47%|████▋     | 4891/10395 [13:59:28<14:52:45,  9.73s/it]                                                          {'loss': 0.9115, 'learning_rate': 1.14360439753641e-05, 'epoch': 0.47}
 47%|████▋     | 4891/10395 [13:59:28<14:52:45,  9.73s/it] 47%|████▋     | 4892/10395 [13:59:35<13:53:45,  9.09s/it]                                                          {'loss': 0.9099, 'learning_rate': 1.1432960467654404e-05, 'epoch': 0.47}
 47%|████▋     | 4892/10395 [13:59:35<13:53:45,  9.09s/it] 47%|████▋     | 4893/10395 [13:59:43<13:17:05,  8.69s/it]                                                          {'loss': 0.9747, 'learning_rate': 1.142987682083597e-05, 'epoch': 0.47}
 47%|████▋     | 4893/10395 [13:59:43<13:17:05,  8.69s/it] 47%|████▋     | 4894/10395 [13:59:52<13:18:06,  8.71s/it]                                                          {'loss': 0.9156, 'learning_rate': 1.1426793035208147e-05, 'epoch': 0.47}
 47%|████▋     | 4894/10395 [13:59:52<13:18:06,  8.71s/it] 47%|████▋     | 4895/10395 [13:59:59<12:34:49,  8.23s/it]                                                          {'loss': 0.9822, 'learning_rate': 1.1423709111070309e-05, 'epoch': 0.47}
 47%|████▋     | 4895/10395 [13:59:59<12:34:49,  8.23s/it] 47%|████▋     | 4896/10395 [14:00:07<12:21:21,  8.09s/it]                                                          {'loss': 0.9694, 'learning_rate': 1.1420625048721832e-05, 'epoch': 0.47}
 47%|████▋     | 4896/10395 [14:00:07<12:21:21,  8.09s/it] 47%|████▋     | 4897/10395 [14:00:16<12:53:40,  8.44s/it]                                                          {'loss': 0.9126, 'learning_rate': 1.141754084846211e-05, 'epoch': 0.47}
 47%|████▋     | 4897/10395 [14:00:16<12:53:40,  8.44s/it] 47%|████▋     | 4898/10395 [14:00:24<12:37:21,  8.27s/it]                                                          {'loss': 0.9566, 'learning_rate': 1.1414456510590553e-05, 'epoch': 0.47}
 47%|████▋     | 4898/10395 [14:00:24<12:37:21,  8.27s/it] 47%|████▋     | 4899/10395 [14:00:32<12:48:48,  8.39s/it]                                                          {'loss': 0.8474, 'learning_rate': 1.1411372035406578e-05, 'epoch': 0.47}
 47%|████▋     | 4899/10395 [14:00:32<12:48:48,  8.39s/it] 47%|████▋     | 4900/10395 [14:00:40<12:27:34,  8.16s/it]                                                          {'loss': 0.8497, 'learning_rate': 1.1408287423209626e-05, 'epoch': 0.47}
 47%|████▋     | 4900/10395 [14:00:40<12:27:34,  8.16s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 47%|████▋     | 4901/10395 [14:02:21<54:48:46, 35.92s/it]                                                          {'loss': 0.9801, 'learning_rate': 1.1405202674299139e-05, 'epoch': 0.47}
 47%|████▋     | 4901/10395 [14:02:21<54:48:46, 35.92s/it] 47%|████▋     | 4902/10395 [14:02:28<41:49:15, 27.41s/it]                                                          {'loss': 0.9195, 'learning_rate': 1.1402117788974575e-05, 'epoch': 0.47}
 47%|████▋     | 4902/10395 [14:02:28<41:49:15, 27.41s/it] 47%|████▋     | 4903/10395 [14:02:36<32:55:56, 21.59s/it]                                                          {'loss': 0.9487, 'learning_rate': 1.1399032767535418e-05, 'epoch': 0.47}
 47%|████▋     | 4903/10395 [14:02:36<32:55:56, 21.59s/it] 47%|████▋     | 4904/10395 [14:02:45<26:52:38, 17.62s/it]                                                          {'loss': 0.8397, 'learning_rate': 1.1395947610281146e-05, 'epoch': 0.47}
 47%|████▋     | 4904/10395 [14:02:45<26:52:38, 17.62s/it] 47%|████▋     | 4905/10395 [14:02:52<22:12:59, 14.57s/it]                                                          {'loss': 0.8772, 'learning_rate': 1.1392862317511266e-05, 'epoch': 0.47}
 47%|████▋     | 4905/10395 [14:02:52<22:12:59, 14.57s/it] 47%|████▋     | 4906/10395 [14:02:59<18:53:55, 12.39s/it]                                                          {'loss': 0.9267, 'learning_rate': 1.1389776889525288e-05, 'epoch': 0.47}
 47%|████▋     | 4906/10395 [14:02:59<18:53:55, 12.39s/it] 47%|████▋     | 4907/10395 [14:03:07<16:35:07, 10.88s/it]                                                          {'loss': 0.9117, 'learning_rate': 1.138669132662274e-05, 'epoch': 0.47}
 47%|████▋     | 4907/10395 [14:03:07<16:35:07, 10.88s/it] 47%|████▋     | 4908/10395 [14:03:15<15:21:31, 10.08s/it]                                                          {'loss': 0.9489, 'learning_rate': 1.1383605629103158e-05, 'epoch': 0.47}
 47%|████▋     | 4908/10395 [14:03:15<15:21:31, 10.08s/it] 47%|████▋     | 4909/10395 [14:03:31<18:03:21, 11.85s/it]                                                          {'loss': 0.3965, 'learning_rate': 1.1380519797266102e-05, 'epoch': 0.47}
 47%|████▋     | 4909/10395 [14:03:31<18:03:21, 11.85s/it] 47%|████▋     | 4910/10395 [14:03:39<16:09:55, 10.61s/it]                                                          {'loss': 0.8593, 'learning_rate': 1.1377433831411133e-05, 'epoch': 0.47}
 47%|████▋     | 4910/10395 [14:03:39<16:09:55, 10.61s/it] 47%|████▋     | 4911/10395 [14:03:46<14:38:12,  9.61s/it]                                                          {'loss': 0.9546, 'learning_rate': 1.1374347731837834e-05, 'epoch': 0.47}
 47%|████▋     | 4911/10395 [14:03:46<14:38:12,  9.61s/it] 47%|████▋     | 4912/10395 [14:03:54<13:59:30,  9.19s/it]                                                          {'loss': 0.982, 'learning_rate': 1.137126149884579e-05, 'epoch': 0.47}
 47%|████▋     | 4912/10395 [14:03:54<13:59:30,  9.19s/it] 47%|████▋     | 4913/10395 [14:04:03<13:35:45,  8.93s/it]                                                          {'loss': 0.9191, 'learning_rate': 1.1368175132734609e-05, 'epoch': 0.47}
 47%|████▋     | 4913/10395 [14:04:03<13:35:45,  8.93s/it] 47%|████▋     | 4914/10395 [14:04:11<13:12:40,  8.68s/it]                                                          {'loss': 0.8232, 'learning_rate': 1.1365088633803913e-05, 'epoch': 0.47}
 47%|████▋     | 4914/10395 [14:04:11<13:12:40,  8.68s/it] 47%|████▋     | 4915/10395 [14:04:19<12:57:40,  8.51s/it]                                                          {'loss': 0.8975, 'learning_rate': 1.1362002002353331e-05, 'epoch': 0.47}
 47%|████▋     | 4915/10395 [14:04:19<12:57:40,  8.51s/it] 47%|████▋     | 4916/10395 [14:04:26<12:33:21,  8.25s/it]                                                          {'loss': 0.9477, 'learning_rate': 1.1358915238682502e-05, 'epoch': 0.47}
 47%|████▋     | 4916/10395 [14:04:26<12:33:21,  8.25s/it] 47%|████▋     | 4917/10395 [14:04:34<12:13:23,  8.03s/it]                                                          {'loss': 0.9349, 'learning_rate': 1.1355828343091087e-05, 'epoch': 0.47}
 47%|████▋     | 4917/10395 [14:04:34<12:13:23,  8.03s/it] 47%|████▋     | 4918/10395 [14:04:42<12:02:41,  7.92s/it]                                                          {'loss': 0.9323, 'learning_rate': 1.1352741315878755e-05, 'epoch': 0.47}
 47%|████▋     | 4918/10395 [14:04:42<12:02:41,  7.92s/it] 47%|████▋     | 4919/10395 [14:04:49<11:56:27,  7.85s/it]                                                          {'loss': 0.8429, 'learning_rate': 1.1349654157345188e-05, 'epoch': 0.47}
 47%|████▋     | 4919/10395 [14:04:49<11:56:27,  7.85s/it] 47%|████▋     | 4920/10395 [14:04:57<12:07:22,  7.97s/it]                                                          {'loss': 0.8826, 'learning_rate': 1.1346566867790073e-05, 'epoch': 0.47}
 47%|████▋     | 4920/10395 [14:04:57<12:07:22,  7.97s/it] 47%|████▋     | 4921/10395 [14:05:05<12:08:12,  7.98s/it]                                                          {'loss': 0.9106, 'learning_rate': 1.1343479447513129e-05, 'epoch': 0.47}
 47%|████▋     | 4921/10395 [14:05:06<12:08:12,  7.98s/it] 47%|████▋     | 4922/10395 [14:05:13<11:57:04,  7.86s/it]                                                          {'loss': 1.0059, 'learning_rate': 1.1340391896814074e-05, 'epoch': 0.47}
 47%|████▋     | 4922/10395 [14:05:13<11:57:04,  7.86s/it] 47%|████▋     | 4923/10395 [14:05:21<11:52:47,  7.82s/it]                                                          {'loss': 0.8898, 'learning_rate': 1.1337304215992636e-05, 'epoch': 0.47}
 47%|████▋     | 4923/10395 [14:05:21<11:52:47,  7.82s/it] 47%|████▋     | 4924/10395 [14:05:29<12:00:50,  7.91s/it]                                                          {'loss': 0.8562, 'learning_rate': 1.1334216405348557e-05, 'epoch': 0.47}
 47%|████▋     | 4924/10395 [14:05:29<12:00:50,  7.91s/it] 47%|████▋     | 4925/10395 [14:05:37<12:02:37,  7.93s/it]                                                          {'loss': 0.8859, 'learning_rate': 1.1331128465181605e-05, 'epoch': 0.47}
 47%|████▋     | 4925/10395 [14:05:37<12:02:37,  7.93s/it] 47%|████▋     | 4926/10395 [14:05:45<12:18:04,  8.10s/it]                                                          {'loss': 0.957, 'learning_rate': 1.1328040395791549e-05, 'epoch': 0.47}
 47%|████▋     | 4926/10395 [14:05:45<12:18:04,  8.10s/it] 47%|████▋     | 4927/10395 [14:05:55<12:47:43,  8.42s/it]                                                          {'loss': 0.8525, 'learning_rate': 1.1324952197478165e-05, 'epoch': 0.47}
 47%|████▋     | 4927/10395 [14:05:55<12:47:43,  8.42s/it] 47%|████▋     | 4928/10395 [14:06:02<12:32:34,  8.26s/it]                                                          {'loss': 0.879, 'learning_rate': 1.1321863870541252e-05, 'epoch': 0.47}
 47%|████▋     | 4928/10395 [14:06:02<12:32:34,  8.26s/it] 47%|████▋     | 4929/10395 [14:06:10<12:15:21,  8.07s/it]                                                          {'loss': 0.8453, 'learning_rate': 1.1318775415280622e-05, 'epoch': 0.47}
 47%|████▋     | 4929/10395 [14:06:10<12:15:21,  8.07s/it] 47%|████▋     | 4930/10395 [14:06:18<12:01:23,  7.92s/it]                                                          {'loss': 0.8473, 'learning_rate': 1.1315686831996096e-05, 'epoch': 0.47}
 47%|████▋     | 4930/10395 [14:06:18<12:01:23,  7.92s/it] 47%|████▋     | 4931/10395 [14:06:25<11:51:50,  7.82s/it]                                                          {'loss': 0.9881, 'learning_rate': 1.13125981209875e-05, 'epoch': 0.47}
 47%|████▋     | 4931/10395 [14:06:25<11:51:50,  7.82s/it] 47%|████▋     | 4932/10395 [14:06:42<15:56:07, 10.50s/it]                                                          {'loss': 0.3865, 'learning_rate': 1.1309509282554682e-05, 'epoch': 0.47}
 47%|████▋     | 4932/10395 [14:06:42<15:56:07, 10.50s/it] 47%|████▋     | 4933/10395 [14:06:50<14:56:10,  9.84s/it]                                                          {'loss': 0.903, 'learning_rate': 1.1306420316997507e-05, 'epoch': 0.47}
 47%|████▋     | 4933/10395 [14:06:50<14:56:10,  9.84s/it] 47%|████▋     | 4934/10395 [14:06:58<14:05:39,  9.29s/it]                                                          {'loss': 0.8776, 'learning_rate': 1.1303331224615835e-05, 'epoch': 0.47}
 47%|████▋     | 4934/10395 [14:06:58<14:05:39,  9.29s/it] 47%|████▋     | 4935/10395 [14:07:05<13:08:49,  8.67s/it]                                                          {'loss': 0.868, 'learning_rate': 1.1300242005709551e-05, 'epoch': 0.47}
 47%|████▋     | 4935/10395 [14:07:06<13:08:49,  8.67s/it] 47%|████▋     | 4936/10395 [14:07:14<12:58:50,  8.56s/it]                                                          {'loss': 0.8399, 'learning_rate': 1.1297152660578557e-05, 'epoch': 0.47}
 47%|████▋     | 4936/10395 [14:07:14<12:58:50,  8.56s/it] 47%|████▋     | 4937/10395 [14:07:21<12:33:11,  8.28s/it]                                                          {'loss': 0.8568, 'learning_rate': 1.1294063189522753e-05, 'epoch': 0.47}
 47%|████▋     | 4937/10395 [14:07:21<12:33:11,  8.28s/it] 48%|████▊     | 4938/10395 [14:07:29<12:19:23,  8.13s/it]                                                          {'loss': 0.8685, 'learning_rate': 1.129097359284206e-05, 'epoch': 0.48}
 48%|████▊     | 4938/10395 [14:07:29<12:19:23,  8.13s/it] 48%|████▊     | 4939/10395 [14:07:37<12:05:42,  7.98s/it]                                                          {'loss': 1.0, 'learning_rate': 1.1287883870836407e-05, 'epoch': 0.48}
 48%|████▊     | 4939/10395 [14:07:37<12:05:42,  7.98s/it] 48%|████▊     | 4940/10395 [14:07:44<11:47:46,  7.78s/it]                                                          {'loss': 0.9667, 'learning_rate': 1.128479402380574e-05, 'epoch': 0.48}
 48%|████▊     | 4940/10395 [14:07:44<11:47:46,  7.78s/it] 48%|████▊     | 4941/10395 [14:07:52<11:40:35,  7.71s/it]                                                          {'loss': 0.9473, 'learning_rate': 1.128170405205002e-05, 'epoch': 0.48}
 48%|████▊     | 4941/10395 [14:07:52<11:40:35,  7.71s/it] 48%|████▊     | 4942/10395 [14:08:00<11:54:29,  7.86s/it]                                                          {'loss': 0.9613, 'learning_rate': 1.1278613955869206e-05, 'epoch': 0.48}
 48%|████▊     | 4942/10395 [14:08:00<11:54:29,  7.86s/it] 48%|████▊     | 4943/10395 [14:08:07<11:43:34,  7.74s/it]                                                          {'loss': 0.8965, 'learning_rate': 1.1275523735563281e-05, 'epoch': 0.48}
 48%|████▊     | 4943/10395 [14:08:07<11:43:34,  7.74s/it] 48%|████▊     | 4944/10395 [14:08:15<11:34:59,  7.65s/it]                                                          {'loss': 0.8818, 'learning_rate': 1.127243339143224e-05, 'epoch': 0.48}
 48%|████▊     | 4944/10395 [14:08:15<11:34:59,  7.65s/it] 48%|████▊     | 4945/10395 [14:08:22<11:30:18,  7.60s/it]                                                          {'loss': 0.9049, 'learning_rate': 1.1269342923776083e-05, 'epoch': 0.48}
 48%|████▊     | 4945/10395 [14:08:22<11:30:18,  7.60s/it] 48%|████▊     | 4946/10395 [14:08:40<15:57:54, 10.55s/it]                                                          {'loss': 0.3865, 'learning_rate': 1.1266252332894827e-05, 'epoch': 0.48}
 48%|████▊     | 4946/10395 [14:08:40<15:57:54, 10.55s/it] 48%|████▊     | 4947/10395 [14:08:47<14:31:29,  9.60s/it]                                                          {'loss': 0.8547, 'learning_rate': 1.1263161619088498e-05, 'epoch': 0.48}
 48%|████▊     | 4947/10395 [14:08:47<14:31:29,  9.60s/it] 48%|████▊     | 4948/10395 [14:08:56<13:58:42,  9.24s/it]                                                          {'loss': 0.8703, 'learning_rate': 1.1260070782657144e-05, 'epoch': 0.48}
 48%|████▊     | 4948/10395 [14:08:56<13:58:42,  9.24s/it] 48%|████▊     | 4949/10395 [14:09:04<13:31:37,  8.94s/it]                                                          {'loss': 0.8024, 'learning_rate': 1.125697982390081e-05, 'epoch': 0.48}
 48%|████▊     | 4949/10395 [14:09:04<13:31:37,  8.94s/it] 48%|████▊     | 4950/10395 [14:09:11<12:51:59,  8.51s/it]                                                          {'loss': 0.9568, 'learning_rate': 1.1253888743119558e-05, 'epoch': 0.48}
 48%|████▊     | 4950/10395 [14:09:11<12:51:59,  8.51s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 48%|████▊     | 4951/10395 [14:11:01<58:38:15, 38.78s/it]                                                          {'loss': 0.3973, 'learning_rate': 1.1250797540613465e-05, 'epoch': 0.48}
 48%|████▊     | 4951/10395 [14:11:01<58:38:15, 38.78s/it] 48%|████▊     | 4952/10395 [14:11:08<44:24:44, 29.37s/it]                                                          {'loss': 0.9151, 'learning_rate': 1.1247706216682626e-05, 'epoch': 0.48}
 48%|████▊     | 4952/10395 [14:11:08<44:24:44, 29.37s/it] 48%|████▊     | 4953/10395 [14:11:16<34:27:13, 22.79s/it]                                                          {'loss': 0.9377, 'learning_rate': 1.1244614771627129e-05, 'epoch': 0.48}
 48%|████▊     | 4953/10395 [14:11:16<34:27:13, 22.79s/it] 48%|████▊     | 4954/10395 [14:11:23<27:27:50, 18.17s/it]                                                          {'loss': 0.9069, 'learning_rate': 1.1241523205747092e-05, 'epoch': 0.48}
 48%|████▊     | 4954/10395 [14:11:23<27:27:50, 18.17s/it] 48%|████▊     | 4955/10395 [14:11:31<22:49:48, 15.11s/it]                                                          {'loss': 0.8784, 'learning_rate': 1.1238431519342634e-05, 'epoch': 0.48}
 48%|████▊     | 4955/10395 [14:11:31<22:49:48, 15.11s/it] 48%|████▊     | 4956/10395 [14:11:39<19:28:40, 12.89s/it]                                                          {'loss': 0.9102, 'learning_rate': 1.1235339712713894e-05, 'epoch': 0.48}
 48%|████▊     | 4956/10395 [14:11:39<19:28:40, 12.89s/it] 48%|████▊     | 4957/10395 [14:11:47<17:20:00, 11.47s/it]                                                          {'loss': 0.9237, 'learning_rate': 1.123224778616101e-05, 'epoch': 0.48}
 48%|████▊     | 4957/10395 [14:11:47<17:20:00, 11.47s/it] 48%|████▊     | 4958/10395 [14:11:54<15:34:13, 10.31s/it]                                                          {'loss': 0.901, 'learning_rate': 1.1229155739984145e-05, 'epoch': 0.48}
 48%|████▊     | 4958/10395 [14:11:54<15:34:13, 10.31s/it] 48%|████▊     | 4959/10395 [14:12:04<15:10:22, 10.05s/it]                                                          {'loss': 0.9565, 'learning_rate': 1.122606357448347e-05, 'epoch': 0.48}
 48%|████▊     | 4959/10395 [14:12:04<15:10:22, 10.05s/it] 48%|████▊     | 4960/10395 [14:12:12<14:08:12,  9.36s/it]                                                          {'loss': 0.8226, 'learning_rate': 1.1222971289959161e-05, 'epoch': 0.48}
 48%|████▊     | 4960/10395 [14:12:12<14:08:12,  9.36s/it] 48%|████▊     | 4961/10395 [14:12:20<13:43:06,  9.09s/it]                                                          {'loss': 0.9338, 'learning_rate': 1.1219878886711413e-05, 'epoch': 0.48}
 48%|████▊     | 4961/10395 [14:12:20<13:43:06,  9.09s/it] 48%|████▊     | 4962/10395 [14:12:27<12:54:31,  8.55s/it]                                                          {'loss': 0.8996, 'learning_rate': 1.121678636504043e-05, 'epoch': 0.48}
 48%|████▊     | 4962/10395 [14:12:27<12:54:31,  8.55s/it] 48%|████▊     | 4963/10395 [14:12:34<12:15:37,  8.13s/it]                                                          {'loss': 0.8911, 'learning_rate': 1.1213693725246426e-05, 'epoch': 0.48}
 48%|████▊     | 4963/10395 [14:12:34<12:15:37,  8.13s/it] 48%|████▊     | 4964/10395 [14:12:42<11:55:33,  7.91s/it]                                                          {'loss': 0.9189, 'learning_rate': 1.121060096762963e-05, 'epoch': 0.48}
 48%|████▊     | 4964/10395 [14:12:42<11:55:33,  7.91s/it] 48%|████▊     | 4965/10395 [14:12:51<12:31:52,  8.31s/it]                                                          {'loss': 0.8398, 'learning_rate': 1.120750809249028e-05, 'epoch': 0.48}
 48%|████▊     | 4965/10395 [14:12:51<12:31:52,  8.31s/it] 48%|████▊     | 4966/10395 [14:13:00<12:42:29,  8.43s/it]                                                          {'loss': 0.8961, 'learning_rate': 1.1204415100128624e-05, 'epoch': 0.48}
 48%|████▊     | 4966/10395 [14:13:00<12:42:29,  8.43s/it] 48%|████▊     | 4967/10395 [14:13:09<13:00:23,  8.63s/it]                                                          {'loss': 0.8013, 'learning_rate': 1.1201321990844921e-05, 'epoch': 0.48}
 48%|████▊     | 4967/10395 [14:13:09<13:00:23,  8.63s/it] 48%|████▊     | 4968/10395 [14:13:17<12:38:49,  8.39s/it]                                                          {'loss': 0.9603, 'learning_rate': 1.1198228764939451e-05, 'epoch': 0.48}
 48%|████▊     | 4968/10395 [14:13:17<12:38:49,  8.39s/it] 48%|████▊     | 4969/10395 [14:13:25<12:43:28,  8.44s/it]                                                          {'loss': 0.7693, 'learning_rate': 1.1195135422712492e-05, 'epoch': 0.48}
 48%|████▊     | 4969/10395 [14:13:25<12:43:28,  8.44s/it] 48%|████▊     | 4970/10395 [14:13:33<12:16:30,  8.15s/it]                                                          {'loss': 0.8781, 'learning_rate': 1.1192041964464339e-05, 'epoch': 0.48}
 48%|████▊     | 4970/10395 [14:13:33<12:16:30,  8.15s/it] 48%|████▊     | 4971/10395 [14:13:40<12:03:01,  8.00s/it]                                                          {'loss': 0.8848, 'learning_rate': 1.11889483904953e-05, 'epoch': 0.48}
 48%|████▊     | 4971/10395 [14:13:40<12:03:01,  8.00s/it] 48%|████▊     | 4972/10395 [14:13:48<11:55:29,  7.92s/it]                                                          {'loss': 0.9716, 'learning_rate': 1.1185854701105691e-05, 'epoch': 0.48}
 48%|████▊     | 4972/10395 [14:13:48<11:55:29,  7.92s/it] 48%|████▊     | 4973/10395 [14:13:55<11:40:55,  7.76s/it]                                                          {'loss': 0.8958, 'learning_rate': 1.1182760896595843e-05, 'epoch': 0.48}
 48%|████▊     | 4973/10395 [14:13:55<11:40:55,  7.76s/it] 48%|████▊     | 4974/10395 [14:14:04<12:12:01,  8.10s/it]                                                          {'loss': 0.8773, 'learning_rate': 1.1179666977266095e-05, 'epoch': 0.48}
 48%|████▊     | 4974/10395 [14:14:04<12:12:01,  8.10s/it] 48%|████▊     | 4975/10395 [14:14:12<11:54:50,  7.91s/it]                                                          {'loss': 0.9459, 'learning_rate': 1.1176572943416797e-05, 'epoch': 0.48}
 48%|████▊     | 4975/10395 [14:14:12<11:54:50,  7.91s/it] 48%|████▊     | 4976/10395 [14:14:19<11:46:09,  7.82s/it]                                                          {'loss': 0.8925, 'learning_rate': 1.1173478795348312e-05, 'epoch': 0.48}
 48%|████▊     | 4976/10395 [14:14:19<11:46:09,  7.82s/it] 48%|████▊     | 4977/10395 [14:14:28<11:51:55,  7.88s/it]                                                          {'loss': 0.9127, 'learning_rate': 1.1170384533361014e-05, 'epoch': 0.48}
 48%|████▊     | 4977/10395 [14:14:28<11:51:55,  7.88s/it] 48%|████▊     | 4978/10395 [14:14:35<11:46:54,  7.83s/it]                                                          {'loss': 0.9452, 'learning_rate': 1.1167290157755287e-05, 'epoch': 0.48}
 48%|████▊     | 4978/10395 [14:14:35<11:46:54,  7.83s/it] 48%|████▊     | 4979/10395 [14:14:43<11:34:41,  7.70s/it]                                                          {'loss': 0.8352, 'learning_rate': 1.1164195668831523e-05, 'epoch': 0.48}
 48%|████▊     | 4979/10395 [14:14:43<11:34:41,  7.70s/it] 48%|████▊     | 4980/10395 [14:14:50<11:26:04,  7.60s/it]                                                          {'loss': 0.9603, 'learning_rate': 1.1161101066890134e-05, 'epoch': 0.48}
 48%|████▊     | 4980/10395 [14:14:50<11:26:04,  7.60s/it] 48%|████▊     | 4981/10395 [14:14:57<11:14:06,  7.47s/it]                                                          {'loss': 0.9346, 'learning_rate': 1.1158006352231535e-05, 'epoch': 0.48}
 48%|████▊     | 4981/10395 [14:14:57<11:14:06,  7.47s/it] 48%|████▊     | 4982/10395 [14:15:06<11:57:22,  7.95s/it]                                                          {'loss': 0.8192, 'learning_rate': 1.1154911525156152e-05, 'epoch': 0.48}
 48%|████▊     | 4982/10395 [14:15:06<11:57:22,  7.95s/it] 48%|████▊     | 4983/10395 [14:15:14<11:54:09,  7.92s/it]                                                          {'loss': 0.9097, 'learning_rate': 1.1151816585964428e-05, 'epoch': 0.48}
 48%|████▊     | 4983/10395 [14:15:14<11:54:09,  7.92s/it] 48%|████▊     | 4984/10395 [14:15:22<11:49:27,  7.87s/it]                                                          {'loss': 0.9147, 'learning_rate': 1.114872153495681e-05, 'epoch': 0.48}
 48%|████▊     | 4984/10395 [14:15:22<11:49:27,  7.87s/it] 48%|████▊     | 4985/10395 [14:15:30<11:49:29,  7.87s/it]                                                          {'loss': 0.8985, 'learning_rate': 1.114562637243376e-05, 'epoch': 0.48}
 48%|████▊     | 4985/10395 [14:15:30<11:49:29,  7.87s/it] 48%|████▊     | 4986/10395 [14:15:37<11:43:35,  7.80s/it]                                                          {'loss': 0.9046, 'learning_rate': 1.1142531098695752e-05, 'epoch': 0.48}
 48%|████▊     | 4986/10395 [14:15:37<11:43:35,  7.80s/it] 48%|████▊     | 4987/10395 [14:15:45<11:26:17,  7.61s/it]                                                          {'loss': 1.0081, 'learning_rate': 1.1139435714043265e-05, 'epoch': 0.48}
 48%|████▊     | 4987/10395 [14:15:45<11:26:17,  7.61s/it] 48%|████▊     | 4988/10395 [14:15:53<11:58:00,  7.97s/it]                                                          {'loss': 0.8697, 'learning_rate': 1.1136340218776796e-05, 'epoch': 0.48}
 48%|████▊     | 4988/10395 [14:15:53<11:58:00,  7.97s/it] 48%|████▊     | 4989/10395 [14:16:01<11:40:35,  7.78s/it]                                                          {'loss': 0.9341, 'learning_rate': 1.1133244613196843e-05, 'epoch': 0.48}
 48%|████▊     | 4989/10395 [14:16:01<11:40:35,  7.78s/it] 48%|████▊     | 4990/10395 [14:16:08<11:31:29,  7.68s/it]                                                          {'loss': 0.8812, 'learning_rate': 1.1130148897603928e-05, 'epoch': 0.48}
 48%|████▊     | 4990/10395 [14:16:08<11:31:29,  7.68s/it] 48%|████▊     | 4991/10395 [14:16:16<11:42:38,  7.80s/it]                                                          {'loss': 0.8352, 'learning_rate': 1.112705307229857e-05, 'epoch': 0.48}
 48%|████▊     | 4991/10395 [14:16:16<11:42:38,  7.80s/it] 48%|████▊     | 4992/10395 [14:16:24<11:40:49,  7.78s/it]                                                          {'loss': 0.8961, 'learning_rate': 1.1123957137581313e-05, 'epoch': 0.48}
 48%|████▊     | 4992/10395 [14:16:24<11:40:49,  7.78s/it] 48%|████▊     | 4993/10395 [14:16:32<11:42:25,  7.80s/it]                                                          {'loss': 0.8855, 'learning_rate': 1.1120861093752695e-05, 'epoch': 0.48}
 48%|████▊     | 4993/10395 [14:16:32<11:42:25,  7.80s/it] 48%|████▊     | 4994/10395 [14:16:50<16:14:05, 10.82s/it]                                                          {'loss': 0.4112, 'learning_rate': 1.1117764941113278e-05, 'epoch': 0.48}
 48%|████▊     | 4994/10395 [14:16:50<16:14:05, 10.82s/it] 48%|████▊     | 4995/10395 [14:16:57<14:42:08,  9.80s/it]                                                          {'loss': 0.8394, 'learning_rate': 1.111466867996363e-05, 'epoch': 0.48}
 48%|████▊     | 4995/10395 [14:16:57<14:42:08,  9.80s/it] 48%|████▊     | 4996/10395 [14:17:05<13:42:57,  9.15s/it]                                                          {'loss': 0.9765, 'learning_rate': 1.1111572310604331e-05, 'epoch': 0.48}
 48%|████▊     | 4996/10395 [14:17:05<13:42:57,  9.15s/it] 48%|████▊     | 4997/10395 [14:17:13<13:29:00,  8.99s/it]                                                          {'loss': 0.9139, 'learning_rate': 1.110847583333596e-05, 'epoch': 0.48}
 48%|████▊     | 4997/10395 [14:17:13<13:29:00,  8.99s/it] 48%|████▊     | 4998/10395 [14:17:21<12:55:09,  8.62s/it]                                                          {'loss': 0.9049, 'learning_rate': 1.1105379248459132e-05, 'epoch': 0.48}
 48%|████▊     | 4998/10395 [14:17:21<12:55:09,  8.62s/it] 48%|████▊     | 4999/10395 [14:17:29<12:41:30,  8.47s/it]                                                          {'loss': 0.9343, 'learning_rate': 1.1102282556274446e-05, 'epoch': 0.48}
 48%|████▊     | 4999/10395 [14:17:29<12:41:30,  8.47s/it] 48%|████▊     | 5000/10395 [14:17:37<12:18:18,  8.21s/it]                                                          {'loss': 0.8954, 'learning_rate': 1.1099185757082522e-05, 'epoch': 0.48}
 48%|████▊     | 5000/10395 [14:17:37<12:18:18,  8.21s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 48%|████▊     | 5001/10395 [14:19:20<55:07:10, 36.79s/it]                                                          {'loss': 0.9219, 'learning_rate': 1.1096088851183997e-05, 'epoch': 0.48}
 48%|████▊     | 5001/10395 [14:19:20<55:07:10, 36.79s/it] 48%|████▊     | 5002/10395 [14:19:28<42:14:23, 28.20s/it]                                                          {'loss': 0.7909, 'learning_rate': 1.1092991838879507e-05, 'epoch': 0.48}
 48%|████▊     | 5002/10395 [14:19:28<42:14:23, 28.20s/it] 48%|████▊     | 5003/10395 [14:19:37<33:15:42, 22.21s/it]                                                          {'loss': 0.8929, 'learning_rate': 1.108989472046971e-05, 'epoch': 0.48}
 48%|████▊     | 5003/10395 [14:19:37<33:15:42, 22.21s/it] 48%|████▊     | 5004/10395 [14:19:45<26:58:16, 18.01s/it]                                                          {'loss': 0.9103, 'learning_rate': 1.1086797496255256e-05, 'epoch': 0.48}
 48%|████▊     | 5004/10395 [14:19:45<26:58:16, 18.01s/it] 48%|████▊     | 5005/10395 [14:19:53<22:43:39, 15.18s/it]                                                          {'loss': 0.8405, 'learning_rate': 1.1083700166536825e-05, 'epoch': 0.48}
 48%|████▊     | 5005/10395 [14:19:53<22:43:39, 15.18s/it] 48%|████▊     | 5006/10395 [14:20:01<19:07:43, 12.78s/it]                                                          {'loss': 0.9592, 'learning_rate': 1.10806027316151e-05, 'epoch': 0.48}
 48%|████▊     | 5006/10395 [14:20:01<19:07:43, 12.78s/it] 48%|████▊     | 5007/10395 [14:20:09<17:06:14, 11.43s/it]                                                          {'loss': 0.8447, 'learning_rate': 1.1077505191790772e-05, 'epoch': 0.48}
 48%|████▊     | 5007/10395 [14:20:09<17:06:14, 11.43s/it] 48%|████▊     | 5008/10395 [14:20:16<15:19:16, 10.24s/it]                                                          {'loss': 0.8961, 'learning_rate': 1.1074407547364538e-05, 'epoch': 0.48}
 48%|████▊     | 5008/10395 [14:20:16<15:19:16, 10.24s/it] 48%|████▊     | 5009/10395 [14:20:33<17:59:17, 12.02s/it]                                                          {'loss': 0.3694, 'learning_rate': 1.1071309798637118e-05, 'epoch': 0.48}
 48%|████▊     | 5009/10395 [14:20:33<17:59:17, 12.02s/it] 48%|████▊     | 5010/10395 [14:20:40<16:02:36, 10.73s/it]                                                          {'loss': 0.9011, 'learning_rate': 1.1068211945909233e-05, 'epoch': 0.48}
 48%|████▊     | 5010/10395 [14:20:40<16:02:36, 10.73s/it] 48%|████▊     | 5011/10395 [14:20:48<14:47:32,  9.89s/it]                                                          {'loss': 0.9088, 'learning_rate': 1.1065113989481614e-05, 'epoch': 0.48}
 48%|████▊     | 5011/10395 [14:20:48<14:47:32,  9.89s/it] 48%|████▊     | 5012/10395 [14:20:55<13:35:45,  9.09s/it]                                                          {'loss': 1.0142, 'learning_rate': 1.1062015929655004e-05, 'epoch': 0.48}
 48%|████▊     | 5012/10395 [14:20:55<13:35:45,  9.09s/it] 48%|████▊     | 5013/10395 [14:21:04<13:23:14,  8.95s/it]                                                          {'loss': 0.9001, 'learning_rate': 1.1058917766730158e-05, 'epoch': 0.48}
 48%|████▊     | 5013/10395 [14:21:04<13:23:14,  8.95s/it] 48%|████▊     | 5014/10395 [14:21:12<12:49:37,  8.58s/it]                                                          {'loss': 0.9353, 'learning_rate': 1.105581950100784e-05, 'epoch': 0.48}
 48%|████▊     | 5014/10395 [14:21:12<12:49:37,  8.58s/it] 48%|████▊     | 5015/10395 [14:21:20<12:32:32,  8.39s/it]                                                          {'loss': 0.8746, 'learning_rate': 1.1052721132788819e-05, 'epoch': 0.48}
 48%|████▊     | 5015/10395 [14:21:20<12:32:32,  8.39s/it] 48%|████▊     | 5016/10395 [14:21:27<12:16:08,  8.21s/it]                                                          {'loss': 0.9202, 'learning_rate': 1.104962266237388e-05, 'epoch': 0.48}
 48%|████▊     | 5016/10395 [14:21:27<12:16:08,  8.21s/it] 48%|████▊     | 5017/10395 [14:21:35<12:00:12,  8.04s/it]                                                          {'loss': 0.8954, 'learning_rate': 1.1046524090063815e-05, 'epoch': 0.48}
 48%|████▊     | 5017/10395 [14:21:35<12:00:12,  8.04s/it] 48%|████▊     | 5018/10395 [14:21:42<11:39:04,  7.80s/it]                                                          {'loss': 0.9338, 'learning_rate': 1.1043425416159432e-05, 'epoch': 0.48}
 48%|████▊     | 5018/10395 [14:21:42<11:39:04,  7.80s/it] 48%|████▊     | 5019/10395 [14:21:59<15:43:22, 10.53s/it]                                                          {'loss': 0.3413, 'learning_rate': 1.1040326640961537e-05, 'epoch': 0.48}
 48%|████▊     | 5019/10395 [14:21:59<15:43:22, 10.53s/it] 48%|████▊     | 5020/10395 [14:22:07<14:24:05,  9.65s/it]                                                          {'loss': 0.8413, 'learning_rate': 1.1037227764770953e-05, 'epoch': 0.48}
 48%|████▊     | 5020/10395 [14:22:07<14:24:05,  9.65s/it] 48%|████▊     | 5021/10395 [14:22:14<13:22:00,  8.95s/it]                                                          {'loss': 0.8373, 'learning_rate': 1.103412878788852e-05, 'epoch': 0.48}
 48%|████▊     | 5021/10395 [14:22:14<13:22:00,  8.95s/it] 48%|████▊     | 5022/10395 [14:22:21<12:34:31,  8.43s/it]                                                          {'loss': 0.9073, 'learning_rate': 1.1031029710615067e-05, 'epoch': 0.48}
 48%|████▊     | 5022/10395 [14:22:21<12:34:31,  8.43s/it] 48%|████▊     | 5023/10395 [14:22:29<12:01:43,  8.06s/it]                                                          {'loss': 0.8813, 'learning_rate': 1.1027930533251456e-05, 'epoch': 0.48}
 48%|████▊     | 5023/10395 [14:22:29<12:01:43,  8.06s/it] 48%|████▊     | 5024/10395 [14:22:46<16:00:20, 10.73s/it]                                                          {'loss': 0.3765, 'learning_rate': 1.1024831256098544e-05, 'epoch': 0.48}
 48%|████▊     | 5024/10395 [14:22:46<16:00:20, 10.73s/it] 48%|████▊     | 5025/10395 [14:22:53<14:44:41,  9.88s/it]                                                          {'loss': 0.9097, 'learning_rate': 1.1021731879457207e-05, 'epoch': 0.48}
 48%|████▊     | 5025/10395 [14:22:53<14:44:41,  9.88s/it] 48%|████▊     | 5026/10395 [14:23:01<13:45:08,  9.22s/it]                                                          {'loss': 0.9395, 'learning_rate': 1.1018632403628322e-05, 'epoch': 0.48}
 48%|████▊     | 5026/10395 [14:23:01<13:45:08,  9.22s/it] 48%|████▊     | 5027/10395 [14:23:10<13:23:27,  8.98s/it]                                                          {'loss': 0.8548, 'learning_rate': 1.1015532828912779e-05, 'epoch': 0.48}
 48%|████▊     | 5027/10395 [14:23:10<13:23:27,  8.98s/it] 48%|████▊     | 5028/10395 [14:23:26<16:47:04, 11.26s/it]                                                          {'loss': 0.3461, 'learning_rate': 1.1012433155611476e-05, 'epoch': 0.48}
 48%|████▊     | 5028/10395 [14:23:26<16:47:04, 11.26s/it] 48%|████▊     | 5029/10395 [14:23:34<15:22:15, 10.31s/it]                                                          {'loss': 0.8735, 'learning_rate': 1.1009333384025331e-05, 'epoch': 0.48}
 48%|████▊     | 5029/10395 [14:23:34<15:22:15, 10.31s/it] 48%|████▊     | 5030/10395 [14:23:52<18:48:47, 12.62s/it]                                                          {'loss': 0.3892, 'learning_rate': 1.1006233514455256e-05, 'epoch': 0.48}
 48%|████▊     | 5030/10395 [14:23:52<18:48:47, 12.62s/it] 48%|████▊     | 5031/10395 [14:24:00<16:40:00, 11.19s/it]                                                          {'loss': 0.9129, 'learning_rate': 1.1003133547202181e-05, 'epoch': 0.48}
 48%|████▊     | 5031/10395 [14:24:00<16:40:00, 11.19s/it] 48%|████▊     | 5032/10395 [14:24:08<15:01:37, 10.09s/it]                                                          {'loss': 0.8703, 'learning_rate': 1.1000033482567045e-05, 'epoch': 0.48}
 48%|████▊     | 5032/10395 [14:24:08<15:01:37, 10.09s/it] 48%|████▊     | 5033/10395 [14:24:15<13:51:29,  9.30s/it]                                                          {'loss': 0.8361, 'learning_rate': 1.0996933320850798e-05, 'epoch': 0.48}
 48%|████▊     | 5033/10395 [14:24:15<13:51:29,  9.30s/it] 48%|████▊     | 5034/10395 [14:24:23<13:11:48,  8.86s/it]                                                          {'loss': 0.9118, 'learning_rate': 1.0993833062354393e-05, 'epoch': 0.48}
 48%|████▊     | 5034/10395 [14:24:23<13:11:48,  8.86s/it] 48%|████▊     | 5035/10395 [14:24:31<12:44:47,  8.56s/it]                                                          {'loss': 0.9159, 'learning_rate': 1.0990732707378795e-05, 'epoch': 0.48}
 48%|████▊     | 5035/10395 [14:24:31<12:44:47,  8.56s/it] 48%|████▊     | 5036/10395 [14:24:38<12:11:03,  8.18s/it]                                                          {'loss': 0.8723, 'learning_rate': 1.0987632256224989e-05, 'epoch': 0.48}
 48%|████▊     | 5036/10395 [14:24:38<12:11:03,  8.18s/it] 48%|████▊     | 5037/10395 [14:24:45<11:47:44,  7.93s/it]                                                          {'loss': 0.9364, 'learning_rate': 1.098453170919395e-05, 'epoch': 0.48}
 48%|████▊     | 5037/10395 [14:24:45<11:47:44,  7.93s/it] 48%|████▊     | 5038/10395 [14:24:53<11:43:33,  7.88s/it]                                                          {'loss': 0.9714, 'learning_rate': 1.0981431066586679e-05, 'epoch': 0.48}
 48%|████▊     | 5038/10395 [14:24:53<11:43:33,  7.88s/it] 48%|████▊     | 5039/10395 [14:25:02<11:58:31,  8.05s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.0978330328704173e-05, 'epoch': 0.48}
 48%|████▊     | 5039/10395 [14:25:02<11:58:31,  8.05s/it] 48%|████▊     | 5040/10395 [14:25:09<11:47:03,  7.92s/it]                                                          {'loss': 0.9213, 'learning_rate': 1.0975229495847455e-05, 'epoch': 0.48}
 48%|████▊     | 5040/10395 [14:25:09<11:47:03,  7.92s/it] 48%|████▊     | 5041/10395 [14:25:17<11:49:03,  7.95s/it]                                                          {'loss': 0.9335, 'learning_rate': 1.097212856831754e-05, 'epoch': 0.48}
 48%|████▊     | 5041/10395 [14:25:17<11:49:03,  7.95s/it] 49%|████▊     | 5042/10395 [14:25:25<11:42:11,  7.87s/it]                                                          {'loss': 0.9406, 'learning_rate': 1.0969027546415459e-05, 'epoch': 0.49}
 49%|████▊     | 5042/10395 [14:25:25<11:42:11,  7.87s/it] 49%|████▊     | 5043/10395 [14:25:33<11:46:21,  7.92s/it]                                                          {'loss': 0.8837, 'learning_rate': 1.0965926430442256e-05, 'epoch': 0.49}
 49%|████▊     | 5043/10395 [14:25:33<11:46:21,  7.92s/it] 49%|████▊     | 5044/10395 [14:25:40<11:32:15,  7.76s/it]                                                          {'loss': 0.9152, 'learning_rate': 1.0962825220698979e-05, 'epoch': 0.49}
 49%|████▊     | 5044/10395 [14:25:40<11:32:15,  7.76s/it] 49%|████▊     | 5045/10395 [14:25:48<11:17:49,  7.60s/it]                                                          {'loss': 0.8323, 'learning_rate': 1.0959723917486687e-05, 'epoch': 0.49}
 49%|████▊     | 5045/10395 [14:25:48<11:17:49,  7.60s/it] 49%|████▊     | 5046/10395 [14:25:55<11:14:13,  7.56s/it]                                                          {'loss': 0.8874, 'learning_rate': 1.0956622521106448e-05, 'epoch': 0.49}
 49%|████▊     | 5046/10395 [14:25:55<11:14:13,  7.56s/it] 49%|████▊     | 5047/10395 [14:26:02<11:06:06,  7.47s/it]                                                          {'loss': 0.8818, 'learning_rate': 1.095352103185934e-05, 'epoch': 0.49}
 49%|████▊     | 5047/10395 [14:26:02<11:06:06,  7.47s/it] 49%|████▊     | 5048/10395 [14:26:20<15:31:42, 10.46s/it]                                                          {'loss': 0.4211, 'learning_rate': 1.0950419450046448e-05, 'epoch': 0.49}
 49%|████▊     | 5048/10395 [14:26:20<15:31:42, 10.46s/it] 49%|████▊     | 5049/10395 [14:26:28<14:33:06,  9.80s/it]                                                          {'loss': 0.976, 'learning_rate': 1.0947317775968864e-05, 'epoch': 0.49}
 49%|████▊     | 5049/10395 [14:26:28<14:33:06,  9.80s/it] 49%|████▊     | 5050/10395 [14:26:37<14:15:33,  9.60s/it]                                                          {'loss': 0.8143, 'learning_rate': 1.0944216009927697e-05, 'epoch': 0.49}
 49%|████▊     | 5050/10395 [14:26:37<14:15:33,  9.60s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 49%|████▊     | 5051/10395 [14:28:17<54:35:40, 36.78s/it]                                                          {'loss': 0.8663, 'learning_rate': 1.0941114152224058e-05, 'epoch': 0.49}
 49%|████▊     | 5051/10395 [14:28:17<54:35:40, 36.78s/it] 49%|████▊     | 5052/10395 [14:28:26<42:03:04, 28.33s/it]                                                          {'loss': 0.9542, 'learning_rate': 1.0938012203159067e-05, 'epoch': 0.49}
 49%|████▊     | 5052/10395 [14:28:26<42:03:04, 28.33s/it] 49%|████▊     | 5053/10395 [14:28:44<37:18:31, 25.14s/it]                                                          {'loss': 0.4609, 'learning_rate': 1.0934910163033856e-05, 'epoch': 0.49}
 49%|████▊     | 5053/10395 [14:28:44<37:18:31, 25.14s/it] 49%|████▊     | 5054/10395 [14:28:51<29:18:18, 19.75s/it]                                                          {'loss': 0.9061, 'learning_rate': 1.0931808032149565e-05, 'epoch': 0.49}
 49%|████▊     | 5054/10395 [14:28:51<29:18:18, 19.75s/it] 49%|████▊     | 5055/10395 [14:28:59<24:21:51, 16.43s/it]                                                          {'loss': 0.8928, 'learning_rate': 1.092870581080734e-05, 'epoch': 0.49}
 49%|████▊     | 5055/10395 [14:28:59<24:21:51, 16.43s/it] 49%|████▊     | 5056/10395 [14:29:08<20:46:21, 14.01s/it]                                                          {'loss': 0.9585, 'learning_rate': 1.0925603499308342e-05, 'epoch': 0.49}
 49%|████▊     | 5056/10395 [14:29:08<20:46:21, 14.01s/it] 49%|████▊     | 5057/10395 [14:29:17<18:39:58, 12.59s/it]                                                          {'loss': 0.9128, 'learning_rate': 1.0922501097953733e-05, 'epoch': 0.49}
 49%|████▊     | 5057/10395 [14:29:17<18:39:58, 12.59s/it] 49%|████▊     | 5058/10395 [14:29:25<16:37:58, 11.22s/it]                                                          {'loss': 0.8607, 'learning_rate': 1.0919398607044688e-05, 'epoch': 0.49}
 49%|████▊     | 5058/10395 [14:29:25<16:37:58, 11.22s/it] 49%|████▊     | 5059/10395 [14:29:32<14:45:45,  9.96s/it]                                                          {'loss': 0.9873, 'learning_rate': 1.0916296026882393e-05, 'epoch': 0.49}
 49%|████▊     | 5059/10395 [14:29:32<14:45:45,  9.96s/it] 49%|████▊     | 5060/10395 [14:29:40<13:48:50,  9.32s/it]                                                          {'loss': 0.9032, 'learning_rate': 1.0913193357768036e-05, 'epoch': 0.49}
 49%|████▊     | 5060/10395 [14:29:40<13:48:50,  9.32s/it] 49%|████▊     | 5061/10395 [14:29:48<13:23:40,  9.04s/it]                                                          {'loss': 0.8591, 'learning_rate': 1.091009060000282e-05, 'epoch': 0.49}
 49%|████▊     | 5061/10395 [14:29:48<13:23:40,  9.04s/it] 49%|████▊     | 5062/10395 [14:29:56<12:36:47,  8.51s/it]                                                          {'loss': 0.928, 'learning_rate': 1.0906987753887955e-05, 'epoch': 0.49}
 49%|████▊     | 5062/10395 [14:29:56<12:36:47,  8.51s/it] 49%|████▊     | 5063/10395 [14:30:04<12:20:37,  8.33s/it]                                                          {'loss': 0.8805, 'learning_rate': 1.0903884819724654e-05, 'epoch': 0.49}
 49%|████▊     | 5063/10395 [14:30:04<12:20:37,  8.33s/it] 49%|████▊     | 5064/10395 [14:30:11<11:56:41,  8.07s/it]                                                          {'loss': 0.9393, 'learning_rate': 1.0900781797814148e-05, 'epoch': 0.49}
 49%|████▊     | 5064/10395 [14:30:11<11:56:41,  8.07s/it] 49%|████▊     | 5065/10395 [14:30:19<11:41:09,  7.89s/it]                                                          {'loss': 0.9718, 'learning_rate': 1.0897678688457672e-05, 'epoch': 0.49}
 49%|████▊     | 5065/10395 [14:30:19<11:41:09,  7.89s/it] 49%|████▊     | 5066/10395 [14:30:26<11:36:52,  7.85s/it]                                                          {'loss': 0.9418, 'learning_rate': 1.0894575491956462e-05, 'epoch': 0.49}
 49%|████▊     | 5066/10395 [14:30:26<11:36:52,  7.85s/it] 49%|████▊     | 5067/10395 [14:30:34<11:35:38,  7.83s/it]                                                          {'loss': 0.9318, 'learning_rate': 1.089147220861178e-05, 'epoch': 0.49}
 49%|████▊     | 5067/10395 [14:30:34<11:35:38,  7.83s/it] 49%|████▉     | 5068/10395 [14:30:42<11:35:50,  7.84s/it]                                                          {'loss': 0.906, 'learning_rate': 1.0888368838724879e-05, 'epoch': 0.49}
 49%|████▉     | 5068/10395 [14:30:42<11:35:50,  7.84s/it] 49%|████▉     | 5069/10395 [14:30:49<11:22:43,  7.69s/it]                                                          {'loss': 0.9889, 'learning_rate': 1.088526538259703e-05, 'epoch': 0.49}
 49%|████▉     | 5069/10395 [14:30:49<11:22:43,  7.69s/it] 49%|████▉     | 5070/10395 [14:30:57<11:21:17,  7.68s/it]                                                          {'loss': 0.9274, 'learning_rate': 1.0882161840529508e-05, 'epoch': 0.49}
 49%|████▉     | 5070/10395 [14:30:57<11:21:17,  7.68s/it] 49%|████▉     | 5071/10395 [14:31:05<11:20:56,  7.67s/it]                                                          {'loss': 0.9462, 'learning_rate': 1.0879058212823602e-05, 'epoch': 0.49}
 49%|████▉     | 5071/10395 [14:31:05<11:20:56,  7.67s/it] 49%|████▉     | 5072/10395 [14:31:12<11:03:09,  7.47s/it]                                                          {'loss': 0.9216, 'learning_rate': 1.0875954499780601e-05, 'epoch': 0.49}
 49%|████▉     | 5072/10395 [14:31:12<11:03:09,  7.47s/it] 49%|████▉     | 5073/10395 [14:31:19<10:57:07,  7.41s/it]                                                          {'loss': 0.9086, 'learning_rate': 1.0872850701701811e-05, 'epoch': 0.49}
 49%|████▉     | 5073/10395 [14:31:19<10:57:07,  7.41s/it] 49%|████▉     | 5074/10395 [14:31:27<11:10:15,  7.56s/it]                                                          {'loss': 0.8623, 'learning_rate': 1.086974681888854e-05, 'epoch': 0.49}
 49%|████▉     | 5074/10395 [14:31:27<11:10:15,  7.56s/it] 49%|████▉     | 5075/10395 [14:31:34<11:10:11,  7.56s/it]                                                          {'loss': 0.9603, 'learning_rate': 1.0866642851642106e-05, 'epoch': 0.49}
 49%|████▉     | 5075/10395 [14:31:34<11:10:11,  7.56s/it] 49%|████▉     | 5076/10395 [14:31:52<15:34:34, 10.54s/it]                                                          {'loss': 0.4883, 'learning_rate': 1.0863538800263836e-05, 'epoch': 0.49}
 49%|████▉     | 5076/10395 [14:31:52<15:34:34, 10.54s/it] 49%|████▉     | 5077/10395 [14:32:09<18:30:16, 12.53s/it]                                                          {'loss': 0.3682, 'learning_rate': 1.0860434665055064e-05, 'epoch': 0.49}
 49%|████▉     | 5077/10395 [14:32:09<18:30:16, 12.53s/it] 49%|████▉     | 5078/10395 [14:32:17<16:23:56, 11.10s/it]                                                          {'loss': 0.9551, 'learning_rate': 1.0857330446317134e-05, 'epoch': 0.49}
 49%|████▉     | 5078/10395 [14:32:17<16:23:56, 11.10s/it] 49%|████▉     | 5079/10395 [14:32:24<14:36:36,  9.89s/it]                                                          {'loss': 1.0617, 'learning_rate': 1.0854226144351397e-05, 'epoch': 0.49}
 49%|████▉     | 5079/10395 [14:32:24<14:36:36,  9.89s/it]WARNING: tokenization mismatch: 1 vs. 1440. (ignored)
 49%|████▉     | 5080/10395 [14:32:31<13:34:05,  9.19s/it]                                                          {'loss': 0.931, 'learning_rate': 1.0851121759459213e-05, 'epoch': 0.49}
 49%|████▉     | 5080/10395 [14:32:31<13:34:05,  9.19s/it] 49%|████▉     | 5081/10395 [14:32:39<12:51:16,  8.71s/it]                                                          {'loss': 0.927, 'learning_rate': 1.0848017291941943e-05, 'epoch': 0.49}
 49%|████▉     | 5081/10395 [14:32:39<12:51:16,  8.71s/it] 49%|████▉     | 5082/10395 [14:32:56<16:30:02, 11.18s/it]                                                          {'loss': 0.3783, 'learning_rate': 1.0844912742100969e-05, 'epoch': 0.49}
 49%|████▉     | 5082/10395 [14:32:56<16:30:02, 11.18s/it] 49%|████▉     | 5083/10395 [14:33:04<15:18:40, 10.38s/it]                                                          {'loss': 0.9384, 'learning_rate': 1.084180811023767e-05, 'epoch': 0.49}
 49%|████▉     | 5083/10395 [14:33:04<15:18:40, 10.38s/it] 49%|████▉     | 5084/10395 [14:33:12<13:59:44,  9.49s/it]                                                          {'loss': 0.8631, 'learning_rate': 1.0838703396653442e-05, 'epoch': 0.49}
 49%|████▉     | 5084/10395 [14:33:12<13:59:44,  9.49s/it] 49%|████▉     | 5085/10395 [14:33:19<13:07:40,  8.90s/it]                                                          {'loss': 0.9174, 'learning_rate': 1.0835598601649677e-05, 'epoch': 0.49}
 49%|████▉     | 5085/10395 [14:33:19<13:07:40,  8.90s/it] 49%|████▉     | 5086/10395 [14:33:27<12:38:29,  8.57s/it]                                                          {'loss': 0.8749, 'learning_rate': 1.0832493725527788e-05, 'epoch': 0.49}
 49%|████▉     | 5086/10395 [14:33:27<12:38:29,  8.57s/it] 49%|████▉     | 5087/10395 [14:33:35<12:11:58,  8.27s/it]                                                          {'loss': 0.8837, 'learning_rate': 1.0829388768589186e-05, 'epoch': 0.49}
 49%|████▉     | 5087/10395 [14:33:35<12:11:58,  8.27s/it] 49%|████▉     | 5088/10395 [14:33:44<12:26:06,  8.44s/it]                                                          {'loss': 0.8714, 'learning_rate': 1.0826283731135296e-05, 'epoch': 0.49}
 49%|████▉     | 5088/10395 [14:33:44<12:26:06,  8.44s/it] 49%|████▉     | 5089/10395 [14:33:51<11:54:08,  8.08s/it]                                                          {'loss': 0.9051, 'learning_rate': 1.0823178613467544e-05, 'epoch': 0.49}
 49%|████▉     | 5089/10395 [14:33:51<11:54:08,  8.08s/it] 49%|████▉     | 5090/10395 [14:34:09<16:23:37, 11.12s/it]                                                          {'loss': 0.4002, 'learning_rate': 1.0820073415887373e-05, 'epoch': 0.49}
 49%|████▉     | 5090/10395 [14:34:09<16:23:37, 11.12s/it] 49%|████▉     | 5091/10395 [14:34:17<14:59:41, 10.18s/it]                                                          {'loss': 0.8976, 'learning_rate': 1.0816968138696232e-05, 'epoch': 0.49}
 49%|████▉     | 5091/10395 [14:34:17<14:59:41, 10.18s/it] 49%|████▉     | 5092/10395 [14:34:24<13:46:36,  9.35s/it]                                                          {'loss': 0.907, 'learning_rate': 1.0813862782195566e-05, 'epoch': 0.49}
 49%|████▉     | 5092/10395 [14:34:24<13:46:36,  9.35s/it] 49%|████▉     | 5093/10395 [14:34:40<16:43:40, 11.36s/it]                                                          {'loss': 0.3665, 'learning_rate': 1.0810757346686835e-05, 'epoch': 0.49}
 49%|████▉     | 5093/10395 [14:34:40<16:43:40, 11.36s/it] 49%|████▉     | 5094/10395 [14:34:48<15:02:07, 10.21s/it]                                                          {'loss': 0.9728, 'learning_rate': 1.080765183247152e-05, 'epoch': 0.49}
 49%|████▉     | 5094/10395 [14:34:48<15:02:07, 10.21s/it] 49%|████▉     | 5095/10395 [14:34:56<13:58:23,  9.49s/it]                                                          {'loss': 0.9305, 'learning_rate': 1.080454623985109e-05, 'epoch': 0.49}
 49%|████▉     | 5095/10395 [14:34:56<13:58:23,  9.49s/it] 49%|████▉     | 5096/10395 [14:35:04<13:21:16,  9.07s/it]                                                          {'loss': 0.9366, 'learning_rate': 1.080144056912703e-05, 'epoch': 0.49}
 49%|████▉     | 5096/10395 [14:35:04<13:21:16,  9.07s/it] 49%|████▉     | 5097/10395 [14:35:11<12:32:37,  8.52s/it]                                                          {'loss': 0.9504, 'learning_rate': 1.0798334820600831e-05, 'epoch': 0.49}
 49%|████▉     | 5097/10395 [14:35:11<12:32:37,  8.52s/it] 49%|████▉     | 5098/10395 [14:35:19<12:27:07,  8.46s/it]                                                          {'loss': 0.8337, 'learning_rate': 1.0795228994573994e-05, 'epoch': 0.49}
 49%|████▉     | 5098/10395 [14:35:19<12:27:07,  8.46s/it] 49%|████▉     | 5099/10395 [14:35:28<12:22:49,  8.42s/it]                                                          {'loss': 0.9376, 'learning_rate': 1.0792123091348028e-05, 'epoch': 0.49}
 49%|████▉     | 5099/10395 [14:35:28<12:22:49,  8.42s/it] 49%|████▉     | 5100/10395 [14:35:36<12:25:46,  8.45s/it]                                                          {'loss': 0.951, 'learning_rate': 1.0789017111224443e-05, 'epoch': 0.49}
 49%|████▉     | 5100/10395 [14:35:36<12:25:46,  8.45s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 49%|████▉     | 5101/10395 [14:37:19<53:55:05, 36.67s/it]                                                          {'loss': 0.9179, 'learning_rate': 1.0785911054504762e-05, 'epoch': 0.49}
 49%|████▉     | 5101/10395 [14:37:19<53:55:05, 36.67s/it] 49%|████▉     | 5102/10395 [14:37:36<45:19:56, 30.83s/it]                                                          {'loss': 0.3909, 'learning_rate': 1.078280492149052e-05, 'epoch': 0.49}
 49%|████▉     | 5102/10395 [14:37:36<45:19:56, 30.83s/it] 49%|████▉     | 5103/10395 [14:37:44<35:16:17, 23.99s/it]                                                          {'loss': 0.8682, 'learning_rate': 1.0779698712483245e-05, 'epoch': 0.49}
 49%|████▉     | 5103/10395 [14:37:44<35:16:17, 23.99s/it] 49%|████▉     | 5104/10395 [14:37:53<28:46:25, 19.58s/it]                                                          {'loss': 0.8867, 'learning_rate': 1.0776592427784484e-05, 'epoch': 0.49}
 49%|████▉     | 5104/10395 [14:37:53<28:46:25, 19.58s/it] 49%|████▉     | 5105/10395 [14:38:10<27:23:20, 18.64s/it]                                                          {'loss': 0.3862, 'learning_rate': 1.077348606769579e-05, 'epoch': 0.49}
 49%|████▉     | 5105/10395 [14:38:10<27:23:20, 18.64s/it] 49%|████▉     | 5106/10395 [14:38:17<22:26:25, 15.27s/it]                                                          {'loss': 0.8896, 'learning_rate': 1.0770379632518726e-05, 'epoch': 0.49}
 49%|████▉     | 5106/10395 [14:38:17<22:26:25, 15.27s/it] 49%|████▉     | 5107/10395 [14:38:26<19:37:46, 13.36s/it]                                                          {'loss': 0.9204, 'learning_rate': 1.0767273122554851e-05, 'epoch': 0.49}
 49%|████▉     | 5107/10395 [14:38:26<19:37:46, 13.36s/it] 49%|████▉     | 5108/10395 [14:38:34<17:24:33, 11.85s/it]                                                          {'loss': 0.9161, 'learning_rate': 1.0764166538105738e-05, 'epoch': 0.49}
 49%|████▉     | 5108/10395 [14:38:34<17:24:33, 11.85s/it] 49%|████▉     | 5109/10395 [14:38:51<19:39:53, 13.39s/it]                                                          {'loss': 0.3736, 'learning_rate': 1.0761059879472975e-05, 'epoch': 0.49}
 49%|████▉     | 5109/10395 [14:38:51<19:39:53, 13.39s/it] 49%|████▉     | 5110/10395 [14:38:59<17:11:51, 11.71s/it]                                                          {'loss': 0.9429, 'learning_rate': 1.0757953146958144e-05, 'epoch': 0.49}
 49%|████▉     | 5110/10395 [14:38:59<17:11:51, 11.71s/it] 49%|████▉     | 5111/10395 [14:39:06<15:13:05, 10.37s/it]                                                          {'loss': 0.8916, 'learning_rate': 1.0754846340862841e-05, 'epoch': 0.49}
 49%|████▉     | 5111/10395 [14:39:06<15:13:05, 10.37s/it] 49%|████▉     | 5112/10395 [14:39:14<13:52:45,  9.46s/it]                                                          {'loss': 0.9754, 'learning_rate': 1.0751739461488667e-05, 'epoch': 0.49}
 49%|████▉     | 5112/10395 [14:39:14<13:52:45,  9.46s/it] 49%|████▉     | 5113/10395 [14:39:21<13:03:52,  8.90s/it]                                                          {'loss': 0.9136, 'learning_rate': 1.0748632509137235e-05, 'epoch': 0.49}
 49%|████▉     | 5113/10395 [14:39:21<13:03:52,  8.90s/it] 49%|████▉     | 5114/10395 [14:39:29<12:40:44,  8.64s/it]                                                          {'loss': 0.9919, 'learning_rate': 1.0745525484110157e-05, 'epoch': 0.49}
 49%|████▉     | 5114/10395 [14:39:29<12:40:44,  8.64s/it] 49%|████▉     | 5115/10395 [14:39:37<12:08:01,  8.27s/it]                                                          {'loss': 0.9872, 'learning_rate': 1.074241838670906e-05, 'epoch': 0.49}
 49%|████▉     | 5115/10395 [14:39:37<12:08:01,  8.27s/it] 49%|████▉     | 5116/10395 [14:39:45<12:04:29,  8.23s/it]                                                          {'loss': 0.9645, 'learning_rate': 1.0739311217235568e-05, 'epoch': 0.49}
 49%|████▉     | 5116/10395 [14:39:45<12:04:29,  8.23s/it] 49%|████▉     | 5117/10395 [14:39:52<11:44:44,  8.01s/it]                                                          {'loss': 0.9139, 'learning_rate': 1.0736203975991329e-05, 'epoch': 0.49}
 49%|████▉     | 5117/10395 [14:39:52<11:44:44,  8.01s/it] 49%|████▉     | 5118/10395 [14:40:00<11:23:00,  7.77s/it]                                                          {'loss': 1.0043, 'learning_rate': 1.0733096663277977e-05, 'epoch': 0.49}
 49%|████▉     | 5118/10395 [14:40:00<11:23:00,  7.77s/it] 49%|████▉     | 5119/10395 [14:40:16<15:22:15, 10.49s/it]                                                          {'loss': 0.3586, 'learning_rate': 1.072998927939717e-05, 'epoch': 0.49}
 49%|████▉     | 5119/10395 [14:40:16<15:22:15, 10.49s/it] 49%|████▉     | 5120/10395 [14:40:24<14:05:38,  9.62s/it]                                                          {'loss': 0.8906, 'learning_rate': 1.0726881824650561e-05, 'epoch': 0.49}
 49%|████▉     | 5120/10395 [14:40:24<14:05:38,  9.62s/it] 49%|████▉     | 5121/10395 [14:40:32<13:21:32,  9.12s/it]                                                          {'loss': 0.9844, 'learning_rate': 1.0723774299339822e-05, 'epoch': 0.49}
 49%|████▉     | 5121/10395 [14:40:32<13:21:32,  9.12s/it] 49%|████▉     | 5122/10395 [14:40:40<12:43:49,  8.69s/it]                                                          {'loss': 0.9528, 'learning_rate': 1.0720666703766617e-05, 'epoch': 0.49}
 49%|████▉     | 5122/10395 [14:40:40<12:43:49,  8.69s/it] 49%|████▉     | 5123/10395 [14:40:57<16:25:57, 11.22s/it]                                                          {'loss': 0.3948, 'learning_rate': 1.071755903823263e-05, 'epoch': 0.49}
 49%|████▉     | 5123/10395 [14:40:57<16:25:57, 11.22s/it] 49%|████▉     | 5124/10395 [14:41:04<14:49:21, 10.12s/it]                                                          {'loss': 0.9414, 'learning_rate': 1.0714451303039545e-05, 'epoch': 0.49}
 49%|████▉     | 5124/10395 [14:41:04<14:49:21, 10.12s/it] 49%|████▉     | 5125/10395 [14:41:12<13:44:21,  9.39s/it]                                                          {'loss': 0.9445, 'learning_rate': 1.0711343498489055e-05, 'epoch': 0.49}
 49%|████▉     | 5125/10395 [14:41:12<13:44:21,  9.39s/it] 49%|████▉     | 5126/10395 [14:41:20<12:55:31,  8.83s/it]                                                          {'loss': 0.8701, 'learning_rate': 1.0708235624882857e-05, 'epoch': 0.49}
 49%|████▉     | 5126/10395 [14:41:20<12:55:31,  8.83s/it] 49%|████▉     | 5127/10395 [14:41:27<12:16:59,  8.39s/it]                                                          {'loss': 0.9354, 'learning_rate': 1.0705127682522658e-05, 'epoch': 0.49}
 49%|████▉     | 5127/10395 [14:41:27<12:16:59,  8.39s/it] 49%|████▉     | 5128/10395 [14:41:36<12:34:21,  8.59s/it]                                                          {'loss': 0.7933, 'learning_rate': 1.070201967171017e-05, 'epoch': 0.49}
 49%|████▉     | 5128/10395 [14:41:37<12:34:21,  8.59s/it] 49%|████▉     | 5129/10395 [14:41:44<12:28:39,  8.53s/it]                                                          {'loss': 0.8472, 'learning_rate': 1.0698911592747114e-05, 'epoch': 0.49}
 49%|████▉     | 5129/10395 [14:41:44<12:28:39,  8.53s/it] 49%|████▉     | 5130/10395 [14:41:52<11:54:14,  8.14s/it]                                                          {'loss': 0.9143, 'learning_rate': 1.0695803445935213e-05, 'epoch': 0.49}
 49%|████▉     | 5130/10395 [14:41:52<11:54:14,  8.14s/it] 49%|████▉     | 5131/10395 [14:42:00<12:03:57,  8.25s/it]                                                          {'loss': 0.8916, 'learning_rate': 1.0692695231576202e-05, 'epoch': 0.49}
 49%|████▉     | 5131/10395 [14:42:00<12:03:57,  8.25s/it] 49%|████▉     | 5132/10395 [14:42:08<12:03:54,  8.25s/it]                                                          {'loss': 0.912, 'learning_rate': 1.0689586949971818e-05, 'epoch': 0.49}
 49%|████▉     | 5132/10395 [14:42:08<12:03:54,  8.25s/it] 49%|████▉     | 5133/10395 [14:42:16<11:54:18,  8.14s/it]                                                          {'loss': 0.8501, 'learning_rate': 1.0686478601423804e-05, 'epoch': 0.49}
 49%|████▉     | 5133/10395 [14:42:16<11:54:18,  8.14s/it] 49%|████▉     | 5134/10395 [14:42:24<11:47:16,  8.07s/it]                                                          {'loss': 0.8604, 'learning_rate': 1.0683370186233917e-05, 'epoch': 0.49}
 49%|████▉     | 5134/10395 [14:42:24<11:47:16,  8.07s/it] 49%|████▉     | 5135/10395 [14:42:32<11:48:32,  8.08s/it]                                                          {'loss': 0.8599, 'learning_rate': 1.068026170470391e-05, 'epoch': 0.49}
 49%|████▉     | 5135/10395 [14:42:32<11:48:32,  8.08s/it] 49%|████▉     | 5136/10395 [14:42:49<15:39:54, 10.72s/it]                                                          {'loss': 0.36, 'learning_rate': 1.0677153157135553e-05, 'epoch': 0.49}
 49%|████▉     | 5136/10395 [14:42:49<15:39:54, 10.72s/it] 49%|████▉     | 5137/10395 [14:42:56<14:08:25,  9.68s/it]                                                          {'loss': 0.8597, 'learning_rate': 1.0674044543830616e-05, 'epoch': 0.49}
 49%|████▉     | 5137/10395 [14:42:56<14:08:25,  9.68s/it] 49%|████▉     | 5138/10395 [14:43:06<14:05:34,  9.65s/it]                                                          {'loss': 0.8616, 'learning_rate': 1.067093586509087e-05, 'epoch': 0.49}
 49%|████▉     | 5138/10395 [14:43:06<14:05:34,  9.65s/it] 49%|████▉     | 5139/10395 [14:43:14<13:16:26,  9.09s/it]                                                          {'loss': 0.8317, 'learning_rate': 1.0667827121218108e-05, 'epoch': 0.49}
 49%|████▉     | 5139/10395 [14:43:14<13:16:26,  9.09s/it] 49%|████▉     | 5140/10395 [14:43:22<12:48:44,  8.78s/it]                                                          {'loss': 0.9564, 'learning_rate': 1.0664718312514114e-05, 'epoch': 0.49}
 49%|████▉     | 5140/10395 [14:43:22<12:48:44,  8.78s/it] 49%|████▉     | 5141/10395 [14:43:29<12:12:00,  8.36s/it]                                                          {'loss': 0.9758, 'learning_rate': 1.066160943928069e-05, 'epoch': 0.49}
 49%|████▉     | 5141/10395 [14:43:29<12:12:00,  8.36s/it] 49%|████▉     | 5142/10395 [14:43:37<12:01:48,  8.24s/it]                                                          {'loss': 0.9647, 'learning_rate': 1.0658500501819633e-05, 'epoch': 0.49}
 49%|████▉     | 5142/10395 [14:43:37<12:01:48,  8.24s/it] 49%|████▉     | 5143/10395 [14:43:55<16:21:12, 11.21s/it]                                                          {'loss': 0.4211, 'learning_rate': 1.0655391500432754e-05, 'epoch': 0.49}
 49%|████▉     | 5143/10395 [14:43:55<16:21:12, 11.21s/it] 49%|████▉     | 5144/10395 [14:44:03<14:55:31, 10.23s/it]                                                          {'loss': 0.9687, 'learning_rate': 1.065228243542187e-05, 'epoch': 0.49}
 49%|████▉     | 5144/10395 [14:44:03<14:55:31, 10.23s/it] 49%|████▉     | 5145/10395 [14:44:11<13:52:37,  9.52s/it]                                                          {'loss': 0.8845, 'learning_rate': 1.06491733070888e-05, 'epoch': 0.49}
 49%|████▉     | 5145/10395 [14:44:11<13:52:37,  9.52s/it] 50%|████▉     | 5146/10395 [14:44:19<13:03:56,  8.96s/it]                                                          {'loss': 0.9949, 'learning_rate': 1.0646064115735373e-05, 'epoch': 0.5}
 50%|████▉     | 5146/10395 [14:44:19<13:03:56,  8.96s/it] 50%|████▉     | 5147/10395 [14:44:26<12:19:24,  8.45s/it]                                                          {'loss': 0.9412, 'learning_rate': 1.0642954861663424e-05, 'epoch': 0.5}
 50%|████▉     | 5147/10395 [14:44:26<12:19:24,  8.45s/it] 50%|████▉     | 5148/10395 [14:44:34<11:56:58,  8.20s/it]                                                          {'loss': 0.8909, 'learning_rate': 1.063984554517479e-05, 'epoch': 0.5}
 50%|████▉     | 5148/10395 [14:44:34<11:56:58,  8.20s/it] 50%|████▉     | 5149/10395 [14:44:42<11:55:56,  8.19s/it]                                                          {'loss': 0.851, 'learning_rate': 1.0636736166571316e-05, 'epoch': 0.5}
 50%|████▉     | 5149/10395 [14:44:42<11:55:56,  8.19s/it] 50%|████▉     | 5150/10395 [14:44:49<11:30:41,  7.90s/it]                                                          {'loss': 0.9184, 'learning_rate': 1.0633626726154858e-05, 'epoch': 0.5}
 50%|████▉     | 5150/10395 [14:44:49<11:30:41,  7.90s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|████▉     | 5151/10395 [14:46:24<49:28:42, 33.97s/it]                                                          {'loss': 0.9121, 'learning_rate': 1.063051722422727e-05, 'epoch': 0.5}
 50%|████▉     | 5151/10395 [14:46:24<49:28:42, 33.97s/it] 50%|████▉     | 5152/10395 [14:46:31<37:57:33, 26.06s/it]                                                          {'loss': 0.8797, 'learning_rate': 1.0627407661090418e-05, 'epoch': 0.5}
 50%|████▉     | 5152/10395 [14:46:31<37:57:33, 26.06s/it] 50%|████▉     | 5153/10395 [14:46:39<30:00:48, 20.61s/it]                                                          {'loss': 0.8439, 'learning_rate': 1.062429803704617e-05, 'epoch': 0.5}
 50%|████▉     | 5153/10395 [14:46:39<30:00:48, 20.61s/it] 50%|████▉     | 5154/10395 [14:46:47<24:24:08, 16.76s/it]                                                          {'loss': 0.9316, 'learning_rate': 1.0621188352396406e-05, 'epoch': 0.5}
 50%|████▉     | 5154/10395 [14:46:47<24:24:08, 16.76s/it] 50%|████▉     | 5155/10395 [14:46:55<20:24:04, 14.02s/it]                                                          {'loss': 0.8345, 'learning_rate': 1.0618078607443e-05, 'epoch': 0.5}
 50%|████▉     | 5155/10395 [14:46:55<20:24:04, 14.02s/it] 50%|████▉     | 5156/10395 [14:47:03<17:42:36, 12.17s/it]                                                          {'loss': 0.8955, 'learning_rate': 1.0614968802487845e-05, 'epoch': 0.5}
 50%|████▉     | 5156/10395 [14:47:03<17:42:36, 12.17s/it] 50%|████▉     | 5157/10395 [14:47:10<15:49:12, 10.87s/it]                                                          {'loss': 0.9094, 'learning_rate': 1.0611858937832835e-05, 'epoch': 0.5}
 50%|████▉     | 5157/10395 [14:47:10<15:49:12, 10.87s/it] 50%|████▉     | 5158/10395 [14:47:19<14:37:58, 10.06s/it]                                                          {'loss': 0.9034, 'learning_rate': 1.0608749013779864e-05, 'epoch': 0.5}
 50%|████▉     | 5158/10395 [14:47:19<14:37:58, 10.06s/it] 50%|████▉     | 5159/10395 [14:47:36<17:58:44, 12.36s/it]                                                          {'loss': 0.3408, 'learning_rate': 1.0605639030630841e-05, 'epoch': 0.5}
 50%|████▉     | 5159/10395 [14:47:36<17:58:44, 12.36s/it] 50%|████▉     | 5160/10395 [14:47:44<15:55:34, 10.95s/it]                                                          {'loss': 1.0185, 'learning_rate': 1.0602528988687675e-05, 'epoch': 0.5}
 50%|████▉     | 5160/10395 [14:47:44<15:55:34, 10.95s/it] 50%|████▉     | 5161/10395 [14:47:51<14:22:12,  9.88s/it]                                                          {'loss': 0.9031, 'learning_rate': 1.0599418888252284e-05, 'epoch': 0.5}
 50%|████▉     | 5161/10395 [14:47:51<14:22:12,  9.88s/it] 50%|████▉     | 5162/10395 [14:48:02<14:31:14,  9.99s/it]                                                          {'loss': 0.9534, 'learning_rate': 1.0596308729626585e-05, 'epoch': 0.5}
 50%|████▉     | 5162/10395 [14:48:02<14:31:14,  9.99s/it] 50%|████▉     | 5163/10395 [14:48:10<13:39:30,  9.40s/it]                                                          {'loss': 0.8936, 'learning_rate': 1.059319851311251e-05, 'epoch': 0.5}
 50%|████▉     | 5163/10395 [14:48:10<13:39:30,  9.40s/it] 50%|████▉     | 5164/10395 [14:48:17<12:45:40,  8.78s/it]                                                          {'loss': 0.9382, 'learning_rate': 1.0590088239011994e-05, 'epoch': 0.5}
 50%|████▉     | 5164/10395 [14:48:17<12:45:40,  8.78s/it] 50%|████▉     | 5165/10395 [14:48:26<12:48:06,  8.81s/it]                                                          {'loss': 0.8515, 'learning_rate': 1.058697790762697e-05, 'epoch': 0.5}
 50%|████▉     | 5165/10395 [14:48:26<12:48:06,  8.81s/it] 50%|████▉     | 5166/10395 [14:48:33<12:03:01,  8.30s/it]                                                          {'loss': 0.9199, 'learning_rate': 1.0583867519259383e-05, 'epoch': 0.5}
 50%|████▉     | 5166/10395 [14:48:33<12:03:01,  8.30s/it] 50%|████▉     | 5167/10395 [14:48:41<12:07:22,  8.35s/it]                                                          {'loss': 0.8541, 'learning_rate': 1.0580757074211187e-05, 'epoch': 0.5}
 50%|████▉     | 5167/10395 [14:48:41<12:07:22,  8.35s/it] 50%|████▉     | 5168/10395 [14:48:49<11:47:50,  8.13s/it]                                                          {'loss': 0.9096, 'learning_rate': 1.0577646572784339e-05, 'epoch': 0.5}
 50%|████▉     | 5168/10395 [14:48:49<11:47:50,  8.13s/it] 50%|████▉     | 5169/10395 [14:48:57<11:39:22,  8.03s/it]                                                          {'loss': 0.8868, 'learning_rate': 1.057453601528079e-05, 'epoch': 0.5}
 50%|████▉     | 5169/10395 [14:48:57<11:39:22,  8.03s/it] 50%|████▉     | 5170/10395 [14:49:07<12:32:56,  8.65s/it]                                                          {'loss': 0.9832, 'learning_rate': 1.0571425402002515e-05, 'epoch': 0.5}
 50%|████▉     | 5170/10395 [14:49:07<12:32:56,  8.65s/it] 50%|████▉     | 5171/10395 [14:49:15<12:20:00,  8.50s/it]                                                          {'loss': 0.9032, 'learning_rate': 1.0568314733251484e-05, 'epoch': 0.5}
 50%|████▉     | 5171/10395 [14:49:15<12:20:00,  8.50s/it] 50%|████▉     | 5172/10395 [14:49:22<11:48:42,  8.14s/it]                                                          {'loss': 0.9735, 'learning_rate': 1.0565204009329674e-05, 'epoch': 0.5}
 50%|████▉     | 5172/10395 [14:49:22<11:48:42,  8.14s/it] 50%|████▉     | 5173/10395 [14:49:30<11:38:16,  8.02s/it]                                                          {'loss': 0.8806, 'learning_rate': 1.0562093230539064e-05, 'epoch': 0.5}
 50%|████▉     | 5173/10395 [14:49:30<11:38:16,  8.02s/it] 50%|████▉     | 5174/10395 [14:49:48<15:41:37, 10.82s/it]                                                          {'loss': 0.3741, 'learning_rate': 1.0558982397181646e-05, 'epoch': 0.5}
 50%|████▉     | 5174/10395 [14:49:48<15:41:37, 10.82s/it] 50%|████▉     | 5175/10395 [14:49:55<14:06:22,  9.73s/it]                                                          {'loss': 0.9578, 'learning_rate': 1.055587150955941e-05, 'epoch': 0.5}
 50%|████▉     | 5175/10395 [14:49:55<14:06:22,  9.73s/it] 50%|████▉     | 5176/10395 [14:50:02<13:03:27,  9.01s/it]                                                          {'loss': 0.9527, 'learning_rate': 1.0552760567974359e-05, 'epoch': 0.5}
 50%|████▉     | 5176/10395 [14:50:02<13:03:27,  9.01s/it] 50%|████▉     | 5177/10395 [14:50:10<12:26:30,  8.58s/it]                                                          {'loss': 0.9413, 'learning_rate': 1.0549649572728489e-05, 'epoch': 0.5}
 50%|████▉     | 5177/10395 [14:50:10<12:26:30,  8.58s/it] 50%|████▉     | 5178/10395 [14:50:18<12:32:37,  8.66s/it]                                                          {'loss': 0.9434, 'learning_rate': 1.0546538524123815e-05, 'epoch': 0.5}
 50%|████▉     | 5178/10395 [14:50:18<12:32:37,  8.66s/it] 50%|████▉     | 5179/10395 [14:50:26<12:12:46,  8.43s/it]                                                          {'loss': 0.9711, 'learning_rate': 1.0543427422462352e-05, 'epoch': 0.5}
 50%|████▉     | 5179/10395 [14:50:26<12:12:46,  8.43s/it] 50%|████▉     | 5180/10395 [14:50:34<11:57:14,  8.25s/it]                                                          {'loss': 0.9037, 'learning_rate': 1.0540316268046114e-05, 'epoch': 0.5}
 50%|████▉     | 5180/10395 [14:50:34<11:57:14,  8.25s/it] 50%|████▉     | 5181/10395 [14:50:42<11:35:38,  8.01s/it]                                                          {'loss': 0.9716, 'learning_rate': 1.0537205061177122e-05, 'epoch': 0.5}
 50%|████▉     | 5181/10395 [14:50:42<11:35:38,  8.01s/it] 50%|████▉     | 5182/10395 [14:50:50<11:38:00,  8.03s/it]                                                          {'loss': 0.9194, 'learning_rate': 1.0534093802157417e-05, 'epoch': 0.5}
 50%|████▉     | 5182/10395 [14:50:50<11:38:00,  8.03s/it] 50%|████▉     | 5183/10395 [14:50:58<11:53:25,  8.21s/it]                                                          {'loss': 0.9318, 'learning_rate': 1.0530982491289029e-05, 'epoch': 0.5}
 50%|████▉     | 5183/10395 [14:50:58<11:53:25,  8.21s/it] 50%|████▉     | 5184/10395 [14:51:06<11:42:05,  8.08s/it]                                                          {'loss': 0.8868, 'learning_rate': 1.052787112887399e-05, 'epoch': 0.5}
 50%|████▉     | 5184/10395 [14:51:06<11:42:05,  8.08s/it] 50%|████▉     | 5185/10395 [14:51:15<11:51:07,  8.19s/it]                                                          {'loss': 0.9476, 'learning_rate': 1.052475971521435e-05, 'epoch': 0.5}
 50%|████▉     | 5185/10395 [14:51:15<11:51:07,  8.19s/it] 50%|████▉     | 5186/10395 [14:51:22<11:41:41,  8.08s/it]                                                          {'loss': 0.8746, 'learning_rate': 1.052164825061216e-05, 'epoch': 0.5}
 50%|████▉     | 5186/10395 [14:51:22<11:41:41,  8.08s/it] 50%|████▉     | 5187/10395 [14:51:31<11:42:16,  8.09s/it]                                                          {'loss': 0.9053, 'learning_rate': 1.0518536735369476e-05, 'epoch': 0.5}
 50%|████▉     | 5187/10395 [14:51:31<11:42:16,  8.09s/it] 50%|████▉     | 5188/10395 [14:51:38<11:30:22,  7.96s/it]                                                          {'loss': 0.9379, 'learning_rate': 1.051542516978835e-05, 'epoch': 0.5}
 50%|████▉     | 5188/10395 [14:51:38<11:30:22,  7.96s/it] 50%|████▉     | 5189/10395 [14:51:46<11:17:28,  7.81s/it]                                                          {'loss': 0.9604, 'learning_rate': 1.0512313554170848e-05, 'epoch': 0.5}
 50%|████▉     | 5189/10395 [14:51:46<11:17:28,  7.81s/it] 50%|████▉     | 5190/10395 [14:51:53<11:07:48,  7.70s/it]                                                          {'loss': 0.9103, 'learning_rate': 1.0509201888819045e-05, 'epoch': 0.5}
 50%|████▉     | 5190/10395 [14:51:53<11:07:48,  7.70s/it] 50%|████▉     | 5191/10395 [14:52:00<10:55:48,  7.56s/it]                                                          {'loss': 0.8433, 'learning_rate': 1.0506090174035008e-05, 'epoch': 0.5}
 50%|████▉     | 5191/10395 [14:52:00<10:55:48,  7.56s/it] 50%|████▉     | 5192/10395 [14:52:09<11:18:19,  7.82s/it]                                                          {'loss': 0.902, 'learning_rate': 1.0502978410120821e-05, 'epoch': 0.5}
 50%|████▉     | 5192/10395 [14:52:09<11:18:19,  7.82s/it] 50%|████▉     | 5193/10395 [14:52:16<11:09:07,  7.72s/it]                                                          {'loss': 0.9171, 'learning_rate': 1.0499866597378561e-05, 'epoch': 0.5}
 50%|████▉     | 5193/10395 [14:52:16<11:09:07,  7.72s/it] 50%|████▉     | 5194/10395 [14:52:24<11:03:31,  7.65s/it]                                                          {'loss': 0.9953, 'learning_rate': 1.0496754736110324e-05, 'epoch': 0.5}
 50%|████▉     | 5194/10395 [14:52:24<11:03:31,  7.65s/it] 50%|████▉     | 5195/10395 [14:52:32<11:22:42,  7.88s/it]                                                          {'loss': 1.0055, 'learning_rate': 1.0493642826618198e-05, 'epoch': 0.5}
 50%|████▉     | 5195/10395 [14:52:32<11:22:42,  7.88s/it] 50%|████▉     | 5196/10395 [14:52:40<11:31:36,  7.98s/it]                                                          {'loss': 0.8347, 'learning_rate': 1.0490530869204281e-05, 'epoch': 0.5}
 50%|████▉     | 5196/10395 [14:52:40<11:31:36,  7.98s/it] 50%|████▉     | 5197/10395 [14:52:49<11:49:06,  8.19s/it]                                                          {'loss': 0.879, 'learning_rate': 1.0487418864170672e-05, 'epoch': 0.5}
 50%|████▉     | 5197/10395 [14:52:49<11:49:06,  8.19s/it] 50%|█████     | 5198/10395 [14:52:57<11:45:53,  8.15s/it]                                                          {'loss': 0.8685, 'learning_rate': 1.0484306811819487e-05, 'epoch': 0.5}
 50%|█████     | 5198/10395 [14:52:57<11:45:53,  8.15s/it] 50%|█████     | 5199/10395 [14:53:05<11:36:39,  8.04s/it]                                                          {'loss': 0.8841, 'learning_rate': 1.048119471245283e-05, 'epoch': 0.5}
 50%|█████     | 5199/10395 [14:53:05<11:36:39,  8.04s/it] 50%|█████     | 5200/10395 [14:53:12<11:23:39,  7.90s/it]                                                          {'loss': 0.914, 'learning_rate': 1.0478082566372817e-05, 'epoch': 0.5}
 50%|█████     | 5200/10395 [14:53:12<11:23:39,  7.90s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|█████     | 5201/10395 [14:54:54<51:58:18, 36.02s/it]                                                          {'loss': 0.9244, 'learning_rate': 1.0474970373881568e-05, 'epoch': 0.5}
 50%|█████     | 5201/10395 [14:54:54<51:58:18, 36.02s/it] 50%|█████     | 5202/10395 [14:55:03<40:08:29, 27.83s/it]                                                          {'loss': 0.9379, 'learning_rate': 1.0471858135281215e-05, 'epoch': 0.5}
 50%|█████     | 5202/10395 [14:55:03<40:08:29, 27.83s/it] 50%|█████     | 5203/10395 [14:55:10<31:11:34, 21.63s/it]                                                          {'loss': 0.9969, 'learning_rate': 1.046874585087388e-05, 'epoch': 0.5}
 50%|█████     | 5203/10395 [14:55:10<31:11:34, 21.63s/it] 50%|█████     | 5204/10395 [14:55:18<25:16:53, 17.53s/it]                                                          {'loss': 0.9524, 'learning_rate': 1.0465633520961697e-05, 'epoch': 0.5}
 50%|█████     | 5204/10395 [14:55:18<25:16:53, 17.53s/it] 50%|█████     | 5205/10395 [14:55:25<20:53:40, 14.49s/it]                                                          {'loss': 0.9497, 'learning_rate': 1.0462521145846811e-05, 'epoch': 0.5}
 50%|█████     | 5205/10395 [14:55:25<20:53:40, 14.49s/it] 50%|█████     | 5206/10395 [14:55:33<17:54:35, 12.43s/it]                                                          {'loss': 0.8902, 'learning_rate': 1.045940872583136e-05, 'epoch': 0.5}
 50%|█████     | 5206/10395 [14:55:33<17:54:35, 12.43s/it] 50%|█████     | 5207/10395 [14:55:41<16:07:20, 11.19s/it]                                                          {'loss': 0.8572, 'learning_rate': 1.0456296261217491e-05, 'epoch': 0.5}
 50%|█████     | 5207/10395 [14:55:41<16:07:20, 11.19s/it] 50%|█████     | 5208/10395 [14:55:50<14:59:24, 10.40s/it]                                                          {'loss': 0.8898, 'learning_rate': 1.0453183752307354e-05, 'epoch': 0.5}
 50%|█████     | 5208/10395 [14:55:50<14:59:24, 10.40s/it] 50%|█████     | 5209/10395 [14:55:58<13:59:33,  9.71s/it]                                                          {'loss': 0.8962, 'learning_rate': 1.0450071199403112e-05, 'epoch': 0.5}
 50%|█████     | 5209/10395 [14:55:58<13:59:33,  9.71s/it] 50%|█████     | 5210/10395 [14:56:06<13:09:02,  9.13s/it]                                                          {'loss': 0.8452, 'learning_rate': 1.0446958602806916e-05, 'epoch': 0.5}
 50%|█████     | 5210/10395 [14:56:06<13:09:02,  9.13s/it] 50%|█████     | 5211/10395 [14:56:13<12:30:59,  8.69s/it]                                                          {'loss': 0.8958, 'learning_rate': 1.0443845962820936e-05, 'epoch': 0.5}
 50%|█████     | 5211/10395 [14:56:13<12:30:59,  8.69s/it] 50%|█████     | 5212/10395 [14:56:22<12:22:41,  8.60s/it]                                                          {'loss': 0.957, 'learning_rate': 1.0440733279747332e-05, 'epoch': 0.5}
 50%|█████     | 5212/10395 [14:56:22<12:22:41,  8.60s/it] 50%|█████     | 5213/10395 [14:56:29<11:51:44,  8.24s/it]                                                          {'loss': 0.9176, 'learning_rate': 1.0437620553888293e-05, 'epoch': 0.5}
 50%|█████     | 5213/10395 [14:56:29<11:51:44,  8.24s/it] 50%|█████     | 5214/10395 [14:56:39<12:24:13,  8.62s/it]                                                          {'loss': 0.9221, 'learning_rate': 1.043450778554598e-05, 'epoch': 0.5}
 50%|█████     | 5214/10395 [14:56:39<12:24:13,  8.62s/it] 50%|█████     | 5215/10395 [14:56:46<11:58:10,  8.32s/it]                                                          {'loss': 0.9214, 'learning_rate': 1.043139497502258e-05, 'epoch': 0.5}
 50%|█████     | 5215/10395 [14:56:46<11:58:10,  8.32s/it] 50%|█████     | 5216/10395 [14:56:55<12:15:10,  8.52s/it]                                                          {'loss': 0.773, 'learning_rate': 1.042828212262028e-05, 'epoch': 0.5}
 50%|█████     | 5216/10395 [14:56:55<12:15:10,  8.52s/it] 50%|█████     | 5217/10395 [14:57:13<16:08:28, 11.22s/it]                                                          {'loss': 0.4092, 'learning_rate': 1.0425169228641264e-05, 'epoch': 0.5}
 50%|█████     | 5217/10395 [14:57:13<16:08:28, 11.22s/it] 50%|█████     | 5218/10395 [14:57:22<15:14:20, 10.60s/it]                                                          {'loss': 0.8643, 'learning_rate': 1.0422056293387728e-05, 'epoch': 0.5}
 50%|█████     | 5218/10395 [14:57:22<15:14:20, 10.60s/it] 50%|█████     | 5219/10395 [14:57:29<13:49:03,  9.61s/it]                                                          {'loss': 0.8612, 'learning_rate': 1.0418943317161872e-05, 'epoch': 0.5}
 50%|█████     | 5219/10395 [14:57:29<13:49:03,  9.61s/it] 50%|█████     | 5220/10395 [14:57:37<12:59:30,  9.04s/it]                                                          {'loss': 0.9027, 'learning_rate': 1.041583030026589e-05, 'epoch': 0.5}
 50%|█████     | 5220/10395 [14:57:37<12:59:30,  9.04s/it] 50%|█████     | 5221/10395 [14:57:44<12:14:27,  8.52s/it]                                                          {'loss': 0.9145, 'learning_rate': 1.0412717243001993e-05, 'epoch': 0.5}
 50%|█████     | 5221/10395 [14:57:44<12:14:27,  8.52s/it] 50%|█████     | 5222/10395 [14:57:52<11:56:35,  8.31s/it]                                                          {'loss': 0.834, 'learning_rate': 1.040960414567239e-05, 'epoch': 0.5}
 50%|█████     | 5222/10395 [14:57:52<11:56:35,  8.31s/it] 50%|█████     | 5223/10395 [14:57:59<11:28:40,  7.99s/it]                                                          {'loss': 1.0068, 'learning_rate': 1.040649100857929e-05, 'epoch': 0.5}
 50%|█████     | 5223/10395 [14:57:59<11:28:40,  7.99s/it] 50%|█████     | 5224/10395 [14:58:07<11:10:36,  7.78s/it]                                                          {'loss': 0.9463, 'learning_rate': 1.040337783202491e-05, 'epoch': 0.5}
 50%|█████     | 5224/10395 [14:58:07<11:10:36,  7.78s/it] 50%|█████     | 5225/10395 [14:58:15<11:14:51,  7.83s/it]                                                          {'loss': 0.9021, 'learning_rate': 1.0400264616311473e-05, 'epoch': 0.5}
 50%|█████     | 5225/10395 [14:58:15<11:14:51,  7.83s/it] 50%|█████     | 5226/10395 [14:58:23<11:41:19,  8.14s/it]                                                          {'loss': 0.9373, 'learning_rate': 1.0397151361741204e-05, 'epoch': 0.5}
 50%|█████     | 5226/10395 [14:58:23<11:41:19,  8.14s/it] 50%|█████     | 5227/10395 [14:58:31<11:35:11,  8.07s/it]                                                          {'loss': 0.9131, 'learning_rate': 1.0394038068616328e-05, 'epoch': 0.5}
 50%|█████     | 5227/10395 [14:58:31<11:35:11,  8.07s/it] 50%|█████     | 5228/10395 [14:58:39<11:35:39,  8.08s/it]                                                          {'loss': 0.8589, 'learning_rate': 1.039092473723908e-05, 'epoch': 0.5}
 50%|█████     | 5228/10395 [14:58:39<11:35:39,  8.08s/it] 50%|█████     | 5229/10395 [14:58:47<11:17:36,  7.87s/it]                                                          {'loss': 0.8948, 'learning_rate': 1.0387811367911694e-05, 'epoch': 0.5}
 50%|█████     | 5229/10395 [14:58:47<11:17:36,  7.87s/it] 50%|█████     | 5230/10395 [14:58:54<11:02:10,  7.69s/it]                                                          {'loss': 1.0033, 'learning_rate': 1.0384697960936408e-05, 'epoch': 0.5}
 50%|█████     | 5230/10395 [14:58:54<11:02:10,  7.69s/it] 50%|█████     | 5231/10395 [14:59:02<11:11:54,  7.81s/it]                                                          {'loss': 0.896, 'learning_rate': 1.0381584516615464e-05, 'epoch': 0.5}
 50%|█████     | 5231/10395 [14:59:02<11:11:54,  7.81s/it] 50%|█████     | 5232/10395 [14:59:10<11:16:39,  7.86s/it]                                                          {'loss': 0.9146, 'learning_rate': 1.0378471035251112e-05, 'epoch': 0.5}
 50%|█████     | 5232/10395 [14:59:10<11:16:39,  7.86s/it] 50%|█████     | 5233/10395 [14:59:19<11:49:14,  8.24s/it]                                                          {'loss': 0.965, 'learning_rate': 1.0375357517145603e-05, 'epoch': 0.5}
 50%|█████     | 5233/10395 [14:59:19<11:49:14,  8.24s/it] 50%|█████     | 5234/10395 [14:59:27<11:33:34,  8.06s/it]                                                          {'loss': 0.9049, 'learning_rate': 1.0372243962601185e-05, 'epoch': 0.5}
 50%|█████     | 5234/10395 [14:59:27<11:33:34,  8.06s/it] 50%|█████     | 5235/10395 [14:59:36<11:59:14,  8.36s/it]                                                          {'loss': 0.8352, 'learning_rate': 1.0369130371920121e-05, 'epoch': 0.5}
 50%|█████     | 5235/10395 [14:59:36<11:59:14,  8.36s/it] 50%|█████     | 5236/10395 [14:59:45<12:19:45,  8.60s/it]                                                          {'loss': 0.902, 'learning_rate': 1.036601674540467e-05, 'epoch': 0.5}
 50%|█████     | 5236/10395 [14:59:45<12:19:45,  8.60s/it] 50%|█████     | 5237/10395 [14:59:53<11:55:02,  8.32s/it]                                                          {'loss': 0.9434, 'learning_rate': 1.0362903083357092e-05, 'epoch': 0.5}
 50%|█████     | 5237/10395 [14:59:53<11:55:02,  8.32s/it] 50%|█████     | 5238/10395 [15:00:00<11:37:21,  8.11s/it]                                                          {'loss': 0.8819, 'learning_rate': 1.0359789386079662e-05, 'epoch': 0.5}
 50%|█████     | 5238/10395 [15:00:00<11:37:21,  8.11s/it] 50%|█████     | 5239/10395 [15:00:09<11:42:41,  8.18s/it]                                                          {'loss': 0.9085, 'learning_rate': 1.0356675653874646e-05, 'epoch': 0.5}
 50%|█████     | 5239/10395 [15:00:09<11:42:41,  8.18s/it] 50%|█████     | 5240/10395 [15:00:17<11:33:25,  8.07s/it]                                                          {'loss': 1.026, 'learning_rate': 1.0353561887044319e-05, 'epoch': 0.5}
 50%|█████     | 5240/10395 [15:00:17<11:33:25,  8.07s/it] 50%|█████     | 5241/10395 [15:00:26<12:16:39,  8.58s/it]                                                          {'loss': 0.8214, 'learning_rate': 1.0350448085890958e-05, 'epoch': 0.5}
 50%|█████     | 5241/10395 [15:00:26<12:16:39,  8.58s/it] 50%|█████     | 5242/10395 [15:00:35<12:19:45,  8.61s/it]                                                          {'loss': 0.8475, 'learning_rate': 1.034733425071685e-05, 'epoch': 0.5}
 50%|█████     | 5242/10395 [15:00:35<12:19:45,  8.61s/it] 50%|█████     | 5243/10395 [15:00:42<11:42:38,  8.18s/it]                                                          {'loss': 0.9287, 'learning_rate': 1.0344220381824273e-05, 'epoch': 0.5}
 50%|█████     | 5243/10395 [15:00:42<11:42:38,  8.18s/it] 50%|█████     | 5244/10395 [15:00:50<11:24:28,  7.97s/it]                                                          {'loss': 0.919, 'learning_rate': 1.0341106479515517e-05, 'epoch': 0.5}
 50%|█████     | 5244/10395 [15:00:50<11:24:28,  7.97s/it] 50%|█████     | 5245/10395 [15:00:57<11:12:51,  7.84s/it]                                                          {'loss': 1.0015, 'learning_rate': 1.0337992544092872e-05, 'epoch': 0.5}
 50%|█████     | 5245/10395 [15:00:57<11:12:51,  7.84s/it] 50%|█████     | 5246/10395 [15:01:15<15:36:39, 10.91s/it]                                                          {'loss': 0.3882, 'learning_rate': 1.0334878575858634e-05, 'epoch': 0.5}
 50%|█████     | 5246/10395 [15:01:15<15:36:39, 10.91s/it] 50%|█████     | 5247/10395 [15:01:23<14:11:00,  9.92s/it]                                                          {'loss': 0.8908, 'learning_rate': 1.03317645751151e-05, 'epoch': 0.5}
 50%|█████     | 5247/10395 [15:01:23<14:11:00,  9.92s/it] 50%|█████     | 5248/10395 [15:01:40<17:14:05, 12.05s/it]                                                          {'loss': 0.4091, 'learning_rate': 1.032865054216457e-05, 'epoch': 0.5}
 50%|█████     | 5248/10395 [15:01:40<17:14:05, 12.05s/it] 50%|█████     | 5249/10395 [15:01:49<15:44:53, 11.02s/it]                                                          {'loss': 0.8557, 'learning_rate': 1.0325536477309349e-05, 'epoch': 0.5}
 50%|█████     | 5249/10395 [15:01:49<15:44:53, 11.02s/it] 51%|█████     | 5250/10395 [15:01:58<14:57:50, 10.47s/it]                                                          {'loss': 0.8687, 'learning_rate': 1.0322422380851737e-05, 'epoch': 0.51}
 51%|█████     | 5250/10395 [15:01:58<14:57:50, 10.47s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 51%|█████     | 5251/10395 [15:03:46<56:48:23, 39.76s/it]                                                          {'loss': 0.3672, 'learning_rate': 1.0319308253094054e-05, 'epoch': 0.51}
 51%|█████     | 5251/10395 [15:03:46<56:48:23, 39.76s/it] 51%|█████     | 5252/10395 [15:03:54<43:06:56, 30.18s/it]                                                          {'loss': 1.0162, 'learning_rate': 1.0316194094338604e-05, 'epoch': 0.51}
 51%|█████     | 5252/10395 [15:03:54<43:06:56, 30.18s/it] 51%|█████     | 5253/10395 [15:04:01<33:28:50, 23.44s/it]                                                          {'loss': 0.9313, 'learning_rate': 1.0313079904887712e-05, 'epoch': 0.51}
 51%|█████     | 5253/10395 [15:04:01<33:28:50, 23.44s/it] 51%|█████     | 5254/10395 [15:04:09<26:48:42, 18.78s/it]                                                          {'loss': 0.8971, 'learning_rate': 1.030996568504369e-05, 'epoch': 0.51}
 51%|█████     | 5254/10395 [15:04:09<26:48:42, 18.78s/it] 51%|█████     | 5255/10395 [15:04:17<21:59:46, 15.41s/it]                                                          {'loss': 0.8743, 'learning_rate': 1.030685143510886e-05, 'epoch': 0.51}
 51%|█████     | 5255/10395 [15:04:17<21:59:46, 15.41s/it] 51%|█████     | 5256/10395 [15:04:25<18:44:19, 13.13s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.0303737155385552e-05, 'epoch': 0.51}
 51%|█████     | 5256/10395 [15:04:25<18:44:19, 13.13s/it] 51%|█████     | 5257/10395 [15:04:33<16:55:21, 11.86s/it]                                                          {'loss': 0.8532, 'learning_rate': 1.030062284617609e-05, 'epoch': 0.51}
 51%|█████     | 5257/10395 [15:04:33<16:55:21, 11.86s/it] 51%|█████     | 5258/10395 [15:04:41<15:08:14, 10.61s/it]                                                          {'loss': 0.8433, 'learning_rate': 1.0297508507782799e-05, 'epoch': 0.51}
 51%|█████     | 5258/10395 [15:04:41<15:08:14, 10.61s/it] 51%|█████     | 5259/10395 [15:04:49<13:59:53,  9.81s/it]                                                          {'loss': 0.9715, 'learning_rate': 1.0294394140508022e-05, 'epoch': 0.51}
 51%|█████     | 5259/10395 [15:04:49<13:59:53,  9.81s/it] 51%|█████     | 5260/10395 [15:04:57<13:09:22,  9.22s/it]                                                          {'loss': 0.9424, 'learning_rate': 1.0291279744654093e-05, 'epoch': 0.51}
 51%|█████     | 5260/10395 [15:04:57<13:09:22,  9.22s/it] 51%|█████     | 5261/10395 [15:05:05<12:32:29,  8.79s/it]                                                          {'loss': 0.9056, 'learning_rate': 1.0288165320523347e-05, 'epoch': 0.51}
 51%|█████     | 5261/10395 [15:05:05<12:32:29,  8.79s/it] 51%|█████     | 5262/10395 [15:05:13<12:07:51,  8.51s/it]                                                          {'loss': 0.8684, 'learning_rate': 1.0285050868418123e-05, 'epoch': 0.51}
 51%|█████     | 5262/10395 [15:05:13<12:07:51,  8.51s/it] 51%|█████     | 5263/10395 [15:05:20<11:47:38,  8.27s/it]                                                          {'loss': 0.9472, 'learning_rate': 1.0281936388640774e-05, 'epoch': 0.51}
 51%|█████     | 5263/10395 [15:05:20<11:47:38,  8.27s/it] 51%|█████     | 5264/10395 [15:05:28<11:33:36,  8.11s/it]                                                          {'loss': 0.9261, 'learning_rate': 1.0278821881493644e-05, 'epoch': 0.51}
 51%|█████     | 5264/10395 [15:05:28<11:33:36,  8.11s/it] 51%|█████     | 5265/10395 [15:05:36<11:20:39,  7.96s/it]                                                          {'loss': 0.8609, 'learning_rate': 1.027570734727908e-05, 'epoch': 0.51}
 51%|█████     | 5265/10395 [15:05:36<11:20:39,  7.96s/it] 51%|█████     | 5266/10395 [15:05:43<11:11:07,  7.85s/it]                                                          {'loss': 0.8976, 'learning_rate': 1.0272592786299433e-05, 'epoch': 0.51}
 51%|█████     | 5266/10395 [15:05:43<11:11:07,  7.85s/it] 51%|█████     | 5267/10395 [15:05:51<11:04:51,  7.78s/it]                                                          {'loss': 0.9497, 'learning_rate': 1.0269478198857066e-05, 'epoch': 0.51}
 51%|█████     | 5267/10395 [15:05:51<11:04:51,  7.78s/it] 51%|█████     | 5268/10395 [15:05:58<10:51:51,  7.63s/it]                                                          {'loss': 0.9339, 'learning_rate': 1.0266363585254331e-05, 'epoch': 0.51}
 51%|█████     | 5268/10395 [15:05:58<10:51:51,  7.63s/it] 51%|█████     | 5269/10395 [15:06:06<10:49:58,  7.61s/it]                                                          {'loss': 0.9075, 'learning_rate': 1.0263248945793585e-05, 'epoch': 0.51}
 51%|█████     | 5269/10395 [15:06:06<10:49:58,  7.61s/it] 51%|█████     | 5270/10395 [15:06:13<10:46:08,  7.56s/it]                                                          {'loss': 0.9246, 'learning_rate': 1.0260134280777193e-05, 'epoch': 0.51}
 51%|█████     | 5270/10395 [15:06:13<10:46:08,  7.56s/it] 51%|█████     | 5271/10395 [15:06:21<10:47:47,  7.59s/it]                                                          {'loss': 0.9066, 'learning_rate': 1.0257019590507527e-05, 'epoch': 0.51}
 51%|█████     | 5271/10395 [15:06:21<10:47:47,  7.59s/it] 51%|█████     | 5272/10395 [15:06:29<10:57:28,  7.70s/it]                                                          {'loss': 0.9423, 'learning_rate': 1.0253904875286944e-05, 'epoch': 0.51}
 51%|█████     | 5272/10395 [15:06:29<10:57:28,  7.70s/it] 51%|█████     | 5273/10395 [15:06:36<10:50:24,  7.62s/it]                                                          {'loss': 0.9266, 'learning_rate': 1.0250790135417816e-05, 'epoch': 0.51}
 51%|█████     | 5273/10395 [15:06:36<10:50:24,  7.62s/it] 51%|█████     | 5274/10395 [15:06:44<10:49:38,  7.61s/it]                                                          {'loss': 0.8283, 'learning_rate': 1.0247675371202521e-05, 'epoch': 0.51}
 51%|█████     | 5274/10395 [15:06:44<10:49:38,  7.61s/it] 51%|█████     | 5275/10395 [15:06:52<11:03:07,  7.77s/it]                                                          {'loss': 0.8427, 'learning_rate': 1.0244560582943432e-05, 'epoch': 0.51}
 51%|█████     | 5275/10395 [15:06:52<11:03:07,  7.77s/it] 51%|█████     | 5276/10395 [15:06:59<10:54:11,  7.67s/it]                                                          {'loss': 0.9704, 'learning_rate': 1.0241445770942924e-05, 'epoch': 0.51}
 51%|█████     | 5276/10395 [15:06:59<10:54:11,  7.67s/it] 51%|█████     | 5277/10395 [15:07:07<10:54:17,  7.67s/it]                                                          {'loss': 0.836, 'learning_rate': 1.023833093550337e-05, 'epoch': 0.51}
 51%|█████     | 5277/10395 [15:07:07<10:54:17,  7.67s/it] 51%|█████     | 5278/10395 [15:07:15<10:54:40,  7.68s/it]                                                          {'loss': 0.9148, 'learning_rate': 1.0235216076927163e-05, 'epoch': 0.51}
 51%|█████     | 5278/10395 [15:07:15<10:54:40,  7.68s/it] 51%|█████     | 5279/10395 [15:07:23<11:02:11,  7.77s/it]                                                          {'loss': 0.9422, 'learning_rate': 1.0232101195516686e-05, 'epoch': 0.51}
 51%|█████     | 5279/10395 [15:07:23<11:02:11,  7.77s/it] 51%|█████     | 5280/10395 [15:07:31<11:03:33,  7.78s/it]                                                          {'loss': 0.851, 'learning_rate': 1.0228986291574317e-05, 'epoch': 0.51}
 51%|█████     | 5280/10395 [15:07:31<11:03:33,  7.78s/it] 51%|█████     | 5281/10395 [15:07:40<11:53:20,  8.37s/it]                                                          {'loss': 0.8435, 'learning_rate': 1.0225871365402445e-05, 'epoch': 0.51}
 51%|█████     | 5281/10395 [15:07:40<11:53:20,  8.37s/it] 51%|█████     | 5282/10395 [15:07:59<16:07:17, 11.35s/it]                                                          {'loss': 0.3821, 'learning_rate': 1.0222756417303468e-05, 'epoch': 0.51}
 51%|█████     | 5282/10395 [15:07:59<16:07:17, 11.35s/it] 51%|█████     | 5283/10395 [15:08:06<14:28:44, 10.20s/it]                                                          {'loss': 0.9211, 'learning_rate': 1.0219641447579772e-05, 'epoch': 0.51}
 51%|█████     | 5283/10395 [15:08:06<14:28:44, 10.20s/it] 51%|█████     | 5284/10395 [15:08:14<13:34:22,  9.56s/it]                                                          {'loss': 0.8604, 'learning_rate': 1.0216526456533756e-05, 'epoch': 0.51}
 51%|█████     | 5284/10395 [15:08:14<13:34:22,  9.56s/it] 51%|█████     | 5285/10395 [15:08:21<12:33:11,  8.84s/it]                                                          {'loss': 1.003, 'learning_rate': 1.021341144446781e-05, 'epoch': 0.51}
 51%|█████     | 5285/10395 [15:08:21<12:33:11,  8.84s/it] 51%|█████     | 5286/10395 [15:08:29<12:02:09,  8.48s/it]                                                          {'loss': 0.8698, 'learning_rate': 1.021029641168434e-05, 'epoch': 0.51}
 51%|█████     | 5286/10395 [15:08:29<12:02:09,  8.48s/it] 51%|█████     | 5287/10395 [15:08:36<11:37:34,  8.19s/it]                                                          {'loss': 0.9435, 'learning_rate': 1.0207181358485742e-05, 'epoch': 0.51}
 51%|█████     | 5287/10395 [15:08:37<11:37:34,  8.19s/it] 51%|█████     | 5288/10395 [15:08:45<11:46:43,  8.30s/it]                                                          {'loss': 0.9064, 'learning_rate': 1.0204066285174423e-05, 'epoch': 0.51}
 51%|█████     | 5288/10395 [15:08:45<11:46:43,  8.30s/it] 51%|█████     | 5289/10395 [15:08:53<11:26:16,  8.06s/it]                                                          {'loss': 0.8579, 'learning_rate': 1.0200951192052781e-05, 'epoch': 0.51}
 51%|█████     | 5289/10395 [15:08:53<11:26:16,  8.06s/it] 51%|█████     | 5290/10395 [15:09:00<11:10:03,  7.88s/it]                                                          {'loss': 0.9684, 'learning_rate': 1.0197836079423231e-05, 'epoch': 0.51}
 51%|█████     | 5290/10395 [15:09:00<11:10:03,  7.88s/it] 51%|█████     | 5291/10395 [15:09:08<11:04:58,  7.82s/it]                                                          {'loss': 0.901, 'learning_rate': 1.0194720947588178e-05, 'epoch': 0.51}
 51%|█████     | 5291/10395 [15:09:08<11:04:58,  7.82s/it] 51%|█████     | 5292/10395 [15:09:24<14:43:01, 10.38s/it]                                                          {'loss': 0.3754, 'learning_rate': 1.0191605796850027e-05, 'epoch': 0.51}
 51%|█████     | 5292/10395 [15:09:24<14:43:01, 10.38s/it] 51%|█████     | 5293/10395 [15:09:32<13:29:57,  9.53s/it]                                                          {'loss': 0.956, 'learning_rate': 1.0188490627511196e-05, 'epoch': 0.51}
 51%|█████     | 5293/10395 [15:09:32<13:29:57,  9.53s/it] 51%|█████     | 5294/10395 [15:09:40<12:59:54,  9.17s/it]                                                          {'loss': 0.8662, 'learning_rate': 1.0185375439874098e-05, 'epoch': 0.51}
 51%|█████     | 5294/10395 [15:09:40<12:59:54,  9.17s/it] 51%|█████     | 5295/10395 [15:09:48<12:43:31,  8.98s/it]                                                          {'loss': 0.8486, 'learning_rate': 1.018226023424115e-05, 'epoch': 0.51}
 51%|█████     | 5295/10395 [15:09:48<12:43:31,  8.98s/it] 51%|█████     | 5296/10395 [15:09:58<12:59:48,  9.18s/it]                                                          {'loss': 0.8031, 'learning_rate': 1.0179145010914769e-05, 'epoch': 0.51}
 51%|█████     | 5296/10395 [15:09:58<12:59:48,  9.18s/it] 51%|█████     | 5297/10395 [15:10:06<12:26:30,  8.79s/it]                                                          {'loss': 0.9517, 'learning_rate': 1.0176029770197369e-05, 'epoch': 0.51}
 51%|█████     | 5297/10395 [15:10:06<12:26:30,  8.79s/it] 51%|█████     | 5298/10395 [15:10:13<11:49:48,  8.36s/it]                                                          {'loss': 0.8918, 'learning_rate': 1.0172914512391379e-05, 'epoch': 0.51}
 51%|█████     | 5298/10395 [15:10:13<11:49:48,  8.36s/it] 51%|█████     | 5299/10395 [15:10:22<11:50:34,  8.37s/it]                                                          {'loss': 0.9183, 'learning_rate': 1.0169799237799214e-05, 'epoch': 0.51}
 51%|█████     | 5299/10395 [15:10:22<11:50:34,  8.37s/it] 51%|█████     | 5300/10395 [15:10:38<15:21:32, 10.85s/it]                                                          {'loss': 0.3701, 'learning_rate': 1.0166683946723303e-05, 'epoch': 0.51}
 51%|█████     | 5300/10395 [15:10:38<15:21:32, 10.85s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 51%|█████     | 5301/10395 [15:12:18<52:53:52, 37.38s/it]                                                          {'loss': 0.9276, 'learning_rate': 1.0163568639466073e-05, 'epoch': 0.51}
 51%|█████     | 5301/10395 [15:12:18<52:53:52, 37.38s/it] 51%|█████     | 5302/10395 [15:12:27<40:47:07, 28.83s/it]                                                          {'loss': 0.9231, 'learning_rate': 1.0160453316329946e-05, 'epoch': 0.51}
 51%|█████     | 5302/10395 [15:12:27<40:47:07, 28.83s/it] 51%|█████     | 5303/10395 [15:12:34<31:37:03, 22.35s/it]                                                          {'loss': 0.9196, 'learning_rate': 1.0157337977617357e-05, 'epoch': 0.51}
 51%|█████     | 5303/10395 [15:12:34<31:37:03, 22.35s/it] 51%|█████     | 5304/10395 [15:12:41<25:22:52, 17.95s/it]                                                          {'loss': 0.9697, 'learning_rate': 1.0154222623630732e-05, 'epoch': 0.51}
 51%|█████     | 5304/10395 [15:12:41<25:22:52, 17.95s/it] 51%|█████     | 5305/10395 [15:12:49<21:00:56, 14.86s/it]                                                          {'loss': 0.943, 'learning_rate': 1.0151107254672503e-05, 'epoch': 0.51}
 51%|█████     | 5305/10395 [15:12:49<21:00:56, 14.86s/it] 51%|█████     | 5306/10395 [15:12:56<17:47:37, 12.59s/it]                                                          {'loss': 0.8956, 'learning_rate': 1.0147991871045104e-05, 'epoch': 0.51}
 51%|█████     | 5306/10395 [15:12:56<17:47:37, 12.59s/it] 51%|█████     | 5307/10395 [15:13:05<16:07:36, 11.41s/it]                                                          {'loss': 0.8359, 'learning_rate': 1.0144876473050973e-05, 'epoch': 0.51}
 51%|█████     | 5307/10395 [15:13:05<16:07:36, 11.41s/it] 51%|█████     | 5308/10395 [15:13:13<14:39:44, 10.38s/it]                                                          {'loss': 0.8711, 'learning_rate': 1.0141761060992544e-05, 'epoch': 0.51}
 51%|█████     | 5308/10395 [15:13:13<14:39:44, 10.38s/it] 51%|█████     | 5309/10395 [15:13:22<13:51:48,  9.81s/it]                                                          {'loss': 0.9153, 'learning_rate': 1.0138645635172251e-05, 'epoch': 0.51}
 51%|█████     | 5309/10395 [15:13:22<13:51:48,  9.81s/it] 51%|█████     | 5310/10395 [15:13:38<16:29:33, 11.68s/it]                                                          {'loss': 0.4128, 'learning_rate': 1.0135530195892537e-05, 'epoch': 0.51}
 51%|█████     | 5310/10395 [15:13:38<16:29:33, 11.68s/it] 51%|█████     | 5311/10395 [15:13:45<14:37:14, 10.35s/it]                                                          {'loss': 0.8512, 'learning_rate': 1.0132414743455842e-05, 'epoch': 0.51}
 51%|█████     | 5311/10395 [15:13:45<14:37:14, 10.35s/it] 51%|█████     | 5312/10395 [15:13:52<13:25:19,  9.51s/it]                                                          {'loss': 0.9057, 'learning_rate': 1.0129299278164609e-05, 'epoch': 0.51}
 51%|█████     | 5312/10395 [15:13:52<13:25:19,  9.51s/it] 51%|█████     | 5313/10395 [15:14:01<13:01:53,  9.23s/it]                                                          {'loss': 0.8152, 'learning_rate': 1.0126183800321274e-05, 'epoch': 0.51}
 51%|█████     | 5313/10395 [15:14:01<13:01:53,  9.23s/it] 51%|█████     | 5314/10395 [15:14:08<12:12:11,  8.65s/it]                                                          {'loss': 0.8525, 'learning_rate': 1.0123068310228287e-05, 'epoch': 0.51}
 51%|█████     | 5314/10395 [15:14:08<12:12:11,  8.65s/it] 51%|█████     | 5315/10395 [15:14:16<11:41:53,  8.29s/it]                                                          {'loss': 0.8997, 'learning_rate': 1.0119952808188094e-05, 'epoch': 0.51}
 51%|█████     | 5315/10395 [15:14:16<11:41:53,  8.29s/it] 51%|█████     | 5316/10395 [15:14:23<11:20:03,  8.03s/it]                                                          {'loss': 0.9307, 'learning_rate': 1.0116837294503134e-05, 'epoch': 0.51}
 51%|█████     | 5316/10395 [15:14:23<11:20:03,  8.03s/it] 51%|█████     | 5317/10395 [15:14:31<11:24:09,  8.08s/it]                                                          {'loss': 0.8751, 'learning_rate': 1.0113721769475863e-05, 'epoch': 0.51}
 51%|█████     | 5317/10395 [15:14:31<11:24:09,  8.08s/it] 51%|█████     | 5318/10395 [15:14:39<11:07:21,  7.89s/it]                                                          {'loss': 0.9191, 'learning_rate': 1.0110606233408723e-05, 'epoch': 0.51}
 51%|█████     | 5318/10395 [15:14:39<11:07:21,  7.89s/it] 51%|█████     | 5319/10395 [15:14:46<10:58:59,  7.79s/it]                                                          {'loss': 0.8854, 'learning_rate': 1.0107490686604169e-05, 'epoch': 0.51}
 51%|█████     | 5319/10395 [15:14:46<10:58:59,  7.79s/it] 51%|█████     | 5320/10395 [15:14:54<11:04:19,  7.85s/it]                                                          {'loss': 0.889, 'learning_rate': 1.0104375129364648e-05, 'epoch': 0.51}
 51%|█████     | 5320/10395 [15:14:54<11:04:19,  7.85s/it] 51%|█████     | 5321/10395 [15:15:02<10:57:24,  7.77s/it]                                                          {'loss': 0.9761, 'learning_rate': 1.0101259561992612e-05, 'epoch': 0.51}
 51%|█████     | 5321/10395 [15:15:02<10:57:24,  7.77s/it] 51%|█████     | 5322/10395 [15:15:10<11:06:00,  7.88s/it]                                                          {'loss': 0.9305, 'learning_rate': 1.0098143984790513e-05, 'epoch': 0.51}
 51%|█████     | 5322/10395 [15:15:10<11:06:00,  7.88s/it] 51%|█████     | 5323/10395 [15:15:17<10:54:42,  7.74s/it]                                                          {'loss': 0.8792, 'learning_rate': 1.0095028398060807e-05, 'epoch': 0.51}
 51%|█████     | 5323/10395 [15:15:17<10:54:42,  7.74s/it] 51%|█████     | 5324/10395 [15:15:26<11:06:11,  7.88s/it]                                                          {'loss': 0.8581, 'learning_rate': 1.0091912802105947e-05, 'epoch': 0.51}
 51%|█████     | 5324/10395 [15:15:26<11:06:11,  7.88s/it] 51%|█████     | 5325/10395 [15:15:33<10:58:13,  7.79s/it]                                                          {'loss': 0.901, 'learning_rate': 1.0088797197228389e-05, 'epoch': 0.51}
 51%|█████     | 5325/10395 [15:15:33<10:58:13,  7.79s/it] 51%|█████     | 5326/10395 [15:15:41<11:08:11,  7.91s/it]                                                          {'loss': 0.8699, 'learning_rate': 1.008568158373059e-05, 'epoch': 0.51}
 51%|█████     | 5326/10395 [15:15:41<11:08:11,  7.91s/it] 51%|█████     | 5327/10395 [15:15:49<10:51:34,  7.71s/it]                                                          {'loss': 0.9471, 'learning_rate': 1.0082565961915001e-05, 'epoch': 0.51}
 51%|█████     | 5327/10395 [15:15:49<10:51:34,  7.71s/it] 51%|█████▏    | 5328/10395 [15:15:57<10:56:01,  7.77s/it]                                                          {'loss': 0.8324, 'learning_rate': 1.0079450332084089e-05, 'epoch': 0.51}
 51%|█████▏    | 5328/10395 [15:15:57<10:56:01,  7.77s/it] 51%|█████▏    | 5329/10395 [15:16:04<10:50:33,  7.71s/it]                                                          {'loss': 0.8695, 'learning_rate': 1.0076334694540308e-05, 'epoch': 0.51}
 51%|█████▏    | 5329/10395 [15:16:04<10:50:33,  7.71s/it] 51%|█████▏    | 5330/10395 [15:16:12<10:52:31,  7.73s/it]                                                          {'loss': 0.9484, 'learning_rate': 1.0073219049586118e-05, 'epoch': 0.51}
 51%|█████▏    | 5330/10395 [15:16:12<10:52:31,  7.73s/it] 51%|█████▏    | 5331/10395 [15:16:19<10:48:59,  7.69s/it]                                                          {'loss': 0.8303, 'learning_rate': 1.0070103397523979e-05, 'epoch': 0.51}
 51%|█████▏    | 5331/10395 [15:16:19<10:48:59,  7.69s/it] 51%|█████▏    | 5332/10395 [15:16:27<10:42:10,  7.61s/it]                                                          {'loss': 0.9335, 'learning_rate': 1.006698773865635e-05, 'epoch': 0.51}
 51%|█████▏    | 5332/10395 [15:16:27<10:42:10,  7.61s/it] 51%|█████▏    | 5333/10395 [15:16:35<10:47:20,  7.67s/it]                                                          {'loss': 1.0106, 'learning_rate': 1.0063872073285696e-05, 'epoch': 0.51}
 51%|█████▏    | 5333/10395 [15:16:35<10:47:20,  7.67s/it] 51%|█████▏    | 5334/10395 [15:16:44<11:21:10,  8.08s/it]                                                          {'loss': 0.8941, 'learning_rate': 1.0060756401714479e-05, 'epoch': 0.51}
 51%|█████▏    | 5334/10395 [15:16:44<11:21:10,  8.08s/it] 51%|█████▏    | 5335/10395 [15:16:51<11:08:21,  7.93s/it]                                                          {'loss': 0.9846, 'learning_rate': 1.0057640724245158e-05, 'epoch': 0.51}
 51%|█████▏    | 5335/10395 [15:16:51<11:08:21,  7.93s/it] 51%|█████▏    | 5336/10395 [15:16:59<11:12:53,  7.98s/it]                                                          {'loss': 0.9512, 'learning_rate': 1.0054525041180201e-05, 'epoch': 0.51}
 51%|█████▏    | 5336/10395 [15:16:59<11:12:53,  7.98s/it] 51%|█████▏    | 5337/10395 [15:17:07<10:59:03,  7.82s/it]                                                          {'loss': 0.8587, 'learning_rate': 1.005140935282207e-05, 'epoch': 0.51}
 51%|█████▏    | 5337/10395 [15:17:07<10:59:03,  7.82s/it] 51%|█████▏    | 5338/10395 [15:17:15<11:00:36,  7.84s/it]                                                          {'loss': 0.8191, 'learning_rate': 1.0048293659473225e-05, 'epoch': 0.51}
 51%|█████▏    | 5338/10395 [15:17:15<11:00:36,  7.84s/it] 51%|█████▏    | 5339/10395 [15:17:22<10:44:53,  7.65s/it]                                                          {'loss': 0.8461, 'learning_rate': 1.0045177961436136e-05, 'epoch': 0.51}
 51%|█████▏    | 5339/10395 [15:17:22<10:44:53,  7.65s/it] 51%|█████▏    | 5340/10395 [15:17:30<10:55:03,  7.78s/it]                                                          {'loss': 0.8672, 'learning_rate': 1.0042062259013269e-05, 'epoch': 0.51}
 51%|█████▏    | 5340/10395 [15:17:30<10:55:03,  7.78s/it] 51%|█████▏    | 5341/10395 [15:17:38<11:01:29,  7.85s/it]                                                          {'loss': 0.8918, 'learning_rate': 1.003894655250709e-05, 'epoch': 0.51}
 51%|█████▏    | 5341/10395 [15:17:38<11:01:29,  7.85s/it] 51%|█████▏    | 5342/10395 [15:17:46<11:03:06,  7.87s/it]                                                          {'loss': 0.8509, 'learning_rate': 1.0035830842220059e-05, 'epoch': 0.51}
 51%|█████▏    | 5342/10395 [15:17:46<11:03:06,  7.87s/it] 51%|█████▏    | 5343/10395 [15:17:55<11:20:27,  8.08s/it]                                                          {'loss': 0.8738, 'learning_rate': 1.0032715128454646e-05, 'epoch': 0.51}
 51%|█████▏    | 5343/10395 [15:17:55<11:20:27,  8.08s/it] 51%|█████▏    | 5344/10395 [15:18:03<11:20:11,  8.08s/it]                                                          {'loss': 0.9231, 'learning_rate': 1.002959941151332e-05, 'epoch': 0.51}
 51%|█████▏    | 5344/10395 [15:18:03<11:20:11,  8.08s/it] 51%|█████▏    | 5345/10395 [15:18:10<11:09:34,  7.96s/it]                                                          {'loss': 0.9406, 'learning_rate': 1.0026483691698548e-05, 'epoch': 0.51}
 51%|█████▏    | 5345/10395 [15:18:10<11:09:34,  7.96s/it] 51%|█████▏    | 5346/10395 [15:18:28<15:12:22, 10.84s/it]                                                          {'loss': 0.3554, 'learning_rate': 1.002336796931279e-05, 'epoch': 0.51}
 51%|█████▏    | 5346/10395 [15:18:28<15:12:22, 10.84s/it] 51%|█████▏    | 5347/10395 [15:18:35<13:49:13,  9.86s/it]                                                          {'loss': 0.9431, 'learning_rate': 1.0020252244658524e-05, 'epoch': 0.51}
 51%|█████▏    | 5347/10395 [15:18:35<13:49:13,  9.86s/it] 51%|█████▏    | 5348/10395 [15:18:43<12:49:58,  9.15s/it]                                                          {'loss': 0.9603, 'learning_rate': 1.0017136518038215e-05, 'epoch': 0.51}
 51%|█████▏    | 5348/10395 [15:18:43<12:49:58,  9.15s/it] 51%|█████▏    | 5349/10395 [15:18:51<12:20:43,  8.81s/it]                                                          {'loss': 0.8872, 'learning_rate': 1.0014020789754327e-05, 'epoch': 0.51}
 51%|█████▏    | 5349/10395 [15:18:51<12:20:43,  8.81s/it] 51%|█████▏    | 5350/10395 [15:18:59<11:49:31,  8.44s/it]                                                          {'loss': 0.9559, 'learning_rate': 1.0010905060109329e-05, 'epoch': 0.51}
 51%|█████▏    | 5350/10395 [15:18:59<11:49:31,  8.44s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 51%|█████▏    | 5351/10395 [15:20:39<50:24:31, 35.98s/it]                                                          {'loss': 1.039, 'learning_rate': 1.000778932940569e-05, 'epoch': 0.51}
 51%|█████▏    | 5351/10395 [15:20:39<50:24:31, 35.98s/it] 51%|█████▏    | 5352/10395 [15:20:47<38:37:29, 27.57s/it]                                                          {'loss': 0.9363, 'learning_rate': 1.0004673597945886e-05, 'epoch': 0.51}
 51%|█████▏    | 5352/10395 [15:20:47<38:37:29, 27.57s/it] 51%|█████▏    | 5353/10395 [15:20:54<30:12:53, 21.57s/it]                                                          {'loss': 0.9372, 'learning_rate': 1.0001557866032374e-05, 'epoch': 0.51}
 51%|█████▏    | 5353/10395 [15:20:54<30:12:53, 21.57s/it] 52%|█████▏    | 5354/10395 [15:21:10<27:55:13, 19.94s/it]                                                          {'loss': 0.3838, 'learning_rate': 9.998442133967628e-06, 'epoch': 0.52}
 52%|█████▏    | 5354/10395 [15:21:10<27:55:13, 19.94s/it] 52%|█████▏    | 5355/10395 [15:21:18<22:34:49, 16.13s/it]                                                          {'loss': 0.8998, 'learning_rate': 9.995326402054117e-06, 'epoch': 0.52}
 52%|█████▏    | 5355/10395 [15:21:18<22:34:49, 16.13s/it] 52%|█████▏    | 5356/10395 [15:21:26<19:24:09, 13.86s/it]                                                          {'loss': 0.8397, 'learning_rate': 9.992210670594309e-06, 'epoch': 0.52}
 52%|█████▏    | 5356/10395 [15:21:26<19:24:09, 13.86s/it] 52%|█████▏    | 5357/10395 [15:21:35<17:04:19, 12.20s/it]                                                          {'loss': 0.8569, 'learning_rate': 9.989094939890673e-06, 'epoch': 0.52}
 52%|█████▏    | 5357/10395 [15:21:35<17:04:19, 12.20s/it] 52%|█████▏    | 5358/10395 [15:21:42<15:17:05, 10.92s/it]                                                          {'loss': 0.8818, 'learning_rate': 9.985979210245678e-06, 'epoch': 0.52}
 52%|█████▏    | 5358/10395 [15:21:42<15:17:05, 10.92s/it] 52%|█████▏    | 5359/10395 [15:21:50<13:58:41,  9.99s/it]                                                          {'loss': 0.9319, 'learning_rate': 9.98286348196179e-06, 'epoch': 0.52}
 52%|█████▏    | 5359/10395 [15:21:50<13:58:41,  9.99s/it] 52%|█████▏    | 5360/10395 [15:21:58<13:09:56,  9.41s/it]                                                          {'loss': 0.8739, 'learning_rate': 9.979747755341479e-06, 'epoch': 0.52}
 52%|█████▏    | 5360/10395 [15:21:58<13:09:56,  9.41s/it] 52%|█████▏    | 5361/10395 [15:22:06<12:23:47,  8.87s/it]                                                          {'loss': 0.9002, 'learning_rate': 9.976632030687212e-06, 'epoch': 0.52}
 52%|█████▏    | 5361/10395 [15:22:06<12:23:47,  8.87s/it] 52%|█████▏    | 5362/10395 [15:22:13<11:40:23,  8.35s/it]                                                          {'loss': 0.9686, 'learning_rate': 9.973516308301457e-06, 'epoch': 0.52}
 52%|█████▏    | 5362/10395 [15:22:13<11:40:23,  8.35s/it] 52%|█████▏    | 5363/10395 [15:22:23<12:10:39,  8.71s/it]                                                          {'loss': 0.8882, 'learning_rate': 9.970400588486681e-06, 'epoch': 0.52}
 52%|█████▏    | 5363/10395 [15:22:23<12:10:39,  8.71s/it] 52%|█████▏    | 5364/10395 [15:22:30<11:48:17,  8.45s/it]                                                          {'loss': 0.8849, 'learning_rate': 9.967284871545356e-06, 'epoch': 0.52}
 52%|█████▏    | 5364/10395 [15:22:30<11:48:17,  8.45s/it] 52%|█████▏    | 5365/10395 [15:22:38<11:22:29,  8.14s/it]                                                          {'loss': 0.9289, 'learning_rate': 9.964169157779946e-06, 'epoch': 0.52}
 52%|█████▏    | 5365/10395 [15:22:38<11:22:29,  8.14s/it] 52%|█████▏    | 5366/10395 [15:22:46<11:19:25,  8.11s/it]                                                          {'loss': 0.9562, 'learning_rate': 9.961053447492915e-06, 'epoch': 0.52}
 52%|█████▏    | 5366/10395 [15:22:46<11:19:25,  8.11s/it] 52%|█████▏    | 5367/10395 [15:22:54<11:11:56,  8.02s/it]                                                          {'loss': 0.8587, 'learning_rate': 9.957937740986732e-06, 'epoch': 0.52}
 52%|█████▏    | 5367/10395 [15:22:54<11:11:56,  8.02s/it] 52%|█████▏    | 5368/10395 [15:23:02<11:07:16,  7.96s/it]                                                          {'loss': 0.8916, 'learning_rate': 9.954822038563865e-06, 'epoch': 0.52}
 52%|█████▏    | 5368/10395 [15:23:02<11:07:16,  7.96s/it] 52%|█████▏    | 5369/10395 [15:23:09<11:02:50,  7.91s/it]                                                          {'loss': 0.904, 'learning_rate': 9.951706340526777e-06, 'epoch': 0.52}
 52%|█████▏    | 5369/10395 [15:23:09<11:02:50,  7.91s/it] 52%|█████▏    | 5370/10395 [15:23:17<10:53:42,  7.81s/it]                                                          {'loss': 0.9674, 'learning_rate': 9.948590647177933e-06, 'epoch': 0.52}
 52%|█████▏    | 5370/10395 [15:23:17<10:53:42,  7.81s/it] 52%|█████▏    | 5371/10395 [15:23:25<10:52:58,  7.80s/it]                                                          {'loss': 0.858, 'learning_rate': 9.945474958819799e-06, 'epoch': 0.52}
 52%|█████▏    | 5371/10395 [15:23:25<10:52:58,  7.80s/it] 52%|█████▏    | 5372/10395 [15:23:32<10:30:41,  7.53s/it]                                                          {'loss': 0.9677, 'learning_rate': 9.942359275754843e-06, 'epoch': 0.52}
 52%|█████▏    | 5372/10395 [15:23:32<10:30:41,  7.53s/it] 52%|█████▏    | 5373/10395 [15:23:39<10:26:09,  7.48s/it]                                                          {'loss': 0.9716, 'learning_rate': 9.939243598285524e-06, 'epoch': 0.52}
 52%|█████▏    | 5373/10395 [15:23:39<10:26:09,  7.48s/it] 52%|█████▏    | 5374/10395 [15:23:46<10:25:53,  7.48s/it]                                                          {'loss': 0.9634, 'learning_rate': 9.936127926714306e-06, 'epoch': 0.52}
 52%|█████▏    | 5374/10395 [15:23:46<10:25:53,  7.48s/it] 52%|█████▏    | 5375/10395 [15:23:55<10:42:33,  7.68s/it]                                                          {'loss': 0.8681, 'learning_rate': 9.933012261343651e-06, 'epoch': 0.52}
 52%|█████▏    | 5375/10395 [15:23:55<10:42:33,  7.68s/it] 52%|█████▏    | 5376/10395 [15:24:02<10:45:39,  7.72s/it]                                                          {'loss': 0.8878, 'learning_rate': 9.929896602476025e-06, 'epoch': 0.52}
 52%|█████▏    | 5376/10395 [15:24:02<10:45:39,  7.72s/it] 52%|█████▏    | 5377/10395 [15:24:10<10:38:49,  7.64s/it]                                                          {'loss': 0.9189, 'learning_rate': 9.926780950413884e-06, 'epoch': 0.52}
 52%|█████▏    | 5377/10395 [15:24:10<10:38:49,  7.64s/it] 52%|█████▏    | 5378/10395 [15:24:18<10:44:28,  7.71s/it]                                                          {'loss': 0.9418, 'learning_rate': 9.923665305459693e-06, 'epoch': 0.52}
 52%|█████▏    | 5378/10395 [15:24:18<10:44:28,  7.71s/it] 52%|█████▏    | 5379/10395 [15:24:25<10:25:47,  7.49s/it]                                                          {'loss': 0.9751, 'learning_rate': 9.920549667915911e-06, 'epoch': 0.52}
 52%|█████▏    | 5379/10395 [15:24:25<10:25:47,  7.49s/it] 52%|█████▏    | 5380/10395 [15:24:34<11:06:34,  7.98s/it]                                                          {'loss': 0.8255, 'learning_rate': 9.917434038085e-06, 'epoch': 0.52}
 52%|█████▏    | 5380/10395 [15:24:34<11:06:34,  7.98s/it] 52%|█████▏    | 5381/10395 [15:24:41<10:55:29,  7.84s/it]                                                          {'loss': 0.9381, 'learning_rate': 9.914318416269416e-06, 'epoch': 0.52}
 52%|█████▏    | 5381/10395 [15:24:41<10:55:29,  7.84s/it] 52%|█████▏    | 5382/10395 [15:24:49<10:40:25,  7.67s/it]                                                          {'loss': 0.9225, 'learning_rate': 9.911202802771615e-06, 'epoch': 0.52}
 52%|█████▏    | 5382/10395 [15:24:49<10:40:25,  7.67s/it] 52%|█████▏    | 5383/10395 [15:24:57<10:59:50,  7.90s/it]                                                          {'loss': 0.8393, 'learning_rate': 9.908087197894056e-06, 'epoch': 0.52}
 52%|█████▏    | 5383/10395 [15:24:57<10:59:50,  7.90s/it] 52%|█████▏    | 5384/10395 [15:25:07<11:38:25,  8.36s/it]                                                          {'loss': 0.9079, 'learning_rate': 9.904971601939197e-06, 'epoch': 0.52}
 52%|█████▏    | 5384/10395 [15:25:07<11:38:25,  8.36s/it] 52%|█████▏    | 5385/10395 [15:25:14<11:23:51,  8.19s/it]                                                          {'loss': 0.8882, 'learning_rate': 9.901856015209488e-06, 'epoch': 0.52}
 52%|█████▏    | 5385/10395 [15:25:14<11:23:51,  8.19s/it] 52%|█████▏    | 5386/10395 [15:25:22<11:01:55,  7.93s/it]                                                          {'loss': 0.9122, 'learning_rate': 9.89874043800739e-06, 'epoch': 0.52}
 52%|█████▏    | 5386/10395 [15:25:22<11:01:55,  7.93s/it] 52%|█████▏    | 5387/10395 [15:25:29<10:44:20,  7.72s/it]                                                          {'loss': 0.8745, 'learning_rate': 9.895624870635357e-06, 'epoch': 0.52}
 52%|█████▏    | 5387/10395 [15:25:29<10:44:20,  7.72s/it] 52%|█████▏    | 5388/10395 [15:25:37<10:54:05,  7.84s/it]                                                          {'loss': 0.8112, 'learning_rate': 9.892509313395835e-06, 'epoch': 0.52}
 52%|█████▏    | 5388/10395 [15:25:37<10:54:05,  7.84s/it] 52%|█████▏    | 5389/10395 [15:25:46<11:11:23,  8.05s/it]                                                          {'loss': 0.9059, 'learning_rate': 9.889393766591278e-06, 'epoch': 0.52}
 52%|█████▏    | 5389/10395 [15:25:46<11:11:23,  8.05s/it] 52%|█████▏    | 5390/10395 [15:25:54<11:12:28,  8.06s/it]                                                          {'loss': 0.9094, 'learning_rate': 9.88627823052414e-06, 'epoch': 0.52}
 52%|█████▏    | 5390/10395 [15:25:54<11:12:28,  8.06s/it] 52%|█████▏    | 5391/10395 [15:26:01<11:04:55,  7.97s/it]                                                          {'loss': 0.9264, 'learning_rate': 9.883162705496867e-06, 'epoch': 0.52}
 52%|█████▏    | 5391/10395 [15:26:01<11:04:55,  7.97s/it] 52%|█████▏    | 5392/10395 [15:26:09<10:55:33,  7.86s/it]                                                          {'loss': 0.9545, 'learning_rate': 9.88004719181191e-06, 'epoch': 0.52}
 52%|█████▏    | 5392/10395 [15:26:09<10:55:33,  7.86s/it] 52%|█████▏    | 5393/10395 [15:26:17<10:48:16,  7.78s/it]                                                          {'loss': 1.0383, 'learning_rate': 9.876931689771713e-06, 'epoch': 0.52}
 52%|█████▏    | 5393/10395 [15:26:17<10:48:16,  7.78s/it] 52%|█████▏    | 5394/10395 [15:26:25<11:03:52,  7.96s/it]                                                          {'loss': 0.9316, 'learning_rate': 9.873816199678731e-06, 'epoch': 0.52}
 52%|█████▏    | 5394/10395 [15:26:25<11:03:52,  7.96s/it] 52%|█████▏    | 5395/10395 [15:26:33<11:06:09,  7.99s/it]                                                          {'loss': 0.8648, 'learning_rate': 9.870700721835396e-06, 'epoch': 0.52}
 52%|█████▏    | 5395/10395 [15:26:33<11:06:09,  7.99s/it] 52%|█████▏    | 5396/10395 [15:26:41<11:12:29,  8.07s/it]                                                          {'loss': 0.9644, 'learning_rate': 9.86758525654416e-06, 'epoch': 0.52}
 52%|█████▏    | 5396/10395 [15:26:41<11:12:29,  8.07s/it] 52%|█████▏    | 5397/10395 [15:26:49<11:15:40,  8.11s/it]                                                          {'loss': 0.7962, 'learning_rate': 9.864469804107464e-06, 'epoch': 0.52}
 52%|█████▏    | 5397/10395 [15:26:49<11:15:40,  8.11s/it] 52%|█████▏    | 5398/10395 [15:26:58<11:22:39,  8.20s/it]                                                          {'loss': 0.8284, 'learning_rate': 9.86135436482775e-06, 'epoch': 0.52}
 52%|█████▏    | 5398/10395 [15:26:58<11:22:39,  8.20s/it] 52%|█████▏    | 5399/10395 [15:27:06<11:27:11,  8.25s/it]                                                          {'loss': 0.8994, 'learning_rate': 9.858238939007461e-06, 'epoch': 0.52}
 52%|█████▏    | 5399/10395 [15:27:06<11:27:11,  8.25s/it] 52%|█████▏    | 5400/10395 [15:27:14<11:08:33,  8.03s/it]                                                          {'loss': 0.8387, 'learning_rate': 9.85512352694903e-06, 'epoch': 0.52}
 52%|█████▏    | 5400/10395 [15:27:14<11:08:33,  8.03s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 52%|█████▏    | 5401/10395 [15:28:57<50:35:07, 36.47s/it]                                                          {'loss': 0.9554, 'learning_rate': 9.852008128954895e-06, 'epoch': 0.52}
 52%|█████▏    | 5401/10395 [15:28:57<50:35:07, 36.47s/it] 52%|█████▏    | 5402/10395 [15:29:04<38:35:08, 27.82s/it]                                                          {'loss': 0.8557, 'learning_rate': 9.848892745327504e-06, 'epoch': 0.52}
 52%|█████▏    | 5402/10395 [15:29:04<38:35:08, 27.82s/it] 52%|█████▏    | 5403/10395 [15:29:13<30:33:21, 22.04s/it]                                                          {'loss': 0.9217, 'learning_rate': 9.845777376369272e-06, 'epoch': 0.52}
 52%|█████▏    | 5403/10395 [15:29:13<30:33:21, 22.04s/it] 52%|█████▏    | 5404/10395 [15:29:30<28:35:51, 20.63s/it]                                                          {'loss': 0.3636, 'learning_rate': 9.842662022382647e-06, 'epoch': 0.52}
 52%|█████▏    | 5404/10395 [15:29:30<28:35:51, 20.63s/it] 52%|█████▏    | 5405/10395 [15:29:37<23:02:52, 16.63s/it]                                                          {'loss': 0.9951, 'learning_rate': 9.839546683670055e-06, 'epoch': 0.52}
 52%|█████▏    | 5405/10395 [15:29:37<23:02:52, 16.63s/it] 52%|█████▏    | 5406/10395 [15:29:45<19:17:11, 13.92s/it]                                                          {'loss': 0.8831, 'learning_rate': 9.83643136053393e-06, 'epoch': 0.52}
 52%|█████▏    | 5406/10395 [15:29:45<19:17:11, 13.92s/it] 52%|█████▏    | 5407/10395 [15:29:53<16:46:45, 12.11s/it]                                                          {'loss': 0.8262, 'learning_rate': 9.833316053276699e-06, 'epoch': 0.52}
 52%|█████▏    | 5407/10395 [15:29:53<16:46:45, 12.11s/it] 52%|█████▏    | 5408/10395 [15:30:09<18:18:51, 13.22s/it]                                                          {'loss': 0.3116, 'learning_rate': 9.830200762200786e-06, 'epoch': 0.52}
 52%|█████▏    | 5408/10395 [15:30:09<18:18:51, 13.22s/it] 52%|█████▏    | 5409/10395 [15:30:16<15:59:51, 11.55s/it]                                                          {'loss': 0.872, 'learning_rate': 9.827085487608628e-06, 'epoch': 0.52}
 52%|█████▏    | 5409/10395 [15:30:16<15:59:51, 11.55s/it] 52%|█████▏    | 5410/10395 [15:30:24<14:26:00, 10.42s/it]                                                          {'loss': 0.8592, 'learning_rate': 9.823970229802635e-06, 'epoch': 0.52}
 52%|█████▏    | 5410/10395 [15:30:24<14:26:00, 10.42s/it] 52%|█████▏    | 5411/10395 [15:30:42<17:42:02, 12.79s/it]                                                          {'loss': 0.4083, 'learning_rate': 9.820854989085235e-06, 'epoch': 0.52}
 52%|█████▏    | 5411/10395 [15:30:42<17:42:02, 12.79s/it] 52%|█████▏    | 5412/10395 [15:30:51<15:46:00, 11.39s/it]                                                          {'loss': 0.9048, 'learning_rate': 9.817739765758853e-06, 'epoch': 0.52}
 52%|█████▏    | 5412/10395 [15:30:51<15:46:00, 11.39s/it] 52%|█████▏    | 5413/10395 [15:30:58<14:10:39, 10.24s/it]                                                          {'loss': 0.9169, 'learning_rate': 9.814624560125903e-06, 'epoch': 0.52}
 52%|█████▏    | 5413/10395 [15:30:58<14:10:39, 10.24s/it] 52%|█████▏    | 5414/10395 [15:31:15<16:55:18, 12.23s/it]                                                          {'loss': 0.3532, 'learning_rate': 9.811509372488805e-06, 'epoch': 0.52}
 52%|█████▏    | 5414/10395 [15:31:15<16:55:18, 12.23s/it] 52%|█████▏    | 5415/10395 [15:31:23<15:16:16, 11.04s/it]                                                          {'loss': 0.9152, 'learning_rate': 9.808394203149976e-06, 'epoch': 0.52}
 52%|█████▏    | 5415/10395 [15:31:23<15:16:16, 11.04s/it] 52%|█████▏    | 5416/10395 [15:31:31<13:55:01, 10.06s/it]                                                          {'loss': 0.9447, 'learning_rate': 9.805279052411829e-06, 'epoch': 0.52}
 52%|█████▏    | 5416/10395 [15:31:31<13:55:01, 10.06s/it] 52%|█████▏    | 5417/10395 [15:31:39<13:03:03,  9.44s/it]                                                          {'loss': 0.9028, 'learning_rate': 9.802163920576774e-06, 'epoch': 0.52}
 52%|█████▏    | 5417/10395 [15:31:39<13:03:03,  9.44s/it] 52%|█████▏    | 5418/10395 [15:31:47<12:23:18,  8.96s/it]                                                          {'loss': 0.8686, 'learning_rate': 9.799048807947222e-06, 'epoch': 0.52}
 52%|█████▏    | 5418/10395 [15:31:47<12:23:18,  8.96s/it] 52%|█████▏    | 5419/10395 [15:31:55<12:02:00,  8.71s/it]                                                          {'loss': 0.8833, 'learning_rate': 9.79593371482558e-06, 'epoch': 0.52}
 52%|█████▏    | 5419/10395 [15:31:55<12:02:00,  8.71s/it] 52%|█████▏    | 5420/10395 [15:32:03<11:33:12,  8.36s/it]                                                          {'loss': 0.9288, 'learning_rate': 9.79281864151426e-06, 'epoch': 0.52}
 52%|█████▏    | 5420/10395 [15:32:03<11:33:12,  8.36s/it] 52%|█████▏    | 5421/10395 [15:32:10<11:21:12,  8.22s/it]                                                          {'loss': 0.8896, 'learning_rate': 9.789703588315663e-06, 'epoch': 0.52}
 52%|█████▏    | 5421/10395 [15:32:10<11:21:12,  8.22s/it] 52%|█████▏    | 5422/10395 [15:32:19<11:18:28,  8.19s/it]                                                          {'loss': 0.9425, 'learning_rate': 9.786588555532192e-06, 'epoch': 0.52}
 52%|█████▏    | 5422/10395 [15:32:19<11:18:28,  8.19s/it] 52%|█████▏    | 5423/10395 [15:32:27<11:21:25,  8.22s/it]                                                          {'loss': 0.8863, 'learning_rate': 9.783473543466249e-06, 'epoch': 0.52}
 52%|█████▏    | 5423/10395 [15:32:27<11:21:25,  8.22s/it] 52%|█████▏    | 5424/10395 [15:32:34<11:02:44,  8.00s/it]                                                          {'loss': 0.9798, 'learning_rate': 9.780358552420233e-06, 'epoch': 0.52}
 52%|█████▏    | 5424/10395 [15:32:34<11:02:44,  8.00s/it] 52%|█████▏    | 5425/10395 [15:32:42<10:45:53,  7.80s/it]                                                          {'loss': 0.9452, 'learning_rate': 9.777243582696537e-06, 'epoch': 0.52}
 52%|█████▏    | 5425/10395 [15:32:42<10:45:53,  7.80s/it] 52%|█████▏    | 5426/10395 [15:32:49<10:38:15,  7.71s/it]                                                          {'loss': 0.9379, 'learning_rate': 9.774128634597558e-06, 'epoch': 0.52}
 52%|█████▏    | 5426/10395 [15:32:49<10:38:15,  7.71s/it] 52%|█████▏    | 5427/10395 [15:32:57<10:52:09,  7.88s/it]                                                          {'loss': 0.8256, 'learning_rate': 9.771013708425688e-06, 'epoch': 0.52}
 52%|█████▏    | 5427/10395 [15:32:57<10:52:09,  7.88s/it] 52%|█████▏    | 5428/10395 [15:33:05<10:55:19,  7.92s/it]                                                          {'loss': 0.9494, 'learning_rate': 9.767898804483317e-06, 'epoch': 0.52}
 52%|█████▏    | 5428/10395 [15:33:05<10:55:19,  7.92s/it] 52%|█████▏    | 5429/10395 [15:33:14<11:13:57,  8.14s/it]                                                          {'loss': 0.8971, 'learning_rate': 9.764783923072837e-06, 'epoch': 0.52}
 52%|█████▏    | 5429/10395 [15:33:14<11:13:57,  8.14s/it] 52%|█████▏    | 5430/10395 [15:33:22<11:01:25,  7.99s/it]                                                          {'loss': 0.9014, 'learning_rate': 9.76166906449663e-06, 'epoch': 0.52}
 52%|█████▏    | 5430/10395 [15:33:22<11:01:25,  7.99s/it] 52%|█████▏    | 5431/10395 [15:33:29<10:53:08,  7.89s/it]                                                          {'loss': 0.8454, 'learning_rate': 9.758554229057081e-06, 'epoch': 0.52}
 52%|█████▏    | 5431/10395 [15:33:29<10:53:08,  7.89s/it] 52%|█████▏    | 5432/10395 [15:33:38<11:11:46,  8.12s/it]                                                          {'loss': 0.8814, 'learning_rate': 9.755439417056573e-06, 'epoch': 0.52}
 52%|█████▏    | 5432/10395 [15:33:38<11:11:46,  8.12s/it] 52%|█████▏    | 5433/10395 [15:33:46<11:01:09,  7.99s/it]                                                          {'loss': 0.913, 'learning_rate': 9.75232462879748e-06, 'epoch': 0.52}
 52%|█████▏    | 5433/10395 [15:33:46<11:01:09,  7.99s/it] 52%|█████▏    | 5434/10395 [15:33:53<10:50:20,  7.87s/it]                                                          {'loss': 0.9499, 'learning_rate': 9.749209864582185e-06, 'epoch': 0.52}
 52%|█████▏    | 5434/10395 [15:33:53<10:50:20,  7.87s/it] 52%|█████▏    | 5435/10395 [15:34:02<11:12:38,  8.14s/it]                                                          {'loss': 0.7981, 'learning_rate': 9.746095124713058e-06, 'epoch': 0.52}
 52%|█████▏    | 5435/10395 [15:34:02<11:12:38,  8.14s/it] 52%|█████▏    | 5436/10395 [15:34:11<11:27:38,  8.32s/it]                                                          {'loss': 0.8232, 'learning_rate': 9.742980409492476e-06, 'epoch': 0.52}
 52%|█████▏    | 5436/10395 [15:34:11<11:27:38,  8.32s/it] 52%|█████▏    | 5437/10395 [15:34:19<11:16:00,  8.18s/it]                                                          {'loss': 0.9465, 'learning_rate': 9.739865719222806e-06, 'epoch': 0.52}
 52%|█████▏    | 5437/10395 [15:34:19<11:16:00,  8.18s/it] 52%|█████▏    | 5438/10395 [15:34:27<11:13:24,  8.15s/it]                                                          {'loss': 0.9925, 'learning_rate': 9.736751054206416e-06, 'epoch': 0.52}
 52%|█████▏    | 5438/10395 [15:34:27<11:13:24,  8.15s/it] 52%|█████▏    | 5439/10395 [15:34:34<10:52:51,  7.90s/it]                                                          {'loss': 0.933, 'learning_rate': 9.733636414745674e-06, 'epoch': 0.52}
 52%|█████▏    | 5439/10395 [15:34:34<10:52:51,  7.90s/it] 52%|█████▏    | 5440/10395 [15:34:42<10:55:08,  7.93s/it]                                                          {'loss': 0.8797, 'learning_rate': 9.730521801142939e-06, 'epoch': 0.52}
 52%|█████▏    | 5440/10395 [15:34:42<10:55:08,  7.93s/it] 52%|█████▏    | 5441/10395 [15:34:50<10:53:41,  7.92s/it]                                                          {'loss': 0.9264, 'learning_rate': 9.727407213700568e-06, 'epoch': 0.52}
 52%|█████▏    | 5441/10395 [15:34:50<10:53:41,  7.92s/it] 52%|█████▏    | 5442/10395 [15:34:58<10:54:07,  7.92s/it]                                                          {'loss': 0.8716, 'learning_rate': 9.724292652720922e-06, 'epoch': 0.52}
 52%|█████▏    | 5442/10395 [15:34:58<10:54:07,  7.92s/it] 52%|█████▏    | 5443/10395 [15:35:06<11:03:06,  8.03s/it]                                                          {'loss': 0.8795, 'learning_rate': 9.721178118506358e-06, 'epoch': 0.52}
 52%|█████▏    | 5443/10395 [15:35:06<11:03:06,  8.03s/it] 52%|█████▏    | 5444/10395 [15:35:14<10:46:58,  7.84s/it]                                                          {'loss': 0.9182, 'learning_rate': 9.718063611359226e-06, 'epoch': 0.52}
 52%|█████▏    | 5444/10395 [15:35:14<10:46:58,  7.84s/it] 52%|█████▏    | 5445/10395 [15:35:31<14:38:32, 10.65s/it]                                                          {'loss': 0.3833, 'learning_rate': 9.714949131581877e-06, 'epoch': 0.52}
 52%|█████▏    | 5445/10395 [15:35:31<14:38:32, 10.65s/it] 52%|█████▏    | 5446/10395 [15:35:38<13:22:19,  9.73s/it]                                                          {'loss': 0.9493, 'learning_rate': 9.71183467947666e-06, 'epoch': 0.52}
 52%|█████▏    | 5446/10395 [15:35:38<13:22:19,  9.73s/it] 52%|█████▏    | 5447/10395 [15:35:46<12:21:00,  8.99s/it]                                                          {'loss': 0.9111, 'learning_rate': 9.708720255345912e-06, 'epoch': 0.52}
 52%|█████▏    | 5447/10395 [15:35:46<12:21:00,  8.99s/it] 52%|█████▏    | 5448/10395 [15:35:53<11:40:52,  8.50s/it]                                                          {'loss': 0.9322, 'learning_rate': 9.705605859491981e-06, 'epoch': 0.52}
 52%|█████▏    | 5448/10395 [15:35:53<11:40:52,  8.50s/it] 52%|█████▏    | 5449/10395 [15:36:01<11:29:16,  8.36s/it]                                                          {'loss': 0.8869, 'learning_rate': 9.702491492217203e-06, 'epoch': 0.52}
 52%|█████▏    | 5449/10395 [15:36:01<11:29:16,  8.36s/it] 52%|█████▏    | 5450/10395 [15:36:09<11:23:38,  8.29s/it]                                                          {'loss': 0.8918, 'learning_rate': 9.699377153823913e-06, 'epoch': 0.52}
 52%|█████▏    | 5450/10395 [15:36:09<11:23:38,  8.29s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 52%|█████▏    | 5451/10395 [15:37:51<49:46:49, 36.25s/it]                                                          {'loss': 0.899, 'learning_rate': 9.69626284461445e-06, 'epoch': 0.52}
 52%|█████▏    | 5451/10395 [15:37:51<49:46:49, 36.25s/it] 52%|█████▏    | 5452/10395 [15:37:59<38:07:01, 27.76s/it]                                                          {'loss': 0.951, 'learning_rate': 9.69314856489114e-06, 'epoch': 0.52}
 52%|█████▏    | 5452/10395 [15:37:59<38:07:01, 27.76s/it] 52%|█████▏    | 5453/10395 [15:38:06<29:48:36, 21.72s/it]                                                          {'loss': 0.9176, 'learning_rate': 9.690034314956313e-06, 'epoch': 0.52}
 52%|█████▏    | 5453/10395 [15:38:06<29:48:36, 21.72s/it] 52%|█████▏    | 5454/10395 [15:38:14<23:51:47, 17.39s/it]                                                          {'loss': 0.9548, 'learning_rate': 9.686920095112291e-06, 'epoch': 0.52}
 52%|█████▏    | 5454/10395 [15:38:14<23:51:47, 17.39s/it] 52%|█████▏    | 5455/10395 [15:38:21<19:42:23, 14.36s/it]                                                          {'loss': 0.8645, 'learning_rate': 9.683805905661397e-06, 'epoch': 0.52}
 52%|█████▏    | 5455/10395 [15:38:21<19:42:23, 14.36s/it] 52%|█████▏    | 5456/10395 [15:38:29<17:06:23, 12.47s/it]                                                          {'loss': 0.8778, 'learning_rate': 9.68069174690595e-06, 'epoch': 0.52}
 52%|█████▏    | 5456/10395 [15:38:29<17:06:23, 12.47s/it] 52%|█████▏    | 5457/10395 [15:38:36<14:57:55, 10.91s/it]                                                          {'loss': 0.8896, 'learning_rate': 9.677577619148266e-06, 'epoch': 0.52}
 52%|█████▏    | 5457/10395 [15:38:36<14:57:55, 10.91s/it] 53%|█████▎    | 5458/10395 [15:38:45<14:17:40, 10.42s/it]                                                          {'loss': 0.8584, 'learning_rate': 9.674463522690656e-06, 'epoch': 0.53}
 53%|█████▎    | 5458/10395 [15:38:45<14:17:40, 10.42s/it] 53%|█████▎    | 5459/10395 [15:38:54<13:21:42,  9.75s/it]                                                          {'loss': 0.9022, 'learning_rate': 9.671349457835432e-06, 'epoch': 0.53}
 53%|█████▎    | 5459/10395 [15:38:54<13:21:42,  9.75s/it] 53%|█████▎    | 5460/10395 [15:39:01<12:26:47,  9.08s/it]                                                          {'loss': 0.9235, 'learning_rate': 9.668235424884902e-06, 'epoch': 0.53}
 53%|█████▎    | 5460/10395 [15:39:01<12:26:47,  9.08s/it] 53%|█████▎    | 5461/10395 [15:39:10<12:23:46,  9.04s/it]                                                          {'loss': 0.9126, 'learning_rate': 9.66512142414137e-06, 'epoch': 0.53}
 53%|█████▎    | 5461/10395 [15:39:10<12:23:46,  9.04s/it] 53%|█████▎    | 5462/10395 [15:39:18<12:01:39,  8.78s/it]                                                          {'loss': 0.8999, 'learning_rate': 9.662007455907131e-06, 'epoch': 0.53}
 53%|█████▎    | 5462/10395 [15:39:18<12:01:39,  8.78s/it] 53%|█████▎    | 5463/10395 [15:39:27<11:50:20,  8.64s/it]                                                          {'loss': 0.87, 'learning_rate': 9.658893520484486e-06, 'epoch': 0.53}
 53%|█████▎    | 5463/10395 [15:39:27<11:50:20,  8.64s/it] 53%|█████▎    | 5464/10395 [15:39:35<11:41:37,  8.54s/it]                                                          {'loss': 0.8749, 'learning_rate': 9.655779618175732e-06, 'epoch': 0.53}
 53%|█████▎    | 5464/10395 [15:39:35<11:41:37,  8.54s/it] 53%|█████▎    | 5465/10395 [15:39:42<11:07:13,  8.12s/it]                                                          {'loss': 0.8119, 'learning_rate': 9.652665749283154e-06, 'epoch': 0.53}
 53%|█████▎    | 5465/10395 [15:39:42<11:07:13,  8.12s/it] 53%|█████▎    | 5466/10395 [15:39:51<11:21:28,  8.30s/it]                                                          {'loss': 0.8492, 'learning_rate': 9.649551914109042e-06, 'epoch': 0.53}
 53%|█████▎    | 5466/10395 [15:39:51<11:21:28,  8.30s/it] 53%|█████▎    | 5467/10395 [15:39:58<10:59:43,  8.03s/it]                                                          {'loss': 0.9664, 'learning_rate': 9.646438112955681e-06, 'epoch': 0.53}
 53%|█████▎    | 5467/10395 [15:39:58<10:59:43,  8.03s/it] 53%|█████▎    | 5468/10395 [15:40:06<10:47:10,  7.88s/it]                                                          {'loss': 0.9634, 'learning_rate': 9.64332434612536e-06, 'epoch': 0.53}
 53%|█████▎    | 5468/10395 [15:40:06<10:47:10,  7.88s/it] 53%|█████▎    | 5469/10395 [15:40:13<10:40:22,  7.80s/it]                                                          {'loss': 0.9436, 'learning_rate': 9.640210613920341e-06, 'epoch': 0.53}
 53%|█████▎    | 5469/10395 [15:40:13<10:40:22,  7.80s/it] 53%|█████▎    | 5470/10395 [15:40:21<10:47:15,  7.89s/it]                                                          {'loss': 0.9032, 'learning_rate': 9.63709691664291e-06, 'epoch': 0.53}
 53%|█████▎    | 5470/10395 [15:40:21<10:47:15,  7.89s/it] 53%|█████▎    | 5471/10395 [15:40:29<10:40:22,  7.80s/it]                                                          {'loss': 0.9168, 'learning_rate': 9.633983254595334e-06, 'epoch': 0.53}
 53%|█████▎    | 5471/10395 [15:40:29<10:40:22,  7.80s/it] 53%|█████▎    | 5472/10395 [15:40:37<10:34:20,  7.73s/it]                                                          {'loss': 0.9093, 'learning_rate': 9.630869628079882e-06, 'epoch': 0.53}
 53%|█████▎    | 5472/10395 [15:40:37<10:34:20,  7.73s/it] 53%|█████▎    | 5473/10395 [15:40:54<14:25:07, 10.55s/it]                                                          {'loss': 0.4226, 'learning_rate': 9.627756037398816e-06, 'epoch': 0.53}
 53%|█████▎    | 5473/10395 [15:40:54<14:25:07, 10.55s/it] 53%|█████▎    | 5474/10395 [15:41:01<13:14:26,  9.69s/it]                                                          {'loss': 0.8986, 'learning_rate': 9.624642482854399e-06, 'epoch': 0.53}
 53%|█████▎    | 5474/10395 [15:41:01<13:14:26,  9.69s/it] 53%|█████▎    | 5475/10395 [15:41:09<12:32:19,  9.17s/it]                                                          {'loss': 0.9022, 'learning_rate': 9.621528964748891e-06, 'epoch': 0.53}
 53%|█████▎    | 5475/10395 [15:41:09<12:32:19,  9.17s/it] 53%|█████▎    | 5476/10395 [15:41:17<11:52:39,  8.69s/it]                                                          {'loss': 0.9051, 'learning_rate': 9.618415483384539e-06, 'epoch': 0.53}
 53%|█████▎    | 5476/10395 [15:41:17<11:52:39,  8.69s/it] 53%|█████▎    | 5477/10395 [15:41:25<11:46:48,  8.62s/it]                                                          {'loss': 0.8608, 'learning_rate': 9.615302039063597e-06, 'epoch': 0.53}
 53%|█████▎    | 5477/10395 [15:41:25<11:46:48,  8.62s/it] 53%|█████▎    | 5478/10395 [15:41:34<11:49:33,  8.66s/it]                                                          {'loss': 0.8706, 'learning_rate': 9.612188632088311e-06, 'epoch': 0.53}
 53%|█████▎    | 5478/10395 [15:41:34<11:49:33,  8.66s/it] 53%|█████▎    | 5479/10395 [15:41:42<11:24:03,  8.35s/it]                                                          {'loss': 0.8291, 'learning_rate': 9.609075262760922e-06, 'epoch': 0.53}
 53%|█████▎    | 5479/10395 [15:41:42<11:24:03,  8.35s/it] 53%|█████▎    | 5480/10395 [15:41:50<11:16:45,  8.26s/it]                                                          {'loss': 0.9154, 'learning_rate': 9.605961931383674e-06, 'epoch': 0.53}
 53%|█████▎    | 5480/10395 [15:41:50<11:16:45,  8.26s/it] 53%|█████▎    | 5481/10395 [15:41:57<10:57:10,  8.02s/it]                                                          {'loss': 0.9566, 'learning_rate': 9.602848638258798e-06, 'epoch': 0.53}
 53%|█████▎    | 5481/10395 [15:41:57<10:57:10,  8.02s/it] 53%|█████▎    | 5482/10395 [15:42:05<10:40:09,  7.82s/it]                                                          {'loss': 0.965, 'learning_rate': 9.599735383688527e-06, 'epoch': 0.53}
 53%|█████▎    | 5482/10395 [15:42:05<10:40:09,  7.82s/it] 53%|█████▎    | 5483/10395 [15:42:13<10:52:16,  7.97s/it]                                                          {'loss': 0.8424, 'learning_rate': 9.596622167975094e-06, 'epoch': 0.53}
 53%|█████▎    | 5483/10395 [15:42:13<10:52:16,  7.97s/it] 53%|█████▎    | 5484/10395 [15:42:20<10:31:41,  7.72s/it]                                                          {'loss': 0.9513, 'learning_rate': 9.593508991420715e-06, 'epoch': 0.53}
 53%|█████▎    | 5484/10395 [15:42:20<10:31:41,  7.72s/it] 53%|█████▎    | 5485/10395 [15:42:27<10:18:56,  7.56s/it]                                                          {'loss': 0.9333, 'learning_rate': 9.590395854327614e-06, 'epoch': 0.53}
 53%|█████▎    | 5485/10395 [15:42:27<10:18:56,  7.56s/it] 53%|█████▎    | 5486/10395 [15:42:35<10:35:18,  7.77s/it]                                                          {'loss': 0.945, 'learning_rate': 9.58728275699801e-06, 'epoch': 0.53}
 53%|█████▎    | 5486/10395 [15:42:35<10:35:18,  7.77s/it] 53%|█████▎    | 5487/10395 [15:42:54<14:53:40, 10.93s/it]                                                          {'loss': 0.3378, 'learning_rate': 9.584169699734113e-06, 'epoch': 0.53}
 53%|█████▎    | 5487/10395 [15:42:54<14:53:40, 10.93s/it] 53%|█████▎    | 5488/10395 [15:43:01<13:31:12,  9.92s/it]                                                          {'loss': 0.8892, 'learning_rate': 9.581056682838133e-06, 'epoch': 0.53}
 53%|█████▎    | 5488/10395 [15:43:01<13:31:12,  9.92s/it] 53%|█████▎    | 5489/10395 [15:43:09<12:40:34,  9.30s/it]                                                          {'loss': 0.9354, 'learning_rate': 9.577943706612272e-06, 'epoch': 0.53}
 53%|█████▎    | 5489/10395 [15:43:09<12:40:34,  9.30s/it] 53%|█████▎    | 5490/10395 [15:43:17<12:11:39,  8.95s/it]                                                          {'loss': 0.8749, 'learning_rate': 9.574830771358741e-06, 'epoch': 0.53}
 53%|█████▎    | 5490/10395 [15:43:17<12:11:39,  8.95s/it] 53%|█████▎    | 5491/10395 [15:43:25<11:41:03,  8.58s/it]                                                          {'loss': 0.9608, 'learning_rate': 9.571717877379727e-06, 'epoch': 0.53}
 53%|█████▎    | 5491/10395 [15:43:25<11:41:03,  8.58s/it] 53%|█████▎    | 5492/10395 [15:43:43<15:25:29, 11.33s/it]                                                          {'loss': 0.3574, 'learning_rate': 9.568605024977423e-06, 'epoch': 0.53}
 53%|█████▎    | 5492/10395 [15:43:43<15:25:29, 11.33s/it] 53%|█████▎    | 5493/10395 [15:43:52<14:23:16, 10.57s/it]                                                          {'loss': 0.9137, 'learning_rate': 9.565492214454022e-06, 'epoch': 0.53}
 53%|█████▎    | 5493/10395 [15:43:52<14:23:16, 10.57s/it] 53%|█████▎    | 5494/10395 [15:44:00<13:25:13,  9.86s/it]                                                          {'loss': 0.9177, 'learning_rate': 9.562379446111712e-06, 'epoch': 0.53}
 53%|█████▎    | 5494/10395 [15:44:00<13:25:13,  9.86s/it] 53%|█████▎    | 5495/10395 [15:44:08<12:40:28,  9.31s/it]                                                          {'loss': 0.8028, 'learning_rate': 9.559266720252666e-06, 'epoch': 0.53}
 53%|█████▎    | 5495/10395 [15:44:08<12:40:28,  9.31s/it] 53%|█████▎    | 5496/10395 [15:44:15<11:56:27,  8.77s/it]                                                          {'loss': 0.8719, 'learning_rate': 9.556154037179069e-06, 'epoch': 0.53}
 53%|█████▎    | 5496/10395 [15:44:15<11:56:27,  8.77s/it] 53%|█████▎    | 5497/10395 [15:44:23<11:18:23,  8.31s/it]                                                          {'loss': 0.9308, 'learning_rate': 9.553041397193089e-06, 'epoch': 0.53}
 53%|█████▎    | 5497/10395 [15:44:23<11:18:23,  8.31s/it] 53%|█████▎    | 5498/10395 [15:44:40<15:08:46, 11.13s/it]                                                          {'loss': 0.3804, 'learning_rate': 9.549928800596893e-06, 'epoch': 0.53}
 53%|█████▎    | 5498/10395 [15:44:40<15:08:46, 11.13s/it] 53%|█████▎    | 5499/10395 [15:44:48<13:54:33, 10.23s/it]                                                          {'loss': 0.9894, 'learning_rate': 9.54681624769265e-06, 'epoch': 0.53}
 53%|█████▎    | 5499/10395 [15:44:48<13:54:33, 10.23s/it] 53%|█████▎    | 5500/10395 [15:44:56<12:48:34,  9.42s/it]                                                          {'loss': 0.9067, 'learning_rate': 9.543703738782512e-06, 'epoch': 0.53}
 53%|█████▎    | 5500/10395 [15:44:56<12:48:34,  9.42s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 53%|█████▎    | 5501/10395 [15:46:37<50:02:26, 36.81s/it]                                                          {'loss': 0.8781, 'learning_rate': 9.540591274168643e-06, 'epoch': 0.53}
 53%|█████▎    | 5501/10395 [15:46:37<50:02:26, 36.81s/it] 53%|█████▎    | 5502/10395 [15:46:45<38:29:35, 28.32s/it]                                                          {'loss': 0.8237, 'learning_rate': 9.53747885415319e-06, 'epoch': 0.53}
 53%|█████▎    | 5502/10395 [15:46:45<38:29:35, 28.32s/it] 53%|█████▎    | 5503/10395 [15:46:53<29:58:15, 22.06s/it]                                                          {'loss': 0.9285, 'learning_rate': 9.534366479038304e-06, 'epoch': 0.53}
 53%|█████▎    | 5503/10395 [15:46:53<29:58:15, 22.06s/it] 53%|█████▎    | 5504/10395 [15:47:00<24:01:21, 17.68s/it]                                                          {'loss': 0.865, 'learning_rate': 9.531254149126124e-06, 'epoch': 0.53}
 53%|█████▎    | 5504/10395 [15:47:00<24:01:21, 17.68s/it] 53%|█████▎    | 5505/10395 [15:47:09<20:20:02, 14.97s/it]                                                          {'loss': 0.8822, 'learning_rate': 9.52814186471879e-06, 'epoch': 0.53}
 53%|█████▎    | 5505/10395 [15:47:09<20:20:02, 14.97s/it] 53%|█████▎    | 5506/10395 [15:47:25<20:54:59, 15.40s/it]                                                          {'loss': 0.3504, 'learning_rate': 9.525029626118436e-06, 'epoch': 0.53}
 53%|█████▎    | 5506/10395 [15:47:25<20:54:59, 15.40s/it] 53%|█████▎    | 5507/10395 [15:47:33<17:58:23, 13.24s/it]                                                          {'loss': 0.8651, 'learning_rate': 9.521917433627187e-06, 'epoch': 0.53}
 53%|█████▎    | 5507/10395 [15:47:33<17:58:23, 13.24s/it] 53%|█████▎    | 5508/10395 [15:47:41<15:51:52, 11.69s/it]                                                          {'loss': 0.7844, 'learning_rate': 9.518805287547175e-06, 'epoch': 0.53}
 53%|█████▎    | 5508/10395 [15:47:41<15:51:52, 11.69s/it] 53%|█████▎    | 5509/10395 [15:47:49<14:22:56, 10.60s/it]                                                          {'loss': 0.7874, 'learning_rate': 9.515693188180518e-06, 'epoch': 0.53}
 53%|█████▎    | 5509/10395 [15:47:49<14:22:56, 10.60s/it] 53%|█████▎    | 5510/10395 [15:47:57<13:14:04,  9.75s/it]                                                          {'loss': 0.9085, 'learning_rate': 9.512581135829328e-06, 'epoch': 0.53}
 53%|█████▎    | 5510/10395 [15:47:57<13:14:04,  9.75s/it] 53%|█████▎    | 5511/10395 [15:48:06<12:51:51,  9.48s/it]                                                          {'loss': 0.9383, 'learning_rate': 9.509469130795724e-06, 'epoch': 0.53}
 53%|█████▎    | 5511/10395 [15:48:06<12:51:51,  9.48s/it] 53%|█████▎    | 5512/10395 [15:48:15<12:37:57,  9.31s/it]                                                          {'loss': 0.8814, 'learning_rate': 9.506357173381807e-06, 'epoch': 0.53}
 53%|█████▎    | 5512/10395 [15:48:15<12:37:57,  9.31s/it] 53%|█████▎    | 5513/10395 [15:48:22<11:52:55,  8.76s/it]                                                          {'loss': 0.9268, 'learning_rate': 9.503245263889681e-06, 'epoch': 0.53}
 53%|█████▎    | 5513/10395 [15:48:22<11:52:55,  8.76s/it] 53%|█████▎    | 5514/10395 [15:48:33<12:33:26,  9.26s/it]                                                          {'loss': 0.8222, 'learning_rate': 9.500133402621442e-06, 'epoch': 0.53}
 53%|█████▎    | 5514/10395 [15:48:33<12:33:26,  9.26s/it] 53%|█████▎    | 5515/10395 [15:48:41<11:56:18,  8.81s/it]                                                          {'loss': 0.9856, 'learning_rate': 9.497021589879182e-06, 'epoch': 0.53}
 53%|█████▎    | 5515/10395 [15:48:41<11:56:18,  8.81s/it] 53%|█████▎    | 5516/10395 [15:48:49<11:39:09,  8.60s/it]                                                          {'loss': 0.9507, 'learning_rate': 9.493909825964994e-06, 'epoch': 0.53}
 53%|█████▎    | 5516/10395 [15:48:49<11:39:09,  8.60s/it] 53%|█████▎    | 5517/10395 [15:48:56<11:08:10,  8.22s/it]                                                          {'loss': 0.9307, 'learning_rate': 9.490798111180957e-06, 'epoch': 0.53}
 53%|█████▎    | 5517/10395 [15:48:56<11:08:10,  8.22s/it] 53%|█████▎    | 5518/10395 [15:49:04<10:53:34,  8.04s/it]                                                          {'loss': 0.8954, 'learning_rate': 9.487686445829153e-06, 'epoch': 0.53}
 53%|█████▎    | 5518/10395 [15:49:04<10:53:34,  8.04s/it] 53%|█████▎    | 5519/10395 [15:49:11<10:41:53,  7.90s/it]                                                          {'loss': 0.9736, 'learning_rate': 9.484574830211655e-06, 'epoch': 0.53}
 53%|█████▎    | 5519/10395 [15:49:11<10:41:53,  7.90s/it] 53%|█████▎    | 5520/10395 [15:49:19<10:37:20,  7.84s/it]                                                          {'loss': 0.9236, 'learning_rate': 9.48146326463053e-06, 'epoch': 0.53}
 53%|█████▎    | 5520/10395 [15:49:19<10:37:20,  7.84s/it] 53%|█████▎    | 5521/10395 [15:49:28<11:11:54,  8.27s/it]                                                          {'loss': 0.8841, 'learning_rate': 9.478351749387843e-06, 'epoch': 0.53}
 53%|█████▎    | 5521/10395 [15:49:28<11:11:54,  8.27s/it] 53%|█████▎    | 5522/10395 [15:49:35<10:43:10,  7.92s/it]                                                          {'loss': 0.8746, 'learning_rate': 9.475240284785653e-06, 'epoch': 0.53}
 53%|█████▎    | 5522/10395 [15:49:35<10:43:10,  7.92s/it]WARNING: tokenization mismatch: 1 vs. 1590. (ignored)
 53%|█████▎    | 5523/10395 [15:49:43<10:45:28,  7.95s/it]                                                          {'loss': 0.9088, 'learning_rate': 9.472128871126014e-06, 'epoch': 0.53}
 53%|█████▎    | 5523/10395 [15:49:43<10:45:28,  7.95s/it] 53%|█████▎    | 5524/10395 [15:49:50<10:22:37,  7.67s/it]                                                          {'loss': 0.963, 'learning_rate': 9.469017508710976e-06, 'epoch': 0.53}
 53%|█████▎    | 5524/10395 [15:49:50<10:22:37,  7.67s/it] 53%|█████▎    | 5525/10395 [15:50:08<14:34:55, 10.78s/it]                                                          {'loss': 0.4069, 'learning_rate': 9.465906197842583e-06, 'epoch': 0.53}
 53%|█████▎    | 5525/10395 [15:50:08<14:34:55, 10.78s/it] 53%|█████▎    | 5526/10395 [15:50:16<13:15:26,  9.80s/it]                                                          {'loss': 0.871, 'learning_rate': 9.462794938822878e-06, 'epoch': 0.53}
 53%|█████▎    | 5526/10395 [15:50:16<13:15:26,  9.80s/it] 53%|█████▎    | 5527/10395 [15:50:24<12:28:48,  9.23s/it]                                                          {'loss': 0.916, 'learning_rate': 9.459683731953891e-06, 'epoch': 0.53}
 53%|█████▎    | 5527/10395 [15:50:24<12:28:48,  9.23s/it] 53%|█████▎    | 5528/10395 [15:50:33<12:28:24,  9.23s/it]                                                          {'loss': 0.9727, 'learning_rate': 9.456572577537653e-06, 'epoch': 0.53}
 53%|█████▎    | 5528/10395 [15:50:33<12:28:24,  9.23s/it] 53%|█████▎    | 5529/10395 [15:50:40<11:41:47,  8.65s/it]                                                          {'loss': 0.9349, 'learning_rate': 9.453461475876188e-06, 'epoch': 0.53}
 53%|█████▎    | 5529/10395 [15:50:40<11:41:47,  8.65s/it] 53%|█████▎    | 5530/10395 [15:50:48<11:13:16,  8.30s/it]                                                          {'loss': 0.9414, 'learning_rate': 9.450350427271513e-06, 'epoch': 0.53}
 53%|█████▎    | 5530/10395 [15:50:48<11:13:16,  8.30s/it] 53%|█████▎    | 5531/10395 [15:50:55<10:52:45,  8.05s/it]                                                          {'loss': 0.9354, 'learning_rate': 9.447239432025643e-06, 'epoch': 0.53}
 53%|█████▎    | 5531/10395 [15:50:55<10:52:45,  8.05s/it] 53%|█████▎    | 5532/10395 [15:51:03<10:50:44,  8.03s/it]                                                          {'loss': 0.8961, 'learning_rate': 9.44412849044059e-06, 'epoch': 0.53}
 53%|█████▎    | 5532/10395 [15:51:03<10:50:44,  8.03s/it] 53%|█████▎    | 5533/10395 [15:51:11<10:53:22,  8.06s/it]                                                          {'loss': 0.8777, 'learning_rate': 9.441017602818356e-06, 'epoch': 0.53}
 53%|█████▎    | 5533/10395 [15:51:11<10:53:22,  8.06s/it] 53%|█████▎    | 5534/10395 [15:51:19<10:38:33,  7.88s/it]                                                          {'loss': 0.952, 'learning_rate': 9.437906769460938e-06, 'epoch': 0.53}
 53%|█████▎    | 5534/10395 [15:51:19<10:38:33,  7.88s/it] 53%|█████▎    | 5535/10395 [15:51:27<10:40:59,  7.91s/it]                                                          {'loss': 0.9967, 'learning_rate': 9.43479599067033e-06, 'epoch': 0.53}
 53%|█████▎    | 5535/10395 [15:51:27<10:40:59,  7.91s/it] 53%|█████▎    | 5536/10395 [15:51:34<10:24:04,  7.71s/it]                                                          {'loss': 0.9348, 'learning_rate': 9.431685266748517e-06, 'epoch': 0.53}
 53%|█████▎    | 5536/10395 [15:51:34<10:24:04,  7.71s/it] 53%|█████▎    | 5537/10395 [15:51:44<11:07:42,  8.25s/it]                                                          {'loss': 0.8749, 'learning_rate': 9.428574597997487e-06, 'epoch': 0.53}
 53%|█████▎    | 5537/10395 [15:51:44<11:07:42,  8.25s/it] 53%|█████▎    | 5538/10395 [15:51:52<11:14:59,  8.34s/it]                                                          {'loss': 0.8364, 'learning_rate': 9.425463984719212e-06, 'epoch': 0.53}
 53%|█████▎    | 5538/10395 [15:51:52<11:14:59,  8.34s/it] 53%|█████▎    | 5539/10395 [15:52:01<11:22:37,  8.43s/it]                                                          {'loss': 0.9258, 'learning_rate': 9.422353427215664e-06, 'epoch': 0.53}
 53%|█████▎    | 5539/10395 [15:52:01<11:22:37,  8.43s/it] 53%|█████▎    | 5540/10395 [15:52:08<11:00:57,  8.17s/it]                                                          {'loss': 0.8879, 'learning_rate': 9.419242925788813e-06, 'epoch': 0.53}
 53%|█████▎    | 5540/10395 [15:52:08<11:00:57,  8.17s/it] 53%|█████▎    | 5541/10395 [15:52:16<10:47:45,  8.01s/it]                                                          {'loss': 0.906, 'learning_rate': 9.416132480740619e-06, 'epoch': 0.53}
 53%|█████▎    | 5541/10395 [15:52:16<10:47:45,  8.01s/it] 53%|█████▎    | 5542/10395 [15:52:23<10:28:24,  7.77s/it]                                                          {'loss': 0.9104, 'learning_rate': 9.413022092373034e-06, 'epoch': 0.53}
 53%|█████▎    | 5542/10395 [15:52:23<10:28:24,  7.77s/it] 53%|█████▎    | 5543/10395 [15:52:31<10:25:41,  7.74s/it]                                                          {'loss': 0.8737, 'learning_rate': 9.409911760988011e-06, 'epoch': 0.53}
 53%|█████▎    | 5543/10395 [15:52:31<10:25:41,  7.74s/it] 53%|█████▎    | 5544/10395 [15:52:40<10:52:08,  8.07s/it]                                                          {'loss': 0.9592, 'learning_rate': 9.406801486887493e-06, 'epoch': 0.53}
 53%|█████▎    | 5544/10395 [15:52:40<10:52:08,  8.07s/it] 53%|█████▎    | 5545/10395 [15:52:48<10:55:52,  8.11s/it]                                                          {'loss': 0.8853, 'learning_rate': 9.403691270373418e-06, 'epoch': 0.53}
 53%|█████▎    | 5545/10395 [15:52:48<10:55:52,  8.11s/it] 53%|█████▎    | 5546/10395 [15:52:58<11:31:06,  8.55s/it]                                                          {'loss': 0.8628, 'learning_rate': 9.40058111174772e-06, 'epoch': 0.53}
 53%|█████▎    | 5546/10395 [15:52:58<11:31:06,  8.55s/it] 53%|█████▎    | 5547/10395 [15:53:07<11:56:32,  8.87s/it]                                                          {'loss': 0.875, 'learning_rate': 9.397471011312325e-06, 'epoch': 0.53}
 53%|█████▎    | 5547/10395 [15:53:07<11:56:32,  8.87s/it] 53%|█████▎    | 5548/10395 [15:53:16<11:50:40,  8.80s/it]                                                          {'loss': 0.9039, 'learning_rate': 9.39436096936916e-06, 'epoch': 0.53}
 53%|█████▎    | 5548/10395 [15:53:16<11:50:40,  8.80s/it] 53%|█████▎    | 5549/10395 [15:53:24<11:29:24,  8.54s/it]                                                          {'loss': 0.8635, 'learning_rate': 9.391250986220138e-06, 'epoch': 0.53}
 53%|█████▎    | 5549/10395 [15:53:24<11:29:24,  8.54s/it] 53%|█████▎    | 5550/10395 [15:53:32<11:20:12,  8.42s/it]                                                          {'loss': 0.9031, 'learning_rate': 9.388141062167168e-06, 'epoch': 0.53}
 53%|█████▎    | 5550/10395 [15:53:32<11:20:12,  8.42s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 53%|█████▎    | 5551/10395 [15:55:11<48:07:37, 35.77s/it]                                                          {'loss': 0.806, 'learning_rate': 9.385031197512158e-06, 'epoch': 0.53}
 53%|█████▎    | 5551/10395 [15:55:11<48:07:37, 35.77s/it] 53%|█████▎    | 5552/10395 [15:55:20<37:20:07, 27.75s/it]                                                          {'loss': 0.8634, 'learning_rate': 9.381921392557003e-06, 'epoch': 0.53}
 53%|█████▎    | 5552/10395 [15:55:20<37:20:07, 27.75s/it] 53%|█████▎    | 5553/10395 [15:55:28<29:10:43, 21.69s/it]                                                          {'loss': 0.9251, 'learning_rate': 9.378811647603598e-06, 'epoch': 0.53}
 53%|█████▎    | 5553/10395 [15:55:28<29:10:43, 21.69s/it] 53%|█████▎    | 5554/10395 [15:55:46<27:41:22, 20.59s/it]                                                          {'loss': 0.3934, 'learning_rate': 9.375701962953831e-06, 'epoch': 0.53}
 53%|█████▎    | 5554/10395 [15:55:46<27:41:22, 20.59s/it] 53%|█████▎    | 5555/10395 [15:55:54<22:29:40, 16.73s/it]                                                          {'loss': 0.8727, 'learning_rate': 9.372592338909584e-06, 'epoch': 0.53}
 53%|█████▎    | 5555/10395 [15:55:54<22:29:40, 16.73s/it] 53%|█████▎    | 5556/10395 [15:56:02<19:03:03, 14.17s/it]                                                          {'loss': 0.907, 'learning_rate': 9.369482775772734e-06, 'epoch': 0.53}
 53%|█████▎    | 5556/10395 [15:56:02<19:03:03, 14.17s/it] 53%|█████▎    | 5557/10395 [15:56:10<16:40:06, 12.40s/it]                                                          {'loss': 0.8953, 'learning_rate': 9.366373273845145e-06, 'epoch': 0.53}
 53%|█████▎    | 5557/10395 [15:56:10<16:40:06, 12.40s/it] 53%|█████▎    | 5558/10395 [15:56:18<14:38:10, 10.89s/it]                                                          {'loss': 0.9914, 'learning_rate': 9.363263833428686e-06, 'epoch': 0.53}
 53%|█████▎    | 5558/10395 [15:56:18<14:38:10, 10.89s/it] 53%|█████▎    | 5559/10395 [15:56:25<13:17:10,  9.89s/it]                                                          {'loss': 0.8564, 'learning_rate': 9.360154454825215e-06, 'epoch': 0.53}
 53%|█████▎    | 5559/10395 [15:56:25<13:17:10,  9.89s/it] 53%|█████▎    | 5560/10395 [15:56:33<12:22:53,  9.22s/it]                                                          {'loss': 0.9106, 'learning_rate': 9.35704513833658e-06, 'epoch': 0.53}
 53%|█████▎    | 5560/10395 [15:56:33<12:22:53,  9.22s/it] 53%|█████▎    | 5561/10395 [15:56:40<11:39:09,  8.68s/it]                                                          {'loss': 0.9171, 'learning_rate': 9.353935884264629e-06, 'epoch': 0.53}
 53%|█████▎    | 5561/10395 [15:56:40<11:39:09,  8.68s/it] 54%|█████▎    | 5562/10395 [15:56:48<11:07:57,  8.29s/it]                                                          {'loss': 0.9883, 'learning_rate': 9.350826692911201e-06, 'epoch': 0.54}
 54%|█████▎    | 5562/10395 [15:56:48<11:07:57,  8.29s/it] 54%|█████▎    | 5563/10395 [15:56:56<11:11:43,  8.34s/it]                                                          {'loss': 0.9177, 'learning_rate': 9.347717564578136e-06, 'epoch': 0.54}
 54%|█████▎    | 5563/10395 [15:56:56<11:11:43,  8.34s/it] 54%|█████▎    | 5564/10395 [15:57:04<11:01:26,  8.21s/it]                                                          {'loss': 0.8915, 'learning_rate': 9.344608499567251e-06, 'epoch': 0.54}
 54%|█████▎    | 5564/10395 [15:57:04<11:01:26,  8.21s/it] 54%|█████▎    | 5565/10395 [15:57:12<10:44:56,  8.01s/it]                                                          {'loss': 0.8992, 'learning_rate': 9.34149949818037e-06, 'epoch': 0.54}
 54%|█████▎    | 5565/10395 [15:57:12<10:44:56,  8.01s/it] 54%|█████▎    | 5566/10395 [15:57:19<10:39:55,  7.95s/it]                                                          {'loss': 0.8683, 'learning_rate': 9.338390560719314e-06, 'epoch': 0.54}
 54%|█████▎    | 5566/10395 [15:57:19<10:39:55,  7.95s/it] 54%|█████▎    | 5567/10395 [15:57:27<10:30:54,  7.84s/it]                                                          {'loss': 0.8677, 'learning_rate': 9.335281687485887e-06, 'epoch': 0.54}
 54%|█████▎    | 5567/10395 [15:57:27<10:30:54,  7.84s/it] 54%|█████▎    | 5568/10395 [15:57:35<10:25:33,  7.78s/it]                                                          {'loss': 1.0185, 'learning_rate': 9.332172878781896e-06, 'epoch': 0.54}
 54%|█████▎    | 5568/10395 [15:57:35<10:25:33,  7.78s/it] 54%|█████▎    | 5569/10395 [15:57:43<10:40:38,  7.96s/it]                                                          {'loss': 0.8319, 'learning_rate': 9.329064134909131e-06, 'epoch': 0.54}
 54%|█████▎    | 5569/10395 [15:57:43<10:40:38,  7.96s/it] 54%|█████▎    | 5570/10395 [15:57:50<10:26:53,  7.80s/it]                                                          {'loss': 0.9113, 'learning_rate': 9.325955456169386e-06, 'epoch': 0.54}
 54%|█████▎    | 5570/10395 [15:57:50<10:26:53,  7.80s/it] 54%|█████▎    | 5571/10395 [15:57:58<10:16:12,  7.66s/it]                                                          {'loss': 0.8797, 'learning_rate': 9.322846842864452e-06, 'epoch': 0.54}
 54%|█████▎    | 5571/10395 [15:57:58<10:16:12,  7.66s/it] 54%|█████▎    | 5572/10395 [15:58:06<10:29:35,  7.83s/it]                                                          {'loss': 0.8591, 'learning_rate': 9.319738295296094e-06, 'epoch': 0.54}
 54%|█████▎    | 5572/10395 [15:58:06<10:29:35,  7.83s/it] 54%|█████▎    | 5573/10395 [15:58:14<10:25:45,  7.79s/it]                                                          {'loss': 0.9376, 'learning_rate': 9.316629813766087e-06, 'epoch': 0.54}
 54%|█████▎    | 5573/10395 [15:58:14<10:25:45,  7.79s/it] 54%|█████▎    | 5574/10395 [15:58:31<14:29:03, 10.82s/it]                                                          {'loss': 0.3862, 'learning_rate': 9.313521398576199e-06, 'epoch': 0.54}
 54%|█████▎    | 5574/10395 [15:58:32<14:29:03, 10.82s/it] 54%|█████▎    | 5575/10395 [15:58:39<13:04:24,  9.76s/it]                                                          {'loss': 0.9478, 'learning_rate': 9.310413050028187e-06, 'epoch': 0.54}
 54%|█████▎    | 5575/10395 [15:58:39<13:04:24,  9.76s/it] 54%|█████▎    | 5576/10395 [15:58:48<12:39:34,  9.46s/it]                                                          {'loss': 0.9442, 'learning_rate': 9.307304768423801e-06, 'epoch': 0.54}
 54%|█████▎    | 5576/10395 [15:58:48<12:39:34,  9.46s/it] 54%|█████▎    | 5577/10395 [15:58:56<12:19:57,  9.21s/it]                                                          {'loss': 0.8532, 'learning_rate': 9.304196554064787e-06, 'epoch': 0.54}
 54%|█████▎    | 5577/10395 [15:58:56<12:19:57,  9.21s/it] 54%|█████▎    | 5578/10395 [15:59:04<11:41:36,  8.74s/it]                                                          {'loss': 0.8453, 'learning_rate': 9.30108840725289e-06, 'epoch': 0.54}
 54%|█████▎    | 5578/10395 [15:59:04<11:41:36,  8.74s/it] 54%|█████▎    | 5579/10395 [15:59:11<11:06:52,  8.31s/it]                                                          {'loss': 0.8664, 'learning_rate': 9.297980328289835e-06, 'epoch': 0.54}
 54%|█████▎    | 5579/10395 [15:59:11<11:06:52,  8.31s/it] 54%|█████▎    | 5580/10395 [15:59:19<10:56:43,  8.18s/it]                                                          {'loss': 0.9074, 'learning_rate': 9.294872317477345e-06, 'epoch': 0.54}
 54%|█████▎    | 5580/10395 [15:59:19<10:56:43,  8.18s/it] 54%|█████▎    | 5581/10395 [15:59:36<14:39:44, 10.96s/it]                                                          {'loss': 0.445, 'learning_rate': 9.291764375117146e-06, 'epoch': 0.54}
 54%|█████▎    | 5581/10395 [15:59:36<14:39:44, 10.96s/it] 54%|█████▎    | 5582/10395 [15:59:44<13:23:35, 10.02s/it]                                                          {'loss': 0.9639, 'learning_rate': 9.288656501510948e-06, 'epoch': 0.54}
 54%|█████▎    | 5582/10395 [15:59:44<13:23:35, 10.02s/it] 54%|█████▎    | 5583/10395 [15:59:52<12:38:10,  9.45s/it]                                                          {'loss': 0.8698, 'learning_rate': 9.285548696960458e-06, 'epoch': 0.54}
 54%|█████▎    | 5583/10395 [15:59:52<12:38:10,  9.45s/it] 54%|█████▎    | 5584/10395 [16:00:01<12:06:27,  9.06s/it]                                                          {'loss': 0.8999, 'learning_rate': 9.282440961767372e-06, 'epoch': 0.54}
 54%|█████▎    | 5584/10395 [16:00:01<12:06:27,  9.06s/it] 54%|█████▎    | 5585/10395 [16:00:08<11:23:05,  8.52s/it]                                                          {'loss': 0.9097, 'learning_rate': 9.279333296233386e-06, 'epoch': 0.54}
 54%|█████▎    | 5585/10395 [16:00:08<11:23:05,  8.52s/it] 54%|█████▎    | 5586/10395 [16:00:16<11:09:06,  8.35s/it]                                                          {'loss': 0.9575, 'learning_rate': 9.276225700660185e-06, 'epoch': 0.54}
 54%|█████▎    | 5586/10395 [16:00:16<11:09:06,  8.35s/it] 54%|█████▎    | 5587/10395 [16:00:23<10:48:27,  8.09s/it]                                                          {'loss': 0.9059, 'learning_rate': 9.273118175349442e-06, 'epoch': 0.54}
 54%|█████▎    | 5587/10395 [16:00:23<10:48:27,  8.09s/it] 54%|█████▍    | 5588/10395 [16:00:30<10:25:08,  7.80s/it]                                                          {'loss': 1.0199, 'learning_rate': 9.270010720602833e-06, 'epoch': 0.54}
 54%|█████▍    | 5588/10395 [16:00:30<10:25:08,  7.80s/it] 54%|█████▍    | 5589/10395 [16:00:39<10:48:36,  8.10s/it]                                                          {'loss': 0.7777, 'learning_rate': 9.266903336722025e-06, 'epoch': 0.54}
 54%|█████▍    | 5589/10395 [16:00:39<10:48:36,  8.10s/it] 54%|█████▍    | 5590/10395 [16:00:47<10:34:15,  7.92s/it]                                                          {'loss': 1.0452, 'learning_rate': 9.263796024008675e-06, 'epoch': 0.54}
 54%|█████▍    | 5590/10395 [16:00:47<10:34:15,  7.92s/it] 54%|█████▍    | 5591/10395 [16:00:54<10:17:35,  7.71s/it]                                                          {'loss': 0.9259, 'learning_rate': 9.260688782764432e-06, 'epoch': 0.54}
 54%|█████▍    | 5591/10395 [16:00:54<10:17:35,  7.71s/it] 54%|█████▍    | 5592/10395 [16:01:02<10:18:02,  7.72s/it]                                                          {'loss': 0.9483, 'learning_rate': 9.257581613290943e-06, 'epoch': 0.54}
 54%|█████▍    | 5592/10395 [16:01:02<10:18:02,  7.72s/it] 54%|█████▍    | 5593/10395 [16:01:09<10:12:03,  7.65s/it]                                                          {'loss': 0.9149, 'learning_rate': 9.254474515889848e-06, 'epoch': 0.54}
 54%|█████▍    | 5593/10395 [16:01:09<10:12:03,  7.65s/it] 54%|█████▍    | 5594/10395 [16:01:17<10:16:29,  7.70s/it]                                                          {'loss': 0.9093, 'learning_rate': 9.25136749086277e-06, 'epoch': 0.54}
 54%|█████▍    | 5594/10395 [16:01:17<10:16:29,  7.70s/it] 54%|█████▍    | 5595/10395 [16:01:26<10:44:49,  8.06s/it]                                                          {'loss': 0.8526, 'learning_rate': 9.248260538511337e-06, 'epoch': 0.54}
 54%|█████▍    | 5595/10395 [16:01:26<10:44:49,  8.06s/it] 54%|█████▍    | 5596/10395 [16:01:33<10:30:12,  7.88s/it]                                                          {'loss': 0.8786, 'learning_rate': 9.245153659137162e-06, 'epoch': 0.54}
 54%|█████▍    | 5596/10395 [16:01:33<10:30:12,  7.88s/it] 54%|█████▍    | 5597/10395 [16:01:41<10:21:11,  7.77s/it]                                                          {'loss': 0.9405, 'learning_rate': 9.242046853041858e-06, 'epoch': 0.54}
 54%|█████▍    | 5597/10395 [16:01:41<10:21:11,  7.77s/it] 54%|█████▍    | 5598/10395 [16:01:48<10:10:37,  7.64s/it]                                                          {'loss': 0.9558, 'learning_rate': 9.238940120527027e-06, 'epoch': 0.54}
 54%|█████▍    | 5598/10395 [16:01:48<10:10:37,  7.64s/it] 54%|█████▍    | 5599/10395 [16:01:56<10:26:06,  7.83s/it]                                                          {'loss': 0.893, 'learning_rate': 9.235833461894262e-06, 'epoch': 0.54}
 54%|█████▍    | 5599/10395 [16:01:56<10:26:06,  7.83s/it] 54%|█████▍    | 5600/10395 [16:02:04<10:20:32,  7.76s/it]                                                          {'loss': 0.9473, 'learning_rate': 9.232726877445154e-06, 'epoch': 0.54}
 54%|█████▍    | 5600/10395 [16:02:04<10:20:32,  7.76s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 54%|█████▍    | 5601/10395 [16:03:44<47:00:54, 35.31s/it]                                                          {'loss': 0.9227, 'learning_rate': 9.229620367481279e-06, 'epoch': 0.54}
 54%|█████▍    | 5601/10395 [16:03:44<47:00:54, 35.31s/it] 54%|█████▍    | 5602/10395 [16:03:51<35:56:05, 26.99s/it]                                                          {'loss': 0.9531, 'learning_rate': 9.22651393230421e-06, 'epoch': 0.54}
 54%|█████▍    | 5602/10395 [16:03:51<35:56:05, 26.99s/it] 54%|█████▍    | 5603/10395 [16:03:59<28:16:55, 21.25s/it]                                                          {'loss': 0.9235, 'learning_rate': 9.22340757221552e-06, 'epoch': 0.54}
 54%|█████▍    | 5603/10395 [16:03:59<28:16:55, 21.25s/it] 54%|█████▍    | 5604/10395 [16:04:07<22:59:10, 17.27s/it]                                                          {'loss': 0.8535, 'learning_rate': 9.220301287516757e-06, 'epoch': 0.54}
 54%|█████▍    | 5604/10395 [16:04:07<22:59:10, 17.27s/it] 54%|█████▍    | 5605/10395 [16:04:15<19:09:08, 14.39s/it]                                                          {'loss': 0.8988, 'learning_rate': 9.217195078509483e-06, 'epoch': 0.54}
 54%|█████▍    | 5605/10395 [16:04:15<19:09:08, 14.39s/it] 54%|█████▍    | 5606/10395 [16:04:24<17:15:09, 12.97s/it]                                                          {'loss': 0.8147, 'learning_rate': 9.21408894549524e-06, 'epoch': 0.54}
 54%|█████▍    | 5606/10395 [16:04:24<17:15:09, 12.97s/it] 54%|█████▍    | 5607/10395 [16:04:32<15:14:12, 11.46s/it]                                                          {'loss': 0.9518, 'learning_rate': 9.210982888775559e-06, 'epoch': 0.54}
 54%|█████▍    | 5607/10395 [16:04:32<15:14:12, 11.46s/it] 54%|█████▍    | 5608/10395 [16:04:40<13:40:55, 10.29s/it]                                                          {'loss': 0.9245, 'learning_rate': 9.207876908651977e-06, 'epoch': 0.54}
 54%|█████▍    | 5608/10395 [16:04:40<13:40:55, 10.29s/it] 54%|█████▍    | 5609/10395 [16:04:47<12:32:24,  9.43s/it]                                                          {'loss': 1.0145, 'learning_rate': 9.20477100542601e-06, 'epoch': 0.54}
 54%|█████▍    | 5609/10395 [16:04:47<12:32:24,  9.43s/it] 54%|█████▍    | 5610/10395 [16:04:55<11:48:53,  8.89s/it]                                                          {'loss': 0.8379, 'learning_rate': 9.201665179399172e-06, 'epoch': 0.54}
 54%|█████▍    | 5610/10395 [16:04:55<11:48:53,  8.89s/it] 54%|█████▍    | 5611/10395 [16:05:02<11:09:36,  8.40s/it]                                                          {'loss': 0.9021, 'learning_rate': 9.198559430872972e-06, 'epoch': 0.54}
 54%|█████▍    | 5611/10395 [16:05:02<11:09:36,  8.40s/it] 54%|█████▍    | 5612/10395 [16:05:10<10:50:32,  8.16s/it]                                                          {'loss': 0.8899, 'learning_rate': 9.195453760148912e-06, 'epoch': 0.54}
 54%|█████▍    | 5612/10395 [16:05:10<10:50:32,  8.16s/it] 54%|█████▍    | 5613/10395 [16:05:17<10:38:46,  8.01s/it]                                                          {'loss': 0.9125, 'learning_rate': 9.192348167528482e-06, 'epoch': 0.54}
 54%|█████▍    | 5613/10395 [16:05:17<10:38:46,  8.01s/it] 54%|█████▍    | 5614/10395 [16:05:25<10:20:03,  7.78s/it]                                                          {'loss': 0.8708, 'learning_rate': 9.189242653313165e-06, 'epoch': 0.54}
 54%|█████▍    | 5614/10395 [16:05:25<10:20:03,  7.78s/it] 54%|█████▍    | 5615/10395 [16:05:34<10:47:33,  8.13s/it]                                                          {'loss': 0.8054, 'learning_rate': 9.18613721780444e-06, 'epoch': 0.54}
 54%|█████▍    | 5615/10395 [16:05:34<10:47:33,  8.13s/it] 54%|█████▍    | 5616/10395 [16:05:42<10:46:17,  8.11s/it]                                                          {'loss': 0.895, 'learning_rate': 9.183031861303773e-06, 'epoch': 0.54}
 54%|█████▍    | 5616/10395 [16:05:42<10:46:17,  8.11s/it] 54%|█████▍    | 5617/10395 [16:05:49<10:35:56,  7.99s/it]                                                          {'loss': 0.9559, 'learning_rate': 9.179926584112629e-06, 'epoch': 0.54}
 54%|█████▍    | 5617/10395 [16:05:49<10:35:56,  7.99s/it] 54%|█████▍    | 5618/10395 [16:05:57<10:32:16,  7.94s/it]                                                          {'loss': 0.946, 'learning_rate': 9.176821386532458e-06, 'epoch': 0.54}
 54%|█████▍    | 5618/10395 [16:05:57<10:32:16,  7.94s/it] 54%|█████▍    | 5619/10395 [16:06:05<10:35:29,  7.98s/it]                                                          {'loss': 0.9212, 'learning_rate': 9.173716268864706e-06, 'epoch': 0.54}
 54%|█████▍    | 5619/10395 [16:06:05<10:35:29,  7.98s/it] 54%|█████▍    | 5620/10395 [16:06:13<10:27:13,  7.88s/it]                                                          {'loss': 0.9455, 'learning_rate': 9.170611231410816e-06, 'epoch': 0.54}
 54%|█████▍    | 5620/10395 [16:06:13<10:27:13,  7.88s/it] 54%|█████▍    | 5621/10395 [16:06:21<10:37:15,  8.01s/it]                                                          {'loss': 0.9283, 'learning_rate': 9.167506274472214e-06, 'epoch': 0.54}
 54%|█████▍    | 5621/10395 [16:06:21<10:37:15,  8.01s/it] 54%|█████▍    | 5622/10395 [16:06:29<10:20:25,  7.80s/it]                                                          {'loss': 0.8913, 'learning_rate': 9.164401398350326e-06, 'epoch': 0.54}
 54%|█████▍    | 5622/10395 [16:06:29<10:20:25,  7.80s/it] 54%|█████▍    | 5623/10395 [16:06:36<10:16:51,  7.76s/it]                                                          {'loss': 0.8881, 'learning_rate': 9.161296603346563e-06, 'epoch': 0.54}
 54%|█████▍    | 5623/10395 [16:06:36<10:16:51,  7.76s/it] 54%|█████▍    | 5624/10395 [16:06:44<10:25:47,  7.87s/it]                                                          {'loss': 0.8689, 'learning_rate': 9.158191889762333e-06, 'epoch': 0.54}
 54%|█████▍    | 5624/10395 [16:06:44<10:25:47,  7.87s/it] 54%|█████▍    | 5625/10395 [16:06:52<10:14:26,  7.73s/it]                                                          {'loss': 0.9392, 'learning_rate': 9.155087257899034e-06, 'epoch': 0.54}
 54%|█████▍    | 5625/10395 [16:06:52<10:14:26,  7.73s/it] 54%|█████▍    | 5626/10395 [16:06:59<10:13:31,  7.72s/it]                                                          {'loss': 0.8816, 'learning_rate': 9.15198270805806e-06, 'epoch': 0.54}
 54%|█████▍    | 5626/10395 [16:06:59<10:13:31,  7.72s/it] 54%|█████▍    | 5627/10395 [16:07:08<10:35:55,  8.00s/it]                                                          {'loss': 0.8607, 'learning_rate': 9.14887824054079e-06, 'epoch': 0.54}
 54%|█████▍    | 5627/10395 [16:07:08<10:35:55,  8.00s/it] 54%|█████▍    | 5628/10395 [16:07:17<10:46:52,  8.14s/it]                                                          {'loss': 0.821, 'learning_rate': 9.145773855648605e-06, 'epoch': 0.54}
 54%|█████▍    | 5628/10395 [16:07:17<10:46:52,  8.14s/it] 54%|█████▍    | 5629/10395 [16:07:24<10:36:52,  8.02s/it]                                                          {'loss': 0.9165, 'learning_rate': 9.142669553682868e-06, 'epoch': 0.54}
 54%|█████▍    | 5629/10395 [16:07:24<10:36:52,  8.02s/it] 54%|█████▍    | 5630/10395 [16:07:32<10:29:21,  7.92s/it]                                                          {'loss': 0.9198, 'learning_rate': 9.13956533494494e-06, 'epoch': 0.54}
 54%|█████▍    | 5630/10395 [16:07:32<10:29:21,  7.92s/it] 54%|█████▍    | 5631/10395 [16:07:40<10:20:01,  7.81s/it]                                                          {'loss': 0.9072, 'learning_rate': 9.136461199736167e-06, 'epoch': 0.54}
 54%|█████▍    | 5631/10395 [16:07:40<10:20:01,  7.81s/it] 54%|█████▍    | 5632/10395 [16:07:47<10:22:43,  7.84s/it]                                                          {'loss': 0.909, 'learning_rate': 9.133357148357897e-06, 'epoch': 0.54}
 54%|█████▍    | 5632/10395 [16:07:48<10:22:43,  7.84s/it] 54%|█████▍    | 5633/10395 [16:07:55<10:15:09,  7.75s/it]                                                          {'loss': 0.9268, 'learning_rate': 9.130253181111464e-06, 'epoch': 0.54}
 54%|█████▍    | 5633/10395 [16:07:55<10:15:09,  7.75s/it] 54%|█████▍    | 5634/10395 [16:08:02<10:03:11,  7.60s/it]                                                          {'loss': 0.925, 'learning_rate': 9.12714929829819e-06, 'epoch': 0.54}
 54%|█████▍    | 5634/10395 [16:08:02<10:03:11,  7.60s/it] 54%|█████▍    | 5635/10395 [16:08:10<9:57:37,  7.53s/it]                                                          {'loss': 0.9104, 'learning_rate': 9.124045500219399e-06, 'epoch': 0.54}
 54%|█████▍    | 5635/10395 [16:08:10<9:57:37,  7.53s/it] 54%|█████▍    | 5636/10395 [16:08:18<10:23:39,  7.86s/it]                                                          {'loss': 0.7929, 'learning_rate': 9.120941787176398e-06, 'epoch': 0.54}
 54%|█████▍    | 5636/10395 [16:08:18<10:23:39,  7.86s/it] 54%|█████▍    | 5637/10395 [16:08:26<10:17:25,  7.79s/it]                                                          {'loss': 0.9778, 'learning_rate': 9.117838159470495e-06, 'epoch': 0.54}
 54%|█████▍    | 5637/10395 [16:08:26<10:17:25,  7.79s/it] 54%|█████▍    | 5638/10395 [16:08:34<10:28:28,  7.93s/it]                                                          {'loss': 0.899, 'learning_rate': 9.114734617402973e-06, 'epoch': 0.54}
 54%|█████▍    | 5638/10395 [16:08:34<10:28:28,  7.93s/it] 54%|█████▍    | 5639/10395 [16:08:42<10:20:11,  7.82s/it]                                                          {'loss': 0.8549, 'learning_rate': 9.111631161275125e-06, 'epoch': 0.54}
 54%|█████▍    | 5639/10395 [16:08:42<10:20:11,  7.82s/it] 54%|█████▍    | 5640/10395 [16:08:51<10:56:31,  8.28s/it]                                                          {'loss': 0.8578, 'learning_rate': 9.108527791388224e-06, 'epoch': 0.54}
 54%|█████▍    | 5640/10395 [16:08:51<10:56:31,  8.28s/it] 54%|█████▍    | 5641/10395 [16:08:59<10:52:21,  8.23s/it]                                                          {'loss': 0.8802, 'learning_rate': 9.10542450804354e-06, 'epoch': 0.54}
 54%|█████▍    | 5641/10395 [16:08:59<10:52:21,  8.23s/it] 54%|█████▍    | 5642/10395 [16:09:07<10:43:14,  8.12s/it]                                                          {'loss': 0.8772, 'learning_rate': 9.102321311542333e-06, 'epoch': 0.54}
 54%|█████▍    | 5642/10395 [16:09:07<10:43:14,  8.12s/it] 54%|█████▍    | 5643/10395 [16:09:15<10:36:00,  8.03s/it]                                                          {'loss': 0.9247, 'learning_rate': 9.099218202185852e-06, 'epoch': 0.54}
 54%|█████▍    | 5643/10395 [16:09:15<10:36:00,  8.03s/it] 54%|█████▍    | 5644/10395 [16:09:23<10:29:22,  7.95s/it]                                                          {'loss': 0.9051, 'learning_rate': 9.09611518027535e-06, 'epoch': 0.54}
 54%|█████▍    | 5644/10395 [16:09:23<10:29:22,  7.95s/it] 54%|█████▍    | 5645/10395 [16:09:30<10:17:03,  7.79s/it]                                                          {'loss': 0.9455, 'learning_rate': 9.093012246112049e-06, 'epoch': 0.54}
 54%|█████▍    | 5645/10395 [16:09:30<10:17:03,  7.79s/it] 54%|█████▍    | 5646/10395 [16:09:37<10:05:48,  7.65s/it]                                                          {'loss': 0.9656, 'learning_rate': 9.089909399997183e-06, 'epoch': 0.54}
 54%|█████▍    | 5646/10395 [16:09:37<10:05:48,  7.65s/it] 54%|█████▍    | 5647/10395 [16:09:45<10:06:46,  7.67s/it]                                                          {'loss': 0.8822, 'learning_rate': 9.086806642231965e-06, 'epoch': 0.54}
 54%|█████▍    | 5647/10395 [16:09:45<10:06:46,  7.67s/it] 54%|█████▍    | 5648/10395 [16:09:53<10:00:12,  7.59s/it]                                                          {'loss': 0.9859, 'learning_rate': 9.08370397311761e-06, 'epoch': 0.54}
 54%|█████▍    | 5648/10395 [16:09:53<10:00:12,  7.59s/it] 54%|█████▍    | 5649/10395 [16:10:00<9:48:39,  7.44s/it]                                                          {'loss': 0.9237, 'learning_rate': 9.080601392955313e-06, 'epoch': 0.54}
 54%|█████▍    | 5649/10395 [16:10:00<9:48:39,  7.44s/it] 54%|█████▍    | 5650/10395 [16:10:07<9:44:18,  7.39s/it]                                                         {'loss': 0.9083, 'learning_rate': 9.077498902046267e-06, 'epoch': 0.54}
 54%|█████▍    | 5650/10395 [16:10:07<9:44:18,  7.39s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 54%|█████▍    | 5651/10395 [16:11:50<47:44:32, 36.23s/it]                                                          {'loss': 0.9377, 'learning_rate': 9.074396500691658e-06, 'epoch': 0.54}
 54%|█████▍    | 5651/10395 [16:11:50<47:44:32, 36.23s/it] 54%|█████▍    | 5652/10395 [16:11:58<36:25:58, 27.65s/it]                                                          {'loss': 0.9487, 'learning_rate': 9.071294189192663e-06, 'epoch': 0.54}
 54%|█████▍    | 5652/10395 [16:11:58<36:25:58, 27.65s/it] 54%|█████▍    | 5653/10395 [16:12:06<28:43:57, 21.81s/it]                                                          {'loss': 0.9327, 'learning_rate': 9.068191967850436e-06, 'epoch': 0.54}
 54%|█████▍    | 5653/10395 [16:12:06<28:43:57, 21.81s/it] 54%|█████▍    | 5654/10395 [16:12:14<23:12:06, 17.62s/it]                                                          {'loss': 0.8529, 'learning_rate': 9.065089836966146e-06, 'epoch': 0.54}
 54%|█████▍    | 5654/10395 [16:12:14<23:12:06, 17.62s/it] 54%|█████▍    | 5655/10395 [16:12:22<19:15:53, 14.63s/it]                                                          {'loss': 0.8727, 'learning_rate': 9.061987796840936e-06, 'epoch': 0.54}
 54%|█████▍    | 5655/10395 [16:12:22<19:15:53, 14.63s/it] 54%|█████▍    | 5656/10395 [16:12:30<16:53:41, 12.83s/it]                                                          {'loss': 0.8152, 'learning_rate': 9.058885847775944e-06, 'epoch': 0.54}
 54%|█████▍    | 5656/10395 [16:12:30<16:53:41, 12.83s/it] 54%|█████▍    | 5657/10395 [16:12:38<14:44:10, 11.20s/it]                                                          {'loss': 0.8937, 'learning_rate': 9.055783990072305e-06, 'epoch': 0.54}
 54%|█████▍    | 5657/10395 [16:12:38<14:44:10, 11.20s/it] 54%|█████▍    | 5658/10395 [16:12:45<13:12:43, 10.04s/it]                                                          {'loss': 0.9065, 'learning_rate': 9.052682224031136e-06, 'epoch': 0.54}
 54%|█████▍    | 5658/10395 [16:12:45<13:12:43, 10.04s/it] 54%|█████▍    | 5659/10395 [16:12:53<12:12:30,  9.28s/it]                                                          {'loss': 0.9429, 'learning_rate': 9.049580549953559e-06, 'epoch': 0.54}
 54%|█████▍    | 5659/10395 [16:12:53<12:12:30,  9.28s/it] 54%|█████▍    | 5660/10395 [16:13:00<11:19:41,  8.61s/it]                                                          {'loss': 0.8792, 'learning_rate': 9.046478968140665e-06, 'epoch': 0.54}
 54%|█████▍    | 5660/10395 [16:13:00<11:19:41,  8.61s/it] 54%|█████▍    | 5661/10395 [16:13:08<11:05:50,  8.44s/it]                                                          {'loss': 0.9482, 'learning_rate': 9.043377478893554e-06, 'epoch': 0.54}
 54%|█████▍    | 5661/10395 [16:13:08<11:05:50,  8.44s/it] 54%|█████▍    | 5662/10395 [16:13:16<11:09:25,  8.49s/it]                                                          {'loss': 0.8384, 'learning_rate': 9.040276082513315e-06, 'epoch': 0.54}
 54%|█████▍    | 5662/10395 [16:13:16<11:09:25,  8.49s/it] 54%|█████▍    | 5663/10395 [16:13:24<10:45:01,  8.18s/it]                                                          {'loss': 0.8612, 'learning_rate': 9.037174779301023e-06, 'epoch': 0.54}
 54%|█████▍    | 5663/10395 [16:13:24<10:45:01,  8.18s/it] 54%|█████▍    | 5664/10395 [16:13:31<10:21:52,  7.89s/it]                                                          {'loss': 0.7905, 'learning_rate': 9.034073569557746e-06, 'epoch': 0.54}
 54%|█████▍    | 5664/10395 [16:13:31<10:21:52,  7.89s/it] 54%|█████▍    | 5665/10395 [16:13:38<10:05:01,  7.67s/it]                                                          {'loss': 0.9203, 'learning_rate': 9.030972453584543e-06, 'epoch': 0.54}
 54%|█████▍    | 5665/10395 [16:13:38<10:05:01,  7.67s/it] 55%|█████▍    | 5666/10395 [16:13:55<13:53:41, 10.58s/it]                                                          {'loss': 0.3658, 'learning_rate': 9.027871431682467e-06, 'epoch': 0.55}
 55%|█████▍    | 5666/10395 [16:13:55<13:53:41, 10.58s/it] 55%|█████▍    | 5667/10395 [16:14:03<12:41:23,  9.66s/it]                                                          {'loss': 0.9656, 'learning_rate': 9.02477050415255e-06, 'epoch': 0.55}
 55%|█████▍    | 5667/10395 [16:14:03<12:41:23,  9.66s/it] 55%|█████▍    | 5668/10395 [16:14:11<12:03:07,  9.18s/it]                                                          {'loss': 0.9478, 'learning_rate': 9.021669671295829e-06, 'epoch': 0.55}
 55%|█████▍    | 5668/10395 [16:14:11<12:03:07,  9.18s/it] 55%|█████▍    | 5669/10395 [16:14:19<11:28:38,  8.74s/it]                                                          {'loss': 0.8786, 'learning_rate': 9.018568933413326e-06, 'epoch': 0.55}
 55%|█████▍    | 5669/10395 [16:14:19<11:28:38,  8.74s/it] 55%|█████▍    | 5670/10395 [16:14:26<10:56:46,  8.34s/it]                                                          {'loss': 0.9345, 'learning_rate': 9.015468290806051e-06, 'epoch': 0.55}
 55%|█████▍    | 5670/10395 [16:14:26<10:56:46,  8.34s/it] 55%|█████▍    | 5671/10395 [16:14:34<10:56:07,  8.33s/it]                                                          {'loss': 0.8901, 'learning_rate': 9.012367743775015e-06, 'epoch': 0.55}
 55%|█████▍    | 5671/10395 [16:14:34<10:56:07,  8.33s/it] 55%|█████▍    | 5672/10395 [16:14:42<10:41:34,  8.15s/it]                                                          {'loss': 0.89, 'learning_rate': 9.009267292621206e-06, 'epoch': 0.55}
 55%|█████▍    | 5672/10395 [16:14:42<10:41:34,  8.15s/it] 55%|█████▍    | 5673/10395 [16:14:50<10:27:26,  7.97s/it]                                                          {'loss': 0.8312, 'learning_rate': 9.00616693764561e-06, 'epoch': 0.55}
 55%|█████▍    | 5673/10395 [16:14:50<10:27:26,  7.97s/it] 55%|█████▍    | 5674/10395 [16:14:57<10:17:47,  7.85s/it]                                                          {'loss': 0.9452, 'learning_rate': 9.003066679149208e-06, 'epoch': 0.55}
 55%|█████▍    | 5674/10395 [16:14:57<10:17:47,  7.85s/it] 55%|█████▍    | 5675/10395 [16:15:05<10:13:40,  7.80s/it]                                                          {'loss': 0.8824, 'learning_rate': 8.999966517432958e-06, 'epoch': 0.55}
 55%|█████▍    | 5675/10395 [16:15:05<10:13:40,  7.80s/it] 55%|█████▍    | 5676/10395 [16:15:13<10:18:17,  7.86s/it]                                                          {'loss': 0.8812, 'learning_rate': 8.99686645279782e-06, 'epoch': 0.55}
 55%|█████▍    | 5676/10395 [16:15:13<10:18:17,  7.86s/it] 55%|█████▍    | 5677/10395 [16:15:22<10:36:49,  8.10s/it]                                                          {'loss': 0.9484, 'learning_rate': 8.993766485544748e-06, 'epoch': 0.55}
 55%|█████▍    | 5677/10395 [16:15:22<10:36:49,  8.10s/it] 55%|█████▍    | 5678/10395 [16:15:29<10:14:46,  7.82s/it]                                                          {'loss': 0.9569, 'learning_rate': 8.990666615974672e-06, 'epoch': 0.55}
 55%|█████▍    | 5678/10395 [16:15:29<10:14:46,  7.82s/it] 55%|█████▍    | 5679/10395 [16:15:37<10:16:09,  7.84s/it]                                                          {'loss': 0.8888, 'learning_rate': 8.987566844388524e-06, 'epoch': 0.55}
 55%|█████▍    | 5679/10395 [16:15:37<10:16:09,  7.84s/it] 55%|█████▍    | 5680/10395 [16:15:44<10:05:37,  7.71s/it]                                                          {'loss': 0.9177, 'learning_rate': 8.984467171087226e-06, 'epoch': 0.55}
 55%|█████▍    | 5680/10395 [16:15:44<10:05:37,  7.71s/it] 55%|█████▍    | 5681/10395 [16:15:52<10:01:01,  7.65s/it]                                                          {'loss': 0.9187, 'learning_rate': 8.981367596371685e-06, 'epoch': 0.55}
 55%|█████▍    | 5681/10395 [16:15:52<10:01:01,  7.65s/it] 55%|█████▍    | 5682/10395 [16:15:59<10:04:40,  7.70s/it]                                                          {'loss': 0.854, 'learning_rate': 8.978268120542798e-06, 'epoch': 0.55}
 55%|█████▍    | 5682/10395 [16:15:59<10:04:40,  7.70s/it] 55%|█████▍    | 5683/10395 [16:16:07<10:01:33,  7.66s/it]                                                          {'loss': 0.8882, 'learning_rate': 8.975168743901459e-06, 'epoch': 0.55}
 55%|█████▍    | 5683/10395 [16:16:07<10:01:33,  7.66s/it] 55%|█████▍    | 5684/10395 [16:16:24<13:46:29, 10.53s/it]                                                          {'loss': 0.3752, 'learning_rate': 8.972069466748546e-06, 'epoch': 0.55}
 55%|█████▍    | 5684/10395 [16:16:24<13:46:29, 10.53s/it] 55%|█████▍    | 5685/10395 [16:16:32<12:42:22,  9.71s/it]                                                          {'loss': 0.8983, 'learning_rate': 8.968970289384935e-06, 'epoch': 0.55}
 55%|█████▍    | 5685/10395 [16:16:32<12:42:22,  9.71s/it] 55%|█████▍    | 5686/10395 [16:16:40<11:52:34,  9.08s/it]                                                          {'loss': 0.9059, 'learning_rate': 8.965871212111486e-06, 'epoch': 0.55}
 55%|█████▍    | 5686/10395 [16:16:40<11:52:34,  9.08s/it] 55%|█████▍    | 5687/10395 [16:16:48<11:23:27,  8.71s/it]                                                          {'loss': 0.8477, 'learning_rate': 8.962772235229049e-06, 'epoch': 0.55}
 55%|█████▍    | 5687/10395 [16:16:48<11:23:27,  8.71s/it] 55%|█████▍    | 5688/10395 [16:16:55<10:59:21,  8.40s/it]                                                          {'loss': 0.8998, 'learning_rate': 8.959673359038468e-06, 'epoch': 0.55}
 55%|█████▍    | 5688/10395 [16:16:55<10:59:21,  8.40s/it] 55%|█████▍    | 5689/10395 [16:17:03<10:38:42,  8.14s/it]                                                          {'loss': 0.887, 'learning_rate': 8.956574583840573e-06, 'epoch': 0.55}
 55%|█████▍    | 5689/10395 [16:17:03<10:38:42,  8.14s/it] 55%|█████▍    | 5690/10395 [16:17:10<10:29:41,  8.03s/it]                                                          {'loss': 0.8946, 'learning_rate': 8.953475909936187e-06, 'epoch': 0.55}
 55%|█████▍    | 5690/10395 [16:17:10<10:29:41,  8.03s/it] 55%|█████▍    | 5691/10395 [16:17:18<10:27:37,  8.01s/it]                                                          {'loss': 0.8249, 'learning_rate': 8.950377337626124e-06, 'epoch': 0.55}
 55%|█████▍    | 5691/10395 [16:17:18<10:27:37,  8.01s/it] 55%|█████▍    | 5692/10395 [16:17:26<10:15:44,  7.86s/it]                                                          {'loss': 0.9082, 'learning_rate': 8.947278867211183e-06, 'epoch': 0.55}
 55%|█████▍    | 5692/10395 [16:17:26<10:15:44,  7.86s/it] 55%|█████▍    | 5693/10395 [16:17:35<10:33:12,  8.08s/it]                                                          {'loss': 0.9312, 'learning_rate': 8.944180498992163e-06, 'epoch': 0.55}
 55%|█████▍    | 5693/10395 [16:17:35<10:33:12,  8.08s/it] 55%|█████▍    | 5694/10395 [16:17:42<10:26:07,  7.99s/it]                                                          {'loss': 0.8871, 'learning_rate': 8.941082233269842e-06, 'epoch': 0.55}
 55%|█████▍    | 5694/10395 [16:17:42<10:26:07,  7.99s/it] 55%|█████▍    | 5695/10395 [16:17:50<10:08:25,  7.77s/it]                                                          {'loss': 0.9122, 'learning_rate': 8.937984070344996e-06, 'epoch': 0.55}
 55%|█████▍    | 5695/10395 [16:17:50<10:08:25,  7.77s/it] 55%|█████▍    | 5696/10395 [16:17:58<10:22:10,  7.94s/it]                                                          {'loss': 0.8748, 'learning_rate': 8.93488601051839e-06, 'epoch': 0.55}
 55%|█████▍    | 5696/10395 [16:17:58<10:22:10,  7.94s/it] 55%|█████▍    | 5697/10395 [16:18:05<10:13:01,  7.83s/it]                                                          {'loss': 0.9047, 'learning_rate': 8.93178805409077e-06, 'epoch': 0.55}
 55%|█████▍    | 5697/10395 [16:18:05<10:13:01,  7.83s/it] 55%|█████▍    | 5698/10395 [16:18:13<10:04:26,  7.72s/it]                                                          {'loss': 0.882, 'learning_rate': 8.928690201362885e-06, 'epoch': 0.55}
 55%|█████▍    | 5698/10395 [16:18:13<10:04:26,  7.72s/it] 55%|█████▍    | 5699/10395 [16:18:21<10:13:30,  7.84s/it]                                                          {'loss': 0.8753, 'learning_rate': 8.925592452635465e-06, 'epoch': 0.55}
 55%|█████▍    | 5699/10395 [16:18:21<10:13:30,  7.84s/it] 55%|█████▍    | 5700/10395 [16:18:29<10:16:24,  7.88s/it]                                                          {'loss': 0.9765, 'learning_rate': 8.922494808209231e-06, 'epoch': 0.55}
 55%|█████▍    | 5700/10395 [16:18:29<10:16:24,  7.88s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▍    | 5701/10395 [16:20:18<49:39:40, 38.09s/it]                                                          {'loss': 0.3843, 'learning_rate': 8.919397268384901e-06, 'epoch': 0.55}
 55%|█████▍    | 5701/10395 [16:20:18<49:39:40, 38.09s/it] 55%|█████▍    | 5702/10395 [16:20:26<37:53:46, 29.07s/it]                                                          {'loss': 0.9203, 'learning_rate': 8.916299833463176e-06, 'epoch': 0.55}
 55%|█████▍    | 5702/10395 [16:20:26<37:53:46, 29.07s/it] 55%|█████▍    | 5703/10395 [16:20:34<29:49:53, 22.89s/it]                                                          {'loss': 0.7868, 'learning_rate': 8.913202503744748e-06, 'epoch': 0.55}
 55%|█████▍    | 5703/10395 [16:20:34<29:49:53, 22.89s/it] 55%|█████▍    | 5704/10395 [16:20:42<23:55:09, 18.36s/it]                                                          {'loss': 0.9542, 'learning_rate': 8.910105279530295e-06, 'epoch': 0.55}
 55%|█████▍    | 5704/10395 [16:20:42<23:55:09, 18.36s/it] 55%|█████▍    | 5705/10395 [16:20:50<19:47:33, 15.19s/it]                                                          {'loss': 0.8638, 'learning_rate': 8.907008161120495e-06, 'epoch': 0.55}
 55%|█████▍    | 5705/10395 [16:20:50<19:47:33, 15.19s/it] 55%|█████▍    | 5706/10395 [16:20:58<17:06:09, 13.13s/it]                                                          {'loss': 0.8445, 'learning_rate': 8.903911148816006e-06, 'epoch': 0.55}
 55%|█████▍    | 5706/10395 [16:20:58<17:06:09, 13.13s/it] 55%|█████▍    | 5707/10395 [16:21:06<15:03:50, 11.57s/it]                                                          {'loss': 0.9113, 'learning_rate': 8.90081424291748e-06, 'epoch': 0.55}
 55%|█████▍    | 5707/10395 [16:21:06<15:03:50, 11.57s/it] 55%|█████▍    | 5708/10395 [16:21:13<13:23:24, 10.28s/it]                                                          {'loss': 0.9426, 'learning_rate': 8.897717443725556e-06, 'epoch': 0.55}
 55%|█████▍    | 5708/10395 [16:21:13<13:23:24, 10.28s/it] 55%|█████▍    | 5709/10395 [16:21:21<12:32:09,  9.63s/it]                                                          {'loss': 0.8726, 'learning_rate': 8.89462075154087e-06, 'epoch': 0.55}
 55%|█████▍    | 5709/10395 [16:21:21<12:32:09,  9.63s/it] 55%|█████▍    | 5710/10395 [16:21:29<11:50:01,  9.09s/it]                                                          {'loss': 0.9272, 'learning_rate': 8.891524166664041e-06, 'epoch': 0.55}
 55%|█████▍    | 5710/10395 [16:21:29<11:50:01,  9.09s/it] 55%|█████▍    | 5711/10395 [16:21:37<11:17:36,  8.68s/it]                                                          {'loss': 0.9084, 'learning_rate': 8.888427689395674e-06, 'epoch': 0.55}
 55%|█████▍    | 5711/10395 [16:21:37<11:17:36,  8.68s/it] 55%|█████▍    | 5712/10395 [16:21:45<11:01:04,  8.47s/it]                                                          {'loss': 0.8885, 'learning_rate': 8.885331320036374e-06, 'epoch': 0.55}
 55%|█████▍    | 5712/10395 [16:21:45<11:01:04,  8.47s/it] 55%|█████▍    | 5713/10395 [16:21:52<10:39:02,  8.19s/it]                                                          {'loss': 0.8356, 'learning_rate': 8.882235058886725e-06, 'epoch': 0.55}
 55%|█████▍    | 5713/10395 [16:21:52<10:39:02,  8.19s/it] 55%|█████▍    | 5714/10395 [16:22:00<10:25:51,  8.02s/it]                                                          {'loss': 0.9121, 'learning_rate': 8.87913890624731e-06, 'epoch': 0.55}
 55%|█████▍    | 5714/10395 [16:22:00<10:25:51,  8.02s/it] 55%|█████▍    | 5715/10395 [16:22:08<10:16:35,  7.91s/it]                                                          {'loss': 0.9499, 'learning_rate': 8.876042862418688e-06, 'epoch': 0.55}
 55%|█████▍    | 5715/10395 [16:22:08<10:16:35,  7.91s/it] 55%|█████▍    | 5716/10395 [16:22:15<10:06:34,  7.78s/it]                                                          {'loss': 0.9021, 'learning_rate': 8.87294692770143e-06, 'epoch': 0.55}
 55%|█████▍    | 5716/10395 [16:22:15<10:06:34,  7.78s/it] 55%|█████▍    | 5717/10395 [16:22:23<9:57:48,  7.67s/it]                                                          {'loss': 0.9456, 'learning_rate': 8.869851102396074e-06, 'epoch': 0.55}
 55%|█████▍    | 5717/10395 [16:22:23<9:57:48,  7.67s/it] 55%|█████▌    | 5718/10395 [16:22:30<9:52:22,  7.60s/it]                                                         {'loss': 0.8247, 'learning_rate': 8.86675538680316e-06, 'epoch': 0.55}
 55%|█████▌    | 5718/10395 [16:22:30<9:52:22,  7.60s/it] 55%|█████▌    | 5719/10395 [16:22:37<9:48:28,  7.55s/it]                                                         {'loss': 0.8588, 'learning_rate': 8.863659781223208e-06, 'epoch': 0.55}
 55%|█████▌    | 5719/10395 [16:22:37<9:48:28,  7.55s/it] 55%|█████▌    | 5720/10395 [16:22:45<9:43:45,  7.49s/it]                                                         {'loss': 0.9025, 'learning_rate': 8.860564285956738e-06, 'epoch': 0.55}
 55%|█████▌    | 5720/10395 [16:22:45<9:43:45,  7.49s/it] 55%|█████▌    | 5721/10395 [16:22:53<10:11:11,  7.85s/it]                                                          {'loss': 0.8926, 'learning_rate': 8.857468901304251e-06, 'epoch': 0.55}
 55%|█████▌    | 5721/10395 [16:22:53<10:11:11,  7.85s/it] 55%|█████▌    | 5722/10395 [16:23:01<10:00:34,  7.71s/it]                                                          {'loss': 0.9772, 'learning_rate': 8.854373627566242e-06, 'epoch': 0.55}
 55%|█████▌    | 5722/10395 [16:23:01<10:00:34,  7.71s/it] 55%|█████▌    | 5723/10395 [16:23:09<10:00:59,  7.72s/it]                                                          {'loss': 0.8371, 'learning_rate': 8.85127846504319e-06, 'epoch': 0.55}
 55%|█████▌    | 5723/10395 [16:23:09<10:00:59,  7.72s/it] 55%|█████▌    | 5724/10395 [16:23:16<10:00:41,  7.72s/it]                                                          {'loss': 0.8442, 'learning_rate': 8.848183414035574e-06, 'epoch': 0.55}
 55%|█████▌    | 5724/10395 [16:23:16<10:00:41,  7.72s/it] 55%|█████▌    | 5725/10395 [16:23:25<10:20:55,  7.98s/it]                                                          {'loss': 0.8673, 'learning_rate': 8.845088474843853e-06, 'epoch': 0.55}
 55%|█████▌    | 5725/10395 [16:23:25<10:20:55,  7.98s/it] 55%|█████▌    | 5726/10395 [16:23:32<10:10:40,  7.85s/it]                                                          {'loss': 0.8521, 'learning_rate': 8.841993647768469e-06, 'epoch': 0.55}
 55%|█████▌    | 5726/10395 [16:23:32<10:10:40,  7.85s/it] 55%|█████▌    | 5727/10395 [16:23:50<13:50:17, 10.67s/it]                                                          {'loss': 0.3891, 'learning_rate': 8.838898933109869e-06, 'epoch': 0.55}
 55%|█████▌    | 5727/10395 [16:23:50<13:50:17, 10.67s/it] 55%|█████▌    | 5728/10395 [16:23:57<12:39:32,  9.76s/it]                                                          {'loss': 0.9604, 'learning_rate': 8.83580433116848e-06, 'epoch': 0.55}
 55%|█████▌    | 5728/10395 [16:23:57<12:39:32,  9.76s/it] 55%|█████▌    | 5729/10395 [16:24:05<11:51:01,  9.14s/it]                                                          {'loss': 0.8579, 'learning_rate': 8.832709842244718e-06, 'epoch': 0.55}
 55%|█████▌    | 5729/10395 [16:24:05<11:51:01,  9.14s/it] 55%|█████▌    | 5730/10395 [16:24:14<11:47:17,  9.10s/it]                                                          {'loss': 0.8651, 'learning_rate': 8.82961546663899e-06, 'epoch': 0.55}
 55%|█████▌    | 5730/10395 [16:24:14<11:47:17,  9.10s/it] 55%|█████▌    | 5731/10395 [16:24:22<11:20:09,  8.75s/it]                                                          {'loss': 0.8519, 'learning_rate': 8.82652120465169e-06, 'epoch': 0.55}
 55%|█████▌    | 5731/10395 [16:24:22<11:20:09,  8.75s/it] 55%|█████▌    | 5732/10395 [16:24:40<14:59:01, 11.57s/it]                                                          {'loss': 0.3705, 'learning_rate': 8.823427056583208e-06, 'epoch': 0.55}
 55%|█████▌    | 5732/10395 [16:24:40<14:59:01, 11.57s/it] 55%|█████▌    | 5733/10395 [16:24:48<13:26:55, 10.39s/it]                                                          {'loss': 0.9196, 'learning_rate': 8.820333022733911e-06, 'epoch': 0.55}
 55%|█████▌    | 5733/10395 [16:24:48<13:26:55, 10.39s/it] 55%|█████▌    | 5734/10395 [16:24:56<12:30:01,  9.65s/it]                                                          {'loss': 0.9008, 'learning_rate': 8.817239103404159e-06, 'epoch': 0.55}
 55%|█████▌    | 5734/10395 [16:24:56<12:30:01,  9.65s/it] 55%|█████▌    | 5735/10395 [16:25:15<16:05:43, 12.43s/it]                                                          {'loss': 0.3776, 'learning_rate': 8.81414529889431e-06, 'epoch': 0.55}
 55%|█████▌    | 5735/10395 [16:25:15<16:05:43, 12.43s/it] 55%|█████▌    | 5736/10395 [16:25:22<14:17:26, 11.04s/it]                                                          {'loss': 0.9037, 'learning_rate': 8.811051609504704e-06, 'epoch': 0.55}
 55%|█████▌    | 5736/10395 [16:25:22<14:17:26, 11.04s/it] 55%|█████▌    | 5737/10395 [16:25:30<12:58:06, 10.02s/it]                                                          {'loss': 0.934, 'learning_rate': 8.807958035535664e-06, 'epoch': 0.55}
 55%|█████▌    | 5737/10395 [16:25:30<12:58:06, 10.02s/it] 55%|█████▌    | 5738/10395 [16:25:38<12:11:34,  9.43s/it]                                                          {'loss': 0.9295, 'learning_rate': 8.804864577287512e-06, 'epoch': 0.55}
 55%|█████▌    | 5738/10395 [16:25:38<12:11:34,  9.43s/it] 55%|█████▌    | 5739/10395 [16:25:47<11:54:13,  9.20s/it]                                                          {'loss': 0.8937, 'learning_rate': 8.80177123506055e-06, 'epoch': 0.55}
 55%|█████▌    | 5739/10395 [16:25:47<11:54:13,  9.20s/it] 55%|█████▌    | 5740/10395 [16:25:54<11:01:04,  8.52s/it]                                                          {'loss': 0.9399, 'learning_rate': 8.798678009155082e-06, 'epoch': 0.55}
 55%|█████▌    | 5740/10395 [16:25:54<11:01:04,  8.52s/it] 55%|█████▌    | 5741/10395 [16:26:01<10:34:41,  8.18s/it]                                                          {'loss': 0.887, 'learning_rate': 8.795584899871381e-06, 'epoch': 0.55}
 55%|█████▌    | 5741/10395 [16:26:01<10:34:41,  8.18s/it] 55%|█████▌    | 5742/10395 [16:26:10<10:43:41,  8.30s/it]                                                          {'loss': 0.866, 'learning_rate': 8.792491907509722e-06, 'epoch': 0.55}
 55%|█████▌    | 5742/10395 [16:26:10<10:43:41,  8.30s/it] 55%|█████▌    | 5743/10395 [16:26:18<10:41:34,  8.27s/it]                                                          {'loss': 0.9682, 'learning_rate': 8.789399032370372e-06, 'epoch': 0.55}
 55%|█████▌    | 5743/10395 [16:26:18<10:41:34,  8.27s/it] 55%|█████▌    | 5744/10395 [16:26:25<10:22:16,  8.03s/it]                                                          {'loss': 0.9524, 'learning_rate': 8.786306274753575e-06, 'epoch': 0.55}
 55%|█████▌    | 5744/10395 [16:26:25<10:22:16,  8.03s/it] 55%|█████▌    | 5745/10395 [16:26:32<9:58:09,  7.72s/it]                                                          {'loss': 0.9028, 'learning_rate': 8.783213634959573e-06, 'epoch': 0.55}
 55%|█████▌    | 5745/10395 [16:26:32<9:58:09,  7.72s/it] 55%|█████▌    | 5746/10395 [16:26:40<10:01:05,  7.76s/it]                                                          {'loss': 0.9002, 'learning_rate': 8.780121113288588e-06, 'epoch': 0.55}
 55%|█████▌    | 5746/10395 [16:26:40<10:01:05,  7.76s/it] 55%|█████▌    | 5747/10395 [16:26:48<9:51:10,  7.63s/it]                                                          {'loss': 0.8807, 'learning_rate': 8.777028710040844e-06, 'epoch': 0.55}
 55%|█████▌    | 5747/10395 [16:26:48<9:51:10,  7.63s/it] 55%|█████▌    | 5748/10395 [16:26:56<10:00:42,  7.76s/it]                                                          {'loss': 0.8479, 'learning_rate': 8.773936425516536e-06, 'epoch': 0.55}
 55%|█████▌    | 5748/10395 [16:26:56<10:00:42,  7.76s/it] 55%|█████▌    | 5749/10395 [16:27:04<10:15:12,  7.94s/it]                                                          {'loss': 0.7844, 'learning_rate': 8.770844260015856e-06, 'epoch': 0.55}
 55%|█████▌    | 5749/10395 [16:27:04<10:15:12,  7.94s/it] 55%|█████▌    | 5750/10395 [16:27:11<10:01:55,  7.78s/it]                                                          {'loss': 0.8579, 'learning_rate': 8.767752213838993e-06, 'epoch': 0.55}
 55%|█████▌    | 5750/10395 [16:27:11<10:01:55,  7.78s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 5751/10395 [16:28:49<44:41:55, 34.65s/it]                                                          {'loss': 0.944, 'learning_rate': 8.764660287286111e-06, 'epoch': 0.55}
 55%|█████▌    | 5751/10395 [16:28:49<44:41:55, 34.65s/it] 55%|█████▌    | 5752/10395 [16:28:57<34:32:12, 26.78s/it]                                                          {'loss': 0.8005, 'learning_rate': 8.761568480657367e-06, 'epoch': 0.55}
 55%|█████▌    | 5752/10395 [16:28:57<34:32:12, 26.78s/it] 55%|█████▌    | 5753/10395 [16:29:05<27:08:19, 21.05s/it]                                                          {'loss': 0.8935, 'learning_rate': 8.75847679425291e-06, 'epoch': 0.55}
 55%|█████▌    | 5753/10395 [16:29:05<27:08:19, 21.05s/it] 55%|█████▌    | 5754/10395 [16:29:12<21:47:39, 16.91s/it]                                                          {'loss': 0.8175, 'learning_rate': 8.755385228372871e-06, 'epoch': 0.55}
 55%|█████▌    | 5754/10395 [16:29:12<21:47:39, 16.91s/it] 55%|█████▌    | 5755/10395 [16:29:20<18:15:03, 14.16s/it]                                                          {'loss': 0.9162, 'learning_rate': 8.752293783317379e-06, 'epoch': 0.55}
 55%|█████▌    | 5755/10395 [16:29:20<18:15:03, 14.16s/it] 55%|█████▌    | 5756/10395 [16:29:27<15:33:50, 12.08s/it]                                                          {'loss': 0.9306, 'learning_rate': 8.749202459386536e-06, 'epoch': 0.55}
 55%|█████▌    | 5756/10395 [16:29:27<15:33:50, 12.08s/it] 55%|█████▌    | 5757/10395 [16:29:34<13:40:24, 10.61s/it]                                                          {'loss': 0.9926, 'learning_rate': 8.746111256880445e-06, 'epoch': 0.55}
 55%|█████▌    | 5757/10395 [16:29:34<13:40:24, 10.61s/it] 55%|█████▌    | 5758/10395 [16:29:41<12:22:29,  9.61s/it]                                                          {'loss': 0.9359, 'learning_rate': 8.743020176099194e-06, 'epoch': 0.55}
 55%|█████▌    | 5758/10395 [16:29:41<12:22:29,  9.61s/it] 55%|█████▌    | 5759/10395 [16:29:49<11:25:18,  8.87s/it]                                                          {'loss': 0.981, 'learning_rate': 8.739929217342859e-06, 'epoch': 0.55}
 55%|█████▌    | 5759/10395 [16:29:49<11:25:18,  8.87s/it] 55%|█████▌    | 5760/10395 [16:29:56<10:53:06,  8.45s/it]                                                          {'loss': 0.8689, 'learning_rate': 8.736838380911502e-06, 'epoch': 0.55}
 55%|█████▌    | 5760/10395 [16:29:56<10:53:06,  8.45s/it] 55%|█████▌    | 5761/10395 [16:30:04<10:31:52,  8.18s/it]                                                          {'loss': 0.8517, 'learning_rate': 8.733747667105176e-06, 'epoch': 0.55}
 55%|█████▌    | 5761/10395 [16:30:04<10:31:52,  8.18s/it] 55%|█████▌    | 5762/10395 [16:30:11<10:20:12,  8.03s/it]                                                          {'loss': 0.8974, 'learning_rate': 8.730657076223922e-06, 'epoch': 0.55}
 55%|█████▌    | 5762/10395 [16:30:11<10:20:12,  8.03s/it] 55%|█████▌    | 5763/10395 [16:30:18<9:58:26,  7.75s/it]                                                          {'loss': 0.9434, 'learning_rate': 8.727566608567766e-06, 'epoch': 0.55}
 55%|█████▌    | 5763/10395 [16:30:18<9:58:26,  7.75s/it] 55%|█████▌    | 5764/10395 [16:30:27<10:11:38,  7.92s/it]                                                          {'loss': 0.8923, 'learning_rate': 8.724476264436724e-06, 'epoch': 0.55}
 55%|█████▌    | 5764/10395 [16:30:27<10:11:38,  7.92s/it] 55%|█████▌    | 5765/10395 [16:30:34<9:55:37,  7.72s/it]                                                          {'loss': 1.025, 'learning_rate': 8.721386044130797e-06, 'epoch': 0.55}
 55%|█████▌    | 5765/10395 [16:30:34<9:55:37,  7.72s/it] 55%|█████▌    | 5766/10395 [16:30:50<13:11:43, 10.26s/it]                                                          {'loss': 0.4138, 'learning_rate': 8.718295947949983e-06, 'epoch': 0.55}
 55%|█████▌    | 5766/10395 [16:30:50<13:11:43, 10.26s/it] 55%|█████▌    | 5767/10395 [16:30:58<12:15:08,  9.53s/it]                                                          {'loss': 0.8771, 'learning_rate': 8.71520597619426e-06, 'epoch': 0.55}
 55%|█████▌    | 5767/10395 [16:30:58<12:15:08,  9.53s/it] 55%|█████▌    | 5768/10395 [16:31:05<11:23:58,  8.87s/it]                                                          {'loss': 0.9552, 'learning_rate': 8.712116129163595e-06, 'epoch': 0.55}
 55%|█████▌    | 5768/10395 [16:31:05<11:23:58,  8.87s/it] 55%|█████▌    | 5769/10395 [16:31:13<10:51:48,  8.45s/it]                                                          {'loss': 0.8612, 'learning_rate': 8.709026407157945e-06, 'epoch': 0.55}
 55%|█████▌    | 5769/10395 [16:31:13<10:51:48,  8.45s/it] 56%|█████▌    | 5770/10395 [16:31:20<10:27:33,  8.14s/it]                                                          {'loss': 0.943, 'learning_rate': 8.70593681047725e-06, 'epoch': 0.56}
 56%|█████▌    | 5770/10395 [16:31:20<10:27:33,  8.14s/it] 56%|█████▌    | 5771/10395 [16:31:37<13:43:23, 10.68s/it]                                                          {'loss': 0.3923, 'learning_rate': 8.702847339421448e-06, 'epoch': 0.56}
 56%|█████▌    | 5771/10395 [16:31:37<13:43:23, 10.68s/it] 56%|█████▌    | 5772/10395 [16:31:44<12:26:05,  9.68s/it]                                                          {'loss': 0.8313, 'learning_rate': 8.69975799429045e-06, 'epoch': 0.56}
 56%|█████▌    | 5772/10395 [16:31:44<12:26:05,  9.68s/it] 56%|█████▌    | 5773/10395 [16:31:52<11:47:56,  9.19s/it]                                                          {'loss': 0.8461, 'learning_rate': 8.696668775384167e-06, 'epoch': 0.56}
 56%|█████▌    | 5773/10395 [16:31:52<11:47:56,  9.19s/it] 56%|█████▌    | 5774/10395 [16:32:00<11:05:55,  8.65s/it]                                                          {'loss': 0.9817, 'learning_rate': 8.693579683002496e-06, 'epoch': 0.56}
 56%|█████▌    | 5774/10395 [16:32:00<11:05:55,  8.65s/it] 56%|█████▌    | 5775/10395 [16:32:07<10:33:38,  8.23s/it]                                                          {'loss': 0.8637, 'learning_rate': 8.690490717445318e-06, 'epoch': 0.56}
 56%|█████▌    | 5775/10395 [16:32:07<10:33:38,  8.23s/it] 56%|█████▌    | 5776/10395 [16:32:14<10:19:51,  8.05s/it]                                                          {'loss': 0.9128, 'learning_rate': 8.687401879012502e-06, 'epoch': 0.56}
 56%|█████▌    | 5776/10395 [16:32:14<10:19:51,  8.05s/it] 56%|█████▌    | 5777/10395 [16:32:22<10:11:24,  7.94s/it]                                                          {'loss': 0.8915, 'learning_rate': 8.68431316800391e-06, 'epoch': 0.56}
 56%|█████▌    | 5777/10395 [16:32:22<10:11:24,  7.94s/it] 56%|█████▌    | 5778/10395 [16:32:31<10:21:39,  8.08s/it]                                                          {'loss': 0.9359, 'learning_rate': 8.68122458471938e-06, 'epoch': 0.56}
 56%|█████▌    | 5778/10395 [16:32:31<10:21:39,  8.08s/it] 56%|█████▌    | 5779/10395 [16:32:38<10:01:35,  7.82s/it]                                                          {'loss': 0.9105, 'learning_rate': 8.67813612945875e-06, 'epoch': 0.56}
 56%|█████▌    | 5779/10395 [16:32:38<10:01:35,  7.82s/it] 56%|█████▌    | 5780/10395 [16:32:45<9:58:15,  7.78s/it]                                                          {'loss': 0.9547, 'learning_rate': 8.675047802521838e-06, 'epoch': 0.56}
 56%|█████▌    | 5780/10395 [16:32:45<9:58:15,  7.78s/it] 56%|█████▌    | 5781/10395 [16:32:53<10:02:45,  7.84s/it]                                                          {'loss': 0.9123, 'learning_rate': 8.671959604208455e-06, 'epoch': 0.56}
 56%|█████▌    | 5781/10395 [16:32:53<10:02:45,  7.84s/it] 56%|█████▌    | 5782/10395 [16:33:01<10:01:01,  7.82s/it]                                                          {'loss': 0.9, 'learning_rate': 8.668871534818397e-06, 'epoch': 0.56}
 56%|█████▌    | 5782/10395 [16:33:01<10:01:01,  7.82s/it] 56%|█████▌    | 5783/10395 [16:33:09<9:55:52,  7.75s/it]                                                          {'loss': 0.8936, 'learning_rate': 8.665783594651443e-06, 'epoch': 0.56}
 56%|█████▌    | 5783/10395 [16:33:09<9:55:52,  7.75s/it] 56%|█████▌    | 5784/10395 [16:33:17<10:07:23,  7.90s/it]                                                          {'loss': 0.8491, 'learning_rate': 8.662695784007371e-06, 'epoch': 0.56}
 56%|█████▌    | 5784/10395 [16:33:17<10:07:23,  7.90s/it] 56%|█████▌    | 5785/10395 [16:33:25<9:59:54,  7.81s/it]                                                          {'loss': 0.8736, 'learning_rate': 8.659608103185933e-06, 'epoch': 0.56}
 56%|█████▌    | 5785/10395 [16:33:25<9:59:54,  7.81s/it] 56%|█████▌    | 5786/10395 [16:33:32<9:53:16,  7.72s/it]                                                         {'loss': 0.8756, 'learning_rate': 8.656520552486873e-06, 'epoch': 0.56}
 56%|█████▌    | 5786/10395 [16:33:32<9:53:16,  7.72s/it] 56%|█████▌    | 5787/10395 [16:33:40<9:52:08,  7.71s/it]                                                         {'loss': 0.8958, 'learning_rate': 8.65343313220993e-06, 'epoch': 0.56}
 56%|█████▌    | 5787/10395 [16:33:40<9:52:08,  7.71s/it] 56%|█████▌    | 5788/10395 [16:33:47<9:41:48,  7.58s/it]                                                         {'loss': 0.944, 'learning_rate': 8.650345842654816e-06, 'epoch': 0.56}
 56%|█████▌    | 5788/10395 [16:33:47<9:41:48,  7.58s/it] 56%|█████▌    | 5789/10395 [16:33:55<9:52:49,  7.72s/it]                                                         {'loss': 0.8574, 'learning_rate': 8.647258684121247e-06, 'epoch': 0.56}
 56%|█████▌    | 5789/10395 [16:33:55<9:52:49,  7.72s/it] 56%|█████▌    | 5790/10395 [16:34:03<9:43:05,  7.60s/it]                                                         {'loss': 0.9714, 'learning_rate': 8.644171656908914e-06, 'epoch': 0.56}
 56%|█████▌    | 5790/10395 [16:34:03<9:43:05,  7.60s/it] 56%|█████▌    | 5791/10395 [16:34:10<9:34:33,  7.49s/it]                                                         {'loss': 0.925, 'learning_rate': 8.641084761317501e-06, 'epoch': 0.56}
 56%|█████▌    | 5791/10395 [16:34:10<9:34:33,  7.49s/it] 56%|█████▌    | 5792/10395 [16:34:17<9:36:50,  7.52s/it]                                                         {'loss': 0.879, 'learning_rate': 8.637997997646674e-06, 'epoch': 0.56}
 56%|█████▌    | 5792/10395 [16:34:17<9:36:50,  7.52s/it] 56%|█████▌    | 5793/10395 [16:34:25<9:35:16,  7.50s/it]                                                         {'loss': 0.9651, 'learning_rate': 8.63491136619609e-06, 'epoch': 0.56}
 56%|█████▌    | 5793/10395 [16:34:25<9:35:16,  7.50s/it] 56%|█████▌    | 5794/10395 [16:34:33<9:55:06,  7.76s/it]                                                         {'loss': 0.9497, 'learning_rate': 8.631824867265393e-06, 'epoch': 0.56}
 56%|█████▌    | 5794/10395 [16:34:33<9:55:06,  7.76s/it] 56%|█████▌    | 5795/10395 [16:34:41<9:54:18,  7.75s/it]                                                         {'loss': 0.9128, 'learning_rate': 8.628738501154214e-06, 'epoch': 0.56}
 56%|█████▌    | 5795/10395 [16:34:41<9:54:18,  7.75s/it] 56%|█████▌    | 5796/10395 [16:34:49<9:58:52,  7.81s/it]                                                         {'loss': 0.8336, 'learning_rate': 8.625652268162169e-06, 'epoch': 0.56}
 56%|█████▌    | 5796/10395 [16:34:49<9:58:52,  7.81s/it] 56%|█████▌    | 5797/10395 [16:34:57<10:13:18,  8.00s/it]                                                          {'loss': 0.8917, 'learning_rate': 8.622566168588867e-06, 'epoch': 0.56}
 56%|█████▌    | 5797/10395 [16:34:57<10:13:18,  8.00s/it] 56%|█████▌    | 5798/10395 [16:35:05<10:09:59,  7.96s/it]                                                          {'loss': 0.821, 'learning_rate': 8.619480202733898e-06, 'epoch': 0.56}
 56%|█████▌    | 5798/10395 [16:35:05<10:09:59,  7.96s/it] 56%|█████▌    | 5799/10395 [16:35:14<10:22:11,  8.12s/it]                                                          {'loss': 0.9021, 'learning_rate': 8.616394370896843e-06, 'epoch': 0.56}
 56%|█████▌    | 5799/10395 [16:35:14<10:22:11,  8.12s/it] 56%|█████▌    | 5800/10395 [16:35:22<10:31:39,  8.25s/it]                                                          {'loss': 0.939, 'learning_rate': 8.613308673377264e-06, 'epoch': 0.56}
 56%|█████▌    | 5800/10395 [16:35:22<10:31:39,  8.25s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 56%|█████▌    | 5801/10395 [16:36:56<43:27:36, 34.06s/it]                                                          {'loss': 0.9078, 'learning_rate': 8.610223110474717e-06, 'epoch': 0.56}
 56%|█████▌    | 5801/10395 [16:36:56<43:27:36, 34.06s/it] 56%|█████▌    | 5802/10395 [16:37:04<33:25:31, 26.20s/it]                                                          {'loss': 0.9491, 'learning_rate': 8.607137682488736e-06, 'epoch': 0.56}
 56%|█████▌    | 5802/10395 [16:37:04<33:25:31, 26.20s/it] 56%|█████▌    | 5803/10395 [16:37:12<26:22:00, 20.67s/it]                                                          {'loss': 0.8489, 'learning_rate': 8.604052389718856e-06, 'epoch': 0.56}
 56%|█████▌    | 5803/10395 [16:37:12<26:22:00, 20.67s/it] 56%|█████▌    | 5804/10395 [16:37:20<21:35:24, 16.93s/it]                                                          {'loss': 0.8771, 'learning_rate': 8.600967232464583e-06, 'epoch': 0.56}
 56%|█████▌    | 5804/10395 [16:37:20<21:35:24, 16.93s/it] 56%|█████▌    | 5805/10395 [16:37:37<21:23:01, 16.77s/it]                                                          {'loss': 0.3423, 'learning_rate': 8.597882211025423e-06, 'epoch': 0.56}
 56%|█████▌    | 5805/10395 [16:37:37<21:23:01, 16.77s/it] 56%|█████▌    | 5806/10395 [16:37:44<17:47:16, 13.95s/it]                                                          {'loss': 0.9159, 'learning_rate': 8.594797325700868e-06, 'epoch': 0.56}
 56%|█████▌    | 5806/10395 [16:37:44<17:47:16, 13.95s/it] 56%|█████▌    | 5807/10395 [16:37:53<15:55:45, 12.50s/it]                                                          {'loss': 0.8553, 'learning_rate': 8.59171257679038e-06, 'epoch': 0.56}
 56%|█████▌    | 5807/10395 [16:37:53<15:55:45, 12.50s/it] 56%|█████▌    | 5808/10395 [16:38:01<14:05:23, 11.06s/it]                                                          {'loss': 0.892, 'learning_rate': 8.588627964593424e-06, 'epoch': 0.56}
 56%|█████▌    | 5808/10395 [16:38:01<14:05:23, 11.06s/it] 56%|█████▌    | 5809/10395 [16:38:09<12:55:52, 10.15s/it]                                                          {'loss': 0.9639, 'learning_rate': 8.58554348940945e-06, 'epoch': 0.56}
 56%|█████▌    | 5809/10395 [16:38:09<12:55:52, 10.15s/it] 56%|█████▌    | 5810/10395 [16:38:17<12:02:22,  9.45s/it]                                                          {'loss': 0.8931, 'learning_rate': 8.582459151537893e-06, 'epoch': 0.56}
 56%|█████▌    | 5810/10395 [16:38:17<12:02:22,  9.45s/it] 56%|█████▌    | 5811/10395 [16:38:25<11:38:53,  9.15s/it]                                                          {'loss': 0.9032, 'learning_rate': 8.579374951278171e-06, 'epoch': 0.56}
 56%|█████▌    | 5811/10395 [16:38:25<11:38:53,  9.15s/it] 56%|█████▌    | 5812/10395 [16:38:33<11:06:19,  8.72s/it]                                                          {'loss': 0.9304, 'learning_rate': 8.576290888929691e-06, 'epoch': 0.56}
 56%|█████▌    | 5812/10395 [16:38:33<11:06:19,  8.72s/it] 56%|█████▌    | 5813/10395 [16:38:40<10:38:36,  8.36s/it]                                                          {'loss': 0.9847, 'learning_rate': 8.573206964791856e-06, 'epoch': 0.56}
 56%|█████▌    | 5813/10395 [16:38:40<10:38:36,  8.36s/it] 56%|█████▌    | 5814/10395 [16:38:48<10:24:59,  8.19s/it]                                                          {'loss': 0.9257, 'learning_rate': 8.570123179164034e-06, 'epoch': 0.56}
 56%|█████▌    | 5814/10395 [16:38:48<10:24:59,  8.19s/it] 56%|█████▌    | 5815/10395 [16:38:55<9:59:27,  7.85s/it]                                                          {'loss': 0.9483, 'learning_rate': 8.567039532345597e-06, 'epoch': 0.56}
 56%|█████▌    | 5815/10395 [16:38:55<9:59:27,  7.85s/it] 56%|█████▌    | 5816/10395 [16:39:04<10:20:45,  8.13s/it]                                                          {'loss': 0.8272, 'learning_rate': 8.563956024635905e-06, 'epoch': 0.56}
 56%|█████▌    | 5816/10395 [16:39:04<10:20:45,  8.13s/it] 56%|█████▌    | 5817/10395 [16:39:12<10:12:09,  8.02s/it]                                                          {'loss': 0.9308, 'learning_rate': 8.560872656334289e-06, 'epoch': 0.56}
 56%|█████▌    | 5817/10395 [16:39:12<10:12:09,  8.02s/it] 56%|█████▌    | 5818/10395 [16:39:19<9:54:29,  7.79s/it]                                                          {'loss': 0.9136, 'learning_rate': 8.557789427740083e-06, 'epoch': 0.56}
 56%|█████▌    | 5818/10395 [16:39:19<9:54:29,  7.79s/it] 56%|█████▌    | 5819/10395 [16:39:28<10:13:38,  8.05s/it]                                                          {'loss': 0.9013, 'learning_rate': 8.554706339152593e-06, 'epoch': 0.56}
 56%|█████▌    | 5819/10395 [16:39:28<10:13:38,  8.05s/it] 56%|█████▌    | 5820/10395 [16:39:35<9:59:24,  7.86s/it]                                                          {'loss': 0.9738, 'learning_rate': 8.551623390871125e-06, 'epoch': 0.56}
 56%|█████▌    | 5820/10395 [16:39:36<9:59:24,  7.86s/it] 56%|█████▌    | 5821/10395 [16:39:43<10:03:49,  7.92s/it]                                                          {'loss': 0.8392, 'learning_rate': 8.548540583194968e-06, 'epoch': 0.56}
 56%|█████▌    | 5821/10395 [16:39:43<10:03:49,  7.92s/it] 56%|█████▌    | 5822/10395 [16:39:50<9:43:26,  7.66s/it]                                                          {'loss': 0.9214, 'learning_rate': 8.545457916423384e-06, 'epoch': 0.56}
 56%|█████▌    | 5822/10395 [16:39:50<9:43:26,  7.66s/it] 56%|█████▌    | 5823/10395 [16:39:58<9:47:49,  7.71s/it]                                                         {'loss': 0.9002, 'learning_rate': 8.542375390855638e-06, 'epoch': 0.56}
 56%|█████▌    | 5823/10395 [16:39:58<9:47:49,  7.71s/it] 56%|█████▌    | 5824/10395 [16:40:06<9:41:53,  7.64s/it]                                                         {'loss': 0.8447, 'learning_rate': 8.539293006790975e-06, 'epoch': 0.56}
 56%|█████▌    | 5824/10395 [16:40:06<9:41:53,  7.64s/it] 56%|█████▌    | 5825/10395 [16:40:14<9:55:40,  7.82s/it]                                                         {'loss': 0.8502, 'learning_rate': 8.536210764528625e-06, 'epoch': 0.56}
 56%|█████▌    | 5825/10395 [16:40:14<9:55:40,  7.82s/it] 56%|█████▌    | 5826/10395 [16:40:21<9:49:56,  7.75s/it]                                                         {'loss': 0.9049, 'learning_rate': 8.533128664367807e-06, 'epoch': 0.56}
 56%|█████▌    | 5826/10395 [16:40:21<9:49:56,  7.75s/it] 56%|█████▌    | 5827/10395 [16:40:29<9:45:50,  7.69s/it]                                                         {'loss': 0.8167, 'learning_rate': 8.53004670660772e-06, 'epoch': 0.56}
 56%|█████▌    | 5827/10395 [16:40:29<9:45:50,  7.69s/it] 56%|█████▌    | 5828/10395 [16:40:36<9:40:08,  7.62s/it]                                                         {'loss': 0.9099, 'learning_rate': 8.526964891547564e-06, 'epoch': 0.56}
 56%|█████▌    | 5828/10395 [16:40:36<9:40:08,  7.62s/it] 56%|█████▌    | 5829/10395 [16:40:44<9:32:54,  7.53s/it]                                                         {'loss': 0.8412, 'learning_rate': 8.523883219486504e-06, 'epoch': 0.56}
 56%|█████▌    | 5829/10395 [16:40:44<9:32:54,  7.53s/it] 56%|█████▌    | 5830/10395 [16:40:51<9:37:41,  7.59s/it]                                                         {'loss': 0.8847, 'learning_rate': 8.520801690723704e-06, 'epoch': 0.56}
 56%|█████▌    | 5830/10395 [16:40:51<9:37:41,  7.59s/it] 56%|█████▌    | 5831/10395 [16:40:59<9:41:35,  7.65s/it]                                                         {'loss': 0.8729, 'learning_rate': 8.517720305558318e-06, 'epoch': 0.56}
 56%|█████▌    | 5831/10395 [16:40:59<9:41:35,  7.65s/it] 56%|█████▌    | 5832/10395 [16:41:07<9:35:16,  7.56s/it]                                                         {'loss': 0.9051, 'learning_rate': 8.514639064289477e-06, 'epoch': 0.56}
 56%|█████▌    | 5832/10395 [16:41:07<9:35:16,  7.56s/it] 56%|█████▌    | 5833/10395 [16:41:14<9:36:19,  7.58s/it]                                                         {'loss': 0.9496, 'learning_rate': 8.511557967216301e-06, 'epoch': 0.56}
 56%|█████▌    | 5833/10395 [16:41:14<9:36:19,  7.58s/it] 56%|█████▌    | 5834/10395 [16:41:22<9:32:21,  7.53s/it]                                                         {'loss': 0.9185, 'learning_rate': 8.508477014637895e-06, 'epoch': 0.56}
 56%|█████▌    | 5834/10395 [16:41:22<9:32:21,  7.53s/it] 56%|█████▌    | 5835/10395 [16:41:29<9:31:47,  7.52s/it]                                                         {'loss': 0.9353, 'learning_rate': 8.505396206853358e-06, 'epoch': 0.56}
 56%|█████▌    | 5835/10395 [16:41:29<9:31:47,  7.52s/it] 56%|█████▌    | 5836/10395 [16:41:37<9:40:58,  7.65s/it]                                                         {'loss': 0.896, 'learning_rate': 8.50231554416176e-06, 'epoch': 0.56}
 56%|█████▌    | 5836/10395 [16:41:37<9:40:58,  7.65s/it] 56%|█████▌    | 5837/10395 [16:41:45<9:38:29,  7.62s/it]                                                         {'loss': 0.9288, 'learning_rate': 8.49923502686217e-06, 'epoch': 0.56}
 56%|█████▌    | 5837/10395 [16:41:45<9:38:29,  7.62s/it] 56%|█████▌    | 5838/10395 [16:41:53<9:48:09,  7.74s/it]                                                         {'loss': 0.8644, 'learning_rate': 8.496154655253632e-06, 'epoch': 0.56}
 56%|█████▌    | 5838/10395 [16:41:53<9:48:09,  7.74s/it] 56%|█████▌    | 5839/10395 [16:42:00<9:48:28,  7.75s/it]                                                         {'loss': 0.9711, 'learning_rate': 8.493074429635188e-06, 'epoch': 0.56}
 56%|█████▌    | 5839/10395 [16:42:00<9:48:28,  7.75s/it] 56%|█████▌    | 5840/10395 [16:42:08<9:55:07,  7.84s/it]                                                         {'loss': 0.8775, 'learning_rate': 8.48999435030586e-06, 'epoch': 0.56}
 56%|█████▌    | 5840/10395 [16:42:08<9:55:07,  7.84s/it] 56%|█████▌    | 5841/10395 [16:42:16<9:51:31,  7.79s/it]                                                         {'loss': 0.863, 'learning_rate': 8.486914417564653e-06, 'epoch': 0.56}
 56%|█████▌    | 5841/10395 [16:42:16<9:51:31,  7.79s/it] 56%|█████▌    | 5842/10395 [16:42:24<9:47:34,  7.74s/it]                                                         {'loss': 0.8678, 'learning_rate': 8.483834631710561e-06, 'epoch': 0.56}
 56%|█████▌    | 5842/10395 [16:42:24<9:47:34,  7.74s/it] 56%|█████▌    | 5843/10395 [16:42:32<9:48:32,  7.76s/it]                                                         {'loss': 0.8615, 'learning_rate': 8.480754993042565e-06, 'epoch': 0.56}
 56%|█████▌    | 5843/10395 [16:42:32<9:48:32,  7.76s/it] 56%|█████▌    | 5844/10395 [16:42:40<10:07:46,  8.01s/it]                                                          {'loss': 0.9398, 'learning_rate': 8.477675501859625e-06, 'epoch': 0.56}
 56%|█████▌    | 5844/10395 [16:42:40<10:07:46,  8.01s/it] 56%|█████▌    | 5845/10395 [16:42:48<10:04:54,  7.98s/it]                                                          {'loss': 0.8735, 'learning_rate': 8.474596158460694e-06, 'epoch': 0.56}
 56%|█████▌    | 5845/10395 [16:42:48<10:04:54,  7.98s/it] 56%|█████▌    | 5846/10395 [16:42:55<9:50:36,  7.79s/it]                                                          {'loss': 0.8609, 'learning_rate': 8.471516963144707e-06, 'epoch': 0.56}
 56%|█████▌    | 5846/10395 [16:42:55<9:50:36,  7.79s/it] 56%|█████▌    | 5847/10395 [16:43:03<9:37:41,  7.62s/it]                                                         {'loss': 0.9266, 'learning_rate': 8.468437916210588e-06, 'epoch': 0.56}
 56%|█████▌    | 5847/10395 [16:43:03<9:37:41,  7.62s/it] 56%|█████▋    | 5848/10395 [16:43:10<9:33:18,  7.57s/it]                                                         {'loss': 0.9277, 'learning_rate': 8.465359017957244e-06, 'epoch': 0.56}
 56%|█████▋    | 5848/10395 [16:43:10<9:33:18,  7.57s/it] 56%|█████▋    | 5849/10395 [16:43:19<10:07:46,  8.02s/it]                                                          {'loss': 0.896, 'learning_rate': 8.462280268683568e-06, 'epoch': 0.56}
 56%|█████▋    | 5849/10395 [16:43:19<10:07:46,  8.02s/it] 56%|█████▋    | 5850/10395 [16:43:27<9:52:04,  7.82s/it]                                                          {'loss': 0.8814, 'learning_rate': 8.459201668688437e-06, 'epoch': 0.56}
 56%|█████▋    | 5850/10395 [16:43:27<9:52:04,  7.82s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 56%|█████▋    | 5851/10395 [16:45:05<44:17:26, 35.09s/it]                                                          {'loss': 0.916, 'learning_rate': 8.456123218270714e-06, 'epoch': 0.56}
 56%|█████▋    | 5851/10395 [16:45:05<44:17:26, 35.09s/it] 56%|█████▋    | 5852/10395 [16:45:14<34:07:27, 27.04s/it]                                                          {'loss': 0.8674, 'learning_rate': 8.45304491772925e-06, 'epoch': 0.56}
 56%|█████▋    | 5852/10395 [16:45:14<34:07:27, 27.04s/it] 56%|█████▋    | 5853/10395 [16:45:21<26:38:15, 21.11s/it]                                                          {'loss': 0.9718, 'learning_rate': 8.449966767362877e-06, 'epoch': 0.56}
 56%|█████▋    | 5853/10395 [16:45:21<26:38:15, 21.11s/it] 56%|█████▋    | 5854/10395 [16:45:29<21:34:05, 17.10s/it]                                                          {'loss': 0.8811, 'learning_rate': 8.44688876747042e-06, 'epoch': 0.56}
 56%|█████▋    | 5854/10395 [16:45:29<21:34:05, 17.10s/it] 56%|█████▋    | 5855/10395 [16:45:36<18:00:01, 14.27s/it]                                                          {'loss': 0.893, 'learning_rate': 8.443810918350683e-06, 'epoch': 0.56}
 56%|█████▋    | 5855/10395 [16:45:36<18:00:01, 14.27s/it] 56%|█████▋    | 5856/10395 [16:45:44<15:33:49, 12.34s/it]                                                          {'loss': 0.8852, 'learning_rate': 8.440733220302455e-06, 'epoch': 0.56}
 56%|█████▋    | 5856/10395 [16:45:44<15:33:49, 12.34s/it] 56%|█████▋    | 5857/10395 [16:46:02<17:43:55, 14.07s/it]                                                          {'loss': 0.3794, 'learning_rate': 8.43765567362452e-06, 'epoch': 0.56}
 56%|█████▋    | 5857/10395 [16:46:02<17:43:55, 14.07s/it] 56%|█████▋    | 5858/10395 [16:46:10<15:28:09, 12.27s/it]                                                          {'loss': 0.8583, 'learning_rate': 8.434578278615627e-06, 'epoch': 0.56}
 56%|█████▋    | 5858/10395 [16:46:10<15:28:09, 12.27s/it] 56%|█████▋    | 5859/10395 [16:46:19<14:05:32, 11.18s/it]                                                          {'loss': 0.9346, 'learning_rate': 8.431501035574532e-06, 'epoch': 0.56}
 56%|█████▋    | 5859/10395 [16:46:19<14:05:32, 11.18s/it] 56%|█████▋    | 5860/10395 [16:46:26<12:36:35, 10.01s/it]                                                          {'loss': 0.8925, 'learning_rate': 8.428423944799962e-06, 'epoch': 0.56}
 56%|█████▋    | 5860/10395 [16:46:26<12:36:35, 10.01s/it] 56%|█████▋    | 5861/10395 [16:46:34<11:42:52,  9.30s/it]                                                          {'loss': 0.882, 'learning_rate': 8.425347006590637e-06, 'epoch': 0.56}
 56%|█████▋    | 5861/10395 [16:46:34<11:42:52,  9.30s/it] 56%|█████▋    | 5862/10395 [16:46:42<11:22:27,  9.03s/it]                                                          {'loss': 0.8414, 'learning_rate': 8.42227022124526e-06, 'epoch': 0.56}
 56%|█████▋    | 5862/10395 [16:46:42<11:22:27,  9.03s/it] 56%|█████▋    | 5863/10395 [16:46:50<10:50:17,  8.61s/it]                                                          {'loss': 0.8719, 'learning_rate': 8.41919358906252e-06, 'epoch': 0.56}
 56%|█████▋    | 5863/10395 [16:46:50<10:50:17,  8.61s/it] 56%|█████▋    | 5864/10395 [16:46:58<10:40:16,  8.48s/it]                                                          {'loss': 0.888, 'learning_rate': 8.416117110341087e-06, 'epoch': 0.56}
 56%|█████▋    | 5864/10395 [16:46:58<10:40:16,  8.48s/it] 56%|█████▋    | 5865/10395 [16:47:08<11:20:27,  9.01s/it]                                                          {'loss': 0.8157, 'learning_rate': 8.413040785379623e-06, 'epoch': 0.56}
 56%|█████▋    | 5865/10395 [16:47:08<11:20:27,  9.01s/it] 56%|█████▋    | 5866/10395 [16:47:16<10:59:26,  8.74s/it]                                                          {'loss': 0.8515, 'learning_rate': 8.409964614476766e-06, 'epoch': 0.56}
 56%|█████▋    | 5866/10395 [16:47:16<10:59:26,  8.74s/it] 56%|█████▋    | 5867/10395 [16:47:24<10:29:28,  8.34s/it]                                                          {'loss': 0.7983, 'learning_rate': 8.406888597931145e-06, 'epoch': 0.56}
 56%|█████▋    | 5867/10395 [16:47:24<10:29:28,  8.34s/it] 56%|█████▋    | 5868/10395 [16:47:31<10:00:37,  7.96s/it]                                                          {'loss': 0.8467, 'learning_rate': 8.403812736041375e-06, 'epoch': 0.56}
 56%|█████▋    | 5868/10395 [16:47:31<10:00:37,  7.96s/it] 56%|█████▋    | 5869/10395 [16:47:39<9:55:32,  7.89s/it]                                                          {'loss': 0.8887, 'learning_rate': 8.400737029106051e-06, 'epoch': 0.56}
 56%|█████▋    | 5869/10395 [16:47:39<9:55:32,  7.89s/it] 56%|█████▋    | 5870/10395 [16:47:46<9:40:15,  7.69s/it]                                                         {'loss': 0.9976, 'learning_rate': 8.397661477423764e-06, 'epoch': 0.56}
 56%|█████▋    | 5870/10395 [16:47:46<9:40:15,  7.69s/it] 56%|█████▋    | 5871/10395 [16:47:54<9:48:32,  7.81s/it]                                                         {'loss': 0.7993, 'learning_rate': 8.394586081293073e-06, 'epoch': 0.56}
 56%|█████▋    | 5871/10395 [16:47:54<9:48:32,  7.81s/it] 56%|█████▋    | 5872/10395 [16:48:03<10:14:54,  8.16s/it]                                                          {'loss': 0.8744, 'learning_rate': 8.391510841012539e-06, 'epoch': 0.56}
 56%|█████▋    | 5872/10395 [16:48:03<10:14:54,  8.16s/it] 56%|█████▋    | 5873/10395 [16:48:10<9:56:56,  7.92s/it]                                                          {'loss': 0.9591, 'learning_rate': 8.388435756880691e-06, 'epoch': 0.56}
 56%|█████▋    | 5873/10395 [16:48:10<9:56:56,  7.92s/it] 57%|█████▋    | 5874/10395 [16:48:27<13:20:14, 10.62s/it]                                                          {'loss': 0.3871, 'learning_rate': 8.385360829196056e-06, 'epoch': 0.57}
 57%|█████▋    | 5874/10395 [16:48:27<13:20:14, 10.62s/it] 57%|█████▋    | 5875/10395 [16:48:35<12:27:09,  9.92s/it]                                                          {'loss': 0.9535, 'learning_rate': 8.382286058257143e-06, 'epoch': 0.57}
 57%|█████▋    | 5875/10395 [16:48:35<12:27:09,  9.92s/it] 57%|█████▋    | 5876/10395 [16:48:45<12:15:10,  9.76s/it]                                                          {'loss': 0.9602, 'learning_rate': 8.37921144436244e-06, 'epoch': 0.57}
 57%|█████▋    | 5876/10395 [16:48:45<12:15:10,  9.76s/it] 57%|█████▋    | 5877/10395 [16:48:52<11:19:39,  9.03s/it]                                                          {'loss': 0.9128, 'learning_rate': 8.376136987810426e-06, 'epoch': 0.57}
 57%|█████▋    | 5877/10395 [16:48:52<11:19:39,  9.03s/it] 57%|█████▋    | 5878/10395 [16:49:09<14:20:09, 11.43s/it]                                                          {'loss': 0.4067, 'learning_rate': 8.373062688899564e-06, 'epoch': 0.57}
 57%|█████▋    | 5878/10395 [16:49:09<14:20:09, 11.43s/it] 57%|█████▋    | 5879/10395 [16:49:17<13:08:32, 10.48s/it]                                                          {'loss': 0.8604, 'learning_rate': 8.369988547928302e-06, 'epoch': 0.57}
 57%|█████▋    | 5879/10395 [16:49:17<13:08:32, 10.48s/it] 57%|█████▋    | 5880/10395 [16:49:25<12:04:27,  9.63s/it]                                                          {'loss': 0.8568, 'learning_rate': 8.366914565195066e-06, 'epoch': 0.57}
 57%|█████▋    | 5880/10395 [16:49:25<12:04:27,  9.63s/it] 57%|█████▋    | 5881/10395 [16:49:34<11:38:30,  9.28s/it]                                                          {'loss': 0.8961, 'learning_rate': 8.363840740998275e-06, 'epoch': 0.57}
 57%|█████▋    | 5881/10395 [16:49:34<11:38:30,  9.28s/it] 57%|█████▋    | 5882/10395 [16:49:40<10:43:11,  8.55s/it]                                                          {'loss': 0.9449, 'learning_rate': 8.360767075636328e-06, 'epoch': 0.57}
 57%|█████▋    | 5882/10395 [16:49:40<10:43:11,  8.55s/it] 57%|█████▋    | 5883/10395 [16:49:49<10:40:59,  8.52s/it]                                                          {'loss': 0.8729, 'learning_rate': 8.35769356940761e-06, 'epoch': 0.57}
 57%|█████▋    | 5883/10395 [16:49:49<10:40:59,  8.52s/it] 57%|█████▋    | 5884/10395 [16:49:57<10:31:28,  8.40s/it]                                                          {'loss': 0.8247, 'learning_rate': 8.354620222610488e-06, 'epoch': 0.57}
 57%|█████▋    | 5884/10395 [16:49:57<10:31:28,  8.40s/it] 57%|█████▋    | 5885/10395 [16:50:05<10:21:36,  8.27s/it]                                                          {'loss': 0.9152, 'learning_rate': 8.351547035543323e-06, 'epoch': 0.57}
 57%|█████▋    | 5885/10395 [16:50:05<10:21:36,  8.27s/it] 57%|█████▋    | 5886/10395 [16:50:12<10:02:32,  8.02s/it]                                                          {'loss': 0.8681, 'learning_rate': 8.348474008504447e-06, 'epoch': 0.57}
 57%|█████▋    | 5886/10395 [16:50:12<10:02:32,  8.02s/it] 57%|█████▋    | 5887/10395 [16:50:28<13:05:06, 10.45s/it]                                                          {'loss': 0.3729, 'learning_rate': 8.345401141792188e-06, 'epoch': 0.57}
 57%|█████▋    | 5887/10395 [16:50:28<13:05:06, 10.45s/it] 57%|█████▋    | 5888/10395 [16:50:36<12:06:36,  9.67s/it]                                                          {'loss': 0.8301, 'learning_rate': 8.342328435704847e-06, 'epoch': 0.57}
 57%|█████▋    | 5888/10395 [16:50:36<12:06:36,  9.67s/it] 57%|█████▋    | 5889/10395 [16:50:44<11:20:52,  9.07s/it]                                                          {'loss': 0.8761, 'learning_rate': 8.33925589054072e-06, 'epoch': 0.57}
 57%|█████▋    | 5889/10395 [16:50:44<11:20:52,  9.07s/it] 57%|█████▋    | 5890/10395 [16:50:53<11:17:07,  9.02s/it]                                                          {'loss': 0.9138, 'learning_rate': 8.336183506598081e-06, 'epoch': 0.57}
 57%|█████▋    | 5890/10395 [16:50:53<11:17:07,  9.02s/it] 57%|█████▋    | 5891/10395 [16:51:01<10:57:18,  8.76s/it]                                                          {'loss': 0.8983, 'learning_rate': 8.333111284175193e-06, 'epoch': 0.57}
 57%|█████▋    | 5891/10395 [16:51:01<10:57:18,  8.76s/it] 57%|█████▋    | 5892/10395 [16:51:09<10:33:23,  8.44s/it]                                                          {'loss': 0.8702, 'learning_rate': 8.330039223570296e-06, 'epoch': 0.57}
 57%|█████▋    | 5892/10395 [16:51:09<10:33:23,  8.44s/it] 57%|█████▋    | 5893/10395 [16:51:17<10:21:25,  8.28s/it]                                                          {'loss': 1.0415, 'learning_rate': 8.326967325081626e-06, 'epoch': 0.57}
 57%|█████▋    | 5893/10395 [16:51:17<10:21:25,  8.28s/it] 57%|█████▋    | 5894/10395 [16:51:24<9:58:05,  7.97s/it]                                                          {'loss': 0.9492, 'learning_rate': 8.323895589007395e-06, 'epoch': 0.57}
 57%|█████▋    | 5894/10395 [16:51:24<9:58:05,  7.97s/it] 57%|█████▋    | 5895/10395 [16:51:32<9:52:55,  7.91s/it]                                                         {'loss': 0.9301, 'learning_rate': 8.320824015645794e-06, 'epoch': 0.57}
 57%|█████▋    | 5895/10395 [16:51:32<9:52:55,  7.91s/it] 57%|█████▋    | 5896/10395 [16:51:40<9:51:55,  7.89s/it]                                                         {'loss': 0.8187, 'learning_rate': 8.31775260529501e-06, 'epoch': 0.57}
 57%|█████▋    | 5896/10395 [16:51:40<9:51:55,  7.89s/it] 57%|█████▋    | 5897/10395 [16:51:48<10:00:18,  8.01s/it]                                                          {'loss': 0.9117, 'learning_rate': 8.314681358253208e-06, 'epoch': 0.57}
 57%|█████▋    | 5897/10395 [16:51:48<10:00:18,  8.01s/it] 57%|█████▋    | 5898/10395 [16:51:55<9:51:33,  7.89s/it]                                                          {'loss': 0.963, 'learning_rate': 8.31161027481854e-06, 'epoch': 0.57}
 57%|█████▋    | 5898/10395 [16:51:55<9:51:33,  7.89s/it] 57%|█████▋    | 5899/10395 [16:52:04<9:56:43,  7.96s/it]                                                         {'loss': 0.9098, 'learning_rate': 8.308539355289137e-06, 'epoch': 0.57}
 57%|█████▋    | 5899/10395 [16:52:04<9:56:43,  7.96s/it] 57%|█████▋    | 5900/10395 [16:52:11<9:47:03,  7.84s/it]                                                         {'loss': 0.8607, 'learning_rate': 8.305468599963116e-06, 'epoch': 0.57}
 57%|█████▋    | 5900/10395 [16:52:11<9:47:03,  7.84s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 57%|█████▋    | 5901/10395 [16:53:49<43:27:16, 34.81s/it]                                                          {'loss': 0.8695, 'learning_rate': 8.302398009138586e-06, 'epoch': 0.57}
 57%|█████▋    | 5901/10395 [16:53:49<43:27:16, 34.81s/it] 57%|█████▋    | 5902/10395 [16:53:56<33:03:43, 26.49s/it]                                                          {'loss': 0.9095, 'learning_rate': 8.299327583113633e-06, 'epoch': 0.57}
 57%|█████▋    | 5902/10395 [16:53:56<33:03:43, 26.49s/it] 57%|█████▋    | 5903/10395 [16:54:03<25:56:13, 20.79s/it]                                                          {'loss': 0.8859, 'learning_rate': 8.296257322186316e-06, 'epoch': 0.57}
 57%|█████▋    | 5903/10395 [16:54:03<25:56:13, 20.79s/it] 57%|█████▋    | 5904/10395 [16:54:11<21:03:07, 16.88s/it]                                                          {'loss': 0.8425, 'learning_rate': 8.2931872266547e-06, 'epoch': 0.57}
 57%|█████▋    | 5904/10395 [16:54:12<21:03:07, 16.88s/it] 57%|█████▋    | 5905/10395 [16:54:19<17:48:58, 14.28s/it]                                                          {'loss': 0.9109, 'learning_rate': 8.290117296816822e-06, 'epoch': 0.57}
 57%|█████▋    | 5905/10395 [16:54:19<17:48:58, 14.28s/it] 57%|█████▋    | 5906/10395 [16:54:27<15:18:58, 12.28s/it]                                                          {'loss': 0.9604, 'learning_rate': 8.287047532970702e-06, 'epoch': 0.57}
 57%|█████▋    | 5906/10395 [16:54:27<15:18:58, 12.28s/it] 57%|█████▋    | 5907/10395 [16:54:34<13:28:14, 10.81s/it]                                                          {'loss': 0.8842, 'learning_rate': 8.283977935414346e-06, 'epoch': 0.57}
 57%|█████▋    | 5907/10395 [16:54:34<13:28:14, 10.81s/it] 57%|█████▋    | 5908/10395 [16:54:42<12:12:32,  9.80s/it]                                                          {'loss': 0.9075, 'learning_rate': 8.280908504445744e-06, 'epoch': 0.57}
 57%|█████▋    | 5908/10395 [16:54:42<12:12:32,  9.80s/it] 57%|█████▋    | 5909/10395 [16:54:50<11:33:59,  9.28s/it]                                                          {'loss': 0.8956, 'learning_rate': 8.277839240362877e-06, 'epoch': 0.57}
 57%|█████▋    | 5909/10395 [16:54:50<11:33:59,  9.28s/it] 57%|█████▋    | 5910/10395 [16:54:59<11:33:27,  9.28s/it]                                                          {'loss': 0.8365, 'learning_rate': 8.274770143463692e-06, 'epoch': 0.57}
 57%|█████▋    | 5910/10395 [16:54:59<11:33:27,  9.28s/it] 57%|█████▋    | 5911/10395 [16:55:06<10:46:44,  8.65s/it]                                                          {'loss': 0.8785, 'learning_rate': 8.271701214046132e-06, 'epoch': 0.57}
 57%|█████▋    | 5911/10395 [16:55:06<10:46:44,  8.65s/it] 57%|█████▋    | 5912/10395 [16:55:15<10:42:51,  8.60s/it]                                                          {'loss': 0.8817, 'learning_rate': 8.268632452408127e-06, 'epoch': 0.57}
 57%|█████▋    | 5912/10395 [16:55:15<10:42:51,  8.60s/it] 57%|█████▋    | 5913/10395 [16:55:22<10:18:41,  8.28s/it]                                                          {'loss': 1.0353, 'learning_rate': 8.265563858847584e-06, 'epoch': 0.57}
 57%|█████▋    | 5913/10395 [16:55:22<10:18:41,  8.28s/it] 57%|█████▋    | 5914/10395 [16:55:30<10:00:39,  8.04s/it]                                                          {'loss': 0.8587, 'learning_rate': 8.262495433662396e-06, 'epoch': 0.57}
 57%|█████▋    | 5914/10395 [16:55:30<10:00:39,  8.04s/it] 57%|█████▋    | 5915/10395 [16:55:37<9:51:15,  7.92s/it]                                                          {'loss': 0.9621, 'learning_rate': 8.259427177150434e-06, 'epoch': 0.57}
 57%|█████▋    | 5915/10395 [16:55:37<9:51:15,  7.92s/it] 57%|█████▋    | 5916/10395 [16:55:46<9:57:14,  8.00s/it]                                                         {'loss': 0.8589, 'learning_rate': 8.25635908960957e-06, 'epoch': 0.57}
 57%|█████▋    | 5916/10395 [16:55:46<9:57:14,  8.00s/it] 57%|█████▋    | 5917/10395 [16:55:55<10:18:48,  8.29s/it]                                                          {'loss': 0.8871, 'learning_rate': 8.253291171337635e-06, 'epoch': 0.57}
 57%|█████▋    | 5917/10395 [16:55:55<10:18:48,  8.29s/it] 57%|█████▋    | 5918/10395 [16:56:11<13:20:15, 10.73s/it]                                                          {'loss': 0.4053, 'learning_rate': 8.250223422632456e-06, 'epoch': 0.57}
 57%|█████▋    | 5918/10395 [16:56:11<13:20:15, 10.73s/it] 57%|█████▋    | 5919/10395 [16:56:19<12:09:50,  9.78s/it]                                                          {'loss': 0.9599, 'learning_rate': 8.247155843791852e-06, 'epoch': 0.57}
 57%|█████▋    | 5919/10395 [16:56:19<12:09:50,  9.78s/it] 57%|█████▋    | 5920/10395 [16:56:27<11:31:53,  9.28s/it]                                                          {'loss': 0.8665, 'learning_rate': 8.244088435113613e-06, 'epoch': 0.57}
 57%|█████▋    | 5920/10395 [16:56:27<11:31:53,  9.28s/it] 57%|█████▋    | 5921/10395 [16:56:35<11:08:16,  8.96s/it]                                                          {'loss': 0.9409, 'learning_rate': 8.241021196895516e-06, 'epoch': 0.57}
 57%|█████▋    | 5921/10395 [16:56:35<11:08:16,  8.96s/it] 57%|█████▋    | 5922/10395 [16:56:43<10:39:40,  8.58s/it]                                                          {'loss': 0.8263, 'learning_rate': 8.237954129435322e-06, 'epoch': 0.57}
 57%|█████▋    | 5922/10395 [16:56:43<10:39:40,  8.58s/it] 57%|█████▋    | 5923/10395 [16:56:50<10:08:29,  8.16s/it]                                                          {'loss': 0.9451, 'learning_rate': 8.234887233030772e-06, 'epoch': 0.57}
 57%|█████▋    | 5923/10395 [16:56:50<10:08:29,  8.16s/it] 57%|█████▋    | 5924/10395 [16:57:07<13:27:26, 10.84s/it]                                                          {'loss': 0.2976, 'learning_rate': 8.231820507979607e-06, 'epoch': 0.57}
 57%|█████▋    | 5924/10395 [16:57:07<13:27:26, 10.84s/it] 57%|█████▋    | 5925/10395 [16:57:15<12:28:45, 10.05s/it]                                                          {'loss': 0.9185, 'learning_rate': 8.22875395457952e-06, 'epoch': 0.57}
 57%|█████▋    | 5925/10395 [16:57:15<12:28:45, 10.05s/it] 57%|█████▋    | 5926/10395 [16:57:23<11:30:50,  9.28s/it]                                                          {'loss': 0.9206, 'learning_rate': 8.225687573128216e-06, 'epoch': 0.57}
 57%|█████▋    | 5926/10395 [16:57:23<11:30:50,  9.28s/it] 57%|█████▋    | 5927/10395 [16:57:30<10:58:05,  8.84s/it]                                                          {'loss': 0.9396, 'learning_rate': 8.222621363923371e-06, 'epoch': 0.57}
 57%|█████▋    | 5927/10395 [16:57:30<10:58:05,  8.84s/it] 57%|█████▋    | 5928/10395 [16:57:38<10:26:28,  8.41s/it]                                                          {'loss': 0.9277, 'learning_rate': 8.219555327262647e-06, 'epoch': 0.57}
 57%|█████▋    | 5928/10395 [16:57:38<10:26:28,  8.41s/it] 57%|█████▋    | 5929/10395 [16:57:46<10:11:25,  8.21s/it]                                                          {'loss': 0.8935, 'learning_rate': 8.216489463443684e-06, 'epoch': 0.57}
 57%|█████▋    | 5929/10395 [16:57:46<10:11:25,  8.21s/it] 57%|█████▋    | 5930/10395 [16:57:54<10:10:28,  8.20s/it]                                                          {'loss': 0.8694, 'learning_rate': 8.213423772764115e-06, 'epoch': 0.57}
 57%|█████▋    | 5930/10395 [16:57:54<10:10:28,  8.20s/it] 57%|█████▋    | 5931/10395 [16:58:01<9:56:42,  8.02s/it]                                                          {'loss': 0.9049, 'learning_rate': 8.21035825552155e-06, 'epoch': 0.57}
 57%|█████▋    | 5931/10395 [16:58:01<9:56:42,  8.02s/it] 57%|█████▋    | 5932/10395 [16:58:09<9:59:39,  8.06s/it]                                                         {'loss': 0.9414, 'learning_rate': 8.207292912013578e-06, 'epoch': 0.57}
 57%|█████▋    | 5932/10395 [16:58:09<9:59:39,  8.06s/it] 57%|█████▋    | 5933/10395 [16:58:18<10:05:34,  8.14s/it]                                                          {'loss': 0.8492, 'learning_rate': 8.20422774253778e-06, 'epoch': 0.57}
 57%|█████▋    | 5933/10395 [16:58:18<10:05:34,  8.14s/it] 57%|█████▋    | 5934/10395 [16:58:25<9:39:48,  7.80s/it]                                                          {'loss': 0.9469, 'learning_rate': 8.201162747391713e-06, 'epoch': 0.57}
 57%|█████▋    | 5934/10395 [16:58:25<9:39:48,  7.80s/it] 57%|█████▋    | 5935/10395 [16:58:32<9:33:29,  7.72s/it]                                                         {'loss': 0.9398, 'learning_rate': 8.198097926872925e-06, 'epoch': 0.57}
 57%|█████▋    | 5935/10395 [16:58:32<9:33:29,  7.72s/it] 57%|█████▋    | 5936/10395 [16:58:40<9:33:50,  7.72s/it]                                                         {'loss': 0.8904, 'learning_rate': 8.195033281278937e-06, 'epoch': 0.57}
 57%|█████▋    | 5936/10395 [16:58:40<9:33:50,  7.72s/it] 57%|█████▋    | 5937/10395 [16:58:58<13:17:08, 10.73s/it]                                                          {'loss': 0.396, 'learning_rate': 8.191968810907264e-06, 'epoch': 0.57}
 57%|█████▋    | 5937/10395 [16:58:58<13:17:08, 10.73s/it] 57%|█████▋    | 5938/10395 [16:59:16<16:10:47, 13.07s/it]                                                          {'loss': 0.3979, 'learning_rate': 8.188904516055395e-06, 'epoch': 0.57}
 57%|█████▋    | 5938/10395 [16:59:16<16:10:47, 13.07s/it] 57%|█████▋    | 5939/10395 [16:59:24<14:09:56, 11.44s/it]                                                          {'loss': 0.8511, 'learning_rate': 8.185840397020805e-06, 'epoch': 0.57}
 57%|█████▋    | 5939/10395 [16:59:24<14:09:56, 11.44s/it] 57%|█████▋    | 5940/10395 [16:59:31<12:35:38, 10.18s/it]                                                          {'loss': 0.8926, 'learning_rate': 8.182776454100951e-06, 'epoch': 0.57}
 57%|█████▋    | 5940/10395 [16:59:31<12:35:38, 10.18s/it] 57%|█████▋    | 5941/10395 [16:59:39<11:35:05,  9.36s/it]                                                          {'loss': 0.987, 'learning_rate': 8.179712687593276e-06, 'epoch': 0.57}
 57%|█████▋    | 5941/10395 [16:59:39<11:35:05,  9.36s/it] 57%|█████▋    | 5942/10395 [16:59:46<10:54:20,  8.82s/it]                                                          {'loss': 0.9524, 'learning_rate': 8.1766490977952e-06, 'epoch': 0.57}
 57%|█████▋    | 5942/10395 [16:59:46<10:54:20,  8.82s/it] 57%|█████▋    | 5943/10395 [16:59:54<10:32:41,  8.53s/it]                                                          {'loss': 0.8487, 'learning_rate': 8.173585685004137e-06, 'epoch': 0.57}
 57%|█████▋    | 5943/10395 [16:59:54<10:32:41,  8.53s/it] 57%|█████▋    | 5944/10395 [17:00:03<10:34:45,  8.56s/it]                                                          {'loss': 0.9102, 'learning_rate': 8.170522449517472e-06, 'epoch': 0.57}
 57%|█████▋    | 5944/10395 [17:00:03<10:34:45,  8.56s/it] 57%|█████▋    | 5945/10395 [17:00:11<10:28:48,  8.48s/it]                                                          {'loss': 0.9333, 'learning_rate': 8.167459391632577e-06, 'epoch': 0.57}
 57%|█████▋    | 5945/10395 [17:00:11<10:28:48,  8.48s/it] 57%|█████▋    | 5946/10395 [17:00:19<10:12:04,  8.25s/it]                                                          {'loss': 0.8674, 'learning_rate': 8.164396511646811e-06, 'epoch': 0.57}
 57%|█████▋    | 5946/10395 [17:00:19<10:12:04,  8.25s/it] 57%|█████▋    | 5947/10395 [17:00:26<9:52:04,  7.99s/it]                                                          {'loss': 0.9893, 'learning_rate': 8.161333809857508e-06, 'epoch': 0.57}
 57%|█████▋    | 5947/10395 [17:00:26<9:52:04,  7.99s/it] 57%|█████▋    | 5948/10395 [17:00:33<9:36:05,  7.77s/it]                                                         {'loss': 0.9943, 'learning_rate': 8.158271286561987e-06, 'epoch': 0.57}
 57%|█████▋    | 5948/10395 [17:00:33<9:36:05,  7.77s/it] 57%|█████▋    | 5949/10395 [17:00:42<9:45:08,  7.90s/it]                                                         {'loss': 0.8419, 'learning_rate': 8.155208942057555e-06, 'epoch': 0.57}
 57%|█████▋    | 5949/10395 [17:00:42<9:45:08,  7.90s/it] 57%|█████▋    | 5950/10395 [17:00:49<9:32:39,  7.73s/it]                                                         {'loss': 0.8892, 'learning_rate': 8.152146776641496e-06, 'epoch': 0.57}
 57%|█████▋    | 5950/10395 [17:00:49<9:32:39,  7.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 57%|█████▋    | 5951/10395 [17:02:30<44:14:58, 35.85s/it]                                                          {'loss': 0.8423, 'learning_rate': 8.149084790611079e-06, 'epoch': 0.57}
 57%|█████▋    | 5951/10395 [17:02:30<44:14:58, 35.85s/it] 57%|█████▋    | 5952/10395 [17:02:38<33:42:56, 27.32s/it]                                                          {'loss': 0.9108, 'learning_rate': 8.146022984263557e-06, 'epoch': 0.57}
 57%|█████▋    | 5952/10395 [17:02:38<33:42:56, 27.32s/it] 57%|█████▋    | 5953/10395 [17:02:46<26:33:28, 21.52s/it]                                                          {'loss': 0.9292, 'learning_rate': 8.142961357896162e-06, 'epoch': 0.57}
 57%|█████▋    | 5953/10395 [17:02:46<26:33:28, 21.52s/it] 57%|█████▋    | 5954/10395 [17:02:54<21:27:28, 17.39s/it]                                                          {'loss': 0.9465, 'learning_rate': 8.139899911806108e-06, 'epoch': 0.57}
 57%|█████▋    | 5954/10395 [17:02:54<21:27:28, 17.39s/it] 57%|█████▋    | 5955/10395 [17:03:01<17:51:24, 14.48s/it]                                                          {'loss': 0.8792, 'learning_rate': 8.136838646290596e-06, 'epoch': 0.57}
 57%|█████▋    | 5955/10395 [17:03:01<17:51:24, 14.48s/it] 57%|█████▋    | 5956/10395 [17:03:09<15:28:11, 12.55s/it]                                                          {'loss': 0.924, 'learning_rate': 8.133777561646807e-06, 'epoch': 0.57}
 57%|█████▋    | 5956/10395 [17:03:09<15:28:11, 12.55s/it] 57%|█████▋    | 5957/10395 [17:03:18<14:07:46, 11.46s/it]                                                          {'loss': 0.8692, 'learning_rate': 8.1307166581719e-06, 'epoch': 0.57}
 57%|█████▋    | 5957/10395 [17:03:18<14:07:46, 11.46s/it] 57%|█████▋    | 5958/10395 [17:03:27<13:00:46, 10.56s/it]                                                          {'loss': 0.8348, 'learning_rate': 8.12765593616303e-06, 'epoch': 0.57}
 57%|█████▋    | 5958/10395 [17:03:27<13:00:46, 10.56s/it] 57%|█████▋    | 5959/10395 [17:03:34<11:55:41,  9.68s/it]                                                          {'loss': 0.8406, 'learning_rate': 8.12459539591732e-06, 'epoch': 0.57}
 57%|█████▋    | 5959/10395 [17:03:34<11:55:41,  9.68s/it] 57%|█████▋    | 5960/10395 [17:03:43<11:24:26,  9.26s/it]                                                          {'loss': 0.8885, 'learning_rate': 8.121535037731883e-06, 'epoch': 0.57}
 57%|█████▋    | 5960/10395 [17:03:43<11:24:26,  9.26s/it] 57%|█████▋    | 5961/10395 [17:03:50<10:52:22,  8.83s/it]                                                          {'loss': 0.8819, 'learning_rate': 8.118474861903807e-06, 'epoch': 0.57}
 57%|█████▋    | 5961/10395 [17:03:50<10:52:22,  8.83s/it] 57%|█████▋    | 5962/10395 [17:03:58<10:27:37,  8.49s/it]                                                          {'loss': 0.9055, 'learning_rate': 8.11541486873017e-06, 'epoch': 0.57}
 57%|█████▋    | 5962/10395 [17:03:58<10:27:37,  8.49s/it] 57%|█████▋    | 5963/10395 [17:04:05<9:56:07,  8.07s/it]                                                          {'loss': 0.9629, 'learning_rate': 8.112355058508034e-06, 'epoch': 0.57}
 57%|█████▋    | 5963/10395 [17:04:05<9:56:07,  8.07s/it] 57%|█████▋    | 5964/10395 [17:04:12<9:37:40,  7.82s/it]                                                         {'loss': 0.9109, 'learning_rate': 8.109295431534432e-06, 'epoch': 0.57}
 57%|█████▋    | 5964/10395 [17:04:12<9:37:40,  7.82s/it] 57%|█████▋    | 5965/10395 [17:04:21<9:52:44,  8.03s/it]                                                         {'loss': 0.8698, 'learning_rate': 8.106235988106387e-06, 'epoch': 0.57}
 57%|█████▋    | 5965/10395 [17:04:21<9:52:44,  8.03s/it] 57%|█████▋    | 5966/10395 [17:04:29<9:50:56,  8.01s/it]                                                         {'loss': 0.82, 'learning_rate': 8.103176728520908e-06, 'epoch': 0.57}
 57%|█████▋    | 5966/10395 [17:04:29<9:50:56,  8.01s/it] 57%|█████▋    | 5967/10395 [17:04:36<9:35:07,  7.79s/it]                                                         {'loss': 0.9194, 'learning_rate': 8.10011765307498e-06, 'epoch': 0.57}
 57%|█████▋    | 5967/10395 [17:04:36<9:35:07,  7.79s/it] 57%|█████▋    | 5968/10395 [17:04:45<9:49:49,  7.99s/it]                                                         {'loss': 0.8484, 'learning_rate': 8.097058762065569e-06, 'epoch': 0.57}
 57%|█████▋    | 5968/10395 [17:04:45<9:49:49,  7.99s/it] 57%|█████▋    | 5969/10395 [17:04:53<9:53:35,  8.05s/it]                                                         {'loss': 0.9274, 'learning_rate': 8.094000055789628e-06, 'epoch': 0.57}
 57%|█████▋    | 5969/10395 [17:04:53<9:53:35,  8.05s/it] 57%|█████▋    | 5970/10395 [17:05:00<9:40:30,  7.87s/it]                                                         {'loss': 0.8595, 'learning_rate': 8.090941534544087e-06, 'epoch': 0.57}
 57%|█████▋    | 5970/10395 [17:05:00<9:40:30,  7.87s/it] 57%|█████▋    | 5971/10395 [17:05:07<9:20:58,  7.61s/it]                                                         {'loss': 0.8775, 'learning_rate': 8.087883198625861e-06, 'epoch': 0.57}
 57%|█████▋    | 5971/10395 [17:05:07<9:20:58,  7.61s/it] 57%|█████▋    | 5972/10395 [17:05:15<9:24:13,  7.65s/it]                                                         {'loss': 0.9181, 'learning_rate': 8.08482504833185e-06, 'epoch': 0.57}
 57%|█████▋    | 5972/10395 [17:05:15<9:24:13,  7.65s/it] 57%|█████▋    | 5973/10395 [17:05:22<9:20:02,  7.60s/it]                                                         {'loss': 0.9196, 'learning_rate': 8.081767083958926e-06, 'epoch': 0.57}
 57%|█████▋    | 5973/10395 [17:05:22<9:20:02,  7.60s/it] 57%|█████▋    | 5974/10395 [17:05:32<10:02:35,  8.18s/it]                                                          {'loss': 0.9361, 'learning_rate': 8.078709305803958e-06, 'epoch': 0.57}
 57%|█████▋    | 5974/10395 [17:05:32<10:02:35,  8.18s/it] 57%|█████▋    | 5975/10395 [17:05:40<10:03:14,  8.19s/it]                                                          {'loss': 0.886, 'learning_rate': 8.07565171416379e-06, 'epoch': 0.57}
 57%|█████▋    | 5975/10395 [17:05:40<10:03:14,  8.19s/it] 57%|█████▋    | 5976/10395 [17:05:58<13:36:00, 11.08s/it]                                                          {'loss': 0.4148, 'learning_rate': 8.072594309335233e-06, 'epoch': 0.57}
 57%|█████▋    | 5976/10395 [17:05:58<13:36:00, 11.08s/it] 57%|█████▋    | 5977/10395 [17:06:05<12:15:33,  9.99s/it]                                                          {'loss': 0.9797, 'learning_rate': 8.069537091615105e-06, 'epoch': 0.57}
 57%|█████▋    | 5977/10395 [17:06:05<12:15:33,  9.99s/it] 58%|█████▊    | 5978/10395 [17:06:13<11:27:02,  9.33s/it]                                                          {'loss': 0.8443, 'learning_rate': 8.066480061300191e-06, 'epoch': 0.58}
 58%|█████▊    | 5978/10395 [17:06:13<11:27:02,  9.33s/it] 58%|█████▊    | 5979/10395 [17:06:20<10:39:46,  8.69s/it]                                                          {'loss': 0.9073, 'learning_rate': 8.063423218687259e-06, 'epoch': 0.58}
 58%|█████▊    | 5979/10395 [17:06:20<10:39:46,  8.69s/it] 58%|█████▊    | 5980/10395 [17:06:28<10:21:41,  8.45s/it]                                                          {'loss': 0.8784, 'learning_rate': 8.060366564073064e-06, 'epoch': 0.58}
 58%|█████▊    | 5980/10395 [17:06:28<10:21:41,  8.45s/it] 58%|█████▊    | 5981/10395 [17:06:36<10:07:05,  8.25s/it]                                                          {'loss': 1.0036, 'learning_rate': 8.057310097754333e-06, 'epoch': 0.58}
 58%|█████▊    | 5981/10395 [17:06:36<10:07:05,  8.25s/it] 58%|█████▊    | 5982/10395 [17:06:45<10:25:44,  8.51s/it]                                                          {'loss': 0.8341, 'learning_rate': 8.054253820027797e-06, 'epoch': 0.58}
 58%|█████▊    | 5982/10395 [17:06:45<10:25:44,  8.51s/it] 58%|█████▊    | 5983/10395 [17:06:54<10:25:53,  8.51s/it]                                                          {'loss': 0.8861, 'learning_rate': 8.051197731190133e-06, 'epoch': 0.58}
 58%|█████▊    | 5983/10395 [17:06:54<10:25:53,  8.51s/it] 58%|█████▊    | 5984/10395 [17:07:01<9:59:36,  8.16s/it]                                                          {'loss': 0.9158, 'learning_rate': 8.04814183153803e-06, 'epoch': 0.58}
 58%|█████▊    | 5984/10395 [17:07:01<9:59:36,  8.16s/it] 58%|█████▊    | 5985/10395 [17:07:11<10:43:24,  8.75s/it]                                                          {'loss': 0.8441, 'learning_rate': 8.045086121368148e-06, 'epoch': 0.58}
 58%|█████▊    | 5985/10395 [17:07:11<10:43:24,  8.75s/it] 58%|█████▊    | 5986/10395 [17:07:19<10:15:45,  8.38s/it]                                                          {'loss': 0.9158, 'learning_rate': 8.042030600977129e-06, 'epoch': 0.58}
 58%|█████▊    | 5986/10395 [17:07:19<10:15:45,  8.38s/it] 58%|█████▊    | 5987/10395 [17:07:27<10:03:19,  8.21s/it]                                                          {'loss': 0.8803, 'learning_rate': 8.038975270661593e-06, 'epoch': 0.58}
 58%|█████▊    | 5987/10395 [17:07:27<10:03:19,  8.21s/it] 58%|█████▊    | 5988/10395 [17:07:34<9:45:29,  7.97s/it]                                                          {'loss': 0.9281, 'learning_rate': 8.035920130718146e-06, 'epoch': 0.58}
 58%|█████▊    | 5988/10395 [17:07:34<9:45:29,  7.97s/it] 58%|█████▊    | 5989/10395 [17:07:41<9:31:22,  7.78s/it]                                                         {'loss': 0.9332, 'learning_rate': 8.032865181443376e-06, 'epoch': 0.58}
 58%|█████▊    | 5989/10395 [17:07:41<9:31:22,  7.78s/it] 58%|█████▊    | 5990/10395 [17:07:49<9:33:45,  7.82s/it]                                                         {'loss': 0.968, 'learning_rate': 8.029810423133857e-06, 'epoch': 0.58}
 58%|█████▊    | 5990/10395 [17:07:49<9:33:45,  7.82s/it] 58%|█████▊    | 5991/10395 [17:08:07<13:05:58, 10.71s/it]                                                          {'loss': 0.3873, 'learning_rate': 8.026755856086123e-06, 'epoch': 0.58}
 58%|█████▊    | 5991/10395 [17:08:07<13:05:58, 10.71s/it] 58%|█████▊    | 5992/10395 [17:08:14<11:52:30,  9.71s/it]                                                          {'loss': 0.9187, 'learning_rate': 8.023701480596718e-06, 'epoch': 0.58}
 58%|█████▊    | 5992/10395 [17:08:14<11:52:30,  9.71s/it] 58%|█████▊    | 5993/10395 [17:08:22<11:13:56,  9.19s/it]                                                          {'loss': 0.9324, 'learning_rate': 8.02064729696215e-06, 'epoch': 0.58}
 58%|█████▊    | 5993/10395 [17:08:22<11:13:56,  9.19s/it] 58%|█████▊    | 5994/10395 [17:08:29<10:35:14,  8.66s/it]                                                          {'loss': 1.0148, 'learning_rate': 8.01759330547891e-06, 'epoch': 0.58}
 58%|█████▊    | 5994/10395 [17:08:29<10:35:14,  8.66s/it] 58%|█████▊    | 5995/10395 [17:08:38<10:28:12,  8.57s/it]                                                          {'loss': 0.8768, 'learning_rate': 8.014539506443477e-06, 'epoch': 0.58}
 58%|█████▊    | 5995/10395 [17:08:38<10:28:12,  8.57s/it] 58%|█████▊    | 5996/10395 [17:08:46<10:20:38,  8.47s/it]                                                          {'loss': 0.7943, 'learning_rate': 8.011485900152305e-06, 'epoch': 0.58}
 58%|█████▊    | 5996/10395 [17:08:46<10:20:38,  8.47s/it] 58%|█████▊    | 5997/10395 [17:08:54<10:06:22,  8.27s/it]                                                          {'loss': 0.967, 'learning_rate': 8.008432486901837e-06, 'epoch': 0.58}
 58%|█████▊    | 5997/10395 [17:08:54<10:06:22,  8.27s/it] 58%|█████▊    | 5998/10395 [17:09:02<10:06:46,  8.28s/it]                                                          {'loss': 0.8358, 'learning_rate': 8.005379266988482e-06, 'epoch': 0.58}
 58%|█████▊    | 5998/10395 [17:09:02<10:06:46,  8.28s/it] 58%|█████▊    | 5999/10395 [17:09:10<9:49:35,  8.05s/it]                                                          {'loss': 0.8761, 'learning_rate': 8.002326240708645e-06, 'epoch': 0.58}
 58%|█████▊    | 5999/10395 [17:09:10<9:49:35,  8.05s/it] 58%|█████▊    | 6000/10395 [17:09:18<10:00:36,  8.20s/it]                                                          {'loss': 0.8971, 'learning_rate': 7.999273408358708e-06, 'epoch': 0.58}
 58%|█████▊    | 6000/10395 [17:09:18<10:00:36,  8.20s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 58%|█████▊    | 6001/10395 [17:10:58<43:25:33, 35.58s/it]                                                          {'loss': 0.9154, 'learning_rate': 7.996220770235034e-06, 'epoch': 0.58}
 58%|█████▊    | 6001/10395 [17:10:58<43:25:33, 35.58s/it] 58%|█████▊    | 6002/10395 [17:11:05<33:03:32, 27.09s/it]                                                          {'loss': 0.941, 'learning_rate': 7.993168326633967e-06, 'epoch': 0.58}
 58%|█████▊    | 6002/10395 [17:11:05<33:03:32, 27.09s/it] 58%|█████▊    | 6003/10395 [17:11:13<26:05:04, 21.38s/it]                                                          {'loss': 0.8868, 'learning_rate': 7.990116077851829e-06, 'epoch': 0.58}
 58%|█████▊    | 6003/10395 [17:11:13<26:05:04, 21.38s/it] 58%|█████▊    | 6004/10395 [17:11:21<21:11:00, 17.37s/it]                                                          {'loss': 0.9166, 'learning_rate': 7.987064024184929e-06, 'epoch': 0.58}
 58%|█████▊    | 6004/10395 [17:11:21<21:11:00, 17.37s/it] 58%|█████▊    | 6005/10395 [17:11:40<21:35:15, 17.70s/it]                                                          {'loss': 0.4126, 'learning_rate': 7.98401216592955e-06, 'epoch': 0.58}
 58%|█████▊    | 6005/10395 [17:11:40<21:35:15, 17.70s/it] 58%|█████▊    | 6006/10395 [17:11:47<17:56:31, 14.72s/it]                                                          {'loss': 0.9346, 'learning_rate': 7.980960503381961e-06, 'epoch': 0.58}
 58%|█████▊    | 6006/10395 [17:11:47<17:56:31, 14.72s/it] 58%|█████▊    | 6007/10395 [17:11:55<15:25:10, 12.65s/it]                                                          {'loss': 0.8797, 'learning_rate': 7.97790903683841e-06, 'epoch': 0.58}
 58%|█████▊    | 6007/10395 [17:11:55<15:25:10, 12.65s/it] 58%|█████▊    | 6008/10395 [17:12:03<13:30:39, 11.09s/it]                                                          {'loss': 0.9814, 'learning_rate': 7.97485776659513e-06, 'epoch': 0.58}
 58%|█████▊    | 6008/10395 [17:12:03<13:30:39, 11.09s/it] 58%|█████▊    | 6009/10395 [17:12:11<12:23:17, 10.17s/it]                                                          {'loss': 0.8183, 'learning_rate': 7.97180669294833e-06, 'epoch': 0.58}
 58%|█████▊    | 6009/10395 [17:12:11<12:23:17, 10.17s/it] 58%|█████▊    | 6010/10395 [17:12:19<11:37:33,  9.54s/it]                                                          {'loss': 0.8631, 'learning_rate': 7.968755816194203e-06, 'epoch': 0.58}
 58%|█████▊    | 6010/10395 [17:12:19<11:37:33,  9.54s/it] 58%|█████▊    | 6011/10395 [17:12:27<11:09:33,  9.16s/it]                                                          {'loss': 0.8506, 'learning_rate': 7.965705136628921e-06, 'epoch': 0.58}
 58%|█████▊    | 6011/10395 [17:12:27<11:09:33,  9.16s/it] 58%|█████▊    | 6012/10395 [17:12:35<10:36:35,  8.71s/it]                                                          {'loss': 0.832, 'learning_rate': 7.962654654548639e-06, 'epoch': 0.58}
 58%|█████▊    | 6012/10395 [17:12:35<10:36:35,  8.71s/it] 58%|█████▊    | 6013/10395 [17:12:42<10:09:53,  8.35s/it]                                                          {'loss': 0.8085, 'learning_rate': 7.959604370249485e-06, 'epoch': 0.58}
 58%|█████▊    | 6013/10395 [17:12:42<10:09:53,  8.35s/it] 58%|█████▊    | 6014/10395 [17:12:50<10:06:33,  8.31s/it]                                                          {'loss': 0.8651, 'learning_rate': 7.95655428402758e-06, 'epoch': 0.58}
 58%|█████▊    | 6014/10395 [17:12:50<10:06:33,  8.31s/it] 58%|█████▊    | 6015/10395 [17:12:58<9:53:52,  8.14s/it]                                                          {'loss': 0.8177, 'learning_rate': 7.953504396179017e-06, 'epoch': 0.58}
 58%|█████▊    | 6015/10395 [17:12:58<9:53:52,  8.14s/it] 58%|█████▊    | 6016/10395 [17:13:05<9:34:10,  7.87s/it]                                                         {'loss': 0.8522, 'learning_rate': 7.950454706999875e-06, 'epoch': 0.58}
 58%|█████▊    | 6016/10395 [17:13:05<9:34:10,  7.87s/it] 58%|█████▊    | 6017/10395 [17:13:13<9:34:08,  7.87s/it]                                                         {'loss': 0.9113, 'learning_rate': 7.94740521678621e-06, 'epoch': 0.58}
 58%|█████▊    | 6017/10395 [17:13:13<9:34:08,  7.87s/it] 58%|█████▊    | 6018/10395 [17:13:21<9:29:18,  7.80s/it]                                                         {'loss': 0.8723, 'learning_rate': 7.94435592583406e-06, 'epoch': 0.58}
 58%|█████▊    | 6018/10395 [17:13:21<9:29:18,  7.80s/it] 58%|█████▊    | 6019/10395 [17:13:29<9:29:54,  7.81s/it]                                                         {'loss': 0.8142, 'learning_rate': 7.941306834439447e-06, 'epoch': 0.58}
 58%|█████▊    | 6019/10395 [17:13:29<9:29:54,  7.81s/it] 58%|█████▊    | 6020/10395 [17:13:37<9:44:19,  8.01s/it]                                                         {'loss': 0.8993, 'learning_rate': 7.938257942898365e-06, 'epoch': 0.58}
 58%|█████▊    | 6020/10395 [17:13:37<9:44:19,  8.01s/it] 58%|█████▊    | 6021/10395 [17:13:45<9:50:35,  8.10s/it]                                                         {'loss': 0.8275, 'learning_rate': 7.935209251506794e-06, 'epoch': 0.58}
 58%|█████▊    | 6021/10395 [17:13:45<9:50:35,  8.10s/it] 58%|█████▊    | 6022/10395 [17:13:53<9:42:24,  7.99s/it]                                                         {'loss': 0.9236, 'learning_rate': 7.932160760560696e-06, 'epoch': 0.58}
 58%|█████▊    | 6022/10395 [17:13:53<9:42:24,  7.99s/it] 58%|█████▊    | 6023/10395 [17:14:01<9:44:18,  8.02s/it]                                                         {'loss': 0.8922, 'learning_rate': 7.929112470356014e-06, 'epoch': 0.58}
 58%|█████▊    | 6023/10395 [17:14:01<9:44:18,  8.02s/it] 58%|█████▊    | 6024/10395 [17:14:19<13:08:58, 10.83s/it]                                                          {'loss': 0.3589, 'learning_rate': 7.926064381188669e-06, 'epoch': 0.58}
 58%|█████▊    | 6024/10395 [17:14:19<13:08:58, 10.83s/it] 58%|█████▊    | 6025/10395 [17:14:27<12:10:17, 10.03s/it]                                                          {'loss': 0.8905, 'learning_rate': 7.923016493354561e-06, 'epoch': 0.58}
 58%|█████▊    | 6025/10395 [17:14:27<12:10:17, 10.03s/it] 58%|█████▊    | 6026/10395 [17:14:35<11:26:43,  9.43s/it]                                                          {'loss': 0.9217, 'learning_rate': 7.919968807149575e-06, 'epoch': 0.58}
 58%|█████▊    | 6026/10395 [17:14:35<11:26:43,  9.43s/it] 58%|█████▊    | 6027/10395 [17:14:42<10:44:25,  8.85s/it]                                                          {'loss': 0.8883, 'learning_rate': 7.91692132286957e-06, 'epoch': 0.58}
 58%|█████▊    | 6027/10395 [17:14:42<10:44:25,  8.85s/it] 58%|█████▊    | 6028/10395 [17:14:50<10:12:29,  8.42s/it]                                                          {'loss': 0.8869, 'learning_rate': 7.913874040810392e-06, 'epoch': 0.58}
 58%|█████▊    | 6028/10395 [17:14:50<10:12:29,  8.42s/it] 58%|█████▊    | 6029/10395 [17:14:57<9:49:49,  8.11s/it]                                                          {'loss': 0.8727, 'learning_rate': 7.910826961267863e-06, 'epoch': 0.58}
 58%|█████▊    | 6029/10395 [17:14:57<9:49:49,  8.11s/it] 58%|█████▊    | 6030/10395 [17:15:06<10:14:46,  8.45s/it]                                                          {'loss': 0.8711, 'learning_rate': 7.907780084537787e-06, 'epoch': 0.58}
 58%|█████▊    | 6030/10395 [17:15:06<10:14:46,  8.45s/it] 58%|█████▊    | 6031/10395 [17:15:14<9:56:59,  8.21s/it]                                                          {'loss': 0.9191, 'learning_rate': 7.904733410915952e-06, 'epoch': 0.58}
 58%|█████▊    | 6031/10395 [17:15:14<9:56:59,  8.21s/it] 58%|█████▊    | 6032/10395 [17:15:21<9:37:39,  7.94s/it]                                                         {'loss': 0.9488, 'learning_rate': 7.901686940698118e-06, 'epoch': 0.58}
 58%|█████▊    | 6032/10395 [17:15:21<9:37:39,  7.94s/it] 58%|█████▊    | 6033/10395 [17:15:29<9:37:11,  7.94s/it]                                                         {'loss': 0.9298, 'learning_rate': 7.898640674180032e-06, 'epoch': 0.58}
 58%|█████▊    | 6033/10395 [17:15:29<9:37:11,  7.94s/it] 58%|█████▊    | 6034/10395 [17:15:37<9:28:19,  7.82s/it]                                                         {'loss': 0.9929, 'learning_rate': 7.895594611657422e-06, 'epoch': 0.58}
 58%|█████▊    | 6034/10395 [17:15:37<9:28:19,  7.82s/it] 58%|█████▊    | 6035/10395 [17:15:44<9:25:07,  7.78s/it]                                                         {'loss': 0.9248, 'learning_rate': 7.892548753425987e-06, 'epoch': 0.58}
 58%|█████▊    | 6035/10395 [17:15:44<9:25:07,  7.78s/it] 58%|█████▊    | 6036/10395 [17:15:53<9:44:18,  8.04s/it]                                                         {'loss': 0.8434, 'learning_rate': 7.889503099781416e-06, 'epoch': 0.58}
 58%|█████▊    | 6036/10395 [17:15:53<9:44:18,  8.04s/it] 58%|█████▊    | 6037/10395 [17:16:10<12:57:04, 10.70s/it]                                                          {'loss': 0.3722, 'learning_rate': 7.886457651019373e-06, 'epoch': 0.58}
 58%|█████▊    | 6037/10395 [17:16:10<12:57:04, 10.70s/it] 58%|█████▊    | 6038/10395 [17:16:17<11:44:41,  9.70s/it]                                                          {'loss': 0.9532, 'learning_rate': 7.883412407435503e-06, 'epoch': 0.58}
 58%|█████▊    | 6038/10395 [17:16:17<11:44:41,  9.70s/it] 58%|█████▊    | 6039/10395 [17:16:25<11:04:55,  9.16s/it]                                                          {'loss': 0.8371, 'learning_rate': 7.880367369325436e-06, 'epoch': 0.58}
 58%|█████▊    | 6039/10395 [17:16:25<11:04:55,  9.16s/it] 58%|█████▊    | 6040/10395 [17:16:33<10:30:02,  8.68s/it]                                                          {'loss': 0.9006, 'learning_rate': 7.877322536984775e-06, 'epoch': 0.58}
 58%|█████▊    | 6040/10395 [17:16:33<10:30:02,  8.68s/it] 58%|█████▊    | 6041/10395 [17:16:50<13:26:04, 11.11s/it]                                                          {'loss': 0.3794, 'learning_rate': 7.874277910709107e-06, 'epoch': 0.58}
 58%|█████▊    | 6041/10395 [17:16:50<13:26:04, 11.11s/it] 58%|█████▊    | 6042/10395 [17:16:58<12:18:10, 10.17s/it]                                                          {'loss': 0.8517, 'learning_rate': 7.871233490793995e-06, 'epoch': 0.58}
 58%|█████▊    | 6042/10395 [17:16:58<12:18:10, 10.17s/it] 58%|█████▊    | 6043/10395 [17:17:05<11:25:54,  9.46s/it]                                                          {'loss': 0.9001, 'learning_rate': 7.868189277534987e-06, 'epoch': 0.58}
 58%|█████▊    | 6043/10395 [17:17:05<11:25:54,  9.46s/it] 58%|█████▊    | 6044/10395 [17:17:14<11:06:17,  9.19s/it]                                                          {'loss': 0.8897, 'learning_rate': 7.865145271227609e-06, 'epoch': 0.58}
 58%|█████▊    | 6044/10395 [17:17:14<11:06:17,  9.19s/it] 58%|█████▊    | 6045/10395 [17:17:22<10:33:05,  8.73s/it]                                                          {'loss': 0.8651, 'learning_rate': 7.862101472167364e-06, 'epoch': 0.58}
 58%|█████▊    | 6045/10395 [17:17:22<10:33:05,  8.73s/it] 58%|█████▊    | 6046/10395 [17:17:30<10:20:22,  8.56s/it]                                                          {'loss': 0.8809, 'learning_rate': 7.859057880649738e-06, 'epoch': 0.58}
 58%|█████▊    | 6046/10395 [17:17:30<10:20:22,  8.56s/it] 58%|█████▊    | 6047/10395 [17:17:37<9:49:35,  8.14s/it]                                                          {'loss': 0.8942, 'learning_rate': 7.8560144969702e-06, 'epoch': 0.58}
 58%|█████▊    | 6047/10395 [17:17:37<9:49:35,  8.14s/it] 58%|█████▊    | 6048/10395 [17:17:45<9:47:17,  8.11s/it]                                                         {'loss': 0.8398, 'learning_rate': 7.852971321424197e-06, 'epoch': 0.58}
 58%|█████▊    | 6048/10395 [17:17:45<9:47:17,  8.11s/it] 58%|█████▊    | 6049/10395 [17:17:53<9:43:03,  8.05s/it]                                                         {'loss': 0.8656, 'learning_rate': 7.849928354307145e-06, 'epoch': 0.58}
 58%|█████▊    | 6049/10395 [17:17:53<9:43:03,  8.05s/it] 58%|█████▊    | 6050/10395 [17:18:00<9:29:43,  7.87s/it]                                                         {'loss': 0.9796, 'learning_rate': 7.846885595914455e-06, 'epoch': 0.58}
 58%|█████▊    | 6050/10395 [17:18:00<9:29:43,  7.87s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 58%|█████▊    | 6051/10395 [17:19:40<42:47:53, 35.47s/it]                                                          {'loss': 0.9021, 'learning_rate': 7.84384304654151e-06, 'epoch': 0.58}
 58%|█████▊    | 6051/10395 [17:19:40<42:47:53, 35.47s/it] 58%|█████▊    | 6052/10395 [17:19:48<32:48:38, 27.20s/it]                                                          {'loss': 0.8653, 'learning_rate': 7.840800706483674e-06, 'epoch': 0.58}
 58%|█████▊    | 6052/10395 [17:19:48<32:48:38, 27.20s/it] 58%|█████▊    | 6053/10395 [17:19:56<25:38:58, 21.27s/it]                                                          {'loss': 0.9231, 'learning_rate': 7.837758576036289e-06, 'epoch': 0.58}
 58%|█████▊    | 6053/10395 [17:19:56<25:38:58, 21.27s/it] 58%|█████▊    | 6054/10395 [17:20:03<20:46:31, 17.23s/it]                                                          {'loss': 0.8964, 'learning_rate': 7.834716655494681e-06, 'epoch': 0.58}
 58%|█████▊    | 6054/10395 [17:20:03<20:46:31, 17.23s/it] 58%|█████▊    | 6055/10395 [17:20:21<20:45:46, 17.22s/it]                                                          {'loss': 0.402, 'learning_rate': 7.831674945154156e-06, 'epoch': 0.58}
 58%|█████▊    | 6055/10395 [17:20:21<20:45:46, 17.22s/it] 58%|█████▊    | 6056/10395 [17:20:29<17:31:44, 14.54s/it]                                                          {'loss': 0.874, 'learning_rate': 7.828633445309995e-06, 'epoch': 0.58}
 58%|█████▊    | 6056/10395 [17:20:29<17:31:44, 14.54s/it] 58%|█████▊    | 6057/10395 [17:20:37<15:07:40, 12.55s/it]                                                          {'loss': 0.9204, 'learning_rate': 7.825592156257455e-06, 'epoch': 0.58}
 58%|█████▊    | 6057/10395 [17:20:37<15:07:40, 12.55s/it] 58%|█████▊    | 6058/10395 [17:20:45<13:24:17, 11.13s/it]                                                          {'loss': 0.8225, 'learning_rate': 7.822551078291783e-06, 'epoch': 0.58}
 58%|█████▊    | 6058/10395 [17:20:45<13:24:17, 11.13s/it] 58%|█████▊    | 6059/10395 [17:20:52<12:09:10, 10.09s/it]                                                          {'loss': 0.8735, 'learning_rate': 7.819510211708198e-06, 'epoch': 0.58}
 58%|█████▊    | 6059/10395 [17:20:52<12:09:10, 10.09s/it] 58%|█████▊    | 6060/10395 [17:21:00<11:08:23,  9.25s/it]                                                          {'loss': 0.9961, 'learning_rate': 7.816469556801904e-06, 'epoch': 0.58}
 58%|█████▊    | 6060/10395 [17:21:00<11:08:23,  9.25s/it] 58%|█████▊    | 6061/10395 [17:21:07<10:40:05,  8.86s/it]                                                          {'loss': 0.8652, 'learning_rate': 7.813429113868075e-06, 'epoch': 0.58}
 58%|█████▊    | 6061/10395 [17:21:07<10:40:05,  8.86s/it] 58%|█████▊    | 6062/10395 [17:21:15<10:15:16,  8.52s/it]                                                          {'loss': 0.8256, 'learning_rate': 7.810388883201879e-06, 'epoch': 0.58}
 58%|█████▊    | 6062/10395 [17:21:15<10:15:16,  8.52s/it] 58%|█████▊    | 6063/10395 [17:21:23<9:50:52,  8.18s/it]                                                          {'loss': 0.8941, 'learning_rate': 7.807348865098456e-06, 'epoch': 0.58}
 58%|█████▊    | 6063/10395 [17:21:23<9:50:52,  8.18s/it] 58%|█████▊    | 6064/10395 [17:21:30<9:35:08,  7.97s/it]                                                         {'loss': 0.9648, 'learning_rate': 7.80430905985291e-06, 'epoch': 0.58}
 58%|█████▊    | 6064/10395 [17:21:30<9:35:08,  7.97s/it] 58%|█████▊    | 6065/10395 [17:21:38<9:26:47,  7.85s/it]                                                         {'loss': 0.9172, 'learning_rate': 7.801269467760353e-06, 'epoch': 0.58}
 58%|█████▊    | 6065/10395 [17:21:38<9:26:47,  7.85s/it] 58%|█████▊    | 6066/10395 [17:21:47<9:53:17,  8.22s/it]                                                         {'loss': 0.8708, 'learning_rate': 7.798230089115855e-06, 'epoch': 0.58}
 58%|█████▊    | 6066/10395 [17:21:47<9:53:17,  8.22s/it] 58%|█████▊    | 6067/10395 [17:21:54<9:35:33,  7.98s/it]                                                         {'loss': 0.9388, 'learning_rate': 7.795190924214476e-06, 'epoch': 0.58}
 58%|█████▊    | 6067/10395 [17:21:54<9:35:33,  7.98s/it] 58%|█████▊    | 6068/10395 [17:22:02<9:24:52,  7.83s/it]                                                         {'loss': 0.9372, 'learning_rate': 7.792151973351251e-06, 'epoch': 0.58}
 58%|█████▊    | 6068/10395 [17:22:02<9:24:52,  7.83s/it] 58%|█████▊    | 6069/10395 [17:22:09<9:08:12,  7.60s/it]                                                         {'loss': 0.8983, 'learning_rate': 7.789113236821191e-06, 'epoch': 0.58}
 58%|█████▊    | 6069/10395 [17:22:09<9:08:12,  7.60s/it] 58%|█████▊    | 6070/10395 [17:22:16<9:00:03,  7.49s/it]                                                         {'loss': 0.9316, 'learning_rate': 7.786074714919296e-06, 'epoch': 0.58}
 58%|█████▊    | 6070/10395 [17:22:16<9:00:03,  7.49s/it] 58%|█████▊    | 6071/10395 [17:22:24<9:17:34,  7.74s/it]                                                         {'loss': 0.967, 'learning_rate': 7.78303640794054e-06, 'epoch': 0.58}
 58%|█████▊    | 6071/10395 [17:22:24<9:17:34,  7.74s/it] 58%|█████▊    | 6072/10395 [17:22:33<9:29:10,  7.90s/it]                                                         {'loss': 0.8232, 'learning_rate': 7.779998316179867e-06, 'epoch': 0.58}
 58%|█████▊    | 6072/10395 [17:22:33<9:29:10,  7.90s/it] 58%|█████▊    | 6073/10395 [17:22:40<9:14:07,  7.69s/it]                                                         {'loss': 0.898, 'learning_rate': 7.776960439932214e-06, 'epoch': 0.58}
 58%|█████▊    | 6073/10395 [17:22:40<9:14:07,  7.69s/it] 58%|█████▊    | 6074/10395 [17:22:48<9:16:45,  7.73s/it]                                                         {'loss': 0.9213, 'learning_rate': 7.773922779492492e-06, 'epoch': 0.58}
 58%|█████▊    | 6074/10395 [17:22:48<9:16:45,  7.73s/it] 58%|█████▊    | 6075/10395 [17:22:55<9:13:27,  7.69s/it]                                                         {'loss': 0.8795, 'learning_rate': 7.770885335155588e-06, 'epoch': 0.58}
 58%|█████▊    | 6075/10395 [17:22:55<9:13:27,  7.69s/it] 58%|█████▊    | 6076/10395 [17:23:03<9:07:58,  7.61s/it]                                                         {'loss': 0.8582, 'learning_rate': 7.767848107216373e-06, 'epoch': 0.58}
 58%|█████▊    | 6076/10395 [17:23:03<9:07:58,  7.61s/it] 58%|█████▊    | 6077/10395 [17:23:11<9:19:37,  7.78s/it]                                                         {'loss': 0.9154, 'learning_rate': 7.764811095969693e-06, 'epoch': 0.58}
 58%|█████▊    | 6077/10395 [17:23:11<9:19:37,  7.78s/it] 58%|█████▊    | 6078/10395 [17:23:18<9:18:29,  7.76s/it]                                                         {'loss': 0.9023, 'learning_rate': 7.76177430171038e-06, 'epoch': 0.58}
 58%|█████▊    | 6078/10395 [17:23:18<9:18:29,  7.76s/it] 58%|█████▊    | 6079/10395 [17:23:26<9:11:57,  7.67s/it]                                                         {'loss': 0.9172, 'learning_rate': 7.75873772473323e-06, 'epoch': 0.58}
 58%|█████▊    | 6079/10395 [17:23:26<9:11:57,  7.67s/it] 58%|█████▊    | 6080/10395 [17:23:34<9:17:07,  7.75s/it]                                                         {'loss': 0.878, 'learning_rate': 7.755701365333029e-06, 'epoch': 0.58}
 58%|█████▊    | 6080/10395 [17:23:34<9:17:07,  7.75s/it] 58%|█████▊    | 6081/10395 [17:23:42<9:18:53,  7.77s/it]                                                         {'loss': 0.8858, 'learning_rate': 7.752665223804547e-06, 'epoch': 0.58}
 58%|█████▊    | 6081/10395 [17:23:42<9:18:53,  7.77s/it] 59%|█████▊    | 6082/10395 [17:23:49<9:12:40,  7.69s/it]                                                         {'loss': 0.9177, 'learning_rate': 7.749629300442522e-06, 'epoch': 0.59}
 59%|█████▊    | 6082/10395 [17:23:49<9:12:40,  7.69s/it] 59%|█████▊    | 6083/10395 [17:23:57<9:08:27,  7.63s/it]                                                         {'loss': 0.8383, 'learning_rate': 7.746593595541676e-06, 'epoch': 0.59}
 59%|█████▊    | 6083/10395 [17:23:57<9:08:27,  7.63s/it] 59%|█████▊    | 6084/10395 [17:24:05<9:13:11,  7.70s/it]                                                         {'loss': 0.8398, 'learning_rate': 7.743558109396706e-06, 'epoch': 0.59}
 59%|█████▊    | 6084/10395 [17:24:05<9:13:11,  7.70s/it] 59%|█████▊    | 6085/10395 [17:24:12<9:11:50,  7.68s/it]                                                         {'loss': 0.9006, 'learning_rate': 7.740522842302299e-06, 'epoch': 0.59}
 59%|█████▊    | 6085/10395 [17:24:12<9:11:50,  7.68s/it] 59%|█████▊    | 6086/10395 [17:24:21<9:35:57,  8.02s/it]                                                         {'loss': 0.8685, 'learning_rate': 7.737487794553101e-06, 'epoch': 0.59}
 59%|█████▊    | 6086/10395 [17:24:21<9:35:57,  8.02s/it] 59%|█████▊    | 6087/10395 [17:24:29<9:34:02,  7.99s/it]                                                         {'loss': 0.8563, 'learning_rate': 7.734452966443751e-06, 'epoch': 0.59}
 59%|█████▊    | 6087/10395 [17:24:29<9:34:02,  7.99s/it] 59%|█████▊    | 6088/10395 [17:24:36<9:23:27,  7.85s/it]                                                         {'loss': 0.8492, 'learning_rate': 7.73141835826887e-06, 'epoch': 0.59}
 59%|█████▊    | 6088/10395 [17:24:36<9:23:27,  7.85s/it] 59%|█████▊    | 6089/10395 [17:24:44<9:12:18,  7.70s/it]                                                         {'loss': 0.8194, 'learning_rate': 7.728383970323044e-06, 'epoch': 0.59}
 59%|█████▊    | 6089/10395 [17:24:44<9:12:18,  7.70s/it] 59%|█████▊    | 6090/10395 [17:24:51<9:07:06,  7.63s/it]                                                         {'loss': 0.9128, 'learning_rate': 7.725349802900848e-06, 'epoch': 0.59}
 59%|█████▊    | 6090/10395 [17:24:51<9:07:06,  7.63s/it] 59%|█████▊    | 6091/10395 [17:24:59<9:09:54,  7.67s/it]                                                         {'loss': 0.9568, 'learning_rate': 7.722315856296833e-06, 'epoch': 0.59}
 59%|█████▊    | 6091/10395 [17:24:59<9:09:54,  7.67s/it] 59%|█████▊    | 6092/10395 [17:25:06<9:06:27,  7.62s/it]                                                         {'loss': 0.9309, 'learning_rate': 7.719282130805524e-06, 'epoch': 0.59}
 59%|█████▊    | 6092/10395 [17:25:06<9:06:27,  7.62s/it] 59%|█████▊    | 6093/10395 [17:25:14<9:07:41,  7.64s/it]                                                         {'loss': 0.9102, 'learning_rate': 7.71624862672144e-06, 'epoch': 0.59}
 59%|█████▊    | 6093/10395 [17:25:14<9:07:41,  7.64s/it] 59%|█████▊    | 6094/10395 [17:25:22<9:06:22,  7.62s/it]                                                         {'loss': 0.8803, 'learning_rate': 7.713215344339053e-06, 'epoch': 0.59}
 59%|█████▊    | 6094/10395 [17:25:22<9:06:22,  7.62s/it] 59%|█████▊    | 6095/10395 [17:25:30<9:17:53,  7.78s/it]                                                         {'loss': 0.9157, 'learning_rate': 7.710182283952832e-06, 'epoch': 0.59}
 59%|█████▊    | 6095/10395 [17:25:30<9:17:53,  7.78s/it] 59%|█████▊    | 6096/10395 [17:25:37<9:01:57,  7.56s/it]                                                         {'loss': 1.0505, 'learning_rate': 7.707149445857225e-06, 'epoch': 0.59}
 59%|█████▊    | 6096/10395 [17:25:37<9:01:57,  7.56s/it] 59%|█████▊    | 6097/10395 [17:25:45<9:01:53,  7.56s/it]                                                         {'loss': 0.8537, 'learning_rate': 7.704116830346649e-06, 'epoch': 0.59}
 59%|█████▊    | 6097/10395 [17:25:45<9:01:53,  7.56s/it] 59%|█████▊    | 6098/10395 [17:25:52<8:58:18,  7.52s/it]                                                         {'loss': 0.9064, 'learning_rate': 7.701084437715503e-06, 'epoch': 0.59}
 59%|█████▊    | 6098/10395 [17:25:52<8:58:18,  7.52s/it] 59%|█████▊    | 6099/10395 [17:26:00<9:10:05,  7.68s/it]                                                         {'loss': 0.9489, 'learning_rate': 7.698052268258169e-06, 'epoch': 0.59}
 59%|█████▊    | 6099/10395 [17:26:00<9:10:05,  7.68s/it] 59%|█████▊    | 6100/10395 [17:26:08<9:07:43,  7.65s/it]                                                         {'loss': 0.9527, 'learning_rate': 7.695020322269004e-06, 'epoch': 0.59}
 59%|█████▊    | 6100/10395 [17:26:08<9:07:43,  7.65s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 59%|█████▊    | 6101/10395 [17:27:50<43:07:17, 36.15s/it]                                                          {'loss': 0.9245, 'learning_rate': 7.691988600042337e-06, 'epoch': 0.59}
 59%|█████▊    | 6101/10395 [17:27:50<43:07:17, 36.15s/it] 59%|█████▊    | 6102/10395 [17:27:59<33:15:51, 27.89s/it]                                                          {'loss': 0.8603, 'learning_rate': 7.688957101872484e-06, 'epoch': 0.59}
 59%|█████▊    | 6102/10395 [17:27:59<33:15:51, 27.89s/it] 59%|█████▊    | 6103/10395 [17:28:07<26:21:06, 22.10s/it]                                                          {'loss': 0.9462, 'learning_rate': 7.685925828053735e-06, 'epoch': 0.59}
 59%|█████▊    | 6103/10395 [17:28:07<26:21:06, 22.10s/it] 59%|█████▊    | 6104/10395 [17:28:16<21:33:14, 18.08s/it]                                                          {'loss': 0.9168, 'learning_rate': 7.682894778880365e-06, 'epoch': 0.59}
 59%|█████▊    | 6104/10395 [17:28:16<21:33:14, 18.08s/it] 59%|█████▊    | 6105/10395 [17:28:24<17:51:39, 14.99s/it]                                                          {'loss': 0.9573, 'learning_rate': 7.679863954646618e-06, 'epoch': 0.59}
 59%|█████▊    | 6105/10395 [17:28:24<17:51:39, 14.99s/it] 59%|█████▊    | 6106/10395 [17:28:32<15:17:32, 12.84s/it]                                                          {'loss': 0.9354, 'learning_rate': 7.67683335564672e-06, 'epoch': 0.59}
 59%|█████▊    | 6106/10395 [17:28:32<15:17:32, 12.84s/it] 59%|█████▊    | 6107/10395 [17:28:41<13:51:26, 11.63s/it]                                                          {'loss': 0.8339, 'learning_rate': 7.673802982174877e-06, 'epoch': 0.59}
 59%|█████▊    | 6107/10395 [17:28:41<13:51:26, 11.63s/it] 59%|█████▉    | 6108/10395 [17:28:49<12:33:44, 10.55s/it]                                                          {'loss': 0.8546, 'learning_rate': 7.670772834525265e-06, 'epoch': 0.59}
 59%|█████▉    | 6108/10395 [17:28:49<12:33:44, 10.55s/it] 59%|█████▉    | 6109/10395 [17:28:56<11:27:07,  9.62s/it]                                                          {'loss': 0.9213, 'learning_rate': 7.667742912992051e-06, 'epoch': 0.59}
 59%|█████▉    | 6109/10395 [17:28:56<11:27:07,  9.62s/it] 59%|█████▉    | 6110/10395 [17:29:13<13:58:07, 11.74s/it]                                                          {'loss': 0.3652, 'learning_rate': 7.664713217869371e-06, 'epoch': 0.59}
 59%|█████▉    | 6110/10395 [17:29:13<13:58:07, 11.74s/it] 59%|█████▉    | 6111/10395 [17:29:20<12:24:57, 10.43s/it]                                                          {'loss': 0.9757, 'learning_rate': 7.661683749451338e-06, 'epoch': 0.59}
 59%|█████▉    | 6111/10395 [17:29:20<12:24:57, 10.43s/it] 59%|█████▉    | 6112/10395 [17:29:31<12:24:10, 10.43s/it]                                                          {'loss': 0.819, 'learning_rate': 7.658654508032053e-06, 'epoch': 0.59}
 59%|█████▉    | 6112/10395 [17:29:31<12:24:10, 10.43s/it] 59%|█████▉    | 6113/10395 [17:29:38<11:17:57,  9.50s/it]                                                          {'loss': 0.8886, 'learning_rate': 7.655625493905584e-06, 'epoch': 0.59}
 59%|█████▉    | 6113/10395 [17:29:38<11:17:57,  9.50s/it] 59%|█████▉    | 6114/10395 [17:29:46<10:39:29,  8.96s/it]                                                          {'loss': 0.8612, 'learning_rate': 7.652596707365982e-06, 'epoch': 0.59}
 59%|█████▉    | 6114/10395 [17:29:46<10:39:29,  8.96s/it] 59%|█████▉    | 6115/10395 [17:29:53<10:08:04,  8.52s/it]                                                          {'loss': 0.905, 'learning_rate': 7.649568148707279e-06, 'epoch': 0.59}
 59%|█████▉    | 6115/10395 [17:29:53<10:08:04,  8.52s/it] 59%|█████▉    | 6116/10395 [17:30:09<12:47:44, 10.77s/it]                                                          {'loss': 0.3697, 'learning_rate': 7.646539818223473e-06, 'epoch': 0.59}
 59%|█████▉    | 6116/10395 [17:30:09<12:47:44, 10.77s/it] 59%|█████▉    | 6117/10395 [17:30:17<11:44:24,  9.88s/it]                                                          {'loss': 0.8482, 'learning_rate': 7.643511716208553e-06, 'epoch': 0.59}
 59%|█████▉    | 6117/10395 [17:30:17<11:44:24,  9.88s/it] 59%|█████▉    | 6118/10395 [17:30:25<11:10:35,  9.41s/it]                                                          {'loss': 0.8346, 'learning_rate': 7.640483842956478e-06, 'epoch': 0.59}
 59%|█████▉    | 6118/10395 [17:30:25<11:10:35,  9.41s/it] 59%|█████▉    | 6119/10395 [17:30:33<10:38:45,  8.96s/it]                                                          {'loss': 0.8544, 'learning_rate': 7.637456198761191e-06, 'epoch': 0.59}
 59%|█████▉    | 6119/10395 [17:30:33<10:38:45,  8.96s/it] 59%|█████▉    | 6120/10395 [17:30:40<9:59:19,  8.41s/it]                                                          {'loss': 1.027, 'learning_rate': 7.634428783916608e-06, 'epoch': 0.59}
 59%|█████▉    | 6120/10395 [17:30:40<9:59:19,  8.41s/it] 59%|█████▉    | 6121/10395 [17:30:48<9:45:20,  8.22s/it]                                                         {'loss': 0.8649, 'learning_rate': 7.631401598716622e-06, 'epoch': 0.59}
 59%|█████▉    | 6121/10395 [17:30:48<9:45:20,  8.22s/it] 59%|█████▉    | 6122/10395 [17:30:56<9:37:05,  8.10s/it]                                                         {'loss': 0.8866, 'learning_rate': 7.628374643455111e-06, 'epoch': 0.59}
 59%|█████▉    | 6122/10395 [17:30:56<9:37:05,  8.10s/it] 59%|█████▉    | 6123/10395 [17:31:03<9:23:37,  7.92s/it]                                                         {'loss': 0.896, 'learning_rate': 7.625347918425918e-06, 'epoch': 0.59}
 59%|█████▉    | 6123/10395 [17:31:03<9:23:37,  7.92s/it] 59%|█████▉    | 6124/10395 [17:31:12<9:38:42,  8.13s/it]                                                         {'loss': 0.8598, 'learning_rate': 7.622321423922875e-06, 'epoch': 0.59}
 59%|█████▉    | 6124/10395 [17:31:12<9:38:42,  8.13s/it] 59%|█████▉    | 6125/10395 [17:31:20<9:37:13,  8.11s/it]                                                         {'loss': 0.9306, 'learning_rate': 7.619295160239787e-06, 'epoch': 0.59}
 59%|█████▉    | 6125/10395 [17:31:20<9:37:13,  8.11s/it] 59%|█████▉    | 6126/10395 [17:31:28<9:29:41,  8.01s/it]                                                         {'loss': 0.8593, 'learning_rate': 7.616269127670435e-06, 'epoch': 0.59}
 59%|█████▉    | 6126/10395 [17:31:28<9:29:41,  8.01s/it] 59%|█████▉    | 6127/10395 [17:31:35<9:16:13,  7.82s/it]                                                         {'loss': 0.885, 'learning_rate': 7.613243326508584e-06, 'epoch': 0.59}
 59%|█████▉    | 6127/10395 [17:31:35<9:16:13,  7.82s/it] 59%|█████▉    | 6128/10395 [17:31:44<9:28:37,  8.00s/it]                                                         {'loss': 0.849, 'learning_rate': 7.61021775704797e-06, 'epoch': 0.59}
 59%|█████▉    | 6128/10395 [17:31:44<9:28:37,  8.00s/it] 59%|█████▉    | 6129/10395 [17:31:51<9:18:33,  7.86s/it]                                                         {'loss': 0.8593, 'learning_rate': 7.607192419582312e-06, 'epoch': 0.59}
 59%|█████▉    | 6129/10395 [17:31:51<9:18:33,  7.86s/it] 59%|█████▉    | 6130/10395 [17:31:59<9:24:27,  7.94s/it]                                                         {'loss': 0.898, 'learning_rate': 7.604167314405298e-06, 'epoch': 0.59}
 59%|█████▉    | 6130/10395 [17:31:59<9:24:27,  7.94s/it] 59%|█████▉    | 6131/10395 [17:32:07<9:16:04,  7.82s/it]                                                         {'loss': 0.8766, 'learning_rate': 7.601142441810601e-06, 'epoch': 0.59}
 59%|█████▉    | 6131/10395 [17:32:07<9:16:04,  7.82s/it] 59%|█████▉    | 6132/10395 [17:32:15<9:24:54,  7.95s/it]                                                         {'loss': 0.8809, 'learning_rate': 7.598117802091871e-06, 'epoch': 0.59}
 59%|█████▉    | 6132/10395 [17:32:15<9:24:54,  7.95s/it] 59%|█████▉    | 6133/10395 [17:32:23<9:21:50,  7.91s/it]                                                         {'loss': 0.8425, 'learning_rate': 7.595093395542731e-06, 'epoch': 0.59}
 59%|█████▉    | 6133/10395 [17:32:23<9:21:50,  7.91s/it] 59%|█████▉    | 6134/10395 [17:32:32<9:37:36,  8.13s/it]                                                         {'loss': 0.9091, 'learning_rate': 7.592069222456781e-06, 'epoch': 0.59}
 59%|█████▉    | 6134/10395 [17:32:32<9:37:36,  8.13s/it] 59%|█████▉    | 6135/10395 [17:32:39<9:32:54,  8.07s/it]                                                         {'loss': 0.9341, 'learning_rate': 7.5890452831276095e-06, 'epoch': 0.59}
 59%|█████▉    | 6135/10395 [17:32:39<9:32:54,  8.07s/it] 59%|█████▉    | 6136/10395 [17:32:47<9:30:16,  8.03s/it]                                                         {'loss': 0.8749, 'learning_rate': 7.586021577848769e-06, 'epoch': 0.59}
 59%|█████▉    | 6136/10395 [17:32:47<9:30:16,  8.03s/it] 59%|█████▉    | 6137/10395 [17:32:55<9:19:33,  7.88s/it]                                                         {'loss': 0.9282, 'learning_rate': 7.582998106913797e-06, 'epoch': 0.59}
 59%|█████▉    | 6137/10395 [17:32:55<9:19:33,  7.88s/it] 59%|█████▉    | 6138/10395 [17:33:03<9:17:45,  7.86s/it]                                                         {'loss': 0.8355, 'learning_rate': 7.579974870616201e-06, 'epoch': 0.59}
 59%|█████▉    | 6138/10395 [17:33:03<9:17:45,  7.86s/it] 59%|█████▉    | 6139/10395 [17:33:11<9:18:46,  7.88s/it]                                                         {'loss': 0.9203, 'learning_rate': 7.5769518692494735e-06, 'epoch': 0.59}
 59%|█████▉    | 6139/10395 [17:33:11<9:18:46,  7.88s/it] 59%|█████▉    | 6140/10395 [17:33:19<9:19:13,  7.89s/it]                                                         {'loss': 0.8528, 'learning_rate': 7.573929103107081e-06, 'epoch': 0.59}
 59%|█████▉    | 6140/10395 [17:33:19<9:19:13,  7.89s/it] 59%|█████▉    | 6141/10395 [17:33:26<9:07:58,  7.73s/it]                                                         {'loss': 0.9022, 'learning_rate': 7.570906572482466e-06, 'epoch': 0.59}
 59%|█████▉    | 6141/10395 [17:33:26<9:07:58,  7.73s/it] 59%|█████▉    | 6142/10395 [17:33:33<9:01:03,  7.63s/it]                                                         {'loss': 0.9234, 'learning_rate': 7.567884277669047e-06, 'epoch': 0.59}
 59%|█████▉    | 6142/10395 [17:33:33<9:01:03,  7.63s/it] 59%|█████▉    | 6143/10395 [17:33:41<9:02:50,  7.66s/it]                                                         {'loss': 0.8861, 'learning_rate': 7.564862218960228e-06, 'epoch': 0.59}
 59%|█████▉    | 6143/10395 [17:33:41<9:02:50,  7.66s/it] 59%|█████▉    | 6144/10395 [17:33:48<8:54:35,  7.55s/it]                                                         {'loss': 0.872, 'learning_rate': 7.561840396649386e-06, 'epoch': 0.59}
 59%|█████▉    | 6144/10395 [17:33:48<8:54:35,  7.55s/it] 59%|█████▉    | 6145/10395 [17:33:56<8:57:08,  7.58s/it]                                                         {'loss': 0.852, 'learning_rate': 7.55881881102986e-06, 'epoch': 0.59}
 59%|█████▉    | 6145/10395 [17:33:56<8:57:08,  7.58s/it] 59%|█████▉    | 6146/10395 [17:34:03<8:52:57,  7.53s/it]                                                         {'loss': 0.9414, 'learning_rate': 7.555797462394989e-06, 'epoch': 0.59}
 59%|█████▉    | 6146/10395 [17:34:03<8:52:57,  7.53s/it] 59%|█████▉    | 6147/10395 [17:34:13<9:40:59,  8.21s/it]                                                         {'loss': 0.8687, 'learning_rate': 7.552776351038078e-06, 'epoch': 0.59}
 59%|█████▉    | 6147/10395 [17:34:13<9:40:59,  8.21s/it] 59%|█████▉    | 6148/10395 [17:34:21<9:40:54,  8.21s/it]                                                         {'loss': 0.9749, 'learning_rate': 7.549755477252409e-06, 'epoch': 0.59}
 59%|█████▉    | 6148/10395 [17:34:21<9:40:54,  8.21s/it] 59%|█████▉    | 6149/10395 [17:34:38<12:42:38, 10.78s/it]                                                          {'loss': 0.3551, 'learning_rate': 7.546734841331242e-06, 'epoch': 0.59}
 59%|█████▉    | 6149/10395 [17:34:38<12:42:38, 10.78s/it] 59%|█████▉    | 6150/10395 [17:34:46<11:48:35, 10.02s/it]                                                          {'loss': 0.9845, 'learning_rate': 7.543714443567812e-06, 'epoch': 0.59}
 59%|█████▉    | 6150/10395 [17:34:46<11:48:35, 10.02s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 59%|█████▉    | 6151/10395 [17:36:27<43:48:54, 37.17s/it]                                                          {'loss': 0.8405, 'learning_rate': 7.540694284255341e-06, 'epoch': 0.59}
 59%|█████▉    | 6151/10395 [17:36:27<43:48:54, 37.17s/it] 59%|█████▉    | 6152/10395 [17:36:34<33:17:32, 28.25s/it]                                                          {'loss': 0.8543, 'learning_rate': 7.5376743636870065e-06, 'epoch': 0.59}
 59%|█████▉    | 6152/10395 [17:36:34<33:17:32, 28.25s/it] 59%|█████▉    | 6153/10395 [17:36:41<25:37:38, 21.75s/it]                                                          {'loss': 0.9495, 'learning_rate': 7.534654682155985e-06, 'epoch': 0.59}
 59%|█████▉    | 6153/10395 [17:36:41<25:37:38, 21.75s/it] 59%|█████▉    | 6154/10395 [17:36:57<23:46:26, 20.18s/it]                                                          {'loss': 0.4168, 'learning_rate': 7.53163523995542e-06, 'epoch': 0.59}
 59%|█████▉    | 6154/10395 [17:36:57<23:46:26, 20.18s/it] 59%|█████▉    | 6155/10395 [17:37:05<19:14:01, 16.33s/it]                                                          {'loss': 1.0225, 'learning_rate': 7.528616037378429e-06, 'epoch': 0.59}
 59%|█████▉    | 6155/10395 [17:37:05<19:14:01, 16.33s/it] 59%|█████▉    | 6156/10395 [17:37:13<16:13:06, 13.77s/it]                                                          {'loss': 0.8549, 'learning_rate': 7.525597074718112e-06, 'epoch': 0.59}
 59%|█████▉    | 6156/10395 [17:37:13<16:13:06, 13.77s/it] 59%|█████▉    | 6157/10395 [17:37:30<17:25:00, 14.79s/it]                                                          {'loss': 0.4463, 'learning_rate': 7.522578352267542e-06, 'epoch': 0.59}
 59%|█████▉    | 6157/10395 [17:37:30<17:25:00, 14.79s/it] 59%|█████▉    | 6158/10395 [17:37:38<14:56:06, 12.69s/it]                                                          {'loss': 0.9175, 'learning_rate': 7.519559870319772e-06, 'epoch': 0.59}
 59%|█████▉    | 6158/10395 [17:37:38<14:56:06, 12.69s/it] 59%|█████▉    | 6159/10395 [17:37:46<13:21:03, 11.35s/it]                                                          {'loss': 0.8225, 'learning_rate': 7.516541629167835e-06, 'epoch': 0.59}
 59%|█████▉    | 6159/10395 [17:37:46<13:21:03, 11.35s/it] 59%|█████▉    | 6160/10395 [17:37:54<12:04:45, 10.27s/it]                                                          {'loss': 0.8662, 'learning_rate': 7.513523629104722e-06, 'epoch': 0.59}
 59%|█████▉    | 6160/10395 [17:37:54<12:04:45, 10.27s/it] 59%|█████▉    | 6161/10395 [17:38:12<14:53:31, 12.66s/it]                                                          {'loss': 0.3682, 'learning_rate': 7.510505870423423e-06, 'epoch': 0.59}
 59%|█████▉    | 6161/10395 [17:38:12<14:53:31, 12.66s/it] 59%|█████▉    | 6162/10395 [17:38:19<13:08:49, 11.18s/it]                                                          {'loss': 0.9503, 'learning_rate': 7.507488353416896e-06, 'epoch': 0.59}
 59%|█████▉    | 6162/10395 [17:38:19<13:08:49, 11.18s/it] 59%|█████▉    | 6163/10395 [17:38:28<12:14:53, 10.42s/it]                                                          {'loss': 0.8518, 'learning_rate': 7.5044710783780725e-06, 'epoch': 0.59}
 59%|█████▉    | 6163/10395 [17:38:28<12:14:53, 10.42s/it] 59%|█████▉    | 6164/10395 [17:38:36<11:28:30,  9.76s/it]                                                          {'loss': 0.9838, 'learning_rate': 7.501454045599863e-06, 'epoch': 0.59}
 59%|█████▉    | 6164/10395 [17:38:36<11:28:30,  9.76s/it] 59%|█████▉    | 6165/10395 [17:38:45<10:57:06,  9.32s/it]                                                          {'loss': 0.9066, 'learning_rate': 7.498437255375153e-06, 'epoch': 0.59}
 59%|█████▉    | 6165/10395 [17:38:45<10:57:06,  9.32s/it] 59%|█████▉    | 6166/10395 [17:38:53<10:41:04,  9.10s/it]                                                          {'loss': 0.9085, 'learning_rate': 7.495420707996816e-06, 'epoch': 0.59}
 59%|█████▉    | 6166/10395 [17:38:53<10:41:04,  9.10s/it] 59%|█████▉    | 6167/10395 [17:39:01<10:10:29,  8.66s/it]                                                          {'loss': 0.9472, 'learning_rate': 7.492404403757679e-06, 'epoch': 0.59}
 59%|█████▉    | 6167/10395 [17:39:01<10:10:29,  8.66s/it] 59%|█████▉    | 6168/10395 [17:39:09<9:53:56,  8.43s/it]                                                          {'loss': 0.9537, 'learning_rate': 7.489388342950562e-06, 'epoch': 0.59}
 59%|█████▉    | 6168/10395 [17:39:09<9:53:56,  8.43s/it] 59%|█████▉    | 6169/10395 [17:39:16<9:29:20,  8.08s/it]                                                         {'loss': 0.9638, 'learning_rate': 7.4863725258682615e-06, 'epoch': 0.59}
 59%|█████▉    | 6169/10395 [17:39:16<9:29:20,  8.08s/it] 59%|█████▉    | 6170/10395 [17:39:24<9:30:04,  8.10s/it]                                                         {'loss': 0.8143, 'learning_rate': 7.4833569528035445e-06, 'epoch': 0.59}
 59%|█████▉    | 6170/10395 [17:39:24<9:30:04,  8.10s/it] 59%|█████▉    | 6171/10395 [17:39:33<9:47:57,  8.35s/it]                                                         {'loss': 0.9337, 'learning_rate': 7.480341624049156e-06, 'epoch': 0.59}
 59%|█████▉    | 6171/10395 [17:39:33<9:47:57,  8.35s/it] 59%|█████▉    | 6172/10395 [17:39:40<9:22:17,  7.99s/it]                                                         {'loss': 0.8765, 'learning_rate': 7.47732653989782e-06, 'epoch': 0.59}
 59%|█████▉    | 6172/10395 [17:39:40<9:22:17,  7.99s/it] 59%|█████▉    | 6173/10395 [17:39:49<9:35:44,  8.18s/it]                                                         {'loss': 0.8912, 'learning_rate': 7.474311700642234e-06, 'epoch': 0.59}
 59%|█████▉    | 6173/10395 [17:39:49<9:35:44,  8.18s/it] 59%|█████▉    | 6174/10395 [17:39:58<9:52:55,  8.43s/it]                                                         {'loss': 0.8822, 'learning_rate': 7.471297106575067e-06, 'epoch': 0.59}
 59%|█████▉    | 6174/10395 [17:39:58<9:52:55,  8.43s/it] 59%|█████▉    | 6175/10395 [17:40:16<13:18:33, 11.35s/it]                                                          {'loss': 0.3489, 'learning_rate': 7.468282757988974e-06, 'epoch': 0.59}
 59%|█████▉    | 6175/10395 [17:40:16<13:18:33, 11.35s/it] 59%|█████▉    | 6176/10395 [17:40:23<11:43:24, 10.00s/it]                                                          {'loss': 0.992, 'learning_rate': 7.465268655176578e-06, 'epoch': 0.59}
 59%|█████▉    | 6176/10395 [17:40:23<11:43:24, 10.00s/it] 59%|█████▉    | 6177/10395 [17:40:31<10:57:33,  9.35s/it]                                                          {'loss': 0.8562, 'learning_rate': 7.462254798430487e-06, 'epoch': 0.59}
 59%|█████▉    | 6177/10395 [17:40:31<10:57:33,  9.35s/it] 59%|█████▉    | 6178/10395 [17:40:39<10:25:41,  8.90s/it]                                                          {'loss': 0.8388, 'learning_rate': 7.459241188043277e-06, 'epoch': 0.59}
 59%|█████▉    | 6178/10395 [17:40:39<10:25:41,  8.90s/it] 59%|█████▉    | 6179/10395 [17:40:46<10:00:32,  8.55s/it]                                                          {'loss': 0.8083, 'learning_rate': 7.456227824307503e-06, 'epoch': 0.59}
 59%|█████▉    | 6179/10395 [17:40:46<10:00:32,  8.55s/it] 59%|█████▉    | 6180/10395 [17:40:54<9:50:40,  8.41s/it]                                                          {'loss': 0.8939, 'learning_rate': 7.453214707515695e-06, 'epoch': 0.59}
 59%|█████▉    | 6180/10395 [17:40:54<9:50:40,  8.41s/it] 59%|█████▉    | 6181/10395 [17:41:02<9:39:51,  8.26s/it]                                                         {'loss': 0.9447, 'learning_rate': 7.450201837960363e-06, 'epoch': 0.59}
 59%|█████▉    | 6181/10395 [17:41:02<9:39:51,  8.26s/it] 59%|█████▉    | 6182/10395 [17:41:10<9:23:24,  8.02s/it]                                                         {'loss': 0.948, 'learning_rate': 7.447189215933985e-06, 'epoch': 0.59}
 59%|█████▉    | 6182/10395 [17:41:10<9:23:24,  8.02s/it] 59%|█████▉    | 6183/10395 [17:41:18<9:28:25,  8.10s/it]                                                         {'loss': 0.8454, 'learning_rate': 7.444176841729022e-06, 'epoch': 0.59}
 59%|█████▉    | 6183/10395 [17:41:18<9:28:25,  8.10s/it] 59%|█████▉    | 6184/10395 [17:41:26<9:17:32,  7.94s/it]                                                         {'loss': 0.9631, 'learning_rate': 7.44116471563791e-06, 'epoch': 0.59}
 59%|█████▉    | 6184/10395 [17:41:26<9:17:32,  7.94s/it] 59%|█████▉    | 6185/10395 [17:41:34<9:27:59,  8.09s/it]                                                         {'loss': 0.8375, 'learning_rate': 7.4381528379530596e-06, 'epoch': 0.59}
 59%|█████▉    | 6185/10395 [17:41:34<9:27:59,  8.09s/it] 60%|█████▉    | 6186/10395 [17:41:41<9:09:29,  7.83s/it]                                                         {'loss': 0.8612, 'learning_rate': 7.435141208966858e-06, 'epoch': 0.6}
 60%|█████▉    | 6186/10395 [17:41:41<9:09:29,  7.83s/it] 60%|█████▉    | 6187/10395 [17:41:49<9:09:28,  7.83s/it]                                                         {'loss': 0.8686, 'learning_rate': 7.432129828971666e-06, 'epoch': 0.6}
 60%|█████▉    | 6187/10395 [17:41:49<9:09:28,  7.83s/it] 60%|█████▉    | 6188/10395 [17:41:58<9:23:04,  8.03s/it]                                                         {'loss': 0.8218, 'learning_rate': 7.429118698259824e-06, 'epoch': 0.6}
 60%|█████▉    | 6188/10395 [17:41:58<9:23:04,  8.03s/it] 60%|█████▉    | 6189/10395 [17:42:06<9:28:58,  8.12s/it]                                                         {'loss': 0.8183, 'learning_rate': 7.426107817123644e-06, 'epoch': 0.6}
 60%|█████▉    | 6189/10395 [17:42:06<9:28:58,  8.12s/it] 60%|█████▉    | 6190/10395 [17:42:13<9:16:27,  7.94s/it]                                                         {'loss': 0.8991, 'learning_rate': 7.423097185855416e-06, 'epoch': 0.6}
 60%|█████▉    | 6190/10395 [17:42:13<9:16:27,  7.94s/it] 60%|█████▉    | 6191/10395 [17:42:21<9:14:40,  7.92s/it]                                                         {'loss': 0.9021, 'learning_rate': 7.4200868047474036e-06, 'epoch': 0.6}
 60%|█████▉    | 6191/10395 [17:42:21<9:14:40,  7.92s/it] 60%|█████▉    | 6192/10395 [17:42:29<9:07:22,  7.81s/it]                                                         {'loss': 0.9299, 'learning_rate': 7.417076674091854e-06, 'epoch': 0.6}
 60%|█████▉    | 6192/10395 [17:42:29<9:07:22,  7.81s/it] 60%|█████▉    | 6193/10395 [17:42:36<8:55:55,  7.65s/it]                                                         {'loss': 0.9239, 'learning_rate': 7.414066794180981e-06, 'epoch': 0.6}
 60%|█████▉    | 6193/10395 [17:42:36<8:55:55,  7.65s/it] 60%|█████▉    | 6194/10395 [17:42:45<9:17:58,  7.97s/it]                                                         {'loss': 0.8758, 'learning_rate': 7.411057165306976e-06, 'epoch': 0.6}
 60%|█████▉    | 6194/10395 [17:42:45<9:17:58,  7.97s/it] 60%|█████▉    | 6195/10395 [17:42:53<9:17:24,  7.96s/it]                                                         {'loss': 0.8911, 'learning_rate': 7.408047787762013e-06, 'epoch': 0.6}
 60%|█████▉    | 6195/10395 [17:42:53<9:17:24,  7.96s/it] 60%|█████▉    | 6196/10395 [17:43:01<9:10:32,  7.87s/it]                                                         {'loss': 0.9325, 'learning_rate': 7.405038661838229e-06, 'epoch': 0.6}
 60%|█████▉    | 6196/10395 [17:43:01<9:10:32,  7.87s/it] 60%|█████▉    | 6197/10395 [17:43:09<9:20:48,  8.02s/it]                                                         {'loss': 0.9071, 'learning_rate': 7.402029787827746e-06, 'epoch': 0.6}
 60%|█████▉    | 6197/10395 [17:43:09<9:20:48,  8.02s/it] 60%|█████▉    | 6198/10395 [17:43:17<9:17:18,  7.97s/it]                                                         {'loss': 0.9638, 'learning_rate': 7.3990211660226595e-06, 'epoch': 0.6}
 60%|█████▉    | 6198/10395 [17:43:17<9:17:18,  7.97s/it] 60%|█████▉    | 6199/10395 [17:43:24<9:12:39,  7.90s/it]                                                         {'loss': 0.8461, 'learning_rate': 7.3960127967150375e-06, 'epoch': 0.6}
 60%|█████▉    | 6199/10395 [17:43:24<9:12:39,  7.90s/it] 60%|█████▉    | 6200/10395 [17:43:32<9:01:32,  7.75s/it]                                                         {'loss': 0.871, 'learning_rate': 7.39300468019693e-06, 'epoch': 0.6}
 60%|█████▉    | 6200/10395 [17:43:32<9:01:32,  7.75s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 60%|█████▉    | 6201/10395 [17:45:13<41:47:45, 35.88s/it]                                                          {'loss': 0.9152, 'learning_rate': 7.3899968167603585e-06, 'epoch': 0.6}
 60%|█████▉    | 6201/10395 [17:45:13<41:47:45, 35.88s/it] 60%|█████▉    | 6202/10395 [17:45:21<31:51:40, 27.36s/it]                                                          {'loss': 0.909, 'learning_rate': 7.386989206697317e-06, 'epoch': 0.6}
 60%|█████▉    | 6202/10395 [17:45:21<31:51:40, 27.36s/it] 60%|█████▉    | 6203/10395 [17:45:29<25:15:44, 21.69s/it]                                                          {'loss': 0.8327, 'learning_rate': 7.383981850299782e-06, 'epoch': 0.6}
 60%|█████▉    | 6203/10395 [17:45:29<25:15:44, 21.69s/it] 60%|█████▉    | 6204/10395 [17:45:37<20:11:56, 17.35s/it]                                                          {'loss': 0.8803, 'learning_rate': 7.380974747859697e-06, 'epoch': 0.6}
 60%|█████▉    | 6204/10395 [17:45:37<20:11:56, 17.35s/it] 60%|█████▉    | 6205/10395 [17:45:54<20:21:20, 17.49s/it]                                                          {'loss': 0.3887, 'learning_rate': 7.377967899668985e-06, 'epoch': 0.6}
 60%|█████▉    | 6205/10395 [17:45:54<20:21:20, 17.49s/it] 60%|█████▉    | 6206/10395 [17:46:03<17:05:37, 14.69s/it]                                                          {'loss': 0.8839, 'learning_rate': 7.3749613060195476e-06, 'epoch': 0.6}
 60%|█████▉    | 6206/10395 [17:46:03<17:05:37, 14.69s/it] 60%|█████▉    | 6207/10395 [17:46:10<14:30:37, 12.47s/it]                                                          {'loss': 0.8349, 'learning_rate': 7.3719549672032546e-06, 'epoch': 0.6}
 60%|█████▉    | 6207/10395 [17:46:10<14:30:37, 12.47s/it] 60%|█████▉    | 6208/10395 [17:46:27<16:05:01, 13.83s/it]                                                          {'loss': 0.3694, 'learning_rate': 7.36894888351196e-06, 'epoch': 0.6}
 60%|█████▉    | 6208/10395 [17:46:27<16:05:01, 13.83s/it] 60%|█████▉    | 6209/10395 [17:46:35<13:57:41, 12.01s/it]                                                          {'loss': 0.8475, 'learning_rate': 7.3659430552374836e-06, 'epoch': 0.6}
 60%|█████▉    | 6209/10395 [17:46:35<13:57:41, 12.01s/it] 60%|█████▉    | 6210/10395 [17:46:42<12:20:45, 10.62s/it]                                                          {'loss': 0.7854, 'learning_rate': 7.362937482671628e-06, 'epoch': 0.6}
 60%|█████▉    | 6210/10395 [17:46:42<12:20:45, 10.62s/it] 60%|█████▉    | 6211/10395 [17:46:50<11:19:04,  9.74s/it]                                                          {'loss': 0.9123, 'learning_rate': 7.359932166106165e-06, 'epoch': 0.6}
 60%|█████▉    | 6211/10395 [17:46:50<11:19:04,  9.74s/it] 60%|█████▉    | 6212/10395 [17:46:57<10:39:20,  9.17s/it]                                                          {'loss': 0.9598, 'learning_rate': 7.356927105832846e-06, 'epoch': 0.6}
 60%|█████▉    | 6212/10395 [17:46:57<10:39:20,  9.17s/it] 60%|█████▉    | 6213/10395 [17:47:05<10:07:33,  8.72s/it]                                                          {'loss': 0.9243, 'learning_rate': 7.353922302143395e-06, 'epoch': 0.6}
 60%|█████▉    | 6213/10395 [17:47:05<10:07:33,  8.72s/it] 60%|█████▉    | 6214/10395 [17:47:13<9:56:21,  8.56s/it]                                                          {'loss': 0.7847, 'learning_rate': 7.350917755329512e-06, 'epoch': 0.6}
 60%|█████▉    | 6214/10395 [17:47:13<9:56:21,  8.56s/it] 60%|█████▉    | 6215/10395 [17:47:21<9:36:02,  8.27s/it]                                                         {'loss': 0.7826, 'learning_rate': 7.34791346568287e-06, 'epoch': 0.6}
 60%|█████▉    | 6215/10395 [17:47:21<9:36:02,  8.27s/it] 60%|█████▉    | 6216/10395 [17:47:28<9:10:56,  7.91s/it]                                                         {'loss': 0.8597, 'learning_rate': 7.344909433495124e-06, 'epoch': 0.6}
 60%|█████▉    | 6216/10395 [17:47:28<9:10:56,  7.91s/it] 60%|█████▉    | 6217/10395 [17:47:38<9:51:36,  8.50s/it]                                                         {'loss': 0.8205, 'learning_rate': 7.341905659057895e-06, 'epoch': 0.6}
 60%|█████▉    | 6217/10395 [17:47:38<9:51:36,  8.50s/it] 60%|█████▉    | 6218/10395 [17:47:45<9:28:36,  8.17s/it]                                                         {'loss': 0.8787, 'learning_rate': 7.3389021426627886e-06, 'epoch': 0.6}
 60%|█████▉    | 6218/10395 [17:47:45<9:28:36,  8.17s/it] 60%|█████▉    | 6219/10395 [17:47:53<9:10:12,  7.91s/it]                                                         {'loss': 0.9118, 'learning_rate': 7.3358988846013715e-06, 'epoch': 0.6}
 60%|█████▉    | 6219/10395 [17:47:53<9:10:12,  7.91s/it] 60%|█████▉    | 6220/10395 [17:48:00<8:51:43,  7.64s/it]                                                         {'loss': 0.8813, 'learning_rate': 7.332895885165198e-06, 'epoch': 0.6}
 60%|█████▉    | 6220/10395 [17:48:00<8:51:43,  7.64s/it] 60%|█████▉    | 6221/10395 [17:48:08<9:10:21,  7.91s/it]                                                         {'loss': 0.8678, 'learning_rate': 7.329893144645792e-06, 'epoch': 0.6}
 60%|█████▉    | 6221/10395 [17:48:08<9:10:21,  7.91s/it] 60%|█████▉    | 6222/10395 [17:48:16<9:11:06,  7.92s/it]                                                         {'loss': 0.8543, 'learning_rate': 7.3268906633346515e-06, 'epoch': 0.6}
 60%|█████▉    | 6222/10395 [17:48:16<9:11:06,  7.92s/it] 60%|█████▉    | 6223/10395 [17:48:24<9:07:18,  7.87s/it]                                                         {'loss': 0.9128, 'learning_rate': 7.323888441523255e-06, 'epoch': 0.6}
 60%|█████▉    | 6223/10395 [17:48:24<9:07:18,  7.87s/it] 60%|█████▉    | 6224/10395 [17:48:32<9:21:27,  8.08s/it]                                                         {'loss': 0.8914, 'learning_rate': 7.32088647950305e-06, 'epoch': 0.6}
 60%|█████▉    | 6224/10395 [17:48:32<9:21:27,  8.08s/it] 60%|█████▉    | 6225/10395 [17:48:40<9:12:04,  7.94s/it]                                                         {'loss': 0.9034, 'learning_rate': 7.317884777565462e-06, 'epoch': 0.6}
 60%|█████▉    | 6225/10395 [17:48:40<9:12:04,  7.94s/it] 60%|█████▉    | 6226/10395 [17:48:48<9:20:37,  8.07s/it]                                                         {'loss': 0.8557, 'learning_rate': 7.314883336001885e-06, 'epoch': 0.6}
 60%|█████▉    | 6226/10395 [17:48:48<9:20:37,  8.07s/it] 60%|█████▉    | 6227/10395 [17:48:57<9:35:28,  8.28s/it]                                                         {'loss': 0.8202, 'learning_rate': 7.311882155103698e-06, 'epoch': 0.6}
 60%|█████▉    | 6227/10395 [17:48:57<9:35:28,  8.28s/it] 60%|█████▉    | 6228/10395 [17:49:06<9:48:04,  8.47s/it]                                                         {'loss': 0.8325, 'learning_rate': 7.308881235162246e-06, 'epoch': 0.6}
 60%|█████▉    | 6228/10395 [17:49:06<9:48:04,  8.47s/it] 60%|█████▉    | 6229/10395 [17:49:14<9:28:23,  8.19s/it]                                                         {'loss': 0.9956, 'learning_rate': 7.305880576468853e-06, 'epoch': 0.6}
 60%|█████▉    | 6229/10395 [17:49:14<9:28:23,  8.19s/it] 60%|█████▉    | 6230/10395 [17:49:22<9:26:24,  8.16s/it]                                                         {'loss': 0.877, 'learning_rate': 7.302880179314813e-06, 'epoch': 0.6}
 60%|█████▉    | 6230/10395 [17:49:22<9:26:24,  8.16s/it] 60%|█████▉    | 6231/10395 [17:49:29<9:13:40,  7.98s/it]                                                         {'loss': 0.9026, 'learning_rate': 7.2998800439914045e-06, 'epoch': 0.6}
 60%|█████▉    | 6231/10395 [17:49:29<9:13:40,  7.98s/it] 60%|█████▉    | 6232/10395 [17:49:38<9:32:13,  8.25s/it]                                                         {'loss': 0.8715, 'learning_rate': 7.296880170789875e-06, 'epoch': 0.6}
 60%|█████▉    | 6232/10395 [17:49:38<9:32:13,  8.25s/it] 60%|█████▉    | 6233/10395 [17:49:46<9:25:16,  8.15s/it]                                                         {'loss': 0.9377, 'learning_rate': 7.293880560001435e-06, 'epoch': 0.6}
 60%|█████▉    | 6233/10395 [17:49:46<9:25:16,  8.15s/it] 60%|█████▉    | 6234/10395 [17:49:53<9:06:23,  7.88s/it]                                                         {'loss': 0.8401, 'learning_rate': 7.29088121191729e-06, 'epoch': 0.6}
 60%|█████▉    | 6234/10395 [17:49:53<9:06:23,  7.88s/it] 60%|█████▉    | 6235/10395 [17:50:01<8:53:52,  7.70s/it]                                                         {'loss': 0.869, 'learning_rate': 7.287882126828607e-06, 'epoch': 0.6}
 60%|█████▉    | 6235/10395 [17:50:01<8:53:52,  7.70s/it] 60%|█████▉    | 6236/10395 [17:50:10<9:27:20,  8.18s/it]                                                         {'loss': 0.8425, 'learning_rate': 7.2848833050265335e-06, 'epoch': 0.6}
 60%|█████▉    | 6236/10395 [17:50:10<9:27:20,  8.18s/it] 60%|██████    | 6237/10395 [17:50:18<9:21:30,  8.10s/it]                                                         {'loss': 0.8392, 'learning_rate': 7.2818847468021834e-06, 'epoch': 0.6}
 60%|██████    | 6237/10395 [17:50:18<9:21:30,  8.10s/it] 60%|██████    | 6238/10395 [17:50:25<9:11:46,  7.96s/it]                                                         {'loss': 0.7928, 'learning_rate': 7.278886452446654e-06, 'epoch': 0.6}
 60%|██████    | 6238/10395 [17:50:25<9:11:46,  7.96s/it] 60%|██████    | 6239/10395 [17:50:33<9:03:41,  7.85s/it]                                                         {'loss': 0.8646, 'learning_rate': 7.275888422251013e-06, 'epoch': 0.6}
 60%|██████    | 6239/10395 [17:50:33<9:03:41,  7.85s/it] 60%|██████    | 6240/10395 [17:50:40<8:56:09,  7.74s/it]                                                         {'loss': 0.9506, 'learning_rate': 7.2728906565063074e-06, 'epoch': 0.6}
 60%|██████    | 6240/10395 [17:50:40<8:56:09,  7.74s/it] 60%|██████    | 6241/10395 [17:50:48<8:55:15,  7.73s/it]                                                         {'loss': 0.836, 'learning_rate': 7.269893155503543e-06, 'epoch': 0.6}
 60%|██████    | 6241/10395 [17:50:48<8:55:15,  7.73s/it] 60%|██████    | 6242/10395 [17:50:56<9:01:20,  7.82s/it]                                                         {'loss': 0.8998, 'learning_rate': 7.266895919533719e-06, 'epoch': 0.6}
 60%|██████    | 6242/10395 [17:50:56<9:01:20,  7.82s/it] 60%|██████    | 6243/10395 [17:51:04<8:53:00,  7.70s/it]                                                         {'loss': 0.9149, 'learning_rate': 7.263898948887797e-06, 'epoch': 0.6}
 60%|██████    | 6243/10395 [17:51:04<8:53:00,  7.70s/it] 60%|██████    | 6244/10395 [17:51:11<8:43:00,  7.56s/it]                                                         {'loss': 0.9542, 'learning_rate': 7.2609022438567205e-06, 'epoch': 0.6}
 60%|██████    | 6244/10395 [17:51:11<8:43:00,  7.56s/it] 60%|██████    | 6245/10395 [17:51:19<8:54:19,  7.73s/it]                                                         {'loss': 0.8382, 'learning_rate': 7.257905804731398e-06, 'epoch': 0.6}
 60%|██████    | 6245/10395 [17:51:19<8:54:19,  7.73s/it] 60%|██████    | 6246/10395 [17:51:27<9:00:52,  7.82s/it]                                                         {'loss': 0.9324, 'learning_rate': 7.25490963180272e-06, 'epoch': 0.6}
 60%|██████    | 6246/10395 [17:51:27<9:00:52,  7.82s/it] 60%|██████    | 6247/10395 [17:51:35<8:53:15,  7.71s/it]                                                         {'loss': 0.9664, 'learning_rate': 7.251913725361553e-06, 'epoch': 0.6}
 60%|██████    | 6247/10395 [17:51:35<8:53:15,  7.71s/it] 60%|██████    | 6248/10395 [17:51:42<8:47:34,  7.63s/it]                                                         {'loss': 0.9018, 'learning_rate': 7.248918085698726e-06, 'epoch': 0.6}
 60%|██████    | 6248/10395 [17:51:42<8:47:34,  7.63s/it] 60%|██████    | 6249/10395 [17:51:49<8:44:17,  7.59s/it]                                                         {'loss': 0.8766, 'learning_rate': 7.24592271310505e-06, 'epoch': 0.6}
 60%|██████    | 6249/10395 [17:51:49<8:44:17,  7.59s/it] 60%|██████    | 6250/10395 [17:51:57<8:41:01,  7.54s/it]                                                         {'loss': 0.8863, 'learning_rate': 7.242927607871314e-06, 'epoch': 0.6}
 60%|██████    | 6250/10395 [17:51:57<8:41:01,  7.54s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 60%|██████    | 6251/10395 [17:53:47<44:08:22, 38.35s/it]                                                          {'loss': 0.3561, 'learning_rate': 7.239932770288274e-06, 'epoch': 0.6}
 60%|██████    | 6251/10395 [17:53:47<44:08:22, 38.35s/it] 60%|██████    | 6252/10395 [17:53:56<33:59:36, 29.54s/it]                                                          {'loss': 0.8569, 'learning_rate': 7.236938200646661e-06, 'epoch': 0.6}
 60%|██████    | 6252/10395 [17:53:56<33:59:36, 29.54s/it] 60%|██████    | 6253/10395 [17:54:04<26:29:53, 23.03s/it]                                                          {'loss': 0.9285, 'learning_rate': 7.2339438992371815e-06, 'epoch': 0.6}
 60%|██████    | 6253/10395 [17:54:04<26:29:53, 23.03s/it] 60%|██████    | 6254/10395 [17:54:13<21:33:17, 18.74s/it]                                                          {'loss': 0.8371, 'learning_rate': 7.230949866350524e-06, 'epoch': 0.6}
 60%|██████    | 6254/10395 [17:54:13<21:33:17, 18.74s/it] 60%|██████    | 6255/10395 [17:54:20<17:39:46, 15.36s/it]                                                          {'loss': 0.8228, 'learning_rate': 7.227956102277332e-06, 'epoch': 0.6}
 60%|██████    | 6255/10395 [17:54:20<17:39:46, 15.36s/it] 60%|██████    | 6256/10395 [17:54:38<18:23:58, 16.00s/it]                                                          {'loss': 0.372, 'learning_rate': 7.224962607308234e-06, 'epoch': 0.6}
 60%|██████    | 6256/10395 [17:54:38<18:23:58, 16.00s/it] 60%|██████    | 6257/10395 [17:54:46<15:48:04, 13.75s/it]                                                          {'loss': 0.8491, 'learning_rate': 7.22196938173384e-06, 'epoch': 0.6}
 60%|██████    | 6257/10395 [17:54:46<15:48:04, 13.75s/it] 60%|██████    | 6258/10395 [17:54:54<13:37:53, 11.86s/it]                                                          {'loss': 0.959, 'learning_rate': 7.218976425844719e-06, 'epoch': 0.6}
 60%|██████    | 6258/10395 [17:54:54<13:37:53, 11.86s/it] 60%|██████    | 6259/10395 [17:55:01<12:07:47, 10.56s/it]                                                          {'loss': 0.8584, 'learning_rate': 7.215983739931426e-06, 'epoch': 0.6}
 60%|██████    | 6259/10395 [17:55:01<12:07:47, 10.56s/it] 60%|██████    | 6260/10395 [17:55:09<11:11:36,  9.75s/it]                                                          {'loss': 0.9911, 'learning_rate': 7.212991324284482e-06, 'epoch': 0.6}
 60%|██████    | 6260/10395 [17:55:09<11:11:36,  9.75s/it] 60%|██████    | 6261/10395 [17:55:17<10:34:02,  9.20s/it]                                                          {'loss': 0.944, 'learning_rate': 7.209999179194381e-06, 'epoch': 0.6}
 60%|██████    | 6261/10395 [17:55:17<10:34:02,  9.20s/it] 60%|██████    | 6262/10395 [17:55:24<9:58:42,  8.69s/it]                                                          {'loss': 0.9269, 'learning_rate': 7.207007304951604e-06, 'epoch': 0.6}
 60%|██████    | 6262/10395 [17:55:24<9:58:42,  8.69s/it] 60%|██████    | 6263/10395 [17:55:33<9:48:04,  8.54s/it]                                                         {'loss': 0.9392, 'learning_rate': 7.204015701846585e-06, 'epoch': 0.6}
 60%|██████    | 6263/10395 [17:55:33<9:48:04,  8.54s/it] 60%|██████    | 6264/10395 [17:55:41<9:54:20,  8.63s/it]                                                         {'loss': 0.893, 'learning_rate': 7.201024370169745e-06, 'epoch': 0.6}
 60%|██████    | 6264/10395 [17:55:41<9:54:20,  8.63s/it] 60%|██████    | 6265/10395 [17:55:50<9:51:29,  8.59s/it]                                                         {'loss': 0.8546, 'learning_rate': 7.19803331021148e-06, 'epoch': 0.6}
 60%|██████    | 6265/10395 [17:55:50<9:51:29,  8.59s/it] 60%|██████    | 6266/10395 [17:55:58<9:44:58,  8.50s/it]                                                         {'loss': 0.9374, 'learning_rate': 7.195042522262152e-06, 'epoch': 0.6}
 60%|██████    | 6266/10395 [17:55:58<9:44:58,  8.50s/it] 60%|██████    | 6267/10395 [17:56:06<9:24:31,  8.21s/it]                                                         {'loss': 0.8998, 'learning_rate': 7.192052006612102e-06, 'epoch': 0.6}
 60%|██████    | 6267/10395 [17:56:06<9:24:31,  8.21s/it] 60%|██████    | 6268/10395 [17:56:13<9:15:01,  8.07s/it]                                                         {'loss': 0.9015, 'learning_rate': 7.189061763551644e-06, 'epoch': 0.6}
 60%|██████    | 6268/10395 [17:56:13<9:15:01,  8.07s/it] 60%|██████    | 6269/10395 [17:56:21<9:10:37,  8.01s/it]                                                         {'loss': 0.9266, 'learning_rate': 7.186071793371066e-06, 'epoch': 0.6}
 60%|██████    | 6269/10395 [17:56:21<9:10:37,  8.01s/it] 60%|██████    | 6270/10395 [17:56:28<8:44:55,  7.64s/it]                                                         {'loss': 0.9605, 'learning_rate': 7.183082096360621e-06, 'epoch': 0.6}
 60%|██████    | 6270/10395 [17:56:28<8:44:55,  7.64s/it] 60%|██████    | 6271/10395 [17:56:36<8:56:16,  7.80s/it]                                                         {'loss': 0.9128, 'learning_rate': 7.180092672810546e-06, 'epoch': 0.6}
 60%|██████    | 6271/10395 [17:56:36<8:56:16,  7.80s/it] 60%|██████    | 6272/10395 [17:56:45<9:14:44,  8.07s/it]                                                         {'loss': 0.8368, 'learning_rate': 7.177103523011047e-06, 'epoch': 0.6}
 60%|██████    | 6272/10395 [17:56:45<9:14:44,  8.07s/it] 60%|██████    | 6273/10395 [17:56:53<9:04:20,  7.92s/it]                                                         {'loss': 0.864, 'learning_rate': 7.174114647252306e-06, 'epoch': 0.6}
 60%|██████    | 6273/10395 [17:56:53<9:04:20,  7.92s/it] 60%|██████    | 6274/10395 [17:57:00<8:55:32,  7.80s/it]                                                         {'loss': 0.7925, 'learning_rate': 7.171126045824477e-06, 'epoch': 0.6}
 60%|██████    | 6274/10395 [17:57:00<8:55:32,  7.80s/it] 60%|██████    | 6275/10395 [17:57:15<11:27:46, 10.02s/it]                                                          {'loss': 0.3416, 'learning_rate': 7.168137719017687e-06, 'epoch': 0.6}
 60%|██████    | 6275/10395 [17:57:15<11:27:46, 10.02s/it] 60%|██████    | 6276/10395 [17:57:23<10:39:27,  9.31s/it]                                                          {'loss': 0.8928, 'learning_rate': 7.165149667122036e-06, 'epoch': 0.6}
 60%|██████    | 6276/10395 [17:57:23<10:39:27,  9.31s/it] 60%|██████    | 6277/10395 [17:57:31<10:10:49,  8.90s/it]                                                          {'loss': 0.9178, 'learning_rate': 7.162161890427597e-06, 'epoch': 0.6}
 60%|██████    | 6277/10395 [17:57:31<10:10:49,  8.90s/it] 60%|██████    | 6278/10395 [17:57:40<10:08:46,  8.87s/it]                                                          {'loss': 0.8551, 'learning_rate': 7.159174389224417e-06, 'epoch': 0.6}
 60%|██████    | 6278/10395 [17:57:40<10:08:46,  8.87s/it] 60%|██████    | 6279/10395 [17:57:48<9:54:04,  8.66s/it]                                                          {'loss': 0.8396, 'learning_rate': 7.156187163802515e-06, 'epoch': 0.6}
 60%|██████    | 6279/10395 [17:57:48<9:54:04,  8.66s/it] 60%|██████    | 6280/10395 [17:58:06<13:18:37, 11.64s/it]                                                          {'loss': 0.3831, 'learning_rate': 7.153200214451885e-06, 'epoch': 0.6}
 60%|██████    | 6280/10395 [17:58:06<13:18:37, 11.64s/it] 60%|██████    | 6281/10395 [17:58:15<12:11:20, 10.67s/it]                                                          {'loss': 0.9127, 'learning_rate': 7.1502135414624966e-06, 'epoch': 0.6}
 60%|██████    | 6281/10395 [17:58:15<12:11:20, 10.67s/it] 60%|██████    | 6282/10395 [17:58:22<11:05:30,  9.71s/it]                                                          {'loss': 0.8209, 'learning_rate': 7.147227145124287e-06, 'epoch': 0.6}
 60%|██████    | 6282/10395 [17:58:22<11:05:30,  9.71s/it] 60%|██████    | 6283/10395 [17:58:30<10:15:14,  8.98s/it]                                                          {'loss': 0.9625, 'learning_rate': 7.1442410257271695e-06, 'epoch': 0.6}
 60%|██████    | 6283/10395 [17:58:30<10:15:14,  8.98s/it] 60%|██████    | 6284/10395 [17:58:37<9:52:12,  8.64s/it]                                                          {'loss': 0.8929, 'learning_rate': 7.141255183561033e-06, 'epoch': 0.6}
 60%|██████    | 6284/10395 [17:58:37<9:52:12,  8.64s/it] 60%|██████    | 6285/10395 [17:58:45<9:36:25,  8.41s/it]                                                         {'loss': 0.9207, 'learning_rate': 7.138269618915732e-06, 'epoch': 0.6}
 60%|██████    | 6285/10395 [17:58:45<9:36:25,  8.41s/it] 60%|██████    | 6286/10395 [17:58:53<9:17:16,  8.14s/it]                                                         {'loss': 0.9532, 'learning_rate': 7.1352843320811005e-06, 'epoch': 0.6}
 60%|██████    | 6286/10395 [17:58:53<9:17:16,  8.14s/it] 60%|██████    | 6287/10395 [17:59:00<9:06:54,  7.99s/it]                                                         {'loss': 0.84, 'learning_rate': 7.132299323346943e-06, 'epoch': 0.6}
 60%|██████    | 6287/10395 [17:59:00<9:06:54,  7.99s/it] 60%|██████    | 6288/10395 [17:59:09<9:09:03,  8.02s/it]                                                         {'loss': 0.8486, 'learning_rate': 7.1293145930030395e-06, 'epoch': 0.6}
 60%|██████    | 6288/10395 [17:59:09<9:09:03,  8.02s/it] 61%|██████    | 6289/10395 [17:59:17<9:14:22,  8.10s/it]                                                         {'loss': 0.8858, 'learning_rate': 7.126330141339142e-06, 'epoch': 0.6}
 61%|██████    | 6289/10395 [17:59:17<9:14:22,  8.10s/it] 61%|██████    | 6290/10395 [17:59:25<9:08:02,  8.01s/it]                                                         {'loss': 0.8853, 'learning_rate': 7.123345968644972e-06, 'epoch': 0.61}
 61%|██████    | 6290/10395 [17:59:25<9:08:02,  8.01s/it] 61%|██████    | 6291/10395 [17:59:32<9:00:43,  7.91s/it]                                                         {'loss': 0.9244, 'learning_rate': 7.120362075210232e-06, 'epoch': 0.61}
 61%|██████    | 6291/10395 [17:59:32<9:00:43,  7.91s/it] 61%|██████    | 6292/10395 [17:59:40<8:46:19,  7.70s/it]                                                         {'loss': 0.9453, 'learning_rate': 7.117378461324584e-06, 'epoch': 0.61}
 61%|██████    | 6292/10395 [17:59:40<8:46:19,  7.70s/it] 61%|██████    | 6293/10395 [17:59:48<8:54:48,  7.82s/it]                                                         {'loss': 0.8972, 'learning_rate': 7.114395127277676e-06, 'epoch': 0.61}
 61%|██████    | 6293/10395 [17:59:48<8:54:48,  7.82s/it] 61%|██████    | 6294/10395 [17:59:55<8:46:16,  7.70s/it]                                                         {'loss': 0.8634, 'learning_rate': 7.111412073359121e-06, 'epoch': 0.61}
 61%|██████    | 6294/10395 [17:59:55<8:46:16,  7.70s/it] 61%|██████    | 6295/10395 [18:00:03<8:49:54,  7.75s/it]                                                         {'loss': 0.823, 'learning_rate': 7.108429299858508e-06, 'epoch': 0.61}
 61%|██████    | 6295/10395 [18:00:03<8:49:54,  7.75s/it] 61%|██████    | 6296/10395 [18:00:10<8:40:28,  7.62s/it]                                                         {'loss': 0.9157, 'learning_rate': 7.105446807065402e-06, 'epoch': 0.61}
 61%|██████    | 6296/10395 [18:00:10<8:40:28,  7.62s/it] 61%|██████    | 6297/10395 [18:00:18<8:34:51,  7.54s/it]                                                         {'loss': 1.0301, 'learning_rate': 7.1024645952693325e-06, 'epoch': 0.61}
 61%|██████    | 6297/10395 [18:00:18<8:34:51,  7.54s/it] 61%|██████    | 6298/10395 [18:00:26<8:49:19,  7.75s/it]                                                         {'loss': 0.8735, 'learning_rate': 7.099482664759812e-06, 'epoch': 0.61}
 61%|██████    | 6298/10395 [18:00:26<8:49:19,  7.75s/it] 61%|██████    | 6299/10395 [18:00:33<8:42:28,  7.65s/it]                                                         {'loss': 0.8608, 'learning_rate': 7.0965010158263125e-06, 'epoch': 0.61}
 61%|██████    | 6299/10395 [18:00:33<8:42:28,  7.65s/it] 61%|██████    | 6300/10395 [18:00:41<8:52:51,  7.81s/it]                                                         {'loss': 0.9123, 'learning_rate': 7.09351964875829e-06, 'epoch': 0.61}
 61%|██████    | 6300/10395 [18:00:41<8:52:51,  7.81s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 61%|██████    | 6301/10395 [18:02:21<40:12:14, 35.35s/it]                                                          {'loss': 0.9035, 'learning_rate': 7.090538563845168e-06, 'epoch': 0.61}
 61%|██████    | 6301/10395 [18:02:21<40:12:14, 35.35s/it] 61%|██████    | 6302/10395 [18:02:29<30:52:20, 27.15s/it]                                                          {'loss': 0.9421, 'learning_rate': 7.087557761376347e-06, 'epoch': 0.61}
 61%|██████    | 6302/10395 [18:02:29<30:52:20, 27.15s/it] 61%|██████    | 6303/10395 [18:02:36<24:08:08, 21.23s/it]                                                          {'loss': 0.8579, 'learning_rate': 7.084577241641191e-06, 'epoch': 0.61}
 61%|██████    | 6303/10395 [18:02:36<24:08:08, 21.23s/it] 61%|██████    | 6304/10395 [18:02:54<22:54:17, 20.16s/it]                                                          {'loss': 0.3584, 'learning_rate': 7.081597004929048e-06, 'epoch': 0.61}
 61%|██████    | 6304/10395 [18:02:54<22:54:17, 20.16s/it] 61%|██████    | 6305/10395 [18:03:01<18:28:39, 16.26s/it]                                                          {'loss': 0.924, 'learning_rate': 7.078617051529232e-06, 'epoch': 0.61}
 61%|██████    | 6305/10395 [18:03:01<18:28:39, 16.26s/it] 61%|██████    | 6306/10395 [18:03:09<15:31:17, 13.67s/it]                                                          {'loss': 0.9217, 'learning_rate': 7.0756373817310306e-06, 'epoch': 0.61}
 61%|██████    | 6306/10395 [18:03:09<15:31:17, 13.67s/it] 61%|██████    | 6307/10395 [18:03:17<13:35:09, 11.96s/it]                                                          {'loss': 0.9163, 'learning_rate': 7.072657995823702e-06, 'epoch': 0.61}
 61%|██████    | 6307/10395 [18:03:17<13:35:09, 11.96s/it] 61%|██████    | 6308/10395 [18:03:25<12:21:50, 10.89s/it]                                                          {'loss': 0.9211, 'learning_rate': 7.069678894096479e-06, 'epoch': 0.61}
 61%|██████    | 6308/10395 [18:03:25<12:21:50, 10.89s/it] 61%|██████    | 6309/10395 [18:03:33<11:09:48,  9.84s/it]                                                          {'loss': 0.9116, 'learning_rate': 7.066700076838566e-06, 'epoch': 0.61}
 61%|██████    | 6309/10395 [18:03:33<11:09:48,  9.84s/it] 61%|██████    | 6310/10395 [18:03:42<10:55:17,  9.62s/it]                                                          {'loss': 0.7823, 'learning_rate': 7.063721544339142e-06, 'epoch': 0.61}
 61%|██████    | 6310/10395 [18:03:42<10:55:17,  9.62s/it] 61%|██████    | 6311/10395 [18:03:49<10:13:13,  9.01s/it]                                                          {'loss': 1.0043, 'learning_rate': 7.060743296887352e-06, 'epoch': 0.61}
 61%|██████    | 6311/10395 [18:03:49<10:13:13,  9.01s/it] 61%|██████    | 6312/10395 [18:03:58<10:06:17,  8.91s/it]                                                          {'loss': 0.9045, 'learning_rate': 7.057765334772325e-06, 'epoch': 0.61}
 61%|██████    | 6312/10395 [18:03:58<10:06:17,  8.91s/it] 61%|██████    | 6313/10395 [18:04:06<9:41:41,  8.55s/it]                                                          {'loss': 0.7931, 'learning_rate': 7.054787658283155e-06, 'epoch': 0.61}
 61%|██████    | 6313/10395 [18:04:06<9:41:41,  8.55s/it] 61%|██████    | 6314/10395 [18:04:14<9:32:48,  8.42s/it]                                                         {'loss': 0.9248, 'learning_rate': 7.0518102677089006e-06, 'epoch': 0.61}
 61%|██████    | 6314/10395 [18:04:14<9:32:48,  8.42s/it] 61%|██████    | 6315/10395 [18:04:21<9:08:26,  8.07s/it]                                                         {'loss': 0.9132, 'learning_rate': 7.048833163338607e-06, 'epoch': 0.61}
 61%|██████    | 6315/10395 [18:04:21<9:08:26,  8.07s/it] 61%|██████    | 6316/10395 [18:04:29<8:58:37,  7.92s/it]                                                         {'loss': 0.9037, 'learning_rate': 7.0458563454612815e-06, 'epoch': 0.61}
 61%|██████    | 6316/10395 [18:04:29<8:58:37,  7.92s/it] 61%|██████    | 6317/10395 [18:04:36<8:46:30,  7.75s/it]                                                         {'loss': 0.8994, 'learning_rate': 7.0428798143659095e-06, 'epoch': 0.61}
 61%|██████    | 6317/10395 [18:04:36<8:46:30,  7.75s/it] 61%|██████    | 6318/10395 [18:04:43<8:40:38,  7.66s/it]                                                         {'loss': 0.8392, 'learning_rate': 7.039903570341447e-06, 'epoch': 0.61}
 61%|██████    | 6318/10395 [18:04:43<8:40:38,  7.66s/it] 61%|██████    | 6319/10395 [18:04:53<9:20:44,  8.25s/it]                                                         {'loss': 0.8924, 'learning_rate': 7.036927613676816e-06, 'epoch': 0.61}
 61%|██████    | 6319/10395 [18:04:53<9:20:44,  8.25s/it] 61%|██████    | 6320/10395 [18:05:11<12:39:16, 11.18s/it]                                                          {'loss': 0.3634, 'learning_rate': 7.033951944660928e-06, 'epoch': 0.61}
 61%|██████    | 6320/10395 [18:05:11<12:39:16, 11.18s/it] 61%|██████    | 6321/10395 [18:05:19<11:35:06, 10.24s/it]                                                          {'loss': 0.8248, 'learning_rate': 7.03097656358264e-06, 'epoch': 0.61}
 61%|██████    | 6321/10395 [18:05:19<11:35:06, 10.24s/it] 61%|██████    | 6322/10395 [18:05:26<10:31:26,  9.30s/it]                                                          {'loss': 0.9768, 'learning_rate': 7.028001470730804e-06, 'epoch': 0.61}
 61%|██████    | 6322/10395 [18:05:26<10:31:26,  9.30s/it] 61%|██████    | 6323/10395 [18:05:34<10:06:06,  8.93s/it]                                                          {'loss': 0.8117, 'learning_rate': 7.025026666394235e-06, 'epoch': 0.61}
 61%|██████    | 6323/10395 [18:05:34<10:06:06,  8.93s/it] 61%|██████    | 6324/10395 [18:05:42<9:32:54,  8.44s/it]                                                          {'loss': 0.9327, 'learning_rate': 7.022052150861719e-06, 'epoch': 0.61}
 61%|██████    | 6324/10395 [18:05:42<9:32:54,  8.44s/it] 61%|██████    | 6325/10395 [18:05:49<9:17:32,  8.22s/it]                                                         {'loss': 0.8466, 'learning_rate': 7.0190779244220175e-06, 'epoch': 0.61}
 61%|██████    | 6325/10395 [18:05:49<9:17:32,  8.22s/it] 61%|██████    | 6326/10395 [18:05:57<9:11:54,  8.14s/it]                                                         {'loss': 0.8728, 'learning_rate': 7.016103987363857e-06, 'epoch': 0.61}
 61%|██████    | 6326/10395 [18:05:57<9:11:54,  8.14s/it] 61%|██████    | 6327/10395 [18:06:05<9:02:06,  8.00s/it]                                                         {'loss': 0.8927, 'learning_rate': 7.013130339975948e-06, 'epoch': 0.61}
 61%|██████    | 6327/10395 [18:06:05<9:02:06,  8.00s/it] 61%|██████    | 6328/10395 [18:06:13<9:03:23,  8.02s/it]                                                         {'loss': 0.8226, 'learning_rate': 7.010156982546966e-06, 'epoch': 0.61}
 61%|██████    | 6328/10395 [18:06:13<9:03:23,  8.02s/it] 61%|██████    | 6329/10395 [18:06:21<8:54:27,  7.89s/it]                                                         {'loss': 0.8803, 'learning_rate': 7.0071839153655496e-06, 'epoch': 0.61}
 61%|██████    | 6329/10395 [18:06:21<8:54:27,  7.89s/it] 61%|██████    | 6330/10395 [18:06:30<9:18:35,  8.24s/it]                                                         {'loss': 0.8464, 'learning_rate': 7.004211138720325e-06, 'epoch': 0.61}
 61%|██████    | 6330/10395 [18:06:30<9:18:35,  8.24s/it] 61%|██████    | 6331/10395 [18:06:37<9:06:24,  8.07s/it]                                                         {'loss': 0.838, 'learning_rate': 7.00123865289988e-06, 'epoch': 0.61}
 61%|██████    | 6331/10395 [18:06:37<9:06:24,  8.07s/it] 61%|██████    | 6332/10395 [18:06:46<9:14:56,  8.20s/it]                                                         {'loss': 0.7939, 'learning_rate': 6.998266458192778e-06, 'epoch': 0.61}
 61%|██████    | 6332/10395 [18:06:46<9:14:56,  8.20s/it] 61%|██████    | 6333/10395 [18:06:54<9:17:16,  8.23s/it]                                                         {'loss': 0.9059, 'learning_rate': 6.995294554887555e-06, 'epoch': 0.61}
 61%|██████    | 6333/10395 [18:06:54<9:17:16,  8.23s/it] 61%|██████    | 6334/10395 [18:07:02<9:06:57,  8.08s/it]                                                         {'loss': 0.9224, 'learning_rate': 6.992322943272712e-06, 'epoch': 0.61}
 61%|██████    | 6334/10395 [18:07:02<9:06:57,  8.08s/it] 61%|██████    | 6335/10395 [18:07:09<8:48:30,  7.81s/it]                                                         {'loss': 0.8612, 'learning_rate': 6.9893516236367374e-06, 'epoch': 0.61}
 61%|██████    | 6335/10395 [18:07:09<8:48:30,  7.81s/it] 61%|██████    | 6336/10395 [18:07:16<8:38:49,  7.67s/it]                                                         {'loss': 0.8333, 'learning_rate': 6.98638059626807e-06, 'epoch': 0.61}
 61%|██████    | 6336/10395 [18:07:16<8:38:49,  7.67s/it] 61%|██████    | 6337/10395 [18:07:25<9:02:46,  8.03s/it]                                                         {'loss': 0.8874, 'learning_rate': 6.98340986145513e-06, 'epoch': 0.61}
 61%|██████    | 6337/10395 [18:07:25<9:02:46,  8.03s/it] 61%|██████    | 6338/10395 [18:07:33<8:50:26,  7.84s/it]                                                         {'loss': 0.9261, 'learning_rate': 6.980439419486318e-06, 'epoch': 0.61}
 61%|██████    | 6338/10395 [18:07:33<8:50:26,  7.84s/it] 61%|██████    | 6339/10395 [18:07:40<8:48:02,  7.81s/it]                                                         {'loss': 0.8862, 'learning_rate': 6.977469270649995e-06, 'epoch': 0.61}
 61%|██████    | 6339/10395 [18:07:40<8:48:02,  7.81s/it] 61%|██████    | 6340/10395 [18:07:48<8:38:50,  7.68s/it]                                                         {'loss': 0.8305, 'learning_rate': 6.9744994152344934e-06, 'epoch': 0.61}
 61%|██████    | 6340/10395 [18:07:48<8:38:50,  7.68s/it] 61%|██████    | 6341/10395 [18:07:55<8:21:21,  7.42s/it]                                                         {'loss': 0.9321, 'learning_rate': 6.971529853528125e-06, 'epoch': 0.61}
 61%|██████    | 6341/10395 [18:07:55<8:21:21,  7.42s/it] 61%|██████    | 6342/10395 [18:08:04<8:59:55,  7.99s/it]                                                         {'loss': 0.9278, 'learning_rate': 6.968560585819168e-06, 'epoch': 0.61}
 61%|██████    | 6342/10395 [18:08:04<8:59:55,  7.99s/it] 61%|██████    | 6343/10395 [18:08:11<8:49:16,  7.84s/it]                                                         {'loss': 0.8782, 'learning_rate': 6.965591612395869e-06, 'epoch': 0.61}
 61%|██████    | 6343/10395 [18:08:11<8:49:16,  7.84s/it] 61%|██████    | 6344/10395 [18:08:19<8:35:23,  7.63s/it]                                                         {'loss': 0.9673, 'learning_rate': 6.962622933546452e-06, 'epoch': 0.61}
 61%|██████    | 6344/10395 [18:08:19<8:35:23,  7.63s/it] 61%|██████    | 6345/10395 [18:08:26<8:31:32,  7.58s/it]                                                         {'loss': 0.8585, 'learning_rate': 6.959654549559108e-06, 'epoch': 0.61}
 61%|██████    | 6345/10395 [18:08:26<8:31:32,  7.58s/it] 61%|██████    | 6346/10395 [18:08:44<12:00:19, 10.67s/it]                                                          {'loss': 0.3734, 'learning_rate': 6.956686460722004e-06, 'epoch': 0.61}
 61%|██████    | 6346/10395 [18:08:44<12:00:19, 10.67s/it] 61%|██████    | 6347/10395 [18:08:51<10:46:57,  9.59s/it]                                                          {'loss': 0.9495, 'learning_rate': 6.9537186673232744e-06, 'epoch': 0.61}
 61%|██████    | 6347/10395 [18:08:51<10:46:57,  9.59s/it] 61%|██████    | 6348/10395 [18:08:58<10:00:35,  8.90s/it]                                                          {'loss': 1.0183, 'learning_rate': 6.9507511696510285e-06, 'epoch': 0.61}
 61%|██████    | 6348/10395 [18:08:58<10:00:35,  8.90s/it] 61%|██████    | 6349/10395 [18:09:08<10:09:14,  9.03s/it]                                                          {'loss': 0.9468, 'learning_rate': 6.947783967993342e-06, 'epoch': 0.61}
 61%|██████    | 6349/10395 [18:09:08<10:09:14,  9.03s/it] 61%|██████    | 6350/10395 [18:09:16<9:47:41,  8.72s/it]                                                          {'loss': 0.8247, 'learning_rate': 6.9448170626382675e-06, 'epoch': 0.61}
 61%|██████    | 6350/10395 [18:09:16<9:47:41,  8.72s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 61%|██████    | 6351/10395 [18:10:54<40:02:50, 35.65s/it]                                                          {'loss': 0.8947, 'learning_rate': 6.941850453873822e-06, 'epoch': 0.61}
 61%|██████    | 6351/10395 [18:10:54<40:02:50, 35.65s/it] 61%|██████    | 6352/10395 [18:11:11<33:37:44, 29.94s/it]                                                          {'loss': 0.4278, 'learning_rate': 6.938884141987996e-06, 'epoch': 0.61}
 61%|██████    | 6352/10395 [18:11:11<33:37:44, 29.94s/it] 61%|██████    | 6353/10395 [18:11:18<26:07:55, 23.27s/it]                                                          {'loss': 0.8027, 'learning_rate': 6.9359181272687595e-06, 'epoch': 0.61}
 61%|██████    | 6353/10395 [18:11:18<26:07:55, 23.27s/it] 61%|██████    | 6354/10395 [18:11:26<20:42:39, 18.45s/it]                                                          {'loss': 0.9282, 'learning_rate': 6.9329524100040415e-06, 'epoch': 0.61}
 61%|██████    | 6354/10395 [18:11:26<20:42:39, 18.45s/it] 61%|██████    | 6355/10395 [18:11:33<16:56:12, 15.09s/it]                                                          {'loss': 0.8629, 'learning_rate': 6.929986990481749e-06, 'epoch': 0.61}
 61%|██████    | 6355/10395 [18:11:33<16:56:12, 15.09s/it] 61%|██████    | 6356/10395 [18:11:40<14:18:10, 12.75s/it]                                                          {'loss': 0.995, 'learning_rate': 6.927021868989761e-06, 'epoch': 0.61}
 61%|██████    | 6356/10395 [18:11:40<14:18:10, 12.75s/it] 61%|██████    | 6357/10395 [18:11:48<12:33:49, 11.20s/it]                                                          {'loss': 0.9068, 'learning_rate': 6.9240570458159225e-06, 'epoch': 0.61}
 61%|██████    | 6357/10395 [18:11:48<12:33:49, 11.20s/it] 61%|██████    | 6358/10395 [18:11:55<11:17:44, 10.07s/it]                                                          {'loss': 0.8578, 'learning_rate': 6.921092521248052e-06, 'epoch': 0.61}
 61%|██████    | 6358/10395 [18:11:55<11:17:44, 10.07s/it] 61%|██████    | 6359/10395 [18:12:03<10:30:56,  9.38s/it]                                                          {'loss': 0.8285, 'learning_rate': 6.918128295573941e-06, 'epoch': 0.61}
 61%|██████    | 6359/10395 [18:12:03<10:30:56,  9.38s/it] 61%|██████    | 6360/10395 [18:12:10<9:51:14,  8.79s/it]                                                          {'loss': 0.9439, 'learning_rate': 6.915164369081344e-06, 'epoch': 0.61}
 61%|██████    | 6360/10395 [18:12:10<9:51:14,  8.79s/it] 61%|██████    | 6361/10395 [18:12:20<10:04:59,  9.00s/it]                                                          {'loss': 0.8712, 'learning_rate': 6.9122007420580014e-06, 'epoch': 0.61}
 61%|██████    | 6361/10395 [18:12:20<10:04:59,  9.00s/it] 61%|██████    | 6362/10395 [18:12:28<9:37:42,  8.59s/it]                                                          {'loss': 0.8081, 'learning_rate': 6.909237414791614e-06, 'epoch': 0.61}
 61%|██████    | 6362/10395 [18:12:28<9:37:42,  8.59s/it] 61%|██████    | 6363/10395 [18:12:45<12:39:22, 11.30s/it]                                                          {'loss': 0.3488, 'learning_rate': 6.906274387569851e-06, 'epoch': 0.61}
 61%|██████    | 6363/10395 [18:12:45<12:39:22, 11.30s/it] 61%|██████    | 6364/10395 [18:12:53<11:22:42, 10.16s/it]                                                          {'loss': 0.9126, 'learning_rate': 6.90331166068036e-06, 'epoch': 0.61}
 61%|██████    | 6364/10395 [18:12:53<11:22:42, 10.16s/it] 61%|██████    | 6365/10395 [18:13:00<10:31:46,  9.41s/it]                                                          {'loss': 0.8223, 'learning_rate': 6.900349234410757e-06, 'epoch': 0.61}
 61%|██████    | 6365/10395 [18:13:00<10:31:46,  9.41s/it] 61%|██████    | 6366/10395 [18:13:08<9:53:57,  8.85s/it]                                                          {'loss': 0.9145, 'learning_rate': 6.897387109048625e-06, 'epoch': 0.61}
 61%|██████    | 6366/10395 [18:13:08<9:53:57,  8.85s/it] 61%|██████▏   | 6367/10395 [18:13:16<9:45:08,  8.72s/it]                                                         {'loss': 0.9107, 'learning_rate': 6.894425284881521e-06, 'epoch': 0.61}
 61%|██████▏   | 6367/10395 [18:13:16<9:45:08,  8.72s/it] 61%|██████▏   | 6368/10395 [18:13:24<9:19:51,  8.34s/it]                                                         {'loss': 0.8531, 'learning_rate': 6.891463762196973e-06, 'epoch': 0.61}
 61%|██████▏   | 6368/10395 [18:13:24<9:19:51,  8.34s/it] 61%|██████▏   | 6369/10395 [18:13:32<9:09:39,  8.19s/it]                                                         {'loss': 0.8845, 'learning_rate': 6.88850254128248e-06, 'epoch': 0.61}
 61%|██████▏   | 6369/10395 [18:13:32<9:09:39,  8.19s/it] 61%|██████▏   | 6370/10395 [18:13:39<8:51:39,  7.93s/it]                                                         {'loss': 0.8378, 'learning_rate': 6.885541622425514e-06, 'epoch': 0.61}
 61%|██████▏   | 6370/10395 [18:13:39<8:51:39,  7.93s/it] 61%|██████▏   | 6371/10395 [18:13:47<8:53:18,  7.95s/it]                                                         {'loss': 0.9208, 'learning_rate': 6.882581005913509e-06, 'epoch': 0.61}
 61%|██████▏   | 6371/10395 [18:13:47<8:53:18,  7.95s/it] 61%|██████▏   | 6372/10395 [18:13:56<9:07:08,  8.16s/it]                                                         {'loss': 0.8489, 'learning_rate': 6.879620692033882e-06, 'epoch': 0.61}
 61%|██████▏   | 6372/10395 [18:13:56<9:07:08,  8.16s/it] 61%|██████▏   | 6373/10395 [18:14:03<8:58:43,  8.04s/it]                                                         {'loss': 0.9252, 'learning_rate': 6.876660681074007e-06, 'epoch': 0.61}
 61%|██████▏   | 6373/10395 [18:14:03<8:58:43,  8.04s/it] 61%|██████▏   | 6374/10395 [18:14:11<8:46:46,  7.86s/it]                                                         {'loss': 0.8249, 'learning_rate': 6.873700973321238e-06, 'epoch': 0.61}
 61%|██████▏   | 6374/10395 [18:14:11<8:46:46,  7.86s/it] 61%|██████▏   | 6375/10395 [18:14:18<8:42:06,  7.79s/it]                                                         {'loss': 0.8527, 'learning_rate': 6.870741569062898e-06, 'epoch': 0.61}
 61%|██████▏   | 6375/10395 [18:14:18<8:42:06,  7.79s/it] 61%|██████▏   | 6376/10395 [18:14:26<8:36:13,  7.71s/it]                                                         {'loss': 0.8697, 'learning_rate': 6.867782468586277e-06, 'epoch': 0.61}
 61%|██████▏   | 6376/10395 [18:14:26<8:36:13,  7.71s/it] 61%|██████▏   | 6377/10395 [18:14:34<8:36:56,  7.72s/it]                                                         {'loss': 0.9371, 'learning_rate': 6.864823672178642e-06, 'epoch': 0.61}
 61%|██████▏   | 6377/10395 [18:14:34<8:36:56,  7.72s/it] 61%|██████▏   | 6378/10395 [18:14:41<8:34:21,  7.68s/it]                                                         {'loss': 0.8988, 'learning_rate': 6.861865180127226e-06, 'epoch': 0.61}
 61%|██████▏   | 6378/10395 [18:14:41<8:34:21,  7.68s/it] 61%|██████▏   | 6379/10395 [18:14:50<8:53:41,  7.97s/it]                                                         {'loss': 0.8893, 'learning_rate': 6.858906992719234e-06, 'epoch': 0.61}
 61%|██████▏   | 6379/10395 [18:14:50<8:53:41,  7.97s/it] 61%|██████▏   | 6380/10395 [18:14:58<8:48:01,  7.89s/it]                                                         {'loss': 0.9966, 'learning_rate': 6.8559491102418376e-06, 'epoch': 0.61}
 61%|██████▏   | 6380/10395 [18:14:58<8:48:01,  7.89s/it] 61%|██████▏   | 6381/10395 [18:15:05<8:40:16,  7.78s/it]                                                         {'loss': 0.8803, 'learning_rate': 6.852991532982181e-06, 'epoch': 0.61}
 61%|██████▏   | 6381/10395 [18:15:05<8:40:16,  7.78s/it] 61%|██████▏   | 6382/10395 [18:15:13<8:40:47,  7.79s/it]                                                         {'loss': 0.8662, 'learning_rate': 6.850034261227381e-06, 'epoch': 0.61}
 61%|██████▏   | 6382/10395 [18:15:13<8:40:47,  7.79s/it] 61%|██████▏   | 6383/10395 [18:15:22<9:10:24,  8.23s/it]                                                         {'loss': 0.754, 'learning_rate': 6.847077295264524e-06, 'epoch': 0.61}
 61%|██████▏   | 6383/10395 [18:15:22<9:10:24,  8.23s/it] 61%|██████▏   | 6384/10395 [18:15:39<12:09:23, 10.91s/it]                                                          {'loss': 0.3648, 'learning_rate': 6.844120635380664e-06, 'epoch': 0.61}
 61%|██████▏   | 6384/10395 [18:15:39<12:09:23, 10.91s/it] 61%|██████▏   | 6385/10395 [18:15:47<11:08:20, 10.00s/it]                                                          {'loss': 0.9495, 'learning_rate': 6.84116428186283e-06, 'epoch': 0.61}
 61%|██████▏   | 6385/10395 [18:15:47<11:08:20, 10.00s/it] 61%|██████▏   | 6386/10395 [18:15:55<10:17:26,  9.24s/it]                                                          {'loss': 0.9284, 'learning_rate': 6.838208234998016e-06, 'epoch': 0.61}
 61%|██████▏   | 6386/10395 [18:15:55<10:17:26,  9.24s/it] 61%|██████▏   | 6387/10395 [18:16:03<9:53:22,  8.88s/it]                                                          {'loss': 0.8833, 'learning_rate': 6.835252495073194e-06, 'epoch': 0.61}
 61%|██████▏   | 6387/10395 [18:16:03<9:53:22,  8.88s/it] 61%|██████▏   | 6388/10395 [18:16:11<9:46:01,  8.78s/it]                                                         {'loss': 0.863, 'learning_rate': 6.832297062375293e-06, 'epoch': 0.61}
 61%|██████▏   | 6388/10395 [18:16:11<9:46:01,  8.78s/it] 61%|██████▏   | 6389/10395 [18:16:19<9:35:23,  8.62s/it]                                                         {'loss': 0.909, 'learning_rate': 6.829341937191225e-06, 'epoch': 0.61}
 61%|██████▏   | 6389/10395 [18:16:19<9:35:23,  8.62s/it] 61%|██████▏   | 6390/10395 [18:16:28<9:35:41,  8.62s/it]                                                         {'loss': 0.7426, 'learning_rate': 6.826387119807864e-06, 'epoch': 0.61}
 61%|██████▏   | 6390/10395 [18:16:28<9:35:41,  8.62s/it] 61%|██████▏   | 6391/10395 [18:16:35<8:59:49,  8.09s/it]                                                         {'loss': 0.9615, 'learning_rate': 6.8234326105120595e-06, 'epoch': 0.61}
 61%|██████▏   | 6391/10395 [18:16:35<8:59:49,  8.09s/it] 61%|██████▏   | 6392/10395 [18:16:43<9:00:52,  8.11s/it]                                                         {'loss': 0.9398, 'learning_rate': 6.820478409590631e-06, 'epoch': 0.61}
 61%|██████▏   | 6392/10395 [18:16:43<9:00:52,  8.11s/it] 62%|██████▏   | 6393/10395 [18:16:51<9:03:49,  8.15s/it]                                                         {'loss': 0.8395, 'learning_rate': 6.817524517330363e-06, 'epoch': 0.61}
 62%|██████▏   | 6393/10395 [18:16:51<9:03:49,  8.15s/it] 62%|██████▏   | 6394/10395 [18:16:59<8:55:29,  8.03s/it]                                                         {'loss': 0.9018, 'learning_rate': 6.814570934018015e-06, 'epoch': 0.62}
 62%|██████▏   | 6394/10395 [18:16:59<8:55:29,  8.03s/it] 62%|██████▏   | 6395/10395 [18:17:08<9:05:26,  8.18s/it]                                                         {'loss': 0.8446, 'learning_rate': 6.811617659940312e-06, 'epoch': 0.62}
 62%|██████▏   | 6395/10395 [18:17:08<9:05:26,  8.18s/it] 62%|██████▏   | 6396/10395 [18:17:15<8:56:12,  8.05s/it]                                                         {'loss': 0.8902, 'learning_rate': 6.808664695383953e-06, 'epoch': 0.62}
 62%|██████▏   | 6396/10395 [18:17:15<8:56:12,  8.05s/it] 62%|██████▏   | 6397/10395 [18:17:23<8:52:19,  7.99s/it]                                                         {'loss': 0.7804, 'learning_rate': 6.805712040635606e-06, 'epoch': 0.62}
 62%|██████▏   | 6397/10395 [18:17:23<8:52:19,  7.99s/it] 62%|██████▏   | 6398/10395 [18:17:31<8:49:44,  7.95s/it]                                                         {'loss': 0.9555, 'learning_rate': 6.802759695981909e-06, 'epoch': 0.62}
 62%|██████▏   | 6398/10395 [18:17:31<8:49:44,  7.95s/it] 62%|██████▏   | 6399/10395 [18:17:38<8:37:55,  7.78s/it]                                                         {'loss': 0.8979, 'learning_rate': 6.799807661709463e-06, 'epoch': 0.62}
 62%|██████▏   | 6399/10395 [18:17:38<8:37:55,  7.78s/it] 62%|██████▏   | 6400/10395 [18:17:46<8:41:57,  7.84s/it]                                                         {'loss': 0.8486, 'learning_rate': 6.796855938104855e-06, 'epoch': 0.62}
 62%|██████▏   | 6400/10395 [18:17:46<8:41:57,  7.84s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 62%|██████▏   | 6401/10395 [18:19:26<39:05:37, 35.24s/it]                                                          {'loss': 0.8453, 'learning_rate': 6.793904525454631e-06, 'epoch': 0.62}
 62%|██████▏   | 6401/10395 [18:19:26<39:05:37, 35.24s/it] 62%|██████▏   | 6402/10395 [18:19:33<29:55:15, 26.98s/it]                                                          {'loss': 0.8605, 'learning_rate': 6.790953424045297e-06, 'epoch': 0.62}
 62%|██████▏   | 6402/10395 [18:19:33<29:55:15, 26.98s/it] 62%|██████▏   | 6403/10395 [18:19:41<23:22:39, 21.08s/it]                                                          {'loss': 0.959, 'learning_rate': 6.7880026341633495e-06, 'epoch': 0.62}
 62%|██████▏   | 6403/10395 [18:19:41<23:22:39, 21.08s/it] 62%|██████▏   | 6404/10395 [18:19:48<18:57:50, 17.11s/it]                                                          {'loss': 0.8624, 'learning_rate': 6.785052156095242e-06, 'epoch': 0.62}
 62%|██████▏   | 6404/10395 [18:19:48<18:57:50, 17.11s/it] 62%|██████▏   | 6405/10395 [18:19:56<15:43:40, 14.19s/it]                                                          {'loss': 0.8625, 'learning_rate': 6.782101990127401e-06, 'epoch': 0.62}
 62%|██████▏   | 6405/10395 [18:19:56<15:43:40, 14.19s/it] 62%|██████▏   | 6406/10395 [18:20:04<13:40:30, 12.34s/it]                                                          {'loss': 0.8984, 'learning_rate': 6.779152136546223e-06, 'epoch': 0.62}
 62%|██████▏   | 6406/10395 [18:20:04<13:40:30, 12.34s/it] 62%|██████▏   | 6407/10395 [18:20:11<12:06:01, 10.92s/it]                                                          {'loss': 0.8922, 'learning_rate': 6.77620259563807e-06, 'epoch': 0.62}
 62%|██████▏   | 6407/10395 [18:20:11<12:06:01, 10.92s/it] 62%|██████▏   | 6408/10395 [18:20:19<10:56:58,  9.89s/it]                                                          {'loss': 0.9633, 'learning_rate': 6.773253367689281e-06, 'epoch': 0.62}
 62%|██████▏   | 6408/10395 [18:20:19<10:56:58,  9.89s/it] 62%|██████▏   | 6409/10395 [18:20:38<13:57:29, 12.61s/it]                                                          {'loss': 0.4345, 'learning_rate': 6.770304452986164e-06, 'epoch': 0.62}
 62%|██████▏   | 6409/10395 [18:20:38<13:57:29, 12.61s/it] 62%|██████▏   | 6410/10395 [18:20:45<12:13:06, 11.04s/it]                                                          {'loss': 0.9063, 'learning_rate': 6.767355851814983e-06, 'epoch': 0.62}
 62%|██████▏   | 6410/10395 [18:20:45<12:13:06, 11.04s/it] 62%|██████▏   | 6411/10395 [18:20:53<11:03:25,  9.99s/it]                                                          {'loss': 0.879, 'learning_rate': 6.76440756446199e-06, 'epoch': 0.62}
 62%|██████▏   | 6411/10395 [18:20:53<11:03:25,  9.99s/it] 62%|██████▏   | 6412/10395 [18:21:01<10:25:45,  9.43s/it]                                                          {'loss': 0.8603, 'learning_rate': 6.761459591213395e-06, 'epoch': 0.62}
 62%|██████▏   | 6412/10395 [18:21:01<10:25:45,  9.43s/it] 62%|██████▏   | 6413/10395 [18:21:09<9:54:52,  8.96s/it]                                                          {'loss': 0.88, 'learning_rate': 6.758511932355383e-06, 'epoch': 0.62}
 62%|██████▏   | 6413/10395 [18:21:09<9:54:52,  8.96s/it] 62%|██████▏   | 6414/10395 [18:21:16<9:20:59,  8.46s/it]                                                         {'loss': 0.8388, 'learning_rate': 6.755564588174106e-06, 'epoch': 0.62}
 62%|██████▏   | 6414/10395 [18:21:16<9:20:59,  8.46s/it] 62%|██████▏   | 6415/10395 [18:21:24<9:01:40,  8.17s/it]                                                         {'loss': 1.016, 'learning_rate': 6.752617558955682e-06, 'epoch': 0.62}
 62%|██████▏   | 6415/10395 [18:21:24<9:01:40,  8.17s/it] 62%|██████▏   | 6416/10395 [18:21:31<8:45:42,  7.93s/it]                                                         {'loss': 0.9518, 'learning_rate': 6.749670844986214e-06, 'epoch': 0.62}
 62%|██████▏   | 6416/10395 [18:21:31<8:45:42,  7.93s/it] 62%|██████▏   | 6417/10395 [18:21:40<9:15:08,  8.37s/it]                                                         {'loss': 0.8455, 'learning_rate': 6.746724446551748e-06, 'epoch': 0.62}
 62%|██████▏   | 6417/10395 [18:21:40<9:15:08,  8.37s/it] 62%|██████▏   | 6418/10395 [18:21:49<9:17:04,  8.40s/it]                                                         {'loss': 0.8634, 'learning_rate': 6.743778363938318e-06, 'epoch': 0.62}
 62%|██████▏   | 6418/10395 [18:21:49<9:17:04,  8.40s/it] 62%|██████▏   | 6419/10395 [18:21:56<9:01:39,  8.17s/it]                                                         {'loss': 0.8878, 'learning_rate': 6.74083259743193e-06, 'epoch': 0.62}
 62%|██████▏   | 6419/10395 [18:21:56<9:01:39,  8.17s/it] 62%|██████▏   | 6420/10395 [18:22:05<9:11:16,  8.32s/it]                                                         {'loss': 0.8709, 'learning_rate': 6.737887147318548e-06, 'epoch': 0.62}
 62%|██████▏   | 6420/10395 [18:22:05<9:11:16,  8.32s/it] 62%|██████▏   | 6421/10395 [18:22:13<9:00:13,  8.16s/it]                                                         {'loss': 0.8632, 'learning_rate': 6.7349420138841105e-06, 'epoch': 0.62}
 62%|██████▏   | 6421/10395 [18:22:13<9:00:13,  8.16s/it] 62%|██████▏   | 6422/10395 [18:22:30<12:00:41, 10.88s/it]                                                          {'loss': 0.3878, 'learning_rate': 6.731997197414522e-06, 'epoch': 0.62}
 62%|██████▏   | 6422/10395 [18:22:30<12:00:41, 10.88s/it] 62%|██████▏   | 6423/10395 [18:22:38<10:51:24,  9.84s/it]                                                          {'loss': 0.931, 'learning_rate': 6.729052698195669e-06, 'epoch': 0.62}
 62%|██████▏   | 6423/10395 [18:22:38<10:51:24,  9.84s/it] 62%|██████▏   | 6424/10395 [18:22:45<10:01:44,  9.09s/it]                                                          {'loss': 0.8689, 'learning_rate': 6.726108516513386e-06, 'epoch': 0.62}
 62%|██████▏   | 6424/10395 [18:22:45<10:01:44,  9.09s/it] 62%|██████▏   | 6425/10395 [18:22:53<9:40:32,  8.77s/it]                                                          {'loss': 0.8583, 'learning_rate': 6.723164652653489e-06, 'epoch': 0.62}
 62%|██████▏   | 6425/10395 [18:22:53<9:40:32,  8.77s/it] 62%|██████▏   | 6426/10395 [18:23:00<9:12:43,  8.36s/it]                                                         {'loss': 0.8721, 'learning_rate': 6.720221106901768e-06, 'epoch': 0.62}
 62%|██████▏   | 6426/10395 [18:23:00<9:12:43,  8.36s/it] 62%|██████▏   | 6427/10395 [18:23:17<12:04:39, 10.96s/it]                                                          {'loss': 0.4097, 'learning_rate': 6.7172778795439704e-06, 'epoch': 0.62}
 62%|██████▏   | 6427/10395 [18:23:17<12:04:39, 10.96s/it] 62%|██████▏   | 6428/10395 [18:23:25<11:08:00, 10.10s/it]                                                          {'loss': 0.9246, 'learning_rate': 6.714334970865823e-06, 'epoch': 0.62}
 62%|██████▏   | 6428/10395 [18:23:25<11:08:00, 10.10s/it] 62%|██████▏   | 6429/10395 [18:23:34<10:31:59,  9.56s/it]                                                          {'loss': 0.8254, 'learning_rate': 6.7113923811530165e-06, 'epoch': 0.62}
 62%|██████▏   | 6429/10395 [18:23:34<10:31:59,  9.56s/it] 62%|██████▏   | 6430/10395 [18:23:42<9:56:51,  9.03s/it]                                                          {'loss': 0.8577, 'learning_rate': 6.708450110691206e-06, 'epoch': 0.62}
 62%|██████▏   | 6430/10395 [18:23:42<9:56:51,  9.03s/it] 62%|██████▏   | 6431/10395 [18:23:49<9:21:09,  8.49s/it]                                                         {'loss': 0.9206, 'learning_rate': 6.705508159766032e-06, 'epoch': 0.62}
 62%|██████▏   | 6431/10395 [18:23:49<9:21:09,  8.49s/it] 62%|██████▏   | 6432/10395 [18:23:56<9:01:18,  8.20s/it]                                                         {'loss': 0.8618, 'learning_rate': 6.70256652866308e-06, 'epoch': 0.62}
 62%|██████▏   | 6432/10395 [18:23:56<9:01:18,  8.20s/it] 62%|██████▏   | 6433/10395 [18:24:04<8:45:37,  7.96s/it]                                                         {'loss': 0.9287, 'learning_rate': 6.699625217667922e-06, 'epoch': 0.62}
 62%|██████▏   | 6433/10395 [18:24:04<8:45:37,  7.96s/it] 62%|██████▏   | 6434/10395 [18:24:10<8:20:34,  7.58s/it]                                                         {'loss': 0.9286, 'learning_rate': 6.696684227066096e-06, 'epoch': 0.62}
 62%|██████▏   | 6434/10395 [18:24:10<8:20:34,  7.58s/it] 62%|██████▏   | 6435/10395 [18:24:18<8:22:56,  7.62s/it]                                                         {'loss': 0.8398, 'learning_rate': 6.6937435571431065e-06, 'epoch': 0.62}
 62%|██████▏   | 6435/10395 [18:24:18<8:22:56,  7.62s/it] 62%|██████▏   | 6436/10395 [18:24:26<8:25:19,  7.66s/it]                                                         {'loss': 0.8137, 'learning_rate': 6.690803208184426e-06, 'epoch': 0.62}
 62%|██████▏   | 6436/10395 [18:24:26<8:25:19,  7.66s/it] 62%|██████▏   | 6437/10395 [18:24:34<8:41:16,  7.90s/it]                                                         {'loss': 0.8868, 'learning_rate': 6.6878631804755e-06, 'epoch': 0.62}
 62%|██████▏   | 6437/10395 [18:24:34<8:41:16,  7.90s/it] 62%|██████▏   | 6438/10395 [18:24:42<8:38:06,  7.86s/it]                                                         {'loss': 0.932, 'learning_rate': 6.684923474301739e-06, 'epoch': 0.62}
 62%|██████▏   | 6438/10395 [18:24:42<8:38:06,  7.86s/it] 62%|██████▏   | 6439/10395 [18:24:50<8:37:34,  7.85s/it]                                                         {'loss': 0.8999, 'learning_rate': 6.681984089948521e-06, 'epoch': 0.62}
 62%|██████▏   | 6439/10395 [18:24:50<8:37:34,  7.85s/it] 62%|██████▏   | 6440/10395 [18:24:57<8:25:54,  7.67s/it]                                                         {'loss': 0.8914, 'learning_rate': 6.679045027701198e-06, 'epoch': 0.62}
 62%|██████▏   | 6440/10395 [18:24:57<8:25:54,  7.67s/it] 62%|██████▏   | 6441/10395 [18:25:05<8:30:32,  7.75s/it]                                                         {'loss': 0.9525, 'learning_rate': 6.676106287845083e-06, 'epoch': 0.62}
 62%|██████▏   | 6441/10395 [18:25:05<8:30:32,  7.75s/it] 62%|██████▏   | 6442/10395 [18:25:14<8:52:55,  8.09s/it]                                                         {'loss': 0.8793, 'learning_rate': 6.67316787066547e-06, 'epoch': 0.62}
 62%|██████▏   | 6442/10395 [18:25:14<8:52:55,  8.09s/it] 62%|██████▏   | 6443/10395 [18:25:22<8:48:36,  8.03s/it]                                                         {'loss': 0.9127, 'learning_rate': 6.67022977644761e-06, 'epoch': 0.62}
 62%|██████▏   | 6443/10395 [18:25:22<8:48:36,  8.03s/it] 62%|██████▏   | 6444/10395 [18:25:29<8:37:37,  7.86s/it]                                                         {'loss': 0.921, 'learning_rate': 6.667292005476729e-06, 'epoch': 0.62}
 62%|██████▏   | 6444/10395 [18:25:29<8:37:37,  7.86s/it] 62%|██████▏   | 6445/10395 [18:25:37<8:33:39,  7.80s/it]                                                         {'loss': 0.9245, 'learning_rate': 6.664354558038017e-06, 'epoch': 0.62}
 62%|██████▏   | 6445/10395 [18:25:37<8:33:39,  7.80s/it] 62%|██████▏   | 6446/10395 [18:25:45<8:27:55,  7.72s/it]                                                         {'loss': 0.8866, 'learning_rate': 6.6614174344166375e-06, 'epoch': 0.62}
 62%|██████▏   | 6446/10395 [18:25:45<8:27:55,  7.72s/it] 62%|██████▏   | 6447/10395 [18:25:52<8:23:34,  7.65s/it]                                                         {'loss': 0.8438, 'learning_rate': 6.658480634897717e-06, 'epoch': 0.62}
 62%|██████▏   | 6447/10395 [18:25:52<8:23:34,  7.65s/it] 62%|██████▏   | 6448/10395 [18:26:00<8:34:51,  7.83s/it]                                                         {'loss': 0.8606, 'learning_rate': 6.655544159766356e-06, 'epoch': 0.62}
 62%|██████▏   | 6448/10395 [18:26:00<8:34:51,  7.83s/it] 62%|██████▏   | 6449/10395 [18:26:08<8:26:59,  7.71s/it]                                                         {'loss': 0.8363, 'learning_rate': 6.652608009307618e-06, 'epoch': 0.62}
 62%|██████▏   | 6449/10395 [18:26:08<8:26:59,  7.71s/it] 62%|██████▏   | 6450/10395 [18:26:15<8:23:08,  7.65s/it]                                                         {'loss': 0.9163, 'learning_rate': 6.6496721838065435e-06, 'epoch': 0.62}
 62%|██████▏   | 6450/10395 [18:26:15<8:23:08,  7.65s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 62%|██████▏   | 6451/10395 [18:27:55<38:35:22, 35.22s/it]                                                          {'loss': 0.9174, 'learning_rate': 6.646736683548134e-06, 'epoch': 0.62}
 62%|██████▏   | 6451/10395 [18:27:55<38:35:22, 35.22s/it] 62%|██████▏   | 6452/10395 [18:28:02<29:24:24, 26.85s/it]                                                          {'loss': 0.9351, 'learning_rate': 6.643801508817362e-06, 'epoch': 0.62}
 62%|██████▏   | 6452/10395 [18:28:02<29:24:24, 26.85s/it] 62%|██████▏   | 6453/10395 [18:28:10<23:05:25, 21.09s/it]                                                          {'loss': 0.9125, 'learning_rate': 6.640866659899169e-06, 'epoch': 0.62}
 62%|██████▏   | 6453/10395 [18:28:10<23:05:25, 21.09s/it] 62%|██████▏   | 6454/10395 [18:28:19<19:06:27, 17.45s/it]                                                          {'loss': 0.758, 'learning_rate': 6.63793213707846e-06, 'epoch': 0.62}
 62%|██████▏   | 6454/10395 [18:28:19<19:06:27, 17.45s/it] 62%|██████▏   | 6455/10395 [18:28:27<16:03:37, 14.67s/it]                                                          {'loss': 0.8679, 'learning_rate': 6.6349979406401135e-06, 'epoch': 0.62}
 62%|██████▏   | 6455/10395 [18:28:27<16:03:37, 14.67s/it] 62%|██████▏   | 6456/10395 [18:28:34<13:41:58, 12.52s/it]                                                          {'loss': 0.9363, 'learning_rate': 6.632064070868975e-06, 'epoch': 0.62}
 62%|██████▏   | 6456/10395 [18:28:34<13:41:58, 12.52s/it] 62%|██████▏   | 6457/10395 [18:28:42<12:07:35, 11.09s/it]                                                          {'loss': 0.8761, 'learning_rate': 6.629130528049861e-06, 'epoch': 0.62}
 62%|██████▏   | 6457/10395 [18:28:42<12:07:35, 11.09s/it] 62%|██████▏   | 6458/10395 [18:28:50<10:55:20,  9.99s/it]                                                          {'loss': 0.8877, 'learning_rate': 6.62619731246755e-06, 'epoch': 0.62}
 62%|██████▏   | 6458/10395 [18:28:50<10:55:20,  9.99s/it] 62%|██████▏   | 6459/10395 [18:28:57<10:02:00,  9.18s/it]                                                          {'loss': 0.9745, 'learning_rate': 6.623264424406796e-06, 'epoch': 0.62}
 62%|██████▏   | 6459/10395 [18:28:57<10:02:00,  9.18s/it] 62%|██████▏   | 6460/10395 [18:29:04<9:29:31,  8.68s/it]                                                          {'loss': 0.8421, 'learning_rate': 6.620331864152318e-06, 'epoch': 0.62}
 62%|██████▏   | 6460/10395 [18:29:04<9:29:31,  8.68s/it] 62%|██████▏   | 6461/10395 [18:29:12<9:14:29,  8.46s/it]                                                         {'loss': 0.9207, 'learning_rate': 6.617399631988797e-06, 'epoch': 0.62}
 62%|██████▏   | 6461/10395 [18:29:12<9:14:29,  8.46s/it] 62%|██████▏   | 6462/10395 [18:29:20<8:50:54,  8.10s/it]                                                         {'loss': 0.9081, 'learning_rate': 6.614467728200893e-06, 'epoch': 0.62}
 62%|██████▏   | 6462/10395 [18:29:20<8:50:54,  8.10s/it] 62%|██████▏   | 6463/10395 [18:29:28<8:53:07,  8.14s/it]                                                         {'loss': 0.8905, 'learning_rate': 6.611536153073225e-06, 'epoch': 0.62}
 62%|██████▏   | 6463/10395 [18:29:28<8:53:07,  8.14s/it] 62%|██████▏   | 6464/10395 [18:29:35<8:38:12,  7.91s/it]                                                         {'loss': 0.9106, 'learning_rate': 6.608604906890384e-06, 'epoch': 0.62}
 62%|██████▏   | 6464/10395 [18:29:35<8:38:12,  7.91s/it] 62%|██████▏   | 6465/10395 [18:29:43<8:38:24,  7.91s/it]                                                         {'loss': 0.9016, 'learning_rate': 6.605673989936934e-06, 'epoch': 0.62}
 62%|██████▏   | 6465/10395 [18:29:43<8:38:24,  7.91s/it] 62%|██████▏   | 6466/10395 [18:29:51<8:34:55,  7.86s/it]                                                         {'loss': 0.8832, 'learning_rate': 6.602743402497399e-06, 'epoch': 0.62}
 62%|██████▏   | 6466/10395 [18:29:51<8:34:55,  7.86s/it] 62%|██████▏   | 6467/10395 [18:29:58<8:25:21,  7.72s/it]                                                         {'loss': 0.8887, 'learning_rate': 6.599813144856278e-06, 'epoch': 0.62}
 62%|██████▏   | 6467/10395 [18:29:58<8:25:21,  7.72s/it] 62%|██████▏   | 6468/10395 [18:30:06<8:21:33,  7.66s/it]                                                         {'loss': 0.916, 'learning_rate': 6.596883217298027e-06, 'epoch': 0.62}
 62%|██████▏   | 6468/10395 [18:30:06<8:21:33,  7.66s/it] 62%|██████▏   | 6469/10395 [18:30:14<8:25:50,  7.73s/it]                                                         {'loss': 0.8532, 'learning_rate': 6.593953620107081e-06, 'epoch': 0.62}
 62%|██████▏   | 6469/10395 [18:30:14<8:25:50,  7.73s/it] 62%|██████▏   | 6470/10395 [18:30:23<9:02:08,  8.29s/it]                                                         {'loss': 0.8101, 'learning_rate': 6.591024353567839e-06, 'epoch': 0.62}
 62%|██████▏   | 6470/10395 [18:30:23<9:02:08,  8.29s/it] 62%|██████▏   | 6471/10395 [18:30:31<8:54:45,  8.18s/it]                                                         {'loss': 0.9558, 'learning_rate': 6.588095417964668e-06, 'epoch': 0.62}
 62%|██████▏   | 6471/10395 [18:30:31<8:54:45,  8.18s/it] 62%|██████▏   | 6472/10395 [18:30:40<9:09:30,  8.40s/it]                                                         {'loss': 0.936, 'learning_rate': 6.5851668135819005e-06, 'epoch': 0.62}
 62%|██████▏   | 6472/10395 [18:30:40<9:09:30,  8.40s/it] 62%|██████▏   | 6473/10395 [18:30:48<8:55:24,  8.19s/it]                                                         {'loss': 0.821, 'learning_rate': 6.582238540703843e-06, 'epoch': 0.62}
 62%|██████▏   | 6473/10395 [18:30:48<8:55:24,  8.19s/it] 62%|██████▏   | 6474/10395 [18:30:55<8:38:28,  7.93s/it]                                                         {'loss': 0.9393, 'learning_rate': 6.579310599614764e-06, 'epoch': 0.62}
 62%|██████▏   | 6474/10395 [18:30:55<8:38:28,  7.93s/it] 62%|██████▏   | 6475/10395 [18:31:03<8:41:10,  7.98s/it]                                                         {'loss': 0.8964, 'learning_rate': 6.576382990598904e-06, 'epoch': 0.62}
 62%|██████▏   | 6475/10395 [18:31:03<8:41:10,  7.98s/it] 62%|██████▏   | 6476/10395 [18:31:11<8:42:47,  8.00s/it]                                                         {'loss': 0.8355, 'learning_rate': 6.5734557139404645e-06, 'epoch': 0.62}
 62%|██████▏   | 6476/10395 [18:31:11<8:42:47,  8.00s/it] 62%|██████▏   | 6477/10395 [18:31:21<9:14:32,  8.49s/it]                                                         {'loss': 0.8477, 'learning_rate': 6.570528769923623e-06, 'epoch': 0.62}
 62%|██████▏   | 6477/10395 [18:31:21<9:14:32,  8.49s/it] 62%|██████▏   | 6478/10395 [18:31:29<9:07:43,  8.39s/it]                                                         {'loss': 0.8527, 'learning_rate': 6.567602158832519e-06, 'epoch': 0.62}
 62%|██████▏   | 6478/10395 [18:31:29<9:07:43,  8.39s/it] 62%|██████▏   | 6479/10395 [18:31:37<9:00:36,  8.28s/it]                                                         {'loss': 0.8889, 'learning_rate': 6.564675880951263e-06, 'epoch': 0.62}
 62%|██████▏   | 6479/10395 [18:31:37<9:00:36,  8.28s/it] 62%|██████▏   | 6480/10395 [18:31:45<8:47:55,  8.09s/it]                                                         {'loss': 0.807, 'learning_rate': 6.561749936563928e-06, 'epoch': 0.62}
 62%|██████▏   | 6480/10395 [18:31:45<8:47:55,  8.09s/it] 62%|██████▏   | 6481/10395 [18:32:03<11:59:35, 11.03s/it]                                                          {'loss': 0.3722, 'learning_rate': 6.5588243259545645e-06, 'epoch': 0.62}
 62%|██████▏   | 6481/10395 [18:32:03<11:59:35, 11.03s/it] 62%|██████▏   | 6482/10395 [18:32:10<10:49:36,  9.96s/it]                                                          {'loss': 0.8698, 'learning_rate': 6.555899049407185e-06, 'epoch': 0.62}
 62%|██████▏   | 6482/10395 [18:32:10<10:49:36,  9.96s/it] 62%|██████▏   | 6483/10395 [18:32:19<10:21:08,  9.53s/it]                                                          {'loss': 0.846, 'learning_rate': 6.55297410720576e-06, 'epoch': 0.62}
 62%|██████▏   | 6483/10395 [18:32:19<10:21:08,  9.53s/it] 62%|██████▏   | 6484/10395 [18:32:26<9:45:23,  8.98s/it]                                                          {'loss': 0.8503, 'learning_rate': 6.550049499634245e-06, 'epoch': 0.62}
 62%|██████▏   | 6484/10395 [18:32:26<9:45:23,  8.98s/it] 62%|██████▏   | 6485/10395 [18:32:36<10:07:00,  9.31s/it]                                                          {'loss': 0.8098, 'learning_rate': 6.547125226976552e-06, 'epoch': 0.62}
 62%|██████▏   | 6485/10395 [18:32:36<10:07:00,  9.31s/it] 62%|██████▏   | 6486/10395 [18:32:44<9:25:34,  8.68s/it]                                                          {'loss': 0.9287, 'learning_rate': 6.544201289516562e-06, 'epoch': 0.62}
 62%|██████▏   | 6486/10395 [18:32:44<9:25:34,  8.68s/it] 62%|██████▏   | 6487/10395 [18:32:51<9:05:23,  8.37s/it]                                                         {'loss': 0.8925, 'learning_rate': 6.5412776875381255e-06, 'epoch': 0.62}
 62%|██████▏   | 6487/10395 [18:32:51<9:05:23,  8.37s/it] 62%|██████▏   | 6488/10395 [18:32:59<8:53:00,  8.19s/it]                                                         {'loss': 0.8551, 'learning_rate': 6.53835442132506e-06, 'epoch': 0.62}
 62%|██████▏   | 6488/10395 [18:32:59<8:53:00,  8.19s/it] 62%|██████▏   | 6489/10395 [18:33:07<8:44:56,  8.06s/it]                                                         {'loss': 0.8711, 'learning_rate': 6.535431491161152e-06, 'epoch': 0.62}
 62%|██████▏   | 6489/10395 [18:33:07<8:44:56,  8.06s/it] 62%|██████▏   | 6490/10395 [18:33:15<8:41:45,  8.02s/it]                                                         {'loss': 0.921, 'learning_rate': 6.532508897330149e-06, 'epoch': 0.62}
 62%|██████▏   | 6490/10395 [18:33:15<8:41:45,  8.02s/it] 62%|██████▏   | 6491/10395 [18:33:24<9:05:26,  8.38s/it]                                                         {'loss': 0.8814, 'learning_rate': 6.529586640115772e-06, 'epoch': 0.62}
 62%|██████▏   | 6491/10395 [18:33:24<9:05:26,  8.38s/it] 62%|██████▏   | 6492/10395 [18:33:31<8:47:56,  8.12s/it]                                                         {'loss': 0.9452, 'learning_rate': 6.526664719801708e-06, 'epoch': 0.62}
 62%|██████▏   | 6492/10395 [18:33:31<8:47:56,  8.12s/it] 62%|██████▏   | 6493/10395 [18:33:39<8:44:55,  8.07s/it]                                                         {'loss': 0.9123, 'learning_rate': 6.523743136671611e-06, 'epoch': 0.62}
 62%|██████▏   | 6493/10395 [18:33:39<8:44:55,  8.07s/it] 62%|██████▏   | 6494/10395 [18:33:47<8:34:15,  7.91s/it]                                                         {'loss': 0.9104, 'learning_rate': 6.520821891009102e-06, 'epoch': 0.62}
 62%|██████▏   | 6494/10395 [18:33:47<8:34:15,  7.91s/it] 62%|██████▏   | 6495/10395 [18:33:54<8:27:54,  7.81s/it]                                                         {'loss': 0.9029, 'learning_rate': 6.517900983097764e-06, 'epoch': 0.62}
 62%|██████▏   | 6495/10395 [18:33:54<8:27:54,  7.81s/it] 62%|██████▏   | 6496/10395 [18:34:02<8:25:26,  7.78s/it]                                                         {'loss': 0.9095, 'learning_rate': 6.514980413221162e-06, 'epoch': 0.62}
 62%|██████▏   | 6496/10395 [18:34:02<8:25:26,  7.78s/it] 63%|██████▎   | 6497/10395 [18:34:09<8:06:21,  7.49s/it]                                                         {'loss': 0.9581, 'learning_rate': 6.512060181662818e-06, 'epoch': 0.62}
 63%|██████▎   | 6497/10395 [18:34:09<8:06:21,  7.49s/it] 63%|██████▎   | 6498/10395 [18:34:17<8:08:25,  7.52s/it]                                                         {'loss': 0.8076, 'learning_rate': 6.509140288706211e-06, 'epoch': 0.63}
 63%|██████▎   | 6498/10395 [18:34:17<8:08:25,  7.52s/it] 63%|██████▎   | 6499/10395 [18:34:24<8:07:39,  7.51s/it]                                                         {'loss': 0.9034, 'learning_rate': 6.506220734634807e-06, 'epoch': 0.63}
 63%|██████▎   | 6499/10395 [18:34:24<8:07:39,  7.51s/it] 63%|██████▎   | 6500/10395 [18:34:32<8:09:55,  7.55s/it]                                                         {'loss': 0.8987, 'learning_rate': 6.503301519732027e-06, 'epoch': 0.63}
 63%|██████▎   | 6500/10395 [18:34:32<8:09:55,  7.55s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 63%|██████▎   | 6501/10395 [18:36:10<37:42:36, 34.86s/it]                                                          {'loss': 0.8835, 'learning_rate': 6.500382644281265e-06, 'epoch': 0.63}
 63%|██████▎   | 6501/10395 [18:36:10<37:42:36, 34.86s/it] 63%|██████▎   | 6502/10395 [18:36:18<28:58:40, 26.80s/it]                                                          {'loss': 0.9211, 'learning_rate': 6.497464108565874e-06, 'epoch': 0.63}
 63%|██████▎   | 6502/10395 [18:36:18<28:58:40, 26.80s/it] 63%|██████▎   | 6503/10395 [18:36:28<23:22:34, 21.62s/it]                                                          {'loss': 0.8698, 'learning_rate': 6.494545912869184e-06, 'epoch': 0.63}
 63%|██████▎   | 6503/10395 [18:36:28<23:22:34, 21.62s/it] 63%|██████▎   | 6504/10395 [18:36:35<18:41:08, 17.29s/it]                                                          {'loss': 0.906, 'learning_rate': 6.491628057474489e-06, 'epoch': 0.63}
 63%|██████▎   | 6504/10395 [18:36:35<18:41:08, 17.29s/it] 63%|██████▎   | 6505/10395 [18:36:43<15:44:10, 14.56s/it]                                                          {'loss': 0.8472, 'learning_rate': 6.488710542665042e-06, 'epoch': 0.63}
 63%|██████▎   | 6505/10395 [18:36:43<15:44:10, 14.56s/it] 63%|██████▎   | 6506/10395 [18:36:51<13:40:51, 12.66s/it]                                                          {'loss': 0.9018, 'learning_rate': 6.4857933687240695e-06, 'epoch': 0.63}
 63%|██████▎   | 6506/10395 [18:36:51<13:40:51, 12.66s/it] 63%|██████▎   | 6507/10395 [18:36:59<11:54:53, 11.03s/it]                                                          {'loss': 0.8291, 'learning_rate': 6.482876535934768e-06, 'epoch': 0.63}
 63%|██████▎   | 6507/10395 [18:36:59<11:54:53, 11.03s/it] 63%|██████▎   | 6508/10395 [18:37:07<10:55:07, 10.11s/it]                                                          {'loss': 0.8323, 'learning_rate': 6.479960044580298e-06, 'epoch': 0.63}
 63%|██████▎   | 6508/10395 [18:37:07<10:55:07, 10.11s/it] 63%|██████▎   | 6509/10395 [18:37:14<10:06:46,  9.37s/it]                                                          {'loss': 0.9191, 'learning_rate': 6.477043894943783e-06, 'epoch': 0.63}
 63%|██████▎   | 6509/10395 [18:37:15<10:06:46,  9.37s/it] 63%|██████▎   | 6510/10395 [18:37:25<10:32:00,  9.76s/it]                                                          {'loss': 0.8233, 'learning_rate': 6.474128087308319e-06, 'epoch': 0.63}
 63%|██████▎   | 6510/10395 [18:37:25<10:32:00,  9.76s/it] 63%|██████▎   | 6511/10395 [18:37:33<9:54:01,  9.18s/it]                                                          {'loss': 0.9091, 'learning_rate': 6.471212621956967e-06, 'epoch': 0.63}
 63%|██████▎   | 6511/10395 [18:37:33<9:54:01,  9.18s/it] 63%|██████▎   | 6512/10395 [18:37:41<9:32:31,  8.85s/it]                                                         {'loss': 0.9434, 'learning_rate': 6.4682974991727506e-06, 'epoch': 0.63}
 63%|██████▎   | 6512/10395 [18:37:41<9:32:31,  8.85s/it] 63%|██████▎   | 6513/10395 [18:37:49<9:09:44,  8.50s/it]                                                         {'loss': 0.9317, 'learning_rate': 6.465382719238666e-06, 'epoch': 0.63}
 63%|██████▎   | 6513/10395 [18:37:49<9:09:44,  8.50s/it] 63%|██████▎   | 6514/10395 [18:37:56<8:55:39,  8.28s/it]                                                         {'loss': 0.9091, 'learning_rate': 6.4624682824376716e-06, 'epoch': 0.63}
 63%|██████▎   | 6514/10395 [18:37:56<8:55:39,  8.28s/it] 63%|██████▎   | 6515/10395 [18:38:04<8:46:57,  8.15s/it]                                                         {'loss': 0.9705, 'learning_rate': 6.4595541890526995e-06, 'epoch': 0.63}
 63%|██████▎   | 6515/10395 [18:38:04<8:46:57,  8.15s/it] 63%|██████▎   | 6516/10395 [18:38:13<9:03:18,  8.40s/it]                                                         {'loss': 0.8364, 'learning_rate': 6.456640439366639e-06, 'epoch': 0.63}
 63%|██████▎   | 6516/10395 [18:38:13<9:03:18,  8.40s/it] 63%|██████▎   | 6517/10395 [18:38:20<8:38:52,  8.03s/it]                                                         {'loss': 0.8282, 'learning_rate': 6.453727033662353e-06, 'epoch': 0.63}
 63%|██████▎   | 6517/10395 [18:38:20<8:38:52,  8.03s/it] 63%|██████▎   | 6518/10395 [18:38:28<8:36:31,  7.99s/it]                                                         {'loss': 0.8404, 'learning_rate': 6.450813972222669e-06, 'epoch': 0.63}
 63%|██████▎   | 6518/10395 [18:38:28<8:36:31,  7.99s/it] 63%|██████▎   | 6519/10395 [18:38:37<8:57:00,  8.31s/it]                                                         {'loss': 0.8448, 'learning_rate': 6.447901255330381e-06, 'epoch': 0.63}
 63%|██████▎   | 6519/10395 [18:38:37<8:57:00,  8.31s/it] 63%|██████▎   | 6520/10395 [18:38:45<8:43:14,  8.10s/it]                                                         {'loss': 0.8496, 'learning_rate': 6.444988883268246e-06, 'epoch': 0.63}
 63%|██████▎   | 6520/10395 [18:38:45<8:43:14,  8.10s/it] 63%|██████▎   | 6521/10395 [18:38:53<8:34:31,  7.97s/it]                                                         {'loss': 0.8761, 'learning_rate': 6.442076856318993e-06, 'epoch': 0.63}
 63%|██████▎   | 6521/10395 [18:38:53<8:34:31,  7.97s/it] 63%|██████▎   | 6522/10395 [18:39:00<8:26:50,  7.85s/it]                                                         {'loss': 0.9031, 'learning_rate': 6.439165174765315e-06, 'epoch': 0.63}
 63%|██████▎   | 6522/10395 [18:39:00<8:26:50,  7.85s/it] 63%|██████▎   | 6523/10395 [18:39:09<8:50:40,  8.22s/it]                                                         {'loss': 0.8954, 'learning_rate': 6.436253838889874e-06, 'epoch': 0.63}
 63%|██████▎   | 6523/10395 [18:39:09<8:50:40,  8.22s/it] 63%|██████▎   | 6524/10395 [18:39:17<8:46:56,  8.17s/it]                                                         {'loss': 0.8518, 'learning_rate': 6.4333428489752935e-06, 'epoch': 0.63}
 63%|██████▎   | 6524/10395 [18:39:17<8:46:56,  8.17s/it] 63%|██████▎   | 6525/10395 [18:39:25<8:35:57,  8.00s/it]                                                         {'loss': 0.8652, 'learning_rate': 6.430432205304168e-06, 'epoch': 0.63}
 63%|██████▎   | 6525/10395 [18:39:25<8:35:57,  8.00s/it] 63%|██████▎   | 6526/10395 [18:39:32<8:28:15,  7.88s/it]                                                         {'loss': 0.8389, 'learning_rate': 6.427521908159058e-06, 'epoch': 0.63}
 63%|██████▎   | 6526/10395 [18:39:32<8:28:15,  7.88s/it] 63%|██████▎   | 6527/10395 [18:39:40<8:19:02,  7.74s/it]                                                         {'loss': 0.8821, 'learning_rate': 6.424611957822484e-06, 'epoch': 0.63}
 63%|██████▎   | 6527/10395 [18:39:40<8:19:02,  7.74s/it] 63%|██████▎   | 6528/10395 [18:39:47<8:15:31,  7.69s/it]                                                         {'loss': 0.9651, 'learning_rate': 6.421702354576941e-06, 'epoch': 0.63}
 63%|██████▎   | 6528/10395 [18:39:47<8:15:31,  7.69s/it] 63%|██████▎   | 6529/10395 [18:39:55<8:10:11,  7.61s/it]                                                         {'loss': 0.8661, 'learning_rate': 6.418793098704885e-06, 'epoch': 0.63}
 63%|██████▎   | 6529/10395 [18:39:55<8:10:11,  7.61s/it] 63%|██████▎   | 6530/10395 [18:40:03<8:18:04,  7.73s/it]                                                         {'loss': 0.9489, 'learning_rate': 6.4158841904887426e-06, 'epoch': 0.63}
 63%|██████▎   | 6530/10395 [18:40:03<8:18:04,  7.73s/it] 63%|██████▎   | 6531/10395 [18:40:11<8:19:41,  7.76s/it]                                                         {'loss': 0.9282, 'learning_rate': 6.412975630210905e-06, 'epoch': 0.63}
 63%|██████▎   | 6531/10395 [18:40:11<8:19:41,  7.76s/it] 63%|██████▎   | 6532/10395 [18:40:18<8:16:29,  7.71s/it]                                                         {'loss': 0.9233, 'learning_rate': 6.410067418153727e-06, 'epoch': 0.63}
 63%|██████▎   | 6532/10395 [18:40:18<8:16:29,  7.71s/it] 63%|██████▎   | 6533/10395 [18:40:26<8:14:32,  7.68s/it]                                                         {'loss': 0.9066, 'learning_rate': 6.407159554599532e-06, 'epoch': 0.63}
 63%|██████▎   | 6533/10395 [18:40:26<8:14:32,  7.68s/it] 63%|██████▎   | 6534/10395 [18:40:34<8:15:35,  7.70s/it]                                                         {'loss': 0.9681, 'learning_rate': 6.4042520398306115e-06, 'epoch': 0.63}
 63%|██████▎   | 6534/10395 [18:40:34<8:15:35,  7.70s/it] 63%|██████▎   | 6535/10395 [18:40:42<8:24:39,  7.84s/it]                                                         {'loss': 0.8491, 'learning_rate': 6.401344874129218e-06, 'epoch': 0.63}
 63%|██████▎   | 6535/10395 [18:40:42<8:24:39,  7.84s/it] 63%|██████▎   | 6536/10395 [18:40:50<8:29:37,  7.92s/it]                                                         {'loss': 0.9484, 'learning_rate': 6.398438057777574e-06, 'epoch': 0.63}
 63%|██████▎   | 6536/10395 [18:40:50<8:29:37,  7.92s/it] 63%|██████▎   | 6537/10395 [18:40:57<8:20:01,  7.78s/it]                                                         {'loss': 0.908, 'learning_rate': 6.395531591057863e-06, 'epoch': 0.63}
 63%|██████▎   | 6537/10395 [18:40:57<8:20:01,  7.78s/it] 63%|██████▎   | 6538/10395 [18:41:05<8:21:09,  7.80s/it]                                                         {'loss': 0.8806, 'learning_rate': 6.392625474252245e-06, 'epoch': 0.63}
 63%|██████▎   | 6538/10395 [18:41:05<8:21:09,  7.80s/it] 63%|██████▎   | 6539/10395 [18:41:13<8:21:41,  7.81s/it]                                                         {'loss': 0.9038, 'learning_rate': 6.389719707642838e-06, 'epoch': 0.63}
 63%|██████▎   | 6539/10395 [18:41:13<8:21:41,  7.81s/it] 63%|██████▎   | 6540/10395 [18:41:22<8:36:05,  8.03s/it]                                                         {'loss': 0.9645, 'learning_rate': 6.386814291511726e-06, 'epoch': 0.63}
 63%|██████▎   | 6540/10395 [18:41:22<8:36:05,  8.03s/it] 63%|██████▎   | 6541/10395 [18:41:29<8:24:53,  7.86s/it]                                                         {'loss': 0.9058, 'learning_rate': 6.383909226140963e-06, 'epoch': 0.63}
 63%|██████▎   | 6541/10395 [18:41:29<8:24:53,  7.86s/it] 63%|██████▎   | 6542/10395 [18:41:38<8:37:58,  8.07s/it]                                                         {'loss': 0.8629, 'learning_rate': 6.381004511812563e-06, 'epoch': 0.63}
 63%|██████▎   | 6542/10395 [18:41:38<8:37:58,  8.07s/it] 63%|██████▎   | 6543/10395 [18:41:45<8:30:00,  7.94s/it]                                                         {'loss': 0.7886, 'learning_rate': 6.37810014880851e-06, 'epoch': 0.63}
 63%|██████▎   | 6543/10395 [18:41:45<8:30:00,  7.94s/it] 63%|██████▎   | 6544/10395 [18:41:53<8:24:04,  7.85s/it]                                                         {'loss': 0.8806, 'learning_rate': 6.375196137410755e-06, 'epoch': 0.63}
 63%|██████▎   | 6544/10395 [18:41:53<8:24:04,  7.85s/it] 63%|██████▎   | 6545/10395 [18:42:00<8:13:12,  7.69s/it]                                                         {'loss': 0.9624, 'learning_rate': 6.372292477901212e-06, 'epoch': 0.63}
 63%|██████▎   | 6545/10395 [18:42:00<8:13:12,  7.69s/it] 63%|██████▎   | 6546/10395 [18:42:09<8:34:50,  8.03s/it]                                                         {'loss': 0.8676, 'learning_rate': 6.369389170561764e-06, 'epoch': 0.63}
 63%|██████▎   | 6546/10395 [18:42:09<8:34:50,  8.03s/it] 63%|██████▎   | 6547/10395 [18:42:16<8:20:26,  7.80s/it]                                                         {'loss': 0.8423, 'learning_rate': 6.3664862156742565e-06, 'epoch': 0.63}
 63%|██████▎   | 6547/10395 [18:42:16<8:20:26,  7.80s/it] 63%|██████▎   | 6548/10395 [18:42:34<11:39:02, 10.90s/it]                                                          {'loss': 0.3508, 'learning_rate': 6.363583613520505e-06, 'epoch': 0.63}
 63%|██████▎   | 6548/10395 [18:42:34<11:39:02, 10.90s/it] 63%|██████▎   | 6549/10395 [18:42:42<10:36:02,  9.92s/it]                                                          {'loss': 0.8366, 'learning_rate': 6.360681364382282e-06, 'epoch': 0.63}
 63%|██████▎   | 6549/10395 [18:42:42<10:36:02,  9.92s/it] 63%|██████▎   | 6550/10395 [18:42:50<10:02:02,  9.39s/it]                                                          {'loss': 0.8965, 'learning_rate': 6.357779468541336e-06, 'epoch': 0.63}
 63%|██████▎   | 6550/10395 [18:42:50<10:02:02,  9.39s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 63%|██████▎   | 6551/10395 [18:44:30<38:55:58, 36.46s/it]                                                          {'loss': 0.9173, 'learning_rate': 6.354877926279375e-06, 'epoch': 0.63}
 63%|██████▎   | 6551/10395 [18:44:30<38:55:58, 36.46s/it] 63%|██████▎   | 6552/10395 [18:44:37<29:41:09, 27.81s/it]                                                          {'loss': 0.8994, 'learning_rate': 6.351976737878076e-06, 'epoch': 0.63}
 63%|██████▎   | 6552/10395 [18:44:37<29:41:09, 27.81s/it] 63%|██████▎   | 6553/10395 [18:44:45<23:07:35, 21.67s/it]                                                          {'loss': 0.9039, 'learning_rate': 6.349075903619077e-06, 'epoch': 0.63}
 63%|██████▎   | 6553/10395 [18:44:45<23:07:35, 21.67s/it] 63%|██████▎   | 6554/10395 [18:44:53<18:38:39, 17.47s/it]                                                          {'loss': 0.8879, 'learning_rate': 6.346175423783989e-06, 'epoch': 0.63}
 63%|██████▎   | 6554/10395 [18:44:53<18:38:39, 17.47s/it] 63%|██████▎   | 6555/10395 [18:45:01<15:46:23, 14.79s/it]                                                          {'loss': 0.8769, 'learning_rate': 6.343275298654384e-06, 'epoch': 0.63}
 63%|██████▎   | 6555/10395 [18:45:01<15:46:23, 14.79s/it] 63%|██████▎   | 6556/10395 [18:45:09<13:30:04, 12.66s/it]                                                          {'loss': 0.8747, 'learning_rate': 6.3403755285118e-06, 'epoch': 0.63}
 63%|██████▎   | 6556/10395 [18:45:09<13:30:04, 12.66s/it] 63%|██████▎   | 6557/10395 [18:45:17<12:07:38, 11.38s/it]                                                          {'loss': 0.7776, 'learning_rate': 6.337476113637735e-06, 'epoch': 0.63}
 63%|██████▎   | 6557/10395 [18:45:17<12:07:38, 11.38s/it] 63%|██████▎   | 6558/10395 [18:45:26<11:12:31, 10.52s/it]                                                          {'loss': 0.855, 'learning_rate': 6.334577054313664e-06, 'epoch': 0.63}
 63%|██████▎   | 6558/10395 [18:45:26<11:12:31, 10.52s/it] 63%|██████▎   | 6559/10395 [18:45:34<10:24:46,  9.77s/it]                                                          {'loss': 0.8845, 'learning_rate': 6.33167835082102e-06, 'epoch': 0.63}
 63%|██████▎   | 6559/10395 [18:45:34<10:24:46,  9.77s/it] 63%|██████▎   | 6560/10395 [18:45:43<10:15:15,  9.63s/it]                                                          {'loss': 0.8257, 'learning_rate': 6.3287800034412e-06, 'epoch': 0.63}
 63%|██████▎   | 6560/10395 [18:45:43<10:15:15,  9.63s/it] 63%|██████▎   | 6561/10395 [18:45:53<10:18:36,  9.68s/it]                                                          {'loss': 0.8132, 'learning_rate': 6.325882012455573e-06, 'epoch': 0.63}
 63%|██████▎   | 6561/10395 [18:45:53<10:18:36,  9.68s/it] 63%|██████▎   | 6562/10395 [18:46:01<9:43:22,  9.13s/it]                                                          {'loss': 0.8867, 'learning_rate': 6.322984378145468e-06, 'epoch': 0.63}
 63%|██████▎   | 6562/10395 [18:46:01<9:43:22,  9.13s/it] 63%|██████▎   | 6563/10395 [18:46:09<9:27:20,  8.88s/it]                                                         {'loss': 0.8978, 'learning_rate': 6.320087100792185e-06, 'epoch': 0.63}
 63%|██████▎   | 6563/10395 [18:46:09<9:27:20,  8.88s/it] 63%|██████▎   | 6564/10395 [18:46:17<9:03:17,  8.51s/it]                                                         {'loss': 0.8591, 'learning_rate': 6.31719018067698e-06, 'epoch': 0.63}
 63%|██████▎   | 6564/10395 [18:46:17<9:03:17,  8.51s/it] 63%|██████▎   | 6565/10395 [18:46:24<8:40:37,  8.16s/it]                                                         {'loss': 0.8997, 'learning_rate': 6.314293618081082e-06, 'epoch': 0.63}
 63%|██████▎   | 6565/10395 [18:46:24<8:40:37,  8.16s/it] 63%|██████▎   | 6566/10395 [18:46:31<8:29:22,  7.98s/it]                                                         {'loss': 0.799, 'learning_rate': 6.311397413285684e-06, 'epoch': 0.63}
 63%|██████▎   | 6566/10395 [18:46:31<8:29:22,  7.98s/it] 63%|██████▎   | 6567/10395 [18:46:40<8:32:13,  8.03s/it]                                                         {'loss': 0.8729, 'learning_rate': 6.308501566571942e-06, 'epoch': 0.63}
 63%|██████▎   | 6567/10395 [18:46:40<8:32:13,  8.03s/it] 63%|██████▎   | 6568/10395 [18:46:48<8:34:03,  8.06s/it]                                                         {'loss': 0.9027, 'learning_rate': 6.305606078220976e-06, 'epoch': 0.63}
 63%|██████▎   | 6568/10395 [18:46:48<8:34:03,  8.06s/it] 63%|██████▎   | 6569/10395 [18:46:55<8:26:08,  7.94s/it]                                                         {'loss': 0.9295, 'learning_rate': 6.302710948513881e-06, 'epoch': 0.63}
 63%|██████▎   | 6569/10395 [18:46:55<8:26:08,  7.94s/it] 63%|██████▎   | 6570/10395 [18:47:03<8:24:29,  7.91s/it]                                                         {'loss': 0.9618, 'learning_rate': 6.299816177731708e-06, 'epoch': 0.63}
 63%|██████▎   | 6570/10395 [18:47:03<8:24:29,  7.91s/it] 63%|██████▎   | 6571/10395 [18:47:11<8:18:12,  7.82s/it]                                                         {'loss': 0.956, 'learning_rate': 6.296921766155468e-06, 'epoch': 0.63}
 63%|██████▎   | 6571/10395 [18:47:11<8:18:12,  7.82s/it] 63%|██████▎   | 6572/10395 [18:47:29<11:27:47, 10.79s/it]                                                          {'loss': 0.3643, 'learning_rate': 6.294027714066152e-06, 'epoch': 0.63}
 63%|██████▎   | 6572/10395 [18:47:29<11:27:47, 10.79s/it] 63%|██████▎   | 6573/10395 [18:47:36<10:17:08,  9.69s/it]                                                          {'loss': 0.9357, 'learning_rate': 6.291134021744706e-06, 'epoch': 0.63}
 63%|██████▎   | 6573/10395 [18:47:36<10:17:08,  9.69s/it] 63%|██████▎   | 6574/10395 [18:47:43<9:36:35,  9.05s/it]                                                          {'loss': 0.9309, 'learning_rate': 6.288240689472043e-06, 'epoch': 0.63}
 63%|██████▎   | 6574/10395 [18:47:43<9:36:35,  9.05s/it] 63%|██████▎   | 6575/10395 [18:47:51<9:11:38,  8.66s/it]                                                         {'loss': 0.8898, 'learning_rate': 6.28534771752904e-06, 'epoch': 0.63}
 63%|██████▎   | 6575/10395 [18:47:51<9:11:38,  8.66s/it] 63%|██████▎   | 6576/10395 [18:48:01<9:30:24,  8.96s/it]                                                         {'loss': 0.7994, 'learning_rate': 6.282455106196543e-06, 'epoch': 0.63}
 63%|██████▎   | 6576/10395 [18:48:01<9:30:24,  8.96s/it] 63%|██████▎   | 6577/10395 [18:48:08<9:01:27,  8.51s/it]                                                         {'loss': 0.8812, 'learning_rate': 6.2795628557553616e-06, 'epoch': 0.63}
 63%|██████▎   | 6577/10395 [18:48:08<9:01:27,  8.51s/it] 63%|██████▎   | 6578/10395 [18:48:16<8:48:47,  8.31s/it]                                                         {'loss': 0.8715, 'learning_rate': 6.276670966486269e-06, 'epoch': 0.63}
 63%|██████▎   | 6578/10395 [18:48:16<8:48:47,  8.31s/it] 63%|██████▎   | 6579/10395 [18:48:24<8:39:40,  8.17s/it]                                                         {'loss': 0.8659, 'learning_rate': 6.273779438669998e-06, 'epoch': 0.63}
 63%|██████▎   | 6579/10395 [18:48:24<8:39:40,  8.17s/it] 63%|██████▎   | 6580/10395 [18:48:31<8:30:02,  8.02s/it]                                                         {'loss': 0.8486, 'learning_rate': 6.270888272587259e-06, 'epoch': 0.63}
 63%|██████▎   | 6580/10395 [18:48:31<8:30:02,  8.02s/it] 63%|██████▎   | 6581/10395 [18:48:39<8:18:55,  7.85s/it]                                                         {'loss': 0.8785, 'learning_rate': 6.267997468518716e-06, 'epoch': 0.63}
 63%|██████▎   | 6581/10395 [18:48:39<8:18:55,  7.85s/it] 63%|██████▎   | 6582/10395 [18:48:48<8:40:26,  8.19s/it]                                                         {'loss': 0.8401, 'learning_rate': 6.265107026745003e-06, 'epoch': 0.63}
 63%|██████▎   | 6582/10395 [18:48:48<8:40:26,  8.19s/it] 63%|██████▎   | 6583/10395 [18:48:56<8:30:49,  8.04s/it]                                                         {'loss': 0.8431, 'learning_rate': 6.26221694754672e-06, 'epoch': 0.63}
 63%|██████▎   | 6583/10395 [18:48:56<8:30:49,  8.04s/it] 63%|██████▎   | 6584/10395 [18:49:04<8:37:44,  8.15s/it]                                                         {'loss': 0.7967, 'learning_rate': 6.259327231204425e-06, 'epoch': 0.63}
 63%|██████▎   | 6584/10395 [18:49:04<8:37:44,  8.15s/it] 63%|██████▎   | 6585/10395 [18:49:12<8:38:08,  8.16s/it]                                                         {'loss': 0.8517, 'learning_rate': 6.256437877998654e-06, 'epoch': 0.63}
 63%|██████▎   | 6585/10395 [18:49:12<8:38:08,  8.16s/it] 63%|██████▎   | 6586/10395 [18:49:20<8:29:54,  8.03s/it]                                                         {'loss': 0.9121, 'learning_rate': 6.25354888820989e-06, 'epoch': 0.63}
 63%|██████▎   | 6586/10395 [18:49:20<8:29:54,  8.03s/it] 63%|██████▎   | 6587/10395 [18:49:27<8:19:27,  7.87s/it]                                                         {'loss': 0.8359, 'learning_rate': 6.250660262118593e-06, 'epoch': 0.63}
 63%|██████▎   | 6587/10395 [18:49:27<8:19:27,  7.87s/it] 63%|██████▎   | 6588/10395 [18:49:36<8:25:42,  7.97s/it]                                                         {'loss': 0.9411, 'learning_rate': 6.247772000005188e-06, 'epoch': 0.63}
 63%|██████▎   | 6588/10395 [18:49:36<8:25:42,  7.97s/it] 63%|██████▎   | 6589/10395 [18:49:43<8:14:18,  7.79s/it]                                                         {'loss': 0.8161, 'learning_rate': 6.244884102150057e-06, 'epoch': 0.63}
 63%|██████▎   | 6589/10395 [18:49:43<8:14:18,  7.79s/it] 63%|██████▎   | 6590/10395 [18:49:50<8:02:22,  7.61s/it]                                                         {'loss': 0.9211, 'learning_rate': 6.241996568833552e-06, 'epoch': 0.63}
 63%|██████▎   | 6590/10395 [18:49:50<8:02:22,  7.61s/it] 63%|██████▎   | 6591/10395 [18:50:00<8:46:04,  8.30s/it]                                                         {'loss': 0.7746, 'learning_rate': 6.239109400335989e-06, 'epoch': 0.63}
 63%|██████▎   | 6591/10395 [18:50:00<8:46:04,  8.30s/it] 63%|██████▎   | 6592/10395 [18:50:09<8:57:53,  8.49s/it]                                                         {'loss': 0.8561, 'learning_rate': 6.2362225969376535e-06, 'epoch': 0.63}
 63%|██████▎   | 6592/10395 [18:50:09<8:57:53,  8.49s/it] 63%|██████▎   | 6593/10395 [18:50:17<8:46:37,  8.31s/it]                                                         {'loss': 0.8275, 'learning_rate': 6.233336158918781e-06, 'epoch': 0.63}
 63%|██████▎   | 6593/10395 [18:50:17<8:46:37,  8.31s/it] 63%|██████▎   | 6594/10395 [18:50:25<8:35:25,  8.14s/it]                                                         {'loss': 0.956, 'learning_rate': 6.230450086559583e-06, 'epoch': 0.63}
 63%|██████▎   | 6594/10395 [18:50:25<8:35:25,  8.14s/it] 63%|██████▎   | 6595/10395 [18:50:33<8:31:17,  8.07s/it]                                                         {'loss': 0.8806, 'learning_rate': 6.227564380140238e-06, 'epoch': 0.63}
 63%|██████▎   | 6595/10395 [18:50:33<8:31:17,  8.07s/it] 63%|██████▎   | 6596/10395 [18:50:41<8:34:15,  8.12s/it]                                                         {'loss': 0.8825, 'learning_rate': 6.22467903994088e-06, 'epoch': 0.63}
 63%|██████▎   | 6596/10395 [18:50:41<8:34:15,  8.12s/it] 63%|██████▎   | 6597/10395 [18:50:49<8:38:45,  8.20s/it]                                                         {'loss': 0.8974, 'learning_rate': 6.221794066241613e-06, 'epoch': 0.63}
 63%|██████▎   | 6597/10395 [18:50:49<8:38:45,  8.20s/it] 63%|██████▎   | 6598/10395 [18:50:57<8:30:08,  8.06s/it]                                                         {'loss': 0.9024, 'learning_rate': 6.218909459322504e-06, 'epoch': 0.63}
 63%|██████▎   | 6598/10395 [18:50:57<8:30:08,  8.06s/it] 63%|██████▎   | 6599/10395 [18:51:04<8:07:56,  7.71s/it]                                                         {'loss': 0.9212, 'learning_rate': 6.2160252194635815e-06, 'epoch': 0.63}
 63%|██████▎   | 6599/10395 [18:51:04<8:07:56,  7.71s/it] 63%|██████▎   | 6600/10395 [18:51:11<8:04:47,  7.66s/it]                                                         {'loss': 0.8606, 'learning_rate': 6.213141346944853e-06, 'epoch': 0.63}
 63%|██████▎   | 6600/10395 [18:51:11<8:04:47,  7.66s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 64%|██████▎   | 6601/10395 [18:52:52<37:30:14, 35.59s/it]                                                          {'loss': 0.9413, 'learning_rate': 6.210257842046263e-06, 'epoch': 0.63}
 64%|██████▎   | 6601/10395 [18:52:52<37:30:14, 35.59s/it] 64%|██████▎   | 6602/10395 [18:53:09<31:27:10, 29.85s/it]                                                          {'loss': 0.3453, 'learning_rate': 6.207374705047744e-06, 'epoch': 0.64}
 64%|██████▎   | 6602/10395 [18:53:09<31:27:10, 29.85s/it] 64%|██████▎   | 6603/10395 [18:53:16<24:21:50, 23.13s/it]                                                          {'loss': 0.8989, 'learning_rate': 6.204491936229184e-06, 'epoch': 0.64}
 64%|██████▎   | 6603/10395 [18:53:16<24:21:50, 23.13s/it] 64%|██████▎   | 6604/10395 [18:53:25<19:45:12, 18.76s/it]                                                          {'loss': 0.8678, 'learning_rate': 6.201609535870436e-06, 'epoch': 0.64}
 64%|██████▎   | 6604/10395 [18:53:25<19:45:12, 18.76s/it] 64%|██████▎   | 6605/10395 [18:53:32<16:18:38, 15.49s/it]                                                          {'loss': 0.8696, 'learning_rate': 6.198727504251316e-06, 'epoch': 0.64}
 64%|██████▎   | 6605/10395 [18:53:32<16:18:38, 15.49s/it] 64%|██████▎   | 6606/10395 [18:53:41<14:02:14, 13.34s/it]                                                          {'loss': 0.8374, 'learning_rate': 6.195845841651609e-06, 'epoch': 0.64}
 64%|██████▎   | 6606/10395 [18:53:41<14:02:14, 13.34s/it] 64%|██████▎   | 6607/10395 [18:53:49<12:19:08, 11.71s/it]                                                          {'loss': 0.9033, 'learning_rate': 6.192964548351058e-06, 'epoch': 0.64}
 64%|██████▎   | 6607/10395 [18:53:49<12:19:08, 11.71s/it] 64%|██████▎   | 6608/10395 [18:53:56<10:58:45, 10.44s/it]                                                          {'loss': 0.9656, 'learning_rate': 6.190083624629373e-06, 'epoch': 0.64}
 64%|██████▎   | 6608/10395 [18:53:56<10:58:45, 10.44s/it] 64%|██████▎   | 6609/10395 [18:54:05<10:28:32,  9.96s/it]                                                          {'loss': 0.9194, 'learning_rate': 6.187203070766225e-06, 'epoch': 0.64}
 64%|██████▎   | 6609/10395 [18:54:05<10:28:32,  9.96s/it] 64%|██████▎   | 6610/10395 [18:54:13<9:43:12,  9.25s/it]                                                          {'loss': 0.9333, 'learning_rate': 6.1843228870412555e-06, 'epoch': 0.64}
 64%|██████▎   | 6610/10395 [18:54:13<9:43:12,  9.25s/it] 64%|██████▎   | 6611/10395 [18:54:20<9:13:13,  8.77s/it]                                                         {'loss': 0.9525, 'learning_rate': 6.181443073734067e-06, 'epoch': 0.64}
 64%|██████▎   | 6611/10395 [18:54:20<9:13:13,  8.77s/it] 64%|██████▎   | 6612/10395 [18:54:28<8:57:45,  8.53s/it]                                                         {'loss': 0.9626, 'learning_rate': 6.1785636311242245e-06, 'epoch': 0.64}
 64%|██████▎   | 6612/10395 [18:54:28<8:57:45,  8.53s/it] 64%|██████▎   | 6613/10395 [18:54:36<8:44:52,  8.33s/it]                                                         {'loss': 0.8856, 'learning_rate': 6.175684559491259e-06, 'epoch': 0.64}
 64%|██████▎   | 6613/10395 [18:54:36<8:44:52,  8.33s/it] 64%|██████▎   | 6614/10395 [18:54:43<8:26:34,  8.04s/it]                                                         {'loss': 0.9528, 'learning_rate': 6.172805859114665e-06, 'epoch': 0.64}
 64%|██████▎   | 6614/10395 [18:54:43<8:26:34,  8.04s/it] 64%|██████▎   | 6615/10395 [18:54:51<8:13:51,  7.84s/it]                                                         {'loss': 0.9533, 'learning_rate': 6.169927530273898e-06, 'epoch': 0.64}
 64%|██████▎   | 6615/10395 [18:54:51<8:13:51,  7.84s/it] 64%|██████▎   | 6616/10395 [18:54:58<8:01:47,  7.65s/it]                                                         {'loss': 0.9609, 'learning_rate': 6.167049573248381e-06, 'epoch': 0.64}
 64%|██████▎   | 6616/10395 [18:54:58<8:01:47,  7.65s/it] 64%|██████▎   | 6617/10395 [18:55:05<7:53:41,  7.52s/it]                                                         {'loss': 0.9077, 'learning_rate': 6.164171988317501e-06, 'epoch': 0.64}
 64%|██████▎   | 6617/10395 [18:55:05<7:53:41,  7.52s/it] 64%|██████▎   | 6618/10395 [18:55:13<7:55:04,  7.55s/it]                                                         {'loss': 0.8858, 'learning_rate': 6.161294775760604e-06, 'epoch': 0.64}
 64%|██████▎   | 6618/10395 [18:55:13<7:55:04,  7.55s/it] 64%|██████▎   | 6619/10395 [18:55:20<7:55:58,  7.56s/it]                                                         {'loss': 0.8783, 'learning_rate': 6.158417935857011e-06, 'epoch': 0.64}
 64%|██████▎   | 6619/10395 [18:55:20<7:55:58,  7.56s/it] 64%|██████▎   | 6620/10395 [18:55:28<7:56:09,  7.57s/it]                                                         {'loss': 0.9012, 'learning_rate': 6.155541468885994e-06, 'epoch': 0.64}
 64%|██████▎   | 6620/10395 [18:55:28<7:56:09,  7.57s/it] 64%|██████▎   | 6621/10395 [18:55:36<8:05:40,  7.72s/it]                                                         {'loss': 0.8665, 'learning_rate': 6.152665375126795e-06, 'epoch': 0.64}
 64%|██████▎   | 6621/10395 [18:55:36<8:05:40,  7.72s/it] 64%|██████▎   | 6622/10395 [18:55:44<8:11:57,  7.82s/it]                                                         {'loss': 0.8817, 'learning_rate': 6.149789654858622e-06, 'epoch': 0.64}
 64%|██████▎   | 6622/10395 [18:55:44<8:11:57,  7.82s/it] 64%|██████▎   | 6623/10395 [18:55:51<8:01:48,  7.66s/it]                                                         {'loss': 0.8936, 'learning_rate': 6.14691430836064e-06, 'epoch': 0.64}
 64%|██████▎   | 6623/10395 [18:55:51<8:01:48,  7.66s/it] 64%|██████▎   | 6624/10395 [18:56:00<8:11:15,  7.82s/it]                                                         {'loss': 0.9073, 'learning_rate': 6.144039335911982e-06, 'epoch': 0.64}
 64%|██████▎   | 6624/10395 [18:56:00<8:11:15,  7.82s/it] 64%|██████▎   | 6625/10395 [18:56:07<8:03:19,  7.69s/it]                                                         {'loss': 1.0131, 'learning_rate': 6.141164737791744e-06, 'epoch': 0.64}
 64%|██████▎   | 6625/10395 [18:56:07<8:03:19,  7.69s/it] 64%|██████▎   | 6626/10395 [18:56:14<7:58:53,  7.62s/it]                                                         {'loss': 0.8291, 'learning_rate': 6.138290514278988e-06, 'epoch': 0.64}
 64%|██████▎   | 6626/10395 [18:56:14<7:58:53,  7.62s/it] 64%|██████▍   | 6627/10395 [18:56:22<8:02:38,  7.69s/it]                                                         {'loss': 0.95, 'learning_rate': 6.135416665652737e-06, 'epoch': 0.64}
 64%|██████▍   | 6627/10395 [18:56:22<8:02:38,  7.69s/it] 64%|██████▍   | 6628/10395 [18:56:30<8:06:10,  7.74s/it]                                                         {'loss': 0.8878, 'learning_rate': 6.132543192191978e-06, 'epoch': 0.64}
 64%|██████▍   | 6628/10395 [18:56:30<8:06:10,  7.74s/it] 64%|██████▍   | 6629/10395 [18:56:38<8:03:18,  7.70s/it]                                                         {'loss': 0.9072, 'learning_rate': 6.129670094175661e-06, 'epoch': 0.64}
 64%|██████▍   | 6629/10395 [18:56:38<8:03:18,  7.70s/it] 64%|██████▍   | 6630/10395 [18:56:46<8:08:53,  7.79s/it]                                                         {'loss': 0.8333, 'learning_rate': 6.1267973718827e-06, 'epoch': 0.64}
 64%|██████▍   | 6630/10395 [18:56:46<8:08:53,  7.79s/it] 64%|██████▍   | 6631/10395 [18:56:55<8:39:03,  8.27s/it]                                                         {'loss': 0.8807, 'learning_rate': 6.123925025591972e-06, 'epoch': 0.64}
 64%|██████▍   | 6631/10395 [18:56:55<8:39:03,  8.27s/it] 64%|██████▍   | 6632/10395 [18:57:03<8:23:39,  8.03s/it]                                                         {'loss': 0.8279, 'learning_rate': 6.12105305558232e-06, 'epoch': 0.64}
 64%|██████▍   | 6632/10395 [18:57:03<8:23:39,  8.03s/it] 64%|██████▍   | 6633/10395 [18:57:10<8:15:16,  7.90s/it]                                                         {'loss': 0.8276, 'learning_rate': 6.118181462132546e-06, 'epoch': 0.64}
 64%|██████▍   | 6633/10395 [18:57:10<8:15:16,  7.90s/it] 64%|██████▍   | 6634/10395 [18:57:18<8:05:18,  7.74s/it]                                                         {'loss': 0.9031, 'learning_rate': 6.115310245521423e-06, 'epoch': 0.64}
 64%|██████▍   | 6634/10395 [18:57:18<8:05:18,  7.74s/it] 64%|██████▍   | 6635/10395 [18:57:26<8:10:13,  7.82s/it]                                                         {'loss': 0.8683, 'learning_rate': 6.1124394060276795e-06, 'epoch': 0.64}
 64%|██████▍   | 6635/10395 [18:57:26<8:10:13,  7.82s/it] 64%|██████▍   | 6636/10395 [18:57:42<10:54:44, 10.45s/it]                                                          {'loss': 0.3543, 'learning_rate': 6.109568943930011e-06, 'epoch': 0.64}
 64%|██████▍   | 6636/10395 [18:57:42<10:54:44, 10.45s/it] 64%|██████▍   | 6637/10395 [18:57:50<9:58:22,  9.55s/it]                                                          {'loss': 0.9678, 'learning_rate': 6.106698859507075e-06, 'epoch': 0.64}
 64%|██████▍   | 6637/10395 [18:57:50<9:58:22,  9.55s/it] 64%|██████▍   | 6638/10395 [18:57:59<9:52:20,  9.46s/it]                                                         {'loss': 0.8643, 'learning_rate': 6.103829153037494e-06, 'epoch': 0.64}
 64%|██████▍   | 6638/10395 [18:57:59<9:52:20,  9.46s/it] 64%|██████▍   | 6639/10395 [18:58:07<9:23:15,  9.00s/it]                                                         {'loss': 0.9357, 'learning_rate': 6.100959824799853e-06, 'epoch': 0.64}
 64%|██████▍   | 6639/10395 [18:58:07<9:23:15,  9.00s/it] 64%|██████▍   | 6640/10395 [18:58:15<9:06:59,  8.74s/it]                                                         {'loss': 0.9235, 'learning_rate': 6.098090875072698e-06, 'epoch': 0.64}
 64%|██████▍   | 6640/10395 [18:58:15<9:06:59,  8.74s/it] 64%|██████▍   | 6641/10395 [18:58:23<9:02:44,  8.67s/it]                                                         {'loss': 0.8101, 'learning_rate': 6.095222304134541e-06, 'epoch': 0.64}
 64%|██████▍   | 6641/10395 [18:58:23<9:02:44,  8.67s/it] 64%|██████▍   | 6642/10395 [18:58:41<11:54:28, 11.42s/it]                                                          {'loss': 0.4055, 'learning_rate': 6.092354112263861e-06, 'epoch': 0.64}
 64%|██████▍   | 6642/10395 [18:58:41<11:54:28, 11.42s/it] 64%|██████▍   | 6643/10395 [18:58:49<10:44:36, 10.31s/it]                                                          {'loss': 0.9286, 'learning_rate': 6.089486299739093e-06, 'epoch': 0.64}
 64%|██████▍   | 6643/10395 [18:58:49<10:44:36, 10.31s/it] 64%|██████▍   | 6644/10395 [18:58:57<10:00:35,  9.61s/it]                                                          {'loss': 0.8001, 'learning_rate': 6.0866188668386405e-06, 'epoch': 0.64}
 64%|██████▍   | 6644/10395 [18:58:57<10:00:35,  9.61s/it] 64%|██████▍   | 6645/10395 [18:59:04<9:20:19,  8.97s/it]                                                          {'loss': 0.8809, 'learning_rate': 6.083751813840864e-06, 'epoch': 0.64}
 64%|██████▍   | 6645/10395 [18:59:04<9:20:19,  8.97s/it] 64%|██████▍   | 6646/10395 [18:59:12<8:56:09,  8.58s/it]                                                         {'loss': 0.8466, 'learning_rate': 6.0808851410240895e-06, 'epoch': 0.64}
 64%|██████▍   | 6646/10395 [18:59:12<8:56:09,  8.58s/it] 64%|██████▍   | 6647/10395 [18:59:20<8:36:04,  8.26s/it]                                                         {'loss': 0.8853, 'learning_rate': 6.078018848666614e-06, 'epoch': 0.64}
 64%|██████▍   | 6647/10395 [18:59:20<8:36:04,  8.26s/it] 64%|██████▍   | 6648/10395 [18:59:27<8:16:19,  7.95s/it]                                                         {'loss': 0.8697, 'learning_rate': 6.075152937046685e-06, 'epoch': 0.64}
 64%|██████▍   | 6648/10395 [18:59:27<8:16:19,  7.95s/it] 64%|██████▍   | 6649/10395 [18:59:34<8:09:25,  7.84s/it]                                                         {'loss': 0.863, 'learning_rate': 6.0722874064425185e-06, 'epoch': 0.64}
 64%|██████▍   | 6649/10395 [18:59:34<8:09:25,  7.84s/it] 64%|██████▍   | 6650/10395 [18:59:42<8:04:16,  7.76s/it]                                                         {'loss': 0.8928, 'learning_rate': 6.069422257132301e-06, 'epoch': 0.64}
 64%|██████▍   | 6650/10395 [18:59:42<8:04:16,  7.76s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 64%|██████▍   | 6651/10395 [19:01:21<36:40:44, 35.27s/it]                                                          {'loss': 0.894, 'learning_rate': 6.066557489394176e-06, 'epoch': 0.64}
 64%|██████▍   | 6651/10395 [19:01:21<36:40:44, 35.27s/it] 64%|██████▍   | 6652/10395 [19:01:30<28:26:43, 27.36s/it]                                                          {'loss': 0.8887, 'learning_rate': 6.063693103506236e-06, 'epoch': 0.64}
 64%|██████▍   | 6652/10395 [19:01:30<28:26:43, 27.36s/it] 64%|██████▍   | 6653/10395 [19:01:38<22:24:23, 21.56s/it]                                                          {'loss': 0.8449, 'learning_rate': 6.06082909974656e-06, 'epoch': 0.64}
 64%|██████▍   | 6653/10395 [19:01:38<22:24:23, 21.56s/it] 64%|██████▍   | 6654/10395 [19:01:46<18:11:02, 17.50s/it]                                                          {'loss': 0.9609, 'learning_rate': 6.057965478393177e-06, 'epoch': 0.64}
 64%|██████▍   | 6654/10395 [19:01:46<18:11:02, 17.50s/it] 64%|██████▍   | 6655/10395 [19:01:54<15:08:28, 14.57s/it]                                                          {'loss': 0.7981, 'learning_rate': 6.055102239724082e-06, 'epoch': 0.64}
 64%|██████▍   | 6655/10395 [19:01:54<15:08:28, 14.57s/it] 64%|██████▍   | 6656/10395 [19:02:02<12:56:53, 12.47s/it]                                                          {'loss': 0.8131, 'learning_rate': 6.052239384017231e-06, 'epoch': 0.64}
 64%|██████▍   | 6656/10395 [19:02:02<12:56:53, 12.47s/it] 64%|██████▍   | 6657/10395 [19:02:10<11:36:08, 11.17s/it]                                                          {'loss': 0.8796, 'learning_rate': 6.049376911550542e-06, 'epoch': 0.64}
 64%|██████▍   | 6657/10395 [19:02:10<11:36:08, 11.17s/it] 64%|██████▍   | 6658/10395 [19:02:18<10:30:16, 10.12s/it]                                                          {'loss': 0.9254, 'learning_rate': 6.046514822601905e-06, 'epoch': 0.64}
 64%|██████▍   | 6658/10395 [19:02:18<10:30:16, 10.12s/it] 64%|██████▍   | 6659/10395 [19:02:25<9:45:59,  9.41s/it]                                                          {'loss': 0.8635, 'learning_rate': 6.0436531174491565e-06, 'epoch': 0.64}
 64%|██████▍   | 6659/10395 [19:02:25<9:45:59,  9.41s/it] 64%|██████▍   | 6660/10395 [19:02:33<9:06:14,  8.77s/it]                                                         {'loss': 0.8007, 'learning_rate': 6.040791796370109e-06, 'epoch': 0.64}
 64%|██████▍   | 6660/10395 [19:02:33<9:06:14,  8.77s/it] 64%|██████▍   | 6661/10395 [19:02:40<8:44:42,  8.43s/it]                                                         {'loss': 0.9144, 'learning_rate': 6.037930859642533e-06, 'epoch': 0.64}
 64%|██████▍   | 6661/10395 [19:02:40<8:44:42,  8.43s/it] 64%|██████▍   | 6662/10395 [19:02:47<8:21:41,  8.06s/it]                                                         {'loss': 0.9477, 'learning_rate': 6.0350703075441645e-06, 'epoch': 0.64}
 64%|██████▍   | 6662/10395 [19:02:47<8:21:41,  8.06s/it] 64%|██████▍   | 6663/10395 [19:02:55<8:16:24,  7.98s/it]                                                         {'loss': 0.9384, 'learning_rate': 6.032210140352695e-06, 'epoch': 0.64}
 64%|██████▍   | 6663/10395 [19:02:55<8:16:24,  7.98s/it] 64%|██████▍   | 6664/10395 [19:03:14<11:33:02, 11.15s/it]                                                          {'loss': 0.377, 'learning_rate': 6.029350358345785e-06, 'epoch': 0.64}
 64%|██████▍   | 6664/10395 [19:03:14<11:33:02, 11.15s/it] 64%|██████▍   | 6665/10395 [19:03:21<10:26:02, 10.07s/it]                                                          {'loss': 0.9143, 'learning_rate': 6.026490961801058e-06, 'epoch': 0.64}
 64%|██████▍   | 6665/10395 [19:03:21<10:26:02, 10.07s/it] 64%|██████▍   | 6666/10395 [19:03:29<9:42:49,  9.38s/it]                                                          {'loss': 0.8957, 'learning_rate': 6.023631950996101e-06, 'epoch': 0.64}
 64%|██████▍   | 6666/10395 [19:03:29<9:42:49,  9.38s/it] 64%|██████▍   | 6667/10395 [19:03:37<9:21:39,  9.04s/it]                                                         {'loss': 0.901, 'learning_rate': 6.0207733262084515e-06, 'epoch': 0.64}
 64%|██████▍   | 6667/10395 [19:03:37<9:21:39,  9.04s/it] 64%|██████▍   | 6668/10395 [19:03:45<8:55:22,  8.62s/it]                                                         {'loss': 0.9393, 'learning_rate': 6.017915087715626e-06, 'epoch': 0.64}
 64%|██████▍   | 6668/10395 [19:03:45<8:55:22,  8.62s/it] 64%|██████▍   | 6669/10395 [19:03:52<8:30:52,  8.23s/it]                                                         {'loss': 0.8924, 'learning_rate': 6.015057235795093e-06, 'epoch': 0.64}
 64%|██████▍   | 6669/10395 [19:03:52<8:30:52,  8.23s/it] 64%|██████▍   | 6670/10395 [19:04:00<8:24:12,  8.12s/it]                                                         {'loss': 0.8977, 'learning_rate': 6.012199770724287e-06, 'epoch': 0.64}
 64%|██████▍   | 6670/10395 [19:04:00<8:24:12,  8.12s/it] 64%|██████▍   | 6671/10395 [19:04:08<8:24:36,  8.13s/it]                                                         {'loss': 0.9146, 'learning_rate': 6.0093426927806074e-06, 'epoch': 0.64}
 64%|██████▍   | 6671/10395 [19:04:08<8:24:36,  8.13s/it] 64%|██████▍   | 6672/10395 [19:04:16<8:22:03,  8.09s/it]                                                         {'loss': 0.8799, 'learning_rate': 6.0064860022414085e-06, 'epoch': 0.64}
 64%|██████▍   | 6672/10395 [19:04:16<8:22:03,  8.09s/it] 64%|██████▍   | 6673/10395 [19:04:24<8:12:04,  7.93s/it]                                                         {'loss': 0.8523, 'learning_rate': 6.00362969938402e-06, 'epoch': 0.64}
 64%|██████▍   | 6673/10395 [19:04:24<8:12:04,  7.93s/it] 64%|██████▍   | 6674/10395 [19:04:32<8:07:56,  7.87s/it]                                                         {'loss': 0.8871, 'learning_rate': 6.000773784485716e-06, 'epoch': 0.64}
 64%|██████▍   | 6674/10395 [19:04:32<8:07:56,  7.87s/it] 64%|██████▍   | 6675/10395 [19:04:39<8:06:24,  7.85s/it]                                                         {'loss': 0.8402, 'learning_rate': 5.997918257823745e-06, 'epoch': 0.64}
 64%|██████▍   | 6675/10395 [19:04:39<8:06:24,  7.85s/it] 64%|██████▍   | 6676/10395 [19:04:47<7:54:47,  7.66s/it]                                                         {'loss': 0.8844, 'learning_rate': 5.995063119675319e-06, 'epoch': 0.64}
 64%|██████▍   | 6676/10395 [19:04:47<7:54:47,  7.66s/it] 64%|██████▍   | 6677/10395 [19:04:54<7:46:30,  7.53s/it]                                                         {'loss': 0.8628, 'learning_rate': 5.992208370317607e-06, 'epoch': 0.64}
 64%|██████▍   | 6677/10395 [19:04:54<7:46:30,  7.53s/it] 64%|██████▍   | 6678/10395 [19:05:03<8:15:44,  8.00s/it]                                                         {'loss': 0.8276, 'learning_rate': 5.98935401002774e-06, 'epoch': 0.64}
 64%|██████▍   | 6678/10395 [19:05:03<8:15:44,  8.00s/it] 64%|██████▍   | 6679/10395 [19:05:10<8:04:14,  7.82s/it]                                                         {'loss': 0.8677, 'learning_rate': 5.986500039082816e-06, 'epoch': 0.64}
 64%|██████▍   | 6679/10395 [19:05:10<8:04:14,  7.82s/it] 64%|██████▍   | 6680/10395 [19:05:18<7:56:37,  7.70s/it]                                                         {'loss': 0.8273, 'learning_rate': 5.983646457759891e-06, 'epoch': 0.64}
 64%|██████▍   | 6680/10395 [19:05:18<7:56:37,  7.70s/it] 64%|██████▍   | 6681/10395 [19:05:25<7:52:22,  7.63s/it]                                                         {'loss': 0.9016, 'learning_rate': 5.9807932663359895e-06, 'epoch': 0.64}
 64%|██████▍   | 6681/10395 [19:05:25<7:52:22,  7.63s/it] 64%|██████▍   | 6682/10395 [19:05:33<7:51:03,  7.61s/it]                                                         {'loss': 0.9191, 'learning_rate': 5.9779404650880835e-06, 'epoch': 0.64}
 64%|██████▍   | 6682/10395 [19:05:33<7:51:03,  7.61s/it] 64%|██████▍   | 6683/10395 [19:05:40<7:50:29,  7.60s/it]                                                         {'loss': 0.85, 'learning_rate': 5.9750880542931215e-06, 'epoch': 0.64}
 64%|██████▍   | 6683/10395 [19:05:40<7:50:29,  7.60s/it] 64%|██████▍   | 6684/10395 [19:05:48<7:54:04,  7.66s/it]                                                         {'loss': 0.988, 'learning_rate': 5.972236034228011e-06, 'epoch': 0.64}
 64%|██████▍   | 6684/10395 [19:05:48<7:54:04,  7.66s/it] 64%|██████▍   | 6685/10395 [19:05:56<7:54:38,  7.68s/it]                                                         {'loss': 0.8835, 'learning_rate': 5.96938440516962e-06, 'epoch': 0.64}
 64%|██████▍   | 6685/10395 [19:05:56<7:54:38,  7.68s/it] 64%|██████▍   | 6686/10395 [19:06:04<8:07:26,  7.89s/it]                                                         {'loss': 0.8295, 'learning_rate': 5.966533167394777e-06, 'epoch': 0.64}
 64%|██████▍   | 6686/10395 [19:06:04<8:07:26,  7.89s/it] 64%|██████▍   | 6687/10395 [19:06:12<7:58:28,  7.74s/it]                                                         {'loss': 0.8478, 'learning_rate': 5.963682321180274e-06, 'epoch': 0.64}
 64%|██████▍   | 6687/10395 [19:06:12<7:58:28,  7.74s/it] 64%|██████▍   | 6688/10395 [19:06:21<8:34:42,  8.33s/it]                                                         {'loss': 0.875, 'learning_rate': 5.960831866802868e-06, 'epoch': 0.64}
 64%|██████▍   | 6688/10395 [19:06:21<8:34:42,  8.33s/it] 64%|██████▍   | 6689/10395 [19:06:29<8:20:58,  8.11s/it]                                                         {'loss': 0.8609, 'learning_rate': 5.95798180453927e-06, 'epoch': 0.64}
 64%|██████▍   | 6689/10395 [19:06:29<8:20:58,  8.11s/it] 64%|██████▍   | 6690/10395 [19:06:36<8:09:14,  7.92s/it]                                                         {'loss': 0.9197, 'learning_rate': 5.955132134666159e-06, 'epoch': 0.64}
 64%|██████▍   | 6690/10395 [19:06:36<8:09:14,  7.92s/it] 64%|██████▍   | 6691/10395 [19:06:44<7:56:58,  7.73s/it]                                                         {'loss': 0.8496, 'learning_rate': 5.95228285746018e-06, 'epoch': 0.64}
 64%|██████▍   | 6691/10395 [19:06:44<7:56:58,  7.73s/it] 64%|██████▍   | 6692/10395 [19:06:51<7:57:46,  7.74s/it]                                                         {'loss': 0.8982, 'learning_rate': 5.94943397319793e-06, 'epoch': 0.64}
 64%|██████▍   | 6692/10395 [19:06:51<7:57:46,  7.74s/it] 64%|██████▍   | 6693/10395 [19:06:59<8:01:13,  7.80s/it]                                                         {'loss': 0.8905, 'learning_rate': 5.946585482155973e-06, 'epoch': 0.64}
 64%|██████▍   | 6693/10395 [19:06:59<8:01:13,  7.80s/it] 64%|██████▍   | 6694/10395 [19:07:07<8:00:12,  7.79s/it]                                                         {'loss': 0.905, 'learning_rate': 5.943737384610837e-06, 'epoch': 0.64}
 64%|██████▍   | 6694/10395 [19:07:07<8:00:12,  7.79s/it] 64%|██████▍   | 6695/10395 [19:07:15<7:56:06,  7.72s/it]                                                         {'loss': 0.8728, 'learning_rate': 5.940889680839008e-06, 'epoch': 0.64}
 64%|██████▍   | 6695/10395 [19:07:15<7:56:06,  7.72s/it] 64%|██████▍   | 6696/10395 [19:07:22<7:52:46,  7.67s/it]                                                         {'loss': 0.8359, 'learning_rate': 5.938042371116932e-06, 'epoch': 0.64}
 64%|██████▍   | 6696/10395 [19:07:22<7:52:46,  7.67s/it] 64%|██████▍   | 6697/10395 [19:07:30<7:45:22,  7.55s/it]                                                         {'loss': 0.8691, 'learning_rate': 5.935195455721024e-06, 'epoch': 0.64}
 64%|██████▍   | 6697/10395 [19:07:30<7:45:22,  7.55s/it] 64%|██████▍   | 6698/10395 [19:07:47<10:46:22, 10.49s/it]                                                          {'loss': 0.3142, 'learning_rate': 5.932348934927652e-06, 'epoch': 0.64}
 64%|██████▍   | 6698/10395 [19:07:47<10:46:22, 10.49s/it] 64%|██████▍   | 6699/10395 [19:07:54<9:49:32,  9.57s/it]                                                          {'loss': 0.7621, 'learning_rate': 5.9295028090131545e-06, 'epoch': 0.64}
 64%|██████▍   | 6699/10395 [19:07:54<9:49:32,  9.57s/it] 64%|██████▍   | 6700/10395 [19:08:02<9:11:33,  8.96s/it]                                                         {'loss': 0.8928, 'learning_rate': 5.926657078253826e-06, 'epoch': 0.64}
 64%|██████▍   | 6700/10395 [19:08:02<9:11:33,  8.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 64%|██████▍   | 6701/10395 [19:09:42<37:13:21, 36.28s/it]                                                          {'loss': 0.9248, 'learning_rate': 5.923811742925923e-06, 'epoch': 0.64}
 64%|██████▍   | 6701/10395 [19:09:42<37:13:21, 36.28s/it] 64%|██████▍   | 6702/10395 [19:09:49<28:18:48, 27.60s/it]                                                          {'loss': 0.8727, 'learning_rate': 5.920966803305664e-06, 'epoch': 0.64}
 64%|██████▍   | 6702/10395 [19:09:49<28:18:48, 27.60s/it] 64%|██████▍   | 6703/10395 [19:09:56<22:00:57, 21.47s/it]                                                          {'loss': 0.9071, 'learning_rate': 5.9181222596692345e-06, 'epoch': 0.64}
 64%|██████▍   | 6703/10395 [19:09:56<22:00:57, 21.47s/it] 64%|██████▍   | 6704/10395 [19:10:04<17:46:11, 17.33s/it]                                                          {'loss': 0.9129, 'learning_rate': 5.91527811229277e-06, 'epoch': 0.64}
 64%|██████▍   | 6704/10395 [19:10:04<17:46:11, 17.33s/it] 65%|██████▍   | 6705/10395 [19:10:13<15:16:04, 14.90s/it]                                                          {'loss': 0.8907, 'learning_rate': 5.912434361452379e-06, 'epoch': 0.64}
 65%|██████▍   | 6705/10395 [19:10:13<15:16:04, 14.90s/it] 65%|██████▍   | 6706/10395 [19:10:21<13:10:17, 12.85s/it]                                                          {'loss': 0.9316, 'learning_rate': 5.9095910074241215e-06, 'epoch': 0.65}
 65%|██████▍   | 6706/10395 [19:10:21<13:10:17, 12.85s/it] 65%|██████▍   | 6707/10395 [19:10:29<11:38:22, 11.36s/it]                                                          {'loss': 0.9095, 'learning_rate': 5.90674805048403e-06, 'epoch': 0.65}
 65%|██████▍   | 6707/10395 [19:10:29<11:38:22, 11.36s/it] 65%|██████▍   | 6708/10395 [19:10:37<10:40:07, 10.42s/it]                                                          {'loss': 0.8104, 'learning_rate': 5.903905490908091e-06, 'epoch': 0.65}
 65%|██████▍   | 6708/10395 [19:10:37<10:40:07, 10.42s/it] 65%|██████▍   | 6709/10395 [19:10:46<10:01:29,  9.79s/it]                                                          {'loss': 0.7803, 'learning_rate': 5.901063328972253e-06, 'epoch': 0.65}
 65%|██████▍   | 6709/10395 [19:10:46<10:01:29,  9.79s/it] 65%|██████▍   | 6710/10395 [19:11:04<12:34:40, 12.29s/it]                                                          {'loss': 0.3647, 'learning_rate': 5.89822156495243e-06, 'epoch': 0.65}
 65%|██████▍   | 6710/10395 [19:11:04<12:34:40, 12.29s/it] 65%|██████▍   | 6711/10395 [19:11:11<11:05:51, 10.84s/it]                                                          {'loss': 0.8834, 'learning_rate': 5.8953801991244895e-06, 'epoch': 0.65}
 65%|██████▍   | 6711/10395 [19:11:11<11:05:51, 10.84s/it] 65%|██████▍   | 6712/10395 [19:11:19<10:01:09,  9.79s/it]                                                          {'loss': 0.8917, 'learning_rate': 5.892539231764268e-06, 'epoch': 0.65}
 65%|██████▍   | 6712/10395 [19:11:19<10:01:09,  9.79s/it] 65%|██████▍   | 6713/10395 [19:11:27<9:33:25,  9.34s/it]                                                          {'loss': 0.8475, 'learning_rate': 5.88969866314756e-06, 'epoch': 0.65}
 65%|██████▍   | 6713/10395 [19:11:27<9:33:25,  9.34s/it] 65%|██████▍   | 6714/10395 [19:11:35<9:00:13,  8.81s/it]                                                         {'loss': 0.8258, 'learning_rate': 5.88685849355012e-06, 'epoch': 0.65}
 65%|██████▍   | 6714/10395 [19:11:35<9:00:13,  8.81s/it] 65%|██████▍   | 6715/10395 [19:11:42<8:36:24,  8.42s/it]                                                         {'loss': 0.8784, 'learning_rate': 5.884018723247671e-06, 'epoch': 0.65}
 65%|██████▍   | 6715/10395 [19:11:42<8:36:24,  8.42s/it] 65%|██████▍   | 6716/10395 [19:11:51<8:36:13,  8.42s/it]                                                         {'loss': 0.8694, 'learning_rate': 5.8811793525158864e-06, 'epoch': 0.65}
 65%|██████▍   | 6716/10395 [19:11:51<8:36:13,  8.42s/it] 65%|██████▍   | 6717/10395 [19:11:58<8:11:43,  8.02s/it]                                                         {'loss': 0.9099, 'learning_rate': 5.878340381630412e-06, 'epoch': 0.65}
 65%|██████▍   | 6717/10395 [19:11:58<8:11:43,  8.02s/it] 65%|██████▍   | 6718/10395 [19:12:06<8:19:24,  8.15s/it]                                                         {'loss': 0.932, 'learning_rate': 5.875501810866842e-06, 'epoch': 0.65}
 65%|██████▍   | 6718/10395 [19:12:06<8:19:24,  8.15s/it] 65%|██████▍   | 6719/10395 [19:12:14<8:19:50,  8.16s/it]                                                         {'loss': 0.894, 'learning_rate': 5.872663640500742e-06, 'epoch': 0.65}
 65%|██████▍   | 6719/10395 [19:12:14<8:19:50,  8.16s/it] 65%|██████▍   | 6720/10395 [19:12:22<8:11:12,  8.02s/it]                                                         {'loss': 0.9195, 'learning_rate': 5.869825870807638e-06, 'epoch': 0.65}
 65%|██████▍   | 6720/10395 [19:12:22<8:11:12,  8.02s/it] 65%|██████▍   | 6721/10395 [19:12:30<8:09:59,  8.00s/it]                                                         {'loss': 0.9135, 'learning_rate': 5.866988502063009e-06, 'epoch': 0.65}
 65%|██████▍   | 6721/10395 [19:12:30<8:09:59,  8.00s/it] 65%|██████▍   | 6722/10395 [19:12:38<8:20:27,  8.18s/it]                                                         {'loss': 0.8795, 'learning_rate': 5.864151534542304e-06, 'epoch': 0.65}
 65%|██████▍   | 6722/10395 [19:12:38<8:20:27,  8.18s/it] 65%|██████▍   | 6723/10395 [19:12:46<8:06:21,  7.95s/it]                                                         {'loss': 0.8742, 'learning_rate': 5.8613149685209305e-06, 'epoch': 0.65}
 65%|██████▍   | 6723/10395 [19:12:46<8:06:21,  7.95s/it] 65%|██████▍   | 6724/10395 [19:12:54<8:09:24,  8.00s/it]                                                         {'loss': 0.8381, 'learning_rate': 5.858478804274257e-06, 'epoch': 0.65}
 65%|██████▍   | 6724/10395 [19:12:54<8:09:24,  8.00s/it] 65%|██████▍   | 6725/10395 [19:13:02<8:16:05,  8.11s/it]                                                         {'loss': 0.7505, 'learning_rate': 5.8556430420776115e-06, 'epoch': 0.65}
 65%|██████▍   | 6725/10395 [19:13:02<8:16:05,  8.11s/it] 65%|██████▍   | 6726/10395 [19:13:10<8:05:58,  7.95s/it]                                                         {'loss': 0.8683, 'learning_rate': 5.85280768220628e-06, 'epoch': 0.65}
 65%|██████▍   | 6726/10395 [19:13:10<8:05:58,  7.95s/it] 65%|██████▍   | 6727/10395 [19:13:18<8:08:53,  8.00s/it]                                                         {'loss': 0.8835, 'learning_rate': 5.849972724935518e-06, 'epoch': 0.65}
 65%|██████▍   | 6727/10395 [19:13:18<8:08:53,  8.00s/it] 65%|██████▍   | 6728/10395 [19:13:26<7:59:08,  7.84s/it]                                                         {'loss': 0.8442, 'learning_rate': 5.847138170540535e-06, 'epoch': 0.65}
 65%|██████▍   | 6728/10395 [19:13:26<7:59:08,  7.84s/it] 65%|██████▍   | 6729/10395 [19:13:33<7:43:41,  7.59s/it]                                                         {'loss': 0.9512, 'learning_rate': 5.844304019296501e-06, 'epoch': 0.65}
 65%|██████▍   | 6729/10395 [19:13:33<7:43:41,  7.59s/it] 65%|██████▍   | 6730/10395 [19:13:41<8:01:20,  7.88s/it]                                                         {'loss': 0.9049, 'learning_rate': 5.841470271478555e-06, 'epoch': 0.65}
 65%|██████▍   | 6730/10395 [19:13:41<8:01:20,  7.88s/it] 65%|██████▍   | 6731/10395 [19:13:50<8:27:50,  8.32s/it]                                                         {'loss': 0.8761, 'learning_rate': 5.838636927361787e-06, 'epoch': 0.65}
 65%|██████▍   | 6731/10395 [19:13:50<8:27:50,  8.32s/it] 65%|██████▍   | 6732/10395 [19:13:58<8:18:22,  8.16s/it]                                                         {'loss': 0.9142, 'learning_rate': 5.8358039872212554e-06, 'epoch': 0.65}
 65%|██████▍   | 6732/10395 [19:13:58<8:18:22,  8.16s/it] 65%|██████▍   | 6733/10395 [19:14:06<8:14:49,  8.11s/it]                                                         {'loss': 0.8596, 'learning_rate': 5.832971451331975e-06, 'epoch': 0.65}
 65%|██████▍   | 6733/10395 [19:14:06<8:14:49,  8.11s/it] 65%|██████▍   | 6734/10395 [19:14:14<8:06:49,  7.98s/it]                                                         {'loss': 0.9351, 'learning_rate': 5.830139319968917e-06, 'epoch': 0.65}
 65%|██████▍   | 6734/10395 [19:14:14<8:06:49,  7.98s/it] 65%|██████▍   | 6735/10395 [19:14:22<8:07:54,  8.00s/it]                                                         {'loss': 0.8129, 'learning_rate': 5.827307593407021e-06, 'epoch': 0.65}
 65%|██████▍   | 6735/10395 [19:14:22<8:07:54,  8.00s/it] 65%|██████▍   | 6736/10395 [19:14:29<7:53:33,  7.77s/it]                                                         {'loss': 0.8032, 'learning_rate': 5.824476271921193e-06, 'epoch': 0.65}
 65%|██████▍   | 6736/10395 [19:14:29<7:53:33,  7.77s/it] 65%|██████▍   | 6737/10395 [19:14:37<7:46:37,  7.65s/it]                                                         {'loss': 0.8587, 'learning_rate': 5.821645355786281e-06, 'epoch': 0.65}
 65%|██████▍   | 6737/10395 [19:14:37<7:46:37,  7.65s/it] 65%|██████▍   | 6738/10395 [19:14:45<7:55:40,  7.80s/it]                                                         {'loss': 0.7908, 'learning_rate': 5.818814845277111e-06, 'epoch': 0.65}
 65%|██████▍   | 6738/10395 [19:14:45<7:55:40,  7.80s/it] 65%|██████▍   | 6739/10395 [19:14:52<7:54:39,  7.79s/it]                                                         {'loss': 0.8467, 'learning_rate': 5.8159847406684615e-06, 'epoch': 0.65}
 65%|██████▍   | 6739/10395 [19:14:52<7:54:39,  7.79s/it] 65%|██████▍   | 6740/10395 [19:15:00<7:53:23,  7.77s/it]                                                         {'loss': 0.8668, 'learning_rate': 5.813155042235068e-06, 'epoch': 0.65}
 65%|██████▍   | 6740/10395 [19:15:00<7:53:23,  7.77s/it] 65%|██████▍   | 6741/10395 [19:15:08<7:46:51,  7.67s/it]                                                         {'loss': 0.8682, 'learning_rate': 5.81032575025164e-06, 'epoch': 0.65}
 65%|██████▍   | 6741/10395 [19:15:08<7:46:51,  7.67s/it] 65%|██████▍   | 6742/10395 [19:15:15<7:38:34,  7.53s/it]                                                         {'loss': 0.8617, 'learning_rate': 5.8074968649928305e-06, 'epoch': 0.65}
 65%|██████▍   | 6742/10395 [19:15:15<7:38:34,  7.53s/it] 65%|██████▍   | 6743/10395 [19:15:23<7:53:48,  7.78s/it]                                                         {'loss': 0.8939, 'learning_rate': 5.804668386733266e-06, 'epoch': 0.65}
 65%|██████▍   | 6743/10395 [19:15:23<7:53:48,  7.78s/it] 65%|██████▍   | 6744/10395 [19:15:31<7:56:45,  7.83s/it]                                                         {'loss': 0.8169, 'learning_rate': 5.801840315747534e-06, 'epoch': 0.65}
 65%|██████▍   | 6744/10395 [19:15:31<7:56:45,  7.83s/it] 65%|██████▍   | 6745/10395 [19:15:39<8:01:46,  7.92s/it]                                                         {'loss': 0.88, 'learning_rate': 5.799012652310168e-06, 'epoch': 0.65}
 65%|██████▍   | 6745/10395 [19:15:39<8:01:46,  7.92s/it] 65%|██████▍   | 6746/10395 [19:15:47<7:50:57,  7.74s/it]                                                         {'loss': 0.9299, 'learning_rate': 5.79618539669568e-06, 'epoch': 0.65}
 65%|██████▍   | 6746/10395 [19:15:47<7:50:57,  7.74s/it] 65%|██████▍   | 6747/10395 [19:15:56<8:12:58,  8.11s/it]                                                         {'loss': 0.8361, 'learning_rate': 5.79335854917853e-06, 'epoch': 0.65}
 65%|██████▍   | 6747/10395 [19:15:56<8:12:58,  8.11s/it] 65%|██████▍   | 6748/10395 [19:16:03<7:57:34,  7.86s/it]                                                         {'loss': 0.905, 'learning_rate': 5.790532110033138e-06, 'epoch': 0.65}
 65%|██████▍   | 6748/10395 [19:16:03<7:57:34,  7.86s/it] 65%|██████▍   | 6749/10395 [19:16:10<7:50:58,  7.75s/it]                                                         {'loss': 0.87, 'learning_rate': 5.787706079533898e-06, 'epoch': 0.65}
 65%|██████▍   | 6749/10395 [19:16:10<7:50:58,  7.75s/it] 65%|██████▍   | 6750/10395 [19:16:20<8:19:06,  8.22s/it]                                                         {'loss': 0.7602, 'learning_rate': 5.7848804579551466e-06, 'epoch': 0.65}
 65%|██████▍   | 6750/10395 [19:16:20<8:19:06,  8.22s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 65%|██████▍   | 6751/10395 [19:18:00<36:18:56, 35.88s/it]                                                          {'loss': 0.8717, 'learning_rate': 5.782055245571191e-06, 'epoch': 0.65}
 65%|██████▍   | 6751/10395 [19:18:00<36:18:56, 35.88s/it] 65%|██████▍   | 6752/10395 [19:18:09<28:13:43, 27.90s/it]                                                          {'loss': 0.8846, 'learning_rate': 5.779230442656303e-06, 'epoch': 0.65}
 65%|██████▍   | 6752/10395 [19:18:09<28:13:43, 27.90s/it] 65%|██████▍   | 6753/10395 [19:18:17<22:08:33, 21.89s/it]                                                          {'loss': 0.8253, 'learning_rate': 5.7764060494847e-06, 'epoch': 0.65}
 65%|██████▍   | 6753/10395 [19:18:17<22:08:33, 21.89s/it] 65%|██████▍   | 6754/10395 [19:18:25<17:49:53, 17.63s/it]                                                          {'loss': 0.855, 'learning_rate': 5.773582066330577e-06, 'epoch': 0.65}
 65%|██████▍   | 6754/10395 [19:18:25<17:49:53, 17.63s/it] 65%|██████▍   | 6755/10395 [19:18:43<17:49:15, 17.63s/it]                                                          {'loss': 0.3344, 'learning_rate': 5.770758493468073e-06, 'epoch': 0.65}
 65%|██████▍   | 6755/10395 [19:18:43<17:49:15, 17.63s/it] 65%|██████▍   | 6756/10395 [19:18:50<14:44:55, 14.59s/it]                                                          {'loss': 0.7999, 'learning_rate': 5.767935331171293e-06, 'epoch': 0.65}
 65%|██████▍   | 6756/10395 [19:18:50<14:44:55, 14.59s/it] 65%|██████▌   | 6757/10395 [19:18:58<12:36:03, 12.47s/it]                                                          {'loss': 0.9534, 'learning_rate': 5.7651125797143114e-06, 'epoch': 0.65}
 65%|██████▌   | 6757/10395 [19:18:58<12:36:03, 12.47s/it] 65%|██████▌   | 6758/10395 [19:19:05<11:06:53, 11.00s/it]                                                          {'loss': 0.9292, 'learning_rate': 5.762290239371147e-06, 'epoch': 0.65}
 65%|██████▌   | 6758/10395 [19:19:05<11:06:53, 11.00s/it] 65%|██████▌   | 6759/10395 [19:19:15<10:48:24, 10.70s/it]                                                          {'loss': 0.8045, 'learning_rate': 5.75946831041579e-06, 'epoch': 0.65}
 65%|██████▌   | 6759/10395 [19:19:15<10:48:24, 10.70s/it] 65%|██████▌   | 6760/10395 [19:19:22<9:40:17,  9.58s/it]                                                          {'loss': 0.9774, 'learning_rate': 5.756646793122191e-06, 'epoch': 0.65}
 65%|██████▌   | 6760/10395 [19:19:22<9:40:17,  9.58s/it] 65%|██████▌   | 6761/10395 [19:19:30<9:09:31,  9.07s/it]                                                         {'loss': 0.8943, 'learning_rate': 5.753825687764254e-06, 'epoch': 0.65}
 65%|██████▌   | 6761/10395 [19:19:30<9:09:31,  9.07s/it] 65%|██████▌   | 6762/10395 [19:19:38<8:53:09,  8.81s/it]                                                         {'loss': 0.8916, 'learning_rate': 5.751004994615841e-06, 'epoch': 0.65}
 65%|██████▌   | 6762/10395 [19:19:38<8:53:09,  8.81s/it] 65%|██████▌   | 6763/10395 [19:19:46<8:30:03,  8.43s/it]                                                         {'loss': 0.8123, 'learning_rate': 5.748184713950786e-06, 'epoch': 0.65}
 65%|██████▌   | 6763/10395 [19:19:46<8:30:03,  8.43s/it] 65%|██████▌   | 6764/10395 [19:19:53<8:08:13,  8.07s/it]                                                         {'loss': 0.9274, 'learning_rate': 5.745364846042869e-06, 'epoch': 0.65}
 65%|██████▌   | 6764/10395 [19:19:53<8:08:13,  8.07s/it] 65%|██████▌   | 6765/10395 [19:20:00<7:58:48,  7.91s/it]                                                         {'loss': 0.8961, 'learning_rate': 5.742545391165845e-06, 'epoch': 0.65}
 65%|██████▌   | 6765/10395 [19:20:01<7:58:48,  7.91s/it] 65%|██████▌   | 6766/10395 [19:20:18<10:56:38, 10.86s/it]                                                          {'loss': 0.363, 'learning_rate': 5.739726349593413e-06, 'epoch': 0.65}
 65%|██████▌   | 6766/10395 [19:20:18<10:56:38, 10.86s/it] 65%|██████▌   | 6767/10395 [19:20:27<10:13:40, 10.15s/it]                                                          {'loss': 0.8514, 'learning_rate': 5.7369077215992415e-06, 'epoch': 0.65}
 65%|██████▌   | 6767/10395 [19:20:27<10:13:40, 10.15s/it] 65%|██████▌   | 6768/10395 [19:20:35<9:40:44,  9.61s/it]                                                          {'loss': 0.8686, 'learning_rate': 5.734089507456963e-06, 'epoch': 0.65}
 65%|██████▌   | 6768/10395 [19:20:35<9:40:44,  9.61s/it] 65%|██████▌   | 6769/10395 [19:20:43<9:18:23,  9.24s/it]                                                         {'loss': 0.8706, 'learning_rate': 5.731271707440158e-06, 'epoch': 0.65}
 65%|██████▌   | 6769/10395 [19:20:43<9:18:23,  9.24s/it] 65%|██████▌   | 6770/10395 [19:20:51<8:56:21,  8.88s/it]                                                         {'loss': 0.9142, 'learning_rate': 5.72845432182237e-06, 'epoch': 0.65}
 65%|██████▌   | 6770/10395 [19:20:51<8:56:21,  8.88s/it] 65%|██████▌   | 6771/10395 [19:20:59<8:32:49,  8.49s/it]                                                         {'loss': 0.8842, 'learning_rate': 5.725637350877111e-06, 'epoch': 0.65}
 65%|██████▌   | 6771/10395 [19:20:59<8:32:49,  8.49s/it] 65%|██████▌   | 6772/10395 [19:21:07<8:28:53,  8.43s/it]                                                         {'loss': 0.7693, 'learning_rate': 5.7228207948778416e-06, 'epoch': 0.65}
 65%|██████▌   | 6772/10395 [19:21:07<8:28:53,  8.43s/it] 65%|██████▌   | 6773/10395 [19:21:17<8:43:17,  8.67s/it]                                                         {'loss': 0.8742, 'learning_rate': 5.720004654097993e-06, 'epoch': 0.65}
 65%|██████▌   | 6773/10395 [19:21:17<8:43:17,  8.67s/it] 65%|██████▌   | 6774/10395 [19:21:24<8:20:26,  8.29s/it]                                                         {'loss': 0.8655, 'learning_rate': 5.71718892881094e-06, 'epoch': 0.65}
 65%|██████▌   | 6774/10395 [19:21:24<8:20:26,  8.29s/it] 65%|██████▌   | 6775/10395 [19:21:31<7:59:42,  7.95s/it]                                                         {'loss': 0.9008, 'learning_rate': 5.714373619290034e-06, 'epoch': 0.65}
 65%|██████▌   | 6775/10395 [19:21:31<7:59:42,  7.95s/it] 65%|██████▌   | 6776/10395 [19:21:38<7:47:49,  7.76s/it]                                                         {'loss': 0.8859, 'learning_rate': 5.711558725808583e-06, 'epoch': 0.65}
 65%|██████▌   | 6776/10395 [19:21:38<7:47:49,  7.76s/it] 65%|██████▌   | 6777/10395 [19:21:47<7:54:12,  7.86s/it]                                                         {'loss': 0.8581, 'learning_rate': 5.708744248639848e-06, 'epoch': 0.65}
 65%|██████▌   | 6777/10395 [19:21:47<7:54:12,  7.86s/it] 65%|██████▌   | 6778/10395 [19:21:54<7:53:00,  7.85s/it]                                                         {'loss': 0.7944, 'learning_rate': 5.705930188057045e-06, 'epoch': 0.65}
 65%|██████▌   | 6778/10395 [19:21:54<7:53:00,  7.85s/it] 65%|██████▌   | 6779/10395 [19:22:03<7:59:50,  7.96s/it]                                                         {'loss': 0.8952, 'learning_rate': 5.703116544333367e-06, 'epoch': 0.65}
 65%|██████▌   | 6779/10395 [19:22:03<7:59:50,  7.96s/it] 65%|██████▌   | 6780/10395 [19:22:10<7:52:20,  7.84s/it]                                                         {'loss': 0.9289, 'learning_rate': 5.700303317741949e-06, 'epoch': 0.65}
 65%|██████▌   | 6780/10395 [19:22:10<7:52:20,  7.84s/it] 65%|██████▌   | 6781/10395 [19:22:19<8:08:48,  8.12s/it]                                                         {'loss': 0.8681, 'learning_rate': 5.697490508555897e-06, 'epoch': 0.65}
 65%|██████▌   | 6781/10395 [19:22:19<8:08:48,  8.12s/it] 65%|██████▌   | 6782/10395 [19:22:27<8:14:32,  8.21s/it]                                                         {'loss': 0.9012, 'learning_rate': 5.694678117048275e-06, 'epoch': 0.65}
 65%|██████▌   | 6782/10395 [19:22:27<8:14:32,  8.21s/it] 65%|██████▌   | 6783/10395 [19:22:36<8:14:45,  8.22s/it]                                                         {'loss': 0.9107, 'learning_rate': 5.691866143492101e-06, 'epoch': 0.65}
 65%|██████▌   | 6783/10395 [19:22:36<8:14:45,  8.22s/it] 65%|██████▌   | 6784/10395 [19:22:44<8:10:06,  8.14s/it]                                                         {'loss': 0.8969, 'learning_rate': 5.689054588160352e-06, 'epoch': 0.65}
 65%|██████▌   | 6784/10395 [19:22:44<8:10:06,  8.14s/it] 65%|██████▌   | 6785/10395 [19:22:52<8:08:58,  8.13s/it]                                                         {'loss': 0.8525, 'learning_rate': 5.686243451325973e-06, 'epoch': 0.65}
 65%|██████▌   | 6785/10395 [19:22:52<8:08:58,  8.13s/it] 65%|██████▌   | 6786/10395 [19:22:59<8:01:11,  8.00s/it]                                                         {'loss': 0.9529, 'learning_rate': 5.68343273326186e-06, 'epoch': 0.65}
 65%|██████▌   | 6786/10395 [19:22:59<8:01:11,  8.00s/it] 65%|██████▌   | 6787/10395 [19:23:07<7:49:46,  7.81s/it]                                                         {'loss': 0.9337, 'learning_rate': 5.680622434240874e-06, 'epoch': 0.65}
 65%|██████▌   | 6787/10395 [19:23:07<7:49:46,  7.81s/it] 65%|██████▌   | 6788/10395 [19:23:14<7:45:02,  7.74s/it]                                                         {'loss': 0.8982, 'learning_rate': 5.67781255453583e-06, 'epoch': 0.65}
 65%|██████▌   | 6788/10395 [19:23:14<7:45:02,  7.74s/it] 65%|██████▌   | 6789/10395 [19:23:22<7:42:59,  7.70s/it]                                                         {'loss': 0.8518, 'learning_rate': 5.675003094419504e-06, 'epoch': 0.65}
 65%|██████▌   | 6789/10395 [19:23:22<7:42:59,  7.70s/it] 65%|██████▌   | 6790/10395 [19:23:31<8:08:02,  8.12s/it]                                                         {'loss': 0.7752, 'learning_rate': 5.6721940541646415e-06, 'epoch': 0.65}
 65%|██████▌   | 6790/10395 [19:23:31<8:08:02,  8.12s/it] 65%|██████▌   | 6791/10395 [19:23:38<7:56:27,  7.93s/it]                                                         {'loss': 0.9122, 'learning_rate': 5.669385434043931e-06, 'epoch': 0.65}
 65%|██████▌   | 6791/10395 [19:23:38<7:56:27,  7.93s/it] 65%|██████▌   | 6792/10395 [19:23:46<7:52:23,  7.87s/it]                                                         {'loss': 0.8377, 'learning_rate': 5.666577234330024e-06, 'epoch': 0.65}
 65%|██████▌   | 6792/10395 [19:23:46<7:52:23,  7.87s/it] 65%|██████▌   | 6793/10395 [19:23:54<7:50:08,  7.83s/it]                                                         {'loss': 0.9011, 'learning_rate': 5.663769455295542e-06, 'epoch': 0.65}
 65%|██████▌   | 6793/10395 [19:23:54<7:50:08,  7.83s/it] 65%|██████▌   | 6794/10395 [19:24:02<7:47:23,  7.79s/it]                                                         {'loss': 0.9227, 'learning_rate': 5.660962097213052e-06, 'epoch': 0.65}
 65%|██████▌   | 6794/10395 [19:24:02<7:47:23,  7.79s/it] 65%|██████▌   | 6795/10395 [19:24:09<7:47:07,  7.79s/it]                                                         {'loss': 0.9609, 'learning_rate': 5.658155160355092e-06, 'epoch': 0.65}
 65%|██████▌   | 6795/10395 [19:24:09<7:47:07,  7.79s/it] 65%|██████▌   | 6796/10395 [19:24:17<7:52:21,  7.87s/it]                                                         {'loss': 0.9004, 'learning_rate': 5.655348644994146e-06, 'epoch': 0.65}
 65%|██████▌   | 6796/10395 [19:24:17<7:52:21,  7.87s/it] 65%|██████▌   | 6797/10395 [19:24:25<7:46:01,  7.77s/it]                                                         {'loss': 0.9215, 'learning_rate': 5.65254255140267e-06, 'epoch': 0.65}
 65%|██████▌   | 6797/10395 [19:24:25<7:46:01,  7.77s/it] 65%|██████▌   | 6798/10395 [19:24:33<7:49:46,  7.84s/it]                                                         {'loss': 0.869, 'learning_rate': 5.649736879853081e-06, 'epoch': 0.65}
 65%|██████▌   | 6798/10395 [19:24:33<7:49:46,  7.84s/it] 65%|██████▌   | 6799/10395 [19:24:41<7:51:51,  7.87s/it]                                                         {'loss': 0.8856, 'learning_rate': 5.646931630617729e-06, 'epoch': 0.65}
 65%|██████▌   | 6799/10395 [19:24:41<7:51:51,  7.87s/it] 65%|██████▌   | 6800/10395 [19:24:49<7:51:10,  7.86s/it]                                                         {'loss': 0.8866, 'learning_rate': 5.644126803968953e-06, 'epoch': 0.65}
 65%|██████▌   | 6800/10395 [19:24:49<7:51:10,  7.86s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 65%|██████▌   | 6801/10395 [19:26:32<36:22:49, 36.44s/it]                                                          {'loss': 0.8982, 'learning_rate': 5.641322400179044e-06, 'epoch': 0.65}
 65%|██████▌   | 6801/10395 [19:26:32<36:22:49, 36.44s/it] 65%|██████▌   | 6802/10395 [19:26:39<27:40:17, 27.73s/it]                                                          {'loss': 0.9137, 'learning_rate': 5.638518419520234e-06, 'epoch': 0.65}
 65%|██████▌   | 6802/10395 [19:26:39<27:40:17, 27.73s/it] 65%|██████▌   | 6803/10395 [19:26:47<21:43:05, 21.77s/it]                                                          {'loss': 0.8377, 'learning_rate': 5.635714862264743e-06, 'epoch': 0.65}
 65%|██████▌   | 6803/10395 [19:26:47<21:43:05, 21.77s/it] 65%|██████▌   | 6804/10395 [19:26:54<17:22:28, 17.42s/it]                                                          {'loss': 0.8553, 'learning_rate': 5.63291172868472e-06, 'epoch': 0.65}
 65%|██████▌   | 6804/10395 [19:26:54<17:22:28, 17.42s/it] 65%|██████▌   | 6805/10395 [19:27:02<14:27:39, 14.50s/it]                                                          {'loss': 0.9433, 'learning_rate': 5.6301090190523e-06, 'epoch': 0.65}
 65%|██████▌   | 6805/10395 [19:27:02<14:27:39, 14.50s/it] 65%|██████▌   | 6806/10395 [19:27:10<12:21:21, 12.39s/it]                                                          {'loss': 0.8781, 'learning_rate': 5.627306733639557e-06, 'epoch': 0.65}
 65%|██████▌   | 6806/10395 [19:27:10<12:21:21, 12.39s/it] 65%|██████▌   | 6807/10395 [19:27:17<10:59:22, 11.03s/it]                                                          {'loss': 0.8923, 'learning_rate': 5.624504872718528e-06, 'epoch': 0.65}
 65%|██████▌   | 6807/10395 [19:27:17<10:59:22, 11.03s/it] 65%|██████▌   | 6808/10395 [19:27:25<9:58:37, 10.01s/it]                                                          {'loss': 0.8444, 'learning_rate': 5.621703436561215e-06, 'epoch': 0.65}
 65%|██████▌   | 6808/10395 [19:27:25<9:58:37, 10.01s/it] 66%|██████▌   | 6809/10395 [19:27:32<9:06:25,  9.14s/it]                                                         {'loss': 0.9199, 'learning_rate': 5.618902425439581e-06, 'epoch': 0.65}
 66%|██████▌   | 6809/10395 [19:27:32<9:06:25,  9.14s/it] 66%|██████▌   | 6810/10395 [19:27:40<8:46:59,  8.82s/it]                                                         {'loss': 0.881, 'learning_rate': 5.616101839625532e-06, 'epoch': 0.66}
 66%|██████▌   | 6810/10395 [19:27:40<8:46:59,  8.82s/it] 66%|██████▌   | 6811/10395 [19:27:48<8:18:13,  8.34s/it]                                                         {'loss': 0.9404, 'learning_rate': 5.613301679390952e-06, 'epoch': 0.66}
 66%|██████▌   | 6811/10395 [19:27:48<8:18:13,  8.34s/it] 66%|██████▌   | 6812/10395 [19:27:55<8:02:57,  8.09s/it]                                                         {'loss': 0.8931, 'learning_rate': 5.610501945007667e-06, 'epoch': 0.66}
 66%|██████▌   | 6812/10395 [19:27:55<8:02:57,  8.09s/it] 66%|██████▌   | 6813/10395 [19:28:02<7:50:44,  7.89s/it]                                                         {'loss': 0.8975, 'learning_rate': 5.607702636747477e-06, 'epoch': 0.66}
 66%|██████▌   | 6813/10395 [19:28:02<7:50:44,  7.89s/it] 66%|██████▌   | 6814/10395 [19:28:10<7:46:42,  7.82s/it]                                                         {'loss': 0.8649, 'learning_rate': 5.604903754882128e-06, 'epoch': 0.66}
 66%|██████▌   | 6814/10395 [19:28:10<7:46:42,  7.82s/it] 66%|██████▌   | 6815/10395 [19:28:18<7:40:59,  7.73s/it]                                                         {'loss': 0.8208, 'learning_rate': 5.602105299683327e-06, 'epoch': 0.66}
 66%|██████▌   | 6815/10395 [19:28:18<7:40:59,  7.73s/it] 66%|██████▌   | 6816/10395 [19:28:25<7:40:47,  7.72s/it]                                                         {'loss': 0.8858, 'learning_rate': 5.5993072714227445e-06, 'epoch': 0.66}
 66%|██████▌   | 6816/10395 [19:28:25<7:40:47,  7.72s/it] 66%|██████▌   | 6817/10395 [19:28:34<7:53:12,  7.94s/it]                                                         {'loss': 0.903, 'learning_rate': 5.596509670372012e-06, 'epoch': 0.66}
 66%|██████▌   | 6817/10395 [19:28:34<7:53:12,  7.94s/it] 66%|██████▌   | 6818/10395 [19:28:42<8:00:12,  8.05s/it]                                                         {'loss': 0.8789, 'learning_rate': 5.593712496802707e-06, 'epoch': 0.66}
 66%|██████▌   | 6818/10395 [19:28:42<8:00:12,  8.05s/it] 66%|██████▌   | 6819/10395 [19:28:49<7:37:51,  7.68s/it]                                                         {'loss': 0.931, 'learning_rate': 5.59091575098638e-06, 'epoch': 0.66}
 66%|██████▌   | 6819/10395 [19:28:49<7:37:51,  7.68s/it] 66%|██████▌   | 6820/10395 [19:28:57<7:38:18,  7.69s/it]                                                         {'loss': 0.8384, 'learning_rate': 5.58811943319453e-06, 'epoch': 0.66}
 66%|██████▌   | 6820/10395 [19:28:57<7:38:18,  7.69s/it] 66%|██████▌   | 6821/10395 [19:29:04<7:35:25,  7.65s/it]                                                         {'loss': 0.8005, 'learning_rate': 5.585323543698612e-06, 'epoch': 0.66}
 66%|██████▌   | 6821/10395 [19:29:04<7:35:25,  7.65s/it] 66%|██████▌   | 6822/10395 [19:29:12<7:34:18,  7.63s/it]                                                         {'loss': 0.9145, 'learning_rate': 5.582528082770056e-06, 'epoch': 0.66}
 66%|██████▌   | 6822/10395 [19:29:12<7:34:18,  7.63s/it] 66%|██████▌   | 6823/10395 [19:29:22<8:16:30,  8.34s/it]                                                         {'loss': 0.8116, 'learning_rate': 5.579733050680227e-06, 'epoch': 0.66}
 66%|██████▌   | 6823/10395 [19:29:22<8:16:30,  8.34s/it] 66%|██████▌   | 6824/10395 [19:29:29<8:02:35,  8.11s/it]                                                         {'loss': 0.877, 'learning_rate': 5.576938447700469e-06, 'epoch': 0.66}
 66%|██████▌   | 6824/10395 [19:29:29<8:02:35,  8.11s/it] 66%|██████▌   | 6825/10395 [19:29:37<8:01:01,  8.08s/it]                                                         {'loss': 0.8497, 'learning_rate': 5.574144274102078e-06, 'epoch': 0.66}
 66%|██████▌   | 6825/10395 [19:29:37<8:01:01,  8.08s/it] 66%|██████▌   | 6826/10395 [19:29:45<7:59:57,  8.07s/it]                                                         {'loss': 0.9157, 'learning_rate': 5.571350530156298e-06, 'epoch': 0.66}
 66%|██████▌   | 6826/10395 [19:29:45<7:59:57,  8.07s/it] 66%|██████▌   | 6827/10395 [19:29:52<7:42:46,  7.78s/it]                                                         {'loss': 0.8812, 'learning_rate': 5.5685572161343514e-06, 'epoch': 0.66}
 66%|██████▌   | 6827/10395 [19:29:52<7:42:46,  7.78s/it] 66%|██████▌   | 6828/10395 [19:30:00<7:38:13,  7.71s/it]                                                         {'loss': 0.854, 'learning_rate': 5.5657643323073975e-06, 'epoch': 0.66}
 66%|██████▌   | 6828/10395 [19:30:00<7:38:13,  7.71s/it] 66%|██████▌   | 6829/10395 [19:30:09<7:56:56,  8.02s/it]                                                         {'loss': 0.8346, 'learning_rate': 5.562971878946563e-06, 'epoch': 0.66}
 66%|██████▌   | 6829/10395 [19:30:09<7:56:56,  8.02s/it] 66%|██████▌   | 6830/10395 [19:30:17<7:52:44,  7.96s/it]                                                         {'loss': 0.937, 'learning_rate': 5.56017985632294e-06, 'epoch': 0.66}
 66%|██████▌   | 6830/10395 [19:30:17<7:52:44,  7.96s/it] 66%|██████▌   | 6831/10395 [19:30:24<7:44:25,  7.82s/it]                                                         {'loss': 0.9263, 'learning_rate': 5.557388264707566e-06, 'epoch': 0.66}
 66%|██████▌   | 6831/10395 [19:30:24<7:44:25,  7.82s/it] 66%|██████▌   | 6832/10395 [19:30:32<7:46:34,  7.86s/it]                                                         {'loss': 0.8267, 'learning_rate': 5.554597104371444e-06, 'epoch': 0.66}
 66%|██████▌   | 6832/10395 [19:30:32<7:46:34,  7.86s/it] 66%|██████▌   | 6833/10395 [19:30:40<7:44:51,  7.83s/it]                                                         {'loss': 0.9039, 'learning_rate': 5.55180637558554e-06, 'epoch': 0.66}
 66%|██████▌   | 6833/10395 [19:30:40<7:44:51,  7.83s/it] 66%|██████▌   | 6834/10395 [19:30:48<7:53:50,  7.98s/it]                                                         {'loss': 0.8676, 'learning_rate': 5.549016078620764e-06, 'epoch': 0.66}
 66%|██████▌   | 6834/10395 [19:30:48<7:53:50,  7.98s/it] 66%|██████▌   | 6835/10395 [19:30:56<7:53:33,  7.98s/it]                                                         {'loss': 0.8587, 'learning_rate': 5.546226213747998e-06, 'epoch': 0.66}
 66%|██████▌   | 6835/10395 [19:30:56<7:53:33,  7.98s/it] 66%|██████▌   | 6836/10395 [19:31:03<7:42:19,  7.79s/it]                                                         {'loss': 0.8722, 'learning_rate': 5.543436781238074e-06, 'epoch': 0.66}
 66%|██████▌   | 6836/10395 [19:31:03<7:42:19,  7.79s/it] 66%|██████▌   | 6837/10395 [19:31:11<7:42:36,  7.80s/it]                                                         {'loss': 0.8042, 'learning_rate': 5.540647781361778e-06, 'epoch': 0.66}
 66%|██████▌   | 6837/10395 [19:31:11<7:42:36,  7.80s/it] 66%|██████▌   | 6838/10395 [19:31:19<7:42:22,  7.80s/it]                                                         {'loss': 0.8749, 'learning_rate': 5.537859214389871e-06, 'epoch': 0.66}
 66%|██████▌   | 6838/10395 [19:31:19<7:42:22,  7.80s/it] 66%|██████▌   | 6839/10395 [19:31:26<7:35:45,  7.69s/it]                                                         {'loss': 0.816, 'learning_rate': 5.535071080593053e-06, 'epoch': 0.66}
 66%|██████▌   | 6839/10395 [19:31:27<7:35:45,  7.69s/it] 66%|██████▌   | 6840/10395 [19:31:34<7:31:07,  7.61s/it]                                                         {'loss': 0.9379, 'learning_rate': 5.532283380241992e-06, 'epoch': 0.66}
 66%|██████▌   | 6840/10395 [19:31:34<7:31:07,  7.61s/it] 66%|██████▌   | 6841/10395 [19:31:43<7:51:38,  7.96s/it]                                                         {'loss': 0.8535, 'learning_rate': 5.529496113607316e-06, 'epoch': 0.66}
 66%|██████▌   | 6841/10395 [19:31:43<7:51:38,  7.96s/it] 66%|██████▌   | 6842/10395 [19:32:00<10:32:01, 10.67s/it]                                                          {'loss': 0.4025, 'learning_rate': 5.526709280959604e-06, 'epoch': 0.66}
 66%|██████▌   | 6842/10395 [19:32:00<10:32:01, 10.67s/it] 66%|██████▌   | 6843/10395 [19:32:10<10:27:31, 10.60s/it]                                                          {'loss': 0.789, 'learning_rate': 5.523922882569393e-06, 'epoch': 0.66}
 66%|██████▌   | 6843/10395 [19:32:10<10:27:31, 10.60s/it] 66%|██████▌   | 6844/10395 [19:32:19<9:50:25,  9.98s/it]                                                          {'loss': 0.8687, 'learning_rate': 5.521136918707186e-06, 'epoch': 0.66}
 66%|██████▌   | 6844/10395 [19:32:19<9:50:25,  9.98s/it] 66%|██████▌   | 6845/10395 [19:32:26<9:06:23,  9.23s/it]                                                         {'loss': 0.8805, 'learning_rate': 5.518351389643433e-06, 'epoch': 0.66}
 66%|██████▌   | 6845/10395 [19:32:26<9:06:23,  9.23s/it] 66%|██████▌   | 6846/10395 [19:32:34<8:37:18,  8.75s/it]                                                         {'loss': 0.8791, 'learning_rate': 5.5155662956485464e-06, 'epoch': 0.66}
 66%|██████▌   | 6846/10395 [19:32:34<8:37:18,  8.75s/it] 66%|██████▌   | 6847/10395 [19:32:41<8:18:08,  8.42s/it]                                                         {'loss': 0.8863, 'learning_rate': 5.512781636992908e-06, 'epoch': 0.66}
 66%|██████▌   | 6847/10395 [19:32:41<8:18:08,  8.42s/it] 66%|██████▌   | 6848/10395 [19:32:50<8:16:27,  8.40s/it]                                                         {'loss': 0.8605, 'learning_rate': 5.5099974139468325e-06, 'epoch': 0.66}
 66%|██████▌   | 6848/10395 [19:32:50<8:16:27,  8.40s/it] 66%|██████▌   | 6849/10395 [19:32:57<7:56:46,  8.07s/it]                                                         {'loss': 0.91, 'learning_rate': 5.5072136267806184e-06, 'epoch': 0.66}
 66%|██████▌   | 6849/10395 [19:32:57<7:56:46,  8.07s/it] 66%|██████▌   | 6850/10395 [19:33:14<10:38:00, 10.80s/it]                                                          {'loss': 0.3627, 'learning_rate': 5.504430275764505e-06, 'epoch': 0.66}
 66%|██████▌   | 6850/10395 [19:33:14<10:38:00, 10.80s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 66%|██████▌   | 6851/10395 [19:34:56<37:23:28, 37.98s/it]                                                          {'loss': 0.9347, 'learning_rate': 5.5016473611686885e-06, 'epoch': 0.66}
 66%|██████▌   | 6851/10395 [19:34:56<37:23:28, 37.98s/it] 66%|██████▌   | 6852/10395 [19:35:03<28:16:19, 28.73s/it]                                                          {'loss': 0.8559, 'learning_rate': 5.498864883263337e-06, 'epoch': 0.66}
 66%|██████▌   | 6852/10395 [19:35:03<28:16:19, 28.73s/it] 66%|██████▌   | 6853/10395 [19:35:10<22:00:52, 22.38s/it]                                                          {'loss': 0.9785, 'learning_rate': 5.49608284231856e-06, 'epoch': 0.66}
 66%|██████▌   | 6853/10395 [19:35:10<22:00:52, 22.38s/it] 66%|██████▌   | 6854/10395 [19:35:18<17:34:25, 17.87s/it]                                                          {'loss': 0.8711, 'learning_rate': 5.493301238604435e-06, 'epoch': 0.66}
 66%|██████▌   | 6854/10395 [19:35:18<17:34:25, 17.87s/it] 66%|██████▌   | 6855/10395 [19:35:34<17:13:12, 17.51s/it]                                                          {'loss': 0.3546, 'learning_rate': 5.490520072390999e-06, 'epoch': 0.66}
 66%|██████▌   | 6855/10395 [19:35:34<17:13:12, 17.51s/it] 66%|██████▌   | 6856/10395 [19:35:53<17:25:48, 17.73s/it]                                                          {'loss': 0.382, 'learning_rate': 5.487739343948234e-06, 'epoch': 0.66}
 66%|██████▌   | 6856/10395 [19:35:53<17:25:48, 17.73s/it] 66%|██████▌   | 6857/10395 [19:36:01<14:33:57, 14.82s/it]                                                          {'loss': 0.8748, 'learning_rate': 5.484959053546095e-06, 'epoch': 0.66}
 66%|██████▌   | 6857/10395 [19:36:01<14:33:57, 14.82s/it] 66%|██████▌   | 6858/10395 [19:36:09<12:31:01, 12.74s/it]                                                          {'loss': 0.9024, 'learning_rate': 5.482179201454483e-06, 'epoch': 0.66}
 66%|██████▌   | 6858/10395 [19:36:09<12:31:01, 12.74s/it] 66%|██████▌   | 6859/10395 [19:36:16<11:03:33, 11.26s/it]                                                          {'loss': 0.8892, 'learning_rate': 5.479399787943254e-06, 'epoch': 0.66}
 66%|██████▌   | 6859/10395 [19:36:16<11:03:33, 11.26s/it] 66%|██████▌   | 6860/10395 [19:36:24<10:06:40, 10.30s/it]                                                          {'loss': 0.9366, 'learning_rate': 5.4766208132822375e-06, 'epoch': 0.66}
 66%|██████▌   | 6860/10395 [19:36:24<10:06:40, 10.30s/it] 66%|██████▌   | 6861/10395 [19:36:33<9:39:24,  9.84s/it]                                                          {'loss': 0.8454, 'learning_rate': 5.473842277741201e-06, 'epoch': 0.66}
 66%|██████▌   | 6861/10395 [19:36:33<9:39:24,  9.84s/it] 66%|██████▌   | 6862/10395 [19:36:51<12:03:05, 12.28s/it]                                                          {'loss': 0.361, 'learning_rate': 5.471064181589887e-06, 'epoch': 0.66}
 66%|██████▌   | 6862/10395 [19:36:51<12:03:05, 12.28s/it] 66%|██████▌   | 6863/10395 [19:36:59<10:38:29, 10.85s/it]                                                          {'loss': 0.9303, 'learning_rate': 5.4682865250979856e-06, 'epoch': 0.66}
 66%|██████▌   | 6863/10395 [19:36:59<10:38:29, 10.85s/it] 66%|██████▌   | 6864/10395 [19:37:07<9:49:23, 10.02s/it]                                                          {'loss': 0.9048, 'learning_rate': 5.465509308535144e-06, 'epoch': 0.66}
 66%|██████▌   | 6864/10395 [19:37:07<9:49:23, 10.02s/it] 66%|██████▌   | 6865/10395 [19:37:15<9:15:12,  9.44s/it]                                                         {'loss': 0.8726, 'learning_rate': 5.462732532170964e-06, 'epoch': 0.66}
 66%|██████▌   | 6865/10395 [19:37:15<9:15:12,  9.44s/it] 66%|██████▌   | 6866/10395 [19:37:23<8:49:02,  8.99s/it]                                                         {'loss': 0.8755, 'learning_rate': 5.459956196275018e-06, 'epoch': 0.66}
 66%|██████▌   | 6866/10395 [19:37:23<8:49:02,  8.99s/it] 66%|██████▌   | 6867/10395 [19:37:30<8:21:38,  8.53s/it]                                                         {'loss': 0.9591, 'learning_rate': 5.457180301116819e-06, 'epoch': 0.66}
 66%|██████▌   | 6867/10395 [19:37:30<8:21:38,  8.53s/it] 66%|██████▌   | 6868/10395 [19:37:38<8:05:15,  8.25s/it]                                                         {'loss': 0.8647, 'learning_rate': 5.454404846965853e-06, 'epoch': 0.66}
 66%|██████▌   | 6868/10395 [19:37:38<8:05:15,  8.25s/it] 66%|██████▌   | 6869/10395 [19:37:46<8:06:54,  8.29s/it]                                                         {'loss': 0.8839, 'learning_rate': 5.451629834091545e-06, 'epoch': 0.66}
 66%|██████▌   | 6869/10395 [19:37:46<8:06:54,  8.29s/it] 66%|██████▌   | 6870/10395 [19:37:53<7:47:49,  7.96s/it]                                                         {'loss': 0.902, 'learning_rate': 5.448855262763293e-06, 'epoch': 0.66}
 66%|██████▌   | 6870/10395 [19:37:53<7:47:49,  7.96s/it] 66%|██████▌   | 6871/10395 [19:38:01<7:37:21,  7.79s/it]                                                         {'loss': 0.9937, 'learning_rate': 5.44608113325045e-06, 'epoch': 0.66}
 66%|██████▌   | 6871/10395 [19:38:01<7:37:21,  7.79s/it] 66%|██████▌   | 6872/10395 [19:38:09<7:40:05,  7.84s/it]                                                         {'loss': 0.8421, 'learning_rate': 5.44330744582232e-06, 'epoch': 0.66}
 66%|██████▌   | 6872/10395 [19:38:09<7:40:05,  7.84s/it] 66%|██████▌   | 6873/10395 [19:38:16<7:37:36,  7.80s/it]                                                         {'loss': 0.8685, 'learning_rate': 5.440534200748161e-06, 'epoch': 0.66}
 66%|██████▌   | 6873/10395 [19:38:16<7:37:36,  7.80s/it] 66%|██████▌   | 6874/10395 [19:38:23<7:19:35,  7.49s/it]                                                         {'loss': 0.9147, 'learning_rate': 5.437761398297201e-06, 'epoch': 0.66}
 66%|██████▌   | 6874/10395 [19:38:23<7:19:35,  7.49s/it] 66%|██████▌   | 6875/10395 [19:38:30<7:14:47,  7.41s/it]                                                         {'loss': 0.9758, 'learning_rate': 5.434989038738613e-06, 'epoch': 0.66}
 66%|██████▌   | 6875/10395 [19:38:30<7:14:47,  7.41s/it] 66%|██████▌   | 6876/10395 [19:38:38<7:12:15,  7.37s/it]                                                         {'loss': 0.9162, 'learning_rate': 5.432217122341537e-06, 'epoch': 0.66}
 66%|██████▌   | 6876/10395 [19:38:38<7:12:15,  7.37s/it] 66%|██████▌   | 6877/10395 [19:38:55<10:13:37, 10.47s/it]                                                          {'loss': 0.3527, 'learning_rate': 5.429445649375056e-06, 'epoch': 0.66}
 66%|██████▌   | 6877/10395 [19:38:55<10:13:37, 10.47s/it] 66%|██████▌   | 6878/10395 [19:39:03<9:19:00,  9.54s/it]                                                          {'loss': 0.9253, 'learning_rate': 5.426674620108225e-06, 'epoch': 0.66}
 66%|██████▌   | 6878/10395 [19:39:03<9:19:00,  9.54s/it] 66%|██████▌   | 6879/10395 [19:39:12<9:06:15,  9.32s/it]                                                         {'loss': 0.822, 'learning_rate': 5.423904034810057e-06, 'epoch': 0.66}
 66%|██████▌   | 6879/10395 [19:39:12<9:06:15,  9.32s/it] 66%|██████▌   | 6880/10395 [19:39:19<8:35:12,  8.79s/it]                                                         {'loss': 0.861, 'learning_rate': 5.421133893749498e-06, 'epoch': 0.66}
 66%|██████▌   | 6880/10395 [19:39:19<8:35:12,  8.79s/it] 66%|██████▌   | 6881/10395 [19:39:26<8:06:17,  8.30s/it]                                                         {'loss': 0.8339, 'learning_rate': 5.418364197195476e-06, 'epoch': 0.66}
 66%|██████▌   | 6881/10395 [19:39:26<8:06:17,  8.30s/it] 66%|██████▌   | 6882/10395 [19:39:34<7:51:20,  8.05s/it]                                                         {'loss': 0.9034, 'learning_rate': 5.415594945416869e-06, 'epoch': 0.66}
 66%|██████▌   | 6882/10395 [19:39:34<7:51:20,  8.05s/it] 66%|██████▌   | 6883/10395 [19:39:42<7:50:33,  8.04s/it]                                                         {'loss': 0.8855, 'learning_rate': 5.412826138682505e-06, 'epoch': 0.66}
 66%|██████▌   | 6883/10395 [19:39:42<7:50:33,  8.04s/it] 66%|██████▌   | 6884/10395 [19:39:49<7:41:56,  7.89s/it]                                                         {'loss': 0.8647, 'learning_rate': 5.410057777261181e-06, 'epoch': 0.66}
 66%|██████▌   | 6884/10395 [19:39:49<7:41:56,  7.89s/it] 66%|██████▌   | 6885/10395 [19:39:57<7:30:38,  7.70s/it]                                                         {'loss': 0.9491, 'learning_rate': 5.407289861421634e-06, 'epoch': 0.66}
 66%|██████▌   | 6885/10395 [19:39:57<7:30:38,  7.70s/it] 66%|██████▌   | 6886/10395 [19:40:04<7:20:50,  7.54s/it]                                                         {'loss': 0.8964, 'learning_rate': 5.404522391432578e-06, 'epoch': 0.66}
 66%|██████▌   | 6886/10395 [19:40:04<7:20:50,  7.54s/it] 66%|██████▋   | 6887/10395 [19:40:11<7:20:13,  7.53s/it]                                                         {'loss': 0.8486, 'learning_rate': 5.401755367562666e-06, 'epoch': 0.66}
 66%|██████▋   | 6887/10395 [19:40:11<7:20:13,  7.53s/it] 66%|██████▋   | 6888/10395 [19:40:19<7:22:16,  7.57s/it]                                                         {'loss': 0.9042, 'learning_rate': 5.398988790080515e-06, 'epoch': 0.66}
 66%|██████▋   | 6888/10395 [19:40:19<7:22:16,  7.57s/it] 66%|██████▋   | 6889/10395 [19:40:27<7:24:35,  7.61s/it]                                                         {'loss': 0.9311, 'learning_rate': 5.396222659254697e-06, 'epoch': 0.66}
 66%|██████▋   | 6889/10395 [19:40:27<7:24:35,  7.61s/it] 66%|██████▋   | 6890/10395 [19:40:34<7:23:35,  7.59s/it]                                                         {'loss': 0.903, 'learning_rate': 5.393456975353751e-06, 'epoch': 0.66}
 66%|██████▋   | 6890/10395 [19:40:34<7:23:35,  7.59s/it] 66%|██████▋   | 6891/10395 [19:40:42<7:28:21,  7.68s/it]                                                         {'loss': 0.8077, 'learning_rate': 5.390691738646153e-06, 'epoch': 0.66}
 66%|██████▋   | 6891/10395 [19:40:42<7:28:21,  7.68s/it] 66%|██████▋   | 6892/10395 [19:40:50<7:35:21,  7.80s/it]                                                         {'loss': 0.9298, 'learning_rate': 5.387926949400355e-06, 'epoch': 0.66}
 66%|██████▋   | 6892/10395 [19:40:50<7:35:21,  7.80s/it] 66%|██████▋   | 6893/10395 [19:40:58<7:38:29,  7.86s/it]                                                         {'loss': 0.8638, 'learning_rate': 5.385162607884749e-06, 'epoch': 0.66}
 66%|██████▋   | 6893/10395 [19:40:58<7:38:29,  7.86s/it] 66%|██████▋   | 6894/10395 [19:41:06<7:33:41,  7.78s/it]                                                         {'loss': 0.8358, 'learning_rate': 5.382398714367698e-06, 'epoch': 0.66}
 66%|██████▋   | 6894/10395 [19:41:06<7:33:41,  7.78s/it] 66%|██████▋   | 6895/10395 [19:41:13<7:33:52,  7.78s/it]                                                         {'loss': 0.8975, 'learning_rate': 5.379635269117512e-06, 'epoch': 0.66}
 66%|██████▋   | 6895/10395 [19:41:13<7:33:52,  7.78s/it] 66%|██████▋   | 6896/10395 [19:41:21<7:24:26,  7.62s/it]                                                         {'loss': 0.87, 'learning_rate': 5.376872272402458e-06, 'epoch': 0.66}
 66%|██████▋   | 6896/10395 [19:41:21<7:24:26,  7.62s/it] 66%|██████▋   | 6897/10395 [19:41:29<7:38:18,  7.86s/it]                                                         {'loss': 0.7668, 'learning_rate': 5.3741097244907625e-06, 'epoch': 0.66}
 66%|██████▋   | 6897/10395 [19:41:29<7:38:18,  7.86s/it] 66%|██████▋   | 6898/10395 [19:41:37<7:34:05,  7.79s/it]                                                         {'loss': 0.8453, 'learning_rate': 5.371347625650614e-06, 'epoch': 0.66}
 66%|██████▋   | 6898/10395 [19:41:37<7:34:05,  7.79s/it] 66%|██████▋   | 6899/10395 [19:41:44<7:29:03,  7.71s/it]                                                         {'loss': 0.862, 'learning_rate': 5.368585976150142e-06, 'epoch': 0.66}
 66%|██████▋   | 6899/10395 [19:41:44<7:29:03,  7.71s/it] 66%|██████▋   | 6900/10395 [19:41:52<7:35:27,  7.82s/it]                                                         {'loss': 0.8872, 'learning_rate': 5.365824776257451e-06, 'epoch': 0.66}
 66%|██████▋   | 6900/10395 [19:41:52<7:35:27,  7.82s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 66%|██████▋   | 6901/10395 [19:43:34<35:02:18, 36.10s/it]                                                          {'loss': 0.8815, 'learning_rate': 5.363064026240586e-06, 'epoch': 0.66}
 66%|██████▋   | 6901/10395 [19:43:34<35:02:18, 36.10s/it] 66%|██████▋   | 6902/10395 [19:43:42<26:41:26, 27.51s/it]                                                          {'loss': 0.9232, 'learning_rate': 5.360303726367554e-06, 'epoch': 0.66}
 66%|██████▋   | 6902/10395 [19:43:42<26:41:26, 27.51s/it] 66%|██████▋   | 6903/10395 [19:43:49<20:49:25, 21.47s/it]                                                          {'loss': 0.8608, 'learning_rate': 5.357543876906324e-06, 'epoch': 0.66}
 66%|██████▋   | 6903/10395 [19:43:49<20:49:25, 21.47s/it] 66%|██████▋   | 6904/10395 [19:43:57<16:43:57, 17.26s/it]                                                          {'loss': 0.8788, 'learning_rate': 5.35478447812481e-06, 'epoch': 0.66}
 66%|██████▋   | 6904/10395 [19:43:57<16:43:57, 17.26s/it] 66%|██████▋   | 6905/10395 [19:44:04<13:54:19, 14.34s/it]                                                          {'loss': 0.8218, 'learning_rate': 5.352025530290892e-06, 'epoch': 0.66}
 66%|██████▋   | 6905/10395 [19:44:04<13:54:19, 14.34s/it] 66%|██████▋   | 6906/10395 [19:44:12<11:55:16, 12.30s/it]                                                          {'loss': 0.9586, 'learning_rate': 5.349267033672406e-06, 'epoch': 0.66}
 66%|██████▋   | 6906/10395 [19:44:12<11:55:16, 12.30s/it] 66%|██████▋   | 6907/10395 [19:44:19<10:25:53, 10.77s/it]                                                          {'loss': 0.8678, 'learning_rate': 5.3465089885371345e-06, 'epoch': 0.66}
 66%|██████▋   | 6907/10395 [19:44:19<10:25:53, 10.77s/it] 66%|██████▋   | 6908/10395 [19:44:27<9:33:27,  9.87s/it]                                                          {'loss': 0.9087, 'learning_rate': 5.34375139515283e-06, 'epoch': 0.66}
 66%|██████▋   | 6908/10395 [19:44:27<9:33:27,  9.87s/it] 66%|██████▋   | 6909/10395 [19:44:36<9:27:33,  9.77s/it]                                                         {'loss': 0.8807, 'learning_rate': 5.340994253787189e-06, 'epoch': 0.66}
 66%|██████▋   | 6909/10395 [19:44:36<9:27:33,  9.77s/it] 66%|██████▋   | 6910/10395 [19:44:45<9:00:39,  9.31s/it]                                                         {'loss': 0.8936, 'learning_rate': 5.338237564707866e-06, 'epoch': 0.66}
 66%|██████▋   | 6910/10395 [19:44:45<9:00:39,  9.31s/it] 66%|██████▋   | 6911/10395 [19:44:52<8:23:50,  8.68s/it]                                                         {'loss': 0.9354, 'learning_rate': 5.335481328182477e-06, 'epoch': 0.66}
 66%|██████▋   | 6911/10395 [19:44:52<8:23:50,  8.68s/it] 66%|██████▋   | 6912/10395 [19:45:09<10:50:14, 11.20s/it]                                                          {'loss': 0.4049, 'learning_rate': 5.3327255444785974e-06, 'epoch': 0.66}
 66%|██████▋   | 6912/10395 [19:45:09<10:50:14, 11.20s/it] 67%|██████▋   | 6913/10395 [19:45:16<9:42:28, 10.04s/it]                                                          {'loss': 0.98, 'learning_rate': 5.329970213863744e-06, 'epoch': 0.66}
 67%|██████▋   | 6913/10395 [19:45:16<9:42:28, 10.04s/it] 67%|██████▋   | 6914/10395 [19:45:24<8:59:57,  9.31s/it]                                                         {'loss': 0.8757, 'learning_rate': 5.327215336605407e-06, 'epoch': 0.67}
 67%|██████▋   | 6914/10395 [19:45:24<8:59:57,  9.31s/it] 67%|██████▋   | 6915/10395 [19:45:32<8:33:38,  8.86s/it]                                                         {'loss': 0.9169, 'learning_rate': 5.324460912971014e-06, 'epoch': 0.67}
 67%|██████▋   | 6915/10395 [19:45:32<8:33:38,  8.86s/it] 67%|██████▋   | 6916/10395 [19:45:41<8:45:09,  9.06s/it]                                                         {'loss': 0.8236, 'learning_rate': 5.321706943227969e-06, 'epoch': 0.67}
 67%|██████▋   | 6916/10395 [19:45:41<8:45:09,  9.06s/it] 67%|██████▋   | 6917/10395 [19:45:49<8:20:19,  8.63s/it]                                                         {'loss': 0.9039, 'learning_rate': 5.318953427643615e-06, 'epoch': 0.67}
 67%|██████▋   | 6917/10395 [19:45:49<8:20:19,  8.63s/it] 67%|██████▋   | 6918/10395 [19:45:56<7:57:25,  8.24s/it]                                                         {'loss': 0.9451, 'learning_rate': 5.316200366485256e-06, 'epoch': 0.67}
 67%|██████▋   | 6918/10395 [19:45:56<7:57:25,  8.24s/it] 67%|██████▋   | 6919/10395 [19:46:04<7:45:58,  8.04s/it]                                                         {'loss': 0.9085, 'learning_rate': 5.313447760020156e-06, 'epoch': 0.67}
 67%|██████▋   | 6919/10395 [19:46:04<7:45:58,  8.04s/it] 67%|██████▋   | 6920/10395 [19:46:12<7:49:15,  8.10s/it]                                                         {'loss': 0.855, 'learning_rate': 5.310695608515535e-06, 'epoch': 0.67}
 67%|██████▋   | 6920/10395 [19:46:12<7:49:15,  8.10s/it] 67%|██████▋   | 6921/10395 [19:46:20<7:44:00,  8.01s/it]                                                         {'loss': 0.8054, 'learning_rate': 5.30794391223856e-06, 'epoch': 0.67}
 67%|██████▋   | 6921/10395 [19:46:20<7:44:00,  8.01s/it] 67%|██████▋   | 6922/10395 [19:46:27<7:31:57,  7.81s/it]                                                         {'loss': 0.89, 'learning_rate': 5.3051926714563685e-06, 'epoch': 0.67}
 67%|██████▋   | 6922/10395 [19:46:27<7:31:57,  7.81s/it] 67%|██████▋   | 6923/10395 [19:46:35<7:35:39,  7.87s/it]                                                         {'loss': 0.8974, 'learning_rate': 5.302441886436038e-06, 'epoch': 0.67}
 67%|██████▋   | 6923/10395 [19:46:35<7:35:39,  7.87s/it] 67%|██████▋   | 6924/10395 [19:46:43<7:33:04,  7.83s/it]                                                         {'loss': 0.9492, 'learning_rate': 5.299691557444608e-06, 'epoch': 0.67}
 67%|██████▋   | 6924/10395 [19:46:43<7:33:04,  7.83s/it] 67%|██████▋   | 6925/10395 [19:46:50<7:29:52,  7.78s/it]                                                         {'loss': 0.8441, 'learning_rate': 5.29694168474908e-06, 'epoch': 0.67}
 67%|██████▋   | 6925/10395 [19:46:50<7:29:52,  7.78s/it] 67%|██████▋   | 6926/10395 [19:46:58<7:21:29,  7.64s/it]                                                         {'loss': 0.8305, 'learning_rate': 5.294192268616398e-06, 'epoch': 0.67}
 67%|██████▋   | 6926/10395 [19:46:58<7:21:29,  7.64s/it] 67%|██████▋   | 6927/10395 [19:47:05<7:14:14,  7.51s/it]                                                         {'loss': 0.9017, 'learning_rate': 5.291443309313475e-06, 'epoch': 0.67}
 67%|██████▋   | 6927/10395 [19:47:05<7:14:14,  7.51s/it] 67%|██████▋   | 6928/10395 [19:47:13<7:15:53,  7.54s/it]                                                         {'loss': 0.857, 'learning_rate': 5.288694807107178e-06, 'epoch': 0.67}
 67%|██████▋   | 6928/10395 [19:47:13<7:15:53,  7.54s/it] 67%|██████▋   | 6929/10395 [19:47:21<7:24:35,  7.70s/it]                                                         {'loss': 0.8814, 'learning_rate': 5.2859467622643154e-06, 'epoch': 0.67}
 67%|██████▋   | 6929/10395 [19:47:21<7:24:35,  7.70s/it] 67%|██████▋   | 6930/10395 [19:47:28<7:25:03,  7.71s/it]                                                         {'loss': 0.89, 'learning_rate': 5.283199175051672e-06, 'epoch': 0.67}
 67%|██████▋   | 6930/10395 [19:47:28<7:25:03,  7.71s/it] 67%|██████▋   | 6931/10395 [19:47:36<7:31:24,  7.82s/it]                                                         {'loss': 0.8458, 'learning_rate': 5.2804520457359735e-06, 'epoch': 0.67}
 67%|██████▋   | 6931/10395 [19:47:36<7:31:24,  7.82s/it] 67%|██████▋   | 6932/10395 [19:47:43<7:12:50,  7.50s/it]                                                         {'loss': 0.9994, 'learning_rate': 5.277705374583899e-06, 'epoch': 0.67}
 67%|██████▋   | 6932/10395 [19:47:44<7:12:50,  7.50s/it] 67%|██████▋   | 6933/10395 [19:47:52<7:33:10,  7.85s/it]                                                         {'loss': 0.8451, 'learning_rate': 5.2749591618621e-06, 'epoch': 0.67}
 67%|██████▋   | 6933/10395 [19:47:52<7:33:10,  7.85s/it] 67%|██████▋   | 6934/10395 [19:48:00<7:30:53,  7.82s/it]                                                         {'loss': 0.9056, 'learning_rate': 5.272213407837164e-06, 'epoch': 0.67}
 67%|██████▋   | 6934/10395 [19:48:00<7:30:53,  7.82s/it] 67%|██████▋   | 6935/10395 [19:48:09<7:52:50,  8.20s/it]                                                         {'loss': 0.9135, 'learning_rate': 5.269468112775649e-06, 'epoch': 0.67}
 67%|██████▋   | 6935/10395 [19:48:09<7:52:50,  8.20s/it] 67%|██████▋   | 6936/10395 [19:48:18<8:08:41,  8.48s/it]                                                         {'loss': 0.8348, 'learning_rate': 5.2667232769440615e-06, 'epoch': 0.67}
 67%|██████▋   | 6936/10395 [19:48:18<8:08:41,  8.48s/it] 67%|██████▋   | 6937/10395 [19:48:25<7:53:56,  8.22s/it]                                                         {'loss': 0.872, 'learning_rate': 5.263978900608862e-06, 'epoch': 0.67}
 67%|██████▋   | 6937/10395 [19:48:25<7:53:56,  8.22s/it] 67%|██████▋   | 6938/10395 [19:48:33<7:42:27,  8.03s/it]                                                         {'loss': 0.8218, 'learning_rate': 5.261234984036472e-06, 'epoch': 0.67}
 67%|██████▋   | 6938/10395 [19:48:33<7:42:27,  8.03s/it] 67%|██████▋   | 6939/10395 [19:48:41<7:34:44,  7.89s/it]                                                         {'loss': 0.9051, 'learning_rate': 5.258491527493262e-06, 'epoch': 0.67}
 67%|██████▋   | 6939/10395 [19:48:41<7:34:44,  7.89s/it] 67%|██████▋   | 6940/10395 [19:48:49<7:49:21,  8.15s/it]                                                         {'loss': 0.8236, 'learning_rate': 5.255748531245559e-06, 'epoch': 0.67}
 67%|██████▋   | 6940/10395 [19:48:49<7:49:21,  8.15s/it] 67%|██████▋   | 6941/10395 [19:48:57<7:48:58,  8.15s/it]                                                         {'loss': 0.9248, 'learning_rate': 5.253005995559654e-06, 'epoch': 0.67}
 67%|██████▋   | 6941/10395 [19:48:57<7:48:58,  8.15s/it] 67%|██████▋   | 6942/10395 [19:49:07<8:14:53,  8.60s/it]                                                         {'loss': 0.8172, 'learning_rate': 5.25026392070178e-06, 'epoch': 0.67}
 67%|██████▋   | 6942/10395 [19:49:07<8:14:53,  8.60s/it] 67%|██████▋   | 6943/10395 [19:49:16<8:10:45,  8.53s/it]                                                         {'loss': 0.7962, 'learning_rate': 5.2475223069381334e-06, 'epoch': 0.67}
 67%|██████▋   | 6943/10395 [19:49:16<8:10:45,  8.53s/it] 67%|██████▋   | 6944/10395 [19:49:23<7:52:38,  8.22s/it]                                                         {'loss': 0.9042, 'learning_rate': 5.244781154534869e-06, 'epoch': 0.67}
 67%|██████▋   | 6944/10395 [19:49:23<7:52:38,  8.22s/it] 67%|██████▋   | 6945/10395 [19:49:31<7:52:12,  8.21s/it]                                                         {'loss': 0.8522, 'learning_rate': 5.242040463758089e-06, 'epoch': 0.67}
 67%|██████▋   | 6945/10395 [19:49:31<7:52:12,  8.21s/it] 67%|██████▋   | 6946/10395 [19:49:39<7:38:48,  7.98s/it]                                                         {'loss': 0.9078, 'learning_rate': 5.239300234873847e-06, 'epoch': 0.67}
 67%|██████▋   | 6946/10395 [19:49:39<7:38:48,  7.98s/it] 67%|██████▋   | 6947/10395 [19:49:46<7:27:59,  7.80s/it]                                                         {'loss': 0.917, 'learning_rate': 5.236560468148171e-06, 'epoch': 0.67}
 67%|██████▋   | 6947/10395 [19:49:46<7:27:59,  7.80s/it] 67%|██████▋   | 6948/10395 [19:50:03<10:05:05, 10.53s/it]                                                          {'loss': 0.3673, 'learning_rate': 5.233821163847019e-06, 'epoch': 0.67}
 67%|██████▋   | 6948/10395 [19:50:03<10:05:05, 10.53s/it] 67%|██████▋   | 6949/10395 [19:50:11<9:21:11,  9.77s/it]                                                          {'loss': 0.8144, 'learning_rate': 5.23108232223633e-06, 'epoch': 0.67}
 67%|██████▋   | 6949/10395 [19:50:11<9:21:11,  9.77s/it] 67%|██████▋   | 6950/10395 [19:50:28<11:28:34, 11.99s/it]                                                          {'loss': 0.368, 'learning_rate': 5.22834394358197e-06, 'epoch': 0.67}
 67%|██████▋   | 6950/10395 [19:50:28<11:28:34, 11.99s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 6951/10395 [19:52:09<37:07:44, 38.81s/it]                                                          {'loss': 0.8429, 'learning_rate': 5.225606028149786e-06, 'epoch': 0.67}
 67%|██████▋   | 6951/10395 [19:52:09<37:07:44, 38.81s/it] 67%|██████▋   | 6952/10395 [19:52:17<28:12:59, 29.50s/it]                                                          {'loss': 0.9147, 'learning_rate': 5.222868576205573e-06, 'epoch': 0.67}
 67%|██████▋   | 6952/10395 [19:52:17<28:12:59, 29.50s/it] 67%|██████▋   | 6953/10395 [19:52:26<22:21:03, 23.38s/it]                                                          {'loss': 0.8105, 'learning_rate': 5.22013158801506e-06, 'epoch': 0.67}
 67%|██████▋   | 6953/10395 [19:52:26<22:21:03, 23.38s/it] 67%|██████▋   | 6954/10395 [19:52:34<17:49:07, 18.64s/it]                                                          {'loss': 0.8941, 'learning_rate': 5.2173950638439605e-06, 'epoch': 0.67}
 67%|██████▋   | 6954/10395 [19:52:34<17:49:07, 18.64s/it] 67%|██████▋   | 6955/10395 [19:52:41<14:31:28, 15.20s/it]                                                          {'loss': 0.9768, 'learning_rate': 5.2146590039579314e-06, 'epoch': 0.67}
 67%|██████▋   | 6955/10395 [19:52:41<14:31:28, 15.20s/it] 67%|██████▋   | 6956/10395 [19:52:50<12:42:56, 13.31s/it]                                                          {'loss': 0.81, 'learning_rate': 5.2119234086225745e-06, 'epoch': 0.67}
 67%|██████▋   | 6956/10395 [19:52:50<12:42:56, 13.31s/it] 67%|██████▋   | 6957/10395 [19:52:58<11:10:42, 11.71s/it]                                                          {'loss': 0.898, 'learning_rate': 5.209188278103465e-06, 'epoch': 0.67}
 67%|██████▋   | 6957/10395 [19:52:58<11:10:42, 11.71s/it] 67%|██████▋   | 6958/10395 [19:53:06<10:02:26, 10.52s/it]                                                          {'loss': 0.9535, 'learning_rate': 5.206453612666117e-06, 'epoch': 0.67}
 67%|██████▋   | 6958/10395 [19:53:06<10:02:26, 10.52s/it] 67%|██████▋   | 6959/10395 [19:53:14<9:19:58,  9.78s/it]                                                          {'loss': 0.8265, 'learning_rate': 5.203719412576007e-06, 'epoch': 0.67}
 67%|██████▋   | 6959/10395 [19:53:14<9:19:58,  9.78s/it] 67%|██████▋   | 6960/10395 [19:53:22<8:52:48,  9.31s/it]                                                         {'loss': 0.8811, 'learning_rate': 5.200985678098576e-06, 'epoch': 0.67}
 67%|██████▋   | 6960/10395 [19:53:22<8:52:48,  9.31s/it] 67%|██████▋   | 6961/10395 [19:53:30<8:23:28,  8.80s/it]                                                         {'loss': 0.8942, 'learning_rate': 5.1982524094991916e-06, 'epoch': 0.67}
 67%|██████▋   | 6961/10395 [19:53:30<8:23:28,  8.80s/it] 67%|██████▋   | 6962/10395 [19:53:38<8:14:19,  8.64s/it]                                                         {'loss': 0.9049, 'learning_rate': 5.195519607043201e-06, 'epoch': 0.67}
 67%|██████▋   | 6962/10395 [19:53:38<8:14:19,  8.64s/it] 67%|██████▋   | 6963/10395 [19:53:46<7:59:08,  8.38s/it]                                                         {'loss': 0.8922, 'learning_rate': 5.192787270995905e-06, 'epoch': 0.67}
 67%|██████▋   | 6963/10395 [19:53:46<7:59:08,  8.38s/it] 67%|██████▋   | 6964/10395 [19:53:53<7:45:45,  8.15s/it]                                                         {'loss': 0.9312, 'learning_rate': 5.190055401622542e-06, 'epoch': 0.67}
 67%|██████▋   | 6964/10395 [19:53:53<7:45:45,  8.15s/it] 67%|██████▋   | 6965/10395 [19:54:01<7:37:14,  8.00s/it]                                                         {'loss': 0.8655, 'learning_rate': 5.187323999188327e-06, 'epoch': 0.67}
 67%|██████▋   | 6965/10395 [19:54:01<7:37:14,  8.00s/it] 67%|██████▋   | 6966/10395 [19:54:09<7:35:51,  7.98s/it]                                                         {'loss': 0.8496, 'learning_rate': 5.184593063958409e-06, 'epoch': 0.67}
 67%|██████▋   | 6966/10395 [19:54:09<7:35:51,  7.98s/it] 67%|██████▋   | 6967/10395 [19:54:17<7:32:44,  7.92s/it]                                                         {'loss': 0.8557, 'learning_rate': 5.18186259619791e-06, 'epoch': 0.67}
 67%|██████▋   | 6967/10395 [19:54:17<7:32:44,  7.92s/it] 67%|██████▋   | 6968/10395 [19:54:25<7:33:51,  7.95s/it]                                                         {'loss': 0.7897, 'learning_rate': 5.179132596171893e-06, 'epoch': 0.67}
 67%|██████▋   | 6968/10395 [19:54:25<7:33:51,  7.95s/it] 67%|██████▋   | 6969/10395 [19:54:33<7:34:42,  7.96s/it]                                                         {'loss': 0.8976, 'learning_rate': 5.176403064145379e-06, 'epoch': 0.67}
 67%|██████▋   | 6969/10395 [19:54:33<7:34:42,  7.96s/it] 67%|██████▋   | 6970/10395 [19:54:40<7:24:43,  7.79s/it]                                                         {'loss': 0.9385, 'learning_rate': 5.173674000383347e-06, 'epoch': 0.67}
 67%|██████▋   | 6970/10395 [19:54:40<7:24:43,  7.79s/it] 67%|██████▋   | 6971/10395 [19:54:47<7:16:44,  7.65s/it]                                                         {'loss': 0.8508, 'learning_rate': 5.170945405150731e-06, 'epoch': 0.67}
 67%|██████▋   | 6971/10395 [19:54:47<7:16:44,  7.65s/it] 67%|██████▋   | 6972/10395 [19:54:56<7:36:47,  8.01s/it]                                                         {'loss': 0.8552, 'learning_rate': 5.168217278712413e-06, 'epoch': 0.67}
 67%|██████▋   | 6972/10395 [19:54:56<7:36:47,  8.01s/it] 67%|██████▋   | 6973/10395 [19:55:05<7:42:47,  8.11s/it]                                                         {'loss': 0.8818, 'learning_rate': 5.165489621333239e-06, 'epoch': 0.67}
 67%|██████▋   | 6973/10395 [19:55:05<7:42:47,  8.11s/it] 67%|██████▋   | 6974/10395 [19:55:13<7:44:29,  8.15s/it]                                                         {'loss': 0.9035, 'learning_rate': 5.162762433278003e-06, 'epoch': 0.67}
 67%|██████▋   | 6974/10395 [19:55:13<7:44:29,  8.15s/it] 67%|██████▋   | 6975/10395 [19:55:20<7:34:19,  7.97s/it]                                                         {'loss': 0.8711, 'learning_rate': 5.160035714811448e-06, 'epoch': 0.67}
 67%|██████▋   | 6975/10395 [19:55:20<7:34:19,  7.97s/it] 67%|██████▋   | 6976/10395 [19:55:28<7:33:50,  7.96s/it]                                                         {'loss': 0.8763, 'learning_rate': 5.157309466198286e-06, 'epoch': 0.67}
 67%|██████▋   | 6976/10395 [19:55:28<7:33:50,  7.96s/it] 67%|██████▋   | 6977/10395 [19:55:36<7:26:06,  7.83s/it]                                                         {'loss': 0.8741, 'learning_rate': 5.15458368770317e-06, 'epoch': 0.67}
 67%|██████▋   | 6977/10395 [19:55:36<7:26:06,  7.83s/it] 67%|██████▋   | 6978/10395 [19:55:43<7:14:24,  7.63s/it]                                                         {'loss': 0.8482, 'learning_rate': 5.151858379590713e-06, 'epoch': 0.67}
 67%|██████▋   | 6978/10395 [19:55:43<7:14:24,  7.63s/it] 67%|██████▋   | 6979/10395 [19:55:53<7:50:45,  8.27s/it]                                                         {'loss': 0.8602, 'learning_rate': 5.149133542125488e-06, 'epoch': 0.67}
 67%|██████▋   | 6979/10395 [19:55:53<7:50:45,  8.27s/it] 67%|██████▋   | 6980/10395 [19:56:00<7:35:51,  8.01s/it]                                                         {'loss': 0.866, 'learning_rate': 5.14640917557201e-06, 'epoch': 0.67}
 67%|██████▋   | 6980/10395 [19:56:00<7:35:51,  8.01s/it] 67%|██████▋   | 6981/10395 [19:56:09<7:50:23,  8.27s/it]                                                         {'loss': 0.7406, 'learning_rate': 5.143685280194757e-06, 'epoch': 0.67}
 67%|██████▋   | 6981/10395 [19:56:09<7:50:23,  8.27s/it] 67%|██████▋   | 6982/10395 [19:56:16<7:36:21,  8.02s/it]                                                         {'loss': 0.8179, 'learning_rate': 5.140961856258166e-06, 'epoch': 0.67}
 67%|██████▋   | 6982/10395 [19:56:16<7:36:21,  8.02s/it] 67%|██████▋   | 6983/10395 [19:56:25<7:37:14,  8.04s/it]                                                         {'loss': 0.8503, 'learning_rate': 5.138238904026606e-06, 'epoch': 0.67}
 67%|██████▋   | 6983/10395 [19:56:25<7:37:14,  8.04s/it] 67%|██████▋   | 6984/10395 [19:56:32<7:28:01,  7.88s/it]                                                         {'loss': 0.8975, 'learning_rate': 5.135516423764424e-06, 'epoch': 0.67}
 67%|██████▋   | 6984/10395 [19:56:32<7:28:01,  7.88s/it] 67%|██████▋   | 6985/10395 [19:56:40<7:21:30,  7.77s/it]                                                         {'loss': 0.8829, 'learning_rate': 5.132794415735916e-06, 'epoch': 0.67}
 67%|██████▋   | 6985/10395 [19:56:40<7:21:30,  7.77s/it] 67%|██████▋   | 6986/10395 [19:56:48<7:32:31,  7.96s/it]                                                         {'loss': 0.8819, 'learning_rate': 5.130072880205321e-06, 'epoch': 0.67}
 67%|██████▋   | 6986/10395 [19:56:48<7:32:31,  7.96s/it] 67%|██████▋   | 6987/10395 [19:56:56<7:34:55,  8.01s/it]                                                         {'loss': 0.9077, 'learning_rate': 5.127351817436847e-06, 'epoch': 0.67}
 67%|██████▋   | 6987/10395 [19:56:56<7:34:55,  8.01s/it] 67%|██████▋   | 6988/10395 [19:57:04<7:34:58,  8.01s/it]                                                         {'loss': 0.8578, 'learning_rate': 5.124631227694643e-06, 'epoch': 0.67}
 67%|██████▋   | 6988/10395 [19:57:04<7:34:58,  8.01s/it] 67%|██████▋   | 6989/10395 [19:57:12<7:26:02,  7.86s/it]                                                         {'loss': 0.8616, 'learning_rate': 5.121911111242823e-06, 'epoch': 0.67}
 67%|██████▋   | 6989/10395 [19:57:12<7:26:02,  7.86s/it] 67%|██████▋   | 6990/10395 [19:57:19<7:18:58,  7.74s/it]                                                         {'loss': 0.8751, 'learning_rate': 5.1191914683454505e-06, 'epoch': 0.67}
 67%|██████▋   | 6990/10395 [19:57:19<7:18:58,  7.74s/it] 67%|██████▋   | 6991/10395 [19:57:27<7:20:02,  7.76s/it]                                                         {'loss': 0.8892, 'learning_rate': 5.116472299266534e-06, 'epoch': 0.67}
 67%|██████▋   | 6991/10395 [19:57:27<7:20:02,  7.76s/it] 67%|██████▋   | 6992/10395 [19:57:35<7:27:53,  7.90s/it]                                                         {'loss': 0.8742, 'learning_rate': 5.113753604270051e-06, 'epoch': 0.67}
 67%|██████▋   | 6992/10395 [19:57:35<7:27:53,  7.90s/it] 67%|██████▋   | 6993/10395 [19:57:43<7:29:54,  7.93s/it]                                                         {'loss': 0.8514, 'learning_rate': 5.111035383619929e-06, 'epoch': 0.67}
 67%|██████▋   | 6993/10395 [19:57:43<7:29:54,  7.93s/it] 67%|██████▋   | 6994/10395 [19:57:51<7:22:11,  7.80s/it]                                                         {'loss': 0.8601, 'learning_rate': 5.1083176375800424e-06, 'epoch': 0.67}
 67%|██████▋   | 6994/10395 [19:57:51<7:22:11,  7.80s/it] 67%|██████▋   | 6995/10395 [19:57:58<7:23:35,  7.83s/it]                                                         {'loss': 0.838, 'learning_rate': 5.1056003664142285e-06, 'epoch': 0.67}
 67%|██████▋   | 6995/10395 [19:57:58<7:23:35,  7.83s/it] 67%|██████▋   | 6996/10395 [19:58:16<10:10:08, 10.77s/it]                                                          {'loss': 0.4116, 'learning_rate': 5.1028835703862676e-06, 'epoch': 0.67}
 67%|██████▋   | 6996/10395 [19:58:16<10:10:08, 10.77s/it] 67%|██████▋   | 6997/10395 [19:58:24<9:14:36,  9.79s/it]                                                          {'loss': 0.9646, 'learning_rate': 5.100167249759909e-06, 'epoch': 0.67}
 67%|██████▋   | 6997/10395 [19:58:24<9:14:36,  9.79s/it] 67%|██████▋   | 6998/10395 [19:58:32<8:54:15,  9.44s/it]                                                         {'loss': 0.8783, 'learning_rate': 5.097451404798843e-06, 'epoch': 0.67}
 67%|██████▋   | 6998/10395 [19:58:32<8:54:15,  9.44s/it] 67%|██████▋   | 6999/10395 [19:58:42<9:01:20,  9.56s/it]                                                         {'loss': 0.8032, 'learning_rate': 5.094736035766714e-06, 'epoch': 0.67}
 67%|██████▋   | 6999/10395 [19:58:42<9:01:20,  9.56s/it] 67%|██████▋   | 7000/10395 [19:58:51<8:48:05,  9.33s/it]                                                         {'loss': 0.936, 'learning_rate': 5.092021142927127e-06, 'epoch': 0.67}
 67%|██████▋   | 7000/10395 [19:58:51<8:48:05,  9.33s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 7001/10395 [20:00:33<34:54:50, 37.03s/it]                                                          {'loss': 0.9195, 'learning_rate': 5.089306726543643e-06, 'epoch': 0.67}
 67%|██████▋   | 7001/10395 [20:00:33<34:54:50, 37.03s/it] 67%|██████▋   | 7002/10395 [20:00:40<26:38:28, 28.27s/it]                                                          {'loss': 0.9044, 'learning_rate': 5.086592786879765e-06, 'epoch': 0.67}
 67%|██████▋   | 7002/10395 [20:00:40<26:38:28, 28.27s/it] 67%|██████▋   | 7003/10395 [20:00:49<20:59:15, 22.27s/it]                                                          {'loss': 0.8595, 'learning_rate': 5.0838793241989635e-06, 'epoch': 0.67}
 67%|██████▋   | 7003/10395 [20:00:49<20:59:15, 22.27s/it] 67%|██████▋   | 7004/10395 [20:00:57<16:58:24, 18.02s/it]                                                          {'loss': 0.9033, 'learning_rate': 5.081166338764651e-06, 'epoch': 0.67}
 67%|██████▋   | 7004/10395 [20:00:57<16:58:24, 18.02s/it] 67%|██████▋   | 7005/10395 [20:01:04<13:53:37, 14.75s/it]                                                          {'loss': 0.8785, 'learning_rate': 5.078453830840193e-06, 'epoch': 0.67}
 67%|██████▋   | 7005/10395 [20:01:04<13:53:37, 14.75s/it] 67%|██████▋   | 7006/10395 [20:01:22<14:51:14, 15.78s/it]                                                          {'loss': 0.3361, 'learning_rate': 5.075741800688926e-06, 'epoch': 0.67}
 67%|██████▋   | 7006/10395 [20:01:22<14:51:14, 15.78s/it] 67%|██████▋   | 7007/10395 [20:01:30<12:30:17, 13.29s/it]                                                          {'loss': 0.8976, 'learning_rate': 5.073030248574116e-06, 'epoch': 0.67}
 67%|██████▋   | 7007/10395 [20:01:30<12:30:17, 13.29s/it] 67%|██████▋   | 7008/10395 [20:01:37<10:51:49, 11.55s/it]                                                          {'loss': 0.8807, 'learning_rate': 5.0703191747590015e-06, 'epoch': 0.67}
 67%|██████▋   | 7008/10395 [20:01:37<10:51:49, 11.55s/it] 67%|██████▋   | 7009/10395 [20:01:46<10:00:39, 10.64s/it]                                                          {'loss': 0.8747, 'learning_rate': 5.067608579506771e-06, 'epoch': 0.67}
 67%|██████▋   | 7009/10395 [20:01:46<10:00:39, 10.64s/it] 67%|██████▋   | 7010/10395 [20:01:53<9:10:49,  9.76s/it]                                                          {'loss': 0.865, 'learning_rate': 5.064898463080555e-06, 'epoch': 0.67}
 67%|██████▋   | 7010/10395 [20:01:53<9:10:49,  9.76s/it] 67%|██████▋   | 7011/10395 [20:02:02<8:48:49,  9.38s/it]                                                         {'loss': 0.888, 'learning_rate': 5.0621888257434535e-06, 'epoch': 0.67}
 67%|██████▋   | 7011/10395 [20:02:02<8:48:49,  9.38s/it] 67%|██████▋   | 7012/10395 [20:02:10<8:25:41,  8.97s/it]                                                         {'loss': 0.8678, 'learning_rate': 5.059479667758509e-06, 'epoch': 0.67}
 67%|██████▋   | 7012/10395 [20:02:10<8:25:41,  8.97s/it] 67%|██████▋   | 7013/10395 [20:02:18<8:07:09,  8.64s/it]                                                         {'loss': 0.9565, 'learning_rate': 5.056770989388716e-06, 'epoch': 0.67}
 67%|██████▋   | 7013/10395 [20:02:18<8:07:09,  8.64s/it] 67%|██████▋   | 7014/10395 [20:02:26<7:55:32,  8.44s/it]                                                         {'loss': 0.8942, 'learning_rate': 5.054062790897036e-06, 'epoch': 0.67}
 67%|██████▋   | 7014/10395 [20:02:26<7:55:32,  8.44s/it] 67%|██████▋   | 7015/10395 [20:02:33<7:35:08,  8.08s/it]                                                         {'loss': 0.8307, 'learning_rate': 5.051355072546367e-06, 'epoch': 0.67}
 67%|██████▋   | 7015/10395 [20:02:33<7:35:08,  8.08s/it] 67%|██████▋   | 7016/10395 [20:02:40<7:27:19,  7.94s/it]                                                         {'loss': 0.847, 'learning_rate': 5.048647834599571e-06, 'epoch': 0.67}
 67%|██████▋   | 7016/10395 [20:02:40<7:27:19,  7.94s/it] 68%|██████▊   | 7017/10395 [20:02:49<7:45:58,  8.28s/it]                                                         {'loss': 0.8348, 'learning_rate': 5.045941077319467e-06, 'epoch': 0.68}
 68%|██████▊   | 7017/10395 [20:02:49<7:45:58,  8.28s/it] 68%|██████▊   | 7018/10395 [20:02:57<7:28:15,  7.96s/it]                                                         {'loss': 0.8869, 'learning_rate': 5.043234800968813e-06, 'epoch': 0.68}
 68%|██████▊   | 7018/10395 [20:02:57<7:28:15,  7.96s/it] 68%|██████▊   | 7019/10395 [20:03:04<7:24:42,  7.90s/it]                                                         {'loss': 0.8561, 'learning_rate': 5.040529005810335e-06, 'epoch': 0.68}
 68%|██████▊   | 7019/10395 [20:03:04<7:24:42,  7.90s/it] 68%|██████▊   | 7020/10395 [20:03:12<7:16:54,  7.77s/it]                                                         {'loss': 0.8905, 'learning_rate': 5.037823692106703e-06, 'epoch': 0.68}
 68%|██████▊   | 7020/10395 [20:03:12<7:16:54,  7.77s/it] 68%|██████▊   | 7021/10395 [20:03:29<9:51:02, 10.51s/it]                                                         {'loss': 0.3918, 'learning_rate': 5.035118860120538e-06, 'epoch': 0.68}
 68%|██████▊   | 7021/10395 [20:03:29<9:51:02, 10.51s/it] 68%|██████▊   | 7022/10395 [20:03:36<8:52:15,  9.47s/it]                                                         {'loss': 0.8486, 'learning_rate': 5.03241451011443e-06, 'epoch': 0.68}
 68%|██████▊   | 7022/10395 [20:03:36<8:52:15,  9.47s/it] 68%|██████▊   | 7023/10395 [20:03:44<8:31:21,  9.10s/it]                                                         {'loss': 0.831, 'learning_rate': 5.0297106423509e-06, 'epoch': 0.68}
 68%|██████▊   | 7023/10395 [20:03:44<8:31:21,  9.10s/it] 68%|██████▊   | 7024/10395 [20:03:51<8:00:55,  8.56s/it]                                                         {'loss': 0.9056, 'learning_rate': 5.02700725709244e-06, 'epoch': 0.68}
 68%|██████▊   | 7024/10395 [20:03:51<8:00:55,  8.56s/it] 68%|██████▊   | 7025/10395 [20:03:59<7:40:09,  8.19s/it]                                                         {'loss': 0.8535, 'learning_rate': 5.0243043546014915e-06, 'epoch': 0.68}
 68%|██████▊   | 7025/10395 [20:03:59<7:40:09,  8.19s/it] 68%|██████▊   | 7026/10395 [20:04:06<7:28:21,  7.99s/it]                                                         {'loss': 0.9294, 'learning_rate': 5.021601935140443e-06, 'epoch': 0.68}
 68%|██████▊   | 7026/10395 [20:04:06<7:28:21,  7.99s/it] 68%|██████▊   | 7027/10395 [20:04:14<7:20:06,  7.84s/it]                                                         {'loss': 0.8557, 'learning_rate': 5.0188999989716354e-06, 'epoch': 0.68}
 68%|██████▊   | 7027/10395 [20:04:14<7:20:06,  7.84s/it] 68%|██████▊   | 7028/10395 [20:04:31<9:55:21, 10.61s/it]                                                         {'loss': 0.4008, 'learning_rate': 5.016198546357377e-06, 'epoch': 0.68}
 68%|██████▊   | 7028/10395 [20:04:31<9:55:21, 10.61s/it] 68%|██████▊   | 7029/10395 [20:04:39<9:09:48,  9.80s/it]                                                         {'loss': 0.8617, 'learning_rate': 5.0134975775599095e-06, 'epoch': 0.68}
 68%|██████▊   | 7029/10395 [20:04:39<9:09:48,  9.80s/it] 68%|██████▊   | 7030/10395 [20:04:47<8:36:42,  9.21s/it]                                                         {'loss': 0.9038, 'learning_rate': 5.010797092841443e-06, 'epoch': 0.68}
 68%|██████▊   | 7030/10395 [20:04:47<8:36:42,  9.21s/it] 68%|██████▊   | 7031/10395 [20:04:54<8:09:06,  8.72s/it]                                                         {'loss': 0.7953, 'learning_rate': 5.0080970924641304e-06, 'epoch': 0.68}
 68%|██████▊   | 7031/10395 [20:04:54<8:09:06,  8.72s/it] 68%|██████▊   | 7032/10395 [20:05:02<7:51:39,  8.42s/it]                                                         {'loss': 0.8704, 'learning_rate': 5.005397576690083e-06, 'epoch': 0.68}
 68%|██████▊   | 7032/10395 [20:05:02<7:51:39,  8.42s/it] 68%|██████▊   | 7033/10395 [20:05:09<7:30:43,  8.04s/it]                                                         {'loss': 0.9826, 'learning_rate': 5.002698545781374e-06, 'epoch': 0.68}
 68%|██████▊   | 7033/10395 [20:05:09<7:30:43,  8.04s/it] 68%|██████▊   | 7034/10395 [20:05:17<7:28:23,  8.00s/it]                                                         {'loss': 0.8963, 'learning_rate': 5.000000000000003e-06, 'epoch': 0.68}
 68%|██████▊   | 7034/10395 [20:05:17<7:28:23,  8.00s/it] 68%|██████▊   | 7035/10395 [20:05:25<7:34:06,  8.11s/it]                                                         {'loss': 0.8205, 'learning_rate': 4.997301939607946e-06, 'epoch': 0.68}
 68%|██████▊   | 7035/10395 [20:05:25<7:34:06,  8.11s/it] 68%|██████▊   | 7036/10395 [20:05:33<7:29:32,  8.03s/it]                                                         {'loss': 0.8777, 'learning_rate': 4.99460436486713e-06, 'epoch': 0.68}
 68%|██████▊   | 7036/10395 [20:05:33<7:29:32,  8.03s/it] 68%|██████▊   | 7037/10395 [20:05:41<7:27:41,  8.00s/it]                                                         {'loss': 0.8619, 'learning_rate': 4.991907276039424e-06, 'epoch': 0.68}
 68%|██████▊   | 7037/10395 [20:05:41<7:27:41,  8.00s/it] 68%|██████▊   | 7038/10395 [20:05:49<7:21:13,  7.89s/it]                                                         {'loss': 0.8763, 'learning_rate': 4.989210673386658e-06, 'epoch': 0.68}
 68%|██████▊   | 7038/10395 [20:05:49<7:21:13,  7.89s/it] 68%|██████▊   | 7039/10395 [20:05:56<7:10:19,  7.69s/it]                                                         {'loss': 0.9168, 'learning_rate': 4.986514557170611e-06, 'epoch': 0.68}
 68%|██████▊   | 7039/10395 [20:05:56<7:10:19,  7.69s/it] 68%|██████▊   | 7040/10395 [20:06:03<7:07:34,  7.65s/it]                                                         {'loss': 0.8325, 'learning_rate': 4.983818927653014e-06, 'epoch': 0.68}
 68%|██████▊   | 7040/10395 [20:06:03<7:07:34,  7.65s/it] 68%|██████▊   | 7041/10395 [20:06:11<7:05:54,  7.62s/it]                                                         {'loss': 0.8365, 'learning_rate': 4.981123785095566e-06, 'epoch': 0.68}
 68%|██████▊   | 7041/10395 [20:06:11<7:05:54,  7.62s/it] 68%|██████▊   | 7042/10395 [20:06:19<7:09:14,  7.68s/it]                                                         {'loss': 0.9206, 'learning_rate': 4.9784291297598865e-06, 'epoch': 0.68}
 68%|██████▊   | 7042/10395 [20:06:19<7:09:14,  7.68s/it] 68%|██████▊   | 7043/10395 [20:06:26<7:05:02,  7.61s/it]                                                         {'loss': 0.8586, 'learning_rate': 4.975734961907577e-06, 'epoch': 0.68}
 68%|██████▊   | 7043/10395 [20:06:26<7:05:02,  7.61s/it] 68%|██████▊   | 7044/10395 [20:06:36<7:32:23,  8.10s/it]                                                         {'loss': 0.8083, 'learning_rate': 4.9730412818001825e-06, 'epoch': 0.68}
 68%|██████▊   | 7044/10395 [20:06:36<7:32:23,  8.10s/it] 68%|██████▊   | 7045/10395 [20:06:43<7:22:39,  7.93s/it]                                                         {'loss': 0.9119, 'learning_rate': 4.970348089699196e-06, 'epoch': 0.68}
 68%|██████▊   | 7045/10395 [20:06:43<7:22:39,  7.93s/it] 68%|██████▊   | 7046/10395 [20:06:51<7:14:35,  7.79s/it]                                                         {'loss': 0.8154, 'learning_rate': 4.967655385866072e-06, 'epoch': 0.68}
 68%|██████▊   | 7046/10395 [20:06:51<7:14:35,  7.79s/it] 68%|██████▊   | 7047/10395 [20:06:59<7:18:37,  7.86s/it]                                                         {'loss': 0.7684, 'learning_rate': 4.964963170562204e-06, 'epoch': 0.68}
 68%|██████▊   | 7047/10395 [20:06:59<7:18:37,  7.86s/it] 68%|██████▊   | 7048/10395 [20:07:07<7:30:31,  8.08s/it]                                                         {'loss': 0.8586, 'learning_rate': 4.962271444048956e-06, 'epoch': 0.68}
 68%|██████▊   | 7048/10395 [20:07:07<7:30:31,  8.08s/it] 68%|██████▊   | 7049/10395 [20:07:15<7:24:57,  7.98s/it]                                                         {'loss': 0.8812, 'learning_rate': 4.959580206587626e-06, 'epoch': 0.68}
 68%|██████▊   | 7049/10395 [20:07:15<7:24:57,  7.98s/it] 68%|██████▊   | 7050/10395 [20:07:22<7:15:13,  7.81s/it]                                                         {'loss': 0.9284, 'learning_rate': 4.9568894584394835e-06, 'epoch': 0.68}
 68%|██████▊   | 7050/10395 [20:07:22<7:15:13,  7.81s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 68%|██████▊   | 7051/10395 [20:09:02<32:59:03, 35.51s/it]                                                          {'loss': 0.8545, 'learning_rate': 4.9541991998657305e-06, 'epoch': 0.68}
 68%|██████▊   | 7051/10395 [20:09:02<32:59:03, 35.51s/it] 68%|██████▊   | 7052/10395 [20:09:10<25:14:46, 27.19s/it]                                                          {'loss': 0.8541, 'learning_rate': 4.951509431127539e-06, 'epoch': 0.68}
 68%|██████▊   | 7052/10395 [20:09:10<25:14:46, 27.19s/it] 68%|██████▊   | 7053/10395 [20:09:26<22:08:58, 23.86s/it]                                                          {'loss': 0.3614, 'learning_rate': 4.948820152486021e-06, 'epoch': 0.68}
 68%|██████▊   | 7053/10395 [20:09:26<22:08:58, 23.86s/it] 68%|██████▊   | 7054/10395 [20:09:34<17:36:03, 18.97s/it]                                                          {'loss': 0.8943, 'learning_rate': 4.9461313642022476e-06, 'epoch': 0.68}
 68%|██████▊   | 7054/10395 [20:09:34<17:36:03, 18.97s/it] 68%|██████▊   | 7055/10395 [20:09:51<17:07:39, 18.46s/it]                                                          {'loss': 0.399, 'learning_rate': 4.943443066537249e-06, 'epoch': 0.68}
 68%|██████▊   | 7055/10395 [20:09:51<17:07:39, 18.46s/it] 68%|██████▊   | 7056/10395 [20:09:59<14:05:36, 15.20s/it]                                                          {'loss': 0.8987, 'learning_rate': 4.940755259751984e-06, 'epoch': 0.68}
 68%|██████▊   | 7056/10395 [20:09:59<14:05:36, 15.20s/it] 68%|██████▊   | 7057/10395 [20:10:06<11:56:25, 12.88s/it]                                                          {'loss': 0.956, 'learning_rate': 4.938067944107387e-06, 'epoch': 0.68}
 68%|██████▊   | 7057/10395 [20:10:06<11:56:25, 12.88s/it] 68%|██████▊   | 7058/10395 [20:10:14<10:35:46, 11.43s/it]                                                          {'loss': 0.8597, 'learning_rate': 4.9353811198643395e-06, 'epoch': 0.68}
 68%|██████▊   | 7058/10395 [20:10:14<10:35:46, 11.43s/it] 68%|██████▊   | 7059/10395 [20:10:22<9:41:52, 10.47s/it]                                                          {'loss': 0.9391, 'learning_rate': 4.932694787283667e-06, 'epoch': 0.68}
 68%|██████▊   | 7059/10395 [20:10:22<9:41:52, 10.47s/it] 68%|██████▊   | 7060/10395 [20:10:38<11:13:31, 12.12s/it]                                                          {'loss': 0.3504, 'learning_rate': 4.930008946626159e-06, 'epoch': 0.68}
 68%|██████▊   | 7060/10395 [20:10:38<11:13:31, 12.12s/it] 68%|██████▊   | 7061/10395 [20:10:46<10:03:00, 10.85s/it]                                                          {'loss': 0.8125, 'learning_rate': 4.9273235981525435e-06, 'epoch': 0.68}
 68%|██████▊   | 7061/10395 [20:10:46<10:03:00, 10.85s/it] 68%|██████▊   | 7062/10395 [20:10:54<9:07:48,  9.86s/it]                                                          {'loss': 0.9694, 'learning_rate': 4.924638742123514e-06, 'epoch': 0.68}
 68%|██████▊   | 7062/10395 [20:10:54<9:07:48,  9.86s/it] 68%|██████▊   | 7063/10395 [20:11:01<8:28:07,  9.15s/it]                                                         {'loss': 0.968, 'learning_rate': 4.921954378799716e-06, 'epoch': 0.68}
 68%|██████▊   | 7063/10395 [20:11:01<8:28:07,  9.15s/it] 68%|██████▊   | 7064/10395 [20:11:09<7:57:21,  8.60s/it]                                                         {'loss': 0.8604, 'learning_rate': 4.919270508441728e-06, 'epoch': 0.68}
 68%|██████▊   | 7064/10395 [20:11:09<7:57:21,  8.60s/it] 68%|██████▊   | 7065/10395 [20:11:16<7:44:08,  8.36s/it]                                                         {'loss': 0.8495, 'learning_rate': 4.916587131310101e-06, 'epoch': 0.68}
 68%|██████▊   | 7065/10395 [20:11:17<7:44:08,  8.36s/it] 68%|██████▊   | 7066/10395 [20:11:24<7:30:03,  8.11s/it]                                                         {'loss': 0.9058, 'learning_rate': 4.913904247665336e-06, 'epoch': 0.68}
 68%|██████▊   | 7066/10395 [20:11:24<7:30:03,  8.11s/it] 68%|██████▊   | 7067/10395 [20:11:32<7:21:40,  7.96s/it]                                                         {'loss': 0.8247, 'learning_rate': 4.911221857767874e-06, 'epoch': 0.68}
 68%|██████▊   | 7067/10395 [20:11:32<7:21:40,  7.96s/it] 68%|██████▊   | 7068/10395 [20:11:39<7:19:30,  7.93s/it]                                                         {'loss': 0.802, 'learning_rate': 4.9085399618781226e-06, 'epoch': 0.68}
 68%|██████▊   | 7068/10395 [20:11:39<7:19:30,  7.93s/it] 68%|██████▊   | 7069/10395 [20:11:47<7:16:23,  7.87s/it]                                                         {'loss': 0.8704, 'learning_rate': 4.905858560256428e-06, 'epoch': 0.68}
 68%|██████▊   | 7069/10395 [20:11:47<7:16:23,  7.87s/it] 68%|██████▊   | 7070/10395 [20:11:55<7:13:18,  7.82s/it]                                                         {'loss': 0.8614, 'learning_rate': 4.903177653163101e-06, 'epoch': 0.68}
 68%|██████▊   | 7070/10395 [20:11:55<7:13:18,  7.82s/it] 68%|██████▊   | 7071/10395 [20:12:02<7:04:26,  7.66s/it]                                                         {'loss': 0.851, 'learning_rate': 4.900497240858398e-06, 'epoch': 0.68}
 68%|██████▊   | 7071/10395 [20:12:02<7:04:26,  7.66s/it] 68%|██████▊   | 7072/10395 [20:12:10<7:01:01,  7.60s/it]                                                         {'loss': 0.9027, 'learning_rate': 4.8978173236025184e-06, 'epoch': 0.68}
 68%|██████▊   | 7072/10395 [20:12:10<7:01:01,  7.60s/it] 68%|██████▊   | 7073/10395 [20:12:18<7:07:49,  7.73s/it]                                                         {'loss': 0.8819, 'learning_rate': 4.895137901655631e-06, 'epoch': 0.68}
 68%|██████▊   | 7073/10395 [20:12:18<7:07:49,  7.73s/it] 68%|██████▊   | 7074/10395 [20:12:25<7:07:44,  7.73s/it]                                                         {'loss': 0.9513, 'learning_rate': 4.892458975277851e-06, 'epoch': 0.68}
 68%|██████▊   | 7074/10395 [20:12:25<7:07:44,  7.73s/it] 68%|██████▊   | 7075/10395 [20:12:33<7:04:41,  7.68s/it]                                                         {'loss': 0.8291, 'learning_rate': 4.8897805447292334e-06, 'epoch': 0.68}
 68%|██████▊   | 7075/10395 [20:12:33<7:04:41,  7.68s/it] 68%|██████▊   | 7076/10395 [20:12:41<7:06:05,  7.70s/it]                                                         {'loss': 0.8612, 'learning_rate': 4.887102610269805e-06, 'epoch': 0.68}
 68%|██████▊   | 7076/10395 [20:12:41<7:06:05,  7.70s/it] 68%|██████▊   | 7077/10395 [20:12:48<7:03:14,  7.65s/it]                                                         {'loss': 0.869, 'learning_rate': 4.884425172159529e-06, 'epoch': 0.68}
 68%|██████▊   | 7077/10395 [20:12:48<7:03:14,  7.65s/it] 68%|██████▊   | 7078/10395 [20:12:58<7:29:47,  8.14s/it]                                                         {'loss': 0.8086, 'learning_rate': 4.881748230658322e-06, 'epoch': 0.68}
 68%|██████▊   | 7078/10395 [20:12:58<7:29:47,  8.14s/it] 68%|██████▊   | 7079/10395 [20:13:05<7:18:29,  7.93s/it]                                                         {'loss': 0.8514, 'learning_rate': 4.879071786026062e-06, 'epoch': 0.68}
 68%|██████▊   | 7079/10395 [20:13:05<7:18:29,  7.93s/it] 68%|██████▊   | 7080/10395 [20:13:13<7:13:24,  7.84s/it]                                                         {'loss': 0.864, 'learning_rate': 4.876395838522565e-06, 'epoch': 0.68}
 68%|██████▊   | 7080/10395 [20:13:13<7:13:24,  7.84s/it] 68%|██████▊   | 7081/10395 [20:13:20<7:09:34,  7.78s/it]                                                         {'loss': 0.8773, 'learning_rate': 4.873720388407612e-06, 'epoch': 0.68}
 68%|██████▊   | 7081/10395 [20:13:20<7:09:34,  7.78s/it] 68%|██████▊   | 7082/10395 [20:13:29<7:19:19,  7.96s/it]                                                         {'loss': 0.86, 'learning_rate': 4.871045435940932e-06, 'epoch': 0.68}
 68%|██████▊   | 7082/10395 [20:13:29<7:19:19,  7.96s/it] 68%|██████▊   | 7083/10395 [20:13:45<9:36:55, 10.45s/it]                                                         {'loss': 0.3375, 'learning_rate': 4.868370981382198e-06, 'epoch': 0.68}
 68%|██████▊   | 7083/10395 [20:13:45<9:36:55, 10.45s/it] 68%|██████▊   | 7084/10395 [20:13:53<8:57:37,  9.74s/it]                                                         {'loss': 0.8676, 'learning_rate': 4.865697024991045e-06, 'epoch': 0.68}
 68%|██████▊   | 7084/10395 [20:13:53<8:57:37,  9.74s/it] 68%|██████▊   | 7085/10395 [20:14:00<8:13:15,  8.94s/it]                                                         {'loss': 0.8651, 'learning_rate': 4.863023567027053e-06, 'epoch': 0.68}
 68%|██████▊   | 7085/10395 [20:14:00<8:13:15,  8.94s/it] 68%|██████▊   | 7086/10395 [20:14:09<8:07:47,  8.84s/it]                                                         {'loss': 0.7854, 'learning_rate': 4.860350607749752e-06, 'epoch': 0.68}
 68%|██████▊   | 7086/10395 [20:14:09<8:07:47,  8.84s/it] 68%|██████▊   | 7087/10395 [20:14:16<7:44:53,  8.43s/it]                                                         {'loss': 0.8576, 'learning_rate': 4.857678147418634e-06, 'epoch': 0.68}
 68%|██████▊   | 7087/10395 [20:14:16<7:44:53,  8.43s/it] 68%|██████▊   | 7088/10395 [20:14:24<7:36:07,  8.28s/it]                                                         {'loss': 0.8072, 'learning_rate': 4.85500618629313e-06, 'epoch': 0.68}
 68%|██████▊   | 7088/10395 [20:14:24<7:36:07,  8.28s/it] 68%|██████▊   | 7089/10395 [20:14:32<7:26:15,  8.10s/it]                                                         {'loss': 0.9128, 'learning_rate': 4.852334724632628e-06, 'epoch': 0.68}
 68%|██████▊   | 7089/10395 [20:14:32<7:26:15,  8.10s/it] 68%|██████▊   | 7090/10395 [20:14:40<7:21:45,  8.02s/it]                                                         {'loss': 0.8204, 'learning_rate': 4.849663762696476e-06, 'epoch': 0.68}
 68%|██████▊   | 7090/10395 [20:14:40<7:21:45,  8.02s/it] 68%|██████▊   | 7091/10395 [20:14:47<7:18:10,  7.96s/it]                                                         {'loss': 0.8353, 'learning_rate': 4.846993300743955e-06, 'epoch': 0.68}
 68%|██████▊   | 7091/10395 [20:14:47<7:18:10,  7.96s/it] 68%|██████▊   | 7092/10395 [20:14:56<7:21:27,  8.02s/it]                                                         {'loss': 0.8533, 'learning_rate': 4.844323339034315e-06, 'epoch': 0.68}
 68%|██████▊   | 7092/10395 [20:14:56<7:21:27,  8.02s/it] 68%|██████▊   | 7093/10395 [20:15:03<7:07:49,  7.77s/it]                                                         {'loss': 0.8674, 'learning_rate': 4.84165387782675e-06, 'epoch': 0.68}
 68%|██████▊   | 7093/10395 [20:15:03<7:07:49,  7.77s/it] 68%|██████▊   | 7094/10395 [20:15:11<7:09:43,  7.81s/it]                                                         {'loss': 0.9218, 'learning_rate': 4.838984917380398e-06, 'epoch': 0.68}
 68%|██████▊   | 7094/10395 [20:15:11<7:09:43,  7.81s/it] 68%|██████▊   | 7095/10395 [20:15:18<7:07:15,  7.77s/it]                                                         {'loss': 0.892, 'learning_rate': 4.836316457954365e-06, 'epoch': 0.68}
 68%|██████▊   | 7095/10395 [20:15:18<7:07:15,  7.77s/it] 68%|██████▊   | 7096/10395 [20:15:26<7:09:11,  7.81s/it]                                                         {'loss': 0.947, 'learning_rate': 4.833648499807691e-06, 'epoch': 0.68}
 68%|██████▊   | 7096/10395 [20:15:26<7:09:11,  7.81s/it] 68%|██████▊   | 7097/10395 [20:15:35<7:24:57,  8.10s/it]                                                         {'loss': 0.8033, 'learning_rate': 4.830981043199382e-06, 'epoch': 0.68}
 68%|██████▊   | 7097/10395 [20:15:35<7:24:57,  8.10s/it] 68%|██████▊   | 7098/10395 [20:15:42<7:03:02,  7.70s/it]                                                         {'loss': 0.9507, 'learning_rate': 4.8283140883883895e-06, 'epoch': 0.68}
 68%|██████▊   | 7098/10395 [20:15:42<7:03:02,  7.70s/it] 68%|██████▊   | 7099/10395 [20:15:51<7:26:04,  8.12s/it]                                                         {'loss': 0.7587, 'learning_rate': 4.825647635633614e-06, 'epoch': 0.68}
 68%|██████▊   | 7099/10395 [20:15:51<7:26:04,  8.12s/it] 68%|██████▊   | 7100/10395 [20:15:59<7:22:35,  8.06s/it]                                                         {'loss': 0.9436, 'learning_rate': 4.822981685193903e-06, 'epoch': 0.68}
 68%|██████▊   | 7100/10395 [20:15:59<7:22:35,  8.06s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 68%|██████▊   | 7101/10395 [20:17:36<31:58:00, 34.94s/it]                                                          {'loss': 0.9453, 'learning_rate': 4.820316237328072e-06, 'epoch': 0.68}
 68%|██████▊   | 7101/10395 [20:17:36<31:58:00, 34.94s/it] 68%|██████▊   | 7102/10395 [20:17:46<24:55:03, 27.24s/it]                                                          {'loss': 0.8707, 'learning_rate': 4.817651292294868e-06, 'epoch': 0.68}
 68%|██████▊   | 7102/10395 [20:17:46<24:55:03, 27.24s/it] 68%|██████▊   | 7103/10395 [20:17:53<19:30:17, 21.33s/it]                                                          {'loss': 0.9026, 'learning_rate': 4.814986850353005e-06, 'epoch': 0.68}
 68%|██████▊   | 7103/10395 [20:17:53<19:30:17, 21.33s/it] 68%|██████▊   | 7104/10395 [20:18:01<15:52:25, 17.36s/it]                                                          {'loss': 0.8644, 'learning_rate': 4.812322911761135e-06, 'epoch': 0.68}
 68%|██████▊   | 7104/10395 [20:18:01<15:52:25, 17.36s/it] 68%|██████▊   | 7105/10395 [20:18:10<13:22:48, 14.64s/it]                                                          {'loss': 0.9254, 'learning_rate': 4.809659476777869e-06, 'epoch': 0.68}
 68%|██████▊   | 7105/10395 [20:18:10<13:22:48, 14.64s/it] 68%|██████▊   | 7106/10395 [20:18:18<11:33:53, 12.66s/it]                                                          {'loss': 0.8399, 'learning_rate': 4.806996545661775e-06, 'epoch': 0.68}
 68%|██████▊   | 7106/10395 [20:18:18<11:33:53, 12.66s/it] 68%|██████▊   | 7107/10395 [20:18:26<10:14:59, 11.22s/it]                                                          {'loss': 0.8584, 'learning_rate': 4.804334118671358e-06, 'epoch': 0.68}
 68%|██████▊   | 7107/10395 [20:18:26<10:14:59, 11.22s/it] 68%|██████▊   | 7108/10395 [20:18:34<9:27:55, 10.37s/it]                                                          {'loss': 0.8267, 'learning_rate': 4.801672196065078e-06, 'epoch': 0.68}
 68%|██████▊   | 7108/10395 [20:18:34<9:27:55, 10.37s/it] 68%|██████▊   | 7109/10395 [20:18:42<8:41:48,  9.53s/it]                                                         {'loss': 0.9563, 'learning_rate': 4.799010778101355e-06, 'epoch': 0.68}
 68%|██████▊   | 7109/10395 [20:18:42<8:41:48,  9.53s/it] 68%|██████▊   | 7110/10395 [20:18:49<8:12:02,  8.99s/it]                                                         {'loss': 0.8607, 'learning_rate': 4.7963498650385485e-06, 'epoch': 0.68}
 68%|██████▊   | 7110/10395 [20:18:49<8:12:02,  8.99s/it] 68%|██████▊   | 7111/10395 [20:18:57<7:50:58,  8.60s/it]                                                         {'loss': 0.8874, 'learning_rate': 4.79368945713498e-06, 'epoch': 0.68}
 68%|██████▊   | 7111/10395 [20:18:57<7:50:58,  8.60s/it] 68%|██████▊   | 7112/10395 [20:19:04<7:27:27,  8.18s/it]                                                         {'loss': 0.931, 'learning_rate': 4.791029554648911e-06, 'epoch': 0.68}
 68%|██████▊   | 7112/10395 [20:19:04<7:27:27,  8.18s/it] 68%|██████▊   | 7113/10395 [20:19:13<7:39:36,  8.40s/it]                                                         {'loss': 0.7343, 'learning_rate': 4.788370157838559e-06, 'epoch': 0.68}
 68%|██████▊   | 7113/10395 [20:19:13<7:39:36,  8.40s/it] 68%|██████▊   | 7114/10395 [20:19:20<7:23:05,  8.10s/it]                                                         {'loss': 0.8981, 'learning_rate': 4.7857112669621e-06, 'epoch': 0.68}
 68%|██████▊   | 7114/10395 [20:19:20<7:23:05,  8.10s/it] 68%|██████▊   | 7115/10395 [20:19:38<9:55:40, 10.90s/it]                                                         {'loss': 0.3561, 'learning_rate': 4.783052882277648e-06, 'epoch': 0.68}
 68%|██████▊   | 7115/10395 [20:19:38<9:55:40, 10.90s/it] 68%|██████▊   | 7116/10395 [20:19:46<9:01:56,  9.92s/it]                                                         {'loss': 0.8911, 'learning_rate': 4.780395004043269e-06, 'epoch': 0.68}
 68%|██████▊   | 7116/10395 [20:19:46<9:01:56,  9.92s/it] 68%|██████▊   | 7117/10395 [20:19:54<8:30:33,  9.35s/it]                                                         {'loss': 0.8866, 'learning_rate': 4.7777376325169935e-06, 'epoch': 0.68}
 68%|██████▊   | 7117/10395 [20:19:54<8:30:33,  9.35s/it] 68%|██████▊   | 7118/10395 [20:20:02<8:10:17,  8.98s/it]                                                         {'loss': 0.9138, 'learning_rate': 4.7750807679567835e-06, 'epoch': 0.68}
 68%|██████▊   | 7118/10395 [20:20:02<8:10:17,  8.98s/it] 68%|██████▊   | 7119/10395 [20:20:10<8:03:05,  8.85s/it]                                                         {'loss': 0.8579, 'learning_rate': 4.772424410620567e-06, 'epoch': 0.68}
 68%|██████▊   | 7119/10395 [20:20:10<8:03:05,  8.85s/it] 68%|██████▊   | 7120/10395 [20:20:18<7:51:57,  8.65s/it]                                                         {'loss': 0.8176, 'learning_rate': 4.7697685607662225e-06, 'epoch': 0.68}
 68%|██████▊   | 7120/10395 [20:20:18<7:51:57,  8.65s/it] 69%|██████▊   | 7121/10395 [20:20:27<7:49:45,  8.61s/it]                                                         {'loss': 0.8658, 'learning_rate': 4.767113218651568e-06, 'epoch': 0.69}
 69%|██████▊   | 7121/10395 [20:20:27<7:49:45,  8.61s/it] 69%|██████▊   | 7122/10395 [20:20:34<7:31:24,  8.27s/it]                                                         {'loss': 0.8632, 'learning_rate': 4.764458384534376e-06, 'epoch': 0.69}
 69%|██████▊   | 7122/10395 [20:20:34<7:31:24,  8.27s/it] 69%|██████▊   | 7123/10395 [20:20:42<7:17:21,  8.02s/it]                                                         {'loss': 0.8721, 'learning_rate': 4.76180405867238e-06, 'epoch': 0.69}
 69%|██████▊   | 7123/10395 [20:20:42<7:17:21,  8.02s/it] 69%|██████▊   | 7124/10395 [20:20:50<7:15:23,  7.99s/it]                                                         {'loss': 0.9049, 'learning_rate': 4.759150241323247e-06, 'epoch': 0.69}
 69%|██████▊   | 7124/10395 [20:20:50<7:15:23,  7.99s/it] 69%|██████▊   | 7125/10395 [20:20:57<7:11:56,  7.93s/it]                                                         {'loss': 0.8351, 'learning_rate': 4.756496932744613e-06, 'epoch': 0.69}
 69%|██████▊   | 7125/10395 [20:20:57<7:11:56,  7.93s/it] 69%|██████▊   | 7126/10395 [20:21:06<7:16:36,  8.01s/it]                                                         {'loss': 0.893, 'learning_rate': 4.7538441331940485e-06, 'epoch': 0.69}
 69%|██████▊   | 7126/10395 [20:21:06<7:16:36,  8.01s/it] 69%|██████▊   | 7127/10395 [20:21:14<7:23:14,  8.14s/it]                                                         {'loss': 0.8378, 'learning_rate': 4.7511918429290835e-06, 'epoch': 0.69}
 69%|██████▊   | 7127/10395 [20:21:14<7:23:14,  8.14s/it] 69%|██████▊   | 7128/10395 [20:21:22<7:19:22,  8.07s/it]                                                         {'loss': 0.9206, 'learning_rate': 4.748540062207202e-06, 'epoch': 0.69}
 69%|██████▊   | 7128/10395 [20:21:22<7:19:22,  8.07s/it] 69%|██████▊   | 7129/10395 [20:21:30<7:16:21,  8.02s/it]                                                         {'loss': 0.9555, 'learning_rate': 4.745888791285829e-06, 'epoch': 0.69}
 69%|██████▊   | 7129/10395 [20:21:30<7:16:21,  8.02s/it] 69%|██████▊   | 7130/10395 [20:21:38<7:16:32,  8.02s/it]                                                         {'loss': 0.8814, 'learning_rate': 4.743238030422339e-06, 'epoch': 0.69}
 69%|██████▊   | 7130/10395 [20:21:38<7:16:32,  8.02s/it] 69%|██████▊   | 7131/10395 [20:21:45<7:06:31,  7.84s/it]                                                         {'loss': 0.9016, 'learning_rate': 4.740587779874072e-06, 'epoch': 0.69}
 69%|██████▊   | 7131/10395 [20:21:45<7:06:31,  7.84s/it] 69%|██████▊   | 7132/10395 [20:21:53<6:59:05,  7.71s/it]                                                         {'loss': 0.9124, 'learning_rate': 4.7379380398983e-06, 'epoch': 0.69}
 69%|██████▊   | 7132/10395 [20:21:53<6:59:05,  7.71s/it] 69%|██████▊   | 7133/10395 [20:22:00<6:50:09,  7.54s/it]                                                         {'loss': 0.8733, 'learning_rate': 4.735288810752262e-06, 'epoch': 0.69}
 69%|██████▊   | 7133/10395 [20:22:00<6:50:09,  7.54s/it] 69%|██████▊   | 7134/10395 [20:22:08<6:52:42,  7.59s/it]                                                         {'loss': 0.8287, 'learning_rate': 4.732640092693132e-06, 'epoch': 0.69}
 69%|██████▊   | 7134/10395 [20:22:08<6:52:42,  7.59s/it] 69%|██████▊   | 7135/10395 [20:22:15<6:53:34,  7.61s/it]                                                         {'loss': 0.8394, 'learning_rate': 4.729991885978045e-06, 'epoch': 0.69}
 69%|██████▊   | 7135/10395 [20:22:15<6:53:34,  7.61s/it] 69%|██████▊   | 7136/10395 [20:22:23<6:52:05,  7.59s/it]                                                         {'loss': 0.9038, 'learning_rate': 4.7273441908640905e-06, 'epoch': 0.69}
 69%|██████▊   | 7136/10395 [20:22:23<6:52:05,  7.59s/it] 69%|██████▊   | 7137/10395 [20:22:31<6:56:02,  7.66s/it]                                                         {'loss': 0.8893, 'learning_rate': 4.724697007608288e-06, 'epoch': 0.69}
 69%|██████▊   | 7137/10395 [20:22:31<6:56:02,  7.66s/it] 69%|██████▊   | 7138/10395 [20:22:38<6:49:36,  7.55s/it]                                                         {'loss': 0.911, 'learning_rate': 4.722050336467626e-06, 'epoch': 0.69}
 69%|██████▊   | 7138/10395 [20:22:38<6:49:36,  7.55s/it] 69%|██████▊   | 7139/10395 [20:22:45<6:47:13,  7.50s/it]                                                         {'loss': 0.9335, 'learning_rate': 4.719404177699042e-06, 'epoch': 0.69}
 69%|██████▊   | 7139/10395 [20:22:45<6:47:13,  7.50s/it] 69%|██████▊   | 7140/10395 [20:22:53<6:48:08,  7.52s/it]                                                         {'loss': 0.8524, 'learning_rate': 4.716758531559412e-06, 'epoch': 0.69}
 69%|██████▊   | 7140/10395 [20:22:53<6:48:08,  7.52s/it] 69%|██████▊   | 7141/10395 [20:23:00<6:48:06,  7.52s/it]                                                         {'loss': 0.9197, 'learning_rate': 4.714113398305577e-06, 'epoch': 0.69}
 69%|██████▊   | 7141/10395 [20:23:00<6:48:06,  7.52s/it] 69%|██████▊   | 7142/10395 [20:23:08<6:53:21,  7.62s/it]                                                         {'loss': 0.8421, 'learning_rate': 4.711468778194315e-06, 'epoch': 0.69}
 69%|██████▊   | 7142/10395 [20:23:08<6:53:21,  7.62s/it] 69%|██████▊   | 7143/10395 [20:23:16<6:56:35,  7.69s/it]                                                         {'loss': 0.8908, 'learning_rate': 4.708824671482361e-06, 'epoch': 0.69}
 69%|██████▊   | 7143/10395 [20:23:16<6:56:35,  7.69s/it] 69%|██████▊   | 7144/10395 [20:23:24<6:57:31,  7.71s/it]                                                         {'loss': 0.9097, 'learning_rate': 4.706181078426408e-06, 'epoch': 0.69}
 69%|██████▊   | 7144/10395 [20:23:24<6:57:31,  7.71s/it] 69%|██████▊   | 7145/10395 [20:23:32<6:55:41,  7.67s/it]                                                         {'loss': 0.9155, 'learning_rate': 4.703537999283076e-06, 'epoch': 0.69}
 69%|██████▊   | 7145/10395 [20:23:32<6:55:41,  7.67s/it] 69%|██████▊   | 7146/10395 [20:23:39<6:50:08,  7.57s/it]                                                         {'loss': 0.9179, 'learning_rate': 4.7008954343089565e-06, 'epoch': 0.69}
 69%|██████▊   | 7146/10395 [20:23:39<6:50:08,  7.57s/it] 69%|██████▉   | 7147/10395 [20:23:46<6:42:57,  7.44s/it]                                                         {'loss': 0.8673, 'learning_rate': 4.6982533837605885e-06, 'epoch': 0.69}
 69%|██████▉   | 7147/10395 [20:23:46<6:42:57,  7.44s/it] 69%|██████▉   | 7148/10395 [20:23:53<6:41:54,  7.43s/it]                                                         {'loss': 0.8777, 'learning_rate': 4.695611847894447e-06, 'epoch': 0.69}
 69%|██████▉   | 7148/10395 [20:23:53<6:41:54,  7.43s/it] 69%|██████▉   | 7149/10395 [20:24:01<6:51:37,  7.61s/it]                                                         {'loss': 0.8764, 'learning_rate': 4.692970826966976e-06, 'epoch': 0.69}
 69%|██████▉   | 7149/10395 [20:24:01<6:51:37,  7.61s/it] 69%|██████▉   | 7150/10395 [20:24:09<6:56:25,  7.70s/it]                                                         {'loss': 0.8969, 'learning_rate': 4.690330321234552e-06, 'epoch': 0.69}
 69%|██████▉   | 7150/10395 [20:24:09<6:56:25,  7.70s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 69%|██████▉   | 7151/10395 [20:25:49<31:55:04, 35.42s/it]                                                          {'loss': 0.8678, 'learning_rate': 4.687690330953517e-06, 'epoch': 0.69}
 69%|██████▉   | 7151/10395 [20:25:49<31:55:04, 35.42s/it] 69%|██████▉   | 7152/10395 [20:25:57<24:24:39, 27.10s/it]                                                          {'loss': 0.8231, 'learning_rate': 4.685050856380153e-06, 'epoch': 0.69}
 69%|██████▉   | 7152/10395 [20:25:57<24:24:39, 27.10s/it] 69%|██████▉   | 7153/10395 [20:26:05<19:10:52, 21.30s/it]                                                          {'loss': 0.9538, 'learning_rate': 4.68241189777069e-06, 'epoch': 0.69}
 69%|██████▉   | 7153/10395 [20:26:05<19:10:52, 21.30s/it] 69%|██████▉   | 7154/10395 [20:26:12<15:24:27, 17.11s/it]                                                          {'loss': 0.9196, 'learning_rate': 4.679773455381316e-06, 'epoch': 0.69}
 69%|██████▉   | 7154/10395 [20:26:12<15:24:27, 17.11s/it] 69%|██████▉   | 7155/10395 [20:26:20<12:53:41, 14.33s/it]                                                          {'loss': 0.8076, 'learning_rate': 4.67713552946817e-06, 'epoch': 0.69}
 69%|██████▉   | 7155/10395 [20:26:20<12:53:41, 14.33s/it] 69%|██████▉   | 7156/10395 [20:26:28<11:07:57, 12.37s/it]                                                          {'loss': 0.8964, 'learning_rate': 4.674498120287328e-06, 'epoch': 0.69}
 69%|██████▉   | 7156/10395 [20:26:28<11:07:57, 12.37s/it] 69%|██████▉   | 7157/10395 [20:26:36<10:01:06, 11.14s/it]                                                          {'loss': 0.8647, 'learning_rate': 4.671861228094831e-06, 'epoch': 0.69}
 69%|██████▉   | 7157/10395 [20:26:36<10:01:06, 11.14s/it] 69%|██████▉   | 7158/10395 [20:26:43<8:58:31,  9.98s/it]                                                          {'loss': 0.9236, 'learning_rate': 4.669224853146659e-06, 'epoch': 0.69}
 69%|██████▉   | 7158/10395 [20:26:43<8:58:31,  9.98s/it] 69%|██████▉   | 7159/10395 [20:26:52<8:43:25,  9.70s/it]                                                         {'loss': 0.8663, 'learning_rate': 4.666588995698743e-06, 'epoch': 0.69}
 69%|██████▉   | 7159/10395 [20:26:52<8:43:25,  9.70s/it] 69%|██████▉   | 7160/10395 [20:27:00<8:15:49,  9.20s/it]                                                         {'loss': 0.9034, 'learning_rate': 4.663953656006975e-06, 'epoch': 0.69}
 69%|██████▉   | 7160/10395 [20:27:00<8:15:49,  9.20s/it] 69%|██████▉   | 7161/10395 [20:27:08<7:54:51,  8.81s/it]                                                         {'loss': 0.8196, 'learning_rate': 4.6613188343271776e-06, 'epoch': 0.69}
 69%|██████▉   | 7161/10395 [20:27:08<7:54:51,  8.81s/it] 69%|██████▉   | 7162/10395 [20:27:16<7:30:07,  8.35s/it]                                                         {'loss': 0.9575, 'learning_rate': 4.65868453091514e-06, 'epoch': 0.69}
 69%|██████▉   | 7162/10395 [20:27:16<7:30:07,  8.35s/it] 69%|██████▉   | 7163/10395 [20:27:23<7:15:33,  8.09s/it]                                                         {'loss': 0.8925, 'learning_rate': 4.656050746026596e-06, 'epoch': 0.69}
 69%|██████▉   | 7163/10395 [20:27:23<7:15:33,  8.09s/it] 69%|██████▉   | 7164/10395 [20:27:31<7:06:17,  7.92s/it]                                                         {'loss': 0.9673, 'learning_rate': 4.653417479917223e-06, 'epoch': 0.69}
 69%|██████▉   | 7164/10395 [20:27:31<7:06:17,  7.92s/it] 69%|██████▉   | 7165/10395 [20:27:38<6:57:00,  7.75s/it]                                                         {'loss': 0.9682, 'learning_rate': 4.650784732842658e-06, 'epoch': 0.69}
 69%|██████▉   | 7165/10395 [20:27:38<6:57:00,  7.75s/it] 69%|██████▉   | 7166/10395 [20:27:46<6:57:40,  7.76s/it]                                                         {'loss': 0.8813, 'learning_rate': 4.648152505058481e-06, 'epoch': 0.69}
 69%|██████▉   | 7166/10395 [20:27:46<6:57:40,  7.76s/it] 69%|██████▉   | 7167/10395 [20:27:55<7:15:54,  8.10s/it]                                                         {'loss': 0.9014, 'learning_rate': 4.645520796820218e-06, 'epoch': 0.69}
 69%|██████▉   | 7167/10395 [20:27:55<7:15:54,  8.10s/it] 69%|██████▉   | 7168/10395 [20:28:02<7:08:53,  7.97s/it]                                                         {'loss': 0.8961, 'learning_rate': 4.6428896083833566e-06, 'epoch': 0.69}
 69%|██████▉   | 7168/10395 [20:28:02<7:08:53,  7.97s/it] 69%|██████▉   | 7169/10395 [20:28:11<7:15:10,  8.09s/it]                                                         {'loss': 0.9106, 'learning_rate': 4.64025894000332e-06, 'epoch': 0.69}
 69%|██████▉   | 7169/10395 [20:28:11<7:15:10,  8.09s/it] 69%|██████▉   | 7170/10395 [20:28:18<7:04:56,  7.91s/it]                                                         {'loss': 0.9076, 'learning_rate': 4.637628791935492e-06, 'epoch': 0.69}
 69%|██████▉   | 7170/10395 [20:28:18<7:04:56,  7.91s/it] 69%|██████▉   | 7171/10395 [20:28:26<6:59:08,  7.80s/it]                                                         {'loss': 0.8573, 'learning_rate': 4.634999164435205e-06, 'epoch': 0.69}
 69%|██████▉   | 7171/10395 [20:28:26<6:59:08,  7.80s/it] 69%|██████▉   | 7172/10395 [20:28:34<7:01:21,  7.84s/it]                                                         {'loss': 0.8869, 'learning_rate': 4.632370057757731e-06, 'epoch': 0.69}
 69%|██████▉   | 7172/10395 [20:28:34<7:01:21,  7.84s/it] 69%|██████▉   | 7173/10395 [20:28:41<6:51:04,  7.66s/it]                                                         {'loss': 0.8875, 'learning_rate': 4.629741472158304e-06, 'epoch': 0.69}
 69%|██████▉   | 7173/10395 [20:28:41<6:51:04,  7.66s/it] 69%|██████▉   | 7174/10395 [20:28:48<6:49:44,  7.63s/it]                                                         {'loss': 0.92, 'learning_rate': 4.6271134078920995e-06, 'epoch': 0.69}
 69%|██████▉   | 7174/10395 [20:28:48<6:49:44,  7.63s/it] 69%|██████▉   | 7175/10395 [20:28:56<6:46:01,  7.57s/it]                                                         {'loss': 0.8866, 'learning_rate': 4.62448586521424e-06, 'epoch': 0.69}
 69%|██████▉   | 7175/10395 [20:28:56<6:46:01,  7.57s/it] 69%|██████▉   | 7176/10395 [20:29:04<6:59:33,  7.82s/it]                                                         {'loss': 0.8588, 'learning_rate': 4.621858844379809e-06, 'epoch': 0.69}
 69%|██████▉   | 7176/10395 [20:29:04<6:59:33,  7.82s/it] 69%|██████▉   | 7177/10395 [20:29:21<9:28:54, 10.61s/it]                                                         {'loss': 0.3369, 'learning_rate': 4.619232345643823e-06, 'epoch': 0.69}
 69%|██████▉   | 7177/10395 [20:29:21<9:28:54, 10.61s/it] 69%|██████▉   | 7178/10395 [20:29:29<8:36:09,  9.63s/it]                                                         {'loss': 0.9075, 'learning_rate': 4.616606369261263e-06, 'epoch': 0.69}
 69%|██████▉   | 7178/10395 [20:29:29<8:36:09,  9.63s/it] 69%|██████▉   | 7179/10395 [20:29:36<7:59:57,  8.95s/it]                                                         {'loss': 0.9092, 'learning_rate': 4.613980915487056e-06, 'epoch': 0.69}
 69%|██████▉   | 7179/10395 [20:29:36<7:59:57,  8.95s/it] 69%|██████▉   | 7180/10395 [20:29:44<7:34:49,  8.49s/it]                                                         {'loss': 0.8358, 'learning_rate': 4.611355984576071e-06, 'epoch': 0.69}
 69%|██████▉   | 7180/10395 [20:29:44<7:34:49,  8.49s/it] 69%|██████▉   | 7181/10395 [20:29:53<7:48:22,  8.74s/it]                                                         {'loss': 0.7026, 'learning_rate': 4.60873157678313e-06, 'epoch': 0.69}
 69%|██████▉   | 7181/10395 [20:29:53<7:48:22,  8.74s/it] 69%|██████▉   | 7182/10395 [20:30:02<7:47:23,  8.73s/it]                                                         {'loss': 0.799, 'learning_rate': 4.606107692363008e-06, 'epoch': 0.69}
 69%|██████▉   | 7182/10395 [20:30:02<7:47:23,  8.73s/it] 69%|██████▉   | 7183/10395 [20:30:09<7:30:25,  8.41s/it]                                                         {'loss': 0.8578, 'learning_rate': 4.603484331570422e-06, 'epoch': 0.69}
 69%|██████▉   | 7183/10395 [20:30:09<7:30:25,  8.41s/it] 69%|██████▉   | 7184/10395 [20:30:17<7:15:23,  8.14s/it]                                                         {'loss': 0.9069, 'learning_rate': 4.6008614946600425e-06, 'epoch': 0.69}
 69%|██████▉   | 7184/10395 [20:30:17<7:15:23,  8.14s/it] 69%|██████▉   | 7185/10395 [20:30:25<7:15:15,  8.14s/it]                                                         {'loss': 0.8216, 'learning_rate': 4.598239181886497e-06, 'epoch': 0.69}
 69%|██████▉   | 7185/10395 [20:30:25<7:15:15,  8.14s/it] 69%|██████▉   | 7186/10395 [20:30:33<7:11:40,  8.07s/it]                                                         {'loss': 0.883, 'learning_rate': 4.595617393504343e-06, 'epoch': 0.69}
 69%|██████▉   | 7186/10395 [20:30:33<7:11:40,  8.07s/it] 69%|██████▉   | 7187/10395 [20:30:41<7:09:05,  8.03s/it]                                                         {'loss': 0.8006, 'learning_rate': 4.592996129768108e-06, 'epoch': 0.69}
 69%|██████▉   | 7187/10395 [20:30:41<7:09:05,  8.03s/it] 69%|██████▉   | 7188/10395 [20:30:49<7:12:39,  8.09s/it]                                                         {'loss': 0.8863, 'learning_rate': 4.590375390932254e-06, 'epoch': 0.69}
 69%|██████▉   | 7188/10395 [20:30:49<7:12:39,  8.09s/it] 69%|██████▉   | 7189/10395 [20:30:56<7:00:40,  7.87s/it]                                                         {'loss': 0.8744, 'learning_rate': 4.587755177251192e-06, 'epoch': 0.69}
 69%|██████▉   | 7189/10395 [20:30:56<7:00:40,  7.87s/it] 69%|██████▉   | 7190/10395 [20:31:14<9:32:32, 10.72s/it]                                                         {'loss': 0.3698, 'learning_rate': 4.585135488979296e-06, 'epoch': 0.69}
 69%|██████▉   | 7190/10395 [20:31:14<9:32:32, 10.72s/it] 69%|██████▉   | 7191/10395 [20:31:21<8:36:07,  9.67s/it]                                                         {'loss': 0.9358, 'learning_rate': 4.582516326370871e-06, 'epoch': 0.69}
 69%|██████▉   | 7191/10395 [20:31:21<8:36:07,  9.67s/it] 69%|██████▉   | 7192/10395 [20:31:28<7:57:39,  8.95s/it]                                                         {'loss': 0.8654, 'learning_rate': 4.579897689680184e-06, 'epoch': 0.69}
 69%|██████▉   | 7192/10395 [20:31:28<7:57:39,  8.95s/it] 69%|██████▉   | 7193/10395 [20:31:36<7:35:29,  8.54s/it]                                                         {'loss': 0.8718, 'learning_rate': 4.57727957916145e-06, 'epoch': 0.69}
 69%|██████▉   | 7193/10395 [20:31:36<7:35:29,  8.54s/it] 69%|██████▉   | 7194/10395 [20:31:44<7:26:16,  8.37s/it]                                                         {'loss': 0.8694, 'learning_rate': 4.574661995068822e-06, 'epoch': 0.69}
 69%|██████▉   | 7194/10395 [20:31:44<7:26:16,  8.37s/it] 69%|██████▉   | 7195/10395 [20:31:52<7:16:49,  8.19s/it]                                                         {'loss': 0.8959, 'learning_rate': 4.572044937656418e-06, 'epoch': 0.69}
 69%|██████▉   | 7195/10395 [20:31:52<7:16:49,  8.19s/it] 69%|██████▉   | 7196/10395 [20:31:59<7:09:20,  8.05s/it]                                                         {'loss': 0.9235, 'learning_rate': 4.569428407178291e-06, 'epoch': 0.69}
 69%|██████▉   | 7196/10395 [20:31:59<7:09:20,  8.05s/it] 69%|██████▉   | 7197/10395 [20:32:08<7:13:51,  8.14s/it]                                                         {'loss': 0.8416, 'learning_rate': 4.566812403888446e-06, 'epoch': 0.69}
 69%|██████▉   | 7197/10395 [20:32:08<7:13:51,  8.14s/it] 69%|██████▉   | 7198/10395 [20:32:24<9:24:24, 10.59s/it]                                                         {'loss': 0.3644, 'learning_rate': 4.564196928040846e-06, 'epoch': 0.69}
 69%|██████▉   | 7198/10395 [20:32:24<9:24:24, 10.59s/it] 69%|██████▉   | 7199/10395 [20:32:31<8:30:07,  9.58s/it]                                                         {'loss': 1.0297, 'learning_rate': 4.561581979889388e-06, 'epoch': 0.69}
 69%|██████▉   | 7199/10395 [20:32:31<8:30:07,  9.58s/it] 69%|██████▉   | 7200/10395 [20:32:39<7:58:33,  8.99s/it]                                                         {'loss': 0.862, 'learning_rate': 4.558967559687929e-06, 'epoch': 0.69}
 69%|██████▉   | 7200/10395 [20:32:39<7:58:33,  8.99s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 69%|██████▉   | 7201/10395 [20:34:19<32:23:27, 36.51s/it]                                                          {'loss': 0.8066, 'learning_rate': 4.556353667690275e-06, 'epoch': 0.69}
 69%|██████▉   | 7201/10395 [20:34:19<32:23:27, 36.51s/it] 69%|██████▉   | 7202/10395 [20:34:28<24:56:09, 28.11s/it]                                                          {'loss': 0.7904, 'learning_rate': 4.5537403041501745e-06, 'epoch': 0.69}
 69%|██████▉   | 7202/10395 [20:34:28<24:56:09, 28.11s/it] 69%|██████▉   | 7203/10395 [20:34:35<19:26:23, 21.92s/it]                                                          {'loss': 0.9323, 'learning_rate': 4.551127469321324e-06, 'epoch': 0.69}
 69%|██████▉   | 7203/10395 [20:34:35<19:26:23, 21.92s/it] 69%|██████▉   | 7204/10395 [20:34:44<15:44:54, 17.77s/it]                                                          {'loss': 0.7979, 'learning_rate': 4.548515163457376e-06, 'epoch': 0.69}
 69%|██████▉   | 7204/10395 [20:34:44<15:44:54, 17.77s/it] 69%|██████▉   | 7205/10395 [20:34:51<12:59:04, 14.65s/it]                                                          {'loss': 0.9225, 'learning_rate': 4.545903386811924e-06, 'epoch': 0.69}
 69%|██████▉   | 7205/10395 [20:34:51<12:59:04, 14.65s/it] 69%|██████▉   | 7206/10395 [20:34:59<11:09:42, 12.60s/it]                                                          {'loss': 0.8729, 'learning_rate': 4.543292139638519e-06, 'epoch': 0.69}
 69%|██████▉   | 7206/10395 [20:34:59<11:09:42, 12.60s/it] 69%|██████▉   | 7207/10395 [20:35:06<9:41:41, 10.95s/it]                                                          {'loss': 0.9125, 'learning_rate': 4.540681422190648e-06, 'epoch': 0.69}
 69%|██████▉   | 7207/10395 [20:35:06<9:41:41, 10.95s/it] 69%|██████▉   | 7208/10395 [20:35:15<9:06:08, 10.28s/it]                                                         {'loss': 0.7902, 'learning_rate': 4.538071234721758e-06, 'epoch': 0.69}
 69%|██████▉   | 7208/10395 [20:35:15<9:06:08, 10.28s/it] 69%|██████▉   | 7209/10395 [20:35:22<8:25:50,  9.53s/it]                                                         {'loss': 0.9171, 'learning_rate': 4.535461577485245e-06, 'epoch': 0.69}
 69%|██████▉   | 7209/10395 [20:35:22<8:25:50,  9.53s/it] 69%|██████▉   | 7210/10395 [20:35:31<8:06:29,  9.16s/it]                                                         {'loss': 0.9014, 'learning_rate': 4.532852450734444e-06, 'epoch': 0.69}
 69%|██████▉   | 7210/10395 [20:35:31<8:06:29,  9.16s/it] 69%|██████▉   | 7211/10395 [20:35:38<7:44:00,  8.74s/it]                                                         {'loss': 0.8951, 'learning_rate': 4.530243854722639e-06, 'epoch': 0.69}
 69%|██████▉   | 7211/10395 [20:35:38<7:44:00,  8.74s/it] 69%|██████▉   | 7212/10395 [20:35:55<9:55:40, 11.23s/it]                                                         {'loss': 0.3314, 'learning_rate': 4.527635789703076e-06, 'epoch': 0.69}
 69%|██████▉   | 7212/10395 [20:35:55<9:55:40, 11.23s/it] 69%|██████▉   | 7213/10395 [20:36:03<8:57:14, 10.13s/it]                                                         {'loss': 0.816, 'learning_rate': 4.525028255928933e-06, 'epoch': 0.69}
 69%|██████▉   | 7213/10395 [20:36:03<8:57:14, 10.13s/it] 69%|██████▉   | 7214/10395 [20:36:10<8:10:17,  9.25s/it]                                                         {'loss': 0.8502, 'learning_rate': 4.5224212536533496e-06, 'epoch': 0.69}
 69%|██████▉   | 7214/10395 [20:36:10<8:10:17,  9.25s/it] 69%|██████▉   | 7215/10395 [20:36:18<7:44:22,  8.76s/it]                                                         {'loss': 0.9216, 'learning_rate': 4.5198147831294015e-06, 'epoch': 0.69}
 69%|██████▉   | 7215/10395 [20:36:18<7:44:22,  8.76s/it] 69%|██████▉   | 7216/10395 [20:36:25<7:17:49,  8.26s/it]                                                         {'loss': 1.0002, 'learning_rate': 4.517208844610124e-06, 'epoch': 0.69}
 69%|██████▉   | 7216/10395 [20:36:25<7:17:49,  8.26s/it] 69%|██████▉   | 7217/10395 [20:36:32<7:04:43,  8.02s/it]                                                         {'loss': 0.9236, 'learning_rate': 4.5146034383485015e-06, 'epoch': 0.69}
 69%|██████▉   | 7217/10395 [20:36:32<7:04:43,  8.02s/it] 69%|██████▉   | 7218/10395 [20:36:41<7:12:28,  8.17s/it]                                                         {'loss': 0.9406, 'learning_rate': 4.511998564597448e-06, 'epoch': 0.69}
 69%|██████▉   | 7218/10395 [20:36:41<7:12:28,  8.17s/it] 69%|██████▉   | 7219/10395 [20:36:48<6:59:19,  7.92s/it]                                                         {'loss': 0.8612, 'learning_rate': 4.509394223609846e-06, 'epoch': 0.69}
 69%|██████▉   | 7219/10395 [20:36:48<6:59:19,  7.92s/it] 69%|██████▉   | 7220/10395 [20:36:57<7:15:12,  8.22s/it]                                                         {'loss': 0.8991, 'learning_rate': 4.506790415638523e-06, 'epoch': 0.69}
 69%|██████▉   | 7220/10395 [20:36:57<7:15:12,  8.22s/it] 69%|██████▉   | 7221/10395 [20:37:05<7:06:26,  8.06s/it]                                                         {'loss': 0.894, 'learning_rate': 4.504187140936244e-06, 'epoch': 0.69}
 69%|██████▉   | 7221/10395 [20:37:05<7:06:26,  8.06s/it] 69%|██████▉   | 7222/10395 [20:37:12<6:55:28,  7.86s/it]                                                         {'loss': 0.8259, 'learning_rate': 4.501584399755736e-06, 'epoch': 0.69}
 69%|██████▉   | 7222/10395 [20:37:12<6:55:28,  7.86s/it] 69%|██████▉   | 7223/10395 [20:37:22<7:26:24,  8.44s/it]                                                         {'loss': 0.879, 'learning_rate': 4.4989821923496605e-06, 'epoch': 0.69}
 69%|██████▉   | 7223/10395 [20:37:22<7:26:24,  8.44s/it] 69%|██████▉   | 7224/10395 [20:37:30<7:19:33,  8.32s/it]                                                         {'loss': 0.8803, 'learning_rate': 4.496380518970642e-06, 'epoch': 0.69}
 69%|██████▉   | 7224/10395 [20:37:30<7:19:33,  8.32s/it] 70%|██████▉   | 7225/10395 [20:37:38<7:21:18,  8.35s/it]                                                         {'loss': 0.9088, 'learning_rate': 4.493779379871241e-06, 'epoch': 0.7}
 70%|██████▉   | 7225/10395 [20:37:38<7:21:18,  8.35s/it] 70%|██████▉   | 7226/10395 [20:37:47<7:23:02,  8.39s/it]                                                         {'loss': 0.8427, 'learning_rate': 4.491178775303968e-06, 'epoch': 0.7}
 70%|██████▉   | 7226/10395 [20:37:47<7:23:02,  8.39s/it] 70%|██████▉   | 7227/10395 [20:37:55<7:21:49,  8.37s/it]                                                         {'loss': 0.8371, 'learning_rate': 4.488578705521287e-06, 'epoch': 0.7}
 70%|██████▉   | 7227/10395 [20:37:55<7:21:49,  8.37s/it] 70%|██████▉   | 7228/10395 [20:38:03<7:06:45,  8.09s/it]                                                         {'loss': 0.8107, 'learning_rate': 4.485979170775611e-06, 'epoch': 0.7}
 70%|██████▉   | 7228/10395 [20:38:03<7:06:45,  8.09s/it] 70%|██████▉   | 7229/10395 [20:38:11<7:02:47,  8.01s/it]                                                         {'loss': 0.9062, 'learning_rate': 4.483380171319289e-06, 'epoch': 0.7}
 70%|██████▉   | 7229/10395 [20:38:11<7:02:47,  8.01s/it] 70%|██████▉   | 7230/10395 [20:38:19<7:06:53,  8.09s/it]                                                         {'loss': 0.8588, 'learning_rate': 4.4807817074046354e-06, 'epoch': 0.7}
 70%|██████▉   | 7230/10395 [20:38:19<7:06:53,  8.09s/it] 70%|██████▉   | 7231/10395 [20:38:26<6:55:48,  7.89s/it]                                                         {'loss': 0.9102, 'learning_rate': 4.478183779283895e-06, 'epoch': 0.7}
 70%|██████▉   | 7231/10395 [20:38:26<6:55:48,  7.89s/it] 70%|██████▉   | 7232/10395 [20:38:44<9:37:32, 10.96s/it]                                                         {'loss': 0.3525, 'learning_rate': 4.475586387209277e-06, 'epoch': 0.7}
 70%|██████▉   | 7232/10395 [20:38:44<9:37:32, 10.96s/it] 70%|██████▉   | 7233/10395 [20:38:52<8:48:15, 10.02s/it]                                                         {'loss': 0.8617, 'learning_rate': 4.4729895314329275e-06, 'epoch': 0.7}
 70%|██████▉   | 7233/10395 [20:38:52<8:48:15, 10.02s/it] 70%|██████▉   | 7234/10395 [20:38:59<8:02:13,  9.15s/it]                                                         {'loss': 0.8237, 'learning_rate': 4.4703932122069386e-06, 'epoch': 0.7}
 70%|██████▉   | 7234/10395 [20:38:59<8:02:13,  9.15s/it] 70%|██████▉   | 7235/10395 [20:39:07<7:44:36,  8.82s/it]                                                         {'loss': 0.8289, 'learning_rate': 4.46779742978336e-06, 'epoch': 0.7}
 70%|██████▉   | 7235/10395 [20:39:07<7:44:36,  8.82s/it] 70%|██████▉   | 7236/10395 [20:39:15<7:30:04,  8.55s/it]                                                         {'loss': 0.845, 'learning_rate': 4.465202184414188e-06, 'epoch': 0.7}
 70%|██████▉   | 7236/10395 [20:39:15<7:30:04,  8.55s/it] 70%|██████▉   | 7237/10395 [20:39:23<7:17:22,  8.31s/it]                                                         {'loss': 0.86, 'learning_rate': 4.462607476351357e-06, 'epoch': 0.7}
 70%|██████▉   | 7237/10395 [20:39:23<7:17:22,  8.31s/it] 70%|██████▉   | 7238/10395 [20:39:31<7:13:49,  8.25s/it]                                                         {'loss': 0.8143, 'learning_rate': 4.460013305846762e-06, 'epoch': 0.7}
 70%|██████▉   | 7238/10395 [20:39:31<7:13:49,  8.25s/it] 70%|██████▉   | 7239/10395 [20:39:39<7:03:59,  8.06s/it]                                                         {'loss': 0.8325, 'learning_rate': 4.457419673152237e-06, 'epoch': 0.7}
 70%|██████▉   | 7239/10395 [20:39:39<7:03:59,  8.06s/it] 70%|██████▉   | 7240/10395 [20:39:46<6:58:28,  7.96s/it]                                                         {'loss': 0.9137, 'learning_rate': 4.454826578519561e-06, 'epoch': 0.7}
 70%|██████▉   | 7240/10395 [20:39:46<6:58:28,  7.96s/it] 70%|██████▉   | 7241/10395 [20:39:54<6:59:10,  7.97s/it]                                                         {'loss': 0.867, 'learning_rate': 4.452234022200474e-06, 'epoch': 0.7}
 70%|██████▉   | 7241/10395 [20:39:54<6:59:10,  7.97s/it] 70%|██████▉   | 7242/10395 [20:40:02<6:55:32,  7.91s/it]                                                         {'loss': 0.796, 'learning_rate': 4.449642004446649e-06, 'epoch': 0.7}
 70%|██████▉   | 7242/10395 [20:40:02<6:55:32,  7.91s/it] 70%|██████▉   | 7243/10395 [20:40:10<6:50:12,  7.81s/it]                                                         {'loss': 0.9081, 'learning_rate': 4.447050525509718e-06, 'epoch': 0.7}
 70%|██████▉   | 7243/10395 [20:40:10<6:50:12,  7.81s/it] 70%|██████▉   | 7244/10395 [20:40:17<6:46:01,  7.73s/it]                                                         {'loss': 0.8589, 'learning_rate': 4.444459585641259e-06, 'epoch': 0.7}
 70%|██████▉   | 7244/10395 [20:40:17<6:46:01,  7.73s/it] 70%|██████▉   | 7245/10395 [20:40:32<8:39:54,  9.90s/it]                                                         {'loss': 0.3246, 'learning_rate': 4.441869185092787e-06, 'epoch': 0.7}
 70%|██████▉   | 7245/10395 [20:40:32<8:39:54,  9.90s/it] 70%|██████▉   | 7246/10395 [20:40:40<8:04:38,  9.23s/it]                                                         {'loss': 0.9444, 'learning_rate': 4.439279324115779e-06, 'epoch': 0.7}
 70%|██████▉   | 7246/10395 [20:40:40<8:04:38,  9.23s/it] 70%|██████▉   | 7247/10395 [20:40:49<7:59:32,  9.14s/it]                                                         {'loss': 0.857, 'learning_rate': 4.436690002961654e-06, 'epoch': 0.7}
 70%|██████▉   | 7247/10395 [20:40:49<7:59:32,  9.14s/it] 70%|██████▉   | 7248/10395 [20:41:06<10:02:43, 11.49s/it]                                                          {'loss': 0.4137, 'learning_rate': 4.434101221881768e-06, 'epoch': 0.7}
 70%|██████▉   | 7248/10395 [20:41:06<10:02:43, 11.49s/it] 70%|██████▉   | 7249/10395 [20:41:14<9:05:59, 10.41s/it]                                                          {'loss': 0.8526, 'learning_rate': 4.431512981127442e-06, 'epoch': 0.7}
 70%|██████▉   | 7249/10395 [20:41:14<9:05:59, 10.41s/it] 70%|██████▉   | 7250/10395 [20:41:22<8:27:46,  9.69s/it]                                                         {'loss': 0.8667, 'learning_rate': 4.428925280949941e-06, 'epoch': 0.7}
 70%|██████▉   | 7250/10395 [20:41:22<8:27:46,  9.69s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 70%|██████▉   | 7251/10395 [20:43:00<31:41:44, 36.29s/it]                                                          {'loss': 0.9202, 'learning_rate': 4.426338121600463e-06, 'epoch': 0.7}
 70%|██████▉   | 7251/10395 [20:43:00<31:41:44, 36.29s/it] 70%|██████▉   | 7252/10395 [20:43:08<24:10:49, 27.70s/it]                                                          {'loss': 0.9149, 'learning_rate': 4.423751503330173e-06, 'epoch': 0.7}
 70%|██████▉   | 7252/10395 [20:43:08<24:10:49, 27.70s/it] 70%|██████▉   | 7253/10395 [20:43:16<19:02:44, 21.82s/it]                                                          {'loss': 0.823, 'learning_rate': 4.421165426390167e-06, 'epoch': 0.7}
 70%|██████▉   | 7253/10395 [20:43:16<19:02:44, 21.82s/it] 70%|██████▉   | 7254/10395 [20:43:24<15:22:59, 17.63s/it]                                                          {'loss': 0.8949, 'learning_rate': 4.418579891031504e-06, 'epoch': 0.7}
 70%|██████▉   | 7254/10395 [20:43:24<15:22:59, 17.63s/it] 70%|██████▉   | 7255/10395 [20:43:32<12:53:56, 14.79s/it]                                                          {'loss': 0.8517, 'learning_rate': 4.4159948975051766e-06, 'epoch': 0.7}
 70%|██████▉   | 7255/10395 [20:43:32<12:53:56, 14.79s/it] 70%|██████▉   | 7256/10395 [20:43:41<11:19:46, 12.99s/it]                                                          {'loss': 0.7963, 'learning_rate': 4.413410446062128e-06, 'epoch': 0.7}
 70%|██████▉   | 7256/10395 [20:43:41<11:19:46, 12.99s/it] 70%|██████▉   | 7257/10395 [20:43:48<9:52:41, 11.33s/it]                                                          {'loss': 0.8925, 'learning_rate': 4.410826536953256e-06, 'epoch': 0.7}
 70%|██████▉   | 7257/10395 [20:43:48<9:52:41, 11.33s/it] 70%|██████▉   | 7258/10395 [20:43:56<8:55:57, 10.25s/it]                                                         {'loss': 0.8508, 'learning_rate': 4.408243170429402e-06, 'epoch': 0.7}
 70%|██████▉   | 7258/10395 [20:43:56<8:55:57, 10.25s/it] 70%|██████▉   | 7259/10395 [20:44:06<8:49:58, 10.14s/it]                                                         {'loss': 0.7477, 'learning_rate': 4.405660346741347e-06, 'epoch': 0.7}
 70%|██████▉   | 7259/10395 [20:44:06<8:49:58, 10.14s/it] 70%|██████▉   | 7260/10395 [20:44:13<8:04:29,  9.27s/it]                                                         {'loss': 0.8761, 'learning_rate': 4.403078066139835e-06, 'epoch': 0.7}
 70%|██████▉   | 7260/10395 [20:44:13<8:04:29,  9.27s/it] 70%|██████▉   | 7261/10395 [20:44:20<7:35:49,  8.73s/it]                                                         {'loss': 0.8739, 'learning_rate': 4.400496328875544e-06, 'epoch': 0.7}
 70%|██████▉   | 7261/10395 [20:44:20<7:35:49,  8.73s/it] 70%|██████▉   | 7262/10395 [20:44:28<7:18:00,  8.39s/it]                                                         {'loss': 0.8397, 'learning_rate': 4.3979151351991e-06, 'epoch': 0.7}
 70%|██████▉   | 7262/10395 [20:44:28<7:18:00,  8.39s/it] 70%|██████▉   | 7263/10395 [20:44:36<7:08:40,  8.21s/it]                                                         {'loss': 0.8714, 'learning_rate': 4.395334485361086e-06, 'epoch': 0.7}
 70%|██████▉   | 7263/10395 [20:44:36<7:08:40,  8.21s/it] 70%|██████▉   | 7264/10395 [20:44:44<7:09:39,  8.23s/it]                                                         {'loss': 0.8456, 'learning_rate': 4.392754379612019e-06, 'epoch': 0.7}
 70%|██████▉   | 7264/10395 [20:44:44<7:09:39,  8.23s/it] 70%|██████▉   | 7265/10395 [20:45:03<9:50:36, 11.32s/it]                                                         {'loss': 0.3732, 'learning_rate': 4.390174818202374e-06, 'epoch': 0.7}
 70%|██████▉   | 7265/10395 [20:45:03<9:50:36, 11.32s/it] 70%|██████▉   | 7266/10395 [20:45:11<8:57:27, 10.31s/it]                                                         {'loss': 0.9406, 'learning_rate': 4.387595801382574e-06, 'epoch': 0.7}
 70%|██████▉   | 7266/10395 [20:45:11<8:57:27, 10.31s/it] 70%|██████▉   | 7267/10395 [20:45:18<8:18:21,  9.56s/it]                                                         {'loss': 0.8014, 'learning_rate': 4.385017329402975e-06, 'epoch': 0.7}
 70%|██████▉   | 7267/10395 [20:45:18<8:18:21,  9.56s/it] 70%|██████▉   | 7268/10395 [20:45:26<7:43:38,  8.90s/it]                                                         {'loss': 0.8207, 'learning_rate': 4.382439402513899e-06, 'epoch': 0.7}
 70%|██████▉   | 7268/10395 [20:45:26<7:43:38,  8.90s/it] 70%|██████▉   | 7269/10395 [20:45:34<7:25:16,  8.55s/it]                                                         {'loss': 0.9018, 'learning_rate': 4.379862020965601e-06, 'epoch': 0.7}
 70%|██████▉   | 7269/10395 [20:45:34<7:25:16,  8.55s/it] 70%|██████▉   | 7270/10395 [20:45:42<7:21:25,  8.48s/it]                                                         {'loss': 0.8092, 'learning_rate': 4.3772851850082835e-06, 'epoch': 0.7}
 70%|██████▉   | 7270/10395 [20:45:42<7:21:25,  8.48s/it] 70%|██████▉   | 7271/10395 [20:45:51<7:31:30,  8.67s/it]                                                         {'loss': 0.8409, 'learning_rate': 4.374708894892108e-06, 'epoch': 0.7}
 70%|██████▉   | 7271/10395 [20:45:51<7:31:30,  8.67s/it] 70%|██████▉   | 7272/10395 [20:45:59<7:14:02,  8.34s/it]                                                         {'loss': 0.8648, 'learning_rate': 4.372133150867168e-06, 'epoch': 0.7}
 70%|██████▉   | 7272/10395 [20:45:59<7:14:02,  8.34s/it] 70%|██████▉   | 7273/10395 [20:46:06<6:56:27,  8.00s/it]                                                         {'loss': 0.8625, 'learning_rate': 4.369557953183516e-06, 'epoch': 0.7}
 70%|██████▉   | 7273/10395 [20:46:06<6:56:27,  8.00s/it] 70%|██████▉   | 7274/10395 [20:46:14<6:58:30,  8.05s/it]                                                         {'loss': 0.8629, 'learning_rate': 4.366983302091149e-06, 'epoch': 0.7}
 70%|██████▉   | 7274/10395 [20:46:14<6:58:30,  8.05s/it] 70%|██████▉   | 7275/10395 [20:46:21<6:47:58,  7.85s/it]                                                         {'loss': 0.8615, 'learning_rate': 4.36440919784e-06, 'epoch': 0.7}
 70%|██████▉   | 7275/10395 [20:46:21<6:47:58,  7.85s/it] 70%|██████▉   | 7276/10395 [20:46:30<6:58:03,  8.04s/it]                                                         {'loss': 0.9232, 'learning_rate': 4.361835640679969e-06, 'epoch': 0.7}
 70%|██████▉   | 7276/10395 [20:46:30<6:58:03,  8.04s/it] 70%|███████   | 7277/10395 [20:46:38<7:02:36,  8.13s/it]                                                         {'loss': 0.8897, 'learning_rate': 4.359262630860883e-06, 'epoch': 0.7}
 70%|███████   | 7277/10395 [20:46:38<7:02:36,  8.13s/it] 70%|███████   | 7278/10395 [20:46:46<7:02:09,  8.13s/it]                                                         {'loss': 0.9111, 'learning_rate': 4.356690168632524e-06, 'epoch': 0.7}
 70%|███████   | 7278/10395 [20:46:46<7:02:09,  8.13s/it] 70%|███████   | 7279/10395 [20:46:54<6:50:06,  7.90s/it]                                                         {'loss': 0.8782, 'learning_rate': 4.354118254244627e-06, 'epoch': 0.7}
 70%|███████   | 7279/10395 [20:46:54<6:50:06,  7.90s/it] 70%|███████   | 7280/10395 [20:47:11<9:15:40, 10.70s/it]                                                         {'loss': 0.3769, 'learning_rate': 4.35154688794686e-06, 'epoch': 0.7}
 70%|███████   | 7280/10395 [20:47:11<9:15:40, 10.70s/it] 70%|███████   | 7281/10395 [20:47:19<8:36:34,  9.95s/it]                                                         {'loss': 0.8226, 'learning_rate': 4.348976069988851e-06, 'epoch': 0.7}
 70%|███████   | 7281/10395 [20:47:19<8:36:34,  9.95s/it] 70%|███████   | 7282/10395 [20:47:27<8:01:08,  9.27s/it]                                                         {'loss': 0.9174, 'learning_rate': 4.346405800620174e-06, 'epoch': 0.7}
 70%|███████   | 7282/10395 [20:47:27<8:01:08,  9.27s/it] 70%|███████   | 7283/10395 [20:47:34<7:35:49,  8.79s/it]                                                         {'loss': 0.9368, 'learning_rate': 4.343836080090339e-06, 'epoch': 0.7}
 70%|███████   | 7283/10395 [20:47:34<7:35:49,  8.79s/it] 70%|███████   | 7284/10395 [20:47:42<7:20:51,  8.50s/it]                                                         {'loss': 0.8552, 'learning_rate': 4.341266908648806e-06, 'epoch': 0.7}
 70%|███████   | 7284/10395 [20:47:42<7:20:51,  8.50s/it] 70%|███████   | 7285/10395 [20:47:51<7:32:49,  8.74s/it]                                                         {'loss': 0.8127, 'learning_rate': 4.338698286544992e-06, 'epoch': 0.7}
 70%|███████   | 7285/10395 [20:47:52<7:32:49,  8.74s/it] 70%|███████   | 7286/10395 [20:47:59<7:17:06,  8.44s/it]                                                         {'loss': 0.8884, 'learning_rate': 4.336130214028248e-06, 'epoch': 0.7}
 70%|███████   | 7286/10395 [20:47:59<7:17:06,  8.44s/it] 70%|███████   | 7287/10395 [20:48:07<7:04:21,  8.19s/it]                                                         {'loss': 0.7589, 'learning_rate': 4.333562691347881e-06, 'epoch': 0.7}
 70%|███████   | 7287/10395 [20:48:07<7:04:21,  8.19s/it] 70%|███████   | 7288/10395 [20:48:14<6:51:58,  7.96s/it]                                                         {'loss': 0.8389, 'learning_rate': 4.330995718753136e-06, 'epoch': 0.7}
 70%|███████   | 7288/10395 [20:48:14<6:51:58,  7.96s/it] 70%|███████   | 7289/10395 [20:48:31<9:14:54, 10.72s/it]                                                         {'loss': 0.3731, 'learning_rate': 4.3284292964932115e-06, 'epoch': 0.7}
 70%|███████   | 7289/10395 [20:48:31<9:14:54, 10.72s/it] 70%|███████   | 7290/10395 [20:48:39<8:23:12,  9.72s/it]                                                         {'loss': 0.9508, 'learning_rate': 4.3258634248172596e-06, 'epoch': 0.7}
 70%|███████   | 7290/10395 [20:48:39<8:23:12,  9.72s/it] 70%|███████   | 7291/10395 [20:48:47<7:54:47,  9.18s/it]                                                         {'loss': 0.8833, 'learning_rate': 4.3232981039743515e-06, 'epoch': 0.7}
 70%|███████   | 7291/10395 [20:48:47<7:54:47,  9.18s/it] 70%|███████   | 7292/10395 [20:48:55<7:35:52,  8.81s/it]                                                         {'loss': 0.8995, 'learning_rate': 4.320733334213533e-06, 'epoch': 0.7}
 70%|███████   | 7292/10395 [20:48:55<7:35:52,  8.81s/it] 70%|███████   | 7293/10395 [20:49:03<7:20:12,  8.51s/it]                                                         {'loss': 0.9033, 'learning_rate': 4.318169115783789e-06, 'epoch': 0.7}
 70%|███████   | 7293/10395 [20:49:03<7:20:12,  8.51s/it] 70%|███████   | 7294/10395 [20:49:10<7:09:29,  8.31s/it]                                                         {'loss': 0.9086, 'learning_rate': 4.315605448934043e-06, 'epoch': 0.7}
 70%|███████   | 7294/10395 [20:49:10<7:09:29,  8.31s/it] 70%|███████   | 7295/10395 [20:49:18<7:02:31,  8.18s/it]                                                         {'loss': 0.8959, 'learning_rate': 4.3130423339131745e-06, 'epoch': 0.7}
 70%|███████   | 7295/10395 [20:49:18<7:02:31,  8.18s/it] 70%|███████   | 7296/10395 [20:49:27<7:13:04,  8.38s/it]                                                         {'loss': 0.8642, 'learning_rate': 4.31047977097e-06, 'epoch': 0.7}
 70%|███████   | 7296/10395 [20:49:27<7:13:04,  8.38s/it] 70%|███████   | 7297/10395 [20:49:35<7:11:33,  8.36s/it]                                                         {'loss': 0.8316, 'learning_rate': 4.307917760353291e-06, 'epoch': 0.7}
 70%|███████   | 7297/10395 [20:49:35<7:11:33,  8.36s/it] 70%|███████   | 7298/10395 [20:49:43<6:55:40,  8.05s/it]                                                         {'loss': 0.8997, 'learning_rate': 4.305356302311769e-06, 'epoch': 0.7}
 70%|███████   | 7298/10395 [20:49:43<6:55:40,  8.05s/it] 70%|███████   | 7299/10395 [20:49:51<6:53:19,  8.01s/it]                                                         {'loss': 0.8708, 'learning_rate': 4.30279539709408e-06, 'epoch': 0.7}
 70%|███████   | 7299/10395 [20:49:51<6:53:19,  8.01s/it] 70%|███████   | 7300/10395 [20:49:58<6:48:17,  7.92s/it]                                                         {'loss': 0.8869, 'learning_rate': 4.300235044948838e-06, 'epoch': 0.7}
 70%|███████   | 7300/10395 [20:49:58<6:48:17,  7.92s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 70%|███████   | 7301/10395 [20:51:46<32:30:48, 37.83s/it]                                                          {'loss': 0.4134, 'learning_rate': 4.297675246124603e-06, 'epoch': 0.7}
 70%|███████   | 7301/10395 [20:51:46<32:30:48, 37.83s/it] 70%|███████   | 7302/10395 [20:51:53<24:35:33, 28.62s/it]                                                          {'loss': 0.8971, 'learning_rate': 4.295116000869864e-06, 'epoch': 0.7}
 70%|███████   | 7302/10395 [20:51:53<24:35:33, 28.62s/it] 70%|███████   | 7303/10395 [20:52:02<19:22:29, 22.56s/it]                                                          {'loss': 0.8608, 'learning_rate': 4.292557309433077e-06, 'epoch': 0.7}
 70%|███████   | 7303/10395 [20:52:02<19:22:29, 22.56s/it] 70%|███████   | 7304/10395 [20:52:10<15:42:50, 18.30s/it]                                                          {'loss': 0.8562, 'learning_rate': 4.289999172062626e-06, 'epoch': 0.7}
 70%|███████   | 7304/10395 [20:52:10<15:42:50, 18.30s/it] 70%|███████   | 7305/10395 [20:52:18<13:01:37, 15.18s/it]                                                          {'loss': 0.8485, 'learning_rate': 4.2874415890068565e-06, 'epoch': 0.7}
 70%|███████   | 7305/10395 [20:52:18<13:01:37, 15.18s/it] 70%|███████   | 7306/10395 [20:52:25<10:53:48, 12.70s/it]                                                          {'loss': 0.8872, 'learning_rate': 4.284884560514048e-06, 'epoch': 0.7}
 70%|███████   | 7306/10395 [20:52:25<10:53:48, 12.70s/it] 70%|███████   | 7307/10395 [20:52:33<9:38:20, 11.24s/it]                                                          {'loss': 0.8459, 'learning_rate': 4.282328086832433e-06, 'epoch': 0.7}
 70%|███████   | 7307/10395 [20:52:33<9:38:20, 11.24s/it] 70%|███████   | 7308/10395 [20:52:41<9:00:54, 10.51s/it]                                                         {'loss': 0.882, 'learning_rate': 4.279772168210185e-06, 'epoch': 0.7}
 70%|███████   | 7308/10395 [20:52:41<9:00:54, 10.51s/it] 70%|███████   | 7309/10395 [20:52:50<8:24:49,  9.82s/it]                                                         {'loss': 0.8481, 'learning_rate': 4.2772168048954365e-06, 'epoch': 0.7}
 70%|███████   | 7309/10395 [20:52:50<8:24:49,  9.82s/it] 70%|███████   | 7310/10395 [20:52:57<7:49:28,  9.13s/it]                                                         {'loss': 0.9085, 'learning_rate': 4.274661997136247e-06, 'epoch': 0.7}
 70%|███████   | 7310/10395 [20:52:57<7:49:28,  9.13s/it] 70%|███████   | 7311/10395 [20:53:05<7:33:42,  8.83s/it]                                                         {'loss': 0.8077, 'learning_rate': 4.272107745180639e-06, 'epoch': 0.7}
 70%|███████   | 7311/10395 [20:53:05<7:33:42,  8.83s/it] 70%|███████   | 7312/10395 [20:53:13<7:24:57,  8.66s/it]                                                         {'loss': 0.8863, 'learning_rate': 4.2695540492765675e-06, 'epoch': 0.7}
 70%|███████   | 7312/10395 [20:53:13<7:24:57,  8.66s/it] 70%|███████   | 7313/10395 [20:53:21<7:10:47,  8.39s/it]                                                         {'loss': 0.9453, 'learning_rate': 4.267000909671946e-06, 'epoch': 0.7}
 70%|███████   | 7313/10395 [20:53:21<7:10:47,  8.39s/it] 70%|███████   | 7314/10395 [20:53:29<7:02:03,  8.22s/it]                                                         {'loss': 0.828, 'learning_rate': 4.264448326614625e-06, 'epoch': 0.7}
 70%|███████   | 7314/10395 [20:53:29<7:02:03,  8.22s/it] 70%|███████   | 7315/10395 [20:53:45<9:01:51, 10.56s/it]                                                         {'loss': 0.3616, 'learning_rate': 4.261896300352399e-06, 'epoch': 0.7}
 70%|███████   | 7315/10395 [20:53:45<9:01:51, 10.56s/it] 70%|███████   | 7316/10395 [20:53:53<8:14:29,  9.64s/it]                                                         {'loss': 0.8953, 'learning_rate': 4.259344831133019e-06, 'epoch': 0.7}
 70%|███████   | 7316/10395 [20:53:53<8:14:29,  9.64s/it] 70%|███████   | 7317/10395 [20:54:00<7:48:23,  9.13s/it]                                                         {'loss': 0.8481, 'learning_rate': 4.256793919204178e-06, 'epoch': 0.7}
 70%|███████   | 7317/10395 [20:54:00<7:48:23,  9.13s/it] 70%|███████   | 7318/10395 [20:54:08<7:19:15,  8.57s/it]                                                         {'loss': 0.8465, 'learning_rate': 4.254243564813507e-06, 'epoch': 0.7}
 70%|███████   | 7318/10395 [20:54:08<7:19:15,  8.57s/it] 70%|███████   | 7319/10395 [20:54:15<7:00:28,  8.20s/it]                                                         {'loss': 0.9404, 'learning_rate': 4.251693768208591e-06, 'epoch': 0.7}
 70%|███████   | 7319/10395 [20:54:15<7:00:28,  8.20s/it] 70%|███████   | 7320/10395 [20:54:23<6:49:42,  7.99s/it]                                                         {'loss': 0.8535, 'learning_rate': 4.2491445296369685e-06, 'epoch': 0.7}
 70%|███████   | 7320/10395 [20:54:23<6:49:42,  7.99s/it] 70%|███████   | 7321/10395 [20:54:30<6:41:42,  7.84s/it]                                                         {'loss': 0.8381, 'learning_rate': 4.246595849346097e-06, 'epoch': 0.7}
 70%|███████   | 7321/10395 [20:54:30<6:41:42,  7.84s/it] 70%|███████   | 7322/10395 [20:54:37<6:34:35,  7.70s/it]                                                         {'loss': 0.881, 'learning_rate': 4.244047727583406e-06, 'epoch': 0.7}
 70%|███████   | 7322/10395 [20:54:37<6:34:35,  7.70s/it] 70%|███████   | 7323/10395 [20:54:45<6:37:49,  7.77s/it]                                                         {'loss': 0.838, 'learning_rate': 4.241500164596264e-06, 'epoch': 0.7}
 70%|███████   | 7323/10395 [20:54:45<6:37:49,  7.77s/it] 70%|███████   | 7324/10395 [20:54:53<6:32:22,  7.67s/it]                                                         {'loss': 0.8978, 'learning_rate': 4.238953160631977e-06, 'epoch': 0.7}
 70%|███████   | 7324/10395 [20:54:53<6:32:22,  7.67s/it] 70%|███████   | 7325/10395 [20:55:01<6:36:58,  7.76s/it]                                                         {'loss': 0.8838, 'learning_rate': 4.236406715937808e-06, 'epoch': 0.7}
 70%|███████   | 7325/10395 [20:55:01<6:36:58,  7.76s/it] 70%|███████   | 7326/10395 [20:55:08<6:33:40,  7.70s/it]                                                         {'loss': 0.8946, 'learning_rate': 4.2338608307609564e-06, 'epoch': 0.7}
 70%|███████   | 7326/10395 [20:55:08<6:33:40,  7.70s/it] 70%|███████   | 7327/10395 [20:55:17<6:46:02,  7.94s/it]                                                         {'loss': 0.841, 'learning_rate': 4.231315505348576e-06, 'epoch': 0.7}
 70%|███████   | 7327/10395 [20:55:17<6:46:02,  7.94s/it] 70%|███████   | 7328/10395 [20:55:24<6:37:08,  7.77s/it]                                                         {'loss': 0.851, 'learning_rate': 4.2287707399477595e-06, 'epoch': 0.7}
 70%|███████   | 7328/10395 [20:55:24<6:37:08,  7.77s/it] 71%|███████   | 7329/10395 [20:55:33<6:49:07,  8.01s/it]                                                         {'loss': 0.8719, 'learning_rate': 4.226226534805542e-06, 'epoch': 0.71}
 71%|███████   | 7329/10395 [20:55:33<6:49:07,  8.01s/it] 71%|███████   | 7330/10395 [20:55:42<7:00:51,  8.24s/it]                                                         {'loss': 0.9425, 'learning_rate': 4.223682890168914e-06, 'epoch': 0.71}
 71%|███████   | 7330/10395 [20:55:42<7:00:51,  8.24s/it] 71%|███████   | 7331/10395 [20:55:49<6:48:27,  8.00s/it]                                                         {'loss': 0.9931, 'learning_rate': 4.22113980628481e-06, 'epoch': 0.71}
 71%|███████   | 7331/10395 [20:55:49<6:48:27,  8.00s/it] 71%|███████   | 7332/10395 [20:55:59<7:14:45,  8.52s/it]                                                         {'loss': 0.8566, 'learning_rate': 4.218597283400101e-06, 'epoch': 0.71}
 71%|███████   | 7332/10395 [20:55:59<7:14:45,  8.52s/it] 71%|███████   | 7333/10395 [20:56:06<7:00:32,  8.24s/it]                                                         {'loss': 0.8534, 'learning_rate': 4.216055321761617e-06, 'epoch': 0.71}
 71%|███████   | 7333/10395 [20:56:06<7:00:32,  8.24s/it] 71%|███████   | 7334/10395 [20:56:14<6:55:37,  8.15s/it]                                                         {'loss': 0.9204, 'learning_rate': 4.213513921616118e-06, 'epoch': 0.71}
 71%|███████   | 7334/10395 [20:56:14<6:55:37,  8.15s/it] 71%|███████   | 7335/10395 [20:56:22<6:44:07,  7.92s/it]                                                         {'loss': 0.8683, 'learning_rate': 4.210973083210325e-06, 'epoch': 0.71}
 71%|███████   | 7335/10395 [20:56:22<6:44:07,  7.92s/it] 71%|███████   | 7336/10395 [20:56:30<6:47:27,  7.99s/it]                                                         {'loss': 0.7843, 'learning_rate': 4.208432806790894e-06, 'epoch': 0.71}
 71%|███████   | 7336/10395 [20:56:30<6:47:27,  7.99s/it] 71%|███████   | 7337/10395 [20:56:38<6:51:30,  8.07s/it]                                                         {'loss': 0.9224, 'learning_rate': 4.205893092604426e-06, 'epoch': 0.71}
 71%|███████   | 7337/10395 [20:56:38<6:51:30,  8.07s/it] 71%|███████   | 7338/10395 [20:56:47<6:57:23,  8.19s/it]                                                         {'loss': 0.8571, 'learning_rate': 4.203353940897474e-06, 'epoch': 0.71}
 71%|███████   | 7338/10395 [20:56:47<6:57:23,  8.19s/it] 71%|███████   | 7339/10395 [20:56:54<6:45:57,  7.97s/it]                                                         {'loss': 0.817, 'learning_rate': 4.200815351916539e-06, 'epoch': 0.71}
 71%|███████   | 7339/10395 [20:56:54<6:45:57,  7.97s/it] 71%|███████   | 7340/10395 [20:57:02<6:39:38,  7.85s/it]                                                         {'loss': 0.8554, 'learning_rate': 4.198277325908052e-06, 'epoch': 0.71}
 71%|███████   | 7340/10395 [20:57:02<6:39:38,  7.85s/it] 71%|███████   | 7341/10395 [20:57:09<6:32:46,  7.72s/it]                                                         {'loss': 0.8714, 'learning_rate': 4.195739863118407e-06, 'epoch': 0.71}
 71%|███████   | 7341/10395 [20:57:09<6:32:46,  7.72s/it] 71%|███████   | 7342/10395 [20:57:17<6:32:46,  7.72s/it]                                                         {'loss': 0.8848, 'learning_rate': 4.193202963793934e-06, 'epoch': 0.71}
 71%|███████   | 7342/10395 [20:57:17<6:32:46,  7.72s/it] 71%|███████   | 7343/10395 [20:57:24<6:32:01,  7.71s/it]                                                         {'loss': 0.8973, 'learning_rate': 4.1906666281809025e-06, 'epoch': 0.71}
 71%|███████   | 7343/10395 [20:57:24<6:32:01,  7.71s/it] 71%|███████   | 7344/10395 [20:57:32<6:26:10,  7.59s/it]                                                         {'loss': 0.926, 'learning_rate': 4.188130856525545e-06, 'epoch': 0.71}
 71%|███████   | 7344/10395 [20:57:32<6:26:10,  7.59s/it] 71%|███████   | 7345/10395 [20:57:39<6:19:54,  7.47s/it]                                                         {'loss': 0.867, 'learning_rate': 4.185595649074021e-06, 'epoch': 0.71}
 71%|███████   | 7345/10395 [20:57:39<6:19:54,  7.47s/it] 71%|███████   | 7346/10395 [20:57:46<6:16:14,  7.40s/it]                                                         {'loss': 0.9507, 'learning_rate': 4.183061006072445e-06, 'epoch': 0.71}
 71%|███████   | 7346/10395 [20:57:46<6:16:14,  7.40s/it] 71%|███████   | 7347/10395 [20:57:53<6:13:43,  7.36s/it]                                                         {'loss': 0.8861, 'learning_rate': 4.180526927766879e-06, 'epoch': 0.71}
 71%|███████   | 7347/10395 [20:57:53<6:13:43,  7.36s/it] 71%|███████   | 7348/10395 [20:58:01<6:22:31,  7.53s/it]                                                         {'loss': 0.8983, 'learning_rate': 4.1779934144033195e-06, 'epoch': 0.71}
 71%|███████   | 7348/10395 [20:58:01<6:22:31,  7.53s/it] 71%|███████   | 7349/10395 [20:58:09<6:17:43,  7.44s/it]                                                         {'loss': 0.9142, 'learning_rate': 4.175460466227721e-06, 'epoch': 0.71}
 71%|███████   | 7349/10395 [20:58:09<6:17:43,  7.44s/it] 71%|███████   | 7350/10395 [20:58:16<6:14:52,  7.39s/it]                                                         {'loss': 0.9414, 'learning_rate': 4.172928083485974e-06, 'epoch': 0.71}
 71%|███████   | 7350/10395 [20:58:16<6:14:52,  7.39s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 71%|███████   | 7351/10395 [20:59:56<29:49:19, 35.27s/it]                                                          {'loss': 0.8513, 'learning_rate': 4.170396266423912e-06, 'epoch': 0.71}
 71%|███████   | 7351/10395 [20:59:56<29:49:19, 35.27s/it] 71%|███████   | 7352/10395 [21:00:03<22:41:40, 26.85s/it]                                                          {'loss': 0.8935, 'learning_rate': 4.167865015287326e-06, 'epoch': 0.71}
 71%|███████   | 7352/10395 [21:00:03<22:41:40, 26.85s/it] 71%|███████   | 7353/10395 [21:00:11<17:47:47, 21.06s/it]                                                          {'loss': 0.8606, 'learning_rate': 4.165334330321937e-06, 'epoch': 0.71}
 71%|███████   | 7353/10395 [21:00:11<17:47:47, 21.06s/it] 71%|███████   | 7354/10395 [21:00:18<14:19:48, 16.96s/it]                                                          {'loss': 0.8713, 'learning_rate': 4.1628042117734236e-06, 'epoch': 0.71}
 71%|███████   | 7354/10395 [21:00:18<14:19:48, 16.96s/it] 71%|███████   | 7355/10395 [21:00:26<11:51:59, 14.05s/it]                                                          {'loss': 0.8534, 'learning_rate': 4.160274659887406e-06, 'epoch': 0.71}
 71%|███████   | 7355/10395 [21:00:26<11:51:59, 14.05s/it] 71%|███████   | 7356/10395 [21:00:34<10:34:12, 12.52s/it]                                                          {'loss': 0.8641, 'learning_rate': 4.157745674909443e-06, 'epoch': 0.71}
 71%|███████   | 7356/10395 [21:00:34<10:34:12, 12.52s/it] 71%|███████   | 7357/10395 [21:00:42<9:23:48, 11.14s/it]                                                          {'loss': 0.9243, 'learning_rate': 4.155217257085047e-06, 'epoch': 0.71}
 71%|███████   | 7357/10395 [21:00:42<9:23:48, 11.14s/it] 71%|███████   | 7358/10395 [21:00:51<8:44:11, 10.36s/it]                                                         {'loss': 0.9092, 'learning_rate': 4.152689406659669e-06, 'epoch': 0.71}
 71%|███████   | 7358/10395 [21:00:51<8:44:11, 10.36s/it] 71%|███████   | 7359/10395 [21:00:59<8:02:28,  9.54s/it]                                                         {'loss': 0.9191, 'learning_rate': 4.150162123878705e-06, 'epoch': 0.71}
 71%|███████   | 7359/10395 [21:00:59<8:02:28,  9.54s/it] 71%|███████   | 7360/10395 [21:01:07<7:40:51,  9.11s/it]                                                         {'loss': 0.9691, 'learning_rate': 4.147635408987504e-06, 'epoch': 0.71}
 71%|███████   | 7360/10395 [21:01:07<7:40:51,  9.11s/it] 71%|███████   | 7361/10395 [21:01:25<9:58:56, 11.84s/it]                                                         {'loss': 0.2956, 'learning_rate': 4.145109262231347e-06, 'epoch': 0.71}
 71%|███████   | 7361/10395 [21:01:25<9:58:56, 11.84s/it] 71%|███████   | 7362/10395 [21:01:33<9:04:00, 10.76s/it]                                                         {'loss': 0.8291, 'learning_rate': 4.142583683855471e-06, 'epoch': 0.71}
 71%|███████   | 7362/10395 [21:01:33<9:04:00, 10.76s/it] 71%|███████   | 7363/10395 [21:01:41<8:12:39,  9.75s/it]                                                         {'loss': 0.9273, 'learning_rate': 4.140058674105058e-06, 'epoch': 0.71}
 71%|███████   | 7363/10395 [21:01:41<8:12:39,  9.75s/it] 71%|███████   | 7364/10395 [21:01:49<7:47:21,  9.25s/it]                                                         {'loss': 0.9645, 'learning_rate': 4.137534233225226e-06, 'epoch': 0.71}
 71%|███████   | 7364/10395 [21:01:49<7:47:21,  9.25s/it] 71%|███████   | 7365/10395 [21:02:06<9:56:06, 11.80s/it]                                                         {'loss': 0.3767, 'learning_rate': 4.135010361461037e-06, 'epoch': 0.71}
 71%|███████   | 7365/10395 [21:02:06<9:56:06, 11.80s/it] 71%|███████   | 7366/10395 [21:02:16<9:21:33, 11.12s/it]                                                         {'loss': 0.8616, 'learning_rate': 4.132487059057514e-06, 'epoch': 0.71}
 71%|███████   | 7366/10395 [21:02:16<9:21:33, 11.12s/it] 71%|███████   | 7367/10395 [21:02:24<8:30:49, 10.12s/it]                                                         {'loss': 0.8896, 'learning_rate': 4.129964326259604e-06, 'epoch': 0.71}
 71%|███████   | 7367/10395 [21:02:24<8:30:49, 10.12s/it] 71%|███████   | 7368/10395 [21:02:31<7:47:13,  9.26s/it]                                                         {'loss': 0.8675, 'learning_rate': 4.1274421633122174e-06, 'epoch': 0.71}
 71%|███████   | 7368/10395 [21:02:31<7:47:13,  9.26s/it] 71%|███████   | 7369/10395 [21:02:39<7:27:24,  8.87s/it]                                                         {'loss': 0.878, 'learning_rate': 4.124920570460192e-06, 'epoch': 0.71}
 71%|███████   | 7369/10395 [21:02:39<7:27:24,  8.87s/it] 71%|███████   | 7370/10395 [21:02:46<7:01:35,  8.36s/it]                                                         {'loss': 0.9343, 'learning_rate': 4.122399547948323e-06, 'epoch': 0.71}
 71%|███████   | 7370/10395 [21:02:46<7:01:35,  8.36s/it] 71%|███████   | 7371/10395 [21:02:54<6:56:43,  8.27s/it]                                                         {'loss': 0.882, 'learning_rate': 4.119879096021352e-06, 'epoch': 0.71}
 71%|███████   | 7371/10395 [21:02:54<6:56:43,  8.27s/it] 71%|███████   | 7372/10395 [21:03:02<6:49:49,  8.13s/it]                                                         {'loss': 0.8337, 'learning_rate': 4.117359214923945e-06, 'epoch': 0.71}
 71%|███████   | 7372/10395 [21:03:02<6:49:49,  8.13s/it] 71%|███████   | 7373/10395 [21:03:09<6:36:04,  7.86s/it]                                                         {'loss': 0.86, 'learning_rate': 4.114839904900735e-06, 'epoch': 0.71}
 71%|███████   | 7373/10395 [21:03:09<6:36:04,  7.86s/it] 71%|███████   | 7374/10395 [21:03:16<6:27:46,  7.70s/it]                                                         {'loss': 0.8751, 'learning_rate': 4.1123211661962934e-06, 'epoch': 0.71}
 71%|███████   | 7374/10395 [21:03:16<6:27:46,  7.70s/it] 71%|███████   | 7375/10395 [21:03:24<6:19:32,  7.54s/it]                                                         {'loss': 0.85, 'learning_rate': 4.109802999055127e-06, 'epoch': 0.71}
 71%|███████   | 7375/10395 [21:03:24<6:19:32,  7.54s/it] 71%|███████   | 7376/10395 [21:03:31<6:19:52,  7.55s/it]                                                         {'loss': 0.9084, 'learning_rate': 4.107285403721703e-06, 'epoch': 0.71}
 71%|███████   | 7376/10395 [21:03:31<6:19:52,  7.55s/it] 71%|███████   | 7377/10395 [21:03:40<6:35:32,  7.86s/it]                                                         {'loss': 0.8946, 'learning_rate': 4.104768380440415e-06, 'epoch': 0.71}
 71%|███████   | 7377/10395 [21:03:40<6:35:32,  7.86s/it] 71%|███████   | 7378/10395 [21:03:55<8:28:44, 10.12s/it]                                                         {'loss': 0.3778, 'learning_rate': 4.102251929455614e-06, 'epoch': 0.71}
 71%|███████   | 7378/10395 [21:03:55<8:28:44, 10.12s/it] 71%|███████   | 7379/10395 [21:04:02<7:44:35,  9.24s/it]                                                         {'loss': 0.8904, 'learning_rate': 4.099736051011599e-06, 'epoch': 0.71}
 71%|███████   | 7379/10395 [21:04:02<7:44:35,  9.24s/it] 71%|███████   | 7380/10395 [21:04:10<7:18:02,  8.72s/it]                                                         {'loss': 0.85, 'learning_rate': 4.097220745352592e-06, 'epoch': 0.71}
 71%|███████   | 7380/10395 [21:04:10<7:18:02,  8.72s/it] 71%|███████   | 7381/10395 [21:04:18<7:03:04,  8.42s/it]                                                         {'loss': 0.8614, 'learning_rate': 4.094706012722782e-06, 'epoch': 0.71}
 71%|███████   | 7381/10395 [21:04:18<7:03:04,  8.42s/it] 71%|███████   | 7382/10395 [21:04:25<6:52:48,  8.22s/it]                                                         {'loss': 0.8656, 'learning_rate': 4.092191853366296e-06, 'epoch': 0.71}
 71%|███████   | 7382/10395 [21:04:25<6:52:48,  8.22s/it] 71%|███████   | 7383/10395 [21:04:43<9:17:54, 11.11s/it]                                                         {'loss': 0.3921, 'learning_rate': 4.089678267527196e-06, 'epoch': 0.71}
 71%|███████   | 7383/10395 [21:04:43<9:17:54, 11.11s/it] 71%|███████   | 7384/10395 [21:04:51<8:23:10, 10.03s/it]                                                         {'loss': 0.8888, 'learning_rate': 4.087165255449502e-06, 'epoch': 0.71}
 71%|███████   | 7384/10395 [21:04:51<8:23:10, 10.03s/it] 71%|███████   | 7385/10395 [21:04:58<7:43:34,  9.24s/it]                                                         {'loss': 0.9785, 'learning_rate': 4.084652817377167e-06, 'epoch': 0.71}
 71%|███████   | 7385/10395 [21:04:58<7:43:34,  9.24s/it] 71%|███████   | 7386/10395 [21:05:06<7:22:51,  8.83s/it]                                                         {'loss': 0.8622, 'learning_rate': 4.082140953554099e-06, 'epoch': 0.71}
 71%|███████   | 7386/10395 [21:05:06<7:22:51,  8.83s/it] 71%|███████   | 7387/10395 [21:05:14<7:05:36,  8.49s/it]                                                         {'loss': 0.8723, 'learning_rate': 4.079629664224136e-06, 'epoch': 0.71}
 71%|███████   | 7387/10395 [21:05:14<7:05:36,  8.49s/it] 71%|███████   | 7388/10395 [21:05:22<6:55:49,  8.30s/it]                                                         {'loss': 0.7976, 'learning_rate': 4.077118949631078e-06, 'epoch': 0.71}
 71%|███████   | 7388/10395 [21:05:22<6:55:49,  8.30s/it] 71%|███████   | 7389/10395 [21:05:29<6:45:15,  8.09s/it]                                                         {'loss': 0.8068, 'learning_rate': 4.074608810018651e-06, 'epoch': 0.71}
 71%|███████   | 7389/10395 [21:05:29<6:45:15,  8.09s/it] 71%|███████   | 7390/10395 [21:05:45<8:39:56, 10.38s/it]                                                         {'loss': 0.3523, 'learning_rate': 4.0720992456305416e-06, 'epoch': 0.71}
 71%|███████   | 7390/10395 [21:05:45<8:39:56, 10.38s/it] 71%|███████   | 7391/10395 [21:05:52<7:54:10,  9.47s/it]                                                         {'loss': 0.9225, 'learning_rate': 4.069590256710366e-06, 'epoch': 0.71}
 71%|███████   | 7391/10395 [21:05:52<7:54:10,  9.47s/it] 71%|███████   | 7392/10395 [21:06:00<7:25:16,  8.90s/it]                                                         {'loss': 0.9023, 'learning_rate': 4.067081843501696e-06, 'epoch': 0.71}
 71%|███████   | 7392/10395 [21:06:00<7:25:16,  8.90s/it] 71%|███████   | 7393/10395 [21:06:07<6:59:54,  8.39s/it]                                                         {'loss': 0.8822, 'learning_rate': 4.064574006248048e-06, 'epoch': 0.71}
 71%|███████   | 7393/10395 [21:06:07<6:59:54,  8.39s/it] 71%|███████   | 7394/10395 [21:06:14<6:44:16,  8.08s/it]                                                         {'loss': 0.8847, 'learning_rate': 4.062066745192864e-06, 'epoch': 0.71}
 71%|███████   | 7394/10395 [21:06:14<6:44:16,  8.08s/it] 71%|███████   | 7395/10395 [21:06:22<6:34:16,  7.89s/it]                                                         {'loss': 0.911, 'learning_rate': 4.0595600605795506e-06, 'epoch': 0.71}
 71%|███████   | 7395/10395 [21:06:22<6:34:16,  7.89s/it] 71%|███████   | 7396/10395 [21:06:29<6:23:48,  7.68s/it]                                                         {'loss': 0.8591, 'learning_rate': 4.057053952651456e-06, 'epoch': 0.71}
 71%|███████   | 7396/10395 [21:06:29<6:23:48,  7.68s/it] 71%|███████   | 7397/10395 [21:06:36<6:18:14,  7.57s/it]                                                         {'loss': 0.903, 'learning_rate': 4.0545484216518606e-06, 'epoch': 0.71}
 71%|███████   | 7397/10395 [21:06:36<6:18:14,  7.57s/it] 71%|███████   | 7398/10395 [21:06:44<6:23:13,  7.67s/it]                                                         {'loss': 0.8743, 'learning_rate': 4.052043467824002e-06, 'epoch': 0.71}
 71%|███████   | 7398/10395 [21:06:44<6:23:13,  7.67s/it] 71%|███████   | 7399/10395 [21:06:52<6:28:31,  7.78s/it]                                                         {'loss': 0.8853, 'learning_rate': 4.0495390914110485e-06, 'epoch': 0.71}
 71%|███████   | 7399/10395 [21:06:52<6:28:31,  7.78s/it] 71%|███████   | 7400/10395 [21:07:00<6:28:28,  7.78s/it]                                                         {'loss': 0.7999, 'learning_rate': 4.047035292656125e-06, 'epoch': 0.71}
 71%|███████   | 7400/10395 [21:07:00<6:28:28,  7.78s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 71%|███████   | 7401/10395 [21:08:38<28:56:04, 34.79s/it]                                                          {'loss': 0.8346, 'learning_rate': 4.0445320718023e-06, 'epoch': 0.71}
 71%|███████   | 7401/10395 [21:08:38<28:56:04, 34.79s/it] 71%|███████   | 7402/10395 [21:08:45<22:09:10, 26.65s/it]                                                          {'loss': 0.8507, 'learning_rate': 4.0420294290925675e-06, 'epoch': 0.71}
 71%|███████   | 7402/10395 [21:08:45<22:09:10, 26.65s/it] 71%|███████   | 7403/10395 [21:08:53<17:27:19, 21.00s/it]                                                          {'loss': 0.9676, 'learning_rate': 4.039527364769887e-06, 'epoch': 0.71}
 71%|███████   | 7403/10395 [21:08:53<17:27:19, 21.00s/it] 71%|███████   | 7404/10395 [21:09:03<14:35:17, 17.56s/it]                                                          {'loss': 0.8071, 'learning_rate': 4.0370258790771546e-06, 'epoch': 0.71}
 71%|███████   | 7404/10395 [21:09:03<14:35:17, 17.56s/it] 71%|███████   | 7405/10395 [21:09:10<12:01:07, 14.47s/it]                                                          {'loss': 0.9241, 'learning_rate': 4.0345249722572046e-06, 'epoch': 0.71}
 71%|███████   | 7405/10395 [21:09:10<12:01:07, 14.47s/it] 71%|███████   | 7406/10395 [21:09:27<12:43:06, 15.32s/it]                                                          {'loss': 0.3946, 'learning_rate': 4.032024644552824e-06, 'epoch': 0.71}
 71%|███████   | 7406/10395 [21:09:27<12:43:06, 15.32s/it] 71%|███████▏  | 7407/10395 [21:09:35<10:44:51, 12.95s/it]                                                          {'loss': 0.868, 'learning_rate': 4.029524896206734e-06, 'epoch': 0.71}
 71%|███████▏  | 7407/10395 [21:09:35<10:44:51, 12.95s/it] 71%|███████▏  | 7408/10395 [21:09:43<9:25:54, 11.37s/it]                                                          {'loss': 0.8588, 'learning_rate': 4.027025727461613e-06, 'epoch': 0.71}
 71%|███████▏  | 7408/10395 [21:09:43<9:25:54, 11.37s/it] 71%|███████▏  | 7409/10395 [21:09:50<8:35:03, 10.35s/it]                                                         {'loss': 0.8752, 'learning_rate': 4.024527138560069e-06, 'epoch': 0.71}
 71%|███████▏  | 7409/10395 [21:09:50<8:35:03, 10.35s/it] 71%|███████▏  | 7410/10395 [21:09:59<8:01:38,  9.68s/it]                                                         {'loss': 0.8729, 'learning_rate': 4.022029129744658e-06, 'epoch': 0.71}
 71%|███████▏  | 7410/10395 [21:09:59<8:01:38,  9.68s/it] 71%|███████▏  | 7411/10395 [21:10:06<7:33:48,  9.12s/it]                                                         {'loss': 0.8571, 'learning_rate': 4.019531701257884e-06, 'epoch': 0.71}
 71%|███████▏  | 7411/10395 [21:10:06<7:33:48,  9.12s/it] 71%|███████▏  | 7412/10395 [21:10:15<7:24:46,  8.95s/it]                                                         {'loss': 0.8279, 'learning_rate': 4.0170348533421945e-06, 'epoch': 0.71}
 71%|███████▏  | 7412/10395 [21:10:15<7:24:46,  8.95s/it] 71%|███████▏  | 7413/10395 [21:10:24<7:19:14,  8.84s/it]                                                         {'loss': 0.9159, 'learning_rate': 4.014538586239973e-06, 'epoch': 0.71}
 71%|███████▏  | 7413/10395 [21:10:24<7:19:14,  8.84s/it] 71%|███████▏  | 7414/10395 [21:10:31<6:56:25,  8.38s/it]                                                         {'loss': 0.8932, 'learning_rate': 4.012042900193559e-06, 'epoch': 0.71}
 71%|███████▏  | 7414/10395 [21:10:31<6:56:25,  8.38s/it] 71%|███████▏  | 7415/10395 [21:10:38<6:42:55,  8.11s/it]                                                         {'loss': 0.8255, 'learning_rate': 4.009547795445222e-06, 'epoch': 0.71}
 71%|███████▏  | 7415/10395 [21:10:38<6:42:55,  8.11s/it] 71%|███████▏  | 7416/10395 [21:10:47<6:45:57,  8.18s/it]                                                         {'loss': 0.8118, 'learning_rate': 4.007053272237181e-06, 'epoch': 0.71}
 71%|███████▏  | 7416/10395 [21:10:47<6:45:57,  8.18s/it] 71%|███████▏  | 7417/10395 [21:10:54<6:33:01,  7.92s/it]                                                         {'loss': 0.9447, 'learning_rate': 4.004559330811606e-06, 'epoch': 0.71}
 71%|███████▏  | 7417/10395 [21:10:54<6:33:01,  7.92s/it] 71%|███████▏  | 7418/10395 [21:11:02<6:32:55,  7.92s/it]                                                         {'loss': 0.9542, 'learning_rate': 4.002065971410594e-06, 'epoch': 0.71}
 71%|███████▏  | 7418/10395 [21:11:02<6:32:55,  7.92s/it] 71%|███████▏  | 7419/10395 [21:11:10<6:30:17,  7.87s/it]                                                         {'loss': 0.8291, 'learning_rate': 3.999573194276199e-06, 'epoch': 0.71}
 71%|███████▏  | 7419/10395 [21:11:10<6:30:17,  7.87s/it] 71%|███████▏  | 7420/10395 [21:11:19<6:45:38,  8.18s/it]                                                         {'loss': 0.7913, 'learning_rate': 3.997080999650421e-06, 'epoch': 0.71}
 71%|███████▏  | 7420/10395 [21:11:19<6:45:38,  8.18s/it] 71%|███████▏  | 7421/10395 [21:11:26<6:37:02,  8.01s/it]                                                         {'loss': 0.8476, 'learning_rate': 3.994589387775186e-06, 'epoch': 0.71}
 71%|███████▏  | 7421/10395 [21:11:26<6:37:02,  8.01s/it] 71%|███████▏  | 7422/10395 [21:11:33<6:24:28,  7.76s/it]                                                         {'loss': 0.837, 'learning_rate': 3.992098358892384e-06, 'epoch': 0.71}
 71%|███████▏  | 7422/10395 [21:11:33<6:24:28,  7.76s/it] 71%|███████▏  | 7423/10395 [21:11:42<6:30:33,  7.88s/it]                                                         {'loss': 0.8493, 'learning_rate': 3.989607913243835e-06, 'epoch': 0.71}
 71%|███████▏  | 7423/10395 [21:11:42<6:30:33,  7.88s/it] 71%|███████▏  | 7424/10395 [21:11:49<6:23:16,  7.74s/it]                                                         {'loss': 1.0046, 'learning_rate': 3.9871180510713005e-06, 'epoch': 0.71}
 71%|███████▏  | 7424/10395 [21:11:49<6:23:16,  7.74s/it] 71%|███████▏  | 7425/10395 [21:11:56<6:17:57,  7.64s/it]                                                         {'loss': 0.9293, 'learning_rate': 3.984628772616501e-06, 'epoch': 0.71}
 71%|███████▏  | 7425/10395 [21:11:56<6:17:57,  7.64s/it] 71%|███████▏  | 7426/10395 [21:12:04<6:18:28,  7.65s/it]                                                         {'loss': 0.881, 'learning_rate': 3.98214007812108e-06, 'epoch': 0.71}
 71%|███████▏  | 7426/10395 [21:12:04<6:18:28,  7.65s/it] 71%|███████▏  | 7427/10395 [21:12:11<6:14:04,  7.56s/it]                                                         {'loss': 0.9021, 'learning_rate': 3.9796519678266425e-06, 'epoch': 0.71}
 71%|███████▏  | 7427/10395 [21:12:11<6:14:04,  7.56s/it] 71%|███████▏  | 7428/10395 [21:12:19<6:13:33,  7.55s/it]                                                         {'loss': 0.95, 'learning_rate': 3.977164441974728e-06, 'epoch': 0.71}
 71%|███████▏  | 7428/10395 [21:12:19<6:13:33,  7.55s/it] 71%|███████▏  | 7429/10395 [21:12:27<6:28:29,  7.86s/it]                                                         {'loss': 0.9013, 'learning_rate': 3.974677500806816e-06, 'epoch': 0.71}
 71%|███████▏  | 7429/10395 [21:12:27<6:28:29,  7.86s/it] 71%|███████▏  | 7430/10395 [21:12:35<6:19:59,  7.69s/it]                                                         {'loss': 0.8691, 'learning_rate': 3.972191144564339e-06, 'epoch': 0.71}
 71%|███████▏  | 7430/10395 [21:12:35<6:19:59,  7.69s/it] 71%|███████▏  | 7431/10395 [21:12:43<6:23:19,  7.76s/it]                                                         {'loss': 0.8933, 'learning_rate': 3.9697053734886645e-06, 'epoch': 0.71}
 71%|███████▏  | 7431/10395 [21:12:43<6:23:19,  7.76s/it] 71%|███████▏  | 7432/10395 [21:12:50<6:15:30,  7.60s/it]                                                         {'loss': 0.9248, 'learning_rate': 3.967220187821102e-06, 'epoch': 0.71}
 71%|███████▏  | 7432/10395 [21:12:50<6:15:30,  7.60s/it] 72%|███████▏  | 7433/10395 [21:12:58<6:23:29,  7.77s/it]                                                         {'loss': 0.9266, 'learning_rate': 3.964735587802915e-06, 'epoch': 0.72}
 72%|███████▏  | 7433/10395 [21:12:58<6:23:29,  7.77s/it] 72%|███████▏  | 7434/10395 [21:13:06<6:23:28,  7.77s/it]                                                         {'loss': 0.9504, 'learning_rate': 3.962251573675297e-06, 'epoch': 0.72}
 72%|███████▏  | 7434/10395 [21:13:06<6:23:28,  7.77s/it] 72%|███████▏  | 7435/10395 [21:13:13<6:16:33,  7.63s/it]                                                         {'loss': 0.91, 'learning_rate': 3.959768145679392e-06, 'epoch': 0.72}
 72%|███████▏  | 7435/10395 [21:13:13<6:16:33,  7.63s/it] 72%|███████▏  | 7436/10395 [21:13:21<6:23:33,  7.78s/it]                                                         {'loss': 0.8792, 'learning_rate': 3.957285304056292e-06, 'epoch': 0.72}
 72%|███████▏  | 7436/10395 [21:13:21<6:23:33,  7.78s/it] 72%|███████▏  | 7437/10395 [21:13:40<9:02:34, 11.01s/it]                                                         {'loss': 0.4001, 'learning_rate': 3.9548030490470215e-06, 'epoch': 0.72}
 72%|███████▏  | 7437/10395 [21:13:40<9:02:34, 11.01s/it] 72%|███████▏  | 7438/10395 [21:13:48<8:21:13, 10.17s/it]                                                         {'loss': 0.8993, 'learning_rate': 3.9523213808925486e-06, 'epoch': 0.72}
 72%|███████▏  | 7438/10395 [21:13:48<8:21:13, 10.17s/it] 72%|███████▏  | 7439/10395 [21:13:57<7:59:57,  9.74s/it]                                                         {'loss': 0.8067, 'learning_rate': 3.949840299833796e-06, 'epoch': 0.72}
 72%|███████▏  | 7439/10395 [21:13:57<7:59:57,  9.74s/it] 72%|███████▏  | 7440/10395 [21:14:04<7:24:57,  9.03s/it]                                                         {'loss': 0.9065, 'learning_rate': 3.947359806111613e-06, 'epoch': 0.72}
 72%|███████▏  | 7440/10395 [21:14:04<7:24:57,  9.03s/it] 72%|███████▏  | 7441/10395 [21:14:12<7:13:48,  8.81s/it]                                                         {'loss': 0.8972, 'learning_rate': 3.94487989996681e-06, 'epoch': 0.72}
 72%|███████▏  | 7441/10395 [21:14:12<7:13:48,  8.81s/it] 72%|███████▏  | 7442/10395 [21:14:21<7:06:26,  8.66s/it]                                                         {'loss': 0.8303, 'learning_rate': 3.942400581640123e-06, 'epoch': 0.72}
 72%|███████▏  | 7442/10395 [21:14:21<7:06:26,  8.66s/it] 72%|███████▏  | 7443/10395 [21:14:29<6:55:23,  8.44s/it]                                                         {'loss': 0.8432, 'learning_rate': 3.939921851372243e-06, 'epoch': 0.72}
 72%|███████▏  | 7443/10395 [21:14:29<6:55:23,  8.44s/it] 72%|███████▏  | 7444/10395 [21:14:37<6:48:30,  8.31s/it]                                                         {'loss': 0.8781, 'learning_rate': 3.937443709403801e-06, 'epoch': 0.72}
 72%|███████▏  | 7444/10395 [21:14:37<6:48:30,  8.31s/it] 72%|███████▏  | 7445/10395 [21:14:54<8:56:04, 10.90s/it]                                                         {'loss': 0.3817, 'learning_rate': 3.934966155975369e-06, 'epoch': 0.72}
 72%|███████▏  | 7445/10395 [21:14:54<8:56:04, 10.90s/it] 72%|███████▏  | 7446/10395 [21:15:01<8:05:10,  9.87s/it]                                                         {'loss': 0.8002, 'learning_rate': 3.932489191327457e-06, 'epoch': 0.72}
 72%|███████▏  | 7446/10395 [21:15:01<8:05:10,  9.87s/it] 72%|███████▏  | 7447/10395 [21:15:10<7:49:44,  9.56s/it]                                                         {'loss': 0.9088, 'learning_rate': 3.930012815700534e-06, 'epoch': 0.72}
 72%|███████▏  | 7447/10395 [21:15:10<7:49:44,  9.56s/it] 72%|███████▏  | 7448/10395 [21:15:18<7:34:23,  9.25s/it]                                                         {'loss': 0.8681, 'learning_rate': 3.92753702933499e-06, 'epoch': 0.72}
 72%|███████▏  | 7448/10395 [21:15:18<7:34:23,  9.25s/it] 72%|███████▏  | 7449/10395 [21:15:27<7:20:32,  8.97s/it]                                                         {'loss': 0.8999, 'learning_rate': 3.925061832471178e-06, 'epoch': 0.72}
 72%|███████▏  | 7449/10395 [21:15:27<7:20:32,  8.97s/it] 72%|███████▏  | 7450/10395 [21:15:35<7:01:52,  8.60s/it]                                                         {'loss': 0.847, 'learning_rate': 3.922587225349378e-06, 'epoch': 0.72}
 72%|███████▏  | 7450/10395 [21:15:35<7:01:52,  8.60s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 72%|███████▏  | 7451/10395 [21:17:13<29:00:36, 35.47s/it]                                                          {'loss': 0.7743, 'learning_rate': 3.9201132082098215e-06, 'epoch': 0.72}
 72%|███████▏  | 7451/10395 [21:17:13<29:00:36, 35.47s/it] 72%|███████▏  | 7452/10395 [21:17:21<22:15:15, 27.22s/it]                                                          {'loss': 0.9149, 'learning_rate': 3.917639781292687e-06, 'epoch': 0.72}
 72%|███████▏  | 7452/10395 [21:17:21<22:15:15, 27.22s/it] 72%|███████▏  | 7453/10395 [21:17:28<17:22:09, 21.25s/it]                                                          {'loss': 0.9401, 'learning_rate': 3.915166944838084e-06, 'epoch': 0.72}
 72%|███████▏  | 7453/10395 [21:17:28<17:22:09, 21.25s/it] 72%|███████▏  | 7454/10395 [21:17:36<14:09:53, 17.34s/it]                                                          {'loss': 0.8526, 'learning_rate': 3.9126946990860655e-06, 'epoch': 0.72}
 72%|███████▏  | 7454/10395 [21:17:36<14:09:53, 17.34s/it] 72%|███████▏  | 7455/10395 [21:17:44<11:51:56, 14.53s/it]                                                          {'loss': 0.8932, 'learning_rate': 3.910223044276643e-06, 'epoch': 0.72}
 72%|███████▏  | 7455/10395 [21:17:44<11:51:56, 14.53s/it] 72%|███████▏  | 7456/10395 [21:17:53<10:26:43, 12.79s/it]                                                          {'loss': 0.8685, 'learning_rate': 3.907751980649749e-06, 'epoch': 0.72}
 72%|███████▏  | 7456/10395 [21:17:53<10:26:43, 12.79s/it] 72%|███████▏  | 7457/10395 [21:18:01<9:20:16, 11.44s/it]                                                          {'loss': 0.9156, 'learning_rate': 3.905281508445273e-06, 'epoch': 0.72}
 72%|███████▏  | 7457/10395 [21:18:01<9:20:16, 11.44s/it] 72%|███████▏  | 7458/10395 [21:18:09<8:25:15, 10.32s/it]                                                         {'loss': 0.8492, 'learning_rate': 3.902811627903048e-06, 'epoch': 0.72}
 72%|███████▏  | 7458/10395 [21:18:09<8:25:15, 10.32s/it] 72%|███████▏  | 7459/10395 [21:18:17<7:45:22,  9.51s/it]                                                         {'loss': 0.8512, 'learning_rate': 3.900342339262837e-06, 'epoch': 0.72}
 72%|███████▏  | 7459/10395 [21:18:17<7:45:22,  9.51s/it] 72%|███████▏  | 7460/10395 [21:18:24<7:17:11,  8.94s/it]                                                         {'loss': 0.9027, 'learning_rate': 3.8978736427643594e-06, 'epoch': 0.72}
 72%|███████▏  | 7460/10395 [21:18:24<7:17:11,  8.94s/it] 72%|███████▏  | 7461/10395 [21:18:42<9:22:11, 11.50s/it]                                                         {'loss': 0.3831, 'learning_rate': 3.895405538647269e-06, 'epoch': 0.72}
 72%|███████▏  | 7461/10395 [21:18:42<9:22:11, 11.50s/it] 72%|███████▏  | 7462/10395 [21:18:49<8:19:55, 10.23s/it]                                                         {'loss': 0.9306, 'learning_rate': 3.892938027151159e-06, 'epoch': 0.72}
 72%|███████▏  | 7462/10395 [21:18:49<8:19:55, 10.23s/it] 72%|███████▏  | 7463/10395 [21:18:57<7:42:51,  9.47s/it]                                                         {'loss': 0.9119, 'learning_rate': 3.890471108515579e-06, 'epoch': 0.72}
 72%|███████▏  | 7463/10395 [21:18:57<7:42:51,  9.47s/it] 72%|███████▏  | 7464/10395 [21:19:04<7:10:12,  8.81s/it]                                                         {'loss': 0.944, 'learning_rate': 3.888004782980004e-06, 'epoch': 0.72}
 72%|███████▏  | 7464/10395 [21:19:04<7:10:12,  8.81s/it] 72%|███████▏  | 7465/10395 [21:19:12<6:53:17,  8.46s/it]                                                         {'loss': 0.8437, 'learning_rate': 3.8855390507838615e-06, 'epoch': 0.72}
 72%|███████▏  | 7465/10395 [21:19:12<6:53:17,  8.46s/it] 72%|███████▏  | 7466/10395 [21:19:19<6:39:55,  8.19s/it]                                                         {'loss': 0.8488, 'learning_rate': 3.883073912166527e-06, 'epoch': 0.72}
 72%|███████▏  | 7466/10395 [21:19:19<6:39:55,  8.19s/it] 72%|███████▏  | 7467/10395 [21:19:27<6:39:49,  8.19s/it]                                                         {'loss': 0.859, 'learning_rate': 3.880609367367304e-06, 'epoch': 0.72}
 72%|███████▏  | 7467/10395 [21:19:27<6:39:49,  8.19s/it] 72%|███████▏  | 7468/10395 [21:19:34<6:23:24,  7.86s/it]                                                         {'loss': 0.904, 'learning_rate': 3.878145416625444e-06, 'epoch': 0.72}
 72%|███████▏  | 7468/10395 [21:19:34<6:23:24,  7.86s/it] 72%|███████▏  | 7469/10395 [21:19:43<6:27:46,  7.95s/it]                                                         {'loss': 0.8853, 'learning_rate': 3.875682060180147e-06, 'epoch': 0.72}
 72%|███████▏  | 7469/10395 [21:19:43<6:27:46,  7.95s/it] 72%|███████▏  | 7470/10395 [21:19:50<6:23:58,  7.88s/it]                                                         {'loss': 0.9432, 'learning_rate': 3.873219298270545e-06, 'epoch': 0.72}
 72%|███████▏  | 7470/10395 [21:19:50<6:23:58,  7.88s/it] 72%|███████▏  | 7471/10395 [21:19:58<6:20:38,  7.81s/it]                                                         {'loss': 0.9304, 'learning_rate': 3.870757131135724e-06, 'epoch': 0.72}
 72%|███████▏  | 7471/10395 [21:19:58<6:20:38,  7.81s/it] 72%|███████▏  | 7472/10395 [21:20:06<6:26:36,  7.94s/it]                                                         {'loss': 0.857, 'learning_rate': 3.868295559014699e-06, 'epoch': 0.72}
 72%|███████▏  | 7472/10395 [21:20:06<6:26:36,  7.94s/it] 72%|███████▏  | 7473/10395 [21:20:14<6:24:51,  7.90s/it]                                                         {'loss': 0.8765, 'learning_rate': 3.865834582146437e-06, 'epoch': 0.72}
 72%|███████▏  | 7473/10395 [21:20:14<6:24:51,  7.90s/it] 72%|███████▏  | 7474/10395 [21:20:21<6:16:58,  7.74s/it]                                                         {'loss': 0.8436, 'learning_rate': 3.863374200769853e-06, 'epoch': 0.72}
 72%|███████▏  | 7474/10395 [21:20:21<6:16:58,  7.74s/it] 72%|███████▏  | 7475/10395 [21:20:30<6:34:37,  8.11s/it]                                                         {'loss': 0.8778, 'learning_rate': 3.8609144151237795e-06, 'epoch': 0.72}
 72%|███████▏  | 7475/10395 [21:20:30<6:34:37,  8.11s/it] 72%|███████▏  | 7476/10395 [21:20:38<6:24:14,  7.90s/it]                                                         {'loss': 0.8858, 'learning_rate': 3.858455225447017e-06, 'epoch': 0.72}
 72%|███████▏  | 7476/10395 [21:20:38<6:24:14,  7.90s/it] 72%|███████▏  | 7477/10395 [21:20:55<8:40:09, 10.70s/it]                                                         {'loss': 0.3968, 'learning_rate': 3.855996631978298e-06, 'epoch': 0.72}
 72%|███████▏  | 7477/10395 [21:20:55<8:40:09, 10.70s/it] 72%|███████▏  | 7478/10395 [21:21:03<8:02:36,  9.93s/it]                                                         {'loss': 0.8833, 'learning_rate': 3.853538634956294e-06, 'epoch': 0.72}
 72%|███████▏  | 7478/10395 [21:21:03<8:02:36,  9.93s/it] 72%|███████▏  | 7479/10395 [21:21:12<7:43:47,  9.54s/it]                                                         {'loss': 0.8422, 'learning_rate': 3.851081234619627e-06, 'epoch': 0.72}
 72%|███████▏  | 7479/10395 [21:21:12<7:43:47,  9.54s/it] 72%|███████▏  | 7480/10395 [21:21:30<9:49:29, 12.13s/it]                                                         {'loss': 0.4055, 'learning_rate': 3.848624431206851e-06, 'epoch': 0.72}
 72%|███████▏  | 7480/10395 [21:21:30<9:49:29, 12.13s/it] 72%|███████▏  | 7481/10395 [21:21:38<8:46:17, 10.84s/it]                                                         {'loss': 0.8294, 'learning_rate': 3.846168224956469e-06, 'epoch': 0.72}
 72%|███████▏  | 7481/10395 [21:21:38<8:46:17, 10.84s/it] 72%|███████▏  | 7482/10395 [21:21:45<8:00:58,  9.91s/it]                                                         {'loss': 0.9226, 'learning_rate': 3.843712616106931e-06, 'epoch': 0.72}
 72%|███████▏  | 7482/10395 [21:21:45<8:00:58,  9.91s/it] 72%|███████▏  | 7483/10395 [21:21:53<7:25:46,  9.18s/it]                                                         {'loss': 0.9404, 'learning_rate': 3.841257604896611e-06, 'epoch': 0.72}
 72%|███████▏  | 7483/10395 [21:21:53<7:25:46,  9.18s/it] 72%|███████▏  | 7484/10395 [21:22:00<7:02:10,  8.70s/it]                                                         {'loss': 0.9134, 'learning_rate': 3.838803191563842e-06, 'epoch': 0.72}
 72%|███████▏  | 7484/10395 [21:22:00<7:02:10,  8.70s/it] 72%|███████▏  | 7485/10395 [21:22:09<7:02:47,  8.72s/it]                                                         {'loss': 0.8105, 'learning_rate': 3.836349376346894e-06, 'epoch': 0.72}
 72%|███████▏  | 7485/10395 [21:22:09<7:02:47,  8.72s/it] 72%|███████▏  | 7486/10395 [21:22:16<6:40:01,  8.25s/it]                                                         {'loss': 0.9497, 'learning_rate': 3.833896159483974e-06, 'epoch': 0.72}
 72%|███████▏  | 7486/10395 [21:22:16<6:40:01,  8.25s/it] 72%|███████▏  | 7487/10395 [21:22:24<6:24:05,  7.92s/it]                                                         {'loss': 0.8651, 'learning_rate': 3.831443541213241e-06, 'epoch': 0.72}
 72%|███████▏  | 7487/10395 [21:22:24<6:24:05,  7.92s/it] 72%|███████▏  | 7488/10395 [21:22:31<6:18:04,  7.80s/it]                                                         {'loss': 0.8393, 'learning_rate': 3.828991521772785e-06, 'epoch': 0.72}
 72%|███████▏  | 7488/10395 [21:22:31<6:18:04,  7.80s/it] 72%|███████▏  | 7489/10395 [21:22:39<6:15:19,  7.75s/it]                                                         {'loss': 0.951, 'learning_rate': 3.826540101400647e-06, 'epoch': 0.72}
 72%|███████▏  | 7489/10395 [21:22:39<6:15:19,  7.75s/it] 72%|███████▏  | 7490/10395 [21:22:47<6:24:13,  7.94s/it]                                                         {'loss': 0.873, 'learning_rate': 3.824089280334802e-06, 'epoch': 0.72}
 72%|███████▏  | 7490/10395 [21:22:47<6:24:13,  7.94s/it] 72%|███████▏  | 7491/10395 [21:22:55<6:20:12,  7.86s/it]                                                         {'loss': 0.8877, 'learning_rate': 3.821639058813169e-06, 'epoch': 0.72}
 72%|███████▏  | 7491/10395 [21:22:55<6:20:12,  7.86s/it] 72%|███████▏  | 7492/10395 [21:23:02<6:16:50,  7.79s/it]                                                         {'loss': 0.8182, 'learning_rate': 3.819189437073613e-06, 'epoch': 0.72}
 72%|███████▏  | 7492/10395 [21:23:02<6:16:50,  7.79s/it] 72%|███████▏  | 7493/10395 [21:23:20<8:43:59, 10.83s/it]                                                         {'loss': 0.3766, 'learning_rate': 3.816740415353942e-06, 'epoch': 0.72}
 72%|███████▏  | 7493/10395 [21:23:20<8:43:59, 10.83s/it] 72%|███████▏  | 7494/10395 [21:23:28<7:57:21,  9.87s/it]                                                         {'loss': 0.9202, 'learning_rate': 3.8142919938918945e-06, 'epoch': 0.72}
 72%|███████▏  | 7494/10395 [21:23:28<7:57:21,  9.87s/it] 72%|███████▏  | 7495/10395 [21:23:44<9:20:18, 11.59s/it]                                                         {'loss': 0.3594, 'learning_rate': 3.8118441729251643e-06, 'epoch': 0.72}
 72%|███████▏  | 7495/10395 [21:23:44<9:20:18, 11.59s/it] 72%|███████▏  | 7496/10395 [21:23:51<8:25:22, 10.46s/it]                                                         {'loss': 0.8605, 'learning_rate': 3.809396952691378e-06, 'epoch': 0.72}
 72%|███████▏  | 7496/10395 [21:23:51<8:25:22, 10.46s/it] 72%|███████▏  | 7497/10395 [21:24:00<7:52:27,  9.78s/it]                                                         {'loss': 0.8632, 'learning_rate': 3.806950333428102e-06, 'epoch': 0.72}
 72%|███████▏  | 7497/10395 [21:24:00<7:52:27,  9.78s/it] 72%|███████▏  | 7498/10395 [21:24:07<7:14:33,  9.00s/it]                                                         {'loss': 0.9272, 'learning_rate': 3.8045043153728565e-06, 'epoch': 0.72}
 72%|███████▏  | 7498/10395 [21:24:07<7:14:33,  9.00s/it] 72%|███████▏  | 7499/10395 [21:24:14<6:54:18,  8.58s/it]                                                         {'loss': 0.8346, 'learning_rate': 3.802058898763089e-06, 'epoch': 0.72}
 72%|███████▏  | 7499/10395 [21:24:14<6:54:18,  8.58s/it] 72%|███████▏  | 7500/10395 [21:24:23<6:58:11,  8.67s/it]                                                         {'loss': 0.8571, 'learning_rate': 3.7996140838361994e-06, 'epoch': 0.72}
 72%|███████▏  | 7500/10395 [21:24:23<6:58:11,  8.67s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 72%|███████▏  | 7501/10395 [21:26:10<30:41:41, 38.18s/it]                                                          {'loss': 0.8114, 'learning_rate': 3.797169870829527e-06, 'epoch': 0.72}
 72%|███████▏  | 7501/10395 [21:26:10<30:41:41, 38.18s/it] 72%|███████▏  | 7502/10395 [21:26:20<23:43:50, 29.53s/it]                                                          {'loss': 0.8736, 'learning_rate': 3.794726259980345e-06, 'epoch': 0.72}
 72%|███████▏  | 7502/10395 [21:26:20<23:43:50, 29.53s/it] 72%|███████▏  | 7503/10395 [21:26:27<18:30:24, 23.04s/it]                                                          {'loss': 0.8715, 'learning_rate': 3.79228325152588e-06, 'epoch': 0.72}
 72%|███████▏  | 7503/10395 [21:26:27<18:30:24, 23.04s/it] 72%|███████▏  | 7504/10395 [21:26:36<15:03:53, 18.76s/it]                                                          {'loss': 0.8295, 'learning_rate': 3.789840845703291e-06, 'epoch': 0.72}
 72%|███████▏  | 7504/10395 [21:26:36<15:03:53, 18.76s/it] 72%|███████▏  | 7505/10395 [21:26:44<12:27:59, 15.53s/it]                                                          {'loss': 0.9234, 'learning_rate': 3.7873990427496776e-06, 'epoch': 0.72}
 72%|███████▏  | 7505/10395 [21:26:44<12:27:59, 15.53s/it]WARNING: tokenization mismatch: 1 vs. 624. (ignored)
 72%|███████▏  | 7506/10395 [21:26:52<10:37:19, 13.24s/it]                                                          {'loss': 0.9558, 'learning_rate': 3.784957842902094e-06, 'epoch': 0.72}
 72%|███████▏  | 7506/10395 [21:26:52<10:37:19, 13.24s/it] 72%|███████▏  | 7507/10395 [21:26:59<9:10:07, 11.43s/it]                                                          {'loss': 0.8817, 'learning_rate': 3.782517246397516e-06, 'epoch': 0.72}
 72%|███████▏  | 7507/10395 [21:26:59<9:10:07, 11.43s/it] 72%|███████▏  | 7508/10395 [21:27:07<8:13:05, 10.25s/it]                                                         {'loss': 0.9184, 'learning_rate': 3.780077253472878e-06, 'epoch': 0.72}
 72%|███████▏  | 7508/10395 [21:27:07<8:13:05, 10.25s/it] 72%|███████▏  | 7509/10395 [21:27:24<9:47:47, 12.22s/it]                                                         {'loss': 0.3531, 'learning_rate': 3.7776378643650515e-06, 'epoch': 0.72}
 72%|███████▏  | 7509/10395 [21:27:24<9:47:47, 12.22s/it] 72%|███████▏  | 7510/10395 [21:27:31<8:44:03, 10.90s/it]                                                         {'loss': 0.8734, 'learning_rate': 3.7751990793108395e-06, 'epoch': 0.72}
 72%|███████▏  | 7510/10395 [21:27:31<8:44:03, 10.90s/it] 72%|███████▏  | 7511/10395 [21:27:40<8:02:50, 10.05s/it]                                                         {'loss': 0.9039, 'learning_rate': 3.7727608985470032e-06, 'epoch': 0.72}
 72%|███████▏  | 7511/10395 [21:27:40<8:02:50, 10.05s/it] 72%|███████▏  | 7512/10395 [21:27:47<7:24:18,  9.25s/it]                                                         {'loss': 0.8693, 'learning_rate': 3.7703233223102307e-06, 'epoch': 0.72}
 72%|███████▏  | 7512/10395 [21:27:47<7:24:18,  9.25s/it] 72%|███████▏  | 7513/10395 [21:27:56<7:16:02,  9.08s/it]                                                         {'loss': 0.9212, 'learning_rate': 3.7678863508371534e-06, 'epoch': 0.72}
 72%|███████▏  | 7513/10395 [21:27:56<7:16:02,  9.08s/it] 72%|███████▏  | 7514/10395 [21:28:06<7:30:22,  9.38s/it]                                                         {'loss': 0.783, 'learning_rate': 3.7654499843643555e-06, 'epoch': 0.72}
 72%|███████▏  | 7514/10395 [21:28:06<7:30:22,  9.38s/it] 72%|███████▏  | 7515/10395 [21:28:13<6:56:46,  8.68s/it]                                                         {'loss': 0.8953, 'learning_rate': 3.7630142231283452e-06, 'epoch': 0.72}
 72%|███████▏  | 7515/10395 [21:28:13<6:56:46,  8.68s/it] 72%|███████▏  | 7516/10395 [21:28:20<6:39:56,  8.34s/it]                                                         {'loss': 0.8872, 'learning_rate': 3.7605790673655862e-06, 'epoch': 0.72}
 72%|███████▏  | 7516/10395 [21:28:20<6:39:56,  8.34s/it] 72%|███████▏  | 7517/10395 [21:28:29<6:39:27,  8.33s/it]                                                         {'loss': 0.8373, 'learning_rate': 3.758144517312482e-06, 'epoch': 0.72}
 72%|███████▏  | 7517/10395 [21:28:29<6:39:27,  8.33s/it] 72%|███████▏  | 7518/10395 [21:28:36<6:29:30,  8.12s/it]                                                         {'loss': 0.9066, 'learning_rate': 3.755710573205368e-06, 'epoch': 0.72}
 72%|███████▏  | 7518/10395 [21:28:36<6:29:30,  8.12s/it] 72%|███████▏  | 7519/10395 [21:28:44<6:23:56,  8.01s/it]                                                         {'loss': 0.9069, 'learning_rate': 3.7532772352805236e-06, 'epoch': 0.72}
 72%|███████▏  | 7519/10395 [21:28:44<6:23:56,  8.01s/it] 72%|███████▏  | 7520/10395 [21:28:52<6:17:52,  7.89s/it]                                                         {'loss': 0.8412, 'learning_rate': 3.7508445037741804e-06, 'epoch': 0.72}
 72%|███████▏  | 7520/10395 [21:28:52<6:17:52,  7.89s/it] 72%|███████▏  | 7521/10395 [21:28:59<6:09:17,  7.71s/it]                                                         {'loss': 0.9233, 'learning_rate': 3.7484123789224945e-06, 'epoch': 0.72}
 72%|███████▏  | 7521/10395 [21:28:59<6:09:17,  7.71s/it] 72%|███████▏  | 7522/10395 [21:29:06<6:04:37,  7.62s/it]                                                         {'loss': 0.8903, 'learning_rate': 3.7459808609615753e-06, 'epoch': 0.72}
 72%|███████▏  | 7522/10395 [21:29:06<6:04:37,  7.62s/it] 72%|███████▏  | 7523/10395 [21:29:24<8:24:03, 10.53s/it]                                                         {'loss': 0.3605, 'learning_rate': 3.743549950127473e-06, 'epoch': 0.72}
 72%|███████▏  | 7523/10395 [21:29:24<8:24:03, 10.53s/it] 72%|███████▏  | 7524/10395 [21:29:32<7:48:47,  9.80s/it]                                                         {'loss': 0.9025, 'learning_rate': 3.741119646656167e-06, 'epoch': 0.72}
 72%|███████▏  | 7524/10395 [21:29:32<7:48:47,  9.80s/it] 72%|███████▏  | 7525/10395 [21:29:39<7:13:14,  9.06s/it]                                                         {'loss': 0.8503, 'learning_rate': 3.738689950783595e-06, 'epoch': 0.72}
 72%|███████▏  | 7525/10395 [21:29:39<7:13:14,  9.06s/it] 72%|███████▏  | 7526/10395 [21:29:47<6:57:39,  8.73s/it]                                                         {'loss': 0.9012, 'learning_rate': 3.736260862745621e-06, 'epoch': 0.72}
 72%|███████▏  | 7526/10395 [21:29:47<6:57:39,  8.73s/it] 72%|███████▏  | 7527/10395 [21:29:55<6:40:13,  8.37s/it]                                                         {'loss': 0.8183, 'learning_rate': 3.733832382778054e-06, 'epoch': 0.72}
 72%|███████▏  | 7527/10395 [21:29:55<6:40:13,  8.37s/it] 72%|███████▏  | 7528/10395 [21:30:02<6:33:29,  8.23s/it]                                                         {'loss': 0.8296, 'learning_rate': 3.731404511116652e-06, 'epoch': 0.72}
 72%|███████▏  | 7528/10395 [21:30:02<6:33:29,  8.23s/it] 72%|███████▏  | 7529/10395 [21:30:10<6:28:38,  8.14s/it]                                                         {'loss': 0.927, 'learning_rate': 3.7289772479971e-06, 'epoch': 0.72}
 72%|███████▏  | 7529/10395 [21:30:10<6:28:38,  8.14s/it] 72%|███████▏  | 7530/10395 [21:30:20<6:53:18,  8.66s/it]                                                         {'loss': 0.8706, 'learning_rate': 3.7265505936550363e-06, 'epoch': 0.72}
 72%|███████▏  | 7530/10395 [21:30:20<6:53:18,  8.66s/it] 72%|███████▏  | 7531/10395 [21:30:28<6:44:16,  8.47s/it]                                                         {'loss': 0.9284, 'learning_rate': 3.7241245483260367e-06, 'epoch': 0.72}
 72%|███████▏  | 7531/10395 [21:30:28<6:44:16,  8.47s/it] 72%|███████▏  | 7532/10395 [21:30:45<8:44:46, 11.00s/it]                                                         {'loss': 0.3827, 'learning_rate': 3.7216991122456125e-06, 'epoch': 0.72}
 72%|███████▏  | 7532/10395 [21:30:45<8:44:46, 11.00s/it] 72%|███████▏  | 7533/10395 [21:30:53<7:59:20, 10.05s/it]                                                         {'loss': 0.9227, 'learning_rate': 3.719274285649225e-06, 'epoch': 0.72}
 72%|███████▏  | 7533/10395 [21:30:53<7:59:20, 10.05s/it] 72%|███████▏  | 7534/10395 [21:31:11<9:49:12, 12.36s/it]                                                         {'loss': 0.3677, 'learning_rate': 3.7168500687722663e-06, 'epoch': 0.72}
 72%|███████▏  | 7534/10395 [21:31:11<9:49:12, 12.36s/it] 72%|███████▏  | 7535/10395 [21:31:18<8:41:37, 10.94s/it]                                                         {'loss': 0.8763, 'learning_rate': 3.7144264618500735e-06, 'epoch': 0.72}
 72%|███████▏  | 7535/10395 [21:31:18<8:41:37, 10.94s/it] 72%|███████▏  | 7536/10395 [21:31:26<7:54:55,  9.97s/it]                                                         {'loss': 0.8343, 'learning_rate': 3.7120034651179315e-06, 'epoch': 0.72}
 72%|███████▏  | 7536/10395 [21:31:26<7:54:55,  9.97s/it] 73%|███████▎  | 7537/10395 [21:31:34<7:19:43,  9.23s/it]                                                         {'loss': 0.901, 'learning_rate': 3.7095810788110508e-06, 'epoch': 0.73}
 73%|███████▎  | 7537/10395 [21:31:34<7:19:43,  9.23s/it] 73%|███████▎  | 7538/10395 [21:31:41<7:00:42,  8.84s/it]                                                         {'loss': 0.9097, 'learning_rate': 3.707159303164597e-06, 'epoch': 0.73}
 73%|███████▎  | 7538/10395 [21:31:41<7:00:42,  8.84s/it] 73%|███████▎  | 7539/10395 [21:31:50<6:49:30,  8.60s/it]                                                         {'loss': 0.8699, 'learning_rate': 3.704738138413674e-06, 'epoch': 0.73}
 73%|███████▎  | 7539/10395 [21:31:50<6:49:30,  8.60s/it] 73%|███████▎  | 7540/10395 [21:31:58<6:42:03,  8.45s/it]                                                         {'loss': 0.825, 'learning_rate': 3.702317584793319e-06, 'epoch': 0.73}
 73%|███████▎  | 7540/10395 [21:31:58<6:42:03,  8.45s/it] 73%|███████▎  | 7541/10395 [21:32:05<6:27:25,  8.14s/it]                                                         {'loss': 0.8682, 'learning_rate': 3.6998976425385114e-06, 'epoch': 0.73}
 73%|███████▎  | 7541/10395 [21:32:05<6:27:25,  8.14s/it] 73%|███████▎  | 7542/10395 [21:32:13<6:29:37,  8.19s/it]                                                         {'loss': 0.8731, 'learning_rate': 3.697478311884181e-06, 'epoch': 0.73}
 73%|███████▎  | 7542/10395 [21:32:13<6:29:37,  8.19s/it] 73%|███████▎  | 7543/10395 [21:32:21<6:18:35,  7.96s/it]                                                         {'loss': 0.8619, 'learning_rate': 3.6950595930651833e-06, 'epoch': 0.73}
 73%|███████▎  | 7543/10395 [21:32:21<6:18:35,  7.96s/it] 73%|███████▎  | 7544/10395 [21:32:29<6:22:29,  8.05s/it]                                                         {'loss': 0.8401, 'learning_rate': 3.6926414863163308e-06, 'epoch': 0.73}
 73%|███████▎  | 7544/10395 [21:32:29<6:22:29,  8.05s/it] 73%|███████▎  | 7545/10395 [21:32:37<6:24:38,  8.10s/it]                                                         {'loss': 0.9573, 'learning_rate': 3.6902239918723602e-06, 'epoch': 0.73}
 73%|███████▎  | 7545/10395 [21:32:37<6:24:38,  8.10s/it] 73%|███████▎  | 7546/10395 [21:32:45<6:17:57,  7.96s/it]                                                         {'loss': 0.9341, 'learning_rate': 3.6878071099679604e-06, 'epoch': 0.73}
 73%|███████▎  | 7546/10395 [21:32:45<6:17:57,  7.96s/it] 73%|███████▎  | 7547/10395 [21:32:53<6:16:24,  7.93s/it]                                                         {'loss': 0.8698, 'learning_rate': 3.6853908408377615e-06, 'epoch': 0.73}
 73%|███████▎  | 7547/10395 [21:32:53<6:16:24,  7.93s/it] 73%|███████▎  | 7548/10395 [21:33:03<6:51:53,  8.68s/it]                                                         {'loss': 0.7695, 'learning_rate': 3.6829751847163242e-06, 'epoch': 0.73}
 73%|███████▎  | 7548/10395 [21:33:03<6:51:53,  8.68s/it] 73%|███████▎  | 7549/10395 [21:33:22<9:12:29, 11.65s/it]                                                         {'loss': 0.3827, 'learning_rate': 3.680560141838153e-06, 'epoch': 0.73}
 73%|███████▎  | 7549/10395 [21:33:22<9:12:29, 11.65s/it] 73%|███████▎  | 7550/10395 [21:33:31<8:35:53, 10.88s/it]                                                         {'loss': 0.8675, 'learning_rate': 3.678145712437703e-06, 'epoch': 0.73}
 73%|███████▎  | 7550/10395 [21:33:31<8:35:53, 10.88s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 73%|███████▎  | 7551/10395 [21:35:11<29:51:48, 37.80s/it]                                                          {'loss': 0.93, 'learning_rate': 3.6757318967493526e-06, 'epoch': 0.73}
 73%|███████▎  | 7551/10395 [21:35:11<29:51:48, 37.80s/it] 73%|███████▎  | 7552/10395 [21:35:19<22:34:43, 28.59s/it]                                                          {'loss': 0.864, 'learning_rate': 3.6733186950074397e-06, 'epoch': 0.73}
 73%|███████▎  | 7552/10395 [21:35:19<22:34:43, 28.59s/it] 73%|███████▎  | 7553/10395 [21:35:27<17:47:33, 22.54s/it]                                                          {'loss': 0.9004, 'learning_rate': 3.6709061074462226e-06, 'epoch': 0.73}
 73%|███████▎  | 7553/10395 [21:35:27<17:47:33, 22.54s/it] 73%|███████▎  | 7554/10395 [21:35:35<14:14:07, 18.04s/it]                                                          {'loss': 0.8818, 'learning_rate': 3.668494134299916e-06, 'epoch': 0.73}
 73%|███████▎  | 7554/10395 [21:35:35<14:14:07, 18.04s/it] 73%|███████▎  | 7555/10395 [21:35:42<11:44:07, 14.88s/it]                                                          {'loss': 0.8763, 'learning_rate': 3.6660827758026753e-06, 'epoch': 0.73}
 73%|███████▎  | 7555/10395 [21:35:42<11:44:07, 14.88s/it] 73%|███████▎  | 7556/10395 [21:35:49<9:55:28, 12.58s/it]                                                          {'loss': 0.9985, 'learning_rate': 3.6636720321885766e-06, 'epoch': 0.73}
 73%|███████▎  | 7556/10395 [21:35:49<9:55:28, 12.58s/it] 73%|███████▎  | 7557/10395 [21:35:57<8:45:26, 11.11s/it]                                                         {'loss': 0.9166, 'learning_rate': 3.661261903691656e-06, 'epoch': 0.73}
 73%|███████▎  | 7557/10395 [21:35:57<8:45:26, 11.11s/it] 73%|███████▎  | 7558/10395 [21:36:05<7:59:44, 10.15s/it]                                                         {'loss': 0.8559, 'learning_rate': 3.6588523905458874e-06, 'epoch': 0.73}
 73%|███████▎  | 7558/10395 [21:36:05<7:59:44, 10.15s/it] 73%|███████▎  | 7559/10395 [21:36:22<9:37:17, 12.21s/it]                                                         {'loss': 0.3323, 'learning_rate': 3.6564434929851735e-06, 'epoch': 0.73}
 73%|███████▎  | 7559/10395 [21:36:22<9:37:17, 12.21s/it] 73%|███████▎  | 7560/10395 [21:36:30<8:41:52, 11.04s/it]                                                         {'loss': 0.83, 'learning_rate': 3.654035211243373e-06, 'epoch': 0.73}
 73%|███████▎  | 7560/10395 [21:36:30<8:41:52, 11.04s/it] 73%|███████▎  | 7561/10395 [21:36:38<7:58:08, 10.12s/it]                                                         {'loss': 0.8195, 'learning_rate': 3.6516275455542693e-06, 'epoch': 0.73}
 73%|███████▎  | 7561/10395 [21:36:38<7:58:08, 10.12s/it] 73%|███████▎  | 7562/10395 [21:36:45<7:17:32,  9.27s/it]                                                         {'loss': 0.9286, 'learning_rate': 3.649220496151601e-06, 'epoch': 0.73}
 73%|███████▎  | 7562/10395 [21:36:45<7:17:32,  9.27s/it] 73%|███████▎  | 7563/10395 [21:36:53<6:49:22,  8.67s/it]                                                         {'loss': 0.8864, 'learning_rate': 3.646814063269034e-06, 'epoch': 0.73}
 73%|███████▎  | 7563/10395 [21:36:53<6:49:22,  8.67s/it] 73%|███████▎  | 7564/10395 [21:37:02<6:57:12,  8.84s/it]                                                         {'loss': 0.8658, 'learning_rate': 3.6444082471401786e-06, 'epoch': 0.73}
 73%|███████▎  | 7564/10395 [21:37:02<6:57:12,  8.84s/it] 73%|███████▎  | 7565/10395 [21:37:10<6:48:19,  8.66s/it]                                                         {'loss': 0.9403, 'learning_rate': 3.642003047998588e-06, 'epoch': 0.73}
 73%|███████▎  | 7565/10395 [21:37:10<6:48:19,  8.66s/it] 73%|███████▎  | 7566/10395 [21:37:18<6:35:21,  8.39s/it]                                                         {'loss': 0.8857, 'learning_rate': 3.6395984660777585e-06, 'epoch': 0.73}
 73%|███████▎  | 7566/10395 [21:37:18<6:35:21,  8.39s/it] 73%|███████▎  | 7567/10395 [21:37:26<6:26:15,  8.20s/it]                                                         {'loss': 0.8139, 'learning_rate': 3.6371945016111143e-06, 'epoch': 0.73}
 73%|███████▎  | 7567/10395 [21:37:26<6:26:15,  8.20s/it] 73%|███████▎  | 7568/10395 [21:37:33<6:15:18,  7.97s/it]                                                         {'loss': 0.9034, 'learning_rate': 3.6347911548320335e-06, 'epoch': 0.73}
 73%|███████▎  | 7568/10395 [21:37:33<6:15:18,  7.97s/it] 73%|███████▎  | 7569/10395 [21:37:41<6:09:56,  7.85s/it]                                                         {'loss': 0.9279, 'learning_rate': 3.6323884259738206e-06, 'epoch': 0.73}
 73%|███████▎  | 7569/10395 [21:37:41<6:09:56,  7.85s/it] 73%|███████▎  | 7570/10395 [21:37:49<6:22:27,  8.12s/it]                                                         {'loss': 0.8544, 'learning_rate': 3.6299863152697368e-06, 'epoch': 0.73}
 73%|███████▎  | 7570/10395 [21:37:49<6:22:27,  8.12s/it] 73%|███████▎  | 7571/10395 [21:37:57<6:15:07,  7.97s/it]                                                         {'loss': 0.9139, 'learning_rate': 3.6275848229529676e-06, 'epoch': 0.73}
 73%|███████▎  | 7571/10395 [21:37:57<6:15:07,  7.97s/it] 73%|███████▎  | 7572/10395 [21:38:05<6:07:55,  7.82s/it]                                                         {'loss': 0.8081, 'learning_rate': 3.625183949256643e-06, 'epoch': 0.73}
 73%|███████▎  | 7572/10395 [21:38:05<6:07:55,  7.82s/it] 73%|███████▎  | 7573/10395 [21:38:13<6:10:04,  7.87s/it]                                                         {'loss': 0.9546, 'learning_rate': 3.6227836944138372e-06, 'epoch': 0.73}
 73%|███████▎  | 7573/10395 [21:38:13<6:10:04,  7.87s/it] 73%|███████▎  | 7574/10395 [21:38:20<6:05:01,  7.76s/it]                                                         {'loss': 0.7959, 'learning_rate': 3.6203840586575657e-06, 'epoch': 0.73}
 73%|███████▎  | 7574/10395 [21:38:20<6:05:01,  7.76s/it] 73%|███████▎  | 7575/10395 [21:38:28<6:01:39,  7.69s/it]                                                         {'loss': 0.9008, 'learning_rate': 3.617985042220773e-06, 'epoch': 0.73}
 73%|███████▎  | 7575/10395 [21:38:28<6:01:39,  7.69s/it] 73%|███████▎  | 7576/10395 [21:38:36<6:09:29,  7.86s/it]                                                         {'loss': 0.9012, 'learning_rate': 3.6155866453363575e-06, 'epoch': 0.73}
 73%|███████▎  | 7576/10395 [21:38:36<6:09:29,  7.86s/it] 73%|███████▎  | 7577/10395 [21:38:52<8:08:34, 10.40s/it]                                                         {'loss': 0.3663, 'learning_rate': 3.6131888682371475e-06, 'epoch': 0.73}
 73%|███████▎  | 7577/10395 [21:38:52<8:08:34, 10.40s/it] 73%|███████▎  | 7578/10395 [21:38:59<7:24:40,  9.47s/it]                                                         {'loss': 0.9168, 'learning_rate': 3.61079171115591e-06, 'epoch': 0.73}
 73%|███████▎  | 7578/10395 [21:38:59<7:24:40,  9.47s/it] 73%|███████▎  | 7579/10395 [21:39:07<6:59:32,  8.94s/it]                                                         {'loss': 0.783, 'learning_rate': 3.608395174325362e-06, 'epoch': 0.73}
 73%|███████▎  | 7579/10395 [21:39:07<6:59:32,  8.94s/it] 73%|███████▎  | 7580/10395 [21:39:15<6:44:05,  8.61s/it]                                                         {'loss': 0.902, 'learning_rate': 3.605999257978149e-06, 'epoch': 0.73}
 73%|███████▎  | 7580/10395 [21:39:15<6:44:05,  8.61s/it] 73%|███████▎  | 7581/10395 [21:39:25<7:04:17,  9.05s/it]                                                         {'loss': 0.8085, 'learning_rate': 3.6036039623468632e-06, 'epoch': 0.73}
 73%|███████▎  | 7581/10395 [21:39:25<7:04:17,  9.05s/it] 73%|███████▎  | 7582/10395 [21:39:33<6:49:57,  8.74s/it]                                                         {'loss': 0.8945, 'learning_rate': 3.6012092876640394e-06, 'epoch': 0.73}
 73%|███████▎  | 7582/10395 [21:39:33<6:49:57,  8.74s/it] 73%|███████▎  | 7583/10395 [21:39:41<6:39:53,  8.53s/it]                                                         {'loss': 0.8681, 'learning_rate': 3.598815234162141e-06, 'epoch': 0.73}
 73%|███████▎  | 7583/10395 [21:39:41<6:39:53,  8.53s/it] 73%|███████▎  | 7584/10395 [21:39:49<6:27:29,  8.27s/it]                                                         {'loss': 0.8503, 'learning_rate': 3.596421802073582e-06, 'epoch': 0.73}
 73%|███████▎  | 7584/10395 [21:39:49<6:27:29,  8.27s/it] 73%|███████▎  | 7585/10395 [21:39:57<6:26:27,  8.25s/it]                                                         {'loss': 0.854, 'learning_rate': 3.5940289916307114e-06, 'epoch': 0.73}
 73%|███████▎  | 7585/10395 [21:39:57<6:26:27,  8.25s/it] 73%|███████▎  | 7586/10395 [21:40:06<6:33:30,  8.41s/it]                                                         {'loss': 0.9095, 'learning_rate': 3.591636803065812e-06, 'epoch': 0.73}
 73%|███████▎  | 7586/10395 [21:40:06<6:33:30,  8.41s/it] 73%|███████▎  | 7587/10395 [21:40:13<6:20:58,  8.14s/it]                                                         {'loss': 0.8762, 'learning_rate': 3.5892452366111187e-06, 'epoch': 0.73}
 73%|███████▎  | 7587/10395 [21:40:13<6:20:58,  8.14s/it] 73%|███████▎  | 7588/10395 [21:40:21<6:16:04,  8.04s/it]                                                         {'loss': 0.8183, 'learning_rate': 3.5868542924988005e-06, 'epoch': 0.73}
 73%|███████▎  | 7588/10395 [21:40:21<6:16:04,  8.04s/it] 73%|███████▎  | 7589/10395 [21:40:30<6:27:49,  8.29s/it]                                                         {'loss': 0.7988, 'learning_rate': 3.58446397096096e-06, 'epoch': 0.73}
 73%|███████▎  | 7589/10395 [21:40:30<6:27:49,  8.29s/it] 73%|███████▎  | 7590/10395 [21:40:38<6:20:59,  8.15s/it]                                                         {'loss': 0.875, 'learning_rate': 3.5820742722296487e-06, 'epoch': 0.73}
 73%|███████▎  | 7590/10395 [21:40:38<6:20:59,  8.15s/it] 73%|███████▎  | 7591/10395 [21:40:55<8:23:58, 10.78s/it]                                                         {'loss': 0.3922, 'learning_rate': 3.5796851965368506e-06, 'epoch': 0.73}
 73%|███████▎  | 7591/10395 [21:40:55<8:23:58, 10.78s/it] 73%|███████▎  | 7592/10395 [21:41:03<7:50:23, 10.07s/it]                                                         {'loss': 0.8754, 'learning_rate': 3.5772967441144956e-06, 'epoch': 0.73}
 73%|███████▎  | 7592/10395 [21:41:03<7:50:23, 10.07s/it] 73%|███████▎  | 7593/10395 [21:41:10<7:11:49,  9.25s/it]                                                         {'loss': 0.9306, 'learning_rate': 3.574908915194447e-06, 'epoch': 0.73}
 73%|███████▎  | 7593/10395 [21:41:10<7:11:49,  9.25s/it] 73%|███████▎  | 7594/10395 [21:41:19<6:55:35,  8.90s/it]                                                         {'loss': 0.9302, 'learning_rate': 3.5725217100085075e-06, 'epoch': 0.73}
 73%|███████▎  | 7594/10395 [21:41:19<6:55:35,  8.90s/it] 73%|███████▎  | 7595/10395 [21:41:27<6:56:03,  8.92s/it]                                                         {'loss': 0.9233, 'learning_rate': 3.5701351287884258e-06, 'epoch': 0.73}
 73%|███████▎  | 7595/10395 [21:41:27<6:56:03,  8.92s/it] 73%|███████▎  | 7596/10395 [21:41:35<6:36:31,  8.50s/it]                                                         {'loss': 0.8377, 'learning_rate': 3.5677491717658875e-06, 'epoch': 0.73}
 73%|███████▎  | 7596/10395 [21:41:35<6:36:31,  8.50s/it] 73%|███████▎  | 7597/10395 [21:41:43<6:33:14,  8.43s/it]                                                         {'loss': 0.8377, 'learning_rate': 3.5653638391725097e-06, 'epoch': 0.73}
 73%|███████▎  | 7597/10395 [21:41:43<6:33:14,  8.43s/it] 73%|███████▎  | 7598/10395 [21:41:52<6:39:18,  8.57s/it]                                                         {'loss': 0.8462, 'learning_rate': 3.5629791312398643e-06, 'epoch': 0.73}
 73%|███████▎  | 7598/10395 [21:41:52<6:39:18,  8.57s/it] 73%|███████▎  | 7599/10395 [21:42:01<6:36:40,  8.51s/it]                                                         {'loss': 0.8855, 'learning_rate': 3.560595048199449e-06, 'epoch': 0.73}
 73%|███████▎  | 7599/10395 [21:42:01<6:36:40,  8.51s/it] 73%|███████▎  | 7600/10395 [21:42:10<6:55:17,  8.91s/it]                                                         {'loss': 0.8909, 'learning_rate': 3.5582115902827006e-06, 'epoch': 0.73}
 73%|███████▎  | 7600/10395 [21:42:10<6:55:17,  8.91s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 73%|███████▎  | 7601/10395 [21:43:53<28:44:58, 37.04s/it]                                                          {'loss': 0.8583, 'learning_rate': 3.555828757721009e-06, 'epoch': 0.73}
 73%|███████▎  | 7601/10395 [21:43:53<28:44:58, 37.04s/it] 73%|███████▎  | 7602/10395 [21:44:00<21:49:45, 28.14s/it]                                                          {'loss': 0.9252, 'learning_rate': 3.5534465507456874e-06, 'epoch': 0.73}
 73%|███████▎  | 7602/10395 [21:44:00<21:49:45, 28.14s/it] 73%|███████▎  | 7603/10395 [21:44:08<17:08:30, 22.10s/it]                                                          {'loss': 0.9493, 'learning_rate': 3.551064969587997e-06, 'epoch': 0.73}
 73%|███████▎  | 7603/10395 [21:44:08<17:08:30, 22.10s/it] 73%|███████▎  | 7604/10395 [21:44:18<14:08:56, 18.25s/it]                                                          {'loss': 0.8146, 'learning_rate': 3.5486840144791435e-06, 'epoch': 0.73}
 73%|███████▎  | 7604/10395 [21:44:18<14:08:56, 18.25s/it] 73%|███████▎  | 7605/10395 [21:44:25<11:39:21, 15.04s/it]                                                          {'loss': 0.8256, 'learning_rate': 3.546303685650254e-06, 'epoch': 0.73}
 73%|███████▎  | 7605/10395 [21:44:25<11:39:21, 15.04s/it] 73%|███████▎  | 7606/10395 [21:44:33<9:52:13, 12.74s/it]                                                          {'loss': 0.9461, 'learning_rate': 3.543923983332416e-06, 'epoch': 0.73}
 73%|███████▎  | 7606/10395 [21:44:33<9:52:13, 12.74s/it] 73%|███████▎  | 7607/10395 [21:44:41<8:53:58, 11.49s/it]                                                         {'loss': 0.8463, 'learning_rate': 3.54154490775664e-06, 'epoch': 0.73}
 73%|███████▎  | 7607/10395 [21:44:41<8:53:58, 11.49s/it] 73%|███████▎  | 7608/10395 [21:44:49<7:57:35, 10.28s/it]                                                         {'loss': 0.8828, 'learning_rate': 3.5391664591538787e-06, 'epoch': 0.73}
 73%|███████▎  | 7608/10395 [21:44:49<7:57:35, 10.28s/it] 73%|███████▎  | 7609/10395 [21:44:57<7:28:42,  9.66s/it]                                                         {'loss': 0.8034, 'learning_rate': 3.5367886377550354e-06, 'epoch': 0.73}
 73%|███████▎  | 7609/10395 [21:44:57<7:28:42,  9.66s/it] 73%|███████▎  | 7610/10395 [21:45:04<6:58:20,  9.01s/it]                                                         {'loss': 0.8204, 'learning_rate': 3.534411443790935e-06, 'epoch': 0.73}
 73%|███████▎  | 7610/10395 [21:45:04<6:58:20,  9.01s/it] 73%|███████▎  | 7611/10395 [21:45:12<6:35:31,  8.52s/it]                                                         {'loss': 0.8165, 'learning_rate': 3.5320348774923553e-06, 'epoch': 0.73}
 73%|███████▎  | 7611/10395 [21:45:12<6:35:31,  8.52s/it] 73%|███████▎  | 7612/10395 [21:45:20<6:31:08,  8.43s/it]                                                         {'loss': 0.8387, 'learning_rate': 3.5296589390900105e-06, 'epoch': 0.73}
 73%|███████▎  | 7612/10395 [21:45:20<6:31:08,  8.43s/it] 73%|███████▎  | 7613/10395 [21:45:27<6:16:10,  8.11s/it]                                                         {'loss': 0.8905, 'learning_rate': 3.527283628814545e-06, 'epoch': 0.73}
 73%|███████▎  | 7613/10395 [21:45:27<6:16:10,  8.11s/it] 73%|███████▎  | 7614/10395 [21:45:36<6:16:16,  8.12s/it]                                                         {'loss': 0.8378, 'learning_rate': 3.524908946896556e-06, 'epoch': 0.73}
 73%|███████▎  | 7614/10395 [21:45:36<6:16:16,  8.12s/it] 73%|███████▎  | 7615/10395 [21:45:44<6:25:02,  8.31s/it]                                                         {'loss': 0.7799, 'learning_rate': 3.5225348935665693e-06, 'epoch': 0.73}
 73%|███████▎  | 7615/10395 [21:45:44<6:25:02,  8.31s/it] 73%|███████▎  | 7616/10395 [21:45:52<6:21:04,  8.23s/it]                                                         {'loss': 0.8928, 'learning_rate': 3.52016146905505e-06, 'epoch': 0.73}
 73%|███████▎  | 7616/10395 [21:45:52<6:21:04,  8.23s/it] 73%|███████▎  | 7617/10395 [21:46:00<6:11:22,  8.02s/it]                                                         {'loss': 0.8578, 'learning_rate': 3.5177886735924105e-06, 'epoch': 0.73}
 73%|███████▎  | 7617/10395 [21:46:00<6:11:22,  8.02s/it] 73%|███████▎  | 7618/10395 [21:46:07<6:02:48,  7.84s/it]                                                         {'loss': 0.8802, 'learning_rate': 3.515416507408991e-06, 'epoch': 0.73}
 73%|███████▎  | 7618/10395 [21:46:07<6:02:48,  7.84s/it] 73%|███████▎  | 7619/10395 [21:46:14<5:51:27,  7.60s/it]                                                         {'loss': 0.9343, 'learning_rate': 3.513044970735079e-06, 'epoch': 0.73}
 73%|███████▎  | 7619/10395 [21:46:14<5:51:27,  7.60s/it] 73%|███████▎  | 7620/10395 [21:46:22<5:51:08,  7.59s/it]                                                         {'loss': 0.8408, 'learning_rate': 3.510674063800903e-06, 'epoch': 0.73}
 73%|███████▎  | 7620/10395 [21:46:22<5:51:08,  7.59s/it] 73%|███████▎  | 7621/10395 [21:46:30<5:55:15,  7.68s/it]                                                         {'loss': 0.8612, 'learning_rate': 3.50830378683662e-06, 'epoch': 0.73}
 73%|███████▎  | 7621/10395 [21:46:30<5:55:15,  7.68s/it] 73%|███████▎  | 7622/10395 [21:46:37<5:53:00,  7.64s/it]                                                         {'loss': 0.777, 'learning_rate': 3.505934140072329e-06, 'epoch': 0.73}
 73%|███████▎  | 7622/10395 [21:46:37<5:53:00,  7.64s/it] 73%|███████▎  | 7623/10395 [21:46:45<5:50:32,  7.59s/it]                                                         {'loss': 0.9247, 'learning_rate': 3.5035651237380787e-06, 'epoch': 0.73}
 73%|███████▎  | 7623/10395 [21:46:45<5:50:32,  7.59s/it] 73%|███████▎  | 7624/10395 [21:46:53<5:54:34,  7.68s/it]                                                         {'loss': 0.9675, 'learning_rate': 3.501196738063839e-06, 'epoch': 0.73}
 73%|███████▎  | 7624/10395 [21:46:53<5:54:34,  7.68s/it] 73%|███████▎  | 7625/10395 [21:47:00<5:53:58,  7.67s/it]                                                         {'loss': 0.9055, 'learning_rate': 3.4988289832795353e-06, 'epoch': 0.73}
 73%|███████▎  | 7625/10395 [21:47:00<5:53:58,  7.67s/it] 73%|███████▎  | 7626/10395 [21:47:08<5:58:31,  7.77s/it]                                                         {'loss': 0.7955, 'learning_rate': 3.4964618596150168e-06, 'epoch': 0.73}
 73%|███████▎  | 7626/10395 [21:47:08<5:58:31,  7.77s/it] 73%|███████▎  | 7627/10395 [21:47:18<6:20:51,  8.26s/it]                                                         {'loss': 0.882, 'learning_rate': 3.4940953673000834e-06, 'epoch': 0.73}
 73%|███████▎  | 7627/10395 [21:47:18<6:20:51,  8.26s/it] 73%|███████▎  | 7628/10395 [21:47:25<6:02:07,  7.85s/it]                                                         {'loss': 0.8013, 'learning_rate': 3.4917295065644717e-06, 'epoch': 0.73}
 73%|███████▎  | 7628/10395 [21:47:25<6:02:07,  7.85s/it] 73%|███████▎  | 7629/10395 [21:47:33<6:03:40,  7.89s/it]                                                         {'loss': 0.8651, 'learning_rate': 3.489364277637852e-06, 'epoch': 0.73}
 73%|███████▎  | 7629/10395 [21:47:33<6:03:40,  7.89s/it] 73%|███████▎  | 7630/10395 [21:47:41<6:05:34,  7.93s/it]                                                         {'loss': 0.8947, 'learning_rate': 3.486999680749832e-06, 'epoch': 0.73}
 73%|███████▎  | 7630/10395 [21:47:41<6:05:34,  7.93s/it] 73%|███████▎  | 7631/10395 [21:47:48<5:57:07,  7.75s/it]                                                         {'loss': 0.8477, 'learning_rate': 3.484635716129967e-06, 'epoch': 0.73}
 73%|███████▎  | 7631/10395 [21:47:48<5:57:07,  7.75s/it] 73%|███████▎  | 7632/10395 [21:47:56<5:58:19,  7.78s/it]                                                         {'loss': 0.8571, 'learning_rate': 3.48227238400774e-06, 'epoch': 0.73}
 73%|███████▎  | 7632/10395 [21:47:56<5:58:19,  7.78s/it] 73%|███████▎  | 7633/10395 [21:48:04<6:00:56,  7.84s/it]                                                         {'loss': 0.8893, 'learning_rate': 3.4799096846125847e-06, 'epoch': 0.73}
 73%|███████▎  | 7633/10395 [21:48:04<6:00:56,  7.84s/it] 73%|███████▎  | 7634/10395 [21:48:12<6:03:06,  7.89s/it]                                                         {'loss': 0.8206, 'learning_rate': 3.477547618173861e-06, 'epoch': 0.73}
 73%|███████▎  | 7634/10395 [21:48:12<6:03:06,  7.89s/it] 73%|███████▎  | 7635/10395 [21:48:29<8:11:36, 10.69s/it]                                                         {'loss': 0.3452, 'learning_rate': 3.4751861849208756e-06, 'epoch': 0.73}
 73%|███████▎  | 7635/10395 [21:48:29<8:11:36, 10.69s/it] 73%|███████▎  | 7636/10395 [21:48:38<7:51:09, 10.25s/it]                                                         {'loss': 0.8252, 'learning_rate': 3.4728253850828785e-06, 'epoch': 0.73}
 73%|███████▎  | 7636/10395 [21:48:38<7:51:09, 10.25s/it] 73%|███████▎  | 7637/10395 [21:48:56<9:34:29, 12.50s/it]                                                         {'loss': 0.3306, 'learning_rate': 3.4704652188890385e-06, 'epoch': 0.73}
 73%|███████▎  | 7637/10395 [21:48:56<9:34:29, 12.50s/it] 73%|███████▎  | 7638/10395 [21:49:04<8:34:22, 11.19s/it]                                                         {'loss': 0.8753, 'learning_rate': 3.46810568656848e-06, 'epoch': 0.73}
 73%|███████▎  | 7638/10395 [21:49:04<8:34:22, 11.19s/it] 73%|███████▎  | 7639/10395 [21:49:13<7:58:06, 10.41s/it]                                                         {'loss': 0.8642, 'learning_rate': 3.465746788350267e-06, 'epoch': 0.73}
 73%|███████▎  | 7639/10395 [21:49:13<7:58:06, 10.41s/it] 73%|███████▎  | 7640/10395 [21:49:20<7:16:20,  9.50s/it]                                                         {'loss': 0.8623, 'learning_rate': 3.4633885244633893e-06, 'epoch': 0.73}
 73%|███████▎  | 7640/10395 [21:49:20<7:16:20,  9.50s/it] 74%|███████▎  | 7641/10395 [21:49:29<7:01:45,  9.19s/it]                                                         {'loss': 0.941, 'learning_rate': 3.4610308951367864e-06, 'epoch': 0.74}
 74%|███████▎  | 7641/10395 [21:49:29<7:01:45,  9.19s/it] 74%|███████▎  | 7642/10395 [21:49:37<6:47:24,  8.88s/it]                                                         {'loss': 0.8452, 'learning_rate': 3.4586739005993285e-06, 'epoch': 0.74}
 74%|███████▎  | 7642/10395 [21:49:37<6:47:24,  8.88s/it] 74%|███████▎  | 7643/10395 [21:49:44<6:23:42,  8.37s/it]                                                         {'loss': 0.9293, 'learning_rate': 3.4563175410798323e-06, 'epoch': 0.74}
 74%|███████▎  | 7643/10395 [21:49:44<6:23:42,  8.37s/it] 74%|███████▎  | 7644/10395 [21:49:52<6:17:01,  8.22s/it]                                                         {'loss': 0.8571, 'learning_rate': 3.4539618168070456e-06, 'epoch': 0.74}
 74%|███████▎  | 7644/10395 [21:49:52<6:17:01,  8.22s/it] 74%|███████▎  | 7645/10395 [21:49:59<6:04:29,  7.95s/it]                                                         {'loss': 0.8959, 'learning_rate': 3.451606728009653e-06, 'epoch': 0.74}
 74%|███████▎  | 7645/10395 [21:49:59<6:04:29,  7.95s/it] 74%|███████▎  | 7646/10395 [21:50:08<6:13:19,  8.15s/it]                                                         {'loss': 0.8743, 'learning_rate': 3.449252274916286e-06, 'epoch': 0.74}
 74%|███████▎  | 7646/10395 [21:50:08<6:13:19,  8.15s/it] 74%|███████▎  | 7647/10395 [21:50:15<5:59:05,  7.84s/it]                                                         {'loss': 0.8651, 'learning_rate': 3.446898457755512e-06, 'epoch': 0.74}
 74%|███████▎  | 7647/10395 [21:50:15<5:59:05,  7.84s/it] 74%|███████▎  | 7648/10395 [21:50:23<5:57:20,  7.81s/it]                                                         {'loss': 0.8963, 'learning_rate': 3.4445452767558284e-06, 'epoch': 0.74}
 74%|███████▎  | 7648/10395 [21:50:23<5:57:20,  7.81s/it] 74%|███████▎  | 7649/10395 [21:50:30<5:57:29,  7.81s/it]                                                         {'loss': 0.9037, 'learning_rate': 3.442192732145684e-06, 'epoch': 0.74}
 74%|███████▎  | 7649/10395 [21:50:30<5:57:29,  7.81s/it] 74%|███████▎  | 7650/10395 [21:50:38<5:59:27,  7.86s/it]                                                         {'loss': 0.8282, 'learning_rate': 3.439840824153451e-06, 'epoch': 0.74}
 74%|███████▎  | 7650/10395 [21:50:38<5:59:27,  7.86s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 74%|███████▎  | 7651/10395 [21:52:21<27:38:03, 36.25s/it]                                                          {'loss': 0.9288, 'learning_rate': 3.437489553007455e-06, 'epoch': 0.74}
 74%|███████▎  | 7651/10395 [21:52:21<27:38:03, 36.25s/it] 74%|███████▎  | 7652/10395 [21:52:29<21:06:11, 27.70s/it]                                                          {'loss': 0.9366, 'learning_rate': 3.4351389189359497e-06, 'epoch': 0.74}
 74%|███████▎  | 7652/10395 [21:52:29<21:06:11, 27.70s/it] 74%|███████▎  | 7653/10395 [21:52:37<16:44:36, 21.98s/it]                                                          {'loss': 0.855, 'learning_rate': 3.432788922167125e-06, 'epoch': 0.74}
 74%|███████▎  | 7653/10395 [21:52:37<16:44:36, 21.98s/it] 74%|███████▎  | 7654/10395 [21:52:45<13:24:46, 17.62s/it]                                                          {'loss': 0.8359, 'learning_rate': 3.430439562929119e-06, 'epoch': 0.74}
 74%|███████▎  | 7654/10395 [21:52:45<13:24:46, 17.62s/it] 74%|███████▎  | 7655/10395 [21:52:53<11:11:23, 14.70s/it]                                                          {'loss': 0.8698, 'learning_rate': 3.4280908414500023e-06, 'epoch': 0.74}
 74%|███████▎  | 7655/10395 [21:52:53<11:11:23, 14.70s/it] 74%|███████▎  | 7656/10395 [21:53:00<9:34:33, 12.59s/it]                                                          {'loss': 0.8509, 'learning_rate': 3.4257427579577805e-06, 'epoch': 0.74}
 74%|███████▎  | 7656/10395 [21:53:00<9:34:33, 12.59s/it] 74%|███████▎  | 7657/10395 [21:53:08<8:23:21, 11.03s/it]                                                         {'loss': 0.8959, 'learning_rate': 3.423395312680402e-06, 'epoch': 0.74}
 74%|███████▎  | 7657/10395 [21:53:08<8:23:21, 11.03s/it] 74%|███████▎  | 7658/10395 [21:53:15<7:37:28, 10.03s/it]                                                         {'loss': 0.7647, 'learning_rate': 3.4210485058457586e-06, 'epoch': 0.74}
 74%|███████▎  | 7658/10395 [21:53:15<7:37:28, 10.03s/it] 74%|███████▎  | 7659/10395 [21:53:34<9:29:35, 12.49s/it]                                                         {'loss': 0.3869, 'learning_rate': 3.418702337681662e-06, 'epoch': 0.74}
 74%|███████▎  | 7659/10395 [21:53:34<9:29:35, 12.49s/it] 74%|███████▎  | 7660/10395 [21:53:41<8:25:24, 11.09s/it]                                                         {'loss': 0.9218, 'learning_rate': 3.416356808415877e-06, 'epoch': 0.74}
 74%|███████▎  | 7660/10395 [21:53:41<8:25:24, 11.09s/it] 74%|███████▎  | 7661/10395 [21:53:58<9:44:10, 12.82s/it]                                                         {'loss': 0.3298, 'learning_rate': 3.4140119182761066e-06, 'epoch': 0.74}
 74%|███████▎  | 7661/10395 [21:53:58<9:44:10, 12.82s/it] 74%|███████▎  | 7662/10395 [21:54:06<8:35:08, 11.31s/it]                                                         {'loss': 0.8199, 'learning_rate': 3.411667667489982e-06, 'epoch': 0.74}
 74%|███████▎  | 7662/10395 [21:54:06<8:35:08, 11.31s/it] 74%|███████▎  | 7663/10395 [21:54:13<7:39:54, 10.10s/it]                                                         {'loss': 0.9013, 'learning_rate': 3.4093240562850847e-06, 'epoch': 0.74}
 74%|███████▎  | 7663/10395 [21:54:13<7:39:54, 10.10s/it] 74%|███████▎  | 7664/10395 [21:54:21<7:01:01,  9.25s/it]                                                         {'loss': 0.8629, 'learning_rate': 3.4069810848889197e-06, 'epoch': 0.74}
 74%|███████▎  | 7664/10395 [21:54:21<7:01:01,  9.25s/it] 74%|███████▎  | 7665/10395 [21:54:29<6:44:40,  8.89s/it]                                                         {'loss': 0.8709, 'learning_rate': 3.404638753528945e-06, 'epoch': 0.74}
 74%|███████▎  | 7665/10395 [21:54:29<6:44:40,  8.89s/it] 74%|███████▎  | 7666/10395 [21:54:36<6:25:04,  8.47s/it]                                                         {'loss': 0.888, 'learning_rate': 3.402297062432547e-06, 'epoch': 0.74}
 74%|███████▎  | 7666/10395 [21:54:36<6:25:04,  8.47s/it] 74%|███████▍  | 7667/10395 [21:54:43<6:10:34,  8.15s/it]                                                         {'loss': 0.8862, 'learning_rate': 3.3999560118270458e-06, 'epoch': 0.74}
 74%|███████▍  | 7667/10395 [21:54:43<6:10:34,  8.15s/it] 74%|███████▍  | 7668/10395 [21:54:51<6:01:52,  7.96s/it]                                                         {'loss': 0.8762, 'learning_rate': 3.397615601939711e-06, 'epoch': 0.74}
 74%|███████▍  | 7668/10395 [21:54:51<6:01:52,  7.96s/it] 74%|███████▍  | 7669/10395 [21:54:58<5:55:24,  7.82s/it]                                                         {'loss': 0.7905, 'learning_rate': 3.395275832997749e-06, 'epoch': 0.74}
 74%|███████▍  | 7669/10395 [21:54:58<5:55:24,  7.82s/it] 74%|███████▍  | 7670/10395 [21:55:07<5:58:37,  7.90s/it]                                                         {'loss': 0.8791, 'learning_rate': 3.3929367052282904e-06, 'epoch': 0.74}
 74%|███████▍  | 7670/10395 [21:55:07<5:58:37,  7.90s/it] 74%|███████▍  | 7671/10395 [21:55:14<5:56:33,  7.85s/it]                                                         {'loss': 0.8589, 'learning_rate': 3.3905982188584195e-06, 'epoch': 0.74}
 74%|███████▍  | 7671/10395 [21:55:14<5:56:33,  7.85s/it] 74%|███████▍  | 7672/10395 [21:55:22<5:53:02,  7.78s/it]                                                         {'loss': 0.8454, 'learning_rate': 3.3882603741151476e-06, 'epoch': 0.74}
 74%|███████▍  | 7672/10395 [21:55:22<5:53:02,  7.78s/it] 74%|███████▍  | 7673/10395 [21:55:29<5:48:44,  7.69s/it]                                                         {'loss': 0.8288, 'learning_rate': 3.3859231712254314e-06, 'epoch': 0.74}
 74%|███████▍  | 7673/10395 [21:55:29<5:48:44,  7.69s/it] 74%|███████▍  | 7674/10395 [21:55:37<5:49:44,  7.71s/it]                                                         {'loss': 0.8365, 'learning_rate': 3.3835866104161596e-06, 'epoch': 0.74}
 74%|███████▍  | 7674/10395 [21:55:37<5:49:44,  7.71s/it] 74%|███████▍  | 7675/10395 [21:55:45<5:55:04,  7.83s/it]                                                         {'loss': 0.8781, 'learning_rate': 3.3812506919141574e-06, 'epoch': 0.74}
 74%|███████▍  | 7675/10395 [21:55:45<5:55:04,  7.83s/it] 74%|███████▍  | 7676/10395 [21:55:53<5:48:03,  7.68s/it]                                                         {'loss': 0.8636, 'learning_rate': 3.3789154159461935e-06, 'epoch': 0.74}
 74%|███████▍  | 7676/10395 [21:55:53<5:48:03,  7.68s/it] 74%|███████▍  | 7677/10395 [21:56:00<5:44:29,  7.60s/it]                                                         {'loss': 0.8874, 'learning_rate': 3.376580782738975e-06, 'epoch': 0.74}
 74%|███████▍  | 7677/10395 [21:56:00<5:44:29,  7.60s/it] 74%|███████▍  | 7678/10395 [21:56:07<5:41:30,  7.54s/it]                                                         {'loss': 0.8297, 'learning_rate': 3.374246792519137e-06, 'epoch': 0.74}
 74%|███████▍  | 7678/10395 [21:56:07<5:41:30,  7.54s/it] 74%|███████▍  | 7679/10395 [21:56:16<5:49:29,  7.72s/it]                                                         {'loss': 0.8678, 'learning_rate': 3.371913445513263e-06, 'epoch': 0.74}
 74%|███████▍  | 7679/10395 [21:56:16<5:49:29,  7.72s/it] 74%|███████▍  | 7680/10395 [21:56:23<5:49:59,  7.73s/it]                                                         {'loss': 0.7628, 'learning_rate': 3.3695807419478686e-06, 'epoch': 0.74}
 74%|███████▍  | 7680/10395 [21:56:23<5:49:59,  7.73s/it] 74%|███████▍  | 7681/10395 [21:56:31<5:48:56,  7.71s/it]                                                         {'loss': 0.9152, 'learning_rate': 3.367248682049403e-06, 'epoch': 0.74}
 74%|███████▍  | 7681/10395 [21:56:31<5:48:56,  7.71s/it] 74%|███████▍  | 7682/10395 [21:56:40<6:08:18,  8.15s/it]                                                         {'loss': 0.8187, 'learning_rate': 3.364917266044264e-06, 'epoch': 0.74}
 74%|███████▍  | 7682/10395 [21:56:40<6:08:18,  8.15s/it] 74%|███████▍  | 7683/10395 [21:56:48<6:04:19,  8.06s/it]                                                         {'loss': 0.8098, 'learning_rate': 3.3625864941587748e-06, 'epoch': 0.74}
 74%|███████▍  | 7683/10395 [21:56:48<6:04:19,  8.06s/it] 74%|███████▍  | 7684/10395 [21:56:56<5:58:33,  7.94s/it]                                                         {'loss': 0.8805, 'learning_rate': 3.3602563666192045e-06, 'epoch': 0.74}
 74%|███████▍  | 7684/10395 [21:56:56<5:58:33,  7.94s/it] 74%|███████▍  | 7685/10395 [21:57:03<5:49:42,  7.74s/it]                                                         {'loss': 0.867, 'learning_rate': 3.357926883651761e-06, 'epoch': 0.74}
 74%|███████▍  | 7685/10395 [21:57:03<5:49:42,  7.74s/it] 74%|███████▍  | 7686/10395 [21:57:11<5:48:06,  7.71s/it]                                                         {'loss': 0.8362, 'learning_rate': 3.3555980454825764e-06, 'epoch': 0.74}
 74%|███████▍  | 7686/10395 [21:57:11<5:48:06,  7.71s/it] 74%|███████▍  | 7687/10395 [21:57:18<5:45:53,  7.66s/it]                                                         {'loss': 0.936, 'learning_rate': 3.353269852337739e-06, 'epoch': 0.74}
 74%|███████▍  | 7687/10395 [21:57:18<5:45:53,  7.66s/it] 74%|███████▍  | 7688/10395 [21:57:36<8:04:14, 10.73s/it]                                                         {'loss': 0.3541, 'learning_rate': 3.3509423044432597e-06, 'epoch': 0.74}
 74%|███████▍  | 7688/10395 [21:57:36<8:04:14, 10.73s/it] 74%|███████▍  | 7689/10395 [21:57:44<7:20:51,  9.78s/it]                                                         {'loss': 0.8252, 'learning_rate': 3.3486154020250893e-06, 'epoch': 0.74}
 74%|███████▍  | 7689/10395 [21:57:44<7:20:51,  9.78s/it] 74%|███████▍  | 7690/10395 [21:57:52<7:08:58,  9.51s/it]                                                         {'loss': 0.7838, 'learning_rate': 3.346289145309125e-06, 'epoch': 0.74}
 74%|███████▍  | 7690/10395 [21:57:52<7:08:58,  9.51s/it] 74%|███████▍  | 7691/10395 [21:58:00<6:46:09,  9.01s/it]                                                         {'loss': 0.7968, 'learning_rate': 3.3439635345211884e-06, 'epoch': 0.74}
 74%|███████▍  | 7691/10395 [21:58:00<6:46:09,  9.01s/it] 74%|███████▍  | 7692/10395 [21:58:08<6:22:05,  8.48s/it]                                                         {'loss': 0.9128, 'learning_rate': 3.341638569887048e-06, 'epoch': 0.74}
 74%|███████▍  | 7692/10395 [21:58:08<6:22:05,  8.48s/it] 74%|███████▍  | 7693/10395 [21:58:16<6:14:56,  8.33s/it]                                                         {'loss': 0.7954, 'learning_rate': 3.3393142516324084e-06, 'epoch': 0.74}
 74%|███████▍  | 7693/10395 [21:58:16<6:14:56,  8.33s/it] 74%|███████▍  | 7694/10395 [21:58:34<8:26:45, 11.26s/it]                                                         {'loss': 0.3349, 'learning_rate': 3.336990579982905e-06, 'epoch': 0.74}
 74%|███████▍  | 7694/10395 [21:58:34<8:26:45, 11.26s/it] 74%|███████▍  | 7695/10395 [21:58:41<7:35:42, 10.13s/it]                                                         {'loss': 0.8793, 'learning_rate': 3.3346675551641204e-06, 'epoch': 0.74}
 74%|███████▍  | 7695/10395 [21:58:41<7:35:42, 10.13s/it] 74%|███████▍  | 7696/10395 [21:58:49<7:04:46,  9.44s/it]                                                         {'loss': 0.8521, 'learning_rate': 3.3323451774015658e-06, 'epoch': 0.74}
 74%|███████▍  | 7696/10395 [21:58:49<7:04:46,  9.44s/it] 74%|███████▍  | 7697/10395 [21:58:57<6:46:11,  9.03s/it]                                                         {'loss': 0.8524, 'learning_rate': 3.3300234469206884e-06, 'epoch': 0.74}
 74%|███████▍  | 7697/10395 [21:58:57<6:46:11,  9.03s/it] 74%|███████▍  | 7698/10395 [21:59:07<6:57:17,  9.28s/it]                                                         {'loss': 0.7817, 'learning_rate': 3.327702363946885e-06, 'epoch': 0.74}
 74%|███████▍  | 7698/10395 [21:59:07<6:57:17,  9.28s/it] 74%|███████▍  | 7699/10395 [21:59:15<6:42:33,  8.96s/it]                                                         {'loss': 0.7337, 'learning_rate': 3.3253819287054735e-06, 'epoch': 0.74}
 74%|███████▍  | 7699/10395 [21:59:15<6:42:33,  8.96s/it] 74%|███████▍  | 7700/10395 [21:59:23<6:31:40,  8.72s/it]                                                         {'loss': 0.8141, 'learning_rate': 3.3230621414217214e-06, 'epoch': 0.74}
 74%|███████▍  | 7700/10395 [21:59:23<6:31:40,  8.72s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 74%|███████▍  | 7701/10395 [22:01:04<27:06:24, 36.22s/it]                                                          {'loss': 0.8696, 'learning_rate': 3.320743002320831e-06, 'epoch': 0.74}
 74%|███████▍  | 7701/10395 [22:01:04<27:06:24, 36.22s/it] 74%|███████▍  | 7702/10395 [22:01:12<20:50:56, 27.87s/it]                                                          {'loss': 0.8691, 'learning_rate': 3.3184245116279355e-06, 'epoch': 0.74}
 74%|███████▍  | 7702/10395 [22:01:12<20:50:56, 27.87s/it] 74%|███████▍  | 7703/10395 [22:01:21<16:34:28, 22.17s/it]                                                          {'loss': 0.8688, 'learning_rate': 3.316106669568108e-06, 'epoch': 0.74}
 74%|███████▍  | 7703/10395 [22:01:21<16:34:28, 22.17s/it] 74%|███████▍  | 7704/10395 [22:01:28<13:13:59, 17.70s/it]                                                          {'loss': 0.9654, 'learning_rate': 3.3137894763663636e-06, 'epoch': 0.74}
 74%|███████▍  | 7704/10395 [22:01:28<13:13:59, 17.70s/it] 74%|███████▍  | 7705/10395 [22:01:37<11:09:52, 14.94s/it]                                                          {'loss': 0.9022, 'learning_rate': 3.311472932247646e-06, 'epoch': 0.74}
 74%|███████▍  | 7705/10395 [22:01:37<11:09:52, 14.94s/it] 74%|███████▍  | 7706/10395 [22:01:44<9:30:23, 12.73s/it]                                                          {'loss': 0.8737, 'learning_rate': 3.3091570374368453e-06, 'epoch': 0.74}
 74%|███████▍  | 7706/10395 [22:01:44<9:30:23, 12.73s/it] 74%|███████▍  | 7707/10395 [22:01:52<8:18:16, 11.12s/it]                                                         {'loss': 0.899, 'learning_rate': 3.3068417921587783e-06, 'epoch': 0.74}
 74%|███████▍  | 7707/10395 [22:01:52<8:18:16, 11.12s/it] 74%|███████▍  | 7708/10395 [22:01:59<7:26:31,  9.97s/it]                                                         {'loss': 0.8733, 'learning_rate': 3.3045271966382066e-06, 'epoch': 0.74}
 74%|███████▍  | 7708/10395 [22:01:59<7:26:31,  9.97s/it] 74%|███████▍  | 7709/10395 [22:02:07<6:57:07,  9.32s/it]                                                         {'loss': 0.9135, 'learning_rate': 3.3022132510998315e-06, 'epoch': 0.74}
 74%|███████▍  | 7709/10395 [22:02:07<6:57:07,  9.32s/it] 74%|███████▍  | 7710/10395 [22:02:14<6:29:00,  8.69s/it]                                                         {'loss': 0.9607, 'learning_rate': 3.2998999557682766e-06, 'epoch': 0.74}
 74%|███████▍  | 7710/10395 [22:02:14<6:29:00,  8.69s/it] 74%|███████▍  | 7711/10395 [22:02:21<6:13:36,  8.35s/it]                                                         {'loss': 0.8476, 'learning_rate': 3.2975873108681147e-06, 'epoch': 0.74}
 74%|███████▍  | 7711/10395 [22:02:21<6:13:36,  8.35s/it] 74%|███████▍  | 7712/10395 [22:02:29<6:06:44,  8.20s/it]                                                         {'loss': 0.9325, 'learning_rate': 3.295275316623856e-06, 'epoch': 0.74}
 74%|███████▍  | 7712/10395 [22:02:29<6:06:44,  8.20s/it] 74%|███████▍  | 7713/10395 [22:02:46<8:00:47, 10.76s/it]                                                         {'loss': 0.442, 'learning_rate': 3.2929639732599393e-06, 'epoch': 0.74}
 74%|███████▍  | 7713/10395 [22:02:46<8:00:47, 10.76s/it] 74%|███████▍  | 7714/10395 [22:02:54<7:18:49,  9.82s/it]                                                         {'loss': 0.8226, 'learning_rate': 3.290653281000751e-06, 'epoch': 0.74}
 74%|███████▍  | 7714/10395 [22:02:54<7:18:49,  9.82s/it] 74%|███████▍  | 7715/10395 [22:03:02<6:54:06,  9.27s/it]                                                         {'loss': 0.9183, 'learning_rate': 3.2883432400705994e-06, 'epoch': 0.74}
 74%|███████▍  | 7715/10395 [22:03:02<6:54:06,  9.27s/it] 74%|███████▍  | 7716/10395 [22:03:09<6:31:25,  8.77s/it]                                                         {'loss': 0.8185, 'learning_rate': 3.286033850693744e-06, 'epoch': 0.74}
 74%|███████▍  | 7716/10395 [22:03:09<6:31:25,  8.77s/it] 74%|███████▍  | 7717/10395 [22:03:18<6:24:47,  8.62s/it]                                                         {'loss': 0.84, 'learning_rate': 3.2837251130943814e-06, 'epoch': 0.74}
 74%|███████▍  | 7717/10395 [22:03:18<6:24:47,  8.62s/it] 74%|███████▍  | 7718/10395 [22:03:26<6:21:43,  8.56s/it]                                                         {'loss': 0.879, 'learning_rate': 3.2814170274966252e-06, 'epoch': 0.74}
 74%|███████▍  | 7718/10395 [22:03:26<6:21:43,  8.56s/it] 74%|███████▍  | 7719/10395 [22:03:35<6:28:37,  8.71s/it]                                                         {'loss': 0.751, 'learning_rate': 3.2791095941245455e-06, 'epoch': 0.74}
 74%|███████▍  | 7719/10395 [22:03:35<6:28:37,  8.71s/it] 74%|███████▍  | 7720/10395 [22:03:43<6:24:18,  8.62s/it]                                                         {'loss': 0.8574, 'learning_rate': 3.276802813202148e-06, 'epoch': 0.74}
 74%|███████▍  | 7720/10395 [22:03:43<6:24:18,  8.62s/it] 74%|███████▍  | 7721/10395 [22:03:51<6:15:08,  8.42s/it]                                                         {'loss': 0.8867, 'learning_rate': 3.274496684953363e-06, 'epoch': 0.74}
 74%|███████▍  | 7721/10395 [22:03:51<6:15:08,  8.42s/it] 74%|███████▍  | 7722/10395 [22:03:59<6:07:16,  8.24s/it]                                                         {'loss': 0.8606, 'learning_rate': 3.27219120960207e-06, 'epoch': 0.74}
 74%|███████▍  | 7722/10395 [22:03:59<6:07:16,  8.24s/it] 74%|███████▍  | 7723/10395 [22:04:07<6:03:11,  8.16s/it]                                                         {'loss': 0.8408, 'learning_rate': 3.2698863873720733e-06, 'epoch': 0.74}
 74%|███████▍  | 7723/10395 [22:04:07<6:03:11,  8.16s/it] 74%|███████▍  | 7724/10395 [22:04:15<6:01:28,  8.12s/it]                                                         {'loss': 0.9124, 'learning_rate': 3.2675822184871286e-06, 'epoch': 0.74}
 74%|███████▍  | 7724/10395 [22:04:15<6:01:28,  8.12s/it] 74%|███████▍  | 7725/10395 [22:04:23<5:55:27,  7.99s/it]                                                         {'loss': 0.865, 'learning_rate': 3.26527870317091e-06, 'epoch': 0.74}
 74%|███████▍  | 7725/10395 [22:04:23<5:55:27,  7.99s/it] 74%|███████▍  | 7726/10395 [22:04:31<5:56:15,  8.01s/it]                                                         {'loss': 0.7571, 'learning_rate': 3.262975841647047e-06, 'epoch': 0.74}
 74%|███████▍  | 7726/10395 [22:04:31<5:56:15,  8.01s/it] 74%|███████▍  | 7727/10395 [22:04:38<5:48:08,  7.83s/it]                                                         {'loss': 0.9244, 'learning_rate': 3.2606736341390886e-06, 'epoch': 0.74}
 74%|███████▍  | 7727/10395 [22:04:38<5:48:08,  7.83s/it] 74%|███████▍  | 7728/10395 [22:04:46<5:40:01,  7.65s/it]                                                         {'loss': 0.8915, 'learning_rate': 3.2583720808705355e-06, 'epoch': 0.74}
 74%|███████▍  | 7728/10395 [22:04:46<5:40:01,  7.65s/it] 74%|███████▍  | 7729/10395 [22:04:53<5:32:15,  7.48s/it]                                                         {'loss': 0.9227, 'learning_rate': 3.2560711820648094e-06, 'epoch': 0.74}
 74%|███████▍  | 7729/10395 [22:04:53<5:32:15,  7.48s/it] 74%|███████▍  | 7730/10395 [22:05:00<5:33:45,  7.51s/it]                                                         {'loss': 0.8593, 'learning_rate': 3.253770937945282e-06, 'epoch': 0.74}
 74%|███████▍  | 7730/10395 [22:05:00<5:33:45,  7.51s/it] 74%|███████▍  | 7731/10395 [22:05:08<5:33:47,  7.52s/it]                                                         {'loss': 0.8626, 'learning_rate': 3.2514713487352622e-06, 'epoch': 0.74}
 74%|███████▍  | 7731/10395 [22:05:08<5:33:47,  7.52s/it] 74%|███████▍  | 7732/10395 [22:05:24<7:32:10, 10.19s/it]                                                         {'loss': 0.3176, 'learning_rate': 3.249172414657975e-06, 'epoch': 0.74}
 74%|███████▍  | 7732/10395 [22:05:24<7:32:10, 10.19s/it] 74%|███████▍  | 7733/10395 [22:05:32<6:58:03,  9.42s/it]                                                         {'loss': 0.8384, 'learning_rate': 3.246874135936603e-06, 'epoch': 0.74}
 74%|███████▍  | 7733/10395 [22:05:32<6:58:03,  9.42s/it] 74%|███████▍  | 7734/10395 [22:05:40<6:41:11,  9.05s/it]                                                         {'loss': 0.8718, 'learning_rate': 3.244576512794263e-06, 'epoch': 0.74}
 74%|███████▍  | 7734/10395 [22:05:40<6:41:11,  9.05s/it] 74%|███████▍  | 7735/10395 [22:05:47<6:19:18,  8.56s/it]                                                         {'loss': 0.983, 'learning_rate': 3.2422795454539945e-06, 'epoch': 0.74}
 74%|███████▍  | 7735/10395 [22:05:47<6:19:18,  8.56s/it] 74%|███████▍  | 7736/10395 [22:05:56<6:22:49,  8.64s/it]                                                         {'loss': 0.8966, 'learning_rate': 3.239983234138789e-06, 'epoch': 0.74}
 74%|███████▍  | 7736/10395 [22:05:56<6:22:49,  8.64s/it] 74%|███████▍  | 7737/10395 [22:06:05<6:25:01,  8.69s/it]                                                         {'loss': 0.8423, 'learning_rate': 3.2376875790715623e-06, 'epoch': 0.74}
 74%|███████▍  | 7737/10395 [22:06:05<6:25:01,  8.69s/it] 74%|███████▍  | 7738/10395 [22:06:12<6:08:08,  8.31s/it]                                                         {'loss': 0.8389, 'learning_rate': 3.235392580475175e-06, 'epoch': 0.74}
 74%|███████▍  | 7738/10395 [22:06:12<6:08:08,  8.31s/it] 74%|███████▍  | 7739/10395 [22:06:20<5:53:00,  7.97s/it]                                                         {'loss': 0.8038, 'learning_rate': 3.233098238572425e-06, 'epoch': 0.74}
 74%|███████▍  | 7739/10395 [22:06:20<5:53:00,  7.97s/it] 74%|███████▍  | 7740/10395 [22:06:28<5:51:52,  7.95s/it]                                                         {'loss': 0.9147, 'learning_rate': 3.230804553586032e-06, 'epoch': 0.74}
 74%|███████▍  | 7740/10395 [22:06:28<5:51:52,  7.95s/it] 74%|███████▍  | 7741/10395 [22:06:35<5:45:55,  7.82s/it]                                                         {'loss': 0.8217, 'learning_rate': 3.228511525738667e-06, 'epoch': 0.74}
 74%|███████▍  | 7741/10395 [22:06:35<5:45:55,  7.82s/it] 74%|███████▍  | 7742/10395 [22:06:42<5:39:16,  7.67s/it]                                                         {'loss': 0.8881, 'learning_rate': 3.2262191552529353e-06, 'epoch': 0.74}
 74%|███████▍  | 7742/10395 [22:06:42<5:39:16,  7.67s/it] 74%|███████▍  | 7743/10395 [22:06:50<5:36:25,  7.61s/it]                                                         {'loss': 0.8555, 'learning_rate': 3.2239274423513687e-06, 'epoch': 0.74}
 74%|███████▍  | 7743/10395 [22:06:50<5:36:25,  7.61s/it] 74%|███████▍  | 7744/10395 [22:06:59<5:50:17,  7.93s/it]                                                         {'loss': 0.8444, 'learning_rate': 3.221636387256449e-06, 'epoch': 0.74}
 74%|███████▍  | 7744/10395 [22:06:59<5:50:17,  7.93s/it] 75%|███████▍  | 7745/10395 [22:07:06<5:49:25,  7.91s/it]                                                         {'loss': 0.9091, 'learning_rate': 3.21934599019058e-06, 'epoch': 0.75}
 75%|███████▍  | 7745/10395 [22:07:06<5:49:25,  7.91s/it] 75%|███████▍  | 7746/10395 [22:07:16<6:10:54,  8.40s/it]                                                         {'loss': 0.8735, 'learning_rate': 3.217056251376116e-06, 'epoch': 0.75}
 75%|███████▍  | 7746/10395 [22:07:16<6:10:54,  8.40s/it] 75%|███████▍  | 7747/10395 [22:07:24<6:03:10,  8.23s/it]                                                         {'loss': 0.8672, 'learning_rate': 3.214767171035336e-06, 'epoch': 0.75}
 75%|███████▍  | 7747/10395 [22:07:24<6:03:10,  8.23s/it] 75%|███████▍  | 7748/10395 [22:07:31<5:51:18,  7.96s/it]                                                         {'loss': 0.8569, 'learning_rate': 3.2124787493904543e-06, 'epoch': 0.75}
 75%|███████▍  | 7748/10395 [22:07:31<5:51:18,  7.96s/it] 75%|███████▍  | 7749/10395 [22:07:39<5:49:36,  7.93s/it]                                                         {'loss': 0.9209, 'learning_rate': 3.2101909866636316e-06, 'epoch': 0.75}
 75%|███████▍  | 7749/10395 [22:07:39<5:49:36,  7.93s/it] 75%|███████▍  | 7750/10395 [22:07:48<6:01:29,  8.20s/it]                                                         {'loss': 0.8903, 'learning_rate': 3.2079038830769606e-06, 'epoch': 0.75}
 75%|███████▍  | 7750/10395 [22:07:48<6:01:29,  8.20s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 75%|███████▍  | 7751/10395 [22:09:30<26:45:08, 36.43s/it]                                                          {'loss': 0.8495, 'learning_rate': 3.205617438852463e-06, 'epoch': 0.75}
 75%|███████▍  | 7751/10395 [22:09:30<26:45:08, 36.43s/it] 75%|███████▍  | 7752/10395 [22:09:48<22:39:20, 30.86s/it]                                                          {'loss': 0.366, 'learning_rate': 3.2033316542121086e-06, 'epoch': 0.75}
 75%|███████▍  | 7752/10395 [22:09:48<22:39:20, 30.86s/it] 75%|███████▍  | 7753/10395 [22:09:56<17:38:00, 24.03s/it]                                                          {'loss': 0.8687, 'learning_rate': 3.2010465293777924e-06, 'epoch': 0.75}
 75%|███████▍  | 7753/10395 [22:09:56<17:38:00, 24.03s/it] 75%|███████▍  | 7754/10395 [22:10:04<14:01:55, 19.13s/it]                                                          {'loss': 0.9162, 'learning_rate': 3.1987620645713455e-06, 'epoch': 0.75}
 75%|███████▍  | 7754/10395 [22:10:04<14:01:55, 19.13s/it] 75%|███████▍  | 7755/10395 [22:10:12<11:36:30, 15.83s/it]                                                          {'loss': 0.8329, 'learning_rate': 3.1964782600145484e-06, 'epoch': 0.75}
 75%|███████▍  | 7755/10395 [22:10:12<11:36:30, 15.83s/it] 75%|███████▍  | 7756/10395 [22:10:20<9:52:01, 13.46s/it]                                                          {'loss': 0.8543, 'learning_rate': 3.1941951159290973e-06, 'epoch': 0.75}
 75%|███████▍  | 7756/10395 [22:10:20<9:52:01, 13.46s/it] 75%|███████▍  | 7757/10395 [22:10:28<8:37:51, 11.78s/it]                                                         {'loss': 0.8418, 'learning_rate': 3.191912632536641e-06, 'epoch': 0.75}
 75%|███████▍  | 7757/10395 [22:10:28<8:37:51, 11.78s/it] 75%|███████▍  | 7758/10395 [22:10:35<7:40:37, 10.48s/it]                                                         {'loss': 0.8703, 'learning_rate': 3.1896308100587613e-06, 'epoch': 0.75}
 75%|███████▍  | 7758/10395 [22:10:35<7:40:37, 10.48s/it] 75%|███████▍  | 7759/10395 [22:10:42<6:57:53,  9.51s/it]                                                         {'loss': 0.8964, 'learning_rate': 3.1873496487169643e-06, 'epoch': 0.75}
 75%|███████▍  | 7759/10395 [22:10:42<6:57:53,  9.51s/it] 75%|███████▍  | 7760/10395 [22:10:50<6:29:07,  8.86s/it]                                                         {'loss': 0.9096, 'learning_rate': 3.185069148732709e-06, 'epoch': 0.75}
 75%|███████▍  | 7760/10395 [22:10:50<6:29:07,  8.86s/it] 75%|███████▍  | 7761/10395 [22:10:58<6:17:54,  8.61s/it]                                                         {'loss': 0.8625, 'learning_rate': 3.1827893103273768e-06, 'epoch': 0.75}
 75%|███████▍  | 7761/10395 [22:10:58<6:17:54,  8.61s/it] 75%|███████▍  | 7762/10395 [22:11:06<6:07:29,  8.37s/it]                                                         {'loss': 0.8288, 'learning_rate': 3.1805101337222867e-06, 'epoch': 0.75}
 75%|███████▍  | 7762/10395 [22:11:06<6:07:29,  8.37s/it] 75%|███████▍  | 7763/10395 [22:11:14<6:04:02,  8.30s/it]                                                         {'loss': 0.8953, 'learning_rate': 3.178231619138703e-06, 'epoch': 0.75}
 75%|███████▍  | 7763/10395 [22:11:14<6:04:02,  8.30s/it] 75%|███████▍  | 7764/10395 [22:11:21<5:51:09,  8.01s/it]                                                         {'loss': 0.8537, 'learning_rate': 3.1759537667978122e-06, 'epoch': 0.75}
 75%|███████▍  | 7764/10395 [22:11:21<5:51:09,  8.01s/it] 75%|███████▍  | 7765/10395 [22:11:29<5:46:42,  7.91s/it]                                                         {'loss': 0.825, 'learning_rate': 3.1736765769207468e-06, 'epoch': 0.75}
 75%|███████▍  | 7765/10395 [22:11:29<5:46:42,  7.91s/it] 75%|███████▍  | 7766/10395 [22:11:37<5:49:33,  7.98s/it]                                                         {'loss': 0.8107, 'learning_rate': 3.1714000497285736e-06, 'epoch': 0.75}
 75%|███████▍  | 7766/10395 [22:11:37<5:49:33,  7.98s/it] 75%|███████▍  | 7767/10395 [22:11:44<5:38:42,  7.73s/it]                                                         {'loss': 0.9009, 'learning_rate': 3.1691241854422882e-06, 'epoch': 0.75}
 75%|███████▍  | 7767/10395 [22:11:44<5:38:42,  7.73s/it] 75%|███████▍  | 7768/10395 [22:11:52<5:41:57,  7.81s/it]                                                         {'loss': 0.9127, 'learning_rate': 3.1668489842828333e-06, 'epoch': 0.75}
 75%|███████▍  | 7768/10395 [22:11:52<5:41:57,  7.81s/it] 75%|███████▍  | 7769/10395 [22:12:00<5:46:54,  7.93s/it]                                                         {'loss': 0.8473, 'learning_rate': 3.164574446471076e-06, 'epoch': 0.75}
 75%|███████▍  | 7769/10395 [22:12:00<5:46:54,  7.93s/it] 75%|███████▍  | 7770/10395 [22:12:08<5:43:24,  7.85s/it]                                                         {'loss': 0.8299, 'learning_rate': 3.16230057222782e-06, 'epoch': 0.75}
 75%|███████▍  | 7770/10395 [22:12:08<5:43:24,  7.85s/it] 75%|███████▍  | 7771/10395 [22:12:15<5:39:57,  7.77s/it]                                                         {'loss': 0.927, 'learning_rate': 3.1600273617738165e-06, 'epoch': 0.75}
 75%|███████▍  | 7771/10395 [22:12:15<5:39:57,  7.77s/it] 75%|███████▍  | 7772/10395 [22:12:23<5:43:05,  7.85s/it]                                                         {'loss': 0.8843, 'learning_rate': 3.1577548153297365e-06, 'epoch': 0.75}
 75%|███████▍  | 7772/10395 [22:12:23<5:43:05,  7.85s/it] 75%|███████▍  | 7773/10395 [22:12:31<5:33:24,  7.63s/it]                                                         {'loss': 0.8555, 'learning_rate': 3.1554829331161963e-06, 'epoch': 0.75}
 75%|███████▍  | 7773/10395 [22:12:31<5:33:24,  7.63s/it] 75%|███████▍  | 7774/10395 [22:12:38<5:25:55,  7.46s/it]                                                         {'loss': 0.9854, 'learning_rate': 3.15321171535375e-06, 'epoch': 0.75}
 75%|███████▍  | 7774/10395 [22:12:38<5:25:55,  7.46s/it] 75%|███████▍  | 7775/10395 [22:12:45<5:27:35,  7.50s/it]                                                         {'loss': 0.8529, 'learning_rate': 3.1509411622628748e-06, 'epoch': 0.75}
 75%|███████▍  | 7775/10395 [22:12:45<5:27:35,  7.50s/it] 75%|███████▍  | 7776/10395 [22:12:53<5:33:13,  7.63s/it]                                                         {'loss': 0.8702, 'learning_rate': 3.148671274063999e-06, 'epoch': 0.75}
 75%|███████▍  | 7776/10395 [22:12:53<5:33:13,  7.63s/it] 75%|███████▍  | 7777/10395 [22:13:01<5:35:48,  7.70s/it]                                                         {'loss': 0.8377, 'learning_rate': 3.146402050977474e-06, 'epoch': 0.75}
 75%|███████▍  | 7777/10395 [22:13:01<5:35:48,  7.70s/it] 75%|███████▍  | 7778/10395 [22:13:18<7:40:38, 10.56s/it]                                                         {'loss': 0.3953, 'learning_rate': 3.144133493223589e-06, 'epoch': 0.75}
 75%|███████▍  | 7778/10395 [22:13:18<7:40:38, 10.56s/it] 75%|███████▍  | 7779/10395 [22:13:26<7:03:40,  9.72s/it]                                                         {'loss': 0.9326, 'learning_rate': 3.141865601022577e-06, 'epoch': 0.75}
 75%|███████▍  | 7779/10395 [22:13:26<7:03:40,  9.72s/it] 75%|███████▍  | 7780/10395 [22:13:35<6:53:19,  9.48s/it]                                                         {'loss': 0.8845, 'learning_rate': 3.1395983745945924e-06, 'epoch': 0.75}
 75%|███████▍  | 7780/10395 [22:13:35<6:53:19,  9.48s/it] 75%|███████▍  | 7781/10395 [22:13:43<6:29:07,  8.93s/it]                                                         {'loss': 0.9182, 'learning_rate': 3.1373318141597377e-06, 'epoch': 0.75}
 75%|███████▍  | 7781/10395 [22:13:43<6:29:07,  8.93s/it] 75%|███████▍  | 7782/10395 [22:13:50<6:06:20,  8.41s/it]                                                         {'loss': 0.8273, 'learning_rate': 3.1350659199380475e-06, 'epoch': 0.75}
 75%|███████▍  | 7782/10395 [22:13:50<6:06:20,  8.41s/it] 75%|███████▍  | 7783/10395 [22:13:58<6:05:17,  8.39s/it]                                                         {'loss': 0.8475, 'learning_rate': 3.132800692149488e-06, 'epoch': 0.75}
 75%|███████▍  | 7783/10395 [22:13:58<6:05:17,  8.39s/it] 75%|███████▍  | 7784/10395 [22:14:06<5:59:50,  8.27s/it]                                                         {'loss': 0.9155, 'learning_rate': 3.130536131013958e-06, 'epoch': 0.75}
 75%|███████▍  | 7784/10395 [22:14:06<5:59:50,  8.27s/it] 75%|███████▍  | 7785/10395 [22:14:14<5:53:38,  8.13s/it]                                                         {'loss': 0.8908, 'learning_rate': 3.128272236751304e-06, 'epoch': 0.75}
 75%|███████▍  | 7785/10395 [22:14:14<5:53:38,  8.13s/it] 75%|███████▍  | 7786/10395 [22:14:22<5:49:35,  8.04s/it]                                                         {'loss': 0.8557, 'learning_rate': 3.1260090095812935e-06, 'epoch': 0.75}
 75%|███████▍  | 7786/10395 [22:14:22<5:49:35,  8.04s/it] 75%|███████▍  | 7787/10395 [22:14:30<5:47:09,  7.99s/it]                                                         {'loss': 0.8876, 'learning_rate': 3.1237464497236415e-06, 'epoch': 0.75}
 75%|███████▍  | 7787/10395 [22:14:30<5:47:09,  7.99s/it] 75%|███████▍  | 7788/10395 [22:14:37<5:44:30,  7.93s/it]                                                         {'loss': 0.8056, 'learning_rate': 3.121484557397986e-06, 'epoch': 0.75}
 75%|███████▍  | 7788/10395 [22:14:37<5:44:30,  7.93s/it] 75%|███████▍  | 7789/10395 [22:14:55<7:49:17, 10.80s/it]                                                         {'loss': 0.3959, 'learning_rate': 3.1192233328239107e-06, 'epoch': 0.75}
 75%|███████▍  | 7789/10395 [22:14:55<7:49:17, 10.80s/it] 75%|███████▍  | 7790/10395 [22:15:03<7:08:11,  9.86s/it]                                                         {'loss': 0.8675, 'learning_rate': 3.116962776220933e-06, 'epoch': 0.75}
 75%|███████▍  | 7790/10395 [22:15:03<7:08:11,  9.86s/it] 75%|███████▍  | 7791/10395 [22:15:10<6:39:34,  9.21s/it]                                                         {'loss': 0.8669, 'learning_rate': 3.1147028878084993e-06, 'epoch': 0.75}
 75%|███████▍  | 7791/10395 [22:15:10<6:39:34,  9.21s/it] 75%|███████▍  | 7792/10395 [22:15:19<6:29:21,  8.98s/it]                                                         {'loss': 0.8176, 'learning_rate': 3.112443667805993e-06, 'epoch': 0.75}
 75%|███████▍  | 7792/10395 [22:15:19<6:29:21,  8.98s/it] 75%|███████▍  | 7793/10395 [22:15:27<6:16:08,  8.67s/it]                                                         {'loss': 0.862, 'learning_rate': 3.11018511643274e-06, 'epoch': 0.75}
 75%|███████▍  | 7793/10395 [22:15:27<6:16:08,  8.67s/it] 75%|███████▍  | 7794/10395 [22:15:34<6:01:53,  8.35s/it]                                                         {'loss': 0.9439, 'learning_rate': 3.107927233907988e-06, 'epoch': 0.75}
 75%|███████▍  | 7794/10395 [22:15:34<6:01:53,  8.35s/it] 75%|███████▍  | 7795/10395 [22:15:42<5:58:31,  8.27s/it]                                                         {'loss': 0.908, 'learning_rate': 3.1056700204509327e-06, 'epoch': 0.75}
 75%|███████▍  | 7795/10395 [22:15:42<5:58:31,  8.27s/it] 75%|███████▍  | 7796/10395 [22:15:50<5:54:29,  8.18s/it]                                                         {'loss': 0.8427, 'learning_rate': 3.103413476280702e-06, 'epoch': 0.75}
 75%|███████▍  | 7796/10395 [22:15:50<5:54:29,  8.18s/it] 75%|███████▌  | 7797/10395 [22:15:57<5:36:21,  7.77s/it]                                                         {'loss': 0.9045, 'learning_rate': 3.1011576016163493e-06, 'epoch': 0.75}
 75%|███████▌  | 7797/10395 [22:15:57<5:36:21,  7.77s/it] 75%|███████▌  | 7798/10395 [22:16:07<5:59:08,  8.30s/it]                                                         {'loss': 0.8047, 'learning_rate': 3.098902396676876e-06, 'epoch': 0.75}
 75%|███████▌  | 7798/10395 [22:16:07<5:59:08,  8.30s/it] 75%|███████▌  | 7799/10395 [22:16:14<5:47:57,  8.04s/it]                                                         {'loss': 0.8522, 'learning_rate': 3.0966478616812123e-06, 'epoch': 0.75}
 75%|███████▌  | 7799/10395 [22:16:14<5:47:57,  8.04s/it] 75%|███████▌  | 7800/10395 [22:16:22<5:40:04,  7.86s/it]                                                         {'loss': 0.9096, 'learning_rate': 3.0943939968482173e-06, 'epoch': 0.75}
 75%|███████▌  | 7800/10395 [22:16:22<5:40:04,  7.86s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 75%|███████▌  | 7801/10395 [22:18:02<25:42:50, 35.69s/it]                                                          {'loss': 0.8852, 'learning_rate': 3.092140802396698e-06, 'epoch': 0.75}
 75%|███████▌  | 7801/10395 [22:18:02<25:42:50, 35.69s/it] 75%|███████▌  | 7802/10395 [22:18:10<19:35:30, 27.20s/it]                                                          {'loss': 0.8734, 'learning_rate': 3.0898882785453866e-06, 'epoch': 0.75}
 75%|███████▌  | 7802/10395 [22:18:10<19:35:30, 27.20s/it] 75%|███████▌  | 7803/10395 [22:18:18<15:30:39, 21.54s/it]                                                          {'loss': 0.8242, 'learning_rate': 3.087636425512952e-06, 'epoch': 0.75}
 75%|███████▌  | 7803/10395 [22:18:18<15:30:39, 21.54s/it] 75%|███████▌  | 7804/10395 [22:18:26<12:29:55, 17.37s/it]                                                          {'loss': 0.9629, 'learning_rate': 3.085385243518005e-06, 'epoch': 0.75}
 75%|███████▌  | 7804/10395 [22:18:26<12:29:55, 17.37s/it] 75%|███████▌  | 7805/10395 [22:18:44<12:40:04, 17.61s/it]                                                          {'loss': 0.3845, 'learning_rate': 3.0831347327790827e-06, 'epoch': 0.75}
 75%|███████▌  | 7805/10395 [22:18:44<12:40:04, 17.61s/it] 75%|███████▌  | 7806/10395 [22:18:51<10:27:17, 14.54s/it]                                                          {'loss': 0.8982, 'learning_rate': 3.080884893514656e-06, 'epoch': 0.75}
 75%|███████▌  | 7806/10395 [22:18:51<10:27:17, 14.54s/it] 75%|███████▌  | 7807/10395 [22:18:59<9:05:30, 12.65s/it]                                                          {'loss': 0.8411, 'learning_rate': 3.078635725943141e-06, 'epoch': 0.75}
 75%|███████▌  | 7807/10395 [22:18:59<9:05:30, 12.65s/it] 75%|███████▌  | 7808/10395 [22:19:07<8:00:58, 11.16s/it]                                                         {'loss': 0.8887, 'learning_rate': 3.0763872302828746e-06, 'epoch': 0.75}
 75%|███████▌  | 7808/10395 [22:19:07<8:00:58, 11.16s/it] 75%|███████▌  | 7809/10395 [22:19:23<8:59:20, 12.51s/it]                                                         {'loss': 0.3538, 'learning_rate': 3.0741394067521444e-06, 'epoch': 0.75}
 75%|███████▌  | 7809/10395 [22:19:23<8:59:20, 12.51s/it] 75%|███████▌  | 7810/10395 [22:19:30<7:53:35, 10.99s/it]                                                         {'loss': 0.9743, 'learning_rate': 3.0718922555691555e-06, 'epoch': 0.75}
 75%|███████▌  | 7810/10395 [22:19:30<7:53:35, 10.99s/it] 75%|███████▌  | 7811/10395 [22:19:37<7:06:05,  9.89s/it]                                                         {'loss': 0.8694, 'learning_rate': 3.0696457769520627e-06, 'epoch': 0.75}
 75%|███████▌  | 7811/10395 [22:19:37<7:06:05,  9.89s/it] 75%|███████▌  | 7812/10395 [22:19:45<6:35:02,  9.18s/it]                                                         {'loss': 0.9427, 'learning_rate': 3.0673999711189527e-06, 'epoch': 0.75}
 75%|███████▌  | 7812/10395 [22:19:45<6:35:02,  9.18s/it] 75%|███████▌  | 7813/10395 [22:19:53<6:22:13,  8.88s/it]                                                         {'loss': 0.8693, 'learning_rate': 3.0651548382878326e-06, 'epoch': 0.75}
 75%|███████▌  | 7813/10395 [22:19:53<6:22:13,  8.88s/it] 75%|███████▌  | 7814/10395 [22:20:09<7:55:07, 11.05s/it]                                                         {'loss': 0.3703, 'learning_rate': 3.06291037867666e-06, 'epoch': 0.75}
 75%|███████▌  | 7814/10395 [22:20:09<7:55:07, 11.05s/it] 75%|███████▌  | 7815/10395 [22:20:17<7:11:33, 10.04s/it]                                                         {'loss': 0.8609, 'learning_rate': 3.0606665925033274e-06, 'epoch': 0.75}
 75%|███████▌  | 7815/10395 [22:20:17<7:11:33, 10.04s/it] 75%|███████▌  | 7816/10395 [22:20:24<6:37:58,  9.26s/it]                                                         {'loss': 0.8797, 'learning_rate': 3.0584234799856494e-06, 'epoch': 0.75}
 75%|███████▌  | 7816/10395 [22:20:24<6:37:58,  9.26s/it] 75%|███████▌  | 7817/10395 [22:20:32<6:15:22,  8.74s/it]                                                         {'loss': 0.8655, 'learning_rate': 3.0561810413413896e-06, 'epoch': 0.75}
 75%|███████▌  | 7817/10395 [22:20:32<6:15:22,  8.74s/it] 75%|███████▌  | 7818/10395 [22:20:40<6:05:58,  8.52s/it]                                                         {'loss': 0.9108, 'learning_rate': 3.0539392767882305e-06, 'epoch': 0.75}
 75%|███████▌  | 7818/10395 [22:20:40<6:05:58,  8.52s/it] 75%|███████▌  | 7819/10395 [22:20:48<5:57:00,  8.32s/it]                                                         {'loss': 0.912, 'learning_rate': 3.0516981865438035e-06, 'epoch': 0.75}
 75%|███████▌  | 7819/10395 [22:20:48<5:57:00,  8.32s/it] 75%|███████▌  | 7820/10395 [22:20:56<5:59:29,  8.38s/it]                                                         {'loss': 0.8241, 'learning_rate': 3.0494577708256747e-06, 'epoch': 0.75}
 75%|███████▌  | 7820/10395 [22:20:56<5:59:29,  8.38s/it] 75%|███████▌  | 7821/10395 [22:21:04<5:52:10,  8.21s/it]                                                         {'loss': 0.8716, 'learning_rate': 3.0472180298513256e-06, 'epoch': 0.75}
 75%|███████▌  | 7821/10395 [22:21:04<5:52:10,  8.21s/it] 75%|███████▌  | 7822/10395 [22:21:12<5:45:11,  8.05s/it]                                                         {'loss': 0.8806, 'learning_rate': 3.044978963838191e-06, 'epoch': 0.75}
 75%|███████▌  | 7822/10395 [22:21:12<5:45:11,  8.05s/it] 75%|███████▌  | 7823/10395 [22:21:20<5:45:45,  8.07s/it]                                                         {'loss': 0.9325, 'learning_rate': 3.0427405730036395e-06, 'epoch': 0.75}
 75%|███████▌  | 7823/10395 [22:21:20<5:45:45,  8.07s/it] 75%|███████▌  | 7824/10395 [22:21:28<5:43:05,  8.01s/it]                                                         {'loss': 0.8984, 'learning_rate': 3.040502857564963e-06, 'epoch': 0.75}
 75%|███████▌  | 7824/10395 [22:21:28<5:43:05,  8.01s/it] 75%|███████▌  | 7825/10395 [22:21:36<5:42:36,  8.00s/it]                                                         {'loss': 0.9234, 'learning_rate': 3.0382658177393985e-06, 'epoch': 0.75}
 75%|███████▌  | 7825/10395 [22:21:36<5:42:36,  8.00s/it] 75%|███████▌  | 7826/10395 [22:21:43<5:32:46,  7.77s/it]                                                         {'loss': 0.9037, 'learning_rate': 3.0360294537441094e-06, 'epoch': 0.75}
 75%|███████▌  | 7826/10395 [22:21:43<5:32:46,  7.77s/it] 75%|███████▌  | 7827/10395 [22:21:51<5:31:00,  7.73s/it]                                                         {'loss': 0.8658, 'learning_rate': 3.0337937657962015e-06, 'epoch': 0.75}
 75%|███████▌  | 7827/10395 [22:21:51<5:31:00,  7.73s/it] 75%|███████▌  | 7828/10395 [22:21:59<5:41:26,  7.98s/it]                                                         {'loss': 0.8369, 'learning_rate': 3.031558754112708e-06, 'epoch': 0.75}
 75%|███████▌  | 7828/10395 [22:21:59<5:41:26,  7.98s/it] 75%|███████▌  | 7829/10395 [22:22:08<5:54:48,  8.30s/it]                                                         {'loss': 0.8388, 'learning_rate': 3.0293244189105954e-06, 'epoch': 0.75}
 75%|███████▌  | 7829/10395 [22:22:08<5:54:48,  8.30s/it] 75%|███████▌  | 7830/10395 [22:22:16<5:43:47,  8.04s/it]                                                         {'loss': 0.8638, 'learning_rate': 3.027090760406771e-06, 'epoch': 0.75}
 75%|███████▌  | 7830/10395 [22:22:16<5:43:47,  8.04s/it] 75%|███████▌  | 7831/10395 [22:22:23<5:32:40,  7.78s/it]                                                         {'loss': 0.9148, 'learning_rate': 3.024857778818079e-06, 'epoch': 0.75}
 75%|███████▌  | 7831/10395 [22:22:23<5:32:40,  7.78s/it] 75%|███████▌  | 7832/10395 [22:22:31<5:32:53,  7.79s/it]                                                         {'loss': 0.8759, 'learning_rate': 3.022625474361285e-06, 'epoch': 0.75}
 75%|███████▌  | 7832/10395 [22:22:31<5:32:53,  7.79s/it] 75%|███████▌  | 7833/10395 [22:22:41<6:04:01,  8.53s/it]                                                         {'loss': 0.867, 'learning_rate': 3.0203938472531012e-06, 'epoch': 0.75}
 75%|███████▌  | 7833/10395 [22:22:41<6:04:01,  8.53s/it] 75%|███████▌  | 7834/10395 [22:22:48<5:47:44,  8.15s/it]                                                         {'loss': 0.9849, 'learning_rate': 3.0181628977101687e-06, 'epoch': 0.75}
 75%|███████▌  | 7834/10395 [22:22:48<5:47:44,  8.15s/it] 75%|███████▌  | 7835/10395 [22:22:57<5:57:18,  8.37s/it]                                                         {'loss': 0.7621, 'learning_rate': 3.0159326259490575e-06, 'epoch': 0.75}
 75%|███████▌  | 7835/10395 [22:22:57<5:57:18,  8.37s/it] 75%|███████▌  | 7836/10395 [22:23:06<6:02:10,  8.49s/it]                                                         {'loss': 0.7578, 'learning_rate': 3.013703032186286e-06, 'epoch': 0.75}
 75%|███████▌  | 7836/10395 [22:23:06<6:02:10,  8.49s/it] 75%|███████▌  | 7837/10395 [22:23:13<5:48:55,  8.18s/it]                                                         {'loss': 0.8964, 'learning_rate': 3.0114741166382897e-06, 'epoch': 0.75}
 75%|███████▌  | 7837/10395 [22:23:13<5:48:55,  8.18s/it] 75%|███████▌  | 7838/10395 [22:23:29<7:30:33, 10.57s/it]                                                         {'loss': 0.3471, 'learning_rate': 3.009245879521453e-06, 'epoch': 0.75}
 75%|███████▌  | 7838/10395 [22:23:29<7:30:33, 10.57s/it] 75%|███████▌  | 7839/10395 [22:23:37<6:51:43,  9.66s/it]                                                         {'loss': 0.9265, 'learning_rate': 3.0070183210520896e-06, 'epoch': 0.75}
 75%|███████▌  | 7839/10395 [22:23:37<6:51:43,  9.66s/it] 75%|███████▌  | 7840/10395 [22:23:44<6:21:07,  8.95s/it]                                                         {'loss': 0.8988, 'learning_rate': 3.0047914414464408e-06, 'epoch': 0.75}
 75%|███████▌  | 7840/10395 [22:23:44<6:21:07,  8.95s/it] 75%|███████▌  | 7841/10395 [22:23:53<6:15:23,  8.82s/it]                                                         {'loss': 0.8607, 'learning_rate': 3.002565240920693e-06, 'epoch': 0.75}
 75%|███████▌  | 7841/10395 [22:23:53<6:15:23,  8.82s/it] 75%|███████▌  | 7842/10395 [22:24:01<6:06:58,  8.62s/it]                                                         {'loss': 0.8634, 'learning_rate': 3.000339719690958e-06, 'epoch': 0.75}
 75%|███████▌  | 7842/10395 [22:24:01<6:06:58,  8.62s/it] 75%|███████▌  | 7843/10395 [22:24:09<5:58:15,  8.42s/it]                                                         {'loss': 0.8518, 'learning_rate': 2.9981148779732817e-06, 'epoch': 0.75}
 75%|███████▌  | 7843/10395 [22:24:09<5:58:15,  8.42s/it] 75%|███████▌  | 7844/10395 [22:24:17<5:51:53,  8.28s/it]                                                         {'loss': 0.865, 'learning_rate': 2.9958907159836524e-06, 'epoch': 0.75}
 75%|███████▌  | 7844/10395 [22:24:17<5:51:53,  8.28s/it] 75%|███████▌  | 7845/10395 [22:24:24<5:37:27,  7.94s/it]                                                         {'loss': 0.9808, 'learning_rate': 2.9936672339379825e-06, 'epoch': 0.75}
 75%|███████▌  | 7845/10395 [22:24:24<5:37:27,  7.94s/it] 75%|███████▌  | 7846/10395 [22:24:32<5:37:11,  7.94s/it]                                                         {'loss': 0.8124, 'learning_rate': 2.991444432052124e-06, 'epoch': 0.75}
 75%|███████▌  | 7846/10395 [22:24:32<5:37:11,  7.94s/it] 75%|███████▌  | 7847/10395 [22:24:41<5:47:44,  8.19s/it]                                                         {'loss': 0.8544, 'learning_rate': 2.9892223105418672e-06, 'epoch': 0.75}
 75%|███████▌  | 7847/10395 [22:24:41<5:47:44,  8.19s/it] 75%|███████▌  | 7848/10395 [22:24:48<5:39:23,  8.00s/it]                                                         {'loss': 0.8606, 'learning_rate': 2.987000869622921e-06, 'epoch': 0.75}
 75%|███████▌  | 7848/10395 [22:24:48<5:39:23,  8.00s/it] 76%|███████▌  | 7849/10395 [22:24:57<5:44:23,  8.12s/it]                                                         {'loss': 0.8105, 'learning_rate': 2.9847801095109484e-06, 'epoch': 0.76}
 76%|███████▌  | 7849/10395 [22:24:57<5:44:23,  8.12s/it] 76%|███████▌  | 7850/10395 [22:25:05<5:42:45,  8.08s/it]                                                         {'loss': 0.905, 'learning_rate': 2.982560030421532e-06, 'epoch': 0.76}
 76%|███████▌  | 7850/10395 [22:25:05<5:42:45,  8.08s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 76%|███████▌  | 7851/10395 [22:26:47<25:46:55, 36.48s/it]                                                          {'loss': 0.9133, 'learning_rate': 2.9803406325701867e-06, 'epoch': 0.76}
 76%|███████▌  | 7851/10395 [22:26:47<25:46:55, 36.48s/it] 76%|███████▌  | 7852/10395 [22:26:56<19:48:43, 28.05s/it]                                                          {'loss': 0.7916, 'learning_rate': 2.9781219161723752e-06, 'epoch': 0.76}
 76%|███████▌  | 7852/10395 [22:26:56<19:48:43, 28.05s/it] 76%|███████▌  | 7853/10395 [22:27:03<15:28:41, 21.92s/it]                                                          {'loss': 0.8087, 'learning_rate': 2.9759038814434795e-06, 'epoch': 0.76}
 76%|███████▌  | 7853/10395 [22:27:03<15:28:41, 21.92s/it] 76%|███████▌  | 7854/10395 [22:27:11<12:32:29, 17.77s/it]                                                          {'loss': 0.7934, 'learning_rate': 2.9736865285988238e-06, 'epoch': 0.76}
 76%|███████▌  | 7854/10395 [22:27:11<12:32:29, 17.77s/it] 76%|███████▌  | 7855/10395 [22:27:20<10:30:41, 14.90s/it]                                                          {'loss': 0.8471, 'learning_rate': 2.9714698578536683e-06, 'epoch': 0.76}
 76%|███████▌  | 7855/10395 [22:27:20<10:30:41, 14.90s/it]WARNING: tokenization mismatch: 1 vs. 737. (ignored)
 76%|███████▌  | 7856/10395 [22:27:28<9:05:11, 12.88s/it]                                                          {'loss': 0.7854, 'learning_rate': 2.9692538694231988e-06, 'epoch': 0.76}
 76%|███████▌  | 7856/10395 [22:27:28<9:05:11, 12.88s/it] 76%|███████▌  | 7857/10395 [22:27:35<7:51:54, 11.16s/it]                                                         {'loss': 0.9297, 'learning_rate': 2.9670385635225363e-06, 'epoch': 0.76}
 76%|███████▌  | 7857/10395 [22:27:35<7:51:54, 11.16s/it] 76%|███████▌  | 7858/10395 [22:27:51<8:50:44, 12.55s/it]                                                         {'loss': 0.3867, 'learning_rate': 2.9648239403667432e-06, 'epoch': 0.76}
 76%|███████▌  | 7858/10395 [22:27:51<8:50:44, 12.55s/it] 76%|███████▌  | 7859/10395 [22:27:59<8:00:45, 11.37s/it]                                                         {'loss': 0.9456, 'learning_rate': 2.9626100001708047e-06, 'epoch': 0.76}
 76%|███████▌  | 7859/10395 [22:27:59<8:00:45, 11.37s/it] 76%|███████▌  | 7860/10395 [22:28:07<7:10:54, 10.20s/it]                                                         {'loss': 0.818, 'learning_rate': 2.9603967431496485e-06, 'epoch': 0.76}
 76%|███████▌  | 7860/10395 [22:28:07<7:10:54, 10.20s/it] 76%|███████▌  | 7861/10395 [22:28:15<6:43:57,  9.56s/it]                                                         {'loss': 0.8749, 'learning_rate': 2.9581841695181355e-06, 'epoch': 0.76}
 76%|███████▌  | 7861/10395 [22:28:15<6:43:57,  9.56s/it] 76%|███████▌  | 7862/10395 [22:28:22<6:15:20,  8.89s/it]                                                         {'loss': 0.8943, 'learning_rate': 2.9559722794910526e-06, 'epoch': 0.76}
 76%|███████▌  | 7862/10395 [22:28:22<6:15:20,  8.89s/it] 76%|███████▌  | 7863/10395 [22:28:31<6:07:08,  8.70s/it]                                                         {'loss': 0.8329, 'learning_rate': 2.9537610732831302e-06, 'epoch': 0.76}
 76%|███████▌  | 7863/10395 [22:28:31<6:07:08,  8.70s/it] 76%|███████▌  | 7864/10395 [22:28:39<6:00:06,  8.54s/it]                                                         {'loss': 0.8692, 'learning_rate': 2.9515505511090247e-06, 'epoch': 0.76}
 76%|███████▌  | 7864/10395 [22:28:39<6:00:06,  8.54s/it] 76%|███████▌  | 7865/10395 [22:28:46<5:46:33,  8.22s/it]                                                         {'loss': 0.8793, 'learning_rate': 2.9493407131833264e-06, 'epoch': 0.76}
 76%|███████▌  | 7865/10395 [22:28:46<5:46:33,  8.22s/it] 76%|███████▌  | 7866/10395 [22:28:54<5:46:11,  8.21s/it]                                                         {'loss': 0.8683, 'learning_rate': 2.9471315597205675e-06, 'epoch': 0.76}
 76%|███████▌  | 7866/10395 [22:28:54<5:46:11,  8.21s/it] 76%|███████▌  | 7867/10395 [22:29:02<5:38:50,  8.04s/it]                                                         {'loss': 0.9169, 'learning_rate': 2.9449230909352024e-06, 'epoch': 0.76}
 76%|███████▌  | 7867/10395 [22:29:02<5:38:50,  8.04s/it] 76%|███████▌  | 7868/10395 [22:29:11<5:49:00,  8.29s/it]                                                         {'loss': 0.8056, 'learning_rate': 2.9427153070416257e-06, 'epoch': 0.76}
 76%|███████▌  | 7868/10395 [22:29:11<5:49:00,  8.29s/it] 76%|███████▌  | 7869/10395 [22:29:21<6:08:19,  8.75s/it]                                                         {'loss': 0.8854, 'learning_rate': 2.9405082082541694e-06, 'epoch': 0.76}
 76%|███████▌  | 7869/10395 [22:29:21<6:08:19,  8.75s/it] 76%|███████▌  | 7870/10395 [22:29:28<5:55:44,  8.45s/it]                                                         {'loss': 0.8482, 'learning_rate': 2.938301794787086e-06, 'epoch': 0.76}
 76%|███████▌  | 7870/10395 [22:29:28<5:55:44,  8.45s/it] 76%|███████▌  | 7871/10395 [22:29:36<5:42:31,  8.14s/it]                                                         {'loss': 0.9238, 'learning_rate': 2.9360960668545767e-06, 'epoch': 0.76}
 76%|███████▌  | 7871/10395 [22:29:36<5:42:31,  8.14s/it] 76%|███████▌  | 7872/10395 [22:29:53<7:34:20, 10.80s/it]                                                         {'loss': 0.3584, 'learning_rate': 2.9338910246707663e-06, 'epoch': 0.76}
 76%|███████▌  | 7872/10395 [22:29:53<7:34:20, 10.80s/it] 76%|███████▌  | 7873/10395 [22:30:00<6:52:40,  9.82s/it]                                                         {'loss': 0.9028, 'learning_rate': 2.9316866684497115e-06, 'epoch': 0.76}
 76%|███████▌  | 7873/10395 [22:30:00<6:52:40,  9.82s/it] 76%|███████▌  | 7874/10395 [22:30:08<6:20:10,  9.05s/it]                                                         {'loss': 0.8993, 'learning_rate': 2.929482998405413e-06, 'epoch': 0.76}
 76%|███████▌  | 7874/10395 [22:30:08<6:20:10,  9.05s/it] 76%|███████▌  | 7875/10395 [22:30:16<6:05:16,  8.70s/it]                                                         {'loss': 0.843, 'learning_rate': 2.927280014751792e-06, 'epoch': 0.76}
 76%|███████▌  | 7875/10395 [22:30:16<6:05:16,  8.70s/it] 76%|███████▌  | 7876/10395 [22:30:23<5:52:43,  8.40s/it]                                                         {'loss': 0.8723, 'learning_rate': 2.9250777177027135e-06, 'epoch': 0.76}
 76%|███████▌  | 7876/10395 [22:30:23<5:52:43,  8.40s/it] 76%|███████▌  | 7877/10395 [22:30:31<5:44:49,  8.22s/it]                                                         {'loss': 0.8509, 'learning_rate': 2.922876107471974e-06, 'epoch': 0.76}
 76%|███████▌  | 7877/10395 [22:30:31<5:44:49,  8.22s/it] 76%|███████▌  | 7878/10395 [22:30:39<5:43:50,  8.20s/it]                                                         {'loss': 0.8522, 'learning_rate': 2.9206751842732973e-06, 'epoch': 0.76}
 76%|███████▌  | 7878/10395 [22:30:39<5:43:50,  8.20s/it] 76%|███████▌  | 7879/10395 [22:30:48<5:54:59,  8.47s/it]                                                         {'loss': 0.8203, 'learning_rate': 2.918474948320342e-06, 'epoch': 0.76}
 76%|███████▌  | 7879/10395 [22:30:48<5:54:59,  8.47s/it] 76%|███████▌  | 7880/10395 [22:30:57<5:59:16,  8.57s/it]                                                         {'loss': 0.8621, 'learning_rate': 2.916275399826709e-06, 'epoch': 0.76}
 76%|███████▌  | 7880/10395 [22:30:57<5:59:16,  8.57s/it] 76%|███████▌  | 7881/10395 [22:31:14<7:40:17, 10.99s/it]                                                         {'loss': 0.3441, 'learning_rate': 2.914076539005919e-06, 'epoch': 0.76}
 76%|███████▌  | 7881/10395 [22:31:14<7:40:17, 10.99s/it] 76%|███████▌  | 7882/10395 [22:31:21<6:59:57, 10.03s/it]                                                         {'loss': 0.8468, 'learning_rate': 2.911878366071439e-06, 'epoch': 0.76}
 76%|███████▌  | 7882/10395 [22:31:21<6:59:57, 10.03s/it] 76%|███████▌  | 7883/10395 [22:31:29<6:29:29,  9.30s/it]                                                         {'loss': 0.8558, 'learning_rate': 2.909680881236656e-06, 'epoch': 0.76}
 76%|███████▌  | 7883/10395 [22:31:29<6:29:29,  9.30s/it] 76%|███████▌  | 7884/10395 [22:31:38<6:19:45,  9.07s/it]                                                         {'loss': 0.7554, 'learning_rate': 2.907484084714902e-06, 'epoch': 0.76}
 76%|███████▌  | 7884/10395 [22:31:38<6:19:45,  9.07s/it] 76%|███████▌  | 7885/10395 [22:31:46<6:08:27,  8.81s/it]                                                         {'loss': 0.8742, 'learning_rate': 2.9052879767194397e-06, 'epoch': 0.76}
 76%|███████▌  | 7885/10395 [22:31:46<6:08:27,  8.81s/it] 76%|███████▌  | 7886/10395 [22:31:53<5:52:56,  8.44s/it]                                                         {'loss': 0.8084, 'learning_rate': 2.903092557463458e-06, 'epoch': 0.76}
 76%|███████▌  | 7886/10395 [22:31:53<5:52:56,  8.44s/it] 76%|███████▌  | 7887/10395 [22:32:01<5:42:39,  8.20s/it]                                                         {'loss': 0.8784, 'learning_rate': 2.9008978271600828e-06, 'epoch': 0.76}
 76%|███████▌  | 7887/10395 [22:32:01<5:42:39,  8.20s/it] 76%|███████▌  | 7888/10395 [22:32:09<5:36:42,  8.06s/it]                                                         {'loss': 0.8212, 'learning_rate': 2.8987037860223776e-06, 'epoch': 0.76}
 76%|███████▌  | 7888/10395 [22:32:09<5:36:42,  8.06s/it] 76%|███████▌  | 7889/10395 [22:32:17<5:32:45,  7.97s/it]                                                         {'loss': 0.8587, 'learning_rate': 2.896510434263331e-06, 'epoch': 0.76}
 76%|███████▌  | 7889/10395 [22:32:17<5:32:45,  7.97s/it] 76%|███████▌  | 7890/10395 [22:32:24<5:31:50,  7.95s/it]                                                         {'loss': 0.8763, 'learning_rate': 2.894317772095875e-06, 'epoch': 0.76}
 76%|███████▌  | 7890/10395 [22:32:24<5:31:50,  7.95s/it] 76%|███████▌  | 7891/10395 [22:32:33<5:34:34,  8.02s/it]                                                         {'loss': 0.8219, 'learning_rate': 2.89212579973286e-06, 'epoch': 0.76}
 76%|███████▌  | 7891/10395 [22:32:33<5:34:34,  8.02s/it] 76%|███████▌  | 7892/10395 [22:32:50<7:31:47, 10.83s/it]                                                         {'loss': 0.3262, 'learning_rate': 2.889934517387084e-06, 'epoch': 0.76}
 76%|███████▌  | 7892/10395 [22:32:50<7:31:47, 10.83s/it] 76%|███████▌  | 7893/10395 [22:32:58<6:59:11, 10.05s/it]                                                         {'loss': 0.8742, 'learning_rate': 2.887743925271277e-06, 'epoch': 0.76}
 76%|███████▌  | 7893/10395 [22:32:58<6:59:11, 10.05s/it] 76%|███████▌  | 7894/10395 [22:33:06<6:31:28,  9.39s/it]                                                         {'loss': 0.8497, 'learning_rate': 2.8855540235980838e-06, 'epoch': 0.76}
 76%|███████▌  | 7894/10395 [22:33:06<6:31:28,  9.39s/it] 76%|███████▌  | 7895/10395 [22:33:15<6:19:39,  9.11s/it]                                                         {'loss': 0.8345, 'learning_rate': 2.883364812580103e-06, 'epoch': 0.76}
 76%|███████▌  | 7895/10395 [22:33:15<6:19:39,  9.11s/it] 76%|███████▌  | 7896/10395 [22:33:23<6:13:30,  8.97s/it]                                                         {'loss': 0.8079, 'learning_rate': 2.8811762924298616e-06, 'epoch': 0.76}
 76%|███████▌  | 7896/10395 [22:33:23<6:13:30,  8.97s/it] 76%|███████▌  | 7897/10395 [22:33:31<6:00:31,  8.66s/it]                                                         {'loss': 0.8538, 'learning_rate': 2.8789884633598086e-06, 'epoch': 0.76}
 76%|███████▌  | 7897/10395 [22:33:31<6:00:31,  8.66s/it] 76%|███████▌  | 7898/10395 [22:33:39<5:45:54,  8.31s/it]                                                         {'loss': 0.8209, 'learning_rate': 2.8768013255823413e-06, 'epoch': 0.76}
 76%|███████▌  | 7898/10395 [22:33:39<5:45:54,  8.31s/it] 76%|███████▌  | 7899/10395 [22:33:46<5:38:33,  8.14s/it]                                                         {'loss': 0.8466, 'learning_rate': 2.874614879309775e-06, 'epoch': 0.76}
 76%|███████▌  | 7899/10395 [22:33:46<5:38:33,  8.14s/it] 76%|███████▌  | 7900/10395 [22:33:54<5:29:23,  7.92s/it]                                                         {'loss': 0.8743, 'learning_rate': 2.8724291247543735e-06, 'epoch': 0.76}
 76%|███████▌  | 7900/10395 [22:33:54<5:29:23,  7.92s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 76%|███████▌  | 7901/10395 [22:35:35<24:56:07, 35.99s/it]                                                          {'loss': 0.8965, 'learning_rate': 2.8702440621283213e-06, 'epoch': 0.76}
 76%|███████▌  | 7901/10395 [22:35:35<24:56:07, 35.99s/it] 76%|███████▌  | 7902/10395 [22:35:44<19:16:10, 27.83s/it]                                                          {'loss': 0.8314, 'learning_rate': 2.8680596916437354e-06, 'epoch': 0.76}
 76%|███████▌  | 7902/10395 [22:35:44<19:16:10, 27.83s/it] 76%|███████▌  | 7903/10395 [22:35:52<15:07:24, 21.85s/it]                                                          {'loss': 0.8567, 'learning_rate': 2.8658760135126727e-06, 'epoch': 0.76}
 76%|███████▌  | 7903/10395 [22:35:52<15:07:24, 21.85s/it] 76%|███████▌  | 7904/10395 [22:35:59<12:07:05, 17.51s/it]                                                          {'loss': 0.84, 'learning_rate': 2.863693027947125e-06, 'epoch': 0.76}
 76%|███████▌  | 7904/10395 [22:35:59<12:07:05, 17.51s/it] 76%|███████▌  | 7905/10395 [22:36:07<10:10:25, 14.71s/it]                                                          {'loss': 0.8224, 'learning_rate': 2.8615107351590056e-06, 'epoch': 0.76}
 76%|███████▌  | 7905/10395 [22:36:08<10:10:25, 14.71s/it] 76%|███████▌  | 7906/10395 [22:36:15<8:40:25, 12.55s/it]                                                          {'loss': 0.9707, 'learning_rate': 2.8593291353601705e-06, 'epoch': 0.76}
 76%|███████▌  | 7906/10395 [22:36:15<8:40:25, 12.55s/it] 76%|███████▌  | 7907/10395 [22:36:23<7:37:40, 11.04s/it]                                                         {'loss': 0.917, 'learning_rate': 2.857148228762401e-06, 'epoch': 0.76}
 76%|███████▌  | 7907/10395 [22:36:23<7:37:40, 11.04s/it] 76%|███████▌  | 7908/10395 [22:36:31<7:01:37, 10.17s/it]                                                         {'loss': 0.8925, 'learning_rate': 2.8549680155774206e-06, 'epoch': 0.76}
 76%|███████▌  | 7908/10395 [22:36:31<7:01:37, 10.17s/it] 76%|███████▌  | 7909/10395 [22:36:38<6:29:21,  9.40s/it]                                                         {'loss': 0.9519, 'learning_rate': 2.852788496016875e-06, 'epoch': 0.76}
 76%|███████▌  | 7909/10395 [22:36:38<6:29:21,  9.40s/it] 76%|███████▌  | 7910/10395 [22:36:46<6:02:51,  8.76s/it]                                                         {'loss': 0.8644, 'learning_rate': 2.850609670292347e-06, 'epoch': 0.76}
 76%|███████▌  | 7910/10395 [22:36:46<6:02:51,  8.76s/it] 76%|███████▌  | 7911/10395 [22:36:53<5:43:01,  8.29s/it]                                                         {'loss': 0.8494, 'learning_rate': 2.848431538615353e-06, 'epoch': 0.76}
 76%|███████▌  | 7911/10395 [22:36:53<5:43:01,  8.29s/it] 76%|███████▌  | 7912/10395 [22:37:00<5:34:59,  8.09s/it]                                                         {'loss': 0.8406, 'learning_rate': 2.8462541011973456e-06, 'epoch': 0.76}
 76%|███████▌  | 7912/10395 [22:37:00<5:34:59,  8.09s/it] 76%|███████▌  | 7913/10395 [22:37:08<5:28:03,  7.93s/it]                                                         {'loss': 0.8111, 'learning_rate': 2.8440773582496996e-06, 'epoch': 0.76}
 76%|███████▌  | 7913/10395 [22:37:08<5:28:03,  7.93s/it] 76%|███████▌  | 7914/10395 [22:37:16<5:27:30,  7.92s/it]                                                         {'loss': 0.759, 'learning_rate': 2.8419013099837333e-06, 'epoch': 0.76}
 76%|███████▌  | 7914/10395 [22:37:16<5:27:30,  7.92s/it] 76%|███████▌  | 7915/10395 [22:37:24<5:31:17,  8.02s/it]                                                         {'loss': 0.881, 'learning_rate': 2.8397259566106915e-06, 'epoch': 0.76}
 76%|███████▌  | 7915/10395 [22:37:24<5:31:17,  8.02s/it] 76%|███████▌  | 7916/10395 [22:37:31<5:23:12,  7.82s/it]                                                         {'loss': 0.8532, 'learning_rate': 2.8375512983417497e-06, 'epoch': 0.76}
 76%|███████▌  | 7916/10395 [22:37:31<5:23:12,  7.82s/it] 76%|███████▌  | 7917/10395 [22:37:40<5:29:09,  7.97s/it]                                                         {'loss': 0.8183, 'learning_rate': 2.835377335388024e-06, 'epoch': 0.76}
 76%|███████▌  | 7917/10395 [22:37:40<5:29:09,  7.97s/it] 76%|███████▌  | 7918/10395 [22:37:47<5:24:42,  7.87s/it]                                                         {'loss': 0.8879, 'learning_rate': 2.8332040679605543e-06, 'epoch': 0.76}
 76%|███████▌  | 7918/10395 [22:37:47<5:24:42,  7.87s/it] 76%|███████▌  | 7919/10395 [22:37:56<5:34:54,  8.12s/it]                                                         {'loss': 0.7987, 'learning_rate': 2.8310314962703166e-06, 'epoch': 0.76}
 76%|███████▌  | 7919/10395 [22:37:56<5:34:54,  8.12s/it] 76%|███████▌  | 7920/10395 [22:38:04<5:31:04,  8.03s/it]                                                         {'loss': 0.8012, 'learning_rate': 2.8288596205282248e-06, 'epoch': 0.76}
 76%|███████▌  | 7920/10395 [22:38:04<5:31:04,  8.03s/it] 76%|███████▌  | 7921/10395 [22:38:12<5:31:40,  8.04s/it]                                                         {'loss': 0.8658, 'learning_rate': 2.8266884409451134e-06, 'epoch': 0.76}
 76%|███████▌  | 7921/10395 [22:38:12<5:31:40,  8.04s/it] 76%|███████▌  | 7922/10395 [22:38:20<5:25:30,  7.90s/it]                                                         {'loss': 0.866, 'learning_rate': 2.8245179577317607e-06, 'epoch': 0.76}
 76%|███████▌  | 7922/10395 [22:38:20<5:25:30,  7.90s/it] 76%|███████▌  | 7923/10395 [22:38:29<5:39:14,  8.23s/it]                                                         {'loss': 0.8192, 'learning_rate': 2.822348171098872e-06, 'epoch': 0.76}
 76%|███████▌  | 7923/10395 [22:38:29<5:39:14,  8.23s/it] 76%|███████▌  | 7924/10395 [22:38:38<5:54:44,  8.61s/it]                                                         {'loss': 0.7945, 'learning_rate': 2.8201790812570795e-06, 'epoch': 0.76}
 76%|███████▌  | 7924/10395 [22:38:38<5:54:44,  8.61s/it] 76%|███████▌  | 7925/10395 [22:38:46<5:44:12,  8.36s/it]                                                         {'loss': 0.8722, 'learning_rate': 2.81801068841696e-06, 'epoch': 0.76}
 76%|███████▌  | 7925/10395 [22:38:46<5:44:12,  8.36s/it] 76%|███████▌  | 7926/10395 [22:38:54<5:37:31,  8.20s/it]                                                         {'loss': 0.8554, 'learning_rate': 2.8158429927890174e-06, 'epoch': 0.76}
 76%|███████▌  | 7926/10395 [22:38:54<5:37:31,  8.20s/it] 76%|███████▋  | 7927/10395 [22:39:01<5:27:56,  7.97s/it]                                                         {'loss': 0.9365, 'learning_rate': 2.8136759945836813e-06, 'epoch': 0.76}
 76%|███████▋  | 7927/10395 [22:39:01<5:27:56,  7.97s/it] 76%|███████▋  | 7928/10395 [22:39:10<5:36:46,  8.19s/it]                                                         {'loss': 0.8172, 'learning_rate': 2.811509694011325e-06, 'epoch': 0.76}
 76%|███████▋  | 7928/10395 [22:39:10<5:36:46,  8.19s/it] 76%|███████▋  | 7929/10395 [22:39:17<5:29:53,  8.03s/it]                                                         {'loss': 0.8632, 'learning_rate': 2.8093440912822436e-06, 'epoch': 0.76}
 76%|███████▋  | 7929/10395 [22:39:17<5:29:53,  8.03s/it] 76%|███████▋  | 7930/10395 [22:39:25<5:28:37,  8.00s/it]                                                         {'loss': 0.8462, 'learning_rate': 2.8071791866066743e-06, 'epoch': 0.76}
 76%|███████▋  | 7930/10395 [22:39:25<5:28:37,  8.00s/it] 76%|███████▋  | 7931/10395 [22:39:33<5:26:12,  7.94s/it]                                                         {'loss': 0.8903, 'learning_rate': 2.8050149801947777e-06, 'epoch': 0.76}
 76%|███████▋  | 7931/10395 [22:39:33<5:26:12,  7.94s/it] 76%|███████▋  | 7932/10395 [22:39:40<5:16:19,  7.71s/it]                                                         {'loss': 0.896, 'learning_rate': 2.8028514722566493e-06, 'epoch': 0.76}
 76%|███████▋  | 7932/10395 [22:39:40<5:16:19,  7.71s/it] 76%|███████▋  | 7933/10395 [22:39:48<5:10:30,  7.57s/it]                                                         {'loss': 0.8981, 'learning_rate': 2.8006886630023177e-06, 'epoch': 0.76}
 76%|███████▋  | 7933/10395 [22:39:48<5:10:30,  7.57s/it] 76%|███████▋  | 7934/10395 [22:39:56<5:21:21,  7.83s/it]                                                         {'loss': 0.8656, 'learning_rate': 2.7985265526417504e-06, 'epoch': 0.76}
 76%|███████▋  | 7934/10395 [22:39:56<5:21:21,  7.83s/it] 76%|███████▋  | 7935/10395 [22:40:04<5:17:23,  7.74s/it]                                                         {'loss': 0.9326, 'learning_rate': 2.7963651413848326e-06, 'epoch': 0.76}
 76%|███████▋  | 7935/10395 [22:40:04<5:17:23,  7.74s/it] 76%|███████▋  | 7936/10395 [22:40:11<5:19:49,  7.80s/it]                                                         {'loss': 0.8745, 'learning_rate': 2.794204429441395e-06, 'epoch': 0.76}
 76%|███████▋  | 7936/10395 [22:40:11<5:19:49,  7.80s/it] 76%|███████▋  | 7937/10395 [22:40:19<5:16:53,  7.74s/it]                                                         {'loss': 0.7701, 'learning_rate': 2.7920444170211925e-06, 'epoch': 0.76}
 76%|███████▋  | 7937/10395 [22:40:19<5:16:53,  7.74s/it] 76%|███████▋  | 7938/10395 [22:40:27<5:20:25,  7.82s/it]                                                         {'loss': 0.9841, 'learning_rate': 2.7898851043339126e-06, 'epoch': 0.76}
 76%|███████▋  | 7938/10395 [22:40:27<5:20:25,  7.82s/it] 76%|███████▋  | 7939/10395 [22:40:38<5:53:41,  8.64s/it]                                                         {'loss': 0.8219, 'learning_rate': 2.787726491589181e-06, 'epoch': 0.76}
 76%|███████▋  | 7939/10395 [22:40:38<5:53:41,  8.64s/it] 76%|███████▋  | 7940/10395 [22:40:45<5:39:41,  8.30s/it]                                                         {'loss': 0.83, 'learning_rate': 2.785568578996546e-06, 'epoch': 0.76}
 76%|███████▋  | 7940/10395 [22:40:45<5:39:41,  8.30s/it] 76%|███████▋  | 7941/10395 [22:40:52<5:25:38,  7.96s/it]                                                         {'loss': 0.8767, 'learning_rate': 2.783411366765495e-06, 'epoch': 0.76}
 76%|███████▋  | 7941/10395 [22:40:52<5:25:38,  7.96s/it] 76%|███████▋  | 7942/10395 [22:41:00<5:26:03,  7.98s/it]                                                         {'loss': 0.8272, 'learning_rate': 2.7812548551054507e-06, 'epoch': 0.76}
 76%|███████▋  | 7942/10395 [22:41:00<5:26:03,  7.98s/it] 76%|███████▋  | 7943/10395 [22:41:08<5:21:08,  7.86s/it]                                                         {'loss': 0.8878, 'learning_rate': 2.779099044225756e-06, 'epoch': 0.76}
 76%|███████▋  | 7943/10395 [22:41:08<5:21:08,  7.86s/it] 76%|███████▋  | 7944/10395 [22:41:16<5:19:11,  7.81s/it]                                                         {'loss': 0.8663, 'learning_rate': 2.7769439343356973e-06, 'epoch': 0.76}
 76%|███████▋  | 7944/10395 [22:41:16<5:19:11,  7.81s/it] 76%|███████▋  | 7945/10395 [22:41:23<5:14:32,  7.70s/it]                                                         {'loss': 0.843, 'learning_rate': 2.774789525644486e-06, 'epoch': 0.76}
 76%|███████▋  | 7945/10395 [22:41:23<5:14:32,  7.70s/it] 76%|███████▋  | 7946/10395 [22:41:31<5:19:10,  7.82s/it]                                                         {'loss': 0.9424, 'learning_rate': 2.7726358183612634e-06, 'epoch': 0.76}
 76%|███████▋  | 7946/10395 [22:41:31<5:19:10,  7.82s/it] 76%|███████▋  | 7947/10395 [22:41:40<5:26:30,  8.00s/it]                                                         {'loss': 0.8875, 'learning_rate': 2.7704828126951145e-06, 'epoch': 0.76}
 76%|███████▋  | 7947/10395 [22:41:40<5:26:30,  8.00s/it] 76%|███████▋  | 7948/10395 [22:41:47<5:18:21,  7.81s/it]                                                         {'loss': 0.9136, 'learning_rate': 2.7683305088550416e-06, 'epoch': 0.76}
 76%|███████▋  | 7948/10395 [22:41:47<5:18:21,  7.81s/it] 76%|███████▋  | 7949/10395 [22:41:55<5:17:29,  7.79s/it]                                                         {'loss': 0.9772, 'learning_rate': 2.766178907049989e-06, 'epoch': 0.76}
 76%|███████▋  | 7949/10395 [22:41:55<5:17:29,  7.79s/it] 76%|███████▋  | 7950/10395 [22:42:02<5:11:05,  7.63s/it]                                                         {'loss': 0.8262, 'learning_rate': 2.7640280074888314e-06, 'epoch': 0.76}
 76%|███████▋  | 7950/10395 [22:42:02<5:11:05,  7.63s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 76%|███████▋  | 7951/10395 [22:43:45<24:37:14, 36.27s/it]                                                          {'loss': 0.8639, 'learning_rate': 2.761877810380369e-06, 'epoch': 0.76}
 76%|███████▋  | 7951/10395 [22:43:45<24:37:14, 36.27s/it] 76%|███████▋  | 7952/10395 [22:44:02<20:40:34, 30.47s/it]                                                          {'loss': 0.3612, 'learning_rate': 2.7597283159333443e-06, 'epoch': 0.76}
 76%|███████▋  | 7952/10395 [22:44:02<20:40:34, 30.47s/it] 77%|███████▋  | 7953/10395 [22:44:10<16:02:42, 23.65s/it]                                                          {'loss': 0.9106, 'learning_rate': 2.7575795243564216e-06, 'epoch': 0.77}
 77%|███████▋  | 7953/10395 [22:44:10<16:02:42, 23.65s/it] 77%|███████▋  | 7954/10395 [22:44:17<12:45:26, 18.81s/it]                                                          {'loss': 0.9144, 'learning_rate': 2.755431435858199e-06, 'epoch': 0.77}
 77%|███████▋  | 7954/10395 [22:44:17<12:45:26, 18.81s/it] 77%|███████▋  | 7955/10395 [22:44:26<10:46:16, 15.89s/it]                                                          {'loss': 0.822, 'learning_rate': 2.7532840506472136e-06, 'epoch': 0.77}
 77%|███████▋  | 7955/10395 [22:44:26<10:46:16, 15.89s/it] 77%|███████▋  | 7956/10395 [22:44:35<9:16:20, 13.69s/it]                                                          {'loss': 0.833, 'learning_rate': 2.7511373689319233e-06, 'epoch': 0.77}
 77%|███████▋  | 7956/10395 [22:44:35<9:16:20, 13.69s/it] 77%|███████▋  | 7957/10395 [22:44:43<8:07:27, 12.00s/it]                                                         {'loss': 0.8616, 'learning_rate': 2.7489913909207254e-06, 'epoch': 0.77}
 77%|███████▋  | 7957/10395 [22:44:43<8:07:27, 12.00s/it] 77%|███████▋  | 7958/10395 [22:44:50<7:09:54, 10.58s/it]                                                         {'loss': 0.9295, 'learning_rate': 2.746846116821953e-06, 'epoch': 0.77}
 77%|███████▋  | 7958/10395 [22:44:50<7:09:54, 10.58s/it] 77%|███████▋  | 7959/10395 [22:44:59<6:43:31,  9.94s/it]                                                         {'loss': 0.8943, 'learning_rate': 2.7447015468438575e-06, 'epoch': 0.77}
 77%|███████▋  | 7959/10395 [22:44:59<6:43:31,  9.94s/it] 77%|███████▋  | 7960/10395 [22:45:06<6:13:33,  9.20s/it]                                                         {'loss': 0.8793, 'learning_rate': 2.74255768119463e-06, 'epoch': 0.77}
 77%|███████▋  | 7960/10395 [22:45:06<6:13:33,  9.20s/it] 77%|███████▋  | 7961/10395 [22:45:15<6:08:01,  9.07s/it]                                                         {'loss': 0.8193, 'learning_rate': 2.740414520082395e-06, 'epoch': 0.77}
 77%|███████▋  | 7961/10395 [22:45:15<6:08:01,  9.07s/it] 77%|███████▋  | 7962/10395 [22:45:23<5:51:17,  8.66s/it]                                                         {'loss': 0.9044, 'learning_rate': 2.7382720637152025e-06, 'epoch': 0.77}
 77%|███████▋  | 7962/10395 [22:45:23<5:51:17,  8.66s/it] 77%|███████▋  | 7963/10395 [22:45:39<7:26:40, 11.02s/it]                                                         {'loss': 0.4161, 'learning_rate': 2.736130312301042e-06, 'epoch': 0.77}
 77%|███████▋  | 7963/10395 [22:45:39<7:26:40, 11.02s/it] 77%|███████▋  | 7964/10395 [22:45:46<6:40:36,  9.89s/it]                                                         {'loss': 0.8505, 'learning_rate': 2.733989266047825e-06, 'epoch': 0.77}
 77%|███████▋  | 7964/10395 [22:45:46<6:40:36,  9.89s/it] 77%|███████▋  | 7965/10395 [22:45:54<6:08:54,  9.11s/it]                                                         {'loss': 0.9351, 'learning_rate': 2.731848925163403e-06, 'epoch': 0.77}
 77%|███████▋  | 7965/10395 [22:45:54<6:08:54,  9.11s/it] 77%|███████▋  | 7966/10395 [22:46:01<5:52:05,  8.70s/it]                                                         {'loss': 0.8403, 'learning_rate': 2.7297092898555588e-06, 'epoch': 0.77}
 77%|███████▋  | 7966/10395 [22:46:01<5:52:05,  8.70s/it] 77%|███████▋  | 7967/10395 [22:46:09<5:44:24,  8.51s/it]                                                         {'loss': 0.9056, 'learning_rate': 2.7275703603319992e-06, 'epoch': 0.77}
 77%|███████▋  | 7967/10395 [22:46:09<5:44:24,  8.51s/it] 77%|███████▋  | 7968/10395 [22:46:17<5:31:26,  8.19s/it]                                                         {'loss': 0.818, 'learning_rate': 2.7254321368003643e-06, 'epoch': 0.77}
 77%|███████▋  | 7968/10395 [22:46:17<5:31:26,  8.19s/it] 77%|███████▋  | 7969/10395 [22:46:24<5:23:44,  8.01s/it]                                                         {'loss': 0.826, 'learning_rate': 2.723294619468235e-06, 'epoch': 0.77}
 77%|███████▋  | 7969/10395 [22:46:24<5:23:44,  8.01s/it] 77%|███████▋  | 7970/10395 [22:46:32<5:17:00,  7.84s/it]                                                         {'loss': 0.8598, 'learning_rate': 2.7211578085431113e-06, 'epoch': 0.77}
 77%|███████▋  | 7970/10395 [22:46:32<5:17:00,  7.84s/it] 77%|███████▋  | 7971/10395 [22:46:39<5:11:04,  7.70s/it]                                                         {'loss': 0.7531, 'learning_rate': 2.719021704232436e-06, 'epoch': 0.77}
 77%|███████▋  | 7971/10395 [22:46:39<5:11:04,  7.70s/it] 77%|███████▋  | 7972/10395 [22:46:47<5:10:15,  7.68s/it]                                                         {'loss': 0.8685, 'learning_rate': 2.7168863067435703e-06, 'epoch': 0.77}
 77%|███████▋  | 7972/10395 [22:46:47<5:10:15,  7.68s/it] 77%|███████▋  | 7973/10395 [22:46:55<5:13:27,  7.77s/it]                                                         {'loss': 0.9142, 'learning_rate': 2.7147516162838184e-06, 'epoch': 0.77}
 77%|███████▋  | 7973/10395 [22:46:55<5:13:27,  7.77s/it] 77%|███████▋  | 7974/10395 [22:47:02<5:07:12,  7.61s/it]                                                         {'loss': 0.8377, 'learning_rate': 2.712617633060416e-06, 'epoch': 0.77}
 77%|███████▋  | 7974/10395 [22:47:02<5:07:12,  7.61s/it] 77%|███████▋  | 7975/10395 [22:47:10<5:07:58,  7.64s/it]                                                         {'loss': 0.8356, 'learning_rate': 2.710484357280515e-06, 'epoch': 0.77}
 77%|███████▋  | 7975/10395 [22:47:10<5:07:58,  7.64s/it] 77%|███████▋  | 7976/10395 [22:47:19<5:24:14,  8.04s/it]                                                         {'loss': 0.8139, 'learning_rate': 2.708351789151216e-06, 'epoch': 0.77}
 77%|███████▋  | 7976/10395 [22:47:19<5:24:14,  8.04s/it] 77%|███████▋  | 7977/10395 [22:47:27<5:23:21,  8.02s/it]                                                         {'loss': 0.7679, 'learning_rate': 2.7062199288795445e-06, 'epoch': 0.77}
 77%|███████▋  | 7977/10395 [22:47:27<5:23:21,  8.02s/it] 77%|███████▋  | 7978/10395 [22:47:34<5:14:15,  7.80s/it]                                                         {'loss': 0.8213, 'learning_rate': 2.704088776672453e-06, 'epoch': 0.77}
 77%|███████▋  | 7978/10395 [22:47:34<5:14:15,  7.80s/it] 77%|███████▋  | 7979/10395 [22:47:42<5:14:00,  7.80s/it]                                                         {'loss': 0.7785, 'learning_rate': 2.701958332736835e-06, 'epoch': 0.77}
 77%|███████▋  | 7979/10395 [22:47:42<5:14:00,  7.80s/it] 77%|███████▋  | 7980/10395 [22:47:50<5:12:53,  7.77s/it]                                                         {'loss': 0.884, 'learning_rate': 2.6998285972795025e-06, 'epoch': 0.77}
 77%|███████▋  | 7980/10395 [22:47:50<5:12:53,  7.77s/it] 77%|███████▋  | 7981/10395 [22:47:57<5:13:41,  7.80s/it]                                                         {'loss': 0.9106, 'learning_rate': 2.697699570507213e-06, 'epoch': 0.77}
 77%|███████▋  | 7981/10395 [22:47:57<5:13:41,  7.80s/it] 77%|███████▋  | 7982/10395 [22:48:07<5:31:51,  8.25s/it]                                                         {'loss': 0.8201, 'learning_rate': 2.695571252626643e-06, 'epoch': 0.77}
 77%|███████▋  | 7982/10395 [22:48:07<5:31:51,  8.25s/it] 77%|███████▋  | 7983/10395 [22:48:15<5:31:53,  8.26s/it]                                                         {'loss': 0.8728, 'learning_rate': 2.6934436438444045e-06, 'epoch': 0.77}
 77%|███████▋  | 7983/10395 [22:48:15<5:31:53,  8.26s/it] 77%|███████▋  | 7984/10395 [22:48:23<5:22:38,  8.03s/it]                                                         {'loss': 0.8572, 'learning_rate': 2.691316744367042e-06, 'epoch': 0.77}
 77%|███████▋  | 7984/10395 [22:48:23<5:22:38,  8.03s/it] 77%|███████▋  | 7985/10395 [22:48:30<5:19:50,  7.96s/it]                                                         {'loss': 0.8817, 'learning_rate': 2.6891905544010344e-06, 'epoch': 0.77}
 77%|███████▋  | 7985/10395 [22:48:30<5:19:50,  7.96s/it] 77%|███████▋  | 7986/10395 [22:48:38<5:19:45,  7.96s/it]                                                         {'loss': 0.7325, 'learning_rate': 2.6870650741527817e-06, 'epoch': 0.77}
 77%|███████▋  | 7986/10395 [22:48:38<5:19:45,  7.96s/it] 77%|███████▋  | 7987/10395 [22:48:46<5:14:43,  7.84s/it]                                                         {'loss': 0.9495, 'learning_rate': 2.684940303828627e-06, 'epoch': 0.77}
 77%|███████▋  | 7987/10395 [22:48:46<5:14:43,  7.84s/it] 77%|███████▋  | 7988/10395 [22:48:53<5:09:00,  7.70s/it]                                                         {'loss': 0.8531, 'learning_rate': 2.6828162436348314e-06, 'epoch': 0.77}
 77%|███████▋  | 7988/10395 [22:48:53<5:09:00,  7.70s/it] 77%|███████▋  | 7989/10395 [22:49:01<5:09:51,  7.73s/it]                                                         {'loss': 0.8669, 'learning_rate': 2.680692893777602e-06, 'epoch': 0.77}
 77%|███████▋  | 7989/10395 [22:49:01<5:09:51,  7.73s/it] 77%|███████▋  | 7990/10395 [22:49:11<5:33:29,  8.32s/it]                                                         {'loss': 0.9757, 'learning_rate': 2.6785702544630644e-06, 'epoch': 0.77}
 77%|███████▋  | 7990/10395 [22:49:11<5:33:29,  8.32s/it] 77%|███████▋  | 7991/10395 [22:49:19<5:29:09,  8.22s/it]                                                         {'loss': 0.8678, 'learning_rate': 2.6764483258972783e-06, 'epoch': 0.77}
 77%|███████▋  | 7991/10395 [22:49:19<5:29:09,  8.22s/it] 77%|███████▋  | 7992/10395 [22:49:36<7:22:29, 11.05s/it]                                                         {'loss': 0.3384, 'learning_rate': 2.6743271082862375e-06, 'epoch': 0.77}
 77%|███████▋  | 7992/10395 [22:49:36<7:22:29, 11.05s/it] 77%|███████▋  | 7993/10395 [22:49:44<6:37:20,  9.93s/it]                                                         {'loss': 0.9358, 'learning_rate': 2.6722066018358696e-06, 'epoch': 0.77}
 77%|███████▋  | 7993/10395 [22:49:44<6:37:20,  9.93s/it] 77%|███████▋  | 7994/10395 [22:49:53<6:26:56,  9.67s/it]                                                         {'loss': 0.9038, 'learning_rate': 2.6700868067520215e-06, 'epoch': 0.77}
 77%|███████▋  | 7994/10395 [22:49:53<6:26:56,  9.67s/it] 77%|███████▋  | 7995/10395 [22:50:00<5:55:13,  8.88s/it]                                                         {'loss': 0.9498, 'learning_rate': 2.667967723240482e-06, 'epoch': 0.77}
 77%|███████▋  | 7995/10395 [22:50:00<5:55:13,  8.88s/it] 77%|███████▋  | 7996/10395 [22:50:08<5:48:20,  8.71s/it]                                                         {'loss': 0.8995, 'learning_rate': 2.6658493515069737e-06, 'epoch': 0.77}
 77%|███████▋  | 7996/10395 [22:50:08<5:48:20,  8.71s/it] 77%|███████▋  | 7997/10395 [22:50:16<5:42:44,  8.58s/it]                                                         {'loss': 0.859, 'learning_rate': 2.663731691757132e-06, 'epoch': 0.77}
 77%|███████▋  | 7997/10395 [22:50:16<5:42:44,  8.58s/it] 77%|███████▋  | 7998/10395 [22:50:24<5:26:57,  8.18s/it]                                                         {'loss': 0.8509, 'learning_rate': 2.661614744196539e-06, 'epoch': 0.77}
 77%|███████▋  | 7998/10395 [22:50:24<5:26:57,  8.18s/it] 77%|███████▋  | 7999/10395 [22:50:31<5:19:17,  8.00s/it]                                                         {'loss': 0.8719, 'learning_rate': 2.659498509030708e-06, 'epoch': 0.77}
 77%|███████▋  | 7999/10395 [22:50:31<5:19:17,  8.00s/it] 77%|███████▋  | 8000/10395 [22:50:40<5:24:31,  8.13s/it]                                                         {'loss': 0.8115, 'learning_rate': 2.657382986465071e-06, 'epoch': 0.77}
 77%|███████▋  | 8000/10395 [22:50:40<5:24:31,  8.13s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 77%|███████▋  | 8001/10395 [22:52:22<24:09:58, 36.34s/it]                                                          {'loss': 0.8168, 'learning_rate': 2.655268176705007e-06, 'epoch': 0.77}
 77%|███████▋  | 8001/10395 [22:52:22<24:09:58, 36.34s/it] 77%|███████▋  | 8002/10395 [22:52:30<18:26:42, 27.75s/it]                                                          {'loss': 0.8756, 'learning_rate': 2.6531540799558087e-06, 'epoch': 0.77}
 77%|███████▋  | 8002/10395 [22:52:30<18:26:42, 27.75s/it] 77%|███████▋  | 8003/10395 [22:52:37<14:26:18, 21.73s/it]                                                          {'loss': 0.8883, 'learning_rate': 2.6510406964227155e-06, 'epoch': 0.77}
 77%|███████▋  | 8003/10395 [22:52:37<14:26:18, 21.73s/it] 77%|███████▋  | 8004/10395 [22:52:45<11:38:35, 17.53s/it]                                                          {'loss': 0.8118, 'learning_rate': 2.6489280263108865e-06, 'epoch': 0.77}
 77%|███████▋  | 8004/10395 [22:52:45<11:38:35, 17.53s/it] 77%|███████▋  | 8005/10395 [22:52:53<9:45:55, 14.71s/it]                                                          {'loss': 0.8228, 'learning_rate': 2.6468160698254132e-06, 'epoch': 0.77}
 77%|███████▋  | 8005/10395 [22:52:53<9:45:55, 14.71s/it] 77%|███████▋  | 8006/10395 [22:53:01<8:19:10, 12.54s/it]                                                         {'loss': 0.8955, 'learning_rate': 2.6447048271713206e-06, 'epoch': 0.77}
 77%|███████▋  | 8006/10395 [22:53:01<8:19:10, 12.54s/it] 77%|███████▋  | 8007/10395 [22:53:10<7:37:30, 11.50s/it]                                                         {'loss': 0.8351, 'learning_rate': 2.6425942985535693e-06, 'epoch': 0.77}
 77%|███████▋  | 8007/10395 [22:53:10<7:37:30, 11.50s/it] 77%|███████▋  | 8008/10395 [22:53:18<6:57:24, 10.49s/it]                                                         {'loss': 0.8544, 'learning_rate': 2.6404844841770362e-06, 'epoch': 0.77}
 77%|███████▋  | 8008/10395 [22:53:18<6:57:24, 10.49s/it] 77%|███████▋  | 8009/10395 [22:53:26<6:25:50,  9.70s/it]                                                         {'loss': 0.8715, 'learning_rate': 2.6383753842465464e-06, 'epoch': 0.77}
 77%|███████▋  | 8009/10395 [22:53:26<6:25:50,  9.70s/it] 77%|███████▋  | 8010/10395 [22:53:34<6:04:20,  9.17s/it]                                                         {'loss': 0.878, 'learning_rate': 2.636266998966839e-06, 'epoch': 0.77}
 77%|███████▋  | 8010/10395 [22:53:34<6:04:20,  9.17s/it] 77%|███████▋  | 8011/10395 [22:53:41<5:44:43,  8.68s/it]                                                         {'loss': 0.8937, 'learning_rate': 2.6341593285425983e-06, 'epoch': 0.77}
 77%|███████▋  | 8011/10395 [22:53:41<5:44:43,  8.68s/it] 77%|███████▋  | 8012/10395 [22:53:57<7:16:14, 10.98s/it]                                                         {'loss': 0.3515, 'learning_rate': 2.632052373178429e-06, 'epoch': 0.77}
 77%|███████▋  | 8012/10395 [22:53:57<7:16:14, 10.98s/it] 77%|███████▋  | 8013/10395 [22:54:06<6:43:29, 10.16s/it]                                                         {'loss': 0.8673, 'learning_rate': 2.6299461330788655e-06, 'epoch': 0.77}
 77%|███████▋  | 8013/10395 [22:54:06<6:43:29, 10.16s/it] 77%|███████▋  | 8014/10395 [22:54:14<6:17:25,  9.51s/it]                                                         {'loss': 0.8605, 'learning_rate': 2.6278406084483832e-06, 'epoch': 0.77}
 77%|███████▋  | 8014/10395 [22:54:14<6:17:25,  9.51s/it] 77%|███████▋  | 8015/10395 [22:54:22<5:59:50,  9.07s/it]                                                         {'loss': 0.8595, 'learning_rate': 2.6257357994913834e-06, 'epoch': 0.77}
 77%|███████▋  | 8015/10395 [22:54:22<5:59:50,  9.07s/it] 77%|███████▋  | 8016/10395 [22:54:30<5:46:16,  8.73s/it]                                                         {'loss': 0.8349, 'learning_rate': 2.6236317064121897e-06, 'epoch': 0.77}
 77%|███████▋  | 8016/10395 [22:54:30<5:46:16,  8.73s/it] 77%|███████▋  | 8017/10395 [22:54:37<5:31:47,  8.37s/it]                                                         {'loss': 0.8476, 'learning_rate': 2.6215283294150694e-06, 'epoch': 0.77}
 77%|███████▋  | 8017/10395 [22:54:37<5:31:47,  8.37s/it] 77%|███████▋  | 8018/10395 [22:54:44<5:17:25,  8.01s/it]                                                         {'loss': 0.9273, 'learning_rate': 2.619425668704212e-06, 'epoch': 0.77}
 77%|███████▋  | 8018/10395 [22:54:44<5:17:25,  8.01s/it] 77%|███████▋  | 8019/10395 [22:54:53<5:19:20,  8.06s/it]                                                         {'loss': 0.8053, 'learning_rate': 2.6173237244837346e-06, 'epoch': 0.77}
 77%|███████▋  | 8019/10395 [22:54:53<5:19:20,  8.06s/it] 77%|███████▋  | 8020/10395 [22:54:59<5:05:44,  7.72s/it]                                                         {'loss': 0.9401, 'learning_rate': 2.6152224969576955e-06, 'epoch': 0.77}
 77%|███████▋  | 8020/10395 [22:54:59<5:05:44,  7.72s/it] 77%|███████▋  | 8021/10395 [22:55:07<5:00:43,  7.60s/it]                                                         {'loss': 0.9312, 'learning_rate': 2.6131219863300726e-06, 'epoch': 0.77}
 77%|███████▋  | 8021/10395 [22:55:07<5:00:43,  7.60s/it] 77%|███████▋  | 8022/10395 [22:55:15<5:03:52,  7.68s/it]                                                         {'loss': 0.8816, 'learning_rate': 2.6110221928047818e-06, 'epoch': 0.77}
 77%|███████▋  | 8022/10395 [22:55:15<5:03:52,  7.68s/it] 77%|███████▋  | 8023/10395 [22:55:23<5:10:19,  7.85s/it]                                                         {'loss': 0.9108, 'learning_rate': 2.60892311658567e-06, 'epoch': 0.77}
 77%|███████▋  | 8023/10395 [22:55:23<5:10:19,  7.85s/it] 77%|███████▋  | 8024/10395 [22:55:31<5:15:34,  7.99s/it]                                                         {'loss': 0.8614, 'learning_rate': 2.6068247578765026e-06, 'epoch': 0.77}
 77%|███████▋  | 8024/10395 [22:55:31<5:15:34,  7.99s/it] 77%|███████▋  | 8025/10395 [22:55:39<5:11:30,  7.89s/it]                                                         {'loss': 0.9189, 'learning_rate': 2.604727116880993e-06, 'epoch': 0.77}
 77%|███████▋  | 8025/10395 [22:55:39<5:11:30,  7.89s/it] 77%|███████▋  | 8026/10395 [22:55:47<5:09:39,  7.84s/it]                                                         {'loss': 0.8922, 'learning_rate': 2.60263019380277e-06, 'epoch': 0.77}
 77%|███████▋  | 8026/10395 [22:55:47<5:09:39,  7.84s/it] 77%|███████▋  | 8027/10395 [22:55:54<5:06:02,  7.75s/it]                                                         {'loss': 0.7677, 'learning_rate': 2.6005339888453973e-06, 'epoch': 0.77}
 77%|███████▋  | 8027/10395 [22:55:54<5:06:02,  7.75s/it] 77%|███████▋  | 8028/10395 [22:56:02<5:12:32,  7.92s/it]                                                         {'loss': 0.877, 'learning_rate': 2.598438502212375e-06, 'epoch': 0.77}
 77%|███████▋  | 8028/10395 [22:56:02<5:12:32,  7.92s/it] 77%|███████▋  | 8029/10395 [22:56:10<5:05:45,  7.75s/it]                                                         {'loss': 0.9279, 'learning_rate': 2.5963437341071218e-06, 'epoch': 0.77}
 77%|███████▋  | 8029/10395 [22:56:10<5:05:45,  7.75s/it] 77%|███████▋  | 8030/10395 [22:56:17<4:59:58,  7.61s/it]                                                         {'loss': 0.8697, 'learning_rate': 2.594249684732998e-06, 'epoch': 0.77}
 77%|███████▋  | 8030/10395 [22:56:17<4:59:58,  7.61s/it] 77%|███████▋  | 8031/10395 [22:56:25<5:06:31,  7.78s/it]                                                         {'loss': 0.9133, 'learning_rate': 2.5921563542932913e-06, 'epoch': 0.77}
 77%|███████▋  | 8031/10395 [22:56:25<5:06:31,  7.78s/it] 77%|███████▋  | 8032/10395 [22:56:33<5:07:06,  7.80s/it]                                                         {'loss': 0.8356, 'learning_rate': 2.5900637429912136e-06, 'epoch': 0.77}
 77%|███████▋  | 8032/10395 [22:56:33<5:07:06,  7.80s/it] 77%|███████▋  | 8033/10395 [22:56:43<5:34:01,  8.49s/it]                                                         {'loss': 0.8788, 'learning_rate': 2.5879718510299135e-06, 'epoch': 0.77}
 77%|███████▋  | 8033/10395 [22:56:43<5:34:01,  8.49s/it] 77%|███████▋  | 8034/10395 [22:56:51<5:22:39,  8.20s/it]                                                         {'loss': 0.8641, 'learning_rate': 2.585880678612468e-06, 'epoch': 0.77}
 77%|███████▋  | 8034/10395 [22:56:51<5:22:39,  8.20s/it] 77%|███████▋  | 8035/10395 [22:56:58<5:11:02,  7.91s/it]                                                         {'loss': 0.9199, 'learning_rate': 2.583790225941879e-06, 'epoch': 0.77}
 77%|███████▋  | 8035/10395 [22:56:58<5:11:02,  7.91s/it] 77%|███████▋  | 8036/10395 [22:57:06<5:12:18,  7.94s/it]                                                         {'loss': 0.8321, 'learning_rate': 2.581700493221089e-06, 'epoch': 0.77}
 77%|███████▋  | 8036/10395 [22:57:06<5:12:18,  7.94s/it] 77%|███████▋  | 8037/10395 [22:57:16<5:38:21,  8.61s/it]                                                         {'loss': 0.7961, 'learning_rate': 2.5796114806529595e-06, 'epoch': 0.77}
 77%|███████▋  | 8037/10395 [22:57:16<5:38:21,  8.61s/it] 77%|███████▋  | 8038/10395 [22:57:33<7:13:06, 11.03s/it]                                                         {'loss': 0.3826, 'learning_rate': 2.5775231884402896e-06, 'epoch': 0.77}
 77%|███████▋  | 8038/10395 [22:57:33<7:13:06, 11.03s/it] 77%|███████▋  | 8039/10395 [22:57:41<6:40:00, 10.19s/it]                                                         {'loss': 0.8526, 'learning_rate': 2.57543561678581e-06, 'epoch': 0.77}
 77%|███████▋  | 8039/10395 [22:57:41<6:40:00, 10.19s/it] 77%|███████▋  | 8040/10395 [22:57:48<6:05:45,  9.32s/it]                                                         {'loss': 0.9014, 'learning_rate': 2.573348765892174e-06, 'epoch': 0.77}
 77%|███████▋  | 8040/10395 [22:57:48<6:05:45,  9.32s/it] 77%|███████▋  | 8041/10395 [22:57:57<5:54:49,  9.04s/it]                                                         {'loss': 0.9111, 'learning_rate': 2.5712626359619664e-06, 'epoch': 0.77}
 77%|███████▋  | 8041/10395 [22:57:57<5:54:49,  9.04s/it] 77%|███████▋  | 8042/10395 [22:58:04<5:34:28,  8.53s/it]                                                         {'loss': 0.8703, 'learning_rate': 2.56917722719771e-06, 'epoch': 0.77}
 77%|███████▋  | 8042/10395 [22:58:04<5:34:28,  8.53s/it] 77%|███████▋  | 8043/10395 [22:58:12<5:22:39,  8.23s/it]                                                         {'loss': 0.8911, 'learning_rate': 2.5670925398018455e-06, 'epoch': 0.77}
 77%|███████▋  | 8043/10395 [22:58:12<5:22:39,  8.23s/it] 77%|███████▋  | 8044/10395 [22:58:20<5:28:02,  8.37s/it]                                                         {'loss': 0.8529, 'learning_rate': 2.565008573976755e-06, 'epoch': 0.77}
 77%|███████▋  | 8044/10395 [22:58:20<5:28:02,  8.37s/it] 77%|███████▋  | 8045/10395 [22:58:29<5:30:02,  8.43s/it]                                                         {'loss': 0.8096, 'learning_rate': 2.5629253299247414e-06, 'epoch': 0.77}
 77%|███████▋  | 8045/10395 [22:58:29<5:30:02,  8.43s/it] 77%|███████▋  | 8046/10395 [22:58:38<5:33:01,  8.51s/it]                                                         {'loss': 0.8509, 'learning_rate': 2.560842807848044e-06, 'epoch': 0.77}
 77%|███████▋  | 8046/10395 [22:58:38<5:33:01,  8.51s/it] 77%|███████▋  | 8047/10395 [22:58:45<5:24:11,  8.28s/it]                                                         {'loss': 0.8425, 'learning_rate': 2.558761007948836e-06, 'epoch': 0.77}
 77%|███████▋  | 8047/10395 [22:58:45<5:24:11,  8.28s/it] 77%|███████▋  | 8048/10395 [22:58:53<5:14:14,  8.03s/it]                                                         {'loss': 0.8105, 'learning_rate': 2.5566799304292e-06, 'epoch': 0.77}
 77%|███████▋  | 8048/10395 [22:58:53<5:14:14,  8.03s/it] 77%|███████▋  | 8049/10395 [22:59:00<5:09:02,  7.90s/it]                                                         {'loss': 0.9247, 'learning_rate': 2.55459957549117e-06, 'epoch': 0.77}
 77%|███████▋  | 8049/10395 [22:59:00<5:09:02,  7.90s/it] 77%|███████▋  | 8050/10395 [22:59:08<5:11:10,  7.96s/it]                                                         {'loss': 0.8491, 'learning_rate': 2.5525199433367055e-06, 'epoch': 0.77}
 77%|███████▋  | 8050/10395 [22:59:08<5:11:10,  7.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 77%|███████▋  | 8051/10395 [23:00:51<23:36:05, 36.25s/it]                                                          {'loss': 0.8809, 'learning_rate': 2.5504410341676864e-06, 'epoch': 0.77}
 77%|███████▋  | 8051/10395 [23:00:51<23:36:05, 36.25s/it] 77%|███████▋  | 8052/10395 [23:00:59<18:04:16, 27.77s/it]                                                          {'loss': 0.89, 'learning_rate': 2.5483628481859355e-06, 'epoch': 0.77}
 77%|███████▋  | 8052/10395 [23:00:59<18:04:16, 27.77s/it] 77%|███████▋  | 8053/10395 [23:01:07<14:17:09, 21.96s/it]                                                          {'loss': 0.875, 'learning_rate': 2.5462853855931923e-06, 'epoch': 0.77}
 77%|███████▋  | 8053/10395 [23:01:07<14:17:09, 21.96s/it] 77%|███████▋  | 8054/10395 [23:01:15<11:32:50, 17.76s/it]                                                          {'loss': 0.8455, 'learning_rate': 2.544208646591134e-06, 'epoch': 0.77}
 77%|███████▋  | 8054/10395 [23:01:15<11:32:50, 17.76s/it] 77%|███████▋  | 8055/10395 [23:01:22<9:29:50, 14.61s/it]                                                          {'loss': 0.9216, 'learning_rate': 2.5421326313813745e-06, 'epoch': 0.77}
 77%|███████▋  | 8055/10395 [23:01:22<9:29:50, 14.61s/it] 77%|███████▋  | 8056/10395 [23:01:30<8:10:34, 12.58s/it]                                                         {'loss': 0.8728, 'learning_rate': 2.5400573401654347e-06, 'epoch': 0.77}
 77%|███████▋  | 8056/10395 [23:01:30<8:10:34, 12.58s/it] 78%|███████▊  | 8057/10395 [23:01:38<7:09:09, 11.01s/it]                                                         {'loss': 0.8285, 'learning_rate': 2.537982773144787e-06, 'epoch': 0.78}
 78%|███████▊  | 8057/10395 [23:01:38<7:09:09, 11.01s/it] 78%|███████▊  | 8058/10395 [23:01:45<6:27:25,  9.95s/it]                                                         {'loss': 0.8651, 'learning_rate': 2.5359089305208284e-06, 'epoch': 0.78}
 78%|███████▊  | 8058/10395 [23:01:45<6:27:25,  9.95s/it] 78%|███████▊  | 8059/10395 [23:01:53<6:04:11,  9.35s/it]                                                         {'loss': 0.9035, 'learning_rate': 2.533835812494877e-06, 'epoch': 0.78}
 78%|███████▊  | 8059/10395 [23:01:53<6:04:11,  9.35s/it] 78%|███████▊  | 8060/10395 [23:02:10<7:36:45, 11.74s/it]                                                         {'loss': 0.3432, 'learning_rate': 2.531763419268192e-06, 'epoch': 0.78}
 78%|███████▊  | 8060/10395 [23:02:10<7:36:45, 11.74s/it] 78%|███████▊  | 8061/10395 [23:02:18<6:44:51, 10.41s/it]                                                         {'loss': 0.8669, 'learning_rate': 2.5296917510419518e-06, 'epoch': 0.78}
 78%|███████▊  | 8061/10395 [23:02:18<6:44:51, 10.41s/it] 78%|███████▊  | 8062/10395 [23:02:25<6:13:25,  9.60s/it]                                                         {'loss': 0.8477, 'learning_rate': 2.527620808017276e-06, 'epoch': 0.78}
 78%|███████▊  | 8062/10395 [23:02:25<6:13:25,  9.60s/it] 78%|███████▊  | 8063/10395 [23:02:34<6:00:00,  9.26s/it]                                                         {'loss': 0.8361, 'learning_rate': 2.5255505903951995e-06, 'epoch': 0.78}
 78%|███████▊  | 8063/10395 [23:02:34<6:00:00,  9.26s/it] 78%|███████▊  | 8064/10395 [23:02:41<5:39:11,  8.73s/it]                                                         {'loss': 0.9213, 'learning_rate': 2.523481098376702e-06, 'epoch': 0.78}
 78%|███████▊  | 8064/10395 [23:02:41<5:39:11,  8.73s/it] 78%|███████▊  | 8065/10395 [23:02:48<5:21:54,  8.29s/it]                                                         {'loss': 0.8116, 'learning_rate': 2.5214123321626794e-06, 'epoch': 0.78}
 78%|███████▊  | 8065/10395 [23:02:48<5:21:54,  8.29s/it] 78%|███████▊  | 8066/10395 [23:02:56<5:14:52,  8.11s/it]                                                         {'loss': 0.7816, 'learning_rate': 2.519344291953969e-06, 'epoch': 0.78}
 78%|███████▊  | 8066/10395 [23:02:56<5:14:52,  8.11s/it] 78%|███████▊  | 8067/10395 [23:03:04<5:07:25,  7.92s/it]                                                         {'loss': 0.9322, 'learning_rate': 2.517276977951325e-06, 'epoch': 0.78}
 78%|███████▊  | 8067/10395 [23:03:04<5:07:25,  7.92s/it] 78%|███████▊  | 8068/10395 [23:03:14<5:34:15,  8.62s/it]                                                         {'loss': 0.8444, 'learning_rate': 2.5152103903554424e-06, 'epoch': 0.78}
 78%|███████▊  | 8068/10395 [23:03:14<5:34:15,  8.62s/it] 78%|███████▊  | 8069/10395 [23:03:21<5:20:11,  8.26s/it]                                                         {'loss': 0.8443, 'learning_rate': 2.513144529366942e-06, 'epoch': 0.78}
 78%|███████▊  | 8069/10395 [23:03:21<5:20:11,  8.26s/it] 78%|███████▊  | 8070/10395 [23:03:29<5:16:59,  8.18s/it]                                                         {'loss': 0.8364, 'learning_rate': 2.511079395186372e-06, 'epoch': 0.78}
 78%|███████▊  | 8070/10395 [23:03:29<5:16:59,  8.18s/it] 78%|███████▊  | 8071/10395 [23:03:37<5:12:15,  8.06s/it]                                                         {'loss': 0.7797, 'learning_rate': 2.5090149880142066e-06, 'epoch': 0.78}
 78%|███████▊  | 8071/10395 [23:03:37<5:12:15,  8.06s/it] 78%|███████▊  | 8072/10395 [23:03:45<5:09:32,  7.99s/it]                                                         {'loss': 0.9045, 'learning_rate': 2.5069513080508612e-06, 'epoch': 0.78}
 78%|███████▊  | 8072/10395 [23:03:45<5:09:32,  7.99s/it] 78%|███████▊  | 8073/10395 [23:04:03<7:06:49, 11.03s/it]                                                         {'loss': 0.3266, 'learning_rate': 2.5048883554966672e-06, 'epoch': 0.78}
 78%|███████▊  | 8073/10395 [23:04:03<7:06:49, 11.03s/it] 78%|███████▊  | 8074/10395 [23:04:10<6:23:03,  9.90s/it]                                                         {'loss': 0.9106, 'learning_rate': 2.5028261305518976e-06, 'epoch': 0.78}
 78%|███████▊  | 8074/10395 [23:04:10<6:23:03,  9.90s/it] 78%|███████▊  | 8075/10395 [23:04:18<5:58:22,  9.27s/it]                                                         {'loss': 0.9538, 'learning_rate': 2.5007646334167425e-06, 'epoch': 0.78}
 78%|███████▊  | 8075/10395 [23:04:18<5:58:22,  9.27s/it] 78%|███████▊  | 8076/10395 [23:04:26<5:40:37,  8.81s/it]                                                         {'loss': 0.8707, 'learning_rate': 2.498703864291331e-06, 'epoch': 0.78}
 78%|███████▊  | 8076/10395 [23:04:26<5:40:37,  8.81s/it] 78%|███████▊  | 8077/10395 [23:04:33<5:24:23,  8.40s/it]                                                         {'loss': 0.8753, 'learning_rate': 2.496643823375724e-06, 'epoch': 0.78}
 78%|███████▊  | 8077/10395 [23:04:33<5:24:23,  8.40s/it] 78%|███████▊  | 8078/10395 [23:04:42<5:23:47,  8.38s/it]                                                         {'loss': 0.8272, 'learning_rate': 2.494584510869894e-06, 'epoch': 0.78}
 78%|███████▊  | 8078/10395 [23:04:42<5:23:47,  8.38s/it] 78%|███████▊  | 8079/10395 [23:04:50<5:26:41,  8.46s/it]                                                         {'loss': 0.8067, 'learning_rate': 2.492525926973761e-06, 'epoch': 0.78}
 78%|███████▊  | 8079/10395 [23:04:50<5:26:41,  8.46s/it] 78%|███████▊  | 8080/10395 [23:04:58<5:18:31,  8.26s/it]                                                         {'loss': 0.9307, 'learning_rate': 2.49046807188717e-06, 'epoch': 0.78}
 78%|███████▊  | 8080/10395 [23:04:58<5:18:31,  8.26s/it] 78%|███████▊  | 8081/10395 [23:05:05<5:08:28,  8.00s/it]                                                         {'loss': 0.9112, 'learning_rate': 2.488410945809887e-06, 'epoch': 0.78}
 78%|███████▊  | 8081/10395 [23:05:05<5:08:28,  8.00s/it] 78%|███████▊  | 8082/10395 [23:05:13<4:58:53,  7.75s/it]                                                         {'loss': 0.8672, 'learning_rate': 2.4863545489416206e-06, 'epoch': 0.78}
 78%|███████▊  | 8082/10395 [23:05:13<4:58:53,  7.75s/it] 78%|███████▊  | 8083/10395 [23:05:21<5:07:42,  7.99s/it]                                                         {'loss': 0.8226, 'learning_rate': 2.4842988814819958e-06, 'epoch': 0.78}
 78%|███████▊  | 8083/10395 [23:05:21<5:07:42,  7.99s/it] 78%|███████▊  | 8084/10395 [23:05:38<6:45:51, 10.54s/it]                                                         {'loss': 0.3915, 'learning_rate': 2.4822439436305766e-06, 'epoch': 0.78}
 78%|███████▊  | 8084/10395 [23:05:38<6:45:51, 10.54s/it] 78%|███████▊  | 8085/10395 [23:05:45<6:13:53,  9.71s/it]                                                         {'loss': 0.9002, 'learning_rate': 2.48018973558685e-06, 'epoch': 0.78}
 78%|███████▊  | 8085/10395 [23:05:45<6:13:53,  9.71s/it] 78%|███████▊  | 8086/10395 [23:05:53<5:50:56,  9.12s/it]                                                         {'loss': 0.7506, 'learning_rate': 2.478136257550231e-06, 'epoch': 0.78}
 78%|███████▊  | 8086/10395 [23:05:53<5:50:56,  9.12s/it] 78%|███████▊  | 8087/10395 [23:06:01<5:32:40,  8.65s/it]                                                         {'loss': 0.8458, 'learning_rate': 2.4760835097200696e-06, 'epoch': 0.78}
 78%|███████▊  | 8087/10395 [23:06:01<5:32:40,  8.65s/it] 78%|███████▊  | 8088/10395 [23:06:08<5:20:50,  8.34s/it]                                                         {'loss': 0.8886, 'learning_rate': 2.4740314922956452e-06, 'epoch': 0.78}
 78%|███████▊  | 8088/10395 [23:06:08<5:20:50,  8.34s/it] 78%|███████▊  | 8089/10395 [23:06:16<5:12:32,  8.13s/it]                                                         {'loss': 0.885, 'learning_rate': 2.4719802054761578e-06, 'epoch': 0.78}
 78%|███████▊  | 8089/10395 [23:06:16<5:12:32,  8.13s/it] 78%|███████▊  | 8090/10395 [23:06:26<5:36:03,  8.75s/it]                                                         {'loss': 0.7635, 'learning_rate': 2.4699296494607484e-06, 'epoch': 0.78}
 78%|███████▊  | 8090/10395 [23:06:26<5:36:03,  8.75s/it] 78%|███████▊  | 8091/10395 [23:06:34<5:24:53,  8.46s/it]                                                         {'loss': 0.8693, 'learning_rate': 2.4678798244484724e-06, 'epoch': 0.78}
 78%|███████▊  | 8091/10395 [23:06:34<5:24:53,  8.46s/it] 78%|███████▊  | 8092/10395 [23:06:42<5:19:12,  8.32s/it]                                                         {'loss': 0.8722, 'learning_rate': 2.4658307306383313e-06, 'epoch': 0.78}
 78%|███████▊  | 8092/10395 [23:06:42<5:19:12,  8.32s/it] 78%|███████▊  | 8093/10395 [23:06:50<5:12:40,  8.15s/it]                                                         {'loss': 0.9052, 'learning_rate': 2.4637823682292406e-06, 'epoch': 0.78}
 78%|███████▊  | 8093/10395 [23:06:50<5:12:40,  8.15s/it] 78%|███████▊  | 8094/10395 [23:06:57<5:01:13,  7.85s/it]                                                         {'loss': 0.7705, 'learning_rate': 2.4617347374200506e-06, 'epoch': 0.78}
 78%|███████▊  | 8094/10395 [23:06:57<5:01:13,  7.85s/it] 78%|███████▊  | 8095/10395 [23:07:05<5:02:10,  7.88s/it]                                                         {'loss': 0.871, 'learning_rate': 2.4596878384095435e-06, 'epoch': 0.78}
 78%|███████▊  | 8095/10395 [23:07:05<5:02:10,  7.88s/it] 78%|███████▊  | 8096/10395 [23:07:13<5:03:25,  7.92s/it]                                                         {'loss': 0.8226, 'learning_rate': 2.4576416713964293e-06, 'epoch': 0.78}
 78%|███████▊  | 8096/10395 [23:07:13<5:03:25,  7.92s/it] 78%|███████▊  | 8097/10395 [23:07:24<5:38:51,  8.85s/it]                                                         {'loss': 0.9154, 'learning_rate': 2.455596236579342e-06, 'epoch': 0.78}
 78%|███████▊  | 8097/10395 [23:07:24<5:38:51,  8.85s/it] 78%|███████▊  | 8098/10395 [23:07:41<7:19:20, 11.48s/it]                                                         {'loss': 0.3281, 'learning_rate': 2.4535515341568504e-06, 'epoch': 0.78}
 78%|███████▊  | 8098/10395 [23:07:41<7:19:20, 11.48s/it] 78%|███████▊  | 8099/10395 [23:07:51<6:56:32, 10.89s/it]                                                         {'loss': 0.7649, 'learning_rate': 2.451507564327451e-06, 'epoch': 0.78}
 78%|███████▊  | 8099/10395 [23:07:51<6:56:32, 10.89s/it] 78%|███████▊  | 8100/10395 [23:07:58<6:13:46,  9.77s/it]                                                         {'loss': 0.8458, 'learning_rate': 2.4494643272895623e-06, 'epoch': 0.78}
 78%|███████▊  | 8100/10395 [23:07:58<6:13:46,  9.77s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 8101/10395 [23:09:38<23:25:02, 36.75s/it]                                                          {'loss': 0.9164, 'learning_rate': 2.4474218232415434e-06, 'epoch': 0.78}
 78%|███████▊  | 8101/10395 [23:09:38<23:25:02, 36.75s/it] 78%|███████▊  | 8102/10395 [23:09:45<17:46:46, 27.91s/it]                                                          {'loss': 0.9247, 'learning_rate': 2.445380052381673e-06, 'epoch': 0.78}
 78%|███████▊  | 8102/10395 [23:09:45<17:46:46, 27.91s/it] 78%|███████▊  | 8103/10395 [23:09:53<13:55:20, 21.87s/it]                                                          {'loss': 0.8677, 'learning_rate': 2.4433390149081614e-06, 'epoch': 0.78}
 78%|███████▊  | 8103/10395 [23:09:53<13:55:20, 21.87s/it] 78%|███████▊  | 8104/10395 [23:10:00<11:08:34, 17.51s/it]                                                          {'loss': 0.8152, 'learning_rate': 2.441298711019152e-06, 'epoch': 0.78}
 78%|███████▊  | 8104/10395 [23:10:00<11:08:34, 17.51s/it] 78%|███████▊  | 8105/10395 [23:10:08<9:12:46, 14.48s/it]                                                          {'loss': 0.8537, 'learning_rate': 2.4392591409127086e-06, 'epoch': 0.78}
 78%|███████▊  | 8105/10395 [23:10:08<9:12:46, 14.48s/it] 78%|███████▊  | 8106/10395 [23:10:16<8:02:23, 12.64s/it]                                                         {'loss': 0.8499, 'learning_rate': 2.4372203047868336e-06, 'epoch': 0.78}
 78%|███████▊  | 8106/10395 [23:10:16<8:02:23, 12.64s/it] 78%|███████▊  | 8107/10395 [23:10:24<7:08:28, 11.24s/it]                                                         {'loss': 0.8902, 'learning_rate': 2.43518220283945e-06, 'epoch': 0.78}
 78%|███████▊  | 8107/10395 [23:10:24<7:08:28, 11.24s/it] 78%|███████▊  | 8108/10395 [23:10:32<6:31:27, 10.27s/it]                                                         {'loss': 0.8748, 'learning_rate': 2.4331448352684084e-06, 'epoch': 0.78}
 78%|███████▊  | 8108/10395 [23:10:32<6:31:27, 10.27s/it] 78%|███████▊  | 8109/10395 [23:10:40<6:04:50,  9.58s/it]                                                         {'loss': 0.8042, 'learning_rate': 2.4311082022714993e-06, 'epoch': 0.78}
 78%|███████▊  | 8109/10395 [23:10:40<6:04:50,  9.58s/it] 78%|███████▊  | 8110/10395 [23:10:48<5:48:12,  9.14s/it]                                                         {'loss': 0.7741, 'learning_rate': 2.4290723040464272e-06, 'epoch': 0.78}
 78%|███████▊  | 8110/10395 [23:10:48<5:48:12,  9.14s/it] 78%|███████▊  | 8111/10395 [23:10:56<5:34:43,  8.79s/it]                                                         {'loss': 0.8344, 'learning_rate': 2.4270371407908377e-06, 'epoch': 0.78}
 78%|███████▊  | 8111/10395 [23:10:56<5:34:43,  8.79s/it] 78%|███████▊  | 8112/10395 [23:11:04<5:19:13,  8.39s/it]                                                         {'loss': 0.8459, 'learning_rate': 2.4250027127023014e-06, 'epoch': 0.78}
 78%|███████▊  | 8112/10395 [23:11:04<5:19:13,  8.39s/it] 78%|███████▊  | 8113/10395 [23:11:11<5:06:48,  8.07s/it]                                                         {'loss': 0.8561, 'learning_rate': 2.422969019978312e-06, 'epoch': 0.78}
 78%|███████▊  | 8113/10395 [23:11:11<5:06:48,  8.07s/it] 78%|███████▊  | 8114/10395 [23:11:19<5:06:07,  8.05s/it]                                                         {'loss': 0.8326, 'learning_rate': 2.4209360628162993e-06, 'epoch': 0.78}
 78%|███████▊  | 8114/10395 [23:11:19<5:06:07,  8.05s/it] 78%|███████▊  | 8115/10395 [23:11:27<5:03:45,  7.99s/it]                                                         {'loss': 0.8736, 'learning_rate': 2.4189038414136177e-06, 'epoch': 0.78}
 78%|███████▊  | 8115/10395 [23:11:27<5:03:45,  7.99s/it] 78%|███████▊  | 8116/10395 [23:11:34<4:54:54,  7.76s/it]                                                         {'loss': 0.8851, 'learning_rate': 2.4168723559675487e-06, 'epoch': 0.78}
 78%|███████▊  | 8116/10395 [23:11:34<4:54:54,  7.76s/it] 78%|███████▊  | 8117/10395 [23:11:41<4:50:57,  7.66s/it]                                                         {'loss': 0.8219, 'learning_rate': 2.4148416066753077e-06, 'epoch': 0.78}
 78%|███████▊  | 8117/10395 [23:11:41<4:50:57,  7.66s/it] 78%|███████▊  | 8118/10395 [23:11:50<4:58:49,  7.87s/it]                                                         {'loss': 0.8512, 'learning_rate': 2.412811593734031e-06, 'epoch': 0.78}
 78%|███████▊  | 8118/10395 [23:11:50<4:58:49,  7.87s/it] 78%|███████▊  | 8119/10395 [23:11:57<4:53:15,  7.73s/it]                                                         {'loss': 0.8748, 'learning_rate': 2.410782317340792e-06, 'epoch': 0.78}
 78%|███████▊  | 8119/10395 [23:11:57<4:53:15,  7.73s/it] 78%|███████▊  | 8120/10395 [23:12:04<4:48:37,  7.61s/it]                                                         {'loss': 0.8974, 'learning_rate': 2.4087537776925897e-06, 'epoch': 0.78}
 78%|███████▊  | 8120/10395 [23:12:04<4:48:37,  7.61s/it] 78%|███████▊  | 8121/10395 [23:12:12<4:46:07,  7.55s/it]                                                         {'loss': 0.8615, 'learning_rate': 2.406725974986348e-06, 'epoch': 0.78}
 78%|███████▊  | 8121/10395 [23:12:12<4:46:07,  7.55s/it] 78%|███████▊  | 8122/10395 [23:12:20<4:48:50,  7.62s/it]                                                         {'loss': 0.8774, 'learning_rate': 2.404698909418919e-06, 'epoch': 0.78}
 78%|███████▊  | 8122/10395 [23:12:20<4:48:50,  7.62s/it] 78%|███████▊  | 8123/10395 [23:12:29<5:06:24,  8.09s/it]                                                         {'loss': 0.8617, 'learning_rate': 2.402672581187091e-06, 'epoch': 0.78}
 78%|███████▊  | 8123/10395 [23:12:29<5:06:24,  8.09s/it] 78%|███████▊  | 8124/10395 [23:12:37<5:02:47,  8.00s/it]                                                         {'loss': 0.875, 'learning_rate': 2.4006469904875707e-06, 'epoch': 0.78}
 78%|███████▊  | 8124/10395 [23:12:37<5:02:47,  8.00s/it] 78%|███████▊  | 8125/10395 [23:12:44<4:54:27,  7.78s/it]                                                         {'loss': 0.85, 'learning_rate': 2.398622137517004e-06, 'epoch': 0.78}
 78%|███████▊  | 8125/10395 [23:12:44<4:54:27,  7.78s/it] 78%|███████▊  | 8126/10395 [23:12:51<4:51:36,  7.71s/it]                                                         {'loss': 0.8384, 'learning_rate': 2.396598022471953e-06, 'epoch': 0.78}
 78%|███████▊  | 8126/10395 [23:12:51<4:51:36,  7.71s/it] 78%|███████▊  | 8127/10395 [23:12:59<4:50:08,  7.68s/it]                                                         {'loss': 0.8446, 'learning_rate': 2.3945746455489173e-06, 'epoch': 0.78}
 78%|███████▊  | 8127/10395 [23:12:59<4:50:08,  7.68s/it] 78%|███████▊  | 8128/10395 [23:13:06<4:43:57,  7.52s/it]                                                         {'loss': 0.8628, 'learning_rate': 2.392552006944325e-06, 'epoch': 0.78}
 78%|███████▊  | 8128/10395 [23:13:06<4:43:57,  7.52s/it] 78%|███████▊  | 8129/10395 [23:13:15<4:55:35,  7.83s/it]                                                         {'loss': 0.8337, 'learning_rate': 2.390530106854527e-06, 'epoch': 0.78}
 78%|███████▊  | 8129/10395 [23:13:15<4:55:35,  7.83s/it] 78%|███████▊  | 8130/10395 [23:13:23<4:59:15,  7.93s/it]                                                         {'loss': 0.8792, 'learning_rate': 2.3885089454758015e-06, 'epoch': 0.78}
 78%|███████▊  | 8130/10395 [23:13:23<4:59:15,  7.93s/it] 78%|███████▊  | 8131/10395 [23:13:30<4:52:28,  7.75s/it]                                                         {'loss': 0.9201, 'learning_rate': 2.3864885230043643e-06, 'epoch': 0.78}
 78%|███████▊  | 8131/10395 [23:13:30<4:52:28,  7.75s/it] 78%|███████▊  | 8132/10395 [23:13:48<6:48:38, 10.83s/it]                                                         {'loss': 0.3579, 'learning_rate': 2.384468839636349e-06, 'epoch': 0.78}
 78%|███████▊  | 8132/10395 [23:13:48<6:48:38, 10.83s/it] 78%|███████▊  | 8133/10395 [23:13:56<6:12:12,  9.87s/it]                                                         {'loss': 0.8746, 'learning_rate': 2.3824498955678243e-06, 'epoch': 0.78}
 78%|███████▊  | 8133/10395 [23:13:56<6:12:12,  9.87s/it] 78%|███████▊  | 8134/10395 [23:14:04<5:47:25,  9.22s/it]                                                         {'loss': 0.8641, 'learning_rate': 2.3804316909947878e-06, 'epoch': 0.78}
 78%|███████▊  | 8134/10395 [23:14:04<5:47:25,  9.22s/it] 78%|███████▊  | 8135/10395 [23:14:12<5:38:49,  9.00s/it]                                                         {'loss': 0.8377, 'learning_rate': 2.378414226113156e-06, 'epoch': 0.78}
 78%|███████▊  | 8135/10395 [23:14:12<5:38:49,  9.00s/it] 78%|███████▊  | 8136/10395 [23:14:19<5:18:11,  8.45s/it]                                                         {'loss': 0.941, 'learning_rate': 2.376397501118788e-06, 'epoch': 0.78}
 78%|███████▊  | 8136/10395 [23:14:19<5:18:11,  8.45s/it] 78%|███████▊  | 8137/10395 [23:14:27<5:10:56,  8.26s/it]                                                         {'loss': 0.7978, 'learning_rate': 2.374381516207458e-06, 'epoch': 0.78}
 78%|███████▊  | 8137/10395 [23:14:27<5:10:56,  8.26s/it] 78%|███████▊  | 8138/10395 [23:14:35<5:07:24,  8.17s/it]                                                         {'loss': 0.8385, 'learning_rate': 2.372366271574872e-06, 'epoch': 0.78}
 78%|███████▊  | 8138/10395 [23:14:35<5:07:24,  8.17s/it] 78%|███████▊  | 8139/10395 [23:14:52<6:50:07, 10.91s/it]                                                         {'loss': 0.379, 'learning_rate': 2.3703517674166697e-06, 'epoch': 0.78}
 78%|███████▊  | 8139/10395 [23:14:52<6:50:07, 10.91s/it] 78%|███████▊  | 8140/10395 [23:15:00<6:10:35,  9.86s/it]                                                         {'loss': 0.9462, 'learning_rate': 2.368338003928411e-06, 'epoch': 0.78}
 78%|███████▊  | 8140/10395 [23:15:00<6:10:35,  9.86s/it] 78%|███████▊  | 8141/10395 [23:15:07<5:40:35,  9.07s/it]                                                         {'loss': 0.8821, 'learning_rate': 2.3663249813055913e-06, 'epoch': 0.78}
 78%|███████▊  | 8141/10395 [23:15:07<5:40:35,  9.07s/it] 78%|███████▊  | 8142/10395 [23:15:14<5:22:06,  8.58s/it]                                                         {'loss': 0.8777, 'learning_rate': 2.3643126997436305e-06, 'epoch': 0.78}
 78%|███████▊  | 8142/10395 [23:15:14<5:22:06,  8.58s/it] 78%|███████▊  | 8143/10395 [23:15:31<6:50:46, 10.94s/it]                                                         {'loss': 0.3872, 'learning_rate': 2.3623011594378753e-06, 'epoch': 0.78}
 78%|███████▊  | 8143/10395 [23:15:31<6:50:46, 10.94s/it] 78%|███████▊  | 8144/10395 [23:15:39<6:22:33, 10.20s/it]                                                         {'loss': 0.8365, 'learning_rate': 2.360290360583599e-06, 'epoch': 0.78}
 78%|███████▊  | 8144/10395 [23:15:39<6:22:33, 10.20s/it] 78%|███████▊  | 8145/10395 [23:15:49<6:15:17, 10.01s/it]                                                         {'loss': 0.8865, 'learning_rate': 2.3582803033760116e-06, 'epoch': 0.78}
 78%|███████▊  | 8145/10395 [23:15:49<6:15:17, 10.01s/it] 78%|███████▊  | 8146/10395 [23:15:56<5:42:09,  9.13s/it]                                                         {'loss': 0.902, 'learning_rate': 2.3562709880102398e-06, 'epoch': 0.78}
 78%|███████▊  | 8146/10395 [23:15:56<5:42:09,  9.13s/it] 78%|███████▊  | 8147/10395 [23:16:05<5:38:58,  9.05s/it]                                                         {'loss': 0.852, 'learning_rate': 2.3542624146813477e-06, 'epoch': 0.78}
 78%|███████▊  | 8147/10395 [23:16:05<5:38:58,  9.05s/it] 78%|███████▊  | 8148/10395 [23:16:14<5:42:12,  9.14s/it]                                                         {'loss': 0.8056, 'learning_rate': 2.352254583584318e-06, 'epoch': 0.78}
 78%|███████▊  | 8148/10395 [23:16:14<5:42:12,  9.14s/it] 78%|███████▊  | 8149/10395 [23:16:22<5:22:51,  8.62s/it]                                                         {'loss': 0.8919, 'learning_rate': 2.3502474949140706e-06, 'epoch': 0.78}
 78%|███████▊  | 8149/10395 [23:16:22<5:22:51,  8.62s/it] 78%|███████▊  | 8150/10395 [23:16:30<5:17:05,  8.47s/it]                                                         {'loss': 0.8603, 'learning_rate': 2.3482411488654555e-06, 'epoch': 0.78}
 78%|███████▊  | 8150/10395 [23:16:30<5:17:05,  8.47s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 8151/10395 [23:18:09<22:20:49, 35.85s/it]                                                          {'loss': 0.9389, 'learning_rate': 2.346235545633231e-06, 'epoch': 0.78}
 78%|███████▊  | 8151/10395 [23:18:09<22:20:49, 35.85s/it] 78%|███████▊  | 8152/10395 [23:18:16<16:55:55, 27.18s/it]                                                          {'loss': 0.961, 'learning_rate': 2.3442306854121033e-06, 'epoch': 0.78}
 78%|███████▊  | 8152/10395 [23:18:16<16:55:55, 27.18s/it] 78%|███████▊  | 8153/10395 [23:18:24<13:14:41, 21.27s/it]                                                          {'loss': 0.9028, 'learning_rate': 2.3422265683967037e-06, 'epoch': 0.78}
 78%|███████▊  | 8153/10395 [23:18:24<13:14:41, 21.27s/it] 78%|███████▊  | 8154/10395 [23:18:33<10:54:57, 17.54s/it]                                                          {'loss': 0.8916, 'learning_rate': 2.340223194781581e-06, 'epoch': 0.78}
 78%|███████▊  | 8154/10395 [23:18:33<10:54:57, 17.54s/it] 78%|███████▊  | 8155/10395 [23:18:41<9:07:48, 14.67s/it]                                                          {'loss': 0.926, 'learning_rate': 2.3382205647612242e-06, 'epoch': 0.78}
 78%|███████▊  | 8155/10395 [23:18:41<9:07:48, 14.67s/it] 78%|███████▊  | 8156/10395 [23:18:57<9:29:59, 15.27s/it]                                                         {'loss': 0.3792, 'learning_rate': 2.33621867853004e-06, 'epoch': 0.78}
 78%|███████▊  | 8156/10395 [23:18:57<9:29:59, 15.27s/it] 78%|███████▊  | 8157/10395 [23:19:05<8:07:43, 13.08s/it]                                                         {'loss': 0.8524, 'learning_rate': 2.3342175362823683e-06, 'epoch': 0.78}
 78%|███████▊  | 8157/10395 [23:19:05<8:07:43, 13.08s/it] 78%|███████▊  | 8158/10395 [23:19:13<7:08:45, 11.50s/it]                                                         {'loss': 0.8421, 'learning_rate': 2.3322171382124816e-06, 'epoch': 0.78}
 78%|███████▊  | 8158/10395 [23:19:13<7:08:45, 11.50s/it] 78%|███████▊  | 8159/10395 [23:19:21<6:33:29, 10.56s/it]                                                         {'loss': 0.7463, 'learning_rate': 2.3302174845145632e-06, 'epoch': 0.78}
 78%|███████▊  | 8159/10395 [23:19:21<6:33:29, 10.56s/it] 78%|███████▊  | 8160/10395 [23:19:30<6:05:37,  9.82s/it]                                                         {'loss': 0.8405, 'learning_rate': 2.3282185753827413e-06, 'epoch': 0.78}
 78%|███████▊  | 8160/10395 [23:19:30<6:05:37,  9.82s/it] 79%|███████▊  | 8161/10395 [23:19:46<7:21:03, 11.85s/it]                                                         {'loss': 0.3388, 'learning_rate': 2.3262204110110685e-06, 'epoch': 0.79}
 79%|███████▊  | 8161/10395 [23:19:46<7:21:03, 11.85s/it] 79%|███████▊  | 8162/10395 [23:20:04<8:30:19, 13.71s/it]                                                         {'loss': 0.3841, 'learning_rate': 2.3242229915935166e-06, 'epoch': 0.79}
 79%|███████▊  | 8162/10395 [23:20:04<8:30:19, 13.71s/it] 79%|███████▊  | 8163/10395 [23:20:12<7:24:18, 11.94s/it]                                                         {'loss': 0.8293, 'learning_rate': 2.322226317323997e-06, 'epoch': 0.79}
 79%|███████▊  | 8163/10395 [23:20:12<7:24:18, 11.94s/it] 79%|███████▊  | 8164/10395 [23:20:20<6:45:13, 10.90s/it]                                                         {'loss': 0.7373, 'learning_rate': 2.320230388396335e-06, 'epoch': 0.79}
 79%|███████▊  | 8164/10395 [23:20:20<6:45:13, 10.90s/it] 79%|███████▊  | 8165/10395 [23:20:28<6:07:57,  9.90s/it]                                                         {'loss': 0.9119, 'learning_rate': 2.3182352050042976e-06, 'epoch': 0.79}
 79%|███████▊  | 8165/10395 [23:20:28<6:07:57,  9.90s/it] 79%|███████▊  | 8166/10395 [23:20:36<5:41:41,  9.20s/it]                                                         {'loss': 0.9119, 'learning_rate': 2.316240767341571e-06, 'epoch': 0.79}
 79%|███████▊  | 8166/10395 [23:20:36<5:41:41,  9.20s/it] 79%|███████▊  | 8167/10395 [23:20:44<5:28:07,  8.84s/it]                                                         {'loss': 0.8815, 'learning_rate': 2.3142470756017686e-06, 'epoch': 0.79}
 79%|███████▊  | 8167/10395 [23:20:44<5:28:07,  8.84s/it] 79%|███████▊  | 8168/10395 [23:20:51<5:10:12,  8.36s/it]                                                         {'loss': 0.8978, 'learning_rate': 2.312254129978434e-06, 'epoch': 0.79}
 79%|███████▊  | 8168/10395 [23:20:51<5:10:12,  8.36s/it] 79%|███████▊  | 8169/10395 [23:20:59<5:06:04,  8.25s/it]                                                         {'loss': 0.8467, 'learning_rate': 2.3102619306650444e-06, 'epoch': 0.79}
 79%|███████▊  | 8169/10395 [23:20:59<5:06:04,  8.25s/it] 79%|███████▊  | 8170/10395 [23:21:07<4:59:35,  8.08s/it]                                                         {'loss': 0.8531, 'learning_rate': 2.308270477854989e-06, 'epoch': 0.79}
 79%|███████▊  | 8170/10395 [23:21:07<4:59:35,  8.08s/it] 79%|███████▊  | 8171/10395 [23:21:15<5:04:31,  8.22s/it]                                                         {'loss': 0.8651, 'learning_rate': 2.3062797717416017e-06, 'epoch': 0.79}
 79%|███████▊  | 8171/10395 [23:21:15<5:04:31,  8.22s/it] 79%|███████▊  | 8172/10395 [23:21:23<5:01:41,  8.14s/it]                                                         {'loss': 0.7772, 'learning_rate': 2.3042898125181334e-06, 'epoch': 0.79}
 79%|███████▊  | 8172/10395 [23:21:23<5:01:41,  8.14s/it] 79%|███████▊  | 8173/10395 [23:21:31<4:59:51,  8.10s/it]                                                         {'loss': 0.8129, 'learning_rate': 2.30230060037776e-06, 'epoch': 0.79}
 79%|███████▊  | 8173/10395 [23:21:31<4:59:51,  8.10s/it] 79%|███████▊  | 8174/10395 [23:21:39<4:52:47,  7.91s/it]                                                         {'loss': 0.9548, 'learning_rate': 2.3003121355135983e-06, 'epoch': 0.79}
 79%|███████▊  | 8174/10395 [23:21:39<4:52:47,  7.91s/it] 79%|███████▊  | 8175/10395 [23:21:47<4:59:31,  8.10s/it]                                                         {'loss': 0.804, 'learning_rate': 2.298324418118677e-06, 'epoch': 0.79}
 79%|███████▊  | 8175/10395 [23:21:47<4:59:31,  8.10s/it] 79%|███████▊  | 8176/10395 [23:21:54<4:52:02,  7.90s/it]                                                         {'loss': 0.8117, 'learning_rate': 2.2963374483859623e-06, 'epoch': 0.79}
 79%|███████▊  | 8176/10395 [23:21:54<4:52:02,  7.90s/it] 79%|███████▊  | 8177/10395 [23:22:02<4:46:26,  7.75s/it]                                                         {'loss': 0.9186, 'learning_rate': 2.294351226508349e-06, 'epoch': 0.79}
 79%|███████▊  | 8177/10395 [23:22:02<4:46:26,  7.75s/it] 79%|███████▊  | 8178/10395 [23:22:10<4:47:56,  7.79s/it]                                                         {'loss': 0.8077, 'learning_rate': 2.292365752678648e-06, 'epoch': 0.79}
 79%|███████▊  | 8178/10395 [23:22:10<4:47:56,  7.79s/it] 79%|███████▊  | 8179/10395 [23:22:17<4:41:00,  7.61s/it]                                                         {'loss': 0.8667, 'learning_rate': 2.290381027089612e-06, 'epoch': 0.79}
 79%|███████▊  | 8179/10395 [23:22:17<4:41:00,  7.61s/it] 79%|███████▊  | 8180/10395 [23:22:34<6:25:28, 10.44s/it]                                                         {'loss': 0.3946, 'learning_rate': 2.2883970499339103e-06, 'epoch': 0.79}
 79%|███████▊  | 8180/10395 [23:22:34<6:25:28, 10.44s/it] 79%|███████▊  | 8181/10395 [23:22:42<5:53:14,  9.57s/it]                                                         {'loss': 0.8937, 'learning_rate': 2.2864138214041396e-06, 'epoch': 0.79}
 79%|███████▊  | 8181/10395 [23:22:42<5:53:14,  9.57s/it] 79%|███████▊  | 8182/10395 [23:22:49<5:34:00,  9.06s/it]                                                         {'loss': 0.8584, 'learning_rate': 2.284431341692834e-06, 'epoch': 0.79}
 79%|███████▊  | 8182/10395 [23:22:49<5:34:00,  9.06s/it] 79%|███████▊  | 8183/10395 [23:22:58<5:25:37,  8.83s/it]                                                         {'loss': 0.87, 'learning_rate': 2.2824496109924432e-06, 'epoch': 0.79}
 79%|███████▊  | 8183/10395 [23:22:58<5:25:37,  8.83s/it] 79%|███████▊  | 8184/10395 [23:23:06<5:18:17,  8.64s/it]                                                         {'loss': 0.7379, 'learning_rate': 2.2804686294953517e-06, 'epoch': 0.79}
 79%|███████▊  | 8184/10395 [23:23:06<5:18:17,  8.64s/it] 79%|███████▊  | 8185/10395 [23:23:14<5:13:07,  8.50s/it]                                                         {'loss': 0.8428, 'learning_rate': 2.278488397393872e-06, 'epoch': 0.79}
 79%|███████▊  | 8185/10395 [23:23:14<5:13:07,  8.50s/it] 79%|███████▊  | 8186/10395 [23:23:21<5:00:46,  8.17s/it]                                                         {'loss': 0.8855, 'learning_rate': 2.2765089148802346e-06, 'epoch': 0.79}
 79%|███████▊  | 8186/10395 [23:23:21<5:00:46,  8.17s/it] 79%|███████▉  | 8187/10395 [23:23:30<4:59:49,  8.15s/it]                                                         {'loss': 0.8473, 'learning_rate': 2.274530182146609e-06, 'epoch': 0.79}
 79%|███████▉  | 8187/10395 [23:23:30<4:59:49,  8.15s/it] 79%|███████▉  | 8188/10395 [23:23:37<4:54:53,  8.02s/it]                                                         {'loss': 0.8102, 'learning_rate': 2.2725521993850853e-06, 'epoch': 0.79}
 79%|███████▉  | 8188/10395 [23:23:37<4:54:53,  8.02s/it] 79%|███████▉  | 8189/10395 [23:23:45<4:48:28,  7.85s/it]                                                         {'loss': 0.8867, 'learning_rate': 2.270574966787676e-06, 'epoch': 0.79}
 79%|███████▉  | 8189/10395 [23:23:45<4:48:28,  7.85s/it] 79%|███████▉  | 8190/10395 [23:23:52<4:45:37,  7.77s/it]                                                         {'loss': 0.8255, 'learning_rate': 2.2685984845463347e-06, 'epoch': 0.79}
 79%|███████▉  | 8190/10395 [23:23:52<4:45:37,  7.77s/it] 79%|███████▉  | 8191/10395 [23:24:00<4:49:37,  7.88s/it]                                                         {'loss': 0.8888, 'learning_rate': 2.266622752852927e-06, 'epoch': 0.79}
 79%|███████▉  | 8191/10395 [23:24:00<4:49:37,  7.88s/it] 79%|███████▉  | 8192/10395 [23:24:08<4:45:15,  7.77s/it]                                                         {'loss': 0.9467, 'learning_rate': 2.2646477718992577e-06, 'epoch': 0.79}
 79%|███████▉  | 8192/10395 [23:24:08<4:45:15,  7.77s/it] 79%|███████▉  | 8193/10395 [23:24:16<4:52:05,  7.96s/it]                                                         {'loss': 0.8, 'learning_rate': 2.262673541877054e-06, 'epoch': 0.79}
 79%|███████▉  | 8193/10395 [23:24:16<4:52:05,  7.96s/it] 79%|███████▉  | 8194/10395 [23:24:24<4:44:41,  7.76s/it]                                                         {'loss': 0.8096, 'learning_rate': 2.2607000629779684e-06, 'epoch': 0.79}
 79%|███████▉  | 8194/10395 [23:24:24<4:44:41,  7.76s/it] 79%|███████▉  | 8195/10395 [23:24:31<4:44:42,  7.76s/it]                                                         {'loss': 0.9239, 'learning_rate': 2.258727335393578e-06, 'epoch': 0.79}
 79%|███████▉  | 8195/10395 [23:24:31<4:44:42,  7.76s/it] 79%|███████▉  | 8196/10395 [23:24:39<4:38:50,  7.61s/it]                                                         {'loss': 0.91, 'learning_rate': 2.256755359315399e-06, 'epoch': 0.79}
 79%|███████▉  | 8196/10395 [23:24:39<4:38:50,  7.61s/it] 79%|███████▉  | 8197/10395 [23:24:56<6:20:18, 10.38s/it]                                                         {'loss': 0.4295, 'learning_rate': 2.2547841349348587e-06, 'epoch': 0.79}
 79%|███████▉  | 8197/10395 [23:24:56<6:20:18, 10.38s/it] 79%|███████▉  | 8198/10395 [23:25:03<5:47:09,  9.48s/it]                                                         {'loss': 0.7907, 'learning_rate': 2.2528136624433227e-06, 'epoch': 0.79}
 79%|███████▉  | 8198/10395 [23:25:03<5:47:09,  9.48s/it] 79%|███████▉  | 8199/10395 [23:25:10<5:22:34,  8.81s/it]                                                         {'loss': 0.8728, 'learning_rate': 2.250843942032084e-06, 'epoch': 0.79}
 79%|███████▉  | 8199/10395 [23:25:10<5:22:34,  8.81s/it] 79%|███████▉  | 8200/10395 [23:25:18<5:11:35,  8.52s/it]                                                         {'loss': 0.7938, 'learning_rate': 2.248874973892352e-06, 'epoch': 0.79}
 79%|███████▉  | 8200/10395 [23:25:18<5:11:35,  8.52s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 79%|███████▉  | 8201/10395 [23:26:59<22:01:09, 36.13s/it]                                                          {'loss': 0.8412, 'learning_rate': 2.246906758215277e-06, 'epoch': 0.79}
 79%|███████▉  | 8201/10395 [23:26:59<22:01:09, 36.13s/it] 79%|███████▉  | 8202/10395 [23:27:06<16:50:26, 27.65s/it]                                                          {'loss': 0.9372, 'learning_rate': 2.2449392951919248e-06, 'epoch': 0.79}
 79%|███████▉  | 8202/10395 [23:27:06<16:50:26, 27.65s/it] 79%|███████▉  | 8203/10395 [23:27:15<13:20:26, 21.91s/it]                                                          {'loss': 0.8476, 'learning_rate': 2.242972585013291e-06, 'epoch': 0.79}
 79%|███████▉  | 8203/10395 [23:27:15<13:20:26, 21.91s/it] 79%|███████▉  | 8204/10395 [23:27:33<12:34:42, 20.67s/it]                                                          {'loss': 0.3518, 'learning_rate': 2.2410066278703037e-06, 'epoch': 0.79}
 79%|███████▉  | 8204/10395 [23:27:33<12:34:42, 20.67s/it] 79%|███████▉  | 8205/10395 [23:27:51<12:07:23, 19.93s/it]                                                          {'loss': 0.3575, 'learning_rate': 2.2390414239538096e-06, 'epoch': 0.79}
 79%|███████▉  | 8205/10395 [23:27:51<12:07:23, 19.93s/it] 79%|███████▉  | 8206/10395 [23:28:00<10:05:33, 16.60s/it]                                                          {'loss': 0.9057, 'learning_rate': 2.2370769734545894e-06, 'epoch': 0.79}
 79%|███████▉  | 8206/10395 [23:28:00<10:05:33, 16.60s/it] 79%|███████▉  | 8207/10395 [23:28:07<8:22:55, 13.79s/it]                                                          {'loss': 0.8626, 'learning_rate': 2.2351132765633488e-06, 'epoch': 0.79}
 79%|███████▉  | 8207/10395 [23:28:07<8:22:55, 13.79s/it] 79%|███████▉  | 8208/10395 [23:28:15<7:24:12, 12.19s/it]                                                         {'loss': 0.9274, 'learning_rate': 2.233150333470716e-06, 'epoch': 0.79}
 79%|███████▉  | 8208/10395 [23:28:15<7:24:12, 12.19s/it] 79%|███████▉  | 8209/10395 [23:28:23<6:36:27, 10.88s/it]                                                         {'loss': 0.8584, 'learning_rate': 2.2311881443672533e-06, 'epoch': 0.79}
 79%|███████▉  | 8209/10395 [23:28:23<6:36:27, 10.88s/it] 79%|███████▉  | 8210/10395 [23:28:32<6:12:15, 10.22s/it]                                                         {'loss': 0.7748, 'learning_rate': 2.2292267094434438e-06, 'epoch': 0.79}
 79%|███████▉  | 8210/10395 [23:28:32<6:12:15, 10.22s/it] 79%|███████▉  | 8211/10395 [23:28:40<5:44:28,  9.46s/it]                                                         {'loss': 0.8723, 'learning_rate': 2.227266028889696e-06, 'epoch': 0.79}
 79%|███████▉  | 8211/10395 [23:28:40<5:44:28,  9.46s/it] 79%|███████▉  | 8212/10395 [23:28:48<5:30:19,  9.08s/it]                                                         {'loss': 0.8383, 'learning_rate': 2.2253061028963553e-06, 'epoch': 0.79}
 79%|███████▉  | 8212/10395 [23:28:48<5:30:19,  9.08s/it] 79%|███████▉  | 8213/10395 [23:28:56<5:22:09,  8.86s/it]                                                         {'loss': 0.8467, 'learning_rate': 2.2233469316536795e-06, 'epoch': 0.79}
 79%|███████▉  | 8213/10395 [23:28:56<5:22:09,  8.86s/it] 79%|███████▉  | 8214/10395 [23:29:04<5:16:05,  8.70s/it]                                                         {'loss': 0.8845, 'learning_rate': 2.2213885153518655e-06, 'epoch': 0.79}
 79%|███████▉  | 8214/10395 [23:29:04<5:16:05,  8.70s/it] 79%|███████▉  | 8215/10395 [23:29:12<5:02:45,  8.33s/it]                                                         {'loss': 0.9244, 'learning_rate': 2.219430854181034e-06, 'epoch': 0.79}
 79%|███████▉  | 8215/10395 [23:29:12<5:02:45,  8.33s/it] 79%|███████▉  | 8216/10395 [23:29:20<4:55:35,  8.14s/it]                                                         {'loss': 0.8882, 'learning_rate': 2.217473948331229e-06, 'epoch': 0.79}
 79%|███████▉  | 8216/10395 [23:29:20<4:55:35,  8.14s/it] 79%|███████▉  | 8217/10395 [23:29:27<4:49:03,  7.96s/it]                                                         {'loss': 0.8742, 'learning_rate': 2.215517797992418e-06, 'epoch': 0.79}
 79%|███████▉  | 8217/10395 [23:29:27<4:49:03,  7.96s/it] 79%|███████▉  | 8218/10395 [23:29:35<4:47:41,  7.93s/it]                                                         {'loss': 0.9221, 'learning_rate': 2.2135624033545065e-06, 'epoch': 0.79}
 79%|███████▉  | 8218/10395 [23:29:35<4:47:41,  7.93s/it] 79%|███████▉  | 8219/10395 [23:29:42<4:41:02,  7.75s/it]                                                         {'loss': 0.7166, 'learning_rate': 2.2116077646073153e-06, 'epoch': 0.79}
 79%|███████▉  | 8219/10395 [23:29:42<4:41:02,  7.75s/it] 79%|███████▉  | 8220/10395 [23:29:50<4:41:36,  7.77s/it]                                                         {'loss': 0.8553, 'learning_rate': 2.2096538819406e-06, 'epoch': 0.79}
 79%|███████▉  | 8220/10395 [23:29:50<4:41:36,  7.77s/it] 79%|███████▉  | 8221/10395 [23:29:58<4:41:59,  7.78s/it]                                                         {'loss': 0.8953, 'learning_rate': 2.2077007555440356e-06, 'epoch': 0.79}
 79%|███████▉  | 8221/10395 [23:29:58<4:41:59,  7.78s/it] 79%|███████▉  | 8222/10395 [23:30:06<4:39:52,  7.73s/it]                                                         {'loss': 0.8557, 'learning_rate': 2.2057483856072303e-06, 'epoch': 0.79}
 79%|███████▉  | 8222/10395 [23:30:06<4:39:52,  7.73s/it] 79%|███████▉  | 8223/10395 [23:30:13<4:39:19,  7.72s/it]                                                         {'loss': 0.8481, 'learning_rate': 2.2037967723197174e-06, 'epoch': 0.79}
 79%|███████▉  | 8223/10395 [23:30:13<4:39:19,  7.72s/it] 79%|███████▉  | 8224/10395 [23:30:21<4:40:51,  7.76s/it]                                                         {'loss': 0.8482, 'learning_rate': 2.2018459158709536e-06, 'epoch': 0.79}
 79%|███████▉  | 8224/10395 [23:30:21<4:40:51,  7.76s/it] 79%|███████▉  | 8225/10395 [23:30:28<4:35:30,  7.62s/it]                                                         {'loss': 0.7212, 'learning_rate': 2.1998958164503204e-06, 'epoch': 0.79}
 79%|███████▉  | 8225/10395 [23:30:28<4:35:30,  7.62s/it] 79%|███████▉  | 8226/10395 [23:30:45<6:16:32, 10.42s/it]                                                         {'loss': 0.3671, 'learning_rate': 2.197946474247136e-06, 'epoch': 0.79}
 79%|███████▉  | 8226/10395 [23:30:45<6:16:32, 10.42s/it] 79%|███████▉  | 8227/10395 [23:30:53<5:45:35,  9.56s/it]                                                         {'loss': 0.9364, 'learning_rate': 2.1959978894506305e-06, 'epoch': 0.79}
 79%|███████▉  | 8227/10395 [23:30:53<5:45:35,  9.56s/it] 79%|███████▉  | 8228/10395 [23:31:01<5:28:39,  9.10s/it]                                                         {'loss': 0.8268, 'learning_rate': 2.194050062249977e-06, 'epoch': 0.79}
 79%|███████▉  | 8228/10395 [23:31:01<5:28:39,  9.10s/it] 79%|███████▉  | 8229/10395 [23:31:09<5:11:24,  8.63s/it]                                                         {'loss': 0.8634, 'learning_rate': 2.1921029928342584e-06, 'epoch': 0.79}
 79%|███████▉  | 8229/10395 [23:31:09<5:11:24,  8.63s/it] 79%|███████▉  | 8230/10395 [23:31:17<5:07:59,  8.54s/it]                                                         {'loss': 0.9209, 'learning_rate': 2.190156681392497e-06, 'epoch': 0.79}
 79%|███████▉  | 8230/10395 [23:31:17<5:07:59,  8.54s/it] 79%|███████▉  | 8231/10395 [23:31:26<5:10:45,  8.62s/it]                                                         {'loss': 0.8176, 'learning_rate': 2.18821112811364e-06, 'epoch': 0.79}
 79%|███████▉  | 8231/10395 [23:31:26<5:10:45,  8.62s/it] 79%|███████▉  | 8232/10395 [23:31:33<5:02:27,  8.39s/it]                                                         {'loss': 0.8861, 'learning_rate': 2.186266333186546e-06, 'epoch': 0.79}
 79%|███████▉  | 8232/10395 [23:31:33<5:02:27,  8.39s/it] 79%|███████▉  | 8233/10395 [23:31:41<4:51:27,  8.09s/it]                                                         {'loss': 0.929, 'learning_rate': 2.18432229680002e-06, 'epoch': 0.79}
 79%|███████▉  | 8233/10395 [23:31:41<4:51:27,  8.09s/it] 79%|███████▉  | 8234/10395 [23:31:49<4:49:30,  8.04s/it]                                                         {'loss': 0.8857, 'learning_rate': 2.1823790191427863e-06, 'epoch': 0.79}
 79%|███████▉  | 8234/10395 [23:31:49<4:49:30,  8.04s/it] 79%|███████▉  | 8235/10395 [23:31:56<4:40:32,  7.79s/it]                                                         {'loss': 0.8436, 'learning_rate': 2.1804365004034877e-06, 'epoch': 0.79}
 79%|███████▉  | 8235/10395 [23:31:56<4:40:32,  7.79s/it] 79%|███████▉  | 8236/10395 [23:32:13<6:22:08, 10.62s/it]                                                         {'loss': 0.37, 'learning_rate': 2.178494740770706e-06, 'epoch': 0.79}
 79%|███████▉  | 8236/10395 [23:32:13<6:22:08, 10.62s/it] 79%|███████▉  | 8237/10395 [23:32:21<5:53:20,  9.82s/it]                                                         {'loss': 0.8406, 'learning_rate': 2.176553740432937e-06, 'epoch': 0.79}
 79%|███████▉  | 8237/10395 [23:32:21<5:53:20,  9.82s/it] 79%|███████▉  | 8238/10395 [23:32:29<5:29:46,  9.17s/it]                                                         {'loss': 0.8323, 'learning_rate': 2.1746134995786127e-06, 'epoch': 0.79}
 79%|███████▉  | 8238/10395 [23:32:29<5:29:46,  9.17s/it] 79%|███████▉  | 8239/10395 [23:32:36<5:10:06,  8.63s/it]                                                         {'loss': 0.7573, 'learning_rate': 2.1726740183960916e-06, 'epoch': 0.79}
 79%|███████▉  | 8239/10395 [23:32:36<5:10:06,  8.63s/it] 79%|███████▉  | 8240/10395 [23:32:44<4:58:09,  8.30s/it]                                                         {'loss': 0.9051, 'learning_rate': 2.170735297073645e-06, 'epoch': 0.79}
 79%|███████▉  | 8240/10395 [23:32:44<4:58:09,  8.30s/it] 79%|███████▉  | 8241/10395 [23:32:52<4:59:46,  8.35s/it]                                                         {'loss': 0.8562, 'learning_rate': 2.1687973357994852e-06, 'epoch': 0.79}
 79%|███████▉  | 8241/10395 [23:32:52<4:59:46,  8.35s/it] 79%|███████▉  | 8242/10395 [23:33:00<4:51:31,  8.12s/it]                                                         {'loss': 0.8478, 'learning_rate': 2.166860134761747e-06, 'epoch': 0.79}
 79%|███████▉  | 8242/10395 [23:33:00<4:51:31,  8.12s/it] 79%|███████▉  | 8243/10395 [23:33:09<5:08:06,  8.59s/it]                                                         {'loss': 0.877, 'learning_rate': 2.164923694148484e-06, 'epoch': 0.79}
 79%|███████▉  | 8243/10395 [23:33:09<5:08:06,  8.59s/it] 79%|███████▉  | 8244/10395 [23:33:17<4:55:22,  8.24s/it]                                                         {'loss': 0.8471, 'learning_rate': 2.1629880141476876e-06, 'epoch': 0.79}
 79%|███████▉  | 8244/10395 [23:33:17<4:55:22,  8.24s/it] 79%|███████▉  | 8245/10395 [23:33:24<4:46:51,  8.01s/it]                                                         {'loss': 0.8021, 'learning_rate': 2.161053094947265e-06, 'epoch': 0.79}
 79%|███████▉  | 8245/10395 [23:33:24<4:46:51,  8.01s/it] 79%|███████▉  | 8246/10395 [23:33:33<4:50:04,  8.10s/it]                                                         {'loss': 0.8328, 'learning_rate': 2.1591189367350597e-06, 'epoch': 0.79}
 79%|███████▉  | 8246/10395 [23:33:33<4:50:04,  8.10s/it] 79%|███████▉  | 8247/10395 [23:33:40<4:45:23,  7.97s/it]                                                         {'loss': 0.8455, 'learning_rate': 2.1571855396988306e-06, 'epoch': 0.79}
 79%|███████▉  | 8247/10395 [23:33:40<4:45:23,  7.97s/it] 79%|███████▉  | 8248/10395 [23:33:50<4:58:42,  8.35s/it]                                                         {'loss': 0.8052, 'learning_rate': 2.155252904026267e-06, 'epoch': 0.79}
 79%|███████▉  | 8248/10395 [23:33:50<4:58:42,  8.35s/it] 79%|███████▉  | 8249/10395 [23:33:58<4:58:59,  8.36s/it]                                                         {'loss': 0.8731, 'learning_rate': 2.153321029904988e-06, 'epoch': 0.79}
 79%|███████▉  | 8249/10395 [23:33:58<4:58:59,  8.36s/it] 79%|███████▉  | 8250/10395 [23:34:16<6:42:04, 11.25s/it]                                                         {'loss': 0.3429, 'learning_rate': 2.151389917522536e-06, 'epoch': 0.79}
 79%|███████▉  | 8250/10395 [23:34:16<6:42:04, 11.25s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 79%|███████▉  | 8251/10395 [23:35:54<22:11:26, 37.26s/it]                                                          {'loss': 0.9423, 'learning_rate': 2.1494595670663764e-06, 'epoch': 0.79}
 79%|███████▉  | 8251/10395 [23:35:54<22:11:26, 37.26s/it] 79%|███████▉  | 8252/10395 [23:36:01<16:52:09, 28.34s/it]                                                          {'loss': 0.9011, 'learning_rate': 2.147529978723909e-06, 'epoch': 0.79}
 79%|███████▉  | 8252/10395 [23:36:01<16:52:09, 28.34s/it] 79%|███████▉  | 8253/10395 [23:36:09<13:07:13, 22.05s/it]                                                          {'loss': 0.8155, 'learning_rate': 2.1456011526824496e-06, 'epoch': 0.79}
 79%|███████▉  | 8253/10395 [23:36:09<13:07:13, 22.05s/it] 79%|███████▉  | 8254/10395 [23:36:17<10:34:24, 17.78s/it]                                                          {'loss': 0.8517, 'learning_rate': 2.1436730891292424e-06, 'epoch': 0.79}
 79%|███████▉  | 8254/10395 [23:36:17<10:34:24, 17.78s/it] 79%|███████▉  | 8255/10395 [23:36:24<8:46:02, 14.75s/it]                                                          {'loss': 0.7922, 'learning_rate': 2.1417457882514657e-06, 'epoch': 0.79}
 79%|███████▉  | 8255/10395 [23:36:24<8:46:02, 14.75s/it] 79%|███████▉  | 8256/10395 [23:36:33<7:36:06, 12.79s/it]                                                         {'loss': 0.8711, 'learning_rate': 2.1398192502362112e-06, 'epoch': 0.79}
 79%|███████▉  | 8256/10395 [23:36:33<7:36:06, 12.79s/it] 79%|███████▉  | 8257/10395 [23:36:42<7:01:15, 11.82s/it]                                                         {'loss': 0.766, 'learning_rate': 2.1378934752705085e-06, 'epoch': 0.79}
 79%|███████▉  | 8257/10395 [23:36:42<7:01:15, 11.82s/it] 79%|███████▉  | 8258/10395 [23:36:50<6:18:54, 10.64s/it]                                                         {'loss': 0.8202, 'learning_rate': 2.135968463541307e-06, 'epoch': 0.79}
 79%|███████▉  | 8258/10395 [23:36:50<6:18:54, 10.64s/it] 79%|███████▉  | 8259/10395 [23:36:58<5:53:22,  9.93s/it]                                                         {'loss': 0.8579, 'learning_rate': 2.134044215235479e-06, 'epoch': 0.79}
 79%|███████▉  | 8259/10395 [23:36:58<5:53:22,  9.93s/it] 79%|███████▉  | 8260/10395 [23:37:07<5:35:31,  9.43s/it]                                                         {'loss': 0.8194, 'learning_rate': 2.1321207305398326e-06, 'epoch': 0.79}
 79%|███████▉  | 8260/10395 [23:37:07<5:35:31,  9.43s/it] 79%|███████▉  | 8261/10395 [23:37:14<5:19:15,  8.98s/it]                                                         {'loss': 0.802, 'learning_rate': 2.130198009641091e-06, 'epoch': 0.79}
 79%|███████▉  | 8261/10395 [23:37:14<5:19:15,  8.98s/it] 79%|███████▉  | 8262/10395 [23:37:22<5:06:22,  8.62s/it]                                                         {'loss': 0.8614, 'learning_rate': 2.128276052725907e-06, 'epoch': 0.79}
 79%|███████▉  | 8262/10395 [23:37:22<5:06:22,  8.62s/it] 79%|███████▉  | 8263/10395 [23:37:30<4:53:50,  8.27s/it]                                                         {'loss': 0.8574, 'learning_rate': 2.1263548599808615e-06, 'epoch': 0.79}
 79%|███████▉  | 8263/10395 [23:37:30<4:53:50,  8.27s/it] 79%|███████▉  | 8264/10395 [23:37:37<4:46:50,  8.08s/it]                                                         {'loss': 0.7589, 'learning_rate': 2.1244344315924627e-06, 'epoch': 0.79}
 79%|███████▉  | 8264/10395 [23:37:37<4:46:50,  8.08s/it] 80%|███████▉  | 8265/10395 [23:37:45<4:45:44,  8.05s/it]                                                         {'loss': 0.8603, 'learning_rate': 2.122514767747136e-06, 'epoch': 0.8}
 80%|███████▉  | 8265/10395 [23:37:45<4:45:44,  8.05s/it] 80%|███████▉  | 8266/10395 [23:37:53<4:42:39,  7.97s/it]                                                         {'loss': 0.9305, 'learning_rate': 2.1205958686312444e-06, 'epoch': 0.8}
 80%|███████▉  | 8266/10395 [23:37:53<4:42:39,  7.97s/it] 80%|███████▉  | 8267/10395 [23:38:01<4:43:45,  8.00s/it]                                                         {'loss': 0.8969, 'learning_rate': 2.118677734431065e-06, 'epoch': 0.8}
 80%|███████▉  | 8267/10395 [23:38:01<4:43:45,  8.00s/it] 80%|███████▉  | 8268/10395 [23:38:09<4:41:09,  7.93s/it]                                                         {'loss': 0.8633, 'learning_rate': 2.116760365332812e-06, 'epoch': 0.8}
 80%|███████▉  | 8268/10395 [23:38:09<4:41:09,  7.93s/it] 80%|███████▉  | 8269/10395 [23:38:16<4:37:12,  7.82s/it]                                                         {'loss': 0.8872, 'learning_rate': 2.1148437615226146e-06, 'epoch': 0.8}
 80%|███████▉  | 8269/10395 [23:38:16<4:37:12,  7.82s/it] 80%|███████▉  | 8270/10395 [23:38:35<6:29:26, 11.00s/it]                                                         {'loss': 0.4005, 'learning_rate': 2.112927923186533e-06, 'epoch': 0.8}
 80%|███████▉  | 8270/10395 [23:38:35<6:29:26, 11.00s/it] 80%|███████▉  | 8271/10395 [23:38:43<6:03:20, 10.26s/it]                                                         {'loss': 0.8308, 'learning_rate': 2.1110128505105534e-06, 'epoch': 0.8}
 80%|███████▉  | 8271/10395 [23:38:43<6:03:20, 10.26s/it] 80%|███████▉  | 8272/10395 [23:38:51<5:30:35,  9.34s/it]                                                         {'loss': 0.8752, 'learning_rate': 2.10909854368059e-06, 'epoch': 0.8}
 80%|███████▉  | 8272/10395 [23:38:51<5:30:35,  9.34s/it] 80%|███████▉  | 8273/10395 [23:38:59<5:15:43,  8.93s/it]                                                         {'loss': 0.8648, 'learning_rate': 2.107185002882475e-06, 'epoch': 0.8}
 80%|███████▉  | 8273/10395 [23:38:59<5:15:43,  8.93s/it] 80%|███████▉  | 8274/10395 [23:39:07<5:09:10,  8.75s/it]                                                         {'loss': 0.8493, 'learning_rate': 2.1052722283019745e-06, 'epoch': 0.8}
 80%|███████▉  | 8274/10395 [23:39:07<5:09:10,  8.75s/it] 80%|███████▉  | 8275/10395 [23:39:14<4:55:00,  8.35s/it]                                                         {'loss': 0.8994, 'learning_rate': 2.103360220124776e-06, 'epoch': 0.8}
 80%|███████▉  | 8275/10395 [23:39:14<4:55:00,  8.35s/it] 80%|███████▉  | 8276/10395 [23:39:22<4:49:13,  8.19s/it]                                                         {'loss': 0.8707, 'learning_rate': 2.101448978536489e-06, 'epoch': 0.8}
 80%|███████▉  | 8276/10395 [23:39:22<4:49:13,  8.19s/it] 80%|███████▉  | 8277/10395 [23:39:30<4:44:57,  8.07s/it]                                                         {'loss': 0.8562, 'learning_rate': 2.099538503722659e-06, 'epoch': 0.8}
 80%|███████▉  | 8277/10395 [23:39:30<4:44:57,  8.07s/it] 80%|███████▉  | 8278/10395 [23:39:38<4:44:14,  8.06s/it]                                                         {'loss': 0.8447, 'learning_rate': 2.0976287958687445e-06, 'epoch': 0.8}
 80%|███████▉  | 8278/10395 [23:39:38<4:44:14,  8.06s/it] 80%|███████▉  | 8279/10395 [23:39:46<4:44:42,  8.07s/it]                                                         {'loss': 0.8265, 'learning_rate': 2.0957198551601386e-06, 'epoch': 0.8}
 80%|███████▉  | 8279/10395 [23:39:46<4:44:42,  8.07s/it] 80%|███████▉  | 8280/10395 [23:39:53<4:36:01,  7.83s/it]                                                         {'loss': 0.8638, 'learning_rate': 2.093811681782161e-06, 'epoch': 0.8}
 80%|███████▉  | 8280/10395 [23:39:53<4:36:01,  7.83s/it] 80%|███████▉  | 8281/10395 [23:40:01<4:30:27,  7.68s/it]                                                         {'loss': 0.8757, 'learning_rate': 2.091904275920047e-06, 'epoch': 0.8}
 80%|███████▉  | 8281/10395 [23:40:01<4:30:27,  7.68s/it] 80%|███████▉  | 8282/10395 [23:40:08<4:25:10,  7.53s/it]                                                         {'loss': 0.918, 'learning_rate': 2.089997637758969e-06, 'epoch': 0.8}
 80%|███████▉  | 8282/10395 [23:40:08<4:25:10,  7.53s/it] 80%|███████▉  | 8283/10395 [23:40:16<4:34:40,  7.80s/it]                                                         {'loss': 0.8161, 'learning_rate': 2.0880917674840173e-06, 'epoch': 0.8}
 80%|███████▉  | 8283/10395 [23:40:16<4:34:40,  7.80s/it] 80%|███████▉  | 8284/10395 [23:40:24<4:35:42,  7.84s/it]                                                         {'loss': 0.8358, 'learning_rate': 2.0861866652802055e-06, 'epoch': 0.8}
 80%|███████▉  | 8284/10395 [23:40:24<4:35:42,  7.84s/it] 80%|███████▉  | 8285/10395 [23:40:32<4:38:40,  7.92s/it]                                                         {'loss': 0.8016, 'learning_rate': 2.0842823313324834e-06, 'epoch': 0.8}
 80%|███████▉  | 8285/10395 [23:40:32<4:38:40,  7.92s/it] 80%|███████▉  | 8286/10395 [23:40:40<4:34:59,  7.82s/it]                                                         {'loss': 0.7819, 'learning_rate': 2.0823787658257132e-06, 'epoch': 0.8}
 80%|███████▉  | 8286/10395 [23:40:40<4:34:59,  7.82s/it] 80%|███████▉  | 8287/10395 [23:40:47<4:29:58,  7.68s/it]                                                         {'loss': 0.8756, 'learning_rate': 2.0804759689446928e-06, 'epoch': 0.8}
 80%|███████▉  | 8287/10395 [23:40:47<4:29:58,  7.68s/it] 80%|███████▉  | 8288/10395 [23:40:54<4:24:04,  7.52s/it]                                                         {'loss': 0.9417, 'learning_rate': 2.0785739408741433e-06, 'epoch': 0.8}
 80%|███████▉  | 8288/10395 [23:40:54<4:24:04,  7.52s/it] 80%|███████▉  | 8289/10395 [23:41:03<4:30:46,  7.71s/it]                                                         {'loss': 0.8551, 'learning_rate': 2.0766726817987058e-06, 'epoch': 0.8}
 80%|███████▉  | 8289/10395 [23:41:03<4:30:46,  7.71s/it] 80%|███████▉  | 8290/10395 [23:41:10<4:24:35,  7.54s/it]                                                         {'loss': 0.9511, 'learning_rate': 2.074772191902955e-06, 'epoch': 0.8}
 80%|███████▉  | 8290/10395 [23:41:10<4:24:35,  7.54s/it] 80%|███████▉  | 8291/10395 [23:41:17<4:24:54,  7.55s/it]                                                         {'loss': 0.8465, 'learning_rate': 2.072872471371383e-06, 'epoch': 0.8}
 80%|███████▉  | 8291/10395 [23:41:17<4:24:54,  7.55s/it] 80%|███████▉  | 8292/10395 [23:41:25<4:24:13,  7.54s/it]                                                         {'loss': 0.8127, 'learning_rate': 2.0709735203884085e-06, 'epoch': 0.8}
 80%|███████▉  | 8292/10395 [23:41:25<4:24:13,  7.54s/it] 80%|███████▉  | 8293/10395 [23:41:33<4:26:36,  7.61s/it]                                                         {'loss': 0.8241, 'learning_rate': 2.0690753391383834e-06, 'epoch': 0.8}
 80%|███████▉  | 8293/10395 [23:41:33<4:26:36,  7.61s/it] 80%|███████▉  | 8294/10395 [23:41:40<4:24:23,  7.55s/it]                                                         {'loss': 0.8997, 'learning_rate': 2.0671779278055728e-06, 'epoch': 0.8}
 80%|███████▉  | 8294/10395 [23:41:40<4:24:23,  7.55s/it] 80%|███████▉  | 8295/10395 [23:41:47<4:21:23,  7.47s/it]                                                         {'loss': 0.8917, 'learning_rate': 2.0652812865741757e-06, 'epoch': 0.8}
 80%|███████▉  | 8295/10395 [23:41:47<4:21:23,  7.47s/it] 80%|███████▉  | 8296/10395 [23:41:55<4:21:24,  7.47s/it]                                                         {'loss': 0.84, 'learning_rate': 2.0633854156283186e-06, 'epoch': 0.8}
 80%|███████▉  | 8296/10395 [23:41:55<4:21:24,  7.47s/it] 80%|███████▉  | 8297/10395 [23:42:12<6:06:48, 10.49s/it]                                                         {'loss': 0.3784, 'learning_rate': 2.0614903151520447e-06, 'epoch': 0.8}
 80%|███████▉  | 8297/10395 [23:42:12<6:06:48, 10.49s/it] 80%|███████▉  | 8298/10395 [23:42:20<5:34:53,  9.58s/it]                                                         {'loss': 0.8765, 'learning_rate': 2.0595959853293233e-06, 'epoch': 0.8}
 80%|███████▉  | 8298/10395 [23:42:20<5:34:53,  9.58s/it] 80%|███████▉  | 8299/10395 [23:42:27<5:12:31,  8.95s/it]                                                         {'loss': 0.8803, 'learning_rate': 2.057702426344057e-06, 'epoch': 0.8}
 80%|███████▉  | 8299/10395 [23:42:27<5:12:31,  8.95s/it] 80%|███████▉  | 8300/10395 [23:42:36<5:08:01,  8.82s/it]                                                         {'loss': 0.8449, 'learning_rate': 2.0558096383800653e-06, 'epoch': 0.8}
 80%|███████▉  | 8300/10395 [23:42:36<5:08:01,  8.82s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 80%|███████▉  | 8301/10395 [23:44:16<21:08:43, 36.35s/it]                                                          {'loss': 0.8869, 'learning_rate': 2.0539176216210986e-06, 'epoch': 0.8}
 80%|███████▉  | 8301/10395 [23:44:16<21:08:43, 36.35s/it] 80%|███████▉  | 8302/10395 [23:44:24<16:04:08, 27.64s/it]                                                          {'loss': 0.7868, 'learning_rate': 2.0520263762508263e-06, 'epoch': 0.8}
 80%|███████▉  | 8302/10395 [23:44:24<16:04:08, 27.64s/it] 80%|███████▉  | 8303/10395 [23:44:31<12:34:27, 21.64s/it]                                                          {'loss': 0.7657, 'learning_rate': 2.0501359024528476e-06, 'epoch': 0.8}
 80%|███████▉  | 8303/10395 [23:44:31<12:34:27, 21.64s/it] 80%|███████▉  | 8304/10395 [23:44:40<10:18:23, 17.74s/it]                                                          {'loss': 0.87, 'learning_rate': 2.0482462004106895e-06, 'epoch': 0.8}
 80%|███████▉  | 8304/10395 [23:44:40<10:18:23, 17.74s/it] 80%|███████▉  | 8305/10395 [23:44:48<8:34:43, 14.78s/it]                                                          {'loss': 0.8669, 'learning_rate': 2.0463572703077984e-06, 'epoch': 0.8}
 80%|███████▉  | 8305/10395 [23:44:48<8:34:43, 14.78s/it] 80%|███████▉  | 8306/10395 [23:44:57<7:33:20, 13.02s/it]                                                         {'loss': 0.8607, 'learning_rate': 2.044469112327543e-06, 'epoch': 0.8}
 80%|███████▉  | 8306/10395 [23:44:57<7:33:20, 13.02s/it] 80%|███████▉  | 8307/10395 [23:45:05<6:48:45, 11.75s/it]                                                         {'loss': 0.8405, 'learning_rate': 2.0425817266532277e-06, 'epoch': 0.8}
 80%|███████▉  | 8307/10395 [23:45:05<6:48:45, 11.75s/it] 80%|███████▉  | 8308/10395 [23:45:13<6:07:19, 10.56s/it]                                                         {'loss': 0.8413, 'learning_rate': 2.040695113468071e-06, 'epoch': 0.8}
 80%|███████▉  | 8308/10395 [23:45:13<6:07:19, 10.56s/it] 80%|███████▉  | 8309/10395 [23:45:21<5:39:45,  9.77s/it]                                                         {'loss': 0.8475, 'learning_rate': 2.0388092729552258e-06, 'epoch': 0.8}
 80%|███████▉  | 8309/10395 [23:45:21<5:39:45,  9.77s/it] 80%|███████▉  | 8310/10395 [23:45:28<5:11:52,  8.97s/it]                                                         {'loss': 0.9005, 'learning_rate': 2.0369242052977613e-06, 'epoch': 0.8}
 80%|███████▉  | 8310/10395 [23:45:28<5:11:52,  8.97s/it] 80%|███████▉  | 8311/10395 [23:45:37<5:10:05,  8.93s/it]                                                         {'loss': 0.8959, 'learning_rate': 2.035039910678677e-06, 'epoch': 0.8}
 80%|███████▉  | 8311/10395 [23:45:37<5:10:05,  8.93s/it] 80%|███████▉  | 8312/10395 [23:45:45<5:02:40,  8.72s/it]                                                         {'loss': 0.8509, 'learning_rate': 2.0331563892809023e-06, 'epoch': 0.8}
 80%|███████▉  | 8312/10395 [23:45:45<5:02:40,  8.72s/it] 80%|███████▉  | 8313/10395 [23:45:55<5:09:38,  8.92s/it]                                                         {'loss': 0.8019, 'learning_rate': 2.031273641287276e-06, 'epoch': 0.8}
 80%|███████▉  | 8313/10395 [23:45:55<5:09:38,  8.92s/it] 80%|███████▉  | 8314/10395 [23:46:02<4:54:29,  8.49s/it]                                                         {'loss': 0.9353, 'learning_rate': 2.0293916668805747e-06, 'epoch': 0.8}
 80%|███████▉  | 8314/10395 [23:46:02<4:54:29,  8.49s/it] 80%|███████▉  | 8315/10395 [23:46:10<4:46:34,  8.27s/it]                                                         {'loss': 0.8796, 'learning_rate': 2.0275104662434997e-06, 'epoch': 0.8}
 80%|███████▉  | 8315/10395 [23:46:10<4:46:34,  8.27s/it] 80%|████████  | 8316/10395 [23:46:17<4:36:45,  7.99s/it]                                                         {'loss': 0.823, 'learning_rate': 2.025630039558668e-06, 'epoch': 0.8}
 80%|████████  | 8316/10395 [23:46:17<4:36:45,  7.99s/it] 80%|████████  | 8317/10395 [23:46:25<4:31:08,  7.83s/it]                                                         {'loss': 0.8743, 'learning_rate': 2.023750387008634e-06, 'epoch': 0.8}
 80%|████████  | 8317/10395 [23:46:25<4:31:08,  7.83s/it] 80%|████████  | 8318/10395 [23:46:32<4:28:01,  7.74s/it]                                                         {'loss': 0.8863, 'learning_rate': 2.0218715087758657e-06, 'epoch': 0.8}
 80%|████████  | 8318/10395 [23:46:32<4:28:01,  7.74s/it] 80%|████████  | 8319/10395 [23:46:40<4:27:49,  7.74s/it]                                                         {'loss': 0.882, 'learning_rate': 2.0199934050427627e-06, 'epoch': 0.8}
 80%|████████  | 8319/10395 [23:46:40<4:27:49,  7.74s/it] 80%|████████  | 8320/10395 [23:46:48<4:33:59,  7.92s/it]                                                         {'loss': 0.8384, 'learning_rate': 2.0181160759916475e-06, 'epoch': 0.8}
 80%|████████  | 8320/10395 [23:46:48<4:33:59,  7.92s/it] 80%|████████  | 8321/10395 [23:46:56<4:33:38,  7.92s/it]                                                         {'loss': 0.8565, 'learning_rate': 2.016239521804764e-06, 'epoch': 0.8}
 80%|████████  | 8321/10395 [23:46:56<4:33:38,  7.92s/it] 80%|████████  | 8322/10395 [23:47:04<4:33:21,  7.91s/it]                                                         {'loss': 0.8404, 'learning_rate': 2.0143637426642857e-06, 'epoch': 0.8}
 80%|████████  | 8322/10395 [23:47:04<4:33:21,  7.91s/it] 80%|████████  | 8323/10395 [23:47:12<4:30:50,  7.84s/it]                                                         {'loss': 0.8379, 'learning_rate': 2.012488738752313e-06, 'epoch': 0.8}
 80%|████████  | 8323/10395 [23:47:12<4:30:50,  7.84s/it] 80%|████████  | 8324/10395 [23:47:20<4:30:29,  7.84s/it]                                                         {'loss': 0.7715, 'learning_rate': 2.0106145102508613e-06, 'epoch': 0.8}
 80%|████████  | 8324/10395 [23:47:20<4:30:29,  7.84s/it] 80%|████████  | 8325/10395 [23:47:28<4:30:14,  7.83s/it]                                                         {'loss': 0.8517, 'learning_rate': 2.008741057341882e-06, 'epoch': 0.8}
 80%|████████  | 8325/10395 [23:47:28<4:30:14,  7.83s/it] 80%|████████  | 8326/10395 [23:47:37<4:42:54,  8.20s/it]                                                         {'loss': 0.9128, 'learning_rate': 2.006868380207242e-06, 'epoch': 0.8}
 80%|████████  | 8326/10395 [23:47:37<4:42:54,  8.20s/it] 80%|████████  | 8327/10395 [23:47:45<4:43:34,  8.23s/it]                                                         {'loss': 0.845, 'learning_rate': 2.004996479028739e-06, 'epoch': 0.8}
 80%|████████  | 8327/10395 [23:47:45<4:43:34,  8.23s/it] 80%|████████  | 8328/10395 [23:47:53<4:46:08,  8.31s/it]                                                         {'loss': 0.8876, 'learning_rate': 2.0031253539880935e-06, 'epoch': 0.8}
 80%|████████  | 8328/10395 [23:47:53<4:46:08,  8.31s/it] 80%|████████  | 8329/10395 [23:48:00<4:32:49,  7.92s/it]                                                         {'loss': 0.9286, 'learning_rate': 2.0012550052669466e-06, 'epoch': 0.8}
 80%|████████  | 8329/10395 [23:48:00<4:32:49,  7.92s/it] 80%|████████  | 8330/10395 [23:48:08<4:31:06,  7.88s/it]                                                         {'loss': 0.8613, 'learning_rate': 1.999385433046871e-06, 'epoch': 0.8}
 80%|████████  | 8330/10395 [23:48:08<4:31:06,  7.88s/it] 80%|████████  | 8331/10395 [23:48:16<4:26:41,  7.75s/it]                                                         {'loss': 0.9256, 'learning_rate': 1.9975166375093625e-06, 'epoch': 0.8}
 80%|████████  | 8331/10395 [23:48:16<4:26:41,  7.75s/it] 80%|████████  | 8332/10395 [23:48:24<4:29:10,  7.83s/it]                                                         {'loss': 0.9022, 'learning_rate': 1.995648618835834e-06, 'epoch': 0.8}
 80%|████████  | 8332/10395 [23:48:24<4:29:10,  7.83s/it] 80%|████████  | 8333/10395 [23:48:31<4:25:21,  7.72s/it]                                                         {'loss': 0.8651, 'learning_rate': 1.9937813772076353e-06, 'epoch': 0.8}
 80%|████████  | 8333/10395 [23:48:31<4:25:21,  7.72s/it] 80%|████████  | 8334/10395 [23:48:38<4:18:55,  7.54s/it]                                                         {'loss': 0.9309, 'learning_rate': 1.9919149128060313e-06, 'epoch': 0.8}
 80%|████████  | 8334/10395 [23:48:38<4:18:55,  7.54s/it] 80%|████████  | 8335/10395 [23:48:46<4:18:05,  7.52s/it]                                                         {'loss': 0.864, 'learning_rate': 1.9900492258122116e-06, 'epoch': 0.8}
 80%|████████  | 8335/10395 [23:48:46<4:18:05,  7.52s/it] 80%|████████  | 8336/10395 [23:48:54<4:27:44,  7.80s/it]                                                         {'loss': 0.903, 'learning_rate': 1.9881843164072955e-06, 'epoch': 0.8}
 80%|████████  | 8336/10395 [23:48:54<4:27:44,  7.80s/it] 80%|████████  | 8337/10395 [23:49:02<4:33:01,  7.96s/it]                                                         {'loss': 0.8227, 'learning_rate': 1.986320184772328e-06, 'epoch': 0.8}
 80%|████████  | 8337/10395 [23:49:03<4:33:01,  7.96s/it] 80%|████████  | 8338/10395 [23:49:20<6:12:48, 10.87s/it]                                                         {'loss': 0.3645, 'learning_rate': 1.9844568310882685e-06, 'epoch': 0.8}
 80%|████████  | 8338/10395 [23:49:20<6:12:48, 10.87s/it] 80%|████████  | 8339/10395 [23:49:29<5:54:29, 10.34s/it]                                                         {'loss': 0.8225, 'learning_rate': 1.9825942555360134e-06, 'epoch': 0.8}
 80%|████████  | 8339/10395 [23:49:29<5:54:29, 10.34s/it] 80%|████████  | 8340/10395 [23:49:37<5:25:24,  9.50s/it]                                                         {'loss': 0.8605, 'learning_rate': 1.9807324582963715e-06, 'epoch': 0.8}
 80%|████████  | 8340/10395 [23:49:37<5:25:24,  9.50s/it] 80%|████████  | 8341/10395 [23:49:45<5:09:03,  9.03s/it]                                                         {'loss': 0.8162, 'learning_rate': 1.9788714395500887e-06, 'epoch': 0.8}
 80%|████████  | 8341/10395 [23:49:45<5:09:03,  9.03s/it] 80%|████████  | 8342/10395 [23:49:53<4:56:15,  8.66s/it]                                                         {'loss': 0.8579, 'learning_rate': 1.977011199477825e-06, 'epoch': 0.8}
 80%|████████  | 8342/10395 [23:49:53<4:56:15,  8.66s/it] 80%|████████  | 8343/10395 [23:50:00<4:43:16,  8.28s/it]                                                         {'loss': 0.8376, 'learning_rate': 1.975151738260166e-06, 'epoch': 0.8}
 80%|████████  | 8343/10395 [23:50:00<4:43:16,  8.28s/it] 80%|████████  | 8344/10395 [23:50:08<4:37:01,  8.10s/it]                                                         {'loss': 0.8531, 'learning_rate': 1.9732930560776276e-06, 'epoch': 0.8}
 80%|████████  | 8344/10395 [23:50:08<4:37:01,  8.10s/it] 80%|████████  | 8345/10395 [23:50:16<4:35:26,  8.06s/it]                                                         {'loss': 0.8778, 'learning_rate': 1.9714351531106477e-06, 'epoch': 0.8}
 80%|████████  | 8345/10395 [23:50:16<4:35:26,  8.06s/it] 80%|████████  | 8346/10395 [23:50:23<4:31:33,  7.95s/it]                                                         {'loss': 0.8624, 'learning_rate': 1.969578029539585e-06, 'epoch': 0.8}
 80%|████████  | 8346/10395 [23:50:23<4:31:33,  7.95s/it] 80%|████████  | 8347/10395 [23:50:31<4:31:50,  7.96s/it]                                                         {'loss': 0.9078, 'learning_rate': 1.9677216855447278e-06, 'epoch': 0.8}
 80%|████████  | 8347/10395 [23:50:31<4:31:50,  7.96s/it] 80%|████████  | 8348/10395 [23:50:39<4:27:01,  7.83s/it]                                                         {'loss': 0.8111, 'learning_rate': 1.965866121306281e-06, 'epoch': 0.8}
 80%|████████  | 8348/10395 [23:50:39<4:27:01,  7.83s/it] 80%|████████  | 8349/10395 [23:50:46<4:19:53,  7.62s/it]                                                         {'loss': 0.9167, 'learning_rate': 1.964011337004387e-06, 'epoch': 0.8}
 80%|████████  | 8349/10395 [23:50:46<4:19:53,  7.62s/it] 80%|████████  | 8350/10395 [23:50:53<4:19:08,  7.60s/it]                                                         {'loss': 0.9065, 'learning_rate': 1.962157332819098e-06, 'epoch': 0.8}
 80%|████████  | 8350/10395 [23:50:53<4:19:08,  7.60s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 80%|████████  | 8351/10395 [23:52:32<19:46:30, 34.83s/it]                                                          {'loss': 0.8909, 'learning_rate': 1.960304108930395e-06, 'epoch': 0.8}
 80%|████████  | 8351/10395 [23:52:32<19:46:30, 34.83s/it] 80%|████████  | 8352/10395 [23:52:49<16:49:39, 29.65s/it]                                                          {'loss': 0.3464, 'learning_rate': 1.9584516655181896e-06, 'epoch': 0.8}
 80%|████████  | 8352/10395 [23:52:49<16:49:39, 29.65s/it] 80%|████████  | 8353/10395 [23:52:58<13:12:20, 23.28s/it]                                                          {'loss': 0.8339, 'learning_rate': 1.9566000027623134e-06, 'epoch': 0.8}
 80%|████████  | 8353/10395 [23:52:58<13:12:20, 23.28s/it] 80%|████████  | 8354/10395 [23:53:05<10:31:25, 18.56s/it]                                                          {'loss': 0.8458, 'learning_rate': 1.9547491208425174e-06, 'epoch': 0.8}
 80%|████████  | 8354/10395 [23:53:05<10:31:25, 18.56s/it]WARNING: tokenization mismatch: 1 vs. 70. (ignored)
 80%|████████  | 8355/10395 [23:53:13<8:36:29, 15.19s/it]                                                          {'loss': 0.8773, 'learning_rate': 1.9528990199384866e-06, 'epoch': 0.8}
 80%|████████  | 8355/10395 [23:53:13<8:36:29, 15.19s/it] 80%|████████  | 8356/10395 [23:53:21<7:24:19, 13.07s/it]                                                         {'loss': 0.9185, 'learning_rate': 1.9510497002298224e-06, 'epoch': 0.8}
 80%|████████  | 8356/10395 [23:53:21<7:24:19, 13.07s/it] 80%|████████  | 8357/10395 [23:53:29<6:34:56, 11.63s/it]                                                         {'loss': 0.8573, 'learning_rate': 1.9492011618960505e-06, 'epoch': 0.8}
 80%|████████  | 8357/10395 [23:53:29<6:34:56, 11.63s/it] 80%|████████  | 8358/10395 [23:53:36<5:49:54, 10.31s/it]                                                         {'loss': 0.9661, 'learning_rate': 1.9473534051166276e-06, 'epoch': 0.8}
 80%|████████  | 8358/10395 [23:53:36<5:49:54, 10.31s/it] 80%|████████  | 8359/10395 [23:53:44<5:22:21,  9.50s/it]                                                         {'loss': 0.7751, 'learning_rate': 1.9455064300709247e-06, 'epoch': 0.8}
 80%|████████  | 8359/10395 [23:53:44<5:22:21,  9.50s/it] 80%|████████  | 8360/10395 [23:53:51<5:02:18,  8.91s/it]                                                         {'loss': 0.8734, 'learning_rate': 1.943660236938245e-06, 'epoch': 0.8}
 80%|████████  | 8360/10395 [23:53:51<5:02:18,  8.91s/it] 80%|████████  | 8361/10395 [23:54:00<5:01:43,  8.90s/it]                                                         {'loss': 0.8253, 'learning_rate': 1.9418148258978165e-06, 'epoch': 0.8}
 80%|████████  | 8361/10395 [23:54:00<5:01:43,  8.90s/it] 80%|████████  | 8362/10395 [23:54:09<4:56:14,  8.74s/it]                                                         {'loss': 0.9123, 'learning_rate': 1.939970197128781e-06, 'epoch': 0.8}
 80%|████████  | 8362/10395 [23:54:09<4:56:14,  8.74s/it] 80%|████████  | 8363/10395 [23:54:16<4:45:05,  8.42s/it]                                                         {'loss': 0.908, 'learning_rate': 1.9381263508102164e-06, 'epoch': 0.8}
 80%|████████  | 8363/10395 [23:54:16<4:45:05,  8.42s/it] 80%|████████  | 8364/10395 [23:54:24<4:39:45,  8.26s/it]                                                         {'loss': 0.8309, 'learning_rate': 1.9362832871211177e-06, 'epoch': 0.8}
 80%|████████  | 8364/10395 [23:54:24<4:39:45,  8.26s/it] 80%|████████  | 8365/10395 [23:54:33<4:40:05,  8.28s/it]                                                         {'loss': 0.8527, 'learning_rate': 1.934441006240404e-06, 'epoch': 0.8}
 80%|████████  | 8365/10395 [23:54:33<4:40:05,  8.28s/it] 80%|████████  | 8366/10395 [23:54:42<4:48:05,  8.52s/it]                                                         {'loss': 0.8719, 'learning_rate': 1.9325995083469217e-06, 'epoch': 0.8}
 80%|████████  | 8366/10395 [23:54:42<4:48:05,  8.52s/it] 80%|████████  | 8367/10395 [23:54:49<4:39:20,  8.26s/it]                                                         {'loss': 0.8766, 'learning_rate': 1.9307587936194383e-06, 'epoch': 0.8}
 80%|████████  | 8367/10395 [23:54:49<4:39:20,  8.26s/it] 81%|████████  | 8368/10395 [23:54:57<4:30:02,  7.99s/it]                                                         {'loss': 0.9447, 'learning_rate': 1.928918862236646e-06, 'epoch': 0.8}
 81%|████████  | 8368/10395 [23:54:57<4:30:02,  7.99s/it] 81%|████████  | 8369/10395 [23:55:04<4:27:16,  7.92s/it]                                                         {'loss': 0.9312, 'learning_rate': 1.9270797143771656e-06, 'epoch': 0.81}
 81%|████████  | 8369/10395 [23:55:04<4:27:16,  7.92s/it] 81%|████████  | 8370/10395 [23:55:12<4:27:35,  7.93s/it]                                                         {'loss': 0.8272, 'learning_rate': 1.9252413502195324e-06, 'epoch': 0.81}
 81%|████████  | 8370/10395 [23:55:12<4:27:35,  7.93s/it] 81%|████████  | 8371/10395 [23:55:20<4:22:04,  7.77s/it]                                                         {'loss': 0.8448, 'learning_rate': 1.923403769942216e-06, 'epoch': 0.81}
 81%|████████  | 8371/10395 [23:55:20<4:22:04,  7.77s/it] 81%|████████  | 8372/10395 [23:55:37<5:54:21, 10.51s/it]                                                         {'loss': 0.4185, 'learning_rate': 1.921566973723601e-06, 'epoch': 0.81}
 81%|████████  | 8372/10395 [23:55:37<5:54:21, 10.51s/it] 81%|████████  | 8373/10395 [23:55:44<5:22:01,  9.56s/it]                                                         {'loss': 0.8434, 'learning_rate': 1.919730961741998e-06, 'epoch': 0.81}
 81%|████████  | 8373/10395 [23:55:44<5:22:01,  9.56s/it] 81%|████████  | 8374/10395 [23:56:02<6:51:45, 12.22s/it]                                                         {'loss': 0.3515, 'learning_rate': 1.9178957341756487e-06, 'epoch': 0.81}
 81%|████████  | 8374/10395 [23:56:02<6:51:45, 12.22s/it] 81%|████████  | 8375/10395 [23:56:11<6:11:47, 11.04s/it]                                                         {'loss': 0.9227, 'learning_rate': 1.9160612912027065e-06, 'epoch': 0.81}
 81%|████████  | 8375/10395 [23:56:11<6:11:47, 11.04s/it] 81%|████████  | 8376/10395 [23:56:18<5:36:04,  9.99s/it]                                                         {'loss': 0.8724, 'learning_rate': 1.91422763300126e-06, 'epoch': 0.81}
 81%|████████  | 8376/10395 [23:56:18<5:36:04,  9.99s/it] 81%|████████  | 8377/10395 [23:56:26<5:10:05,  9.22s/it]                                                         {'loss': 0.871, 'learning_rate': 1.9123947597493174e-06, 'epoch': 0.81}
 81%|████████  | 8377/10395 [23:56:26<5:10:05,  9.22s/it] 81%|████████  | 8378/10395 [23:56:35<5:13:39,  9.33s/it]                                                         {'loss': 0.8539, 'learning_rate': 1.910562671624808e-06, 'epoch': 0.81}
 81%|████████  | 8378/10395 [23:56:35<5:13:39,  9.33s/it] 81%|████████  | 8379/10395 [23:56:43<4:57:19,  8.85s/it]                                                         {'loss': 0.9415, 'learning_rate': 1.9087313688055854e-06, 'epoch': 0.81}
 81%|████████  | 8379/10395 [23:56:43<4:57:19,  8.85s/it] 81%|████████  | 8380/10395 [23:56:51<4:43:18,  8.44s/it]                                                         {'loss': 0.8819, 'learning_rate': 1.9069008514694321e-06, 'epoch': 0.81}
 81%|████████  | 8380/10395 [23:56:51<4:43:18,  8.44s/it] 81%|████████  | 8381/10395 [23:56:58<4:33:29,  8.15s/it]                                                         {'loss': 0.8529, 'learning_rate': 1.9050711197940474e-06, 'epoch': 0.81}
 81%|████████  | 8381/10395 [23:56:58<4:33:29,  8.15s/it] 81%|████████  | 8382/10395 [23:57:07<4:39:02,  8.32s/it]                                                         {'loss': 0.8608, 'learning_rate': 1.9032421739570617e-06, 'epoch': 0.81}
 81%|████████  | 8382/10395 [23:57:07<4:39:02,  8.32s/it] 81%|████████  | 8383/10395 [23:57:15<4:43:39,  8.46s/it]                                                         {'loss': 0.9285, 'learning_rate': 1.9014140141360205e-06, 'epoch': 0.81}
 81%|████████  | 8383/10395 [23:57:15<4:43:39,  8.46s/it] 81%|████████  | 8384/10395 [23:57:24<4:39:00,  8.32s/it]                                                         {'loss': 0.8606, 'learning_rate': 1.8995866405083996e-06, 'epoch': 0.81}
 81%|████████  | 8384/10395 [23:57:24<4:39:00,  8.32s/it] 81%|████████  | 8385/10395 [23:57:32<4:37:10,  8.27s/it]                                                         {'loss': 0.9103, 'learning_rate': 1.8977600532516004e-06, 'epoch': 0.81}
 81%|████████  | 8385/10395 [23:57:32<4:37:10,  8.27s/it] 81%|████████  | 8386/10395 [23:57:39<4:31:19,  8.10s/it]                                                         {'loss': 0.8089, 'learning_rate': 1.8959342525429404e-06, 'epoch': 0.81}
 81%|████████  | 8386/10395 [23:57:39<4:31:19,  8.10s/it] 81%|████████  | 8387/10395 [23:57:48<4:39:23,  8.35s/it]                                                         {'loss': 0.8854, 'learning_rate': 1.8941092385596616e-06, 'epoch': 0.81}
 81%|████████  | 8387/10395 [23:57:48<4:39:23,  8.35s/it] 81%|████████  | 8388/10395 [23:57:57<4:39:06,  8.34s/it]                                                         {'loss': 0.8052, 'learning_rate': 1.892285011478938e-06, 'epoch': 0.81}
 81%|████████  | 8388/10395 [23:57:57<4:39:06,  8.34s/it] 81%|████████  | 8389/10395 [23:58:05<4:40:13,  8.38s/it]                                                         {'loss': 0.8018, 'learning_rate': 1.8904615714778574e-06, 'epoch': 0.81}
 81%|████████  | 8389/10395 [23:58:05<4:40:13,  8.38s/it] 81%|████████  | 8390/10395 [23:58:13<4:34:13,  8.21s/it]                                                         {'loss': 0.8431, 'learning_rate': 1.8886389187334398e-06, 'epoch': 0.81}
 81%|████████  | 8390/10395 [23:58:13<4:34:13,  8.21s/it] 81%|████████  | 8391/10395 [23:58:23<4:50:07,  8.69s/it]                                                         {'loss': 0.8496, 'learning_rate': 1.8868170534226193e-06, 'epoch': 0.81}
 81%|████████  | 8391/10395 [23:58:23<4:50:07,  8.69s/it] 81%|████████  | 8392/10395 [23:58:32<4:51:18,  8.73s/it]                                                         {'loss': 0.8785, 'learning_rate': 1.8849959757222613e-06, 'epoch': 0.81}
 81%|████████  | 8392/10395 [23:58:32<4:51:18,  8.73s/it] 81%|████████  | 8393/10395 [23:58:39<4:37:11,  8.31s/it]                                                         {'loss': 0.9037, 'learning_rate': 1.8831756858091566e-06, 'epoch': 0.81}
 81%|████████  | 8393/10395 [23:58:39<4:37:11,  8.31s/it] 81%|████████  | 8394/10395 [23:58:46<4:28:43,  8.06s/it]                                                         {'loss': 0.8482, 'learning_rate': 1.8813561838600058e-06, 'epoch': 0.81}
 81%|████████  | 8394/10395 [23:58:46<4:28:43,  8.06s/it] 81%|████████  | 8395/10395 [23:58:54<4:26:07,  7.98s/it]                                                         {'loss': 0.9199, 'learning_rate': 1.8795374700514479e-06, 'epoch': 0.81}
 81%|████████  | 8395/10395 [23:58:54<4:26:07,  7.98s/it] 81%|████████  | 8396/10395 [23:59:02<4:20:54,  7.83s/it]                                                         {'loss': 0.921, 'learning_rate': 1.8777195445600404e-06, 'epoch': 0.81}
 81%|████████  | 8396/10395 [23:59:02<4:20:54,  7.83s/it] 81%|████████  | 8397/10395 [23:59:09<4:17:00,  7.72s/it]                                                         {'loss': 0.8256, 'learning_rate': 1.87590240756226e-06, 'epoch': 0.81}
 81%|████████  | 8397/10395 [23:59:09<4:17:00,  7.72s/it] 81%|████████  | 8398/10395 [23:59:17<4:16:31,  7.71s/it]                                                         {'loss': 0.8604, 'learning_rate': 1.8740860592345156e-06, 'epoch': 0.81}
 81%|████████  | 8398/10395 [23:59:17<4:16:31,  7.71s/it] 81%|████████  | 8399/10395 [23:59:24<4:15:50,  7.69s/it]                                                         {'loss': 0.7913, 'learning_rate': 1.8722704997531282e-06, 'epoch': 0.81}
 81%|████████  | 8399/10395 [23:59:24<4:15:50,  7.69s/it] 81%|████████  | 8400/10395 [23:59:33<4:22:13,  7.89s/it]                                                         {'loss': 0.885, 'learning_rate': 1.870455729294355e-06, 'epoch': 0.81}
 81%|████████  | 8400/10395 [23:59:33<4:22:13,  7.89s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 81%|████████  | 8401/10395 [24:01:11<19:27:10, 35.12s/it]                                                          {'loss': 0.8581, 'learning_rate': 1.8686417480343633e-06, 'epoch': 0.81}
 81%|████████  | 8401/10395 [24:01:11<19:27:10, 35.12s/it] 81%|████████  | 8402/10395 [24:01:19<14:51:51, 26.85s/it]                                                          {'loss': 0.861, 'learning_rate': 1.8668285561492573e-06, 'epoch': 0.81}
 81%|████████  | 8402/10395 [24:01:19<14:51:51, 26.85s/it] 81%|████████  | 8403/10395 [24:01:27<11:39:15, 21.06s/it]                                                          {'loss': 0.8148, 'learning_rate': 1.8650161538150513e-06, 'epoch': 0.81}
 81%|████████  | 8403/10395 [24:01:27<11:39:15, 21.06s/it] 81%|████████  | 8404/10395 [24:01:35<9:29:38, 17.17s/it]                                                          {'loss': 0.8226, 'learning_rate': 1.863204541207696e-06, 'epoch': 0.81}
 81%|████████  | 8404/10395 [24:01:35<9:29:38, 17.17s/it] 81%|████████  | 8405/10395 [24:01:42<7:52:29, 14.25s/it]                                                         {'loss': 0.8481, 'learning_rate': 1.8613937185030518e-06, 'epoch': 0.81}
 81%|████████  | 8405/10395 [24:01:42<7:52:29, 14.25s/it] 81%|████████  | 8406/10395 [24:01:50<6:48:02, 12.31s/it]                                                         {'loss': 0.9081, 'learning_rate': 1.8595836858769135e-06, 'epoch': 0.81}
 81%|████████  | 8406/10395 [24:01:50<6:48:02, 12.31s/it] 81%|████████  | 8407/10395 [24:01:57<5:57:18, 10.78s/it]                                                         {'loss': 0.8697, 'learning_rate': 1.8577744435049972e-06, 'epoch': 0.81}
 81%|████████  | 8407/10395 [24:01:57<5:57:18, 10.78s/it] 81%|████████  | 8408/10395 [24:02:05<5:24:44,  9.81s/it]                                                         {'loss': 0.9643, 'learning_rate': 1.855965991562938e-06, 'epoch': 0.81}
 81%|████████  | 8408/10395 [24:02:05<5:24:44,  9.81s/it] 81%|████████  | 8409/10395 [24:02:21<6:27:51, 11.72s/it]                                                         {'loss': 0.3373, 'learning_rate': 1.8541583302262944e-06, 'epoch': 0.81}
 81%|████████  | 8409/10395 [24:02:21<6:27:51, 11.72s/it] 81%|████████  | 8410/10395 [24:02:28<5:47:49, 10.51s/it]                                                         {'loss': 0.8841, 'learning_rate': 1.852351459670555e-06, 'epoch': 0.81}
 81%|████████  | 8410/10395 [24:02:28<5:47:49, 10.51s/it] 81%|████████  | 8411/10395 [24:02:46<6:56:22, 12.59s/it]                                                         {'loss': 0.4046, 'learning_rate': 1.8505453800711215e-06, 'epoch': 0.81}
 81%|████████  | 8411/10395 [24:02:46<6:56:22, 12.59s/it] 81%|████████  | 8412/10395 [24:02:53<6:06:15, 11.08s/it]                                                         {'loss': 0.8968, 'learning_rate': 1.8487400916033293e-06, 'epoch': 0.81}
 81%|████████  | 8412/10395 [24:02:53<6:06:15, 11.08s/it] 81%|████████  | 8413/10395 [24:03:01<5:34:43, 10.13s/it]                                                         {'loss': 0.8969, 'learning_rate': 1.8469355944424271e-06, 'epoch': 0.81}
 81%|████████  | 8413/10395 [24:03:01<5:34:43, 10.13s/it] 81%|████████  | 8414/10395 [24:03:10<5:16:37,  9.59s/it]                                                         {'loss': 0.8526, 'learning_rate': 1.8451318887635949e-06, 'epoch': 0.81}
 81%|████████  | 8414/10395 [24:03:10<5:16:37,  9.59s/it] 81%|████████  | 8415/10395 [24:03:17<4:57:01,  9.00s/it]                                                         {'loss': 0.9148, 'learning_rate': 1.843328974741936e-06, 'epoch': 0.81}
 81%|████████  | 8415/10395 [24:03:17<4:57:01,  9.00s/it] 81%|████████  | 8416/10395 [24:03:24<4:38:36,  8.45s/it]                                                         {'loss': 0.9068, 'learning_rate': 1.8415268525524654e-06, 'epoch': 0.81}
 81%|████████  | 8416/10395 [24:03:24<4:38:36,  8.45s/it] 81%|████████  | 8417/10395 [24:03:33<4:44:10,  8.62s/it]                                                         {'loss': 0.8565, 'learning_rate': 1.8397255223701326e-06, 'epoch': 0.81}
 81%|████████  | 8417/10395 [24:03:33<4:44:10,  8.62s/it] 81%|████████  | 8418/10395 [24:03:42<4:46:02,  8.68s/it]                                                         {'loss': 0.8331, 'learning_rate': 1.83792498436981e-06, 'epoch': 0.81}
 81%|████████  | 8418/10395 [24:03:42<4:46:02,  8.68s/it] 81%|████████  | 8419/10395 [24:03:50<4:39:26,  8.49s/it]                                                         {'loss': 0.8107, 'learning_rate': 1.8361252387262852e-06, 'epoch': 0.81}
 81%|████████  | 8419/10395 [24:03:50<4:39:26,  8.49s/it] 81%|████████  | 8420/10395 [24:03:58<4:33:07,  8.30s/it]                                                         {'loss': 0.817, 'learning_rate': 1.8343262856142786e-06, 'epoch': 0.81}
 81%|████████  | 8420/10395 [24:03:58<4:33:07,  8.30s/it] 81%|████████  | 8421/10395 [24:04:06<4:23:34,  8.01s/it]                                                         {'loss': 0.892, 'learning_rate': 1.8325281252084238e-06, 'epoch': 0.81}
 81%|████████  | 8421/10395 [24:04:06<4:23:34,  8.01s/it] 81%|████████  | 8422/10395 [24:04:13<4:14:46,  7.75s/it]                                                         {'loss': 0.9227, 'learning_rate': 1.8307307576832866e-06, 'epoch': 0.81}
 81%|████████  | 8422/10395 [24:04:13<4:14:46,  7.75s/it] 81%|████████  | 8423/10395 [24:04:21<4:24:09,  8.04s/it]                                                         {'loss': 0.8061, 'learning_rate': 1.82893418321335e-06, 'epoch': 0.81}
 81%|████████  | 8423/10395 [24:04:21<4:24:09,  8.04s/it] 81%|████████  | 8424/10395 [24:04:29<4:19:13,  7.89s/it]                                                         {'loss': 0.8564, 'learning_rate': 1.8271384019730186e-06, 'epoch': 0.81}
 81%|████████  | 8424/10395 [24:04:29<4:19:13,  7.89s/it] 81%|████████  | 8425/10395 [24:04:37<4:18:50,  7.88s/it]                                                         {'loss': 0.8388, 'learning_rate': 1.8253434141366256e-06, 'epoch': 0.81}
 81%|████████  | 8425/10395 [24:04:37<4:18:50,  7.88s/it] 81%|████████  | 8426/10395 [24:04:44<4:15:49,  7.80s/it]                                                         {'loss': 0.8804, 'learning_rate': 1.8235492198784267e-06, 'epoch': 0.81}
 81%|████████  | 8426/10395 [24:04:44<4:15:49,  7.80s/it] 81%|████████  | 8427/10395 [24:04:52<4:16:08,  7.81s/it]                                                         {'loss': 0.9636, 'learning_rate': 1.8217558193725948e-06, 'epoch': 0.81}
 81%|████████  | 8427/10395 [24:04:52<4:16:08,  7.81s/it] 81%|████████  | 8428/10395 [24:05:00<4:13:09,  7.72s/it]                                                         {'loss': 0.8008, 'learning_rate': 1.8199632127932331e-06, 'epoch': 0.81}
 81%|████████  | 8428/10395 [24:05:00<4:13:09,  7.72s/it] 81%|████████  | 8429/10395 [24:05:08<4:18:03,  7.88s/it]                                                         {'loss': 0.8732, 'learning_rate': 1.8181714003143592e-06, 'epoch': 0.81}
 81%|████████  | 8429/10395 [24:05:08<4:18:03,  7.88s/it] 81%|████████  | 8430/10395 [24:05:15<4:13:15,  7.73s/it]                                                         {'loss': 0.8479, 'learning_rate': 1.8163803821099236e-06, 'epoch': 0.81}
 81%|████████  | 8430/10395 [24:05:15<4:13:15,  7.73s/it] 81%|████████  | 8431/10395 [24:05:23<4:08:22,  7.59s/it]                                                         {'loss': 0.8498, 'learning_rate': 1.8145901583537928e-06, 'epoch': 0.81}
 81%|████████  | 8431/10395 [24:05:23<4:08:22,  7.59s/it] 81%|████████  | 8432/10395 [24:05:30<4:06:05,  7.52s/it]                                                         {'loss': 0.8784, 'learning_rate': 1.8128007292197536e-06, 'epoch': 0.81}
 81%|████████  | 8432/10395 [24:05:30<4:06:05,  7.52s/it] 81%|████████  | 8433/10395 [24:05:37<4:04:16,  7.47s/it]                                                         {'loss': 0.9112, 'learning_rate': 1.8110120948815247e-06, 'epoch': 0.81}
 81%|████████  | 8433/10395 [24:05:37<4:04:16,  7.47s/it] 81%|████████  | 8434/10395 [24:05:45<4:05:28,  7.51s/it]                                                         {'loss': 0.9252, 'learning_rate': 1.8092242555127437e-06, 'epoch': 0.81}
 81%|████████  | 8434/10395 [24:05:45<4:05:28,  7.51s/it] 81%|████████  | 8435/10395 [24:05:52<4:01:57,  7.41s/it]                                                         {'loss': 0.9626, 'learning_rate': 1.8074372112869653e-06, 'epoch': 0.81}
 81%|████████  | 8435/10395 [24:05:52<4:01:57,  7.41s/it] 81%|████████  | 8436/10395 [24:06:00<4:02:40,  7.43s/it]                                                         {'loss': 0.8132, 'learning_rate': 1.8056509623776775e-06, 'epoch': 0.81}
 81%|████████  | 8436/10395 [24:06:00<4:02:40,  7.43s/it] 81%|████████  | 8437/10395 [24:06:07<3:58:40,  7.31s/it]                                                         {'loss': 0.8776, 'learning_rate': 1.8038655089582836e-06, 'epoch': 0.81}
 81%|████████  | 8437/10395 [24:06:07<3:58:40,  7.31s/it] 81%|████████  | 8438/10395 [24:06:14<4:02:05,  7.42s/it]                                                         {'loss': 0.9007, 'learning_rate': 1.8020808512021071e-06, 'epoch': 0.81}
 81%|████████  | 8438/10395 [24:06:14<4:02:05,  7.42s/it] 81%|████████  | 8439/10395 [24:06:22<4:07:43,  7.60s/it]                                                         {'loss': 0.8984, 'learning_rate': 1.8002969892824062e-06, 'epoch': 0.81}
 81%|████████  | 8439/10395 [24:06:22<4:07:43,  7.60s/it] 81%|████████  | 8440/10395 [24:06:32<4:29:14,  8.26s/it]                                                         {'loss': 0.8654, 'learning_rate': 1.798513923372348e-06, 'epoch': 0.81}
 81%|████████  | 8440/10395 [24:06:32<4:29:14,  8.26s/it] 81%|████████  | 8441/10395 [24:06:40<4:23:11,  8.08s/it]                                                         {'loss': 0.8073, 'learning_rate': 1.7967316536450309e-06, 'epoch': 0.81}
 81%|████████  | 8441/10395 [24:06:40<4:23:11,  8.08s/it] 81%|████████  | 8442/10395 [24:06:48<4:20:04,  7.99s/it]                                                         {'loss': 0.841, 'learning_rate': 1.794950180273478e-06, 'epoch': 0.81}
 81%|████████  | 8442/10395 [24:06:48<4:20:04,  7.99s/it] 81%|████████  | 8443/10395 [24:06:55<4:16:45,  7.89s/it]                                                         {'loss': 0.8604, 'learning_rate': 1.793169503430624e-06, 'epoch': 0.81}
 81%|████████  | 8443/10395 [24:06:55<4:16:45,  7.89s/it] 81%|████████  | 8444/10395 [24:07:03<4:11:58,  7.75s/it]                                                         {'loss': 0.8383, 'learning_rate': 1.7913896232893391e-06, 'epoch': 0.81}
 81%|████████  | 8444/10395 [24:07:03<4:11:58,  7.75s/it] 81%|████████  | 8445/10395 [24:07:11<4:19:53,  8.00s/it]                                                         {'loss': 0.8918, 'learning_rate': 1.7896105400224073e-06, 'epoch': 0.81}
 81%|████████  | 8445/10395 [24:07:11<4:19:53,  8.00s/it] 81%|████████▏ | 8446/10395 [24:07:19<4:17:49,  7.94s/it]                                                         {'loss': 0.9029, 'learning_rate': 1.7878322538025373e-06, 'epoch': 0.81}
 81%|████████▏ | 8446/10395 [24:07:19<4:17:49,  7.94s/it] 81%|████████▏ | 8447/10395 [24:07:27<4:13:46,  7.82s/it]                                                         {'loss': 0.8586, 'learning_rate': 1.786054764802364e-06, 'epoch': 0.81}
 81%|████████▏ | 8447/10395 [24:07:27<4:13:46,  7.82s/it] 81%|████████▏ | 8448/10395 [24:07:35<4:16:23,  7.90s/it]                                                         {'loss': 0.7946, 'learning_rate': 1.7842780731944398e-06, 'epoch': 0.81}
 81%|████████▏ | 8448/10395 [24:07:35<4:16:23,  7.90s/it] 81%|████████▏ | 8449/10395 [24:07:43<4:19:23,  8.00s/it]                                                         {'loss': 0.8148, 'learning_rate': 1.782502179151242e-06, 'epoch': 0.81}
 81%|████████▏ | 8449/10395 [24:07:43<4:19:23,  8.00s/it] 81%|████████▏ | 8450/10395 [24:07:50<4:14:53,  7.86s/it]                                                         {'loss': 0.8693, 'learning_rate': 1.7807270828451739e-06, 'epoch': 0.81}
 81%|████████▏ | 8450/10395 [24:07:50<4:14:53,  7.86s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 81%|████████▏ | 8451/10395 [24:09:29<18:54:57, 35.03s/it]                                                          {'loss': 0.8048, 'learning_rate': 1.7789527844485544e-06, 'epoch': 0.81}
 81%|████████▏ | 8451/10395 [24:09:29<18:54:57, 35.03s/it] 81%|████████▏ | 8452/10395 [24:09:36<14:26:25, 26.76s/it]                                                          {'loss': 0.9161, 'learning_rate': 1.777179284133632e-06, 'epoch': 0.81}
 81%|████████▏ | 8452/10395 [24:09:36<14:26:25, 26.76s/it] 81%|████████▏ | 8453/10395 [24:09:44<11:18:40, 20.97s/it]                                                          {'loss': 0.9269, 'learning_rate': 1.775406582072573e-06, 'epoch': 0.81}
 81%|████████▏ | 8453/10395 [24:09:44<11:18:40, 20.97s/it] 81%|████████▏ | 8454/10395 [24:09:51<9:03:12, 16.79s/it]                                                          {'loss': 0.895, 'learning_rate': 1.7736346784374646e-06, 'epoch': 0.81}
 81%|████████▏ | 8454/10395 [24:09:51<9:03:12, 16.79s/it] 81%|████████▏ | 8455/10395 [24:09:59<7:36:57, 14.13s/it]                                                         {'loss': 0.8501, 'learning_rate': 1.7718635734003243e-06, 'epoch': 0.81}
 81%|████████▏ | 8455/10395 [24:09:59<7:36:57, 14.13s/it] 81%|████████▏ | 8456/10395 [24:10:06<6:32:19, 12.14s/it]                                                         {'loss': 0.8646, 'learning_rate': 1.7700932671330816e-06, 'epoch': 0.81}
 81%|████████▏ | 8456/10395 [24:10:06<6:32:19, 12.14s/it] 81%|████████▏ | 8457/10395 [24:10:16<6:11:55, 11.51s/it]                                                         {'loss': 0.8403, 'learning_rate': 1.7683237598075976e-06, 'epoch': 0.81}
 81%|████████▏ | 8457/10395 [24:10:16<6:11:55, 11.51s/it] 81%|████████▏ | 8458/10395 [24:10:24<5:35:29, 10.39s/it]                                                         {'loss': 0.8547, 'learning_rate': 1.7665550515956542e-06, 'epoch': 0.81}
 81%|████████▏ | 8458/10395 [24:10:24<5:35:29, 10.39s/it] 81%|████████▏ | 8459/10395 [24:10:32<5:12:38,  9.69s/it]                                                         {'loss': 0.8176, 'learning_rate': 1.7647871426689523e-06, 'epoch': 0.81}
 81%|████████▏ | 8459/10395 [24:10:32<5:12:38,  9.69s/it] 81%|████████▏ | 8460/10395 [24:10:40<4:58:41,  9.26s/it]                                                         {'loss': 0.875, 'learning_rate': 1.763020033199112e-06, 'epoch': 0.81}
 81%|████████▏ | 8460/10395 [24:10:40<4:58:41,  9.26s/it] 81%|████████▏ | 8461/10395 [24:10:48<4:44:14,  8.82s/it]                                                         {'loss': 0.8761, 'learning_rate': 1.7612537233576875e-06, 'epoch': 0.81}
 81%|████████▏ | 8461/10395 [24:10:48<4:44:14,  8.82s/it] 81%|████████▏ | 8462/10395 [24:10:56<4:33:19,  8.48s/it]                                                         {'loss': 0.8949, 'learning_rate': 1.7594882133161427e-06, 'epoch': 0.81}
 81%|████████▏ | 8462/10395 [24:10:56<4:33:19,  8.48s/it] 81%|████████▏ | 8463/10395 [24:11:04<4:25:33,  8.25s/it]                                                         {'loss': 0.8866, 'learning_rate': 1.757723503245875e-06, 'epoch': 0.81}
 81%|████████▏ | 8463/10395 [24:11:04<4:25:33,  8.25s/it] 81%|████████▏ | 8464/10395 [24:11:11<4:22:05,  8.14s/it]                                                         {'loss': 0.9335, 'learning_rate': 1.7559595933181929e-06, 'epoch': 0.81}
 81%|████████▏ | 8464/10395 [24:11:11<4:22:05,  8.14s/it] 81%|████████▏ | 8465/10395 [24:11:19<4:12:21,  7.85s/it]                                                         {'loss': 0.8585, 'learning_rate': 1.7541964837043358e-06, 'epoch': 0.81}
 81%|████████▏ | 8465/10395 [24:11:19<4:12:21,  7.85s/it] 81%|████████▏ | 8466/10395 [24:11:26<4:09:17,  7.75s/it]                                                         {'loss': 0.9336, 'learning_rate': 1.7524341745754657e-06, 'epoch': 0.81}
 81%|████████▏ | 8466/10395 [24:11:26<4:09:17,  7.75s/it] 81%|████████▏ | 8467/10395 [24:11:34<4:14:29,  7.92s/it]                                                         {'loss': 0.8862, 'learning_rate': 1.7506726661026608e-06, 'epoch': 0.81}
 81%|████████▏ | 8467/10395 [24:11:34<4:14:29,  7.92s/it] 81%|████████▏ | 8468/10395 [24:11:43<4:15:48,  7.97s/it]                                                         {'loss': 0.8854, 'learning_rate': 1.7489119584569214e-06, 'epoch': 0.81}
 81%|████████▏ | 8468/10395 [24:11:43<4:15:48,  7.97s/it] 81%|████████▏ | 8469/10395 [24:11:50<4:10:26,  7.80s/it]                                                         {'loss': 0.8622, 'learning_rate': 1.74715205180918e-06, 'epoch': 0.81}
 81%|████████▏ | 8469/10395 [24:11:50<4:10:26,  7.80s/it] 81%|████████▏ | 8470/10395 [24:11:59<4:19:26,  8.09s/it]                                                         {'loss': 0.868, 'learning_rate': 1.7453929463302777e-06, 'epoch': 0.81}
 81%|████████▏ | 8470/10395 [24:11:59<4:19:26,  8.09s/it] 81%|████████▏ | 8471/10395 [24:12:06<4:12:04,  7.86s/it]                                                         {'loss': 0.9063, 'learning_rate': 1.7436346421909877e-06, 'epoch': 0.81}
 81%|████████▏ | 8471/10395 [24:12:07<4:12:04,  7.86s/it] 82%|████████▏ | 8472/10395 [24:12:15<4:19:58,  8.11s/it]                                                         {'loss': 0.9244, 'learning_rate': 1.741877139562006e-06, 'epoch': 0.81}
 82%|████████▏ | 8472/10395 [24:12:15<4:19:58,  8.11s/it] 82%|████████▏ | 8473/10395 [24:12:23<4:19:41,  8.11s/it]                                                         {'loss': 0.7946, 'learning_rate': 1.7401204386139414e-06, 'epoch': 0.82}
 82%|████████▏ | 8473/10395 [24:12:23<4:19:41,  8.11s/it] 82%|████████▏ | 8474/10395 [24:12:30<4:11:47,  7.86s/it]                                                         {'loss': 0.9488, 'learning_rate': 1.7383645395173355e-06, 'epoch': 0.82}
 82%|████████▏ | 8474/10395 [24:12:30<4:11:47,  7.86s/it] 82%|████████▏ | 8475/10395 [24:12:38<4:06:53,  7.72s/it]                                                         {'loss': 0.8452, 'learning_rate': 1.736609442442645e-06, 'epoch': 0.82}
 82%|████████▏ | 8475/10395 [24:12:38<4:06:53,  7.72s/it] 82%|████████▏ | 8476/10395 [24:12:45<4:08:06,  7.76s/it]                                                         {'loss': 0.8838, 'learning_rate': 1.7348551475602483e-06, 'epoch': 0.82}
 82%|████████▏ | 8476/10395 [24:12:45<4:08:06,  7.76s/it] 82%|████████▏ | 8477/10395 [24:12:55<4:25:55,  8.32s/it]                                                         {'loss': 0.7576, 'learning_rate': 1.7331016550404534e-06, 'epoch': 0.82}
 82%|████████▏ | 8477/10395 [24:12:55<4:25:55,  8.32s/it] 82%|████████▏ | 8478/10395 [24:13:04<4:27:43,  8.38s/it]                                                         {'loss': 0.8207, 'learning_rate': 1.731348965053481e-06, 'epoch': 0.82}
 82%|████████▏ | 8478/10395 [24:13:04<4:27:43,  8.38s/it] 82%|████████▏ | 8479/10395 [24:13:11<4:22:08,  8.21s/it]                                                         {'loss': 0.8934, 'learning_rate': 1.7295970777694816e-06, 'epoch': 0.82}
 82%|████████▏ | 8479/10395 [24:13:11<4:22:08,  8.21s/it] 82%|████████▏ | 8480/10395 [24:13:29<5:51:35, 11.02s/it]                                                         {'loss': 0.3627, 'learning_rate': 1.7278459933585256e-06, 'epoch': 0.82}
 82%|████████▏ | 8480/10395 [24:13:29<5:51:35, 11.02s/it] 82%|████████▏ | 8481/10395 [24:13:46<6:51:30, 12.90s/it]                                                         {'loss': 0.3536, 'learning_rate': 1.726095711990604e-06, 'epoch': 0.82}
 82%|████████▏ | 8481/10395 [24:13:46<6:51:30, 12.90s/it] 82%|████████▏ | 8482/10395 [24:13:53<5:55:35, 11.15s/it]                                                         {'loss': 0.9172, 'learning_rate': 1.7243462338356254e-06, 'epoch': 0.82}
 82%|████████▏ | 8482/10395 [24:13:53<5:55:35, 11.15s/it] 82%|████████▏ | 8483/10395 [24:14:01<5:25:19, 10.21s/it]                                                         {'loss': 0.9564, 'learning_rate': 1.7225975590634326e-06, 'epoch': 0.82}
 82%|████████▏ | 8483/10395 [24:14:01<5:25:19, 10.21s/it] 82%|████████▏ | 8484/10395 [24:14:09<5:02:35,  9.50s/it]                                                         {'loss': 0.8742, 'learning_rate': 1.7208496878437774e-06, 'epoch': 0.82}
 82%|████████▏ | 8484/10395 [24:14:09<5:02:35,  9.50s/it] 82%|████████▏ | 8485/10395 [24:14:17<4:49:59,  9.11s/it]                                                         {'loss': 0.8513, 'learning_rate': 1.7191026203463445e-06, 'epoch': 0.82}
 82%|████████▏ | 8485/10395 [24:14:17<4:49:59,  9.11s/it] 82%|████████▏ | 8486/10395 [24:14:25<4:37:13,  8.71s/it]                                                         {'loss': 0.8837, 'learning_rate': 1.7173563567407302e-06, 'epoch': 0.82}
 82%|████████▏ | 8486/10395 [24:14:25<4:37:13,  8.71s/it] 82%|████████▏ | 8487/10395 [24:14:33<4:30:10,  8.50s/it]                                                         {'loss': 0.8525, 'learning_rate': 1.7156108971964602e-06, 'epoch': 0.82}
 82%|████████▏ | 8487/10395 [24:14:33<4:30:10,  8.50s/it] 82%|████████▏ | 8488/10395 [24:14:41<4:22:12,  8.25s/it]                                                         {'loss': 0.7822, 'learning_rate': 1.7138662418829866e-06, 'epoch': 0.82}
 82%|████████▏ | 8488/10395 [24:14:41<4:22:12,  8.25s/it] 82%|████████▏ | 8489/10395 [24:14:49<4:24:24,  8.32s/it]                                                         {'loss': 0.8633, 'learning_rate': 1.7121223909696649e-06, 'epoch': 0.82}
 82%|████████▏ | 8489/10395 [24:14:49<4:24:24,  8.32s/it] 82%|████████▏ | 8490/10395 [24:14:58<4:30:45,  8.53s/it]                                                         {'loss': 0.8713, 'learning_rate': 1.7103793446257898e-06, 'epoch': 0.82}
 82%|████████▏ | 8490/10395 [24:14:58<4:30:45,  8.53s/it] 82%|████████▏ | 8491/10395 [24:15:06<4:25:29,  8.37s/it]                                                         {'loss': 0.8958, 'learning_rate': 1.7086371030205762e-06, 'epoch': 0.82}
 82%|████████▏ | 8491/10395 [24:15:06<4:25:29,  8.37s/it] 82%|████████▏ | 8492/10395 [24:15:14<4:21:13,  8.24s/it]                                                         {'loss': 0.8929, 'learning_rate': 1.7068956663231518e-06, 'epoch': 0.82}
 82%|████████▏ | 8492/10395 [24:15:14<4:21:13,  8.24s/it] 82%|████████▏ | 8493/10395 [24:15:32<5:52:49, 11.13s/it]                                                         {'loss': 0.3108, 'learning_rate': 1.7051550347025759e-06, 'epoch': 0.82}
 82%|████████▏ | 8493/10395 [24:15:32<5:52:49, 11.13s/it] 82%|████████▏ | 8494/10395 [24:15:49<6:45:00, 12.78s/it]                                                         {'loss': 0.3632, 'learning_rate': 1.70341520832782e-06, 'epoch': 0.82}
 82%|████████▏ | 8494/10395 [24:15:49<6:45:00, 12.78s/it] 82%|████████▏ | 8495/10395 [24:15:56<5:53:07, 11.15s/it]                                                         {'loss': 0.8483, 'learning_rate': 1.7016761873677866e-06, 'epoch': 0.82}
 82%|████████▏ | 8495/10395 [24:15:56<5:53:07, 11.15s/it] 82%|████████▏ | 8496/10395 [24:16:03<5:17:08, 10.02s/it]                                                         {'loss': 0.8216, 'learning_rate': 1.6999379719913e-06, 'epoch': 0.82}
 82%|████████▏ | 8496/10395 [24:16:03<5:17:08, 10.02s/it] 82%|████████▏ | 8497/10395 [24:16:12<5:02:36,  9.57s/it]                                                         {'loss': 0.8021, 'learning_rate': 1.6982005623670927e-06, 'epoch': 0.82}
 82%|████████▏ | 8497/10395 [24:16:12<5:02:36,  9.57s/it] 82%|████████▏ | 8498/10395 [24:16:20<4:44:50,  9.01s/it]                                                         {'loss': 0.8663, 'learning_rate': 1.6964639586638332e-06, 'epoch': 0.82}
 82%|████████▏ | 8498/10395 [24:16:20<4:44:50,  9.01s/it] 82%|████████▏ | 8499/10395 [24:16:27<4:32:34,  8.63s/it]                                                         {'loss': 0.8804, 'learning_rate': 1.694728161050111e-06, 'epoch': 0.82}
 82%|████████▏ | 8499/10395 [24:16:27<4:32:34,  8.63s/it] 82%|████████▏ | 8500/10395 [24:16:34<4:17:32,  8.15s/it]                                                         {'loss': 0.8478, 'learning_rate': 1.692993169694428e-06, 'epoch': 0.82}
 82%|████████▏ | 8500/10395 [24:16:34<4:17:32,  8.15s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 82%|████████▏ | 8501/10395 [24:18:18<19:22:35, 36.83s/it]                                                          {'loss': 0.8903, 'learning_rate': 1.6912589847652183e-06, 'epoch': 0.82}
 82%|████████▏ | 8501/10395 [24:18:18<19:22:35, 36.83s/it] 82%|████████▏ | 8502/10395 [24:18:26<14:46:28, 28.10s/it]                                                          {'loss': 0.8309, 'learning_rate': 1.6895256064308285e-06, 'epoch': 0.82}
 82%|████████▏ | 8502/10395 [24:18:26<14:46:28, 28.10s/it] 82%|████████▏ | 8503/10395 [24:18:35<11:41:50, 22.26s/it]                                                          {'loss': 0.8634, 'learning_rate': 1.687793034859536e-06, 'epoch': 0.82}
 82%|████████▏ | 8503/10395 [24:18:35<11:41:50, 22.26s/it] 82%|████████▏ | 8504/10395 [24:18:43<9:33:00, 18.18s/it]                                                          {'loss': 0.8725, 'learning_rate': 1.6860612702195312e-06, 'epoch': 0.82}
 82%|████████▏ | 8504/10395 [24:18:43<9:33:00, 18.18s/it] 82%|████████▏ | 8505/10395 [24:18:51<7:57:37, 15.16s/it]                                                         {'loss': 0.9135, 'learning_rate': 1.6843303126789301e-06, 'epoch': 0.82}
 82%|████████▏ | 8505/10395 [24:18:51<7:57:37, 15.16s/it] 82%|████████▏ | 8506/10395 [24:18:59<6:46:15, 12.90s/it]                                                         {'loss': 0.9198, 'learning_rate': 1.6826001624057709e-06, 'epoch': 0.82}
 82%|████████▏ | 8506/10395 [24:18:59<6:46:15, 12.90s/it] 82%|████████▏ | 8507/10395 [24:19:15<7:19:42, 13.97s/it]                                                         {'loss': 0.3098, 'learning_rate': 1.6808708195680156e-06, 'epoch': 0.82}
 82%|████████▏ | 8507/10395 [24:19:15<7:19:42, 13.97s/it] 82%|████████▏ | 8508/10395 [24:19:23<6:23:30, 12.19s/it]                                                         {'loss': 0.8309, 'learning_rate': 1.6791422843335415e-06, 'epoch': 0.82}
 82%|████████▏ | 8508/10395 [24:19:23<6:23:30, 12.19s/it] 82%|████████▏ | 8509/10395 [24:19:31<5:38:30, 10.77s/it]                                                         {'loss': 0.8477, 'learning_rate': 1.677414556870155e-06, 'epoch': 0.82}
 82%|████████▏ | 8509/10395 [24:19:31<5:38:30, 10.77s/it] 82%|████████▏ | 8510/10395 [24:19:38<5:05:28,  9.72s/it]                                                         {'loss': 0.9206, 'learning_rate': 1.6756876373455776e-06, 'epoch': 0.82}
 82%|████████▏ | 8510/10395 [24:19:38<5:05:28,  9.72s/it] 82%|████████▏ | 8511/10395 [24:19:45<4:38:55,  8.88s/it]                                                         {'loss': 0.9149, 'learning_rate': 1.6739615259274533e-06, 'epoch': 0.82}
 82%|████████▏ | 8511/10395 [24:19:45<4:38:55,  8.88s/it] 82%|████████▏ | 8512/10395 [24:19:53<4:29:03,  8.57s/it]                                                         {'loss': 0.8409, 'learning_rate': 1.6722362227833534e-06, 'epoch': 0.82}
 82%|████████▏ | 8512/10395 [24:19:53<4:29:03,  8.57s/it] 82%|████████▏ | 8513/10395 [24:20:01<4:22:57,  8.38s/it]                                                         {'loss': 0.8771, 'learning_rate': 1.6705117280807626e-06, 'epoch': 0.82}
 82%|████████▏ | 8513/10395 [24:20:01<4:22:57,  8.38s/it] 82%|████████▏ | 8514/10395 [24:20:08<4:13:13,  8.08s/it]                                                         {'loss': 0.9118, 'learning_rate': 1.6687880419870917e-06, 'epoch': 0.82}
 82%|████████▏ | 8514/10395 [24:20:08<4:13:13,  8.08s/it] 82%|████████▏ | 8515/10395 [24:20:17<4:14:52,  8.13s/it]                                                         {'loss': 0.9127, 'learning_rate': 1.6670651646696777e-06, 'epoch': 0.82}
 82%|████████▏ | 8515/10395 [24:20:17<4:14:52,  8.13s/it] 82%|████████▏ | 8516/10395 [24:20:24<4:12:34,  8.07s/it]                                                         {'loss': 0.8279, 'learning_rate': 1.6653430962957661e-06, 'epoch': 0.82}
 82%|████████▏ | 8516/10395 [24:20:24<4:12:34,  8.07s/it] 82%|████████▏ | 8517/10395 [24:20:32<4:12:21,  8.06s/it]                                                         {'loss': 0.9637, 'learning_rate': 1.6636218370325396e-06, 'epoch': 0.82}
 82%|████████▏ | 8517/10395 [24:20:32<4:12:21,  8.06s/it] 82%|████████▏ | 8518/10395 [24:20:40<4:09:36,  7.98s/it]                                                         {'loss': 0.8843, 'learning_rate': 1.661901387047089e-06, 'epoch': 0.82}
 82%|████████▏ | 8518/10395 [24:20:40<4:09:36,  7.98s/it] 82%|████████▏ | 8519/10395 [24:20:47<4:01:10,  7.71s/it]                                                         {'loss': 0.8983, 'learning_rate': 1.6601817465064317e-06, 'epoch': 0.82}
 82%|████████▏ | 8519/10395 [24:20:47<4:01:10,  7.71s/it] 82%|████████▏ | 8520/10395 [24:20:55<3:59:33,  7.67s/it]                                                         {'loss': 0.8472, 'learning_rate': 1.65846291557751e-06, 'epoch': 0.82}
 82%|████████▏ | 8520/10395 [24:20:55<3:59:33,  7.67s/it] 82%|████████▏ | 8521/10395 [24:21:04<4:16:01,  8.20s/it]                                                         {'loss': 0.7338, 'learning_rate': 1.6567448944271803e-06, 'epoch': 0.82}
 82%|████████▏ | 8521/10395 [24:21:04<4:16:01,  8.20s/it] 82%|████████▏ | 8522/10395 [24:21:12<4:10:55,  8.04s/it]                                                         {'loss': 0.8558, 'learning_rate': 1.6550276832222256e-06, 'epoch': 0.82}
 82%|████████▏ | 8522/10395 [24:21:12<4:10:55,  8.04s/it] 82%|████████▏ | 8523/10395 [24:21:19<4:04:45,  7.84s/it]                                                         {'loss': 0.8632, 'learning_rate': 1.653311282129354e-06, 'epoch': 0.82}
 82%|████████▏ | 8523/10395 [24:21:19<4:04:45,  7.84s/it] 82%|████████▏ | 8524/10395 [24:21:27<4:01:42,  7.75s/it]                                                         {'loss': 0.893, 'learning_rate': 1.6515956913151832e-06, 'epoch': 0.82}
 82%|████████▏ | 8524/10395 [24:21:27<4:01:42,  7.75s/it] 82%|████████▏ | 8525/10395 [24:21:34<3:56:05,  7.58s/it]                                                         {'loss': 0.9485, 'learning_rate': 1.6498809109462644e-06, 'epoch': 0.82}
 82%|████████▏ | 8525/10395 [24:21:34<3:56:05,  7.58s/it] 82%|████████▏ | 8526/10395 [24:21:52<5:27:42, 10.52s/it]                                                         {'loss': 0.3875, 'learning_rate': 1.6481669411890632e-06, 'epoch': 0.82}
 82%|████████▏ | 8526/10395 [24:21:52<5:27:42, 10.52s/it] 82%|████████▏ | 8527/10395 [24:21:59<4:59:53,  9.63s/it]                                                         {'loss': 0.885, 'learning_rate': 1.6464537822099647e-06, 'epoch': 0.82}
 82%|████████▏ | 8527/10395 [24:21:59<4:59:53,  9.63s/it] 82%|████████▏ | 8528/10395 [24:22:07<4:44:02,  9.13s/it]                                                         {'loss': 0.8357, 'learning_rate': 1.6447414341752832e-06, 'epoch': 0.82}
 82%|████████▏ | 8528/10395 [24:22:07<4:44:02,  9.13s/it] 82%|████████▏ | 8529/10395 [24:22:14<4:26:42,  8.58s/it]                                                         {'loss': 0.9102, 'learning_rate': 1.643029897251246e-06, 'epoch': 0.82}
 82%|████████▏ | 8529/10395 [24:22:14<4:26:42,  8.58s/it] 82%|████████▏ | 8530/10395 [24:22:22<4:17:40,  8.29s/it]                                                         {'loss': 0.7968, 'learning_rate': 1.6413191716040078e-06, 'epoch': 0.82}
 82%|████████▏ | 8530/10395 [24:22:22<4:17:40,  8.29s/it] 82%|████████▏ | 8531/10395 [24:22:29<4:07:28,  7.97s/it]                                                         {'loss': 0.889, 'learning_rate': 1.6396092573996437e-06, 'epoch': 0.82}
 82%|████████▏ | 8531/10395 [24:22:29<4:07:28,  7.97s/it] 82%|████████▏ | 8532/10395 [24:22:36<3:57:49,  7.66s/it]                                                         {'loss': 0.9469, 'learning_rate': 1.6379001548041474e-06, 'epoch': 0.82}
 82%|████████▏ | 8532/10395 [24:22:36<3:57:49,  7.66s/it] 82%|████████▏ | 8533/10395 [24:22:44<4:01:46,  7.79s/it]                                                         {'loss': 0.8474, 'learning_rate': 1.6361918639834306e-06, 'epoch': 0.82}
 82%|████████▏ | 8533/10395 [24:22:44<4:01:46,  7.79s/it] 82%|████████▏ | 8534/10395 [24:22:52<4:05:55,  7.93s/it]                                                         {'loss': 0.8746, 'learning_rate': 1.6344843851033376e-06, 'epoch': 0.82}
 82%|████████▏ | 8534/10395 [24:22:52<4:05:55,  7.93s/it] 82%|████████▏ | 8535/10395 [24:23:00<4:03:07,  7.84s/it]                                                         {'loss': 0.7851, 'learning_rate': 1.63277771832962e-06, 'epoch': 0.82}
 82%|████████▏ | 8535/10395 [24:23:00<4:03:07,  7.84s/it] 82%|████████▏ | 8536/10395 [24:23:08<4:05:15,  7.92s/it]                                                         {'loss': 0.9272, 'learning_rate': 1.631071863827962e-06, 'epoch': 0.82}
 82%|████████▏ | 8536/10395 [24:23:08<4:05:15,  7.92s/it] 82%|████████▏ | 8537/10395 [24:23:16<4:01:32,  7.80s/it]                                                         {'loss': 0.8852, 'learning_rate': 1.6293668217639647e-06, 'epoch': 0.82}
 82%|████████▏ | 8537/10395 [24:23:16<4:01:32,  7.80s/it] 82%|████████▏ | 8538/10395 [24:23:32<5:20:44, 10.36s/it]                                                         {'loss': 0.3632, 'learning_rate': 1.6276625923031452e-06, 'epoch': 0.82}
 82%|████████▏ | 8538/10395 [24:23:32<5:20:44, 10.36s/it] 82%|████████▏ | 8539/10395 [24:23:40<4:54:27,  9.52s/it]                                                         {'loss': 0.8549, 'learning_rate': 1.6259591756109528e-06, 'epoch': 0.82}
 82%|████████▏ | 8539/10395 [24:23:40<4:54:27,  9.52s/it] 82%|████████▏ | 8540/10395 [24:23:47<4:34:30,  8.88s/it]                                                         {'loss': 0.8897, 'learning_rate': 1.624256571852748e-06, 'epoch': 0.82}
 82%|████████▏ | 8540/10395 [24:23:47<4:34:30,  8.88s/it] 82%|████████▏ | 8541/10395 [24:24:05<5:55:00, 11.49s/it]                                                         {'loss': 0.387, 'learning_rate': 1.6225547811938135e-06, 'epoch': 0.82}
 82%|████████▏ | 8541/10395 [24:24:05<5:55:00, 11.49s/it] 82%|████████▏ | 8542/10395 [24:24:13<5:25:58, 10.56s/it]                                                         {'loss': 0.8514, 'learning_rate': 1.6208538037993616e-06, 'epoch': 0.82}
 82%|████████▏ | 8542/10395 [24:24:13<5:25:58, 10.56s/it] 82%|████████▏ | 8543/10395 [24:24:20<4:56:48,  9.62s/it]                                                         {'loss': 0.8867, 'learning_rate': 1.6191536398345131e-06, 'epoch': 0.82}
 82%|████████▏ | 8543/10395 [24:24:20<4:56:48,  9.62s/it] 82%|████████▏ | 8544/10395 [24:24:28<4:35:12,  8.92s/it]                                                         {'loss': 0.8968, 'learning_rate': 1.6174542894643185e-06, 'epoch': 0.82}
 82%|████████▏ | 8544/10395 [24:24:28<4:35:12,  8.92s/it] 82%|████████▏ | 8545/10395 [24:24:36<4:27:42,  8.68s/it]                                                         {'loss': 0.8448, 'learning_rate': 1.6157557528537515e-06, 'epoch': 0.82}
 82%|████████▏ | 8545/10395 [24:24:36<4:27:42,  8.68s/it] 82%|████████▏ | 8546/10395 [24:24:43<4:16:51,  8.34s/it]                                                         {'loss': 0.9314, 'learning_rate': 1.6140580301676955e-06, 'epoch': 0.82}
 82%|████████▏ | 8546/10395 [24:24:43<4:16:51,  8.34s/it] 82%|████████▏ | 8547/10395 [24:24:51<4:11:48,  8.18s/it]                                                         {'loss': 0.8613, 'learning_rate': 1.6123611215709679e-06, 'epoch': 0.82}
 82%|████████▏ | 8547/10395 [24:24:51<4:11:48,  8.18s/it] 82%|████████▏ | 8548/10395 [24:25:00<4:13:45,  8.24s/it]                                                         {'loss': 0.825, 'learning_rate': 1.6106650272282986e-06, 'epoch': 0.82}
 82%|████████▏ | 8548/10395 [24:25:00<4:13:45,  8.24s/it] 82%|████████▏ | 8549/10395 [24:25:17<5:41:15, 11.09s/it]                                                         {'loss': 0.3675, 'learning_rate': 1.6089697473043375e-06, 'epoch': 0.82}
 82%|████████▏ | 8549/10395 [24:25:17<5:41:15, 11.09s/it] 82%|████████▏ | 8550/10395 [24:25:26<5:17:39, 10.33s/it]                                                         {'loss': 0.8873, 'learning_rate': 1.607275281963664e-06, 'epoch': 0.82}
 82%|████████▏ | 8550/10395 [24:25:26<5:17:39, 10.33s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 82%|████████▏ | 8551/10395 [24:27:09<19:30:09, 38.07s/it]                                                          {'loss': 0.8197, 'learning_rate': 1.6055816313707684e-06, 'epoch': 0.82}
 82%|████████▏ | 8551/10395 [24:27:09<19:30:09, 38.07s/it] 82%|████████▏ | 8552/10395 [24:27:16<14:45:57, 28.84s/it]                                                          {'loss': 0.849, 'learning_rate': 1.6038887956900694e-06, 'epoch': 0.82}
 82%|████████▏ | 8552/10395 [24:27:16<14:45:57, 28.84s/it] 82%|████████▏ | 8553/10395 [24:27:23<11:29:16, 22.45s/it]                                                          {'loss': 0.9234, 'learning_rate': 1.6021967750859058e-06, 'epoch': 0.82}
 82%|████████▏ | 8553/10395 [24:27:23<11:29:16, 22.45s/it] 82%|████████▏ | 8554/10395 [24:27:31<9:13:04, 18.03s/it]                                                          {'loss': 0.8529, 'learning_rate': 1.6005055697225313e-06, 'epoch': 0.82}
 82%|████████▏ | 8554/10395 [24:27:31<9:13:04, 18.03s/it] 82%|████████▏ | 8555/10395 [24:27:48<9:05:23, 17.78s/it]                                                         {'loss': 0.3834, 'learning_rate': 1.5988151797641283e-06, 'epoch': 0.82}
 82%|████████▏ | 8555/10395 [24:27:48<9:05:23, 17.78s/it] 82%|████████▏ | 8556/10395 [24:28:04<8:49:07, 17.26s/it]                                                         {'loss': 0.3386, 'learning_rate': 1.597125605374794e-06, 'epoch': 0.82}
 82%|████████▏ | 8556/10395 [24:28:04<8:49:07, 17.26s/it] 82%|████████▏ | 8557/10395 [24:28:12<7:15:58, 14.23s/it]                                                         {'loss': 0.8659, 'learning_rate': 1.5954368467185466e-06, 'epoch': 0.82}
 82%|████████▏ | 8557/10395 [24:28:12<7:15:58, 14.23s/it] 82%|████████▏ | 8558/10395 [24:28:20<6:21:43, 12.47s/it]                                                         {'loss': 0.785, 'learning_rate': 1.5937489039593312e-06, 'epoch': 0.82}
 82%|████████▏ | 8558/10395 [24:28:20<6:21:43, 12.47s/it] 82%|████████▏ | 8559/10395 [24:28:27<5:36:31, 11.00s/it]                                                         {'loss': 0.8534, 'learning_rate': 1.592061777261007e-06, 'epoch': 0.82}
 82%|████████▏ | 8559/10395 [24:28:27<5:36:31, 11.00s/it] 82%|████████▏ | 8560/10395 [24:28:35<5:01:55,  9.87s/it]                                                         {'loss': 0.9097, 'learning_rate': 1.5903754667873571e-06, 'epoch': 0.82}
 82%|████████▏ | 8560/10395 [24:28:35<5:01:55,  9.87s/it] 82%|████████▏ | 8561/10395 [24:28:43<4:43:27,  9.27s/it]                                                         {'loss': 0.8377, 'learning_rate': 1.5886899727020878e-06, 'epoch': 0.82}
 82%|████████▏ | 8561/10395 [24:28:43<4:43:27,  9.27s/it] 82%|████████▏ | 8562/10395 [24:28:50<4:24:42,  8.66s/it]                                                         {'loss': 0.8448, 'learning_rate': 1.587005295168821e-06, 'epoch': 0.82}
 82%|████████▏ | 8562/10395 [24:28:50<4:24:42,  8.66s/it] 82%|████████▏ | 8563/10395 [24:28:57<4:12:00,  8.25s/it]                                                         {'loss': 0.8769, 'learning_rate': 1.585321434351098e-06, 'epoch': 0.82}
 82%|████████▏ | 8563/10395 [24:28:57<4:12:00,  8.25s/it] 82%|████████▏ | 8564/10395 [24:29:06<4:15:13,  8.36s/it]                                                         {'loss': 0.8269, 'learning_rate': 1.583638390412392e-06, 'epoch': 0.82}
 82%|████████▏ | 8564/10395 [24:29:06<4:15:13,  8.36s/it] 82%|████████▏ | 8565/10395 [24:29:13<4:06:54,  8.10s/it]                                                         {'loss': 0.8608, 'learning_rate': 1.5819561635160819e-06, 'epoch': 0.82}
 82%|████████▏ | 8565/10395 [24:29:13<4:06:54,  8.10s/it] 82%|████████▏ | 8566/10395 [24:29:21<4:03:51,  8.00s/it]                                                         {'loss': 0.8761, 'learning_rate': 1.5802747538254803e-06, 'epoch': 0.82}
 82%|████████▏ | 8566/10395 [24:29:21<4:03:51,  8.00s/it] 82%|████████▏ | 8567/10395 [24:29:29<4:00:56,  7.91s/it]                                                         {'loss': 0.8482, 'learning_rate': 1.5785941615038102e-06, 'epoch': 0.82}
 82%|████████▏ | 8567/10395 [24:29:29<4:00:56,  7.91s/it] 82%|████████▏ | 8568/10395 [24:29:36<3:55:41,  7.74s/it]                                                         {'loss': 0.9355, 'learning_rate': 1.5769143867142235e-06, 'epoch': 0.82}
 82%|████████▏ | 8568/10395 [24:29:36<3:55:41,  7.74s/it] 82%|████████▏ | 8569/10395 [24:29:44<3:53:59,  7.69s/it]                                                         {'loss': 0.8494, 'learning_rate': 1.5752354296197914e-06, 'epoch': 0.82}
 82%|████████▏ | 8569/10395 [24:29:44<3:53:59,  7.69s/it] 82%|████████▏ | 8570/10395 [24:29:51<3:51:04,  7.60s/it]                                                         {'loss': 0.8531, 'learning_rate': 1.5735572903834962e-06, 'epoch': 0.82}
 82%|████████▏ | 8570/10395 [24:29:51<3:51:04,  7.60s/it] 82%|████████▏ | 8571/10395 [24:29:58<3:48:18,  7.51s/it]                                                         {'loss': 0.8587, 'learning_rate': 1.5718799691682506e-06, 'epoch': 0.82}
 82%|████████▏ | 8571/10395 [24:29:58<3:48:18,  7.51s/it] 82%|████████▏ | 8572/10395 [24:30:06<3:50:19,  7.58s/it]                                                         {'loss': 0.8263, 'learning_rate': 1.5702034661368904e-06, 'epoch': 0.82}
 82%|████████▏ | 8572/10395 [24:30:06<3:50:19,  7.58s/it] 82%|████████▏ | 8573/10395 [24:30:14<3:50:41,  7.60s/it]                                                         {'loss': 0.8838, 'learning_rate': 1.5685277814521593e-06, 'epoch': 0.82}
 82%|████████▏ | 8573/10395 [24:30:14<3:50:41,  7.60s/it] 82%|████████▏ | 8574/10395 [24:30:21<3:47:40,  7.50s/it]                                                         {'loss': 0.8821, 'learning_rate': 1.5668529152767364e-06, 'epoch': 0.82}
 82%|████████▏ | 8574/10395 [24:30:21<3:47:40,  7.50s/it] 82%|████████▏ | 8575/10395 [24:30:29<3:51:11,  7.62s/it]                                                         {'loss': 0.8363, 'learning_rate': 1.5651788677732083e-06, 'epoch': 0.82}
 82%|████████▏ | 8575/10395 [24:30:29<3:51:11,  7.62s/it] 83%|████████▎ | 8576/10395 [24:30:36<3:48:28,  7.54s/it]                                                         {'loss': 0.7922, 'learning_rate': 1.5635056391040904e-06, 'epoch': 0.82}
 83%|████████▎ | 8576/10395 [24:30:36<3:48:28,  7.54s/it] 83%|████████▎ | 8577/10395 [24:30:43<3:44:38,  7.41s/it]                                                         {'loss': 0.8997, 'learning_rate': 1.5618332294318216e-06, 'epoch': 0.83}
 83%|████████▎ | 8577/10395 [24:30:43<3:44:38,  7.41s/it] 83%|████████▎ | 8578/10395 [24:30:51<3:47:13,  7.50s/it]                                                         {'loss': 0.8305, 'learning_rate': 1.5601616389187445e-06, 'epoch': 0.83}
 83%|████████▎ | 8578/10395 [24:30:51<3:47:13,  7.50s/it] 83%|████████▎ | 8579/10395 [24:30:58<3:45:05,  7.44s/it]                                                         {'loss': 0.8346, 'learning_rate': 1.5584908677271405e-06, 'epoch': 0.83}
 83%|████████▎ | 8579/10395 [24:30:58<3:45:05,  7.44s/it] 83%|████████▎ | 8580/10395 [24:31:06<3:50:31,  7.62s/it]                                                         {'loss': 0.8547, 'learning_rate': 1.556820916019206e-06, 'epoch': 0.83}
 83%|████████▎ | 8580/10395 [24:31:06<3:50:31,  7.62s/it] 83%|████████▎ | 8581/10395 [24:31:15<4:00:13,  7.95s/it]                                                         {'loss': 0.8004, 'learning_rate': 1.5551517839570507e-06, 'epoch': 0.83}
 83%|████████▎ | 8581/10395 [24:31:15<4:00:13,  7.95s/it] 83%|████████▎ | 8582/10395 [24:31:22<3:53:00,  7.71s/it]                                                         {'loss': 0.8462, 'learning_rate': 1.5534834717027158e-06, 'epoch': 0.83}
 83%|████████▎ | 8582/10395 [24:31:22<3:53:00,  7.71s/it] 83%|████████▎ | 8583/10395 [24:31:30<3:57:23,  7.86s/it]                                                         {'loss': 0.8374, 'learning_rate': 1.551815979418153e-06, 'epoch': 0.83}
 83%|████████▎ | 8583/10395 [24:31:30<3:57:23,  7.86s/it] 83%|████████▎ | 8584/10395 [24:31:38<3:52:21,  7.70s/it]                                                         {'loss': 0.8166, 'learning_rate': 1.550149307265244e-06, 'epoch': 0.83}
 83%|████████▎ | 8584/10395 [24:31:38<3:52:21,  7.70s/it] 83%|████████▎ | 8585/10395 [24:31:45<3:51:07,  7.66s/it]                                                         {'loss': 0.8711, 'learning_rate': 1.5484834554057827e-06, 'epoch': 0.83}
 83%|████████▎ | 8585/10395 [24:31:45<3:51:07,  7.66s/it] 83%|████████▎ | 8586/10395 [24:31:53<3:49:16,  7.60s/it]                                                         {'loss': 0.8716, 'learning_rate': 1.5468184240014839e-06, 'epoch': 0.83}
 83%|████████▎ | 8586/10395 [24:31:53<3:49:16,  7.60s/it] 83%|████████▎ | 8587/10395 [24:32:01<3:49:50,  7.63s/it]                                                         {'loss': 0.8909, 'learning_rate': 1.5451542132139886e-06, 'epoch': 0.83}
 83%|████████▎ | 8587/10395 [24:32:01<3:49:50,  7.63s/it] 83%|████████▎ | 8588/10395 [24:32:08<3:48:07,  7.57s/it]                                                         {'loss': 0.9263, 'learning_rate': 1.5434908232048551e-06, 'epoch': 0.83}
 83%|████████▎ | 8588/10395 [24:32:08<3:48:07,  7.57s/it] 83%|████████▎ | 8589/10395 [24:32:16<3:50:44,  7.67s/it]                                                         {'loss': 0.8314, 'learning_rate': 1.54182825413556e-06, 'epoch': 0.83}
 83%|████████▎ | 8589/10395 [24:32:16<3:50:44,  7.67s/it] 83%|████████▎ | 8590/10395 [24:32:23<3:46:15,  7.52s/it]                                                         {'loss': 0.8567, 'learning_rate': 1.540166506167504e-06, 'epoch': 0.83}
 83%|████████▎ | 8590/10395 [24:32:23<3:46:15,  7.52s/it] 83%|████████▎ | 8591/10395 [24:32:30<3:44:39,  7.47s/it]                                                         {'loss': 0.9193, 'learning_rate': 1.5385055794620063e-06, 'epoch': 0.83}
 83%|████████▎ | 8591/10395 [24:32:30<3:44:39,  7.47s/it] 83%|████████▎ | 8592/10395 [24:32:38<3:47:42,  7.58s/it]                                                         {'loss': 0.8313, 'learning_rate': 1.5368454741803018e-06, 'epoch': 0.83}
 83%|████████▎ | 8592/10395 [24:32:38<3:47:42,  7.58s/it] 83%|████████▎ | 8593/10395 [24:32:45<3:44:24,  7.47s/it]                                                         {'loss': 0.937, 'learning_rate': 1.5351861904835542e-06, 'epoch': 0.83}
 83%|████████▎ | 8593/10395 [24:32:45<3:44:24,  7.47s/it] 83%|████████▎ | 8594/10395 [24:33:03<5:14:19, 10.47s/it]                                                         {'loss': 0.3608, 'learning_rate': 1.533527728532841e-06, 'epoch': 0.83}
 83%|████████▎ | 8594/10395 [24:33:03<5:14:19, 10.47s/it] 83%|████████▎ | 8595/10395 [24:33:11<4:53:39,  9.79s/it]                                                         {'loss': 0.827, 'learning_rate': 1.5318700884891613e-06, 'epoch': 0.83}
 83%|████████▎ | 8595/10395 [24:33:11<4:53:39,  9.79s/it] 83%|████████▎ | 8596/10395 [24:33:18<4:31:53,  9.07s/it]                                                         {'loss': 0.8622, 'learning_rate': 1.530213270513441e-06, 'epoch': 0.83}
 83%|████████▎ | 8596/10395 [24:33:18<4:31:53,  9.07s/it] 83%|████████▎ | 8597/10395 [24:33:26<4:18:03,  8.61s/it]                                                         {'loss': 0.8239, 'learning_rate': 1.5285572747665134e-06, 'epoch': 0.83}
 83%|████████▎ | 8597/10395 [24:33:26<4:18:03,  8.61s/it] 83%|████████▎ | 8598/10395 [24:33:35<4:20:55,  8.71s/it]                                                         {'loss': 0.7439, 'learning_rate': 1.5269021014091434e-06, 'epoch': 0.83}
 83%|████████▎ | 8598/10395 [24:33:35<4:20:55,  8.71s/it] 83%|████████▎ | 8599/10395 [24:33:42<4:09:29,  8.33s/it]                                                         {'loss': 0.7976, 'learning_rate': 1.5252477506020113e-06, 'epoch': 0.83}
 83%|████████▎ | 8599/10395 [24:33:42<4:09:29,  8.33s/it] 83%|████████▎ | 8600/10395 [24:33:51<4:09:27,  8.34s/it]                                                         {'loss': 0.9089, 'learning_rate': 1.5235942225057154e-06, 'epoch': 0.83}
 83%|████████▎ | 8600/10395 [24:33:51<4:09:27,  8.34s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 83%|████████▎ | 8601/10395 [24:35:32<18:00:38, 36.14s/it]                                                          {'loss': 0.9044, 'learning_rate': 1.5219415172807795e-06, 'epoch': 0.83}
 83%|████████▎ | 8601/10395 [24:35:32<18:00:38, 36.14s/it] 83%|████████▎ | 8602/10395 [24:35:49<15:06:25, 30.33s/it]                                                          {'loss': 0.3728, 'learning_rate': 1.5202896350876407e-06, 'epoch': 0.83}
 83%|████████▎ | 8602/10395 [24:35:49<15:06:25, 30.33s/it] 83%|████████▎ | 8603/10395 [24:35:56<11:40:38, 23.46s/it]                                                          {'loss': 0.8916, 'learning_rate': 1.5186385760866639e-06, 'epoch': 0.83}
 83%|████████▎ | 8603/10395 [24:35:56<11:40:38, 23.46s/it] 83%|████████▎ | 8604/10395 [24:36:04<9:23:48, 18.89s/it]                                                          {'loss': 0.8227, 'learning_rate': 1.5169883404381313e-06, 'epoch': 0.83}
 83%|████████▎ | 8604/10395 [24:36:04<9:23:48, 18.89s/it] 83%|████████▎ | 8605/10395 [24:36:11<7:38:08, 15.36s/it]                                                         {'loss': 0.8667, 'learning_rate': 1.51533892830224e-06, 'epoch': 0.83}
 83%|████████▎ | 8605/10395 [24:36:11<7:38:08, 15.36s/it] 83%|████████▎ | 8606/10395 [24:36:19<6:31:00, 13.11s/it]                                                         {'loss': 0.854, 'learning_rate': 1.5136903398391168e-06, 'epoch': 0.83}
 83%|████████▎ | 8606/10395 [24:36:19<6:31:00, 13.11s/it] 83%|████████▎ | 8607/10395 [24:36:28<5:49:49, 11.74s/it]                                                         {'loss': 0.8832, 'learning_rate': 1.5120425752087985e-06, 'epoch': 0.83}
 83%|████████▎ | 8607/10395 [24:36:28<5:49:49, 11.74s/it] 83%|████████▎ | 8608/10395 [24:36:45<6:38:45, 13.39s/it]                                                         {'loss': 0.3861, 'learning_rate': 1.510395634571248e-06, 'epoch': 0.83}
 83%|████████▎ | 8608/10395 [24:36:45<6:38:45, 13.39s/it] 83%|████████▎ | 8609/10395 [24:36:53<5:48:33, 11.71s/it]                                                         {'loss': 0.8896, 'learning_rate': 1.5087495180863454e-06, 'epoch': 0.83}
 83%|████████▎ | 8609/10395 [24:36:53<5:48:33, 11.71s/it] 83%|████████▎ | 8610/10395 [24:37:01<5:17:34, 10.67s/it]                                                         {'loss': 0.8139, 'learning_rate': 1.5071042259138957e-06, 'epoch': 0.83}
 83%|████████▎ | 8610/10395 [24:37:01<5:17:34, 10.67s/it] 83%|████████▎ | 8611/10395 [24:37:09<4:55:47,  9.95s/it]                                                         {'loss': 0.8854, 'learning_rate': 1.5054597582136176e-06, 'epoch': 0.83}
 83%|████████▎ | 8611/10395 [24:37:09<4:55:47,  9.95s/it] 83%|████████▎ | 8612/10395 [24:37:16<4:31:09,  9.12s/it]                                                         {'loss': 0.9101, 'learning_rate': 1.5038161151451548e-06, 'epoch': 0.83}
 83%|████████▎ | 8612/10395 [24:37:17<4:31:09,  9.12s/it] 83%|████████▎ | 8613/10395 [24:37:25<4:23:16,  8.86s/it]                                                         {'loss': 0.781, 'learning_rate': 1.502173296868067e-06, 'epoch': 0.83}
 83%|████████▎ | 8613/10395 [24:37:25<4:23:16,  8.86s/it] 83%|████████▎ | 8614/10395 [24:37:33<4:15:56,  8.62s/it]                                                         {'loss': 0.7981, 'learning_rate': 1.5005313035418334e-06, 'epoch': 0.83}
 83%|████████▎ | 8614/10395 [24:37:33<4:15:56,  8.62s/it] 83%|████████▎ | 8615/10395 [24:37:50<5:35:04, 11.29s/it]                                                         {'loss': 0.347, 'learning_rate': 1.498890135325859e-06, 'epoch': 0.83}
 83%|████████▎ | 8615/10395 [24:37:50<5:35:04, 11.29s/it] 83%|████████▎ | 8616/10395 [24:37:58<5:06:07, 10.32s/it]                                                         {'loss': 0.865, 'learning_rate': 1.4972497923794627e-06, 'epoch': 0.83}
 83%|████████▎ | 8616/10395 [24:37:58<5:06:07, 10.32s/it] 83%|████████▎ | 8617/10395 [24:38:05<4:35:11,  9.29s/it]                                                         {'loss': 0.9092, 'learning_rate': 1.495610274861885e-06, 'epoch': 0.83}
 83%|████████▎ | 8617/10395 [24:38:05<4:35:11,  9.29s/it] 83%|████████▎ | 8618/10395 [24:38:13<4:19:56,  8.78s/it]                                                         {'loss': 0.9019, 'learning_rate': 1.4939715829322898e-06, 'epoch': 0.83}
 83%|████████▎ | 8618/10395 [24:38:13<4:19:56,  8.78s/it] 83%|████████▎ | 8619/10395 [24:38:20<4:09:22,  8.42s/it]                                                         {'loss': 0.8256, 'learning_rate': 1.4923337167497542e-06, 'epoch': 0.83}
 83%|████████▎ | 8619/10395 [24:38:20<4:09:22,  8.42s/it] 83%|████████▎ | 8620/10395 [24:38:29<4:08:33,  8.40s/it]                                                         {'loss': 0.8007, 'learning_rate': 1.4906966764732832e-06, 'epoch': 0.83}
 83%|████████▎ | 8620/10395 [24:38:29<4:08:33,  8.40s/it] 83%|████████▎ | 8621/10395 [24:38:36<4:01:12,  8.16s/it]                                                         {'loss': 0.885, 'learning_rate': 1.4890604622617933e-06, 'epoch': 0.83}
 83%|████████▎ | 8621/10395 [24:38:36<4:01:12,  8.16s/it] 83%|████████▎ | 8622/10395 [24:38:45<4:02:32,  8.21s/it]                                                         {'loss': 0.9012, 'learning_rate': 1.4874250742741247e-06, 'epoch': 0.83}
 83%|████████▎ | 8622/10395 [24:38:45<4:02:32,  8.21s/it] 83%|████████▎ | 8623/10395 [24:38:53<4:06:08,  8.33s/it]                                                         {'loss': 0.7904, 'learning_rate': 1.4857905126690397e-06, 'epoch': 0.83}
 83%|████████▎ | 8623/10395 [24:38:53<4:06:08,  8.33s/it] 83%|████████▎ | 8624/10395 [24:39:01<3:59:41,  8.12s/it]                                                         {'loss': 0.8439, 'learning_rate': 1.4841567776052145e-06, 'epoch': 0.83}
 83%|████████▎ | 8624/10395 [24:39:01<3:59:41,  8.12s/it] 83%|████████▎ | 8625/10395 [24:39:09<3:58:19,  8.08s/it]                                                         {'loss': 0.8808, 'learning_rate': 1.4825238692412514e-06, 'epoch': 0.83}
 83%|████████▎ | 8625/10395 [24:39:09<3:58:19,  8.08s/it] 83%|████████▎ | 8626/10395 [24:39:18<4:02:26,  8.22s/it]                                                         {'loss': 0.8548, 'learning_rate': 1.480891787735672e-06, 'epoch': 0.83}
 83%|████████▎ | 8626/10395 [24:39:18<4:02:26,  8.22s/it] 83%|████████▎ | 8627/10395 [24:39:26<4:04:56,  8.31s/it]                                                         {'loss': 0.8611, 'learning_rate': 1.4792605332469089e-06, 'epoch': 0.83}
 83%|████████▎ | 8627/10395 [24:39:26<4:04:56,  8.31s/it] 83%|████████▎ | 8628/10395 [24:39:34<4:05:15,  8.33s/it]                                                         {'loss': 0.8622, 'learning_rate': 1.4776301059333275e-06, 'epoch': 0.83}
 83%|████████▎ | 8628/10395 [24:39:34<4:05:15,  8.33s/it] 83%|████████▎ | 8629/10395 [24:39:42<3:56:51,  8.05s/it]                                                         {'loss': 0.8161, 'learning_rate': 1.4760005059532034e-06, 'epoch': 0.83}
 83%|████████▎ | 8629/10395 [24:39:42<3:56:51,  8.05s/it] 83%|████████▎ | 8630/10395 [24:39:50<3:53:50,  7.95s/it]                                                         {'loss': 0.8948, 'learning_rate': 1.4743717334647313e-06, 'epoch': 0.83}
 83%|████████▎ | 8630/10395 [24:39:50<3:53:50,  7.95s/it] 83%|████████▎ | 8631/10395 [24:39:57<3:49:04,  7.79s/it]                                                         {'loss': 0.7969, 'learning_rate': 1.4727437886260343e-06, 'epoch': 0.83}
 83%|████████▎ | 8631/10395 [24:39:57<3:49:04,  7.79s/it] 83%|████████▎ | 8632/10395 [24:40:05<3:50:47,  7.85s/it]                                                         {'loss': 0.8719, 'learning_rate': 1.4711166715951453e-06, 'epoch': 0.83}
 83%|████████▎ | 8632/10395 [24:40:05<3:50:47,  7.85s/it] 83%|████████▎ | 8633/10395 [24:40:12<3:47:05,  7.73s/it]                                                         {'loss': 0.8554, 'learning_rate': 1.4694903825300234e-06, 'epoch': 0.83}
 83%|████████▎ | 8633/10395 [24:40:12<3:47:05,  7.73s/it] 83%|████████▎ | 8634/10395 [24:40:20<3:42:06,  7.57s/it]                                                         {'loss': 0.7768, 'learning_rate': 1.4678649215885476e-06, 'epoch': 0.83}
 83%|████████▎ | 8634/10395 [24:40:20<3:42:06,  7.57s/it] 83%|████████▎ | 8635/10395 [24:40:27<3:42:10,  7.57s/it]                                                         {'loss': 0.8872, 'learning_rate': 1.4662402889285131e-06, 'epoch': 0.83}
 83%|████████▎ | 8635/10395 [24:40:27<3:42:10,  7.57s/it] 83%|████████▎ | 8636/10395 [24:40:34<3:39:21,  7.48s/it]                                                         {'loss': 0.8883, 'learning_rate': 1.4646164847076317e-06, 'epoch': 0.83}
 83%|████████▎ | 8636/10395 [24:40:34<3:39:21,  7.48s/it] 83%|████████▎ | 8637/10395 [24:40:42<3:38:40,  7.46s/it]                                                         {'loss': 0.8275, 'learning_rate': 1.4629935090835434e-06, 'epoch': 0.83}
 83%|████████▎ | 8637/10395 [24:40:42<3:38:40,  7.46s/it] 83%|████████▎ | 8638/10395 [24:40:49<3:39:24,  7.49s/it]                                                         {'loss': 0.8443, 'learning_rate': 1.4613713622138004e-06, 'epoch': 0.83}
 83%|████████▎ | 8638/10395 [24:40:49<3:39:24,  7.49s/it] 83%|████████▎ | 8639/10395 [24:40:58<3:45:29,  7.70s/it]                                                         {'loss': 0.8315, 'learning_rate': 1.4597500442558798e-06, 'epoch': 0.83}
 83%|████████▎ | 8639/10395 [24:40:58<3:45:29,  7.70s/it] 83%|████████▎ | 8640/10395 [24:41:05<3:40:47,  7.55s/it]                                                         {'loss': 0.9683, 'learning_rate': 1.4581295553671725e-06, 'epoch': 0.83}
 83%|████████▎ | 8640/10395 [24:41:05<3:40:47,  7.55s/it] 83%|████████▎ | 8641/10395 [24:41:14<3:57:59,  8.14s/it]                                                         {'loss': 0.79, 'learning_rate': 1.456509895704994e-06, 'epoch': 0.83}
 83%|████████▎ | 8641/10395 [24:41:14<3:57:59,  8.14s/it] 83%|████████▎ | 8642/10395 [24:41:22<3:57:05,  8.11s/it]                                                         {'loss': 0.8798, 'learning_rate': 1.454891065426579e-06, 'epoch': 0.83}
 83%|████████▎ | 8642/10395 [24:41:22<3:57:05,  8.11s/it] 83%|████████▎ | 8643/10395 [24:41:30<3:51:31,  7.93s/it]                                                         {'loss': 0.8465, 'learning_rate': 1.4532730646890791e-06, 'epoch': 0.83}
 83%|████████▎ | 8643/10395 [24:41:30<3:51:31,  7.93s/it] 83%|████████▎ | 8644/10395 [24:41:46<5:06:56, 10.52s/it]                                                         {'loss': 0.3119, 'learning_rate': 1.4516558936495629e-06, 'epoch': 0.83}
 83%|████████▎ | 8644/10395 [24:41:46<5:06:56, 10.52s/it] 83%|████████▎ | 8645/10395 [24:41:54<4:38:03,  9.53s/it]                                                         {'loss': 0.8375, 'learning_rate': 1.4500395524650268e-06, 'epoch': 0.83}
 83%|████████▎ | 8645/10395 [24:41:54<4:38:03,  9.53s/it] 83%|████████▎ | 8646/10395 [24:42:02<4:23:55,  9.05s/it]                                                         {'loss': 0.8996, 'learning_rate': 1.4484240412923778e-06, 'epoch': 0.83}
 83%|████████▎ | 8646/10395 [24:42:02<4:23:55,  9.05s/it] 83%|████████▎ | 8647/10395 [24:42:10<4:18:41,  8.88s/it]                                                         {'loss': 0.8179, 'learning_rate': 1.4468093602884502e-06, 'epoch': 0.83}
 83%|████████▎ | 8647/10395 [24:42:10<4:18:41,  8.88s/it] 83%|████████▎ | 8648/10395 [24:42:18<4:07:33,  8.50s/it]                                                         {'loss': 0.8493, 'learning_rate': 1.4451955096099902e-06, 'epoch': 0.83}
 83%|████████▎ | 8648/10395 [24:42:18<4:07:33,  8.50s/it] 83%|████████▎ | 8649/10395 [24:42:25<3:58:54,  8.21s/it]                                                         {'loss': 0.8698, 'learning_rate': 1.4435824894136673e-06, 'epoch': 0.83}
 83%|████████▎ | 8649/10395 [24:42:25<3:58:54,  8.21s/it] 83%|████████▎ | 8650/10395 [24:42:33<3:56:40,  8.14s/it]                                                         {'loss': 0.8432, 'learning_rate': 1.441970299856076e-06, 'epoch': 0.83}
 83%|████████▎ | 8650/10395 [24:42:33<3:56:40,  8.14s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 83%|████████▎ | 8651/10395 [24:44:16<17:45:00, 36.64s/it]                                                          {'loss': 0.8988, 'learning_rate': 1.4403589410937158e-06, 'epoch': 0.83}
 83%|████████▎ | 8651/10395 [24:44:16<17:45:00, 36.64s/it] 83%|████████▎ | 8652/10395 [24:44:26<13:50:03, 28.57s/it]                                                          {'loss': 0.8333, 'learning_rate': 1.4387484132830164e-06, 'epoch': 0.83}
 83%|████████▎ | 8652/10395 [24:44:26<13:50:03, 28.57s/it] 83%|████████▎ | 8653/10395 [24:44:33<10:43:06, 22.15s/it]                                                          {'loss': 0.8995, 'learning_rate': 1.4371387165803285e-06, 'epoch': 0.83}
 83%|████████▎ | 8653/10395 [24:44:33<10:43:06, 22.15s/it] 83%|████████▎ | 8654/10395 [24:44:41<8:33:32, 17.70s/it]                                                          {'loss': 0.9163, 'learning_rate': 1.4355298511419124e-06, 'epoch': 0.83}
 83%|████████▎ | 8654/10395 [24:44:41<8:33:32, 17.70s/it] 83%|████████▎ | 8655/10395 [24:44:57<8:18:27, 17.19s/it]                                                         {'loss': 0.3817, 'learning_rate': 1.4339218171239588e-06, 'epoch': 0.83}
 83%|████████▎ | 8655/10395 [24:44:57<8:18:27, 17.19s/it] 83%|████████▎ | 8656/10395 [24:45:04<6:52:34, 14.23s/it]                                                         {'loss': 0.8253, 'learning_rate': 1.4323146146825661e-06, 'epoch': 0.83}
 83%|████████▎ | 8656/10395 [24:45:04<6:52:34, 14.23s/it] 83%|████████▎ | 8657/10395 [24:45:12<5:58:44, 12.38s/it]                                                         {'loss': 0.8862, 'learning_rate': 1.4307082439737652e-06, 'epoch': 0.83}
 83%|████████▎ | 8657/10395 [24:45:12<5:58:44, 12.38s/it] 83%|████████▎ | 8658/10395 [24:45:21<5:25:41, 11.25s/it]                                                         {'loss': 0.7697, 'learning_rate': 1.4291027051534944e-06, 'epoch': 0.83}
 83%|████████▎ | 8658/10395 [24:45:21<5:25:41, 11.25s/it] 83%|████████▎ | 8659/10395 [24:45:29<5:00:20, 10.38s/it]                                                         {'loss': 0.8607, 'learning_rate': 1.427497998377615e-06, 'epoch': 0.83}
 83%|████████▎ | 8659/10395 [24:45:29<5:00:20, 10.38s/it] 83%|████████▎ | 8660/10395 [24:45:37<4:35:57,  9.54s/it]                                                         {'loss': 0.8581, 'learning_rate': 1.4258941238019097e-06, 'epoch': 0.83}
 83%|████████▎ | 8660/10395 [24:45:37<4:35:57,  9.54s/it] 83%|████████▎ | 8661/10395 [24:45:45<4:22:28,  9.08s/it]                                                         {'loss': 0.8599, 'learning_rate': 1.4242910815820832e-06, 'epoch': 0.83}
 83%|████████▎ | 8661/10395 [24:45:45<4:22:28,  9.08s/it] 83%|████████▎ | 8662/10395 [24:45:52<4:04:35,  8.47s/it]                                                         {'loss': 0.9341, 'learning_rate': 1.4226888718737485e-06, 'epoch': 0.83}
 83%|████████▎ | 8662/10395 [24:45:52<4:04:35,  8.47s/it] 83%|████████▎ | 8663/10395 [24:45:59<3:53:57,  8.10s/it]                                                         {'loss': 0.767, 'learning_rate': 1.4210874948324515e-06, 'epoch': 0.83}
 83%|████████▎ | 8663/10395 [24:45:59<3:53:57,  8.10s/it] 83%|████████▎ | 8664/10395 [24:46:06<3:46:47,  7.86s/it]                                                         {'loss': 0.7739, 'learning_rate': 1.4194869506136455e-06, 'epoch': 0.83}
 83%|████████▎ | 8664/10395 [24:46:06<3:46:47,  7.86s/it] 83%|████████▎ | 8665/10395 [24:46:13<3:42:36,  7.72s/it]                                                         {'loss': 0.8233, 'learning_rate': 1.4178872393727116e-06, 'epoch': 0.83}
 83%|████████▎ | 8665/10395 [24:46:13<3:42:36,  7.72s/it] 83%|████████▎ | 8666/10395 [24:46:21<3:40:35,  7.66s/it]                                                         {'loss': 0.8711, 'learning_rate': 1.4162883612649448e-06, 'epoch': 0.83}
 83%|████████▎ | 8666/10395 [24:46:21<3:40:35,  7.66s/it] 83%|████████▎ | 8667/10395 [24:46:29<3:45:04,  7.82s/it]                                                         {'loss': 0.8459, 'learning_rate': 1.4146903164455571e-06, 'epoch': 0.83}
 83%|████████▎ | 8667/10395 [24:46:29<3:45:04,  7.82s/it] 83%|████████▎ | 8668/10395 [24:46:37<3:43:09,  7.75s/it]                                                         {'loss': 0.8666, 'learning_rate': 1.4130931050696873e-06, 'epoch': 0.83}
 83%|████████▎ | 8668/10395 [24:46:37<3:43:09,  7.75s/it] 83%|████████▎ | 8669/10395 [24:46:44<3:38:29,  7.60s/it]                                                         {'loss': 0.8897, 'learning_rate': 1.4114967272923907e-06, 'epoch': 0.83}
 83%|████████▎ | 8669/10395 [24:46:44<3:38:29,  7.60s/it] 83%|████████▎ | 8670/10395 [24:46:52<3:42:03,  7.72s/it]                                                         {'loss': 0.8211, 'learning_rate': 1.409901183268636e-06, 'epoch': 0.83}
 83%|████████▎ | 8670/10395 [24:46:52<3:42:03,  7.72s/it] 83%|████████▎ | 8671/10395 [24:47:00<3:42:27,  7.74s/it]                                                         {'loss': 0.929, 'learning_rate': 1.4083064731533202e-06, 'epoch': 0.83}
 83%|████████▎ | 8671/10395 [24:47:00<3:42:27,  7.74s/it] 83%|████████▎ | 8672/10395 [24:47:08<3:48:15,  7.95s/it]                                                         {'loss': 0.9551, 'learning_rate': 1.4067125971012508e-06, 'epoch': 0.83}
 83%|████████▎ | 8672/10395 [24:47:08<3:48:15,  7.95s/it] 83%|████████▎ | 8673/10395 [24:47:16<3:48:28,  7.96s/it]                                                         {'loss': 0.8488, 'learning_rate': 1.4051195552671559e-06, 'epoch': 0.83}
 83%|████████▎ | 8673/10395 [24:47:16<3:48:28,  7.96s/it] 83%|████████▎ | 8674/10395 [24:47:24<3:42:54,  7.77s/it]                                                         {'loss': 0.8799, 'learning_rate': 1.4035273478056878e-06, 'epoch': 0.83}
 83%|████████▎ | 8674/10395 [24:47:24<3:42:54,  7.77s/it] 83%|████████▎ | 8675/10395 [24:47:31<3:41:53,  7.74s/it]                                                         {'loss': 0.8567, 'learning_rate': 1.4019359748714168e-06, 'epoch': 0.83}
 83%|████████▎ | 8675/10395 [24:47:31<3:41:53,  7.74s/it] 83%|████████▎ | 8676/10395 [24:47:39<3:40:50,  7.71s/it]                                                         {'loss': 0.905, 'learning_rate': 1.400345436618824e-06, 'epoch': 0.83}
 83%|████████▎ | 8676/10395 [24:47:39<3:40:50,  7.71s/it] 83%|████████▎ | 8677/10395 [24:47:46<3:38:42,  7.64s/it]                                                         {'loss': 0.7607, 'learning_rate': 1.3987557332023215e-06, 'epoch': 0.83}
 83%|████████▎ | 8677/10395 [24:47:46<3:38:42,  7.64s/it] 83%|████████▎ | 8678/10395 [24:47:55<3:45:10,  7.87s/it]                                                         {'loss': 0.8922, 'learning_rate': 1.3971668647762293e-06, 'epoch': 0.83}
 83%|████████▎ | 8678/10395 [24:47:55<3:45:10,  7.87s/it] 83%|████████▎ | 8679/10395 [24:48:02<3:41:29,  7.74s/it]                                                         {'loss': 0.8176, 'learning_rate': 1.395578831494795e-06, 'epoch': 0.83}
 83%|████████▎ | 8679/10395 [24:48:02<3:41:29,  7.74s/it] 84%|████████▎ | 8680/10395 [24:48:10<3:39:08,  7.67s/it]                                                         {'loss': 0.8637, 'learning_rate': 1.3939916335121807e-06, 'epoch': 0.83}
 84%|████████▎ | 8680/10395 [24:48:10<3:39:08,  7.67s/it] 84%|████████▎ | 8681/10395 [24:48:18<3:43:19,  7.82s/it]                                                         {'loss': 0.9741, 'learning_rate': 1.3924052709824653e-06, 'epoch': 0.84}
 84%|████████▎ | 8681/10395 [24:48:18<3:43:19,  7.82s/it] 84%|████████▎ | 8682/10395 [24:48:26<3:42:45,  7.80s/it]                                                         {'loss': 0.8924, 'learning_rate': 1.3908197440596516e-06, 'epoch': 0.84}
 84%|████████▎ | 8682/10395 [24:48:26<3:42:45,  7.80s/it] 84%|████████▎ | 8683/10395 [24:48:35<3:57:44,  8.33s/it]                                                         {'loss': 0.8851, 'learning_rate': 1.3892350528976617e-06, 'epoch': 0.84}
 84%|████████▎ | 8683/10395 [24:48:35<3:57:44,  8.33s/it] 84%|████████▎ | 8684/10395 [24:48:43<3:57:02,  8.31s/it]                                                         {'loss': 0.9053, 'learning_rate': 1.3876511976503292e-06, 'epoch': 0.84}
 84%|████████▎ | 8684/10395 [24:48:43<3:57:02,  8.31s/it] 84%|████████▎ | 8685/10395 [24:49:00<5:06:12, 10.74s/it]                                                         {'loss': 0.3432, 'learning_rate': 1.386068178471416e-06, 'epoch': 0.84}
 84%|████████▎ | 8685/10395 [24:49:00<5:06:12, 10.74s/it] 84%|████████▎ | 8686/10395 [24:49:08<4:40:37,  9.85s/it]                                                         {'loss': 0.8829, 'learning_rate': 1.3844859955145928e-06, 'epoch': 0.84}
 84%|████████▎ | 8686/10395 [24:49:08<4:40:37,  9.85s/it] 84%|████████▎ | 8687/10395 [24:49:16<4:27:55,  9.41s/it]                                                         {'loss': 0.8329, 'learning_rate': 1.382904648933462e-06, 'epoch': 0.84}
 84%|████████▎ | 8687/10395 [24:49:16<4:27:55,  9.41s/it] 84%|████████▎ | 8688/10395 [24:49:24<4:15:41,  8.99s/it]                                                         {'loss': 0.8399, 'learning_rate': 1.3813241388815312e-06, 'epoch': 0.84}
 84%|████████▎ | 8688/10395 [24:49:24<4:15:41,  8.99s/it] 84%|████████▎ | 8689/10395 [24:49:31<4:00:52,  8.47s/it]                                                         {'loss': 0.9204, 'learning_rate': 1.3797444655122338e-06, 'epoch': 0.84}
 84%|████████▎ | 8689/10395 [24:49:31<4:00:52,  8.47s/it] 84%|████████▎ | 8690/10395 [24:49:40<3:59:21,  8.42s/it]                                                         {'loss': 0.8857, 'learning_rate': 1.3781656289789213e-06, 'epoch': 0.84}
 84%|████████▎ | 8690/10395 [24:49:40<3:59:21,  8.42s/it] 84%|████████▎ | 8691/10395 [24:49:47<3:52:33,  8.19s/it]                                                         {'loss': 0.8542, 'learning_rate': 1.376587629434868e-06, 'epoch': 0.84}
 84%|████████▎ | 8691/10395 [24:49:47<3:52:33,  8.19s/it] 84%|████████▎ | 8692/10395 [24:49:55<3:50:46,  8.13s/it]                                                         {'loss': 0.8383, 'learning_rate': 1.3750104670332566e-06, 'epoch': 0.84}
 84%|████████▎ | 8692/10395 [24:49:55<3:50:46,  8.13s/it] 84%|████████▎ | 8693/10395 [24:50:03<3:48:28,  8.05s/it]                                                         {'loss': 0.8669, 'learning_rate': 1.373434141927199e-06, 'epoch': 0.84}
 84%|████████▎ | 8693/10395 [24:50:03<3:48:28,  8.05s/it] 84%|████████▎ | 8694/10395 [24:50:11<3:44:18,  7.91s/it]                                                         {'loss': 0.8289, 'learning_rate': 1.37185865426972e-06, 'epoch': 0.84}
 84%|████████▎ | 8694/10395 [24:50:11<3:44:18,  7.91s/it] 84%|████████▎ | 8695/10395 [24:50:19<3:44:11,  7.91s/it]                                                         {'loss': 0.8863, 'learning_rate': 1.3702840042137621e-06, 'epoch': 0.84}
 84%|████████▎ | 8695/10395 [24:50:19<3:44:11,  7.91s/it] 84%|████████▎ | 8696/10395 [24:50:27<3:45:07,  7.95s/it]                                                         {'loss': 0.8916, 'learning_rate': 1.3687101919121947e-06, 'epoch': 0.84}
 84%|████████▎ | 8696/10395 [24:50:27<3:45:07,  7.95s/it] 84%|████████▎ | 8697/10395 [24:50:45<5:09:45, 10.95s/it]                                                         {'loss': 0.3662, 'learning_rate': 1.3671372175177934e-06, 'epoch': 0.84}
 84%|████████▎ | 8697/10395 [24:50:45<5:09:45, 10.95s/it] 84%|████████▎ | 8698/10395 [24:50:53<4:45:48, 10.10s/it]                                                         {'loss': 0.8687, 'learning_rate': 1.3655650811832632e-06, 'epoch': 0.84}
 84%|████████▎ | 8698/10395 [24:50:53<4:45:48, 10.10s/it] 84%|████████▎ | 8699/10395 [24:51:00<4:25:40,  9.40s/it]                                                         {'loss': 0.9011, 'learning_rate': 1.3639937830612248e-06, 'epoch': 0.84}
 84%|████████▎ | 8699/10395 [24:51:00<4:25:40,  9.40s/it] 84%|████████▎ | 8700/10395 [24:51:10<4:25:32,  9.40s/it]                                                         {'loss': 0.7562, 'learning_rate': 1.3624233233042128e-06, 'epoch': 0.84}
 84%|████████▎ | 8700/10395 [24:51:10<4:25:32,  9.40s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 84%|████████▎ | 8701/10395 [24:52:53<17:43:18, 37.66s/it]                                                          {'loss': 0.8654, 'learning_rate': 1.3608537020646872e-06, 'epoch': 0.84}
 84%|████████▎ | 8701/10395 [24:52:54<17:43:18, 37.66s/it] 84%|████████▎ | 8702/10395 [24:53:01<13:28:47, 28.66s/it]                                                          {'loss': 0.8189, 'learning_rate': 1.3592849194950241e-06, 'epoch': 0.84}
 84%|████████▎ | 8702/10395 [24:53:01<13:28:47, 28.66s/it] 84%|████████▎ | 8703/10395 [24:53:09<10:31:55, 22.41s/it]                                                          {'loss': 0.8492, 'learning_rate': 1.3577169757475117e-06, 'epoch': 0.84}
 84%|████████▎ | 8703/10395 [24:53:09<10:31:55, 22.41s/it] 84%|████████▎ | 8704/10395 [24:53:18<8:36:03, 18.31s/it]                                                          {'loss': 0.8898, 'learning_rate': 1.3561498709743703e-06, 'epoch': 0.84}
 84%|████████▎ | 8704/10395 [24:53:18<8:36:03, 18.31s/it] 84%|████████▎ | 8705/10395 [24:53:28<7:23:59, 15.76s/it]                                                         {'loss': 0.736, 'learning_rate': 1.354583605327725e-06, 'epoch': 0.84}
 84%|████████▎ | 8705/10395 [24:53:28<7:23:59, 15.76s/it] 84%|████████▍ | 8706/10395 [24:53:35<6:12:30, 13.23s/it]                                                         {'loss': 0.9084, 'learning_rate': 1.3530181789596274e-06, 'epoch': 0.84}
 84%|████████▍ | 8706/10395 [24:53:35<6:12:30, 13.23s/it] 84%|████████▍ | 8707/10395 [24:53:43<5:24:59, 11.55s/it]                                                         {'loss': 0.8714, 'learning_rate': 1.3514535920220494e-06, 'epoch': 0.84}
 84%|████████▍ | 8707/10395 [24:53:43<5:24:59, 11.55s/it] 84%|████████▍ | 8708/10395 [24:53:50<4:49:41, 10.30s/it]                                                         {'loss': 0.915, 'learning_rate': 1.3498898446668718e-06, 'epoch': 0.84}
 84%|████████▍ | 8708/10395 [24:53:50<4:49:41, 10.30s/it] 84%|████████▍ | 8709/10395 [24:53:57<4:23:32,  9.38s/it]                                                         {'loss': 0.8775, 'learning_rate': 1.348326937045905e-06, 'epoch': 0.84}
 84%|████████▍ | 8709/10395 [24:53:57<4:23:32,  9.38s/it] 84%|████████▍ | 8710/10395 [24:54:05<4:08:22,  8.84s/it]                                                         {'loss': 0.8987, 'learning_rate': 1.3467648693108703e-06, 'epoch': 0.84}
 84%|████████▍ | 8710/10395 [24:54:05<4:08:22,  8.84s/it] 84%|████████▍ | 8711/10395 [24:54:12<3:58:46,  8.51s/it]                                                         {'loss': 0.8153, 'learning_rate': 1.3452036416134084e-06, 'epoch': 0.84}
 84%|████████▍ | 8711/10395 [24:54:12<3:58:46,  8.51s/it] 84%|████████▍ | 8712/10395 [24:54:20<3:46:59,  8.09s/it]                                                         {'loss': 0.9071, 'learning_rate': 1.3436432541050837e-06, 'epoch': 0.84}
 84%|████████▍ | 8712/10395 [24:54:20<3:46:59,  8.09s/it] 84%|████████▍ | 8713/10395 [24:54:27<3:42:27,  7.94s/it]                                                         {'loss': 0.8339, 'learning_rate': 1.3420837069373705e-06, 'epoch': 0.84}
 84%|████████▍ | 8713/10395 [24:54:27<3:42:27,  7.94s/it] 84%|████████▍ | 8714/10395 [24:54:35<3:40:38,  7.88s/it]                                                         {'loss': 0.8355, 'learning_rate': 1.3405250002616688e-06, 'epoch': 0.84}
 84%|████████▍ | 8714/10395 [24:54:35<3:40:38,  7.88s/it] 84%|████████▍ | 8715/10395 [24:54:43<3:40:28,  7.87s/it]                                                         {'loss': 0.8075, 'learning_rate': 1.3389671342292975e-06, 'epoch': 0.84}
 84%|████████▍ | 8715/10395 [24:54:43<3:40:28,  7.87s/it] 84%|████████▍ | 8716/10395 [24:54:50<3:34:55,  7.68s/it]                                                         {'loss': 0.9104, 'learning_rate': 1.3374101089914882e-06, 'epoch': 0.84}
 84%|████████▍ | 8716/10395 [24:54:50<3:34:55,  7.68s/it] 84%|████████▍ | 8717/10395 [24:54:58<3:41:15,  7.91s/it]                                                         {'loss': 0.8317, 'learning_rate': 1.3358539246993906e-06, 'epoch': 0.84}
 84%|████████▍ | 8717/10395 [24:54:58<3:41:15,  7.91s/it] 84%|████████▍ | 8718/10395 [24:55:06<3:41:02,  7.91s/it]                                                         {'loss': 0.8796, 'learning_rate': 1.3342985815040821e-06, 'epoch': 0.84}
 84%|████████▍ | 8718/10395 [24:55:06<3:41:02,  7.91s/it] 84%|████████▍ | 8719/10395 [24:55:14<3:37:45,  7.80s/it]                                                         {'loss': 0.9132, 'learning_rate': 1.332744079556546e-06, 'epoch': 0.84}
 84%|████████▍ | 8719/10395 [24:55:14<3:37:45,  7.80s/it] 84%|████████▍ | 8720/10395 [24:55:22<3:38:01,  7.81s/it]                                                         {'loss': 0.7464, 'learning_rate': 1.3311904190076942e-06, 'epoch': 0.84}
 84%|████████▍ | 8720/10395 [24:55:22<3:38:01,  7.81s/it] 84%|████████▍ | 8721/10395 [24:55:29<3:35:33,  7.73s/it]                                                         {'loss': 0.8416, 'learning_rate': 1.329637600008349e-06, 'epoch': 0.84}
 84%|████████▍ | 8721/10395 [24:55:29<3:35:33,  7.73s/it] 84%|████████▍ | 8722/10395 [24:55:37<3:36:39,  7.77s/it]                                                         {'loss': 0.7798, 'learning_rate': 1.3280856227092575e-06, 'epoch': 0.84}
 84%|████████▍ | 8722/10395 [24:55:37<3:36:39,  7.77s/it] 84%|████████▍ | 8723/10395 [24:55:44<3:33:19,  7.66s/it]                                                         {'loss': 0.7881, 'learning_rate': 1.3265344872610841e-06, 'epoch': 0.84}
 84%|████████▍ | 8723/10395 [24:55:44<3:33:19,  7.66s/it] 84%|████████▍ | 8724/10395 [24:55:52<3:32:51,  7.64s/it]                                                         {'loss': 0.8514, 'learning_rate': 1.324984193814407e-06, 'epoch': 0.84}
 84%|████████▍ | 8724/10395 [24:55:52<3:32:51,  7.64s/it] 84%|████████▍ | 8725/10395 [24:56:00<3:33:14,  7.66s/it]                                                         {'loss': 0.8228, 'learning_rate': 1.3234347425197237e-06, 'epoch': 0.84}
 84%|████████▍ | 8725/10395 [24:56:00<3:33:14,  7.66s/it] 84%|████████▍ | 8726/10395 [24:56:07<3:29:01,  7.51s/it]                                                         {'loss': 0.864, 'learning_rate': 1.321886133527457e-06, 'epoch': 0.84}
 84%|████████▍ | 8726/10395 [24:56:07<3:29:01,  7.51s/it] 84%|████████▍ | 8727/10395 [24:56:25<4:55:15, 10.62s/it]                                                         {'loss': 0.3683, 'learning_rate': 1.3203383669879355e-06, 'epoch': 0.84}
 84%|████████▍ | 8727/10395 [24:56:25<4:55:15, 10.62s/it] 84%|████████▍ | 8728/10395 [24:56:33<4:30:59,  9.75s/it]                                                         {'loss': 0.8649, 'learning_rate': 1.3187914430514193e-06, 'epoch': 0.84}
 84%|████████▍ | 8728/10395 [24:56:33<4:30:59,  9.75s/it] 84%|████████▍ | 8729/10395 [24:56:50<5:31:56, 11.95s/it]                                                         {'loss': 0.3636, 'learning_rate': 1.3172453618680758e-06, 'epoch': 0.84}
 84%|████████▍ | 8729/10395 [24:56:50<5:31:56, 11.95s/it] 84%|████████▍ | 8730/10395 [24:56:58<4:58:41, 10.76s/it]                                                         {'loss': 0.8704, 'learning_rate': 1.3157001235879985e-06, 'epoch': 0.84}
 84%|████████▍ | 8730/10395 [24:56:58<4:58:41, 10.76s/it] 84%|████████▍ | 8731/10395 [24:57:05<4:32:46,  9.84s/it]                                                         {'loss': 0.865, 'learning_rate': 1.3141557283611983e-06, 'epoch': 0.84}
 84%|████████▍ | 8731/10395 [24:57:05<4:32:46,  9.84s/it] 84%|████████▍ | 8732/10395 [24:57:13<4:13:29,  9.15s/it]                                                         {'loss': 0.8874, 'learning_rate': 1.3126121763375944e-06, 'epoch': 0.84}
 84%|████████▍ | 8732/10395 [24:57:13<4:13:29,  9.15s/it] 84%|████████▍ | 8733/10395 [24:57:21<4:05:56,  8.88s/it]                                                         {'loss': 0.8311, 'learning_rate': 1.3110694676670343e-06, 'epoch': 0.84}
 84%|████████▍ | 8733/10395 [24:57:21<4:05:56,  8.88s/it] 84%|████████▍ | 8734/10395 [24:57:30<4:06:58,  8.92s/it]                                                         {'loss': 0.8645, 'learning_rate': 1.3095276024992854e-06, 'epoch': 0.84}
 84%|████████▍ | 8734/10395 [24:57:30<4:06:58,  8.92s/it] 84%|████████▍ | 8735/10395 [24:57:38<3:55:47,  8.52s/it]                                                         {'loss': 0.8593, 'learning_rate': 1.307986580984022e-06, 'epoch': 0.84}
 84%|████████▍ | 8735/10395 [24:57:38<3:55:47,  8.52s/it] 84%|████████▍ | 8736/10395 [24:57:45<3:46:39,  8.20s/it]                                                         {'loss': 0.8395, 'learning_rate': 1.3064464032708491e-06, 'epoch': 0.84}
 84%|████████▍ | 8736/10395 [24:57:45<3:46:39,  8.20s/it] 84%|████████▍ | 8737/10395 [24:57:53<3:45:21,  8.16s/it]                                                         {'loss': 0.765, 'learning_rate': 1.304907069509279e-06, 'epoch': 0.84}
 84%|████████▍ | 8737/10395 [24:57:53<3:45:21,  8.16s/it] 84%|████████▍ | 8738/10395 [24:58:01<3:43:00,  8.08s/it]                                                         {'loss': 0.8645, 'learning_rate': 1.3033685798487517e-06, 'epoch': 0.84}
 84%|████████▍ | 8738/10395 [24:58:01<3:43:00,  8.08s/it] 84%|████████▍ | 8739/10395 [24:58:19<5:02:38, 10.97s/it]                                                         {'loss': 0.3239, 'learning_rate': 1.301830934438616e-06, 'epoch': 0.84}
 84%|████████▍ | 8739/10395 [24:58:19<5:02:38, 10.97s/it] 84%|████████▍ | 8740/10395 [24:58:26<4:33:46,  9.93s/it]                                                         {'loss': 0.8768, 'learning_rate': 1.300294133428146e-06, 'epoch': 0.84}
 84%|████████▍ | 8740/10395 [24:58:26<4:33:46,  9.93s/it] 84%|████████▍ | 8741/10395 [24:58:35<4:26:49,  9.68s/it]                                                         {'loss': 0.8419, 'learning_rate': 1.2987581769665293e-06, 'epoch': 0.84}
 84%|████████▍ | 8741/10395 [24:58:35<4:26:49,  9.68s/it] 84%|████████▍ | 8742/10395 [24:58:43<4:09:44,  9.07s/it]                                                         {'loss': 0.9313, 'learning_rate': 1.297223065202875e-06, 'epoch': 0.84}
 84%|████████▍ | 8742/10395 [24:58:43<4:09:44,  9.07s/it] 84%|████████▍ | 8743/10395 [24:58:51<3:59:34,  8.70s/it]                                                         {'loss': 0.9674, 'learning_rate': 1.2956887982862065e-06, 'epoch': 0.84}
 84%|████████▍ | 8743/10395 [24:58:51<3:59:34,  8.70s/it] 84%|████████▍ | 8744/10395 [24:58:58<3:49:07,  8.33s/it]                                                         {'loss': 0.8167, 'learning_rate': 1.294155376365468e-06, 'epoch': 0.84}
 84%|████████▍ | 8744/10395 [24:58:58<3:49:07,  8.33s/it] 84%|████████▍ | 8745/10395 [24:59:06<3:43:16,  8.12s/it]                                                         {'loss': 0.8926, 'learning_rate': 1.2926227995895234e-06, 'epoch': 0.84}
 84%|████████▍ | 8745/10395 [24:59:06<3:43:16,  8.12s/it] 84%|████████▍ | 8746/10395 [24:59:14<3:42:37,  8.10s/it]                                                         {'loss': 0.9079, 'learning_rate': 1.2910910681071499e-06, 'epoch': 0.84}
 84%|████████▍ | 8746/10395 [24:59:14<3:42:37,  8.10s/it] 84%|████████▍ | 8747/10395 [24:59:22<3:44:50,  8.19s/it]                                                         {'loss': 0.8555, 'learning_rate': 1.2895601820670423e-06, 'epoch': 0.84}
 84%|████████▍ | 8747/10395 [24:59:22<3:44:50,  8.19s/it] 84%|████████▍ | 8748/10395 [24:59:30<3:40:28,  8.03s/it]                                                         {'loss': 0.8549, 'learning_rate': 1.2880301416178199e-06, 'epoch': 0.84}
 84%|████████▍ | 8748/10395 [24:59:30<3:40:28,  8.03s/it] 84%|████████▍ | 8749/10395 [24:59:38<3:41:07,  8.06s/it]                                                         {'loss': 0.7855, 'learning_rate': 1.2865009469080114e-06, 'epoch': 0.84}
 84%|████████▍ | 8749/10395 [24:59:38<3:41:07,  8.06s/it] 84%|████████▍ | 8750/10395 [24:59:47<3:48:15,  8.33s/it]                                                         {'loss': 0.9195, 'learning_rate': 1.2849725980860716e-06, 'epoch': 0.84}
 84%|████████▍ | 8750/10395 [24:59:47<3:48:15,  8.33s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 84%|████████▍ | 8751/10395 [25:01:29<16:40:12, 36.50s/it]                                                          {'loss': 0.9029, 'learning_rate': 1.2834450953003675e-06, 'epoch': 0.84}
 84%|████████▍ | 8751/10395 [25:01:29<16:40:12, 36.50s/it] 84%|████████▍ | 8752/10395 [25:01:37<12:43:18, 27.87s/it]                                                          {'loss': 0.8457, 'learning_rate': 1.2819184386991845e-06, 'epoch': 0.84}
 84%|████████▍ | 8752/10395 [25:01:37<12:43:18, 27.87s/it] 84%|████████▍ | 8753/10395 [25:01:45<9:54:29, 21.72s/it]                                                          {'loss': 0.9233, 'learning_rate': 1.2803926284307345e-06, 'epoch': 0.84}
 84%|████████▍ | 8753/10395 [25:01:45<9:54:29, 21.72s/it] 84%|████████▍ | 8754/10395 [25:01:52<7:56:46, 17.43s/it]                                                         {'loss': 0.8712, 'learning_rate': 1.2788676646431296e-06, 'epoch': 0.84}
 84%|████████▍ | 8754/10395 [25:01:52<7:56:46, 17.43s/it] 84%|████████▍ | 8755/10395 [25:02:01<6:46:07, 14.86s/it]                                                         {'loss': 0.8619, 'learning_rate': 1.2773435474844143e-06, 'epoch': 0.84}
 84%|████████▍ | 8755/10395 [25:02:01<6:46:07, 14.86s/it] 84%|████████▍ | 8756/10395 [25:02:09<5:50:47, 12.84s/it]                                                         {'loss': 0.9099, 'learning_rate': 1.2758202771025495e-06, 'epoch': 0.84}
 84%|████████▍ | 8756/10395 [25:02:09<5:50:47, 12.84s/it] 84%|████████▍ | 8757/10395 [25:02:18<5:16:06, 11.58s/it]                                                         {'loss': 0.798, 'learning_rate': 1.2742978536454065e-06, 'epoch': 0.84}
 84%|████████▍ | 8757/10395 [25:02:18<5:16:06, 11.58s/it] 84%|████████▍ | 8758/10395 [25:02:25<4:43:35, 10.39s/it]                                                         {'loss': 0.9114, 'learning_rate': 1.2727762772607832e-06, 'epoch': 0.84}
 84%|████████▍ | 8758/10395 [25:02:25<4:43:35, 10.39s/it] 84%|████████▍ | 8759/10395 [25:02:43<5:44:09, 12.62s/it]                                                         {'loss': 0.4101, 'learning_rate': 1.2712555480963861e-06, 'epoch': 0.84}
 84%|████████▍ | 8759/10395 [25:02:43<5:44:09, 12.62s/it] 84%|████████▍ | 8760/10395 [25:02:51<5:01:58, 11.08s/it]                                                         {'loss': 0.8751, 'learning_rate': 1.2697356662998495e-06, 'epoch': 0.84}
 84%|████████▍ | 8760/10395 [25:02:51<5:01:58, 11.08s/it] 84%|████████▍ | 8761/10395 [25:02:59<4:42:54, 10.39s/it]                                                         {'loss': 0.6799, 'learning_rate': 1.2682166320187183e-06, 'epoch': 0.84}
 84%|████████▍ | 8761/10395 [25:02:59<4:42:54, 10.39s/it] 84%|████████▍ | 8762/10395 [25:03:07<4:19:09,  9.52s/it]                                                         {'loss': 0.913, 'learning_rate': 1.266698445400454e-06, 'epoch': 0.84}
 84%|████████▍ | 8762/10395 [25:03:07<4:19:09,  9.52s/it] 84%|████████▍ | 8763/10395 [25:03:15<4:04:23,  8.99s/it]                                                         {'loss': 0.8646, 'learning_rate': 1.2651811065924414e-06, 'epoch': 0.84}
 84%|████████▍ | 8763/10395 [25:03:15<4:04:23,  8.99s/it] 84%|████████▍ | 8764/10395 [25:03:23<3:56:08,  8.69s/it]                                                         {'loss': 0.9079, 'learning_rate': 1.263664615741982e-06, 'epoch': 0.84}
 84%|████████▍ | 8764/10395 [25:03:23<3:56:08,  8.69s/it] 84%|████████▍ | 8765/10395 [25:03:40<5:05:11, 11.23s/it]                                                         {'loss': 0.3575, 'learning_rate': 1.262148972996291e-06, 'epoch': 0.84}
 84%|████████▍ | 8765/10395 [25:03:40<5:05:11, 11.23s/it] 84%|████████▍ | 8766/10395 [25:03:48<4:37:19, 10.21s/it]                                                         {'loss': 0.8833, 'learning_rate': 1.2606341785025067e-06, 'epoch': 0.84}
 84%|████████▍ | 8766/10395 [25:03:48<4:37:19, 10.21s/it] 84%|████████▍ | 8767/10395 [25:03:55<4:14:21,  9.37s/it]                                                         {'loss': 0.8688, 'learning_rate': 1.2591202324076779e-06, 'epoch': 0.84}
 84%|████████▍ | 8767/10395 [25:03:55<4:14:21,  9.37s/it] 84%|████████▍ | 8768/10395 [25:04:03<4:03:03,  8.96s/it]                                                         {'loss': 0.8495, 'learning_rate': 1.2576071348587803e-06, 'epoch': 0.84}
 84%|████████▍ | 8768/10395 [25:04:03<4:03:03,  8.96s/it] 84%|████████▍ | 8769/10395 [25:04:13<4:12:31,  9.32s/it]                                                         {'loss': 0.8164, 'learning_rate': 1.2560948860026989e-06, 'epoch': 0.84}
 84%|████████▍ | 8769/10395 [25:04:13<4:12:31,  9.32s/it] 84%|████████▍ | 8770/10395 [25:04:20<3:55:22,  8.69s/it]                                                         {'loss': 0.888, 'learning_rate': 1.2545834859862383e-06, 'epoch': 0.84}
 84%|████████▍ | 8770/10395 [25:04:20<3:55:22,  8.69s/it] 84%|████████▍ | 8771/10395 [25:04:27<3:39:26,  8.11s/it]                                                         {'loss': 0.898, 'learning_rate': 1.2530729349561244e-06, 'epoch': 0.84}
 84%|████████▍ | 8771/10395 [25:04:27<3:39:26,  8.11s/it] 84%|████████▍ | 8772/10395 [25:04:35<3:34:44,  7.94s/it]                                                         {'loss': 0.8402, 'learning_rate': 1.2515632330589987e-06, 'epoch': 0.84}
 84%|████████▍ | 8772/10395 [25:04:35<3:34:44,  7.94s/it] 84%|████████▍ | 8773/10395 [25:04:42<3:32:33,  7.86s/it]                                                         {'loss': 0.8519, 'learning_rate': 1.2500543804414179e-06, 'epoch': 0.84}
 84%|████████▍ | 8773/10395 [25:04:42<3:32:33,  7.86s/it] 84%|████████▍ | 8774/10395 [25:04:49<3:24:28,  7.57s/it]                                                         {'loss': 0.9022, 'learning_rate': 1.2485463772498607e-06, 'epoch': 0.84}
 84%|████████▍ | 8774/10395 [25:04:49<3:24:28,  7.57s/it] 84%|████████▍ | 8775/10395 [25:04:58<3:32:07,  7.86s/it]                                                         {'loss': 0.8938, 'learning_rate': 1.2470392236307193e-06, 'epoch': 0.84}
 84%|████████▍ | 8775/10395 [25:04:58<3:32:07,  7.86s/it] 84%|████████▍ | 8776/10395 [25:05:06<3:34:07,  7.94s/it]                                                         {'loss': 0.8127, 'learning_rate': 1.2455329197303023e-06, 'epoch': 0.84}
 84%|████████▍ | 8776/10395 [25:05:06<3:34:07,  7.94s/it] 84%|████████▍ | 8777/10395 [25:05:13<3:31:10,  7.83s/it]                                                         {'loss': 0.7768, 'learning_rate': 1.2440274656948436e-06, 'epoch': 0.84}
 84%|████████▍ | 8777/10395 [25:05:13<3:31:10,  7.83s/it] 84%|████████▍ | 8778/10395 [25:05:22<3:34:26,  7.96s/it]                                                         {'loss': 0.8084, 'learning_rate': 1.2425228616704854e-06, 'epoch': 0.84}
 84%|████████▍ | 8778/10395 [25:05:22<3:34:26,  7.96s/it] 84%|████████▍ | 8779/10395 [25:05:29<3:31:23,  7.85s/it]                                                         {'loss': 0.8384, 'learning_rate': 1.2410191078032918e-06, 'epoch': 0.84}
 84%|████████▍ | 8779/10395 [25:05:29<3:31:23,  7.85s/it] 84%|████████▍ | 8780/10395 [25:05:37<3:27:59,  7.73s/it]                                                         {'loss': 0.8899, 'learning_rate': 1.2395162042392483e-06, 'epoch': 0.84}
 84%|████████▍ | 8780/10395 [25:05:37<3:27:59,  7.73s/it] 84%|████████▍ | 8781/10395 [25:05:54<4:45:02, 10.60s/it]                                                         {'loss': 0.3854, 'learning_rate': 1.2380141511242483e-06, 'epoch': 0.84}
 84%|████████▍ | 8781/10395 [25:05:54<4:45:02, 10.60s/it] 84%|████████▍ | 8782/10395 [25:06:02<4:23:43,  9.81s/it]                                                         {'loss': 0.934, 'learning_rate': 1.2365129486041116e-06, 'epoch': 0.84}
 84%|████████▍ | 8782/10395 [25:06:02<4:23:43,  9.81s/it] 84%|████████▍ | 8783/10395 [25:06:21<5:35:11, 12.48s/it]                                                         {'loss': 0.3872, 'learning_rate': 1.2350125968245707e-06, 'epoch': 0.84}
 84%|████████▍ | 8783/10395 [25:06:21<5:35:11, 12.48s/it] 85%|████████▍ | 8784/10395 [25:06:30<5:08:17, 11.48s/it]                                                         {'loss': 0.8872, 'learning_rate': 1.2335130959312747e-06, 'epoch': 0.84}
 85%|████████▍ | 8784/10395 [25:06:30<5:08:17, 11.48s/it] 85%|████████▍ | 8785/10395 [25:06:38<4:38:00, 10.36s/it]                                                         {'loss': 0.8384, 'learning_rate': 1.2320144460697948e-06, 'epoch': 0.85}
 85%|████████▍ | 8785/10395 [25:06:38<4:38:00, 10.36s/it] 85%|████████▍ | 8786/10395 [25:06:46<4:22:12,  9.78s/it]                                                         {'loss': 0.8315, 'learning_rate': 1.2305166473856122e-06, 'epoch': 0.85}
 85%|████████▍ | 8786/10395 [25:06:46<4:22:12,  9.78s/it] 85%|████████▍ | 8787/10395 [25:06:54<4:05:26,  9.16s/it]                                                         {'loss': 0.8212, 'learning_rate': 1.2290197000241344e-06, 'epoch': 0.85}
 85%|████████▍ | 8787/10395 [25:06:54<4:05:26,  9.16s/it] 85%|████████▍ | 8788/10395 [25:07:01<3:53:22,  8.71s/it]                                                         {'loss': 0.8352, 'learning_rate': 1.2275236041306815e-06, 'epoch': 0.85}
 85%|████████▍ | 8788/10395 [25:07:01<3:53:22,  8.71s/it] 85%|████████▍ | 8789/10395 [25:07:09<3:47:33,  8.50s/it]                                                         {'loss': 0.8901, 'learning_rate': 1.2260283598504885e-06, 'epoch': 0.85}
 85%|████████▍ | 8789/10395 [25:07:09<3:47:33,  8.50s/it] 85%|████████▍ | 8790/10395 [25:07:18<3:51:19,  8.65s/it]                                                         {'loss': 0.8227, 'learning_rate': 1.2245339673287148e-06, 'epoch': 0.85}
 85%|████████▍ | 8790/10395 [25:07:18<3:51:19,  8.65s/it] 85%|████████▍ | 8791/10395 [25:07:35<4:59:10, 11.19s/it]                                                         {'loss': 0.3858, 'learning_rate': 1.2230404267104301e-06, 'epoch': 0.85}
 85%|████████▍ | 8791/10395 [25:07:35<4:59:10, 11.19s/it] 85%|████████▍ | 8792/10395 [25:07:43<4:30:39, 10.13s/it]                                                         {'loss': 0.8458, 'learning_rate': 1.2215477381406215e-06, 'epoch': 0.85}
 85%|████████▍ | 8792/10395 [25:07:43<4:30:39, 10.13s/it] 85%|████████▍ | 8793/10395 [25:07:50<4:06:51,  9.25s/it]                                                         {'loss': 0.8283, 'learning_rate': 1.2200559017642022e-06, 'epoch': 0.85}
 85%|████████▍ | 8793/10395 [25:07:50<4:06:51,  9.25s/it] 85%|████████▍ | 8794/10395 [25:07:58<3:55:43,  8.83s/it]                                                         {'loss': 0.9033, 'learning_rate': 1.2185649177259906e-06, 'epoch': 0.85}
 85%|████████▍ | 8794/10395 [25:07:58<3:55:43,  8.83s/it] 85%|████████▍ | 8795/10395 [25:08:15<4:56:13, 11.11s/it]                                                         {'loss': 0.356, 'learning_rate': 1.2170747861707298e-06, 'epoch': 0.85}
 85%|████████▍ | 8795/10395 [25:08:15<4:56:13, 11.11s/it] 85%|████████▍ | 8796/10395 [25:08:22<4:28:50, 10.09s/it]                                                         {'loss': 0.8711, 'learning_rate': 1.2155855072430833e-06, 'epoch': 0.85}
 85%|████████▍ | 8796/10395 [25:08:22<4:28:50, 10.09s/it] 85%|████████▍ | 8797/10395 [25:08:30<4:07:03,  9.28s/it]                                                         {'loss': 0.8487, 'learning_rate': 1.2140970810876218e-06, 'epoch': 0.85}
 85%|████████▍ | 8797/10395 [25:08:30<4:07:03,  9.28s/it] 85%|████████▍ | 8798/10395 [25:08:38<3:57:38,  8.93s/it]                                                         {'loss': 0.8231, 'learning_rate': 1.2126095078488398e-06, 'epoch': 0.85}
 85%|████████▍ | 8798/10395 [25:08:38<3:57:38,  8.93s/it] 85%|████████▍ | 8799/10395 [25:08:46<3:53:56,  8.79s/it]                                                         {'loss': 0.8339, 'learning_rate': 1.2111227876711484e-06, 'epoch': 0.85}
 85%|████████▍ | 8799/10395 [25:08:46<3:53:56,  8.79s/it] 85%|████████▍ | 8800/10395 [25:08:54<3:46:04,  8.50s/it]                                                         {'loss': 0.8465, 'learning_rate': 1.2096369206988735e-06, 'epoch': 0.85}
 85%|████████▍ | 8800/10395 [25:08:54<3:46:04,  8.50s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 85%|████████▍ | 8801/10395 [25:10:37<16:16:56, 36.77s/it]                                                          {'loss': 0.8829, 'learning_rate': 1.2081519070762637e-06, 'epoch': 0.85}
 85%|████████▍ | 8801/10395 [25:10:37<16:16:56, 36.77s/it] 85%|████████▍ | 8802/10395 [25:10:45<12:25:54, 28.09s/it]                                                          {'loss': 0.8829, 'learning_rate': 1.2066677469474764e-06, 'epoch': 0.85}
 85%|████████▍ | 8802/10395 [25:10:45<12:25:54, 28.09s/it] 85%|████████▍ | 8803/10395 [25:10:52<9:42:46, 21.96s/it]                                                          {'loss': 0.7876, 'learning_rate': 1.2051844404565927e-06, 'epoch': 0.85}
 85%|████████▍ | 8803/10395 [25:10:52<9:42:46, 21.96s/it] 85%|████████▍ | 8804/10395 [25:11:00<7:49:42, 17.71s/it]                                                         {'loss': 0.8705, 'learning_rate': 1.2037019877476109e-06, 'epoch': 0.85}
 85%|████████▍ | 8804/10395 [25:11:00<7:49:42, 17.71s/it] 85%|████████▍ | 8805/10395 [25:11:07<6:26:39, 14.59s/it]                                                         {'loss': 0.8023, 'learning_rate': 1.2022203889644425e-06, 'epoch': 0.85}
 85%|████████▍ | 8805/10395 [25:11:07<6:26:39, 14.59s/it] 85%|████████▍ | 8806/10395 [25:11:16<5:41:14, 12.88s/it]                                                         {'loss': 0.9154, 'learning_rate': 1.2007396442509155e-06, 'epoch': 0.85}
 85%|████████▍ | 8806/10395 [25:11:16<5:41:14, 12.88s/it] 85%|████████▍ | 8807/10395 [25:11:24<5:00:10, 11.34s/it]                                                         {'loss': 0.8263, 'learning_rate': 1.1992597537507822e-06, 'epoch': 0.85}
 85%|████████▍ | 8807/10395 [25:11:24<5:00:10, 11.34s/it] 85%|████████▍ | 8808/10395 [25:11:32<4:29:57, 10.21s/it]                                                         {'loss': 0.8913, 'learning_rate': 1.1977807176077028e-06, 'epoch': 0.85}
 85%|████████▍ | 8808/10395 [25:11:32<4:29:57, 10.21s/it] 85%|████████▍ | 8809/10395 [25:11:41<4:19:22,  9.81s/it]                                                         {'loss': 0.7869, 'learning_rate': 1.1963025359652602e-06, 'epoch': 0.85}
 85%|████████▍ | 8809/10395 [25:11:41<4:19:22,  9.81s/it] 85%|████████▍ | 8810/10395 [25:11:48<4:00:16,  9.10s/it]                                                         {'loss': 0.8804, 'learning_rate': 1.1948252089669564e-06, 'epoch': 0.85}
 85%|████████▍ | 8810/10395 [25:11:48<4:00:16,  9.10s/it] 85%|████████▍ | 8811/10395 [25:11:56<3:48:50,  8.67s/it]                                                         {'loss': 0.7464, 'learning_rate': 1.1933487367562025e-06, 'epoch': 0.85}
 85%|████████▍ | 8811/10395 [25:11:56<3:48:50,  8.67s/it] 85%|████████▍ | 8812/10395 [25:12:03<3:40:16,  8.35s/it]                                                         {'loss': 0.8186, 'learning_rate': 1.1918731194763355e-06, 'epoch': 0.85}
 85%|████████▍ | 8812/10395 [25:12:03<3:40:16,  8.35s/it] 85%|████████▍ | 8813/10395 [25:12:11<3:34:28,  8.13s/it]                                                         {'loss': 0.8602, 'learning_rate': 1.1903983572706024e-06, 'epoch': 0.85}
 85%|████████▍ | 8813/10395 [25:12:11<3:34:28,  8.13s/it] 85%|████████▍ | 8814/10395 [25:12:19<3:34:28,  8.14s/it]                                                         {'loss': 0.8578, 'learning_rate': 1.1889244502821695e-06, 'epoch': 0.85}
 85%|████████▍ | 8814/10395 [25:12:19<3:34:28,  8.14s/it] 85%|████████▍ | 8815/10395 [25:12:26<3:25:58,  7.82s/it]                                                         {'loss': 0.901, 'learning_rate': 1.1874513986541224e-06, 'epoch': 0.85}
 85%|████████▍ | 8815/10395 [25:12:26<3:25:58,  7.82s/it] 85%|████████▍ | 8816/10395 [25:12:34<3:22:24,  7.69s/it]                                                         {'loss': 0.8719, 'learning_rate': 1.1859792025294603e-06, 'epoch': 0.85}
 85%|████████▍ | 8816/10395 [25:12:34<3:22:24,  7.69s/it] 85%|████████▍ | 8817/10395 [25:12:41<3:23:54,  7.75s/it]                                                         {'loss': 0.7797, 'learning_rate': 1.1845078620511008e-06, 'epoch': 0.85}
 85%|████████▍ | 8817/10395 [25:12:41<3:23:54,  7.75s/it] 85%|████████▍ | 8818/10395 [25:12:49<3:20:51,  7.64s/it]                                                         {'loss': 0.8663, 'learning_rate': 1.183037377361882e-06, 'epoch': 0.85}
 85%|████████▍ | 8818/10395 [25:12:49<3:20:51,  7.64s/it] 85%|████████▍ | 8819/10395 [25:12:56<3:19:00,  7.58s/it]                                                         {'loss': 0.8041, 'learning_rate': 1.1815677486045517e-06, 'epoch': 0.85}
 85%|████████▍ | 8819/10395 [25:12:56<3:19:00,  7.58s/it] 85%|████████▍ | 8820/10395 [25:13:03<3:15:37,  7.45s/it]                                                         {'loss': 0.9212, 'learning_rate': 1.1800989759217784e-06, 'epoch': 0.85}
 85%|████████▍ | 8820/10395 [25:13:03<3:15:37,  7.45s/it] 85%|████████▍ | 8821/10395 [25:13:12<3:23:07,  7.74s/it]                                                         {'loss': 0.948, 'learning_rate': 1.17863105945615e-06, 'epoch': 0.85}
 85%|████████▍ | 8821/10395 [25:13:12<3:23:07,  7.74s/it] 85%|████████▍ | 8822/10395 [25:13:20<3:25:20,  7.83s/it]                                                         {'loss': 0.9122, 'learning_rate': 1.177163999350165e-06, 'epoch': 0.85}
 85%|████████▍ | 8822/10395 [25:13:20<3:25:20,  7.83s/it] 85%|████████▍ | 8823/10395 [25:13:28<3:24:28,  7.80s/it]                                                         {'loss': 0.8496, 'learning_rate': 1.1756977957462457e-06, 'epoch': 0.85}
 85%|████████▍ | 8823/10395 [25:13:28<3:24:28,  7.80s/it] 85%|████████▍ | 8824/10395 [25:13:35<3:23:27,  7.77s/it]                                                         {'loss': 0.8739, 'learning_rate': 1.1742324487867251e-06, 'epoch': 0.85}
 85%|████████▍ | 8824/10395 [25:13:35<3:23:27,  7.77s/it] 85%|████████▍ | 8825/10395 [25:13:43<3:25:45,  7.86s/it]                                                         {'loss': 0.8254, 'learning_rate': 1.1727679586138586e-06, 'epoch': 0.85}
 85%|████████▍ | 8825/10395 [25:13:43<3:25:45,  7.86s/it] 85%|████████▍ | 8826/10395 [25:13:52<3:27:54,  7.95s/it]                                                         {'loss': 0.9569, 'learning_rate': 1.1713043253698186e-06, 'epoch': 0.85}
 85%|████████▍ | 8826/10395 [25:13:52<3:27:54,  7.95s/it] 85%|████████▍ | 8827/10395 [25:13:59<3:26:56,  7.92s/it]                                                         {'loss': 0.8426, 'learning_rate': 1.169841549196683e-06, 'epoch': 0.85}
 85%|████████▍ | 8827/10395 [25:13:59<3:26:56,  7.92s/it] 85%|████████▍ | 8828/10395 [25:14:08<3:34:42,  8.22s/it]                                                         {'loss': 0.8257, 'learning_rate': 1.1683796302364604e-06, 'epoch': 0.85}
 85%|████████▍ | 8828/10395 [25:14:08<3:34:42,  8.22s/it] 85%|████████▍ | 8829/10395 [25:14:16<3:27:41,  7.96s/it]                                                         {'loss': 0.8536, 'learning_rate': 1.1669185686310713e-06, 'epoch': 0.85}
 85%|████████▍ | 8829/10395 [25:14:16<3:27:41,  7.96s/it] 85%|████████▍ | 8830/10395 [25:14:23<3:25:00,  7.86s/it]                                                         {'loss': 0.86, 'learning_rate': 1.1654583645223494e-06, 'epoch': 0.85}
 85%|████████▍ | 8830/10395 [25:14:23<3:25:00,  7.86s/it] 85%|████████▍ | 8831/10395 [25:14:39<4:23:21, 10.10s/it]                                                         {'loss': 0.3659, 'learning_rate': 1.1639990180520521e-06, 'epoch': 0.85}
 85%|████████▍ | 8831/10395 [25:14:39<4:23:21, 10.10s/it] 85%|████████▍ | 8832/10395 [25:14:47<4:07:45,  9.51s/it]                                                         {'loss': 0.8335, 'learning_rate': 1.1625405293618453e-06, 'epoch': 0.85}
 85%|████████▍ | 8832/10395 [25:14:47<4:07:45,  9.51s/it] 85%|████████▍ | 8833/10395 [25:14:54<3:51:54,  8.91s/it]                                                         {'loss': 0.7877, 'learning_rate': 1.1610828985933186e-06, 'epoch': 0.85}
 85%|████████▍ | 8833/10395 [25:14:54<3:51:54,  8.91s/it] 85%|████████▍ | 8834/10395 [25:15:02<3:46:04,  8.69s/it]                                                         {'loss': 0.8375, 'learning_rate': 1.1596261258879792e-06, 'epoch': 0.85}
 85%|████████▍ | 8834/10395 [25:15:02<3:46:04,  8.69s/it] 85%|████████▍ | 8835/10395 [25:15:10<3:38:23,  8.40s/it]                                                         {'loss': 0.8588, 'learning_rate': 1.1581702113872396e-06, 'epoch': 0.85}
 85%|████████▍ | 8835/10395 [25:15:10<3:38:23,  8.40s/it] 85%|████████▌ | 8836/10395 [25:15:18<3:34:51,  8.27s/it]                                                         {'loss': 0.8193, 'learning_rate': 1.1567151552324408e-06, 'epoch': 0.85}
 85%|████████▌ | 8836/10395 [25:15:18<3:34:51,  8.27s/it] 85%|████████▌ | 8837/10395 [25:15:26<3:30:18,  8.10s/it]                                                         {'loss': 0.8676, 'learning_rate': 1.1552609575648387e-06, 'epoch': 0.85}
 85%|████████▌ | 8837/10395 [25:15:26<3:30:18,  8.10s/it] 85%|████████▌ | 8838/10395 [25:15:35<3:35:52,  8.32s/it]                                                         {'loss': 0.8924, 'learning_rate': 1.1538076185255987e-06, 'epoch': 0.85}
 85%|████████▌ | 8838/10395 [25:15:35<3:35:52,  8.32s/it] 85%|████████▌ | 8839/10395 [25:15:43<3:35:19,  8.30s/it]                                                         {'loss': 0.8288, 'learning_rate': 1.152355138255814e-06, 'epoch': 0.85}
 85%|████████▌ | 8839/10395 [25:15:43<3:35:19,  8.30s/it] 85%|████████▌ | 8840/10395 [25:15:52<3:38:50,  8.44s/it]                                                         {'loss': 0.8656, 'learning_rate': 1.1509035168964822e-06, 'epoch': 0.85}
 85%|████████▌ | 8840/10395 [25:15:52<3:38:50,  8.44s/it] 85%|████████▌ | 8841/10395 [25:15:59<3:28:44,  8.06s/it]                                                         {'loss': 0.8999, 'learning_rate': 1.1494527545885281e-06, 'epoch': 0.85}
 85%|████████▌ | 8841/10395 [25:15:59<3:28:44,  8.06s/it] 85%|████████▌ | 8842/10395 [25:16:07<3:28:06,  8.04s/it]                                                         {'loss': 0.8845, 'learning_rate': 1.148002851472788e-06, 'epoch': 0.85}
 85%|████████▌ | 8842/10395 [25:16:07<3:28:06,  8.04s/it] 85%|████████▌ | 8843/10395 [25:16:17<3:43:06,  8.63s/it]                                                         {'loss': 0.787, 'learning_rate': 1.1465538076900119e-06, 'epoch': 0.85}
 85%|████████▌ | 8843/10395 [25:16:17<3:43:06,  8.63s/it] 85%|████████▌ | 8844/10395 [25:16:25<3:39:23,  8.49s/it]                                                         {'loss': 0.7798, 'learning_rate': 1.1451056233808711e-06, 'epoch': 0.85}
 85%|████████▌ | 8844/10395 [25:16:25<3:39:23,  8.49s/it] 85%|████████▌ | 8845/10395 [25:16:33<3:33:09,  8.25s/it]                                                         {'loss': 0.8674, 'learning_rate': 1.1436582986859568e-06, 'epoch': 0.85}
 85%|████████▌ | 8845/10395 [25:16:33<3:33:09,  8.25s/it] 85%|████████▌ | 8846/10395 [25:16:40<3:23:14,  7.87s/it]                                                         {'loss': 0.8594, 'learning_rate': 1.1422118337457667e-06, 'epoch': 0.85}
 85%|████████▌ | 8846/10395 [25:16:40<3:23:14,  7.87s/it] 85%|████████▌ | 8847/10395 [25:16:48<3:23:08,  7.87s/it]                                                         {'loss': 0.8395, 'learning_rate': 1.1407662287007237e-06, 'epoch': 0.85}
 85%|████████▌ | 8847/10395 [25:16:48<3:23:08,  7.87s/it] 85%|████████▌ | 8848/10395 [25:16:55<3:17:47,  7.67s/it]                                                         {'loss': 0.8704, 'learning_rate': 1.1393214836911615e-06, 'epoch': 0.85}
 85%|████████▌ | 8848/10395 [25:16:55<3:17:47,  7.67s/it] 85%|████████▌ | 8849/10395 [25:17:03<3:18:17,  7.70s/it]                                                         {'loss': 0.8371, 'learning_rate': 1.1378775988573365e-06, 'epoch': 0.85}
 85%|████████▌ | 8849/10395 [25:17:03<3:18:17,  7.70s/it] 85%|████████▌ | 8850/10395 [25:17:11<3:23:09,  7.89s/it]                                                         {'loss': 0.8307, 'learning_rate': 1.1364345743394157e-06, 'epoch': 0.85}
 85%|████████▌ | 8850/10395 [25:17:11<3:23:09,  7.89s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 85%|████████▌ | 8851/10395 [25:18:54<15:35:56, 36.37s/it]                                                          {'loss': 0.8938, 'learning_rate': 1.1349924102774822e-06, 'epoch': 0.85}
 85%|████████▌ | 8851/10395 [25:18:54<15:35:56, 36.37s/it] 85%|████████▌ | 8852/10395 [25:19:01<11:47:46, 27.52s/it]                                                          {'loss': 0.8744, 'learning_rate': 1.1335511068115424e-06, 'epoch': 0.85}
 85%|████████▌ | 8852/10395 [25:19:01<11:47:46, 27.52s/it] 85%|████████▌ | 8853/10395 [25:19:09<9:18:49, 21.74s/it]                                                          {'loss': 0.8567, 'learning_rate': 1.132110664081515e-06, 'epoch': 0.85}
 85%|████████▌ | 8853/10395 [25:19:09<9:18:49, 21.74s/it] 85%|████████▌ | 8854/10395 [25:19:17<7:31:55, 17.60s/it]                                                         {'loss': 0.8645, 'learning_rate': 1.1306710822272305e-06, 'epoch': 0.85}
 85%|████████▌ | 8854/10395 [25:19:17<7:31:55, 17.60s/it] 85%|████████▌ | 8855/10395 [25:19:26<6:25:31, 15.02s/it]                                                         {'loss': 0.8631, 'learning_rate': 1.129232361388446e-06, 'epoch': 0.85}
 85%|████████▌ | 8855/10395 [25:19:26<6:25:31, 15.02s/it] 85%|████████▌ | 8856/10395 [25:19:33<5:25:29, 12.69s/it]                                                         {'loss': 0.9096, 'learning_rate': 1.1277945017048274e-06, 'epoch': 0.85}
 85%|████████▌ | 8856/10395 [25:19:33<5:25:29, 12.69s/it] 85%|████████▌ | 8857/10395 [25:19:40<4:44:28, 11.10s/it]                                                         {'loss': 0.8629, 'learning_rate': 1.1263575033159569e-06, 'epoch': 0.85}
 85%|████████▌ | 8857/10395 [25:19:40<4:44:28, 11.10s/it] 85%|████████▌ | 8858/10395 [25:19:48<4:18:04, 10.07s/it]                                                         {'loss': 0.8388, 'learning_rate': 1.124921366361338e-06, 'epoch': 0.85}
 85%|████████▌ | 8858/10395 [25:19:48<4:18:04, 10.07s/it] 85%|████████▌ | 8859/10395 [25:19:56<4:05:08,  9.58s/it]                                                         {'loss': 0.858, 'learning_rate': 1.1234860909803856e-06, 'epoch': 0.85}
 85%|████████▌ | 8859/10395 [25:19:56<4:05:08,  9.58s/it] 85%|████████▌ | 8860/10395 [25:20:04<3:46:12,  8.84s/it]                                                         {'loss': 0.9378, 'learning_rate': 1.1220516773124336e-06, 'epoch': 0.85}
 85%|████████▌ | 8860/10395 [25:20:04<3:46:12,  8.84s/it] 85%|████████▌ | 8861/10395 [25:20:11<3:35:25,  8.43s/it]                                                         {'loss': 0.8364, 'learning_rate': 1.1206181254967352e-06, 'epoch': 0.85}
 85%|████████▌ | 8861/10395 [25:20:11<3:35:25,  8.43s/it] 85%|████████▌ | 8862/10395 [25:20:19<3:29:31,  8.20s/it]                                                         {'loss': 0.8826, 'learning_rate': 1.1191854356724518e-06, 'epoch': 0.85}
 85%|████████▌ | 8862/10395 [25:20:19<3:29:31,  8.20s/it] 85%|████████▌ | 8863/10395 [25:20:26<3:23:34,  7.97s/it]                                                         {'loss': 0.9401, 'learning_rate': 1.11775360797867e-06, 'epoch': 0.85}
 85%|████████▌ | 8863/10395 [25:20:26<3:23:34,  7.97s/it] 85%|████████▌ | 8864/10395 [25:20:34<3:24:05,  8.00s/it]                                                         {'loss': 0.8076, 'learning_rate': 1.116322642554386e-06, 'epoch': 0.85}
 85%|████████▌ | 8864/10395 [25:20:34<3:24:05,  8.00s/it] 85%|████████▌ | 8865/10395 [25:20:42<3:19:20,  7.82s/it]                                                         {'loss': 0.8089, 'learning_rate': 1.1148925395385135e-06, 'epoch': 0.85}
 85%|████████▌ | 8865/10395 [25:20:42<3:19:20,  7.82s/it] 85%|████████▌ | 8866/10395 [25:20:59<4:28:50, 10.55s/it]                                                         {'loss': 0.377, 'learning_rate': 1.113463299069888e-06, 'epoch': 0.85}
 85%|████████▌ | 8866/10395 [25:20:59<4:28:50, 10.55s/it] 85%|████████▌ | 8867/10395 [25:21:07<4:09:55,  9.81s/it]                                                         {'loss': 0.8773, 'learning_rate': 1.1120349212872516e-06, 'epoch': 0.85}
 85%|████████▌ | 8867/10395 [25:21:07<4:09:55,  9.81s/it] 85%|████████▌ | 8868/10395 [25:21:15<3:58:33,  9.37s/it]                                                         {'loss': 0.8123, 'learning_rate': 1.1106074063292726e-06, 'epoch': 0.85}
 85%|████████▌ | 8868/10395 [25:21:15<3:58:33,  9.37s/it] 85%|████████▌ | 8869/10395 [25:21:23<3:46:04,  8.89s/it]                                                         {'loss': 0.928, 'learning_rate': 1.1091807543345322e-06, 'epoch': 0.85}
 85%|████████▌ | 8869/10395 [25:21:23<3:46:04,  8.89s/it] 85%|████████▌ | 8870/10395 [25:21:30<3:36:16,  8.51s/it]                                                         {'loss': 0.9164, 'learning_rate': 1.107754965441522e-06, 'epoch': 0.85}
 85%|████████▌ | 8870/10395 [25:21:30<3:36:16,  8.51s/it] 85%|████████▌ | 8871/10395 [25:21:38<3:29:10,  8.23s/it]                                                         {'loss': 0.8115, 'learning_rate': 1.106330039788659e-06, 'epoch': 0.85}
 85%|████████▌ | 8871/10395 [25:21:38<3:29:10,  8.23s/it] 85%|████████▌ | 8872/10395 [25:21:46<3:30:33,  8.30s/it]                                                         {'loss': 0.8226, 'learning_rate': 1.10490597751427e-06, 'epoch': 0.85}
 85%|████████▌ | 8872/10395 [25:21:46<3:30:33,  8.30s/it] 85%|████████▌ | 8873/10395 [25:21:54<3:27:47,  8.19s/it]                                                         {'loss': 0.9023, 'learning_rate': 1.1034827787565972e-06, 'epoch': 0.85}
 85%|████████▌ | 8873/10395 [25:21:54<3:27:47,  8.19s/it] 85%|████████▌ | 8874/10395 [25:22:02<3:23:33,  8.03s/it]                                                         {'loss': 0.8855, 'learning_rate': 1.1020604436538052e-06, 'epoch': 0.85}
 85%|████████▌ | 8874/10395 [25:22:02<3:23:33,  8.03s/it] 85%|████████▌ | 8875/10395 [25:22:10<3:22:45,  8.00s/it]                                                         {'loss': 0.8051, 'learning_rate': 1.1006389723439714e-06, 'epoch': 0.85}
 85%|████████▌ | 8875/10395 [25:22:10<3:22:45,  8.00s/it] 85%|████████▌ | 8876/10395 [25:22:26<4:21:07, 10.31s/it]                                                         {'loss': 0.3224, 'learning_rate': 1.0992183649650868e-06, 'epoch': 0.85}
 85%|████████▌ | 8876/10395 [25:22:26<4:21:07, 10.31s/it] 85%|████████▌ | 8877/10395 [25:22:33<4:01:31,  9.55s/it]                                                         {'loss': 0.8002, 'learning_rate': 1.097798621655064e-06, 'epoch': 0.85}
 85%|████████▌ | 8877/10395 [25:22:33<4:01:31,  9.55s/it] 85%|████████▌ | 8878/10395 [25:22:41<3:45:53,  8.93s/it]                                                         {'loss': 0.8853, 'learning_rate': 1.0963797425517276e-06, 'epoch': 0.85}
 85%|████████▌ | 8878/10395 [25:22:41<3:45:53,  8.93s/it] 85%|████████▌ | 8879/10395 [25:22:49<3:36:37,  8.57s/it]                                                         {'loss': 0.7706, 'learning_rate': 1.094961727792816e-06, 'epoch': 0.85}
 85%|████████▌ | 8879/10395 [25:22:49<3:36:37,  8.57s/it] 85%|████████▌ | 8880/10395 [25:22:58<3:39:12,  8.68s/it]                                                         {'loss': 0.7917, 'learning_rate': 1.0935445775159926e-06, 'epoch': 0.85}
 85%|████████▌ | 8880/10395 [25:22:58<3:39:12,  8.68s/it] 85%|████████▌ | 8881/10395 [25:23:06<3:33:46,  8.47s/it]                                                         {'loss': 0.8935, 'learning_rate': 1.092128291858825e-06, 'epoch': 0.85}
 85%|████████▌ | 8881/10395 [25:23:06<3:33:46,  8.47s/it] 85%|████████▌ | 8882/10395 [25:23:14<3:30:26,  8.35s/it]                                                         {'loss': 0.836, 'learning_rate': 1.0907128709588077e-06, 'epoch': 0.85}
 85%|████████▌ | 8882/10395 [25:23:14<3:30:26,  8.35s/it] 85%|████████▌ | 8883/10395 [25:23:21<3:24:39,  8.12s/it]                                                         {'loss': 0.7855, 'learning_rate': 1.0892983149533476e-06, 'epoch': 0.85}
 85%|████████▌ | 8883/10395 [25:23:21<3:24:39,  8.12s/it] 85%|████████▌ | 8884/10395 [25:23:30<3:25:54,  8.18s/it]                                                         {'loss': 0.8144, 'learning_rate': 1.0878846239797624e-06, 'epoch': 0.85}
 85%|████████▌ | 8884/10395 [25:23:30<3:25:54,  8.18s/it] 85%|████████▌ | 8885/10395 [25:23:38<3:30:12,  8.35s/it]                                                         {'loss': 0.8603, 'learning_rate': 1.0864717981752948e-06, 'epoch': 0.85}
 85%|████████▌ | 8885/10395 [25:23:38<3:30:12,  8.35s/it] 85%|████████▌ | 8886/10395 [25:23:46<3:24:03,  8.11s/it]                                                         {'loss': 0.864, 'learning_rate': 1.085059837677097e-06, 'epoch': 0.85}
 85%|████████▌ | 8886/10395 [25:23:46<3:24:03,  8.11s/it] 85%|████████▌ | 8887/10395 [25:23:54<3:25:23,  8.17s/it]                                                         {'loss': 0.8574, 'learning_rate': 1.0836487426222364e-06, 'epoch': 0.85}
 85%|████████▌ | 8887/10395 [25:23:54<3:25:23,  8.17s/it] 86%|████████▌ | 8888/10395 [25:24:02<3:20:15,  7.97s/it]                                                         {'loss': 0.9199, 'learning_rate': 1.0822385131477042e-06, 'epoch': 0.85}
 86%|████████▌ | 8888/10395 [25:24:02<3:20:15,  7.97s/it] 86%|████████▌ | 8889/10395 [25:24:10<3:20:36,  7.99s/it]                                                         {'loss': 0.8137, 'learning_rate': 1.0808291493903978e-06, 'epoch': 0.86}
 86%|████████▌ | 8889/10395 [25:24:10<3:20:36,  7.99s/it] 86%|████████▌ | 8890/10395 [25:24:17<3:18:07,  7.90s/it]                                                         {'loss': 0.8332, 'learning_rate': 1.0794206514871363e-06, 'epoch': 0.86}
 86%|████████▌ | 8890/10395 [25:24:17<3:18:07,  7.90s/it] 86%|████████▌ | 8891/10395 [25:24:25<3:18:18,  7.91s/it]                                                         {'loss': 0.8912, 'learning_rate': 1.0780130195746574e-06, 'epoch': 0.86}
 86%|████████▌ | 8891/10395 [25:24:25<3:18:18,  7.91s/it] 86%|████████▌ | 8892/10395 [25:24:34<3:20:16,  7.99s/it]                                                         {'loss': 0.8871, 'learning_rate': 1.0766062537896072e-06, 'epoch': 0.86}
 86%|████████▌ | 8892/10395 [25:24:34<3:20:16,  7.99s/it] 86%|████████▌ | 8893/10395 [25:24:41<3:17:29,  7.89s/it]                                                         {'loss': 0.8769, 'learning_rate': 1.075200354268553e-06, 'epoch': 0.86}
 86%|████████▌ | 8893/10395 [25:24:41<3:17:29,  7.89s/it] 86%|████████▌ | 8894/10395 [25:24:49<3:14:20,  7.77s/it]                                                         {'loss': 0.8327, 'learning_rate': 1.0737953211479767e-06, 'epoch': 0.86}
 86%|████████▌ | 8894/10395 [25:24:49<3:14:20,  7.77s/it] 86%|████████▌ | 8895/10395 [25:24:56<3:11:17,  7.65s/it]                                                         {'loss': 0.8437, 'learning_rate': 1.0723911545642728e-06, 'epoch': 0.86}
 86%|████████▌ | 8895/10395 [25:24:56<3:11:17,  7.65s/it] 86%|████████▌ | 8896/10395 [25:25:03<3:09:15,  7.58s/it]                                                         {'loss': 0.8276, 'learning_rate': 1.0709878546537589e-06, 'epoch': 0.86}
 86%|████████▌ | 8896/10395 [25:25:03<3:09:15,  7.58s/it] 86%|████████▌ | 8897/10395 [25:25:11<3:06:56,  7.49s/it]                                                         {'loss': 0.8234, 'learning_rate': 1.0695854215526613e-06, 'epoch': 0.86}
 86%|████████▌ | 8897/10395 [25:25:11<3:06:56,  7.49s/it] 86%|████████▌ | 8898/10395 [25:25:18<3:07:17,  7.51s/it]                                                         {'loss': 0.8449, 'learning_rate': 1.068183855397127e-06, 'epoch': 0.86}
 86%|████████▌ | 8898/10395 [25:25:18<3:07:17,  7.51s/it] 86%|████████▌ | 8899/10395 [25:25:26<3:07:11,  7.51s/it]                                                         {'loss': 0.8885, 'learning_rate': 1.0667831563232178e-06, 'epoch': 0.86}
 86%|████████▌ | 8899/10395 [25:25:26<3:07:11,  7.51s/it] 86%|████████▌ | 8900/10395 [25:25:34<3:15:31,  7.85s/it]                                                         {'loss': 0.8236, 'learning_rate': 1.0653833244669109e-06, 'epoch': 0.86}
 86%|████████▌ | 8900/10395 [25:25:34<3:15:31,  7.85s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 86%|████████▌ | 8901/10395 [25:27:15<14:47:46, 35.65s/it]                                                          {'loss': 0.8572, 'learning_rate': 1.0639843599640942e-06, 'epoch': 0.86}
 86%|████████▌ | 8901/10395 [25:27:15<14:47:46, 35.65s/it] 86%|████████▌ | 8902/10395 [25:27:24<11:28:28, 27.67s/it]                                                          {'loss': 0.8255, 'learning_rate': 1.0625862629505812e-06, 'epoch': 0.86}
 86%|████████▌ | 8902/10395 [25:27:24<11:28:28, 27.67s/it] 86%|████████▌ | 8903/10395 [25:27:32<9:01:34, 21.78s/it]                                                          {'loss': 0.8152, 'learning_rate': 1.0611890335620934e-06, 'epoch': 0.86}
 86%|████████▌ | 8903/10395 [25:27:32<9:01:34, 21.78s/it] 86%|████████▌ | 8904/10395 [25:27:40<7:17:51, 17.62s/it]                                                         {'loss': 0.8739, 'learning_rate': 1.0597926719342744e-06, 'epoch': 0.86}
 86%|████████▌ | 8904/10395 [25:27:40<7:17:51, 17.62s/it] 86%|████████▌ | 8905/10395 [25:27:48<6:06:22, 14.75s/it]                                                         {'loss': 0.8067, 'learning_rate': 1.0583971782026747e-06, 'epoch': 0.86}
 86%|████████▌ | 8905/10395 [25:27:48<6:06:22, 14.75s/it] 86%|████████▌ | 8906/10395 [25:28:06<6:26:57, 15.59s/it]                                                         {'loss': 0.3404, 'learning_rate': 1.0570025525027682e-06, 'epoch': 0.86}
 86%|████████▌ | 8906/10395 [25:28:06<6:26:57, 15.59s/it] 86%|████████▌ | 8907/10395 [25:28:13<5:27:35, 13.21s/it]                                                         {'loss': 0.801, 'learning_rate': 1.0556087949699468e-06, 'epoch': 0.86}
 86%|████████▌ | 8907/10395 [25:28:13<5:27:35, 13.21s/it] 86%|████████▌ | 8908/10395 [25:28:21<4:48:15, 11.63s/it]                                                         {'loss': 0.8763, 'learning_rate': 1.0542159057395063e-06, 'epoch': 0.86}
 86%|████████▌ | 8908/10395 [25:28:21<4:48:15, 11.63s/it] 86%|████████▌ | 8909/10395 [25:28:30<4:25:20, 10.71s/it]                                                         {'loss': 0.8553, 'learning_rate': 1.0528238849466677e-06, 'epoch': 0.86}
 86%|████████▌ | 8909/10395 [25:28:30<4:25:20, 10.71s/it] 86%|████████▌ | 8910/10395 [25:28:37<4:01:29,  9.76s/it]                                                         {'loss': 0.9316, 'learning_rate': 1.0514327327265683e-06, 'epoch': 0.86}
 86%|████████▌ | 8910/10395 [25:28:37<4:01:29,  9.76s/it] 86%|████████▌ | 8911/10395 [25:28:46<3:54:22,  9.48s/it]                                                         {'loss': 0.8586, 'learning_rate': 1.0500424492142547e-06, 'epoch': 0.86}
 86%|████████▌ | 8911/10395 [25:28:46<3:54:22,  9.48s/it] 86%|████████▌ | 8912/10395 [25:28:54<3:43:37,  9.05s/it]                                                         {'loss': 0.8081, 'learning_rate': 1.0486530345446954e-06, 'epoch': 0.86}
 86%|████████▌ | 8912/10395 [25:28:54<3:43:37,  9.05s/it] 86%|████████▌ | 8913/10395 [25:29:02<3:32:21,  8.60s/it]                                                         {'loss': 0.8124, 'learning_rate': 1.0472644888527683e-06, 'epoch': 0.86}
 86%|████████▌ | 8913/10395 [25:29:02<3:32:21,  8.60s/it] 86%|████████▌ | 8914/10395 [25:29:09<3:23:52,  8.26s/it]                                                         {'loss': 0.827, 'learning_rate': 1.045876812273272e-06, 'epoch': 0.86}
 86%|████████▌ | 8914/10395 [25:29:09<3:23:52,  8.26s/it] 86%|████████▌ | 8915/10395 [25:29:17<3:21:47,  8.18s/it]                                                         {'loss': 0.9069, 'learning_rate': 1.0444900049409245e-06, 'epoch': 0.86}
 86%|████████▌ | 8915/10395 [25:29:17<3:21:47,  8.18s/it] 86%|████████▌ | 8916/10395 [25:29:26<3:25:53,  8.35s/it]                                                         {'loss': 0.7494, 'learning_rate': 1.0431040669903458e-06, 'epoch': 0.86}
 86%|████████▌ | 8916/10395 [25:29:26<3:25:53,  8.35s/it] 86%|████████▌ | 8917/10395 [25:29:34<3:20:40,  8.15s/it]                                                         {'loss': 0.8595, 'learning_rate': 1.0417189985560826e-06, 'epoch': 0.86}
 86%|████████▌ | 8917/10395 [25:29:34<3:20:40,  8.15s/it] 86%|████████▌ | 8918/10395 [25:29:41<3:18:38,  8.07s/it]                                                         {'loss': 0.8716, 'learning_rate': 1.0403347997725977e-06, 'epoch': 0.86}
 86%|████████▌ | 8918/10395 [25:29:41<3:18:38,  8.07s/it] 86%|████████▌ | 8919/10395 [25:29:50<3:18:39,  8.08s/it]                                                         {'loss': 0.8626, 'learning_rate': 1.038951470774261e-06, 'epoch': 0.86}
 86%|████████▌ | 8919/10395 [25:29:50<3:18:39,  8.08s/it] 86%|████████▌ | 8920/10395 [25:29:57<3:15:11,  7.94s/it]                                                         {'loss': 0.9616, 'learning_rate': 1.0375690116953674e-06, 'epoch': 0.86}
 86%|████████▌ | 8920/10395 [25:29:57<3:15:11,  7.94s/it] 86%|████████▌ | 8921/10395 [25:30:05<3:11:48,  7.81s/it]                                                         {'loss': 0.8494, 'learning_rate': 1.0361874226701196e-06, 'epoch': 0.86}
 86%|████████▌ | 8921/10395 [25:30:05<3:11:48,  7.81s/it] 86%|████████▌ | 8922/10395 [25:30:21<4:14:35, 10.37s/it]                                                         {'loss': 0.3828, 'learning_rate': 1.0348067038326436e-06, 'epoch': 0.86}
 86%|████████▌ | 8922/10395 [25:30:21<4:14:35, 10.37s/it] 86%|████████▌ | 8923/10395 [25:30:28<3:53:21,  9.51s/it]                                                         {'loss': 0.8354, 'learning_rate': 1.0334268553169735e-06, 'epoch': 0.86}
 86%|████████▌ | 8923/10395 [25:30:28<3:53:21,  9.51s/it] 86%|████████▌ | 8924/10395 [25:30:36<3:39:15,  8.94s/it]                                                         {'loss': 0.8647, 'learning_rate': 1.032047877257062e-06, 'epoch': 0.86}
 86%|████████▌ | 8924/10395 [25:30:36<3:39:15,  8.94s/it] 86%|████████▌ | 8925/10395 [25:30:43<3:26:28,  8.43s/it]                                                         {'loss': 0.9223, 'learning_rate': 1.0306697697867761e-06, 'epoch': 0.86}
 86%|████████▌ | 8925/10395 [25:30:43<3:26:28,  8.43s/it] 86%|████████▌ | 8926/10395 [25:30:51<3:18:49,  8.12s/it]                                                         {'loss': 0.8757, 'learning_rate': 1.0292925330399052e-06, 'epoch': 0.86}
 86%|████████▌ | 8926/10395 [25:30:51<3:18:49,  8.12s/it] 86%|████████▌ | 8927/10395 [25:30:59<3:17:49,  8.09s/it]                                                         {'loss': 0.8588, 'learning_rate': 1.0279161671501415e-06, 'epoch': 0.86}
 86%|████████▌ | 8927/10395 [25:30:59<3:17:49,  8.09s/it] 86%|████████▌ | 8928/10395 [25:31:07<3:15:23,  7.99s/it]                                                         {'loss': 0.8857, 'learning_rate': 1.026540672251105e-06, 'epoch': 0.86}
 86%|████████▌ | 8928/10395 [25:31:07<3:15:23,  7.99s/it] 86%|████████▌ | 8929/10395 [25:31:16<3:24:20,  8.36s/it]                                                         {'loss': 0.8057, 'learning_rate': 1.0251660484763237e-06, 'epoch': 0.86}
 86%|████████▌ | 8929/10395 [25:31:16<3:24:20,  8.36s/it] 86%|████████▌ | 8930/10395 [25:31:23<3:18:41,  8.14s/it]                                                         {'loss': 0.8492, 'learning_rate': 1.0237922959592417e-06, 'epoch': 0.86}
 86%|████████▌ | 8930/10395 [25:31:23<3:18:41,  8.14s/it] 86%|████████▌ | 8931/10395 [25:31:31<3:15:39,  8.02s/it]                                                         {'loss': 0.8947, 'learning_rate': 1.0224194148332224e-06, 'epoch': 0.86}
 86%|████████▌ | 8931/10395 [25:31:31<3:15:39,  8.02s/it] 86%|████████▌ | 8932/10395 [25:31:39<3:12:01,  7.88s/it]                                                         {'loss': 0.903, 'learning_rate': 1.02104740523154e-06, 'epoch': 0.86}
 86%|████████▌ | 8932/10395 [25:31:39<3:12:01,  7.88s/it] 86%|████████▌ | 8933/10395 [25:31:47<3:17:45,  8.12s/it]                                                         {'loss': 0.8094, 'learning_rate': 1.0196762672873872e-06, 'epoch': 0.86}
 86%|████████▌ | 8933/10395 [25:31:47<3:17:45,  8.12s/it] 86%|████████▌ | 8934/10395 [25:31:55<3:13:33,  7.95s/it]                                                         {'loss': 0.8058, 'learning_rate': 1.018306001133873e-06, 'epoch': 0.86}
 86%|████████▌ | 8934/10395 [25:31:55<3:13:33,  7.95s/it] 86%|████████▌ | 8935/10395 [25:32:03<3:12:08,  7.90s/it]                                                         {'loss': 0.8307, 'learning_rate': 1.0169366069040164e-06, 'epoch': 0.86}
 86%|████████▌ | 8935/10395 [25:32:03<3:12:08,  7.90s/it] 86%|████████▌ | 8936/10395 [25:32:10<3:10:08,  7.82s/it]                                                         {'loss': 0.8812, 'learning_rate': 1.0155680847307602e-06, 'epoch': 0.86}
 86%|████████▌ | 8936/10395 [25:32:10<3:10:08,  7.82s/it] 86%|████████▌ | 8937/10395 [25:32:18<3:11:32,  7.88s/it]                                                         {'loss': 0.9066, 'learning_rate': 1.0142004347469535e-06, 'epoch': 0.86}
 86%|████████▌ | 8937/10395 [25:32:18<3:11:32,  7.88s/it] 86%|████████▌ | 8938/10395 [25:32:26<3:12:21,  7.92s/it]                                                         {'loss': 0.8291, 'learning_rate': 1.0128336570853636e-06, 'epoch': 0.86}
 86%|████████▌ | 8938/10395 [25:32:26<3:12:21,  7.92s/it] 86%|████████▌ | 8939/10395 [25:32:43<4:17:57, 10.63s/it]                                                         {'loss': 0.3648, 'learning_rate': 1.0114677518786798e-06, 'epoch': 0.86}
 86%|████████▌ | 8939/10395 [25:32:43<4:17:57, 10.63s/it] 86%|████████▌ | 8940/10395 [25:33:00<4:59:17, 12.34s/it]                                                         {'loss': 0.3317, 'learning_rate': 1.0101027192594948e-06, 'epoch': 0.86}
 86%|████████▌ | 8940/10395 [25:33:00<4:59:17, 12.34s/it] 86%|████████▌ | 8941/10395 [25:33:07<4:25:17, 10.95s/it]                                                         {'loss': 0.8687, 'learning_rate': 1.0087385593603272e-06, 'epoch': 0.86}
 86%|████████▌ | 8941/10395 [25:33:07<4:25:17, 10.95s/it] 86%|████████▌ | 8942/10395 [25:33:16<4:07:37, 10.23s/it]                                                         {'loss': 0.8425, 'learning_rate': 1.0073752723136076e-06, 'epoch': 0.86}
 86%|████████▌ | 8942/10395 [25:33:16<4:07:37, 10.23s/it] 86%|████████▌ | 8943/10395 [25:33:25<4:00:50,  9.95s/it]                                                         {'loss': 0.8401, 'learning_rate': 1.006012858251677e-06, 'epoch': 0.86}
 86%|████████▌ | 8943/10395 [25:33:25<4:00:50,  9.95s/it] 86%|████████▌ | 8944/10395 [25:33:33<3:45:18,  9.32s/it]                                                         {'loss': 0.771, 'learning_rate': 1.0046513173068006e-06, 'epoch': 0.86}
 86%|████████▌ | 8944/10395 [25:33:33<3:45:18,  9.32s/it] 86%|████████▌ | 8945/10395 [25:33:50<4:40:51, 11.62s/it]                                                         {'loss': 0.3155, 'learning_rate': 1.0032906496111504e-06, 'epoch': 0.86}
 86%|████████▌ | 8945/10395 [25:33:50<4:40:51, 11.62s/it] 86%|████████▌ | 8946/10395 [25:34:06<5:14:58, 13.04s/it]                                                         {'loss': 0.3505, 'learning_rate': 1.0019308552968165e-06, 'epoch': 0.86}
 86%|████████▌ | 8946/10395 [25:34:06<5:14:58, 13.04s/it] 86%|████████▌ | 8947/10395 [25:34:14<4:33:05, 11.32s/it]                                                         {'loss': 0.8432, 'learning_rate': 1.0005719344958053e-06, 'epoch': 0.86}
 86%|████████▌ | 8947/10395 [25:34:14<4:33:05, 11.32s/it] 86%|████████▌ | 8948/10395 [25:34:21<4:07:50, 10.28s/it]                                                         {'loss': 0.8444, 'learning_rate': 9.992138873400414e-07, 'epoch': 0.86}
 86%|████████▌ | 8948/10395 [25:34:21<4:07:50, 10.28s/it] 86%|████████▌ | 8949/10395 [25:34:29<3:46:12,  9.39s/it]                                                         {'loss': 0.8309, 'learning_rate': 9.97856713961357e-07, 'epoch': 0.86}
 86%|████████▌ | 8949/10395 [25:34:29<3:46:12,  9.39s/it] 86%|████████▌ | 8950/10395 [25:34:36<3:32:57,  8.84s/it]                                                         {'loss': 0.9505, 'learning_rate': 9.965004144915069e-07, 'epoch': 0.86}
 86%|████████▌ | 8950/10395 [25:34:36<3:32:57,  8.84s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 86%|████████▌ | 8951/10395 [25:36:15<14:24:24, 35.92s/it]                                                          {'loss': 0.814, 'learning_rate': 9.951449890621555e-07, 'epoch': 0.86}
 86%|████████▌ | 8951/10395 [25:36:15<14:24:24, 35.92s/it] 86%|████████▌ | 8952/10395 [25:36:23<10:58:24, 27.38s/it]                                                          {'loss': 0.8666, 'learning_rate': 9.937904378048846e-07, 'epoch': 0.86}
 86%|████████▌ | 8952/10395 [25:36:23<10:58:24, 27.38s/it] 86%|████████▌ | 8953/10395 [25:36:31<8:35:22, 21.44s/it]                                                          {'loss': 0.7872, 'learning_rate': 9.92436760851192e-07, 'epoch': 0.86}
 86%|████████▌ | 8953/10395 [25:36:31<8:35:22, 21.44s/it] 86%|████████▌ | 8954/10395 [25:36:48<8:04:57, 20.19s/it]                                                         {'loss': 0.3541, 'learning_rate': 9.910839583324883e-07, 'epoch': 0.86}
 86%|████████▌ | 8954/10395 [25:36:48<8:04:57, 20.19s/it] 86%|████████▌ | 8955/10395 [25:36:55<6:32:57, 16.37s/it]                                                         {'loss': 0.8848, 'learning_rate': 9.897320303801018e-07, 'epoch': 0.86}
 86%|████████▌ | 8955/10395 [25:36:55<6:32:57, 16.37s/it] 86%|████████▌ | 8956/10395 [25:37:03<5:28:37, 13.70s/it]                                                         {'loss': 0.8177, 'learning_rate': 9.883809771252762e-07, 'epoch': 0.86}
 86%|████████▌ | 8956/10395 [25:37:03<5:28:37, 13.70s/it] 86%|████████▌ | 8957/10395 [25:37:10<4:42:42, 11.80s/it]                                                         {'loss': 0.8681, 'learning_rate': 9.870307986991657e-07, 'epoch': 0.86}
 86%|████████▌ | 8957/10395 [25:37:10<4:42:42, 11.80s/it] 86%|████████▌ | 8958/10395 [25:37:18<4:14:12, 10.61s/it]                                                         {'loss': 0.7594, 'learning_rate': 9.856814952328464e-07, 'epoch': 0.86}
 86%|████████▌ | 8958/10395 [25:37:18<4:14:12, 10.61s/it] 86%|████████▌ | 8959/10395 [25:37:26<3:56:12,  9.87s/it]                                                         {'loss': 0.8816, 'learning_rate': 9.843330668573048e-07, 'epoch': 0.86}
 86%|████████▌ | 8959/10395 [25:37:26<3:56:12,  9.87s/it] 86%|████████▌ | 8960/10395 [25:37:34<3:44:23,  9.38s/it]                                                         {'loss': 0.9034, 'learning_rate': 9.829855137034395e-07, 'epoch': 0.86}
 86%|████████▌ | 8960/10395 [25:37:34<3:44:23,  9.38s/it] 86%|████████▌ | 8961/10395 [25:37:42<3:29:29,  8.77s/it]                                                         {'loss': 0.8991, 'learning_rate': 9.816388359020734e-07, 'epoch': 0.86}
 86%|████████▌ | 8961/10395 [25:37:42<3:29:29,  8.77s/it] 86%|████████▌ | 8962/10395 [25:37:49<3:18:01,  8.29s/it]                                                         {'loss': 0.8449, 'learning_rate': 9.802930335839346e-07, 'epoch': 0.86}
 86%|████████▌ | 8962/10395 [25:37:49<3:18:01,  8.29s/it] 86%|████████▌ | 8963/10395 [25:37:56<3:10:20,  7.98s/it]                                                         {'loss': 0.8491, 'learning_rate': 9.789481068796737e-07, 'epoch': 0.86}
 86%|████████▌ | 8963/10395 [25:37:56<3:10:20,  7.98s/it] 86%|████████▌ | 8964/10395 [25:38:04<3:06:30,  7.82s/it]                                                         {'loss': 0.8823, 'learning_rate': 9.77604055919854e-07, 'epoch': 0.86}
 86%|████████▌ | 8964/10395 [25:38:04<3:06:30,  7.82s/it] 86%|████████▌ | 8965/10395 [25:38:12<3:07:50,  7.88s/it]                                                         {'loss': 0.9109, 'learning_rate': 9.762608808349494e-07, 'epoch': 0.86}
 86%|████████▌ | 8965/10395 [25:38:12<3:07:50,  7.88s/it] 86%|████████▋ | 8966/10395 [25:38:19<3:06:56,  7.85s/it]                                                         {'loss': 0.8621, 'learning_rate': 9.749185817553564e-07, 'epoch': 0.86}
 86%|████████▋ | 8966/10395 [25:38:19<3:06:56,  7.85s/it] 86%|████████▋ | 8967/10395 [25:38:27<3:02:34,  7.67s/it]                                                         {'loss': 0.85, 'learning_rate': 9.735771588113818e-07, 'epoch': 0.86}
 86%|████████▋ | 8967/10395 [25:38:27<3:02:34,  7.67s/it] 86%|████████▋ | 8968/10395 [25:38:36<3:14:12,  8.17s/it]                                                         {'loss': 0.809, 'learning_rate': 9.722366121332449e-07, 'epoch': 0.86}
 86%|████████▋ | 8968/10395 [25:38:36<3:14:12,  8.17s/it] 86%|████████▋ | 8969/10395 [25:38:44<3:14:00,  8.16s/it]                                                         {'loss': 0.8886, 'learning_rate': 9.708969418510861e-07, 'epoch': 0.86}
 86%|████████▋ | 8969/10395 [25:38:44<3:14:00,  8.16s/it] 86%|████████▋ | 8970/10395 [25:38:52<3:13:29,  8.15s/it]                                                         {'loss': 0.8378, 'learning_rate': 9.695581480949566e-07, 'epoch': 0.86}
 86%|████████▋ | 8970/10395 [25:38:52<3:13:29,  8.15s/it] 86%|████████▋ | 8971/10395 [25:39:00<3:07:45,  7.91s/it]                                                         {'loss': 0.8999, 'learning_rate': 9.68220230994823e-07, 'epoch': 0.86}
 86%|████████▋ | 8971/10395 [25:39:00<3:07:45,  7.91s/it] 86%|████████▋ | 8972/10395 [25:39:07<3:05:11,  7.81s/it]                                                         {'loss': 0.8593, 'learning_rate': 9.668831906805709e-07, 'epoch': 0.86}
 86%|████████▋ | 8972/10395 [25:39:07<3:05:11,  7.81s/it] 86%|████████▋ | 8973/10395 [25:39:15<3:07:28,  7.91s/it]                                                         {'loss': 0.811, 'learning_rate': 9.655470272819946e-07, 'epoch': 0.86}
 86%|████████▋ | 8973/10395 [25:39:15<3:07:28,  7.91s/it] 86%|████████▋ | 8974/10395 [25:39:23<3:05:21,  7.83s/it]                                                         {'loss': 0.8449, 'learning_rate': 9.642117409288032e-07, 'epoch': 0.86}
 86%|████████▋ | 8974/10395 [25:39:23<3:05:21,  7.83s/it] 86%|████████▋ | 8975/10395 [25:39:41<4:20:48, 11.02s/it]                                                         {'loss': 0.3487, 'learning_rate': 9.628773317506302e-07, 'epoch': 0.86}
 86%|████████▋ | 8975/10395 [25:39:41<4:20:48, 11.02s/it] 86%|████████▋ | 8976/10395 [25:39:49<3:53:58,  9.89s/it]                                                         {'loss': 0.8971, 'learning_rate': 9.615437998770105e-07, 'epoch': 0.86}
 86%|████████▋ | 8976/10395 [25:39:49<3:53:58,  9.89s/it] 86%|████████▋ | 8977/10395 [25:39:56<3:39:38,  9.29s/it]                                                         {'loss': 0.8975, 'learning_rate': 9.602111454374053e-07, 'epoch': 0.86}
 86%|████████▋ | 8977/10395 [25:39:56<3:39:38,  9.29s/it] 86%|████████▋ | 8978/10395 [25:40:04<3:26:50,  8.76s/it]                                                         {'loss': 0.8509, 'learning_rate': 9.58879368561182e-07, 'epoch': 0.86}
 86%|████████▋ | 8978/10395 [25:40:04<3:26:50,  8.76s/it] 86%|████████▋ | 8979/10395 [25:40:12<3:20:01,  8.48s/it]                                                         {'loss': 0.8453, 'learning_rate': 9.575484693776294e-07, 'epoch': 0.86}
 86%|████████▋ | 8979/10395 [25:40:12<3:20:01,  8.48s/it] 86%|████████▋ | 8980/10395 [25:40:20<3:17:24,  8.37s/it]                                                         {'loss': 0.8371, 'learning_rate': 9.562184480159486e-07, 'epoch': 0.86}
 86%|████████▋ | 8980/10395 [25:40:20<3:17:24,  8.37s/it] 86%|████████▋ | 8981/10395 [25:40:28<3:12:14,  8.16s/it]                                                         {'loss': 0.8801, 'learning_rate': 9.548893046052553e-07, 'epoch': 0.86}
 86%|████████▋ | 8981/10395 [25:40:28<3:12:14,  8.16s/it] 86%|████████▋ | 8982/10395 [25:40:36<3:12:20,  8.17s/it]                                                         {'loss': 0.8224, 'learning_rate': 9.535610392745764e-07, 'epoch': 0.86}
 86%|████████▋ | 8982/10395 [25:40:36<3:12:20,  8.17s/it] 86%|████████▋ | 8983/10395 [25:40:44<3:10:00,  8.07s/it]                                                         {'loss': 0.9551, 'learning_rate': 9.522336521528608e-07, 'epoch': 0.86}
 86%|████████▋ | 8983/10395 [25:40:44<3:10:00,  8.07s/it] 86%|████████▋ | 8984/10395 [25:40:53<3:15:56,  8.33s/it]                                                         {'loss': 0.8425, 'learning_rate': 9.509071433689654e-07, 'epoch': 0.86}
 86%|████████▋ | 8984/10395 [25:40:53<3:15:56,  8.33s/it] 86%|████████▋ | 8985/10395 [25:41:00<3:08:32,  8.02s/it]                                                         {'loss': 0.8628, 'learning_rate': 9.495815130516695e-07, 'epoch': 0.86}
 86%|████████▋ | 8985/10395 [25:41:00<3:08:32,  8.02s/it] 86%|████████▋ | 8986/10395 [25:41:07<3:04:02,  7.84s/it]                                                         {'loss': 0.9056, 'learning_rate': 9.482567613296567e-07, 'epoch': 0.86}
 86%|████████▋ | 8986/10395 [25:41:07<3:04:02,  7.84s/it] 86%|████████▋ | 8987/10395 [25:41:15<2:59:56,  7.67s/it]                                                         {'loss': 0.8069, 'learning_rate': 9.469328883315343e-07, 'epoch': 0.86}
 86%|████████▋ | 8987/10395 [25:41:15<2:59:56,  7.67s/it] 86%|████████▋ | 8988/10395 [25:41:22<2:59:21,  7.65s/it]                                                         {'loss': 0.8108, 'learning_rate': 9.456098941858238e-07, 'epoch': 0.86}
 86%|████████▋ | 8988/10395 [25:41:22<2:59:21,  7.65s/it] 86%|████████▋ | 8989/10395 [25:41:30<2:57:23,  7.57s/it]                                                         {'loss': 0.748, 'learning_rate': 9.442877790209526e-07, 'epoch': 0.86}
 86%|████████▋ | 8989/10395 [25:41:30<2:57:23,  7.57s/it] 86%|████████▋ | 8990/10395 [25:41:37<2:58:44,  7.63s/it]                                                         {'loss': 0.8963, 'learning_rate': 9.429665429652712e-07, 'epoch': 0.86}
 86%|████████▋ | 8990/10395 [25:41:37<2:58:44,  7.63s/it] 86%|████████▋ | 8991/10395 [25:41:45<2:58:27,  7.63s/it]                                                         {'loss': 0.8796, 'learning_rate': 9.41646186147045e-07, 'epoch': 0.86}
 86%|████████▋ | 8991/10395 [25:41:45<2:58:27,  7.63s/it] 87%|████████▋ | 8992/10395 [25:41:53<2:58:18,  7.63s/it]                                                         {'loss': 0.8578, 'learning_rate': 9.403267086944468e-07, 'epoch': 0.86}
 87%|████████▋ | 8992/10395 [25:41:53<2:58:18,  7.63s/it] 87%|████████▋ | 8993/10395 [25:42:08<3:52:21,  9.94s/it]                                                         {'loss': 0.3427, 'learning_rate': 9.390081107355731e-07, 'epoch': 0.87}
 87%|████████▋ | 8993/10395 [25:42:08<3:52:21,  9.94s/it] 87%|████████▋ | 8994/10395 [25:42:16<3:36:20,  9.27s/it]                                                         {'loss': 0.8272, 'learning_rate': 9.376903923984271e-07, 'epoch': 0.87}
 87%|████████▋ | 8994/10395 [25:42:16<3:36:20,  9.27s/it] 87%|████████▋ | 8995/10395 [25:42:23<3:23:32,  8.72s/it]                                                         {'loss': 0.8682, 'learning_rate': 9.363735538109331e-07, 'epoch': 0.87}
 87%|████████▋ | 8995/10395 [25:42:23<3:23:32,  8.72s/it] 87%|████████▋ | 8996/10395 [25:42:32<3:24:09,  8.76s/it]                                                         {'loss': 0.8379, 'learning_rate': 9.350575951009255e-07, 'epoch': 0.87}
 87%|████████▋ | 8996/10395 [25:42:32<3:24:09,  8.76s/it] 87%|████████▋ | 8997/10395 [25:42:40<3:17:01,  8.46s/it]                                                         {'loss': 0.7848, 'learning_rate': 9.337425163961533e-07, 'epoch': 0.87}
 87%|████████▋ | 8997/10395 [25:42:40<3:17:01,  8.46s/it] 87%|████████▋ | 8998/10395 [25:42:48<3:12:54,  8.29s/it]                                                         {'loss': 0.7834, 'learning_rate': 9.324283178242832e-07, 'epoch': 0.87}
 87%|████████▋ | 8998/10395 [25:42:48<3:12:54,  8.29s/it] 87%|████████▋ | 8999/10395 [25:42:55<3:06:06,  8.00s/it]                                                         {'loss': 0.8465, 'learning_rate': 9.311149995128954e-07, 'epoch': 0.87}
 87%|████████▋ | 8999/10395 [25:42:55<3:06:06,  8.00s/it] 87%|████████▋ | 9000/10395 [25:43:03<3:09:59,  8.17s/it]                                                         {'loss': 0.803, 'learning_rate': 9.298025615894824e-07, 'epoch': 0.87}
 87%|████████▋ | 9000/10395 [25:43:03<3:09:59,  8.17s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 87%|████████▋ | 9001/10395 [25:44:43<13:50:00, 35.73s/it]                                                          {'loss': 0.9117, 'learning_rate': 9.284910041814543e-07, 'epoch': 0.87}
 87%|████████▋ | 9001/10395 [25:44:43<13:50:00, 35.73s/it] 87%|████████▋ | 9002/10395 [25:44:51<10:31:22, 27.19s/it]                                                          {'loss': 0.9291, 'learning_rate': 9.271803274161329e-07, 'epoch': 0.87}
 87%|████████▋ | 9002/10395 [25:44:51<10:31:22, 27.19s/it] 87%|████████▋ | 9003/10395 [25:44:59<8:15:44, 21.37s/it]                                                          {'loss': 0.8535, 'learning_rate': 9.258705314207572e-07, 'epoch': 0.87}
 87%|████████▋ | 9003/10395 [25:44:59<8:15:44, 21.37s/it] 87%|████████▋ | 9004/10395 [25:45:06<6:38:55, 17.21s/it]                                                         {'loss': 0.8199, 'learning_rate': 9.245616163224802e-07, 'epoch': 0.87}
 87%|████████▋ | 9004/10395 [25:45:06<6:38:55, 17.21s/it] 87%|████████▋ | 9005/10395 [25:45:14<5:31:25, 14.31s/it]                                                         {'loss': 0.8268, 'learning_rate': 9.232535822483645e-07, 'epoch': 0.87}
 87%|████████▋ | 9005/10395 [25:45:14<5:31:25, 14.31s/it] 87%|████████▋ | 9006/10395 [25:45:31<5:52:19, 15.22s/it]                                                         {'loss': 0.35, 'learning_rate': 9.219464293253944e-07, 'epoch': 0.87}
 87%|████████▋ | 9006/10395 [25:45:31<5:52:19, 15.22s/it] 87%|████████▋ | 9007/10395 [25:45:40<5:06:38, 13.26s/it]                                                         {'loss': 0.8096, 'learning_rate': 9.206401576804669e-07, 'epoch': 0.87}
 87%|████████▋ | 9007/10395 [25:45:40<5:06:38, 13.26s/it] 87%|████████▋ | 9008/10395 [25:45:47<4:27:34, 11.57s/it]                                                         {'loss': 0.7755, 'learning_rate': 9.193347674403886e-07, 'epoch': 0.87}
 87%|████████▋ | 9008/10395 [25:45:47<4:27:34, 11.57s/it] 87%|████████▋ | 9009/10395 [25:45:55<3:57:45, 10.29s/it]                                                         {'loss': 0.9264, 'learning_rate': 9.180302587318868e-07, 'epoch': 0.87}
 87%|████████▋ | 9009/10395 [25:45:55<3:57:45, 10.29s/it] 87%|████████▋ | 9010/10395 [25:46:03<3:42:13,  9.63s/it]                                                         {'loss': 0.9143, 'learning_rate': 9.167266316815992e-07, 'epoch': 0.87}
 87%|████████▋ | 9010/10395 [25:46:03<3:42:13,  9.63s/it] 87%|████████▋ | 9011/10395 [25:46:11<3:35:19,  9.33s/it]                                                         {'loss': 0.8249, 'learning_rate': 9.15423886416078e-07, 'epoch': 0.87}
 87%|████████▋ | 9011/10395 [25:46:11<3:35:19,  9.33s/it] 87%|████████▋ | 9012/10395 [25:46:19<3:21:47,  8.75s/it]                                                         {'loss': 0.9128, 'learning_rate': 9.14122023061792e-07, 'epoch': 0.87}
 87%|████████▋ | 9012/10395 [25:46:19<3:21:47,  8.75s/it] 87%|████████▋ | 9013/10395 [25:46:26<3:12:13,  8.35s/it]                                                         {'loss': 0.8724, 'learning_rate': 9.128210417451245e-07, 'epoch': 0.87}
 87%|████████▋ | 9013/10395 [25:46:26<3:12:13,  8.35s/it] 87%|████████▋ | 9014/10395 [25:46:36<3:20:58,  8.73s/it]                                                         {'loss': 0.8468, 'learning_rate': 9.115209425923699e-07, 'epoch': 0.87}
 87%|████████▋ | 9014/10395 [25:46:36<3:20:58,  8.73s/it] 87%|████████▋ | 9015/10395 [25:46:43<3:13:02,  8.39s/it]                                                         {'loss': 0.8685, 'learning_rate': 9.102217257297419e-07, 'epoch': 0.87}
 87%|████████▋ | 9015/10395 [25:46:43<3:13:02,  8.39s/it] 87%|████████▋ | 9016/10395 [25:46:51<3:06:47,  8.13s/it]                                                         {'loss': 0.9334, 'learning_rate': 9.089233912833617e-07, 'epoch': 0.87}
 87%|████████▋ | 9016/10395 [25:46:51<3:06:47,  8.13s/it] 87%|████████▋ | 9017/10395 [25:46:58<3:02:18,  7.94s/it]                                                         {'loss': 0.8952, 'learning_rate': 9.076259393792708e-07, 'epoch': 0.87}
 87%|████████▋ | 9017/10395 [25:46:58<3:02:18,  7.94s/it] 87%|████████▋ | 9018/10395 [25:47:06<2:59:21,  7.82s/it]                                                         {'loss': 0.8945, 'learning_rate': 9.063293701434273e-07, 'epoch': 0.87}
 87%|████████▋ | 9018/10395 [25:47:06<2:59:21,  7.82s/it] 87%|████████▋ | 9019/10395 [25:47:13<2:57:23,  7.74s/it]                                                         {'loss': 0.8515, 'learning_rate': 9.050336837016915e-07, 'epoch': 0.87}
 87%|████████▋ | 9019/10395 [25:47:13<2:57:23,  7.74s/it] 87%|████████▋ | 9020/10395 [25:47:21<2:56:05,  7.68s/it]                                                         {'loss': 0.9055, 'learning_rate': 9.037388801798485e-07, 'epoch': 0.87}
 87%|████████▋ | 9020/10395 [25:47:21<2:56:05,  7.68s/it] 87%|████████▋ | 9021/10395 [25:47:38<4:03:49, 10.65s/it]                                                         {'loss': 0.3553, 'learning_rate': 9.024449597036001e-07, 'epoch': 0.87}
 87%|████████▋ | 9021/10395 [25:47:38<4:03:49, 10.65s/it] 87%|████████▋ | 9022/10395 [25:47:46<3:42:21,  9.72s/it]                                                         {'loss': 0.8206, 'learning_rate': 9.011519223985499e-07, 'epoch': 0.87}
 87%|████████▋ | 9022/10395 [25:47:46<3:42:21,  9.72s/it] 87%|████████▋ | 9023/10395 [25:47:54<3:29:37,  9.17s/it]                                                         {'loss': 0.8257, 'learning_rate': 8.998597683902299e-07, 'epoch': 0.87}
 87%|████████▋ | 9023/10395 [25:47:54<3:29:37,  9.17s/it] 87%|████████▋ | 9024/10395 [25:48:01<3:16:17,  8.59s/it]                                                         {'loss': 0.9318, 'learning_rate': 8.985684978040743e-07, 'epoch': 0.87}
 87%|████████▋ | 9024/10395 [25:48:01<3:16:17,  8.59s/it] 87%|████████▋ | 9025/10395 [25:48:09<3:12:54,  8.45s/it]                                                         {'loss': 0.8166, 'learning_rate': 8.972781107654405e-07, 'epoch': 0.87}
 87%|████████▋ | 9025/10395 [25:48:09<3:12:54,  8.45s/it] 87%|████████▋ | 9026/10395 [25:48:18<3:12:09,  8.42s/it]                                                         {'loss': 0.8652, 'learning_rate': 8.95988607399596e-07, 'epoch': 0.87}
 87%|████████▋ | 9026/10395 [25:48:18<3:12:09,  8.42s/it] 87%|████████▋ | 9027/10395 [25:48:27<3:20:24,  8.79s/it]                                                         {'loss': 0.827, 'learning_rate': 8.946999878317197e-07, 'epoch': 0.87}
 87%|████████▋ | 9027/10395 [25:48:27<3:20:24,  8.79s/it] 87%|████████▋ | 9028/10395 [25:48:35<3:13:57,  8.51s/it]                                                         {'loss': 0.8294, 'learning_rate': 8.934122521869104e-07, 'epoch': 0.87}
 87%|████████▋ | 9028/10395 [25:48:35<3:13:57,  8.51s/it] 87%|████████▋ | 9029/10395 [25:48:42<3:04:55,  8.12s/it]                                                         {'loss': 0.8859, 'learning_rate': 8.921254005901813e-07, 'epoch': 0.87}
 87%|████████▋ | 9029/10395 [25:48:42<3:04:55,  8.12s/it] 87%|████████▋ | 9030/10395 [25:48:50<2:59:17,  7.88s/it]                                                         {'loss': 0.8722, 'learning_rate': 8.908394331664516e-07, 'epoch': 0.87}
 87%|████████▋ | 9030/10395 [25:48:50<2:59:17,  7.88s/it] 87%|████████▋ | 9031/10395 [25:48:57<2:54:07,  7.66s/it]                                                         {'loss': 0.8726, 'learning_rate': 8.895543500405668e-07, 'epoch': 0.87}
 87%|████████▋ | 9031/10395 [25:48:57<2:54:07,  7.66s/it] 87%|████████▋ | 9032/10395 [25:49:04<2:53:13,  7.63s/it]                                                         {'loss': 0.823, 'learning_rate': 8.88270151337276e-07, 'epoch': 0.87}
 87%|████████▋ | 9032/10395 [25:49:04<2:53:13,  7.63s/it] 87%|████████▋ | 9033/10395 [25:49:21<3:54:54, 10.35s/it]                                                         {'loss': 0.3475, 'learning_rate': 8.869868371812451e-07, 'epoch': 0.87}
 87%|████████▋ | 9033/10395 [25:49:21<3:54:54, 10.35s/it] 87%|████████▋ | 9034/10395 [25:49:30<3:46:01,  9.96s/it]                                                         {'loss': 0.8278, 'learning_rate': 8.857044076970589e-07, 'epoch': 0.87}
 87%|████████▋ | 9034/10395 [25:49:30<3:46:01,  9.96s/it] 87%|████████▋ | 9035/10395 [25:49:38<3:31:23,  9.33s/it]                                                         {'loss': 0.8416, 'learning_rate': 8.8442286300921e-07, 'epoch': 0.87}
 87%|████████▋ | 9035/10395 [25:49:38<3:31:23,  9.33s/it] 87%|████████▋ | 9036/10395 [25:49:45<3:17:55,  8.74s/it]                                                         {'loss': 0.8426, 'learning_rate': 8.8314220324211e-07, 'epoch': 0.87}
 87%|████████▋ | 9036/10395 [25:49:45<3:17:55,  8.74s/it] 87%|████████▋ | 9037/10395 [25:49:53<3:10:30,  8.42s/it]                                                         {'loss': 0.8997, 'learning_rate': 8.818624285200827e-07, 'epoch': 0.87}
 87%|████████▋ | 9037/10395 [25:49:53<3:10:30,  8.42s/it] 87%|████████▋ | 9038/10395 [25:50:01<3:07:56,  8.31s/it]                                                         {'loss': 0.8885, 'learning_rate': 8.805835389673644e-07, 'epoch': 0.87}
 87%|████████▋ | 9038/10395 [25:50:01<3:07:56,  8.31s/it] 87%|████████▋ | 9039/10395 [25:50:09<3:03:57,  8.14s/it]                                                         {'loss': 0.8168, 'learning_rate': 8.793055347081103e-07, 'epoch': 0.87}
 87%|████████▋ | 9039/10395 [25:50:09<3:03:57,  8.14s/it] 87%|████████▋ | 9040/10395 [25:50:16<2:57:12,  7.85s/it]                                                         {'loss': 0.8542, 'learning_rate': 8.780284158663833e-07, 'epoch': 0.87}
 87%|████████▋ | 9040/10395 [25:50:16<2:57:12,  7.85s/it] 87%|████████▋ | 9041/10395 [25:50:24<2:58:15,  7.90s/it]                                                         {'loss': 0.8859, 'learning_rate': 8.767521825661618e-07, 'epoch': 0.87}
 87%|████████▋ | 9041/10395 [25:50:24<2:58:15,  7.90s/it] 87%|████████▋ | 9042/10395 [25:50:32<2:58:48,  7.93s/it]                                                         {'loss': 0.858, 'learning_rate': 8.754768349313436e-07, 'epoch': 0.87}
 87%|████████▋ | 9042/10395 [25:50:32<2:58:48,  7.93s/it] 87%|████████▋ | 9043/10395 [25:50:40<2:58:40,  7.93s/it]                                                         {'loss': 0.8029, 'learning_rate': 8.742023730857341e-07, 'epoch': 0.87}
 87%|████████▋ | 9043/10395 [25:50:40<2:58:40,  7.93s/it] 87%|████████▋ | 9044/10395 [25:50:49<3:04:42,  8.20s/it]                                                         {'loss': 0.815, 'learning_rate': 8.729287971530554e-07, 'epoch': 0.87}
 87%|████████▋ | 9044/10395 [25:50:49<3:04:42,  8.20s/it] 87%|████████▋ | 9045/10395 [25:50:56<3:00:29,  8.02s/it]                                                         {'loss': 0.8647, 'learning_rate': 8.716561072569474e-07, 'epoch': 0.87}
 87%|████████▋ | 9045/10395 [25:50:56<3:00:29,  8.02s/it] 87%|████████▋ | 9046/10395 [25:51:04<2:54:19,  7.75s/it]                                                         {'loss': 0.8532, 'learning_rate': 8.703843035209547e-07, 'epoch': 0.87}
 87%|████████▋ | 9046/10395 [25:51:04<2:54:19,  7.75s/it] 87%|████████▋ | 9047/10395 [25:51:11<2:54:54,  7.79s/it]                                                         {'loss': 0.8451, 'learning_rate': 8.691133860685452e-07, 'epoch': 0.87}
 87%|████████▋ | 9047/10395 [25:51:11<2:54:54,  7.79s/it] 87%|████████▋ | 9048/10395 [25:51:30<4:05:25, 10.93s/it]                                                         {'loss': 0.3881, 'learning_rate': 8.678433550230959e-07, 'epoch': 0.87}
 87%|████████▋ | 9048/10395 [25:51:30<4:05:25, 10.93s/it] 87%|████████▋ | 9049/10395 [25:51:47<4:50:30, 12.95s/it]                                                         {'loss': 0.3462, 'learning_rate': 8.665742105078967e-07, 'epoch': 0.87}
 87%|████████▋ | 9049/10395 [25:51:47<4:50:30, 12.95s/it] 87%|████████▋ | 9050/10395 [25:51:55<4:11:45, 11.23s/it]                                                         {'loss': 0.8278, 'learning_rate': 8.65305952646156e-07, 'epoch': 0.87}
 87%|████████▋ | 9050/10395 [25:51:55<4:11:45, 11.23s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 87%|████████▋ | 9051/10395 [25:53:35<14:13:43, 38.11s/it]                                                          {'loss': 0.8675, 'learning_rate': 8.640385815609909e-07, 'epoch': 0.87}
 87%|████████▋ | 9051/10395 [25:53:35<14:13:43, 38.11s/it] 87%|████████▋ | 9052/10395 [25:53:44<10:53:03, 29.18s/it]                                                          {'loss': 0.8824, 'learning_rate': 8.627720973754372e-07, 'epoch': 0.87}
 87%|████████▋ | 9052/10395 [25:53:44<10:53:03, 29.18s/it] 87%|████████▋ | 9053/10395 [25:53:51<8:27:43, 22.70s/it]                                                          {'loss': 0.8653, 'learning_rate': 8.615065002124434e-07, 'epoch': 0.87}
 87%|████████▋ | 9053/10395 [25:53:51<8:27:43, 22.70s/it] 87%|████████▋ | 9054/10395 [25:53:59<6:48:56, 18.30s/it]                                                         {'loss': 0.8547, 'learning_rate': 8.602417901948701e-07, 'epoch': 0.87}
 87%|████████▋ | 9054/10395 [25:53:59<6:48:56, 18.30s/it] 87%|████████▋ | 9055/10395 [25:54:09<5:48:29, 15.60s/it]                                                         {'loss': 0.7426, 'learning_rate': 8.58977967445489e-07, 'epoch': 0.87}
 87%|████████▋ | 9055/10395 [25:54:09<5:48:29, 15.60s/it] 87%|████████▋ | 9056/10395 [25:54:16<4:55:04, 13.22s/it]                                                         {'loss': 0.8085, 'learning_rate': 8.577150320869953e-07, 'epoch': 0.87}
 87%|████████▋ | 9056/10395 [25:54:16<4:55:04, 13.22s/it] 87%|████████▋ | 9057/10395 [25:54:24<4:16:31, 11.50s/it]                                                         {'loss': 0.8119, 'learning_rate': 8.564529842419866e-07, 'epoch': 0.87}
 87%|████████▋ | 9057/10395 [25:54:24<4:16:31, 11.50s/it] 87%|████████▋ | 9058/10395 [25:54:32<3:55:45, 10.58s/it]                                                         {'loss': 0.7845, 'learning_rate': 8.551918240329848e-07, 'epoch': 0.87}
 87%|████████▋ | 9058/10395 [25:54:32<3:55:45, 10.58s/it] 87%|████████▋ | 9059/10395 [25:54:40<3:36:35,  9.73s/it]                                                         {'loss': 0.831, 'learning_rate': 8.539315515824165e-07, 'epoch': 0.87}
 87%|████████▋ | 9059/10395 [25:54:40<3:36:35,  9.73s/it] 87%|████████▋ | 9060/10395 [25:54:56<4:19:02, 11.64s/it]                                                         {'loss': 0.3986, 'learning_rate': 8.52672167012627e-07, 'epoch': 0.87}
 87%|████████▋ | 9060/10395 [25:54:56<4:19:02, 11.64s/it] 87%|████████▋ | 9061/10395 [25:55:04<3:56:48, 10.65s/it]                                                         {'loss': 0.8752, 'learning_rate': 8.514136704458786e-07, 'epoch': 0.87}
 87%|████████▋ | 9061/10395 [25:55:04<3:56:48, 10.65s/it] 87%|████████▋ | 9062/10395 [25:55:12<3:38:51,  9.85s/it]                                                         {'loss': 0.7896, 'learning_rate': 8.501560620043403e-07, 'epoch': 0.87}
 87%|████████▋ | 9062/10395 [25:55:12<3:38:51,  9.85s/it] 87%|████████▋ | 9063/10395 [25:55:20<3:20:43,  9.04s/it]                                                         {'loss': 0.8223, 'learning_rate': 8.488993418100955e-07, 'epoch': 0.87}
 87%|████████▋ | 9063/10395 [25:55:20<3:20:43,  9.04s/it] 87%|████████▋ | 9064/10395 [25:55:28<3:15:47,  8.83s/it]                                                         {'loss': 0.8519, 'learning_rate': 8.476435099851488e-07, 'epoch': 0.87}
 87%|████████▋ | 9064/10395 [25:55:28<3:15:47,  8.83s/it] 87%|████████▋ | 9065/10395 [25:55:36<3:08:54,  8.52s/it]                                                         {'loss': 0.8056, 'learning_rate': 8.463885666514105e-07, 'epoch': 0.87}
 87%|████████▋ | 9065/10395 [25:55:36<3:08:54,  8.52s/it] 87%|████████▋ | 9066/10395 [25:55:43<3:01:45,  8.21s/it]                                                         {'loss': 0.8893, 'learning_rate': 8.451345119307097e-07, 'epoch': 0.87}
 87%|████████▋ | 9066/10395 [25:55:43<3:01:45,  8.21s/it] 87%|████████▋ | 9067/10395 [25:55:51<2:56:42,  7.98s/it]                                                         {'loss': 0.9273, 'learning_rate': 8.438813459447848e-07, 'epoch': 0.87}
 87%|████████▋ | 9067/10395 [25:55:51<2:56:42,  7.98s/it] 87%|████████▋ | 9068/10395 [25:55:58<2:55:11,  7.92s/it]                                                         {'loss': 0.8802, 'learning_rate': 8.426290688152927e-07, 'epoch': 0.87}
 87%|████████▋ | 9068/10395 [25:55:58<2:55:11,  7.92s/it] 87%|████████▋ | 9069/10395 [25:56:15<3:54:57, 10.63s/it]                                                         {'loss': 0.3171, 'learning_rate': 8.413776806638041e-07, 'epoch': 0.87}
 87%|████████▋ | 9069/10395 [25:56:15<3:54:57, 10.63s/it] 87%|████████▋ | 9070/10395 [25:56:23<3:35:58,  9.78s/it]                                                         {'loss': 0.8929, 'learning_rate': 8.401271816117951e-07, 'epoch': 0.87}
 87%|████████▋ | 9070/10395 [25:56:23<3:35:58,  9.78s/it] 87%|████████▋ | 9071/10395 [25:56:40<4:26:06, 12.06s/it]                                                         {'loss': 0.3806, 'learning_rate': 8.388775717806641e-07, 'epoch': 0.87}
 87%|████████▋ | 9071/10395 [25:56:40<4:26:06, 12.06s/it] 87%|████████▋ | 9072/10395 [25:56:48<3:57:41, 10.78s/it]                                                         {'loss': 0.8517, 'learning_rate': 8.37628851291723e-07, 'epoch': 0.87}
 87%|████████▋ | 9072/10395 [25:56:48<3:57:41, 10.78s/it] 87%|████████▋ | 9073/10395 [25:56:56<3:39:35,  9.97s/it]                                                         {'loss': 0.8999, 'learning_rate': 8.363810202661915e-07, 'epoch': 0.87}
 87%|████████▋ | 9073/10395 [25:56:56<3:39:35,  9.97s/it] 87%|████████▋ | 9074/10395 [25:57:05<3:28:16,  9.46s/it]                                                         {'loss': 0.8412, 'learning_rate': 8.351340788252094e-07, 'epoch': 0.87}
 87%|████████▋ | 9074/10395 [25:57:05<3:28:16,  9.46s/it] 87%|████████▋ | 9075/10395 [25:57:12<3:16:42,  8.94s/it]                                                         {'loss': 0.8948, 'learning_rate': 8.338880270898242e-07, 'epoch': 0.87}
 87%|████████▋ | 9075/10395 [25:57:12<3:16:42,  8.94s/it] 87%|████████▋ | 9076/10395 [25:57:21<3:14:45,  8.86s/it]                                                         {'loss': 0.8226, 'learning_rate': 8.326428651810026e-07, 'epoch': 0.87}
 87%|████████▋ | 9076/10395 [25:57:21<3:14:45,  8.86s/it] 87%|████████▋ | 9077/10395 [25:57:30<3:16:08,  8.93s/it]                                                         {'loss': 0.9234, 'learning_rate': 8.3139859321962e-07, 'epoch': 0.87}
 87%|████████▋ | 9077/10395 [25:57:30<3:16:08,  8.93s/it] 87%|████████▋ | 9078/10395 [25:57:38<3:10:51,  8.70s/it]                                                         {'loss': 0.8393, 'learning_rate': 8.301552113264688e-07, 'epoch': 0.87}
 87%|████████▋ | 9078/10395 [25:57:38<3:10:51,  8.70s/it] 87%|████████▋ | 9079/10395 [25:57:56<4:08:43, 11.34s/it]                                                         {'loss': 0.3833, 'learning_rate': 8.289127196222535e-07, 'epoch': 0.87}
 87%|████████▋ | 9079/10395 [25:57:56<4:08:43, 11.34s/it] 87%|████████▋ | 9080/10395 [25:58:03<3:42:13, 10.14s/it]                                                         {'loss': 0.9098, 'learning_rate': 8.276711182275932e-07, 'epoch': 0.87}
 87%|████████▋ | 9080/10395 [25:58:03<3:42:13, 10.14s/it] 87%|████████▋ | 9081/10395 [25:58:10<3:22:31,  9.25s/it]                                                         {'loss': 0.9168, 'learning_rate': 8.26430407263018e-07, 'epoch': 0.87}
 87%|████████▋ | 9081/10395 [25:58:10<3:22:31,  9.25s/it] 87%|████████▋ | 9082/10395 [25:58:18<3:11:28,  8.75s/it]                                                         {'loss': 0.9066, 'learning_rate': 8.251905868489751e-07, 'epoch': 0.87}
 87%|████████▋ | 9082/10395 [25:58:18<3:11:28,  8.75s/it] 87%|████████▋ | 9083/10395 [25:58:25<3:03:00,  8.37s/it]                                                         {'loss': 0.8341, 'learning_rate': 8.239516571058248e-07, 'epoch': 0.87}
 87%|████████▋ | 9083/10395 [25:58:25<3:03:00,  8.37s/it] 87%|████████▋ | 9084/10395 [25:58:35<3:13:24,  8.85s/it]                                                         {'loss': 0.7256, 'learning_rate': 8.227136181538387e-07, 'epoch': 0.87}
 87%|████████▋ | 9084/10395 [25:58:35<3:13:24,  8.85s/it] 87%|████████▋ | 9085/10395 [25:58:43<3:04:56,  8.47s/it]                                                         {'loss': 0.8402, 'learning_rate': 8.214764701132017e-07, 'epoch': 0.87}
 87%|████████▋ | 9085/10395 [25:58:43<3:04:56,  8.47s/it] 87%|████████▋ | 9086/10395 [25:58:51<2:59:13,  8.21s/it]                                                         {'loss': 0.8308, 'learning_rate': 8.202402131040143e-07, 'epoch': 0.87}
 87%|████████▋ | 9086/10395 [25:58:51<2:59:13,  8.21s/it] 87%|████████▋ | 9087/10395 [25:58:59<2:58:29,  8.19s/it]                                                         {'loss': 0.8467, 'learning_rate': 8.190048472462897e-07, 'epoch': 0.87}
 87%|████████▋ | 9087/10395 [25:58:59<2:58:29,  8.19s/it] 87%|████████▋ | 9088/10395 [25:59:07<2:59:04,  8.22s/it]                                                         {'loss': 0.7603, 'learning_rate': 8.17770372659955e-07, 'epoch': 0.87}
 87%|████████▋ | 9088/10395 [25:59:07<2:59:04,  8.22s/it] 87%|████████▋ | 9089/10395 [25:59:14<2:54:32,  8.02s/it]                                                         {'loss': 0.9631, 'learning_rate': 8.165367894648502e-07, 'epoch': 0.87}
 87%|████████▋ | 9089/10395 [25:59:15<2:54:32,  8.02s/it] 87%|████████▋ | 9090/10395 [25:59:23<2:57:28,  8.16s/it]                                                         {'loss': 0.8088, 'learning_rate': 8.15304097780727e-07, 'epoch': 0.87}
 87%|████████▋ | 9090/10395 [25:59:23<2:57:28,  8.16s/it] 87%|████████▋ | 9091/10395 [25:59:31<2:56:14,  8.11s/it]                                                         {'loss': 0.7366, 'learning_rate': 8.140722977272586e-07, 'epoch': 0.87}
 87%|████████▋ | 9091/10395 [25:59:31<2:56:14,  8.11s/it] 87%|████████▋ | 9092/10395 [25:59:38<2:50:57,  7.87s/it]                                                         {'loss': 0.842, 'learning_rate': 8.128413894240173e-07, 'epoch': 0.87}
 87%|████████▋ | 9092/10395 [25:59:38<2:50:57,  7.87s/it] 87%|████████▋ | 9093/10395 [25:59:55<3:47:40, 10.49s/it]                                                         {'loss': 0.3595, 'learning_rate': 8.116113729905006e-07, 'epoch': 0.87}
 87%|████████▋ | 9093/10395 [25:59:55<3:47:40, 10.49s/it] 87%|████████▋ | 9094/10395 [26:00:02<3:26:44,  9.53s/it]                                                         {'loss': 0.8771, 'learning_rate': 8.103822485461188e-07, 'epoch': 0.87}
 87%|████████▋ | 9094/10395 [26:00:02<3:26:44,  9.53s/it] 87%|████████▋ | 9095/10395 [26:00:11<3:19:36,  9.21s/it]                                                         {'loss': 0.8415, 'learning_rate': 8.091540162101874e-07, 'epoch': 0.87}
 87%|████████▋ | 9095/10395 [26:00:11<3:19:36,  9.21s/it] 88%|████████▊ | 9096/10395 [26:00:19<3:14:16,  8.97s/it]                                                         {'loss': 0.9294, 'learning_rate': 8.079266761019455e-07, 'epoch': 0.87}
 88%|████████▊ | 9096/10395 [26:00:19<3:14:16,  8.97s/it] 88%|████████▊ | 9097/10395 [26:00:27<3:04:52,  8.55s/it]                                                         {'loss': 0.8825, 'learning_rate': 8.067002283405356e-07, 'epoch': 0.88}
 88%|████████▊ | 9097/10395 [26:00:27<3:04:52,  8.55s/it] 88%|████████▊ | 9098/10395 [26:00:34<2:59:31,  8.31s/it]                                                         {'loss': 0.847, 'learning_rate': 8.054746730450247e-07, 'epoch': 0.88}
 88%|████████▊ | 9098/10395 [26:00:34<2:59:31,  8.31s/it] 88%|████████▊ | 9099/10395 [26:00:52<3:58:56, 11.06s/it]                                                         {'loss': 0.3758, 'learning_rate': 8.042500103343831e-07, 'epoch': 0.88}
 88%|████████▊ | 9099/10395 [26:00:52<3:58:56, 11.06s/it] 88%|████████▊ | 9100/10395 [26:00:59<3:35:57, 10.01s/it]                                                         {'loss': 0.8609, 'learning_rate': 8.030262403274969e-07, 'epoch': 0.88}
 88%|████████▊ | 9100/10395 [26:00:59<3:35:57, 10.01s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 88%|████████▊ | 9101/10395 [26:02:42<13:33:51, 37.74s/it]                                                          {'loss': 0.8323, 'learning_rate': 8.018033631431699e-07, 'epoch': 0.88}
 88%|████████▊ | 9101/10395 [26:02:42<13:33:51, 37.74s/it] 88%|████████▊ | 9102/10395 [26:02:49<10:16:53, 28.63s/it]                                                          {'loss': 0.8237, 'learning_rate': 8.005813789001171e-07, 'epoch': 0.88}
 88%|████████▊ | 9102/10395 [26:02:49<10:16:53, 28.63s/it] 88%|████████▊ | 9103/10395 [26:02:56<7:58:22, 22.22s/it]                                                          {'loss': 0.905, 'learning_rate': 7.993602877169626e-07, 'epoch': 0.88}
 88%|████████▊ | 9103/10395 [26:02:56<7:58:22, 22.22s/it] 88%|████████▊ | 9104/10395 [26:03:04<6:23:55, 17.84s/it]                                                         {'loss': 0.8443, 'learning_rate': 7.981400897122526e-07, 'epoch': 0.88}
 88%|████████▊ | 9104/10395 [26:03:04<6:23:55, 17.84s/it] 88%|████████▊ | 9105/10395 [26:03:13<5:25:29, 15.14s/it]                                                         {'loss': 0.8371, 'learning_rate': 7.969207850044359e-07, 'epoch': 0.88}
 88%|████████▊ | 9105/10395 [26:03:13<5:25:29, 15.14s/it] 88%|████████▊ | 9106/10395 [26:03:21<4:39:26, 13.01s/it]                                                         {'loss': 0.8628, 'learning_rate': 7.957023737118841e-07, 'epoch': 0.88}
 88%|████████▊ | 9106/10395 [26:03:21<4:39:26, 13.01s/it] 88%|████████▊ | 9107/10395 [26:03:28<4:01:18, 11.24s/it]                                                         {'loss': 0.7935, 'learning_rate': 7.944848559528762e-07, 'epoch': 0.88}
 88%|████████▊ | 9107/10395 [26:03:28<4:01:18, 11.24s/it] 88%|████████▊ | 9108/10395 [26:03:36<3:38:50, 10.20s/it]                                                         {'loss': 0.9234, 'learning_rate': 7.932682318456042e-07, 'epoch': 0.88}
 88%|████████▊ | 9108/10395 [26:03:36<3:38:50, 10.20s/it] 88%|████████▊ | 9109/10395 [26:03:44<3:25:04,  9.57s/it]                                                         {'loss': 0.873, 'learning_rate': 7.920525015081771e-07, 'epoch': 0.88}
 88%|████████▊ | 9109/10395 [26:03:44<3:25:04,  9.57s/it] 88%|████████▊ | 9110/10395 [26:03:51<3:10:51,  8.91s/it]                                                         {'loss': 0.9465, 'learning_rate': 7.90837665058618e-07, 'epoch': 0.88}
 88%|████████▊ | 9110/10395 [26:03:51<3:10:51,  8.91s/it] 88%|████████▊ | 9111/10395 [26:03:59<3:02:52,  8.55s/it]                                                         {'loss': 0.8804, 'learning_rate': 7.896237226148573e-07, 'epoch': 0.88}
 88%|████████▊ | 9111/10395 [26:03:59<3:02:52,  8.55s/it] 88%|████████▊ | 9112/10395 [26:04:06<2:54:41,  8.17s/it]                                                         {'loss': 0.8681, 'learning_rate': 7.88410674294744e-07, 'epoch': 0.88}
 88%|████████▊ | 9112/10395 [26:04:06<2:54:41,  8.17s/it] 88%|████████▊ | 9113/10395 [26:04:14<2:52:18,  8.06s/it]                                                         {'loss': 0.8571, 'learning_rate': 7.87198520216037e-07, 'epoch': 0.88}
 88%|████████▊ | 9113/10395 [26:04:14<2:52:18,  8.06s/it] 88%|████████▊ | 9114/10395 [26:04:30<3:45:14, 10.55s/it]                                                         {'loss': 0.3349, 'learning_rate': 7.85987260496408e-07, 'epoch': 0.88}
 88%|████████▊ | 9114/10395 [26:04:31<3:45:14, 10.55s/it] 88%|████████▊ | 9115/10395 [26:04:39<3:34:01, 10.03s/it]                                                         {'loss': 0.8507, 'learning_rate': 7.847768952534473e-07, 'epoch': 0.88}
 88%|████████▊ | 9115/10395 [26:04:39<3:34:01, 10.03s/it] 88%|████████▊ | 9116/10395 [26:04:47<3:16:54,  9.24s/it]                                                         {'loss': 0.902, 'learning_rate': 7.83567424604651e-07, 'epoch': 0.88}
 88%|████████▊ | 9116/10395 [26:04:47<3:16:54,  9.24s/it] 88%|████████▊ | 9117/10395 [26:04:54<3:07:06,  8.78s/it]                                                         {'loss': 0.872, 'learning_rate': 7.823588486674338e-07, 'epoch': 0.88}
 88%|████████▊ | 9117/10395 [26:04:54<3:07:06,  8.78s/it] 88%|████████▊ | 9118/10395 [26:05:02<3:01:53,  8.55s/it]                                                         {'loss': 0.84, 'learning_rate': 7.811511675591221e-07, 'epoch': 0.88}
 88%|████████▊ | 9118/10395 [26:05:02<3:01:53,  8.55s/it] 88%|████████▊ | 9119/10395 [26:05:10<2:54:35,  8.21s/it]                                                         {'loss': 0.86, 'learning_rate': 7.799443813969532e-07, 'epoch': 0.88}
 88%|████████▊ | 9119/10395 [26:05:10<2:54:35,  8.21s/it] 88%|████████▊ | 9120/10395 [26:05:17<2:49:52,  7.99s/it]                                                         {'loss': 0.8939, 'learning_rate': 7.787384902980821e-07, 'epoch': 0.88}
 88%|████████▊ | 9120/10395 [26:05:17<2:49:52,  7.99s/it] 88%|████████▊ | 9121/10395 [26:05:25<2:49:19,  7.97s/it]                                                         {'loss': 0.8235, 'learning_rate': 7.775334943795732e-07, 'epoch': 0.88}
 88%|████████▊ | 9121/10395 [26:05:25<2:49:19,  7.97s/it] 88%|████████▊ | 9122/10395 [26:05:34<2:51:37,  8.09s/it]                                                         {'loss': 0.8721, 'learning_rate': 7.763293937584015e-07, 'epoch': 0.88}
 88%|████████▊ | 9122/10395 [26:05:34<2:51:37,  8.09s/it] 88%|████████▊ | 9123/10395 [26:05:42<2:53:00,  8.16s/it]                                                         {'loss': 0.8697, 'learning_rate': 7.751261885514638e-07, 'epoch': 0.88}
 88%|████████▊ | 9123/10395 [26:05:42<2:53:00,  8.16s/it] 88%|████████▊ | 9124/10395 [26:05:50<2:54:00,  8.21s/it]                                                         {'loss': 0.869, 'learning_rate': 7.739238788755599e-07, 'epoch': 0.88}
 88%|████████▊ | 9124/10395 [26:05:50<2:54:00,  8.21s/it] 88%|████████▊ | 9125/10395 [26:05:59<2:58:04,  8.41s/it]                                                         {'loss': 0.7929, 'learning_rate': 7.727224648474097e-07, 'epoch': 0.88}
 88%|████████▊ | 9125/10395 [26:05:59<2:58:04,  8.41s/it] 88%|████████▊ | 9126/10395 [26:06:06<2:50:33,  8.06s/it]                                                         {'loss': 0.8064, 'learning_rate': 7.715219465836454e-07, 'epoch': 0.88}
 88%|████████▊ | 9126/10395 [26:06:06<2:50:33,  8.06s/it] 88%|████████▊ | 9127/10395 [26:06:15<2:55:18,  8.30s/it]                                                         {'loss': 0.8129, 'learning_rate': 7.703223242008073e-07, 'epoch': 0.88}
 88%|████████▊ | 9127/10395 [26:06:15<2:55:18,  8.30s/it] 88%|████████▊ | 9128/10395 [26:06:23<2:51:25,  8.12s/it]                                                         {'loss': 0.8552, 'learning_rate': 7.691235978153555e-07, 'epoch': 0.88}
 88%|████████▊ | 9128/10395 [26:06:23<2:51:25,  8.12s/it] 88%|████████▊ | 9129/10395 [26:06:31<2:48:16,  7.98s/it]                                                         {'loss': 0.8793, 'learning_rate': 7.679257675436591e-07, 'epoch': 0.88}
 88%|████████▊ | 9129/10395 [26:06:31<2:48:16,  7.98s/it] 88%|████████▊ | 9130/10395 [26:06:38<2:46:23,  7.89s/it]                                                         {'loss': 0.8733, 'learning_rate': 7.667288335019984e-07, 'epoch': 0.88}
 88%|████████▊ | 9130/10395 [26:06:38<2:46:23,  7.89s/it] 88%|████████▊ | 9131/10395 [26:06:46<2:45:35,  7.86s/it]                                                         {'loss': 0.9266, 'learning_rate': 7.655327958065728e-07, 'epoch': 0.88}
 88%|████████▊ | 9131/10395 [26:06:46<2:45:35,  7.86s/it] 88%|████████▊ | 9132/10395 [26:06:54<2:42:50,  7.74s/it]                                                         {'loss': 0.934, 'learning_rate': 7.643376545734871e-07, 'epoch': 0.88}
 88%|████████▊ | 9132/10395 [26:06:54<2:42:50,  7.74s/it] 88%|████████▊ | 9133/10395 [26:07:02<2:44:45,  7.83s/it]                                                         {'loss': 0.8129, 'learning_rate': 7.631434099187662e-07, 'epoch': 0.88}
 88%|████████▊ | 9133/10395 [26:07:02<2:44:45,  7.83s/it] 88%|████████▊ | 9134/10395 [26:07:09<2:44:19,  7.82s/it]                                                         {'loss': 0.9235, 'learning_rate': 7.619500619583442e-07, 'epoch': 0.88}
 88%|████████▊ | 9134/10395 [26:07:09<2:44:19,  7.82s/it] 88%|████████▊ | 9135/10395 [26:07:16<2:39:48,  7.61s/it]                                                         {'loss': 0.787, 'learning_rate': 7.607576108080694e-07, 'epoch': 0.88}
 88%|████████▊ | 9135/10395 [26:07:16<2:39:48,  7.61s/it] 88%|████████▊ | 9136/10395 [26:07:24<2:36:24,  7.45s/it]                                                         {'loss': 0.7982, 'learning_rate': 7.595660565836993e-07, 'epoch': 0.88}
 88%|████████▊ | 9136/10395 [26:07:24<2:36:24,  7.45s/it] 88%|████████▊ | 9137/10395 [26:07:32<2:42:13,  7.74s/it]                                                         {'loss': 0.921, 'learning_rate': 7.583753994009113e-07, 'epoch': 0.88}
 88%|████████▊ | 9137/10395 [26:07:32<2:42:13,  7.74s/it] 88%|████████▊ | 9138/10395 [26:07:48<3:31:01, 10.07s/it]                                                         {'loss': 0.3582, 'learning_rate': 7.571856393752886e-07, 'epoch': 0.88}
 88%|████████▊ | 9138/10395 [26:07:48<3:31:01, 10.07s/it] 88%|████████▊ | 9139/10395 [26:07:55<3:16:33,  9.39s/it]                                                         {'loss': 0.8764, 'learning_rate': 7.559967766223331e-07, 'epoch': 0.88}
 88%|████████▊ | 9139/10395 [26:07:55<3:16:33,  9.39s/it] 88%|████████▊ | 9140/10395 [26:08:03<3:05:06,  8.85s/it]                                                         {'loss': 0.9383, 'learning_rate': 7.548088112574548e-07, 'epoch': 0.88}
 88%|████████▊ | 9140/10395 [26:08:03<3:05:06,  8.85s/it] 88%|████████▊ | 9141/10395 [26:08:10<2:56:56,  8.47s/it]                                                         {'loss': 0.9116, 'learning_rate': 7.536217433959802e-07, 'epoch': 0.88}
 88%|████████▊ | 9141/10395 [26:08:10<2:56:56,  8.47s/it] 88%|████████▊ | 9142/10395 [26:08:18<2:50:19,  8.16s/it]                                                         {'loss': 0.8467, 'learning_rate': 7.524355731531485e-07, 'epoch': 0.88}
 88%|████████▊ | 9142/10395 [26:08:18<2:50:19,  8.16s/it] 88%|████████▊ | 9143/10395 [26:08:25<2:44:56,  7.90s/it]                                                         {'loss': 0.8547, 'learning_rate': 7.512503006441096e-07, 'epoch': 0.88}
 88%|████████▊ | 9143/10395 [26:08:25<2:44:56,  7.90s/it] 88%|████████▊ | 9144/10395 [26:08:33<2:41:23,  7.74s/it]                                                         {'loss': 0.8672, 'learning_rate': 7.500659259839249e-07, 'epoch': 0.88}
 88%|████████▊ | 9144/10395 [26:08:33<2:41:23,  7.74s/it] 88%|████████▊ | 9145/10395 [26:08:40<2:41:26,  7.75s/it]                                                         {'loss': 0.838, 'learning_rate': 7.488824492875746e-07, 'epoch': 0.88}
 88%|████████▊ | 9145/10395 [26:08:40<2:41:26,  7.75s/it] 88%|████████▊ | 9146/10395 [26:08:48<2:43:16,  7.84s/it]                                                         {'loss': 0.8905, 'learning_rate': 7.476998706699445e-07, 'epoch': 0.88}
 88%|████████▊ | 9146/10395 [26:08:48<2:43:16,  7.84s/it] 88%|████████▊ | 9147/10395 [26:08:58<2:51:56,  8.27s/it]                                                         {'loss': 0.8646, 'learning_rate': 7.465181902458395e-07, 'epoch': 0.88}
 88%|████████▊ | 9147/10395 [26:08:58<2:51:56,  8.27s/it] 88%|████████▊ | 9148/10395 [26:09:05<2:46:45,  8.02s/it]                                                         {'loss': 0.8861, 'learning_rate': 7.453374081299747e-07, 'epoch': 0.88}
 88%|████████▊ | 9148/10395 [26:09:05<2:46:45,  8.02s/it] 88%|████████▊ | 9149/10395 [26:09:13<2:42:48,  7.84s/it]                                                         {'loss': 0.8432, 'learning_rate': 7.441575244369759e-07, 'epoch': 0.88}
 88%|████████▊ | 9149/10395 [26:09:13<2:42:48,  7.84s/it] 88%|████████▊ | 9150/10395 [26:09:20<2:42:52,  7.85s/it]                                                         {'loss': 0.8975, 'learning_rate': 7.429785392813871e-07, 'epoch': 0.88}
 88%|████████▊ | 9150/10395 [26:09:20<2:42:52,  7.85s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 88%|████████▊ | 9151/10395 [26:10:59<12:08:52, 35.15s/it]                                                          {'loss': 0.8769, 'learning_rate': 7.418004527776579e-07, 'epoch': 0.88}
 88%|████████▊ | 9151/10395 [26:10:59<12:08:52, 35.15s/it] 88%|████████▊ | 9152/10395 [26:11:09<9:28:31, 27.44s/it]                                                          {'loss': 0.8437, 'learning_rate': 7.406232650401557e-07, 'epoch': 0.88}
 88%|████████▊ | 9152/10395 [26:11:09<9:28:31, 27.44s/it] 88%|████████▊ | 9153/10395 [26:11:16<7:25:10, 21.51s/it]                                                         {'loss': 0.897, 'learning_rate': 7.394469761831602e-07, 'epoch': 0.88}
 88%|████████▊ | 9153/10395 [26:11:16<7:25:10, 21.51s/it] 88%|████████▊ | 9154/10395 [26:11:26<6:11:07, 17.94s/it]                                                         {'loss': 0.7245, 'learning_rate': 7.382715863208612e-07, 'epoch': 0.88}
 88%|████████▊ | 9154/10395 [26:11:26<6:11:07, 17.94s/it] 88%|████████▊ | 9155/10395 [26:11:34<5:09:45, 14.99s/it]                                                         {'loss': 0.8502, 'learning_rate': 7.37097095567364e-07, 'epoch': 0.88}
 88%|████████▊ | 9155/10395 [26:11:34<5:09:45, 14.99s/it] 88%|████████▊ | 9156/10395 [26:11:42<4:24:22, 12.80s/it]                                                         {'loss': 0.8164, 'learning_rate': 7.359235040366875e-07, 'epoch': 0.88}
 88%|████████▊ | 9156/10395 [26:11:42<4:24:22, 12.80s/it] 88%|████████▊ | 9157/10395 [26:11:58<4:45:24, 13.83s/it]                                                         {'loss': 0.3361, 'learning_rate': 7.347508118427604e-07, 'epoch': 0.88}
 88%|████████▊ | 9157/10395 [26:11:58<4:45:24, 13.83s/it] 88%|████████▊ | 9158/10395 [26:12:05<4:05:01, 11.88s/it]                                                         {'loss': 0.8386, 'learning_rate': 7.335790190994218e-07, 'epoch': 0.88}
 88%|████████▊ | 9158/10395 [26:12:05<4:05:01, 11.88s/it] 88%|████████▊ | 9159/10395 [26:12:13<3:41:01, 10.73s/it]                                                         {'loss': 0.8335, 'learning_rate': 7.324081259204319e-07, 'epoch': 0.88}
 88%|████████▊ | 9159/10395 [26:12:13<3:41:01, 10.73s/it] 88%|████████▊ | 9160/10395 [26:12:21<3:23:53,  9.91s/it]                                                         {'loss': 0.8446, 'learning_rate': 7.312381324194551e-07, 'epoch': 0.88}
 88%|████████▊ | 9160/10395 [26:12:21<3:23:53,  9.91s/it] 88%|████████▊ | 9161/10395 [26:12:29<3:08:04,  9.15s/it]                                                         {'loss': 0.8868, 'learning_rate': 7.30069038710074e-07, 'epoch': 0.88}
 88%|████████▊ | 9161/10395 [26:12:29<3:08:04,  9.15s/it] 88%|████████▊ | 9162/10395 [26:12:36<2:57:21,  8.63s/it]                                                         {'loss': 0.8843, 'learning_rate': 7.289008449057788e-07, 'epoch': 0.88}
 88%|████████▊ | 9162/10395 [26:12:36<2:57:21,  8.63s/it] 88%|████████▊ | 9163/10395 [26:12:44<2:52:42,  8.41s/it]                                                         {'loss': 0.872, 'learning_rate': 7.277335511199779e-07, 'epoch': 0.88}
 88%|████████▊ | 9163/10395 [26:12:44<2:52:42,  8.41s/it] 88%|████████▊ | 9164/10395 [26:12:52<2:49:14,  8.25s/it]                                                         {'loss': 0.8824, 'learning_rate': 7.265671574659904e-07, 'epoch': 0.88}
 88%|████████▊ | 9164/10395 [26:12:52<2:49:14,  8.25s/it] 88%|████████▊ | 9165/10395 [26:13:00<2:48:17,  8.21s/it]                                                         {'loss': 0.8047, 'learning_rate': 7.25401664057046e-07, 'epoch': 0.88}
 88%|████████▊ | 9165/10395 [26:13:00<2:48:17,  8.21s/it] 88%|████████▊ | 9166/10395 [26:13:08<2:46:35,  8.13s/it]                                                         {'loss': 0.8833, 'learning_rate': 7.242370710062862e-07, 'epoch': 0.88}
 88%|████████▊ | 9166/10395 [26:13:08<2:46:35,  8.13s/it] 88%|████████▊ | 9167/10395 [26:13:16<2:43:34,  7.99s/it]                                                         {'loss': 0.9342, 'learning_rate': 7.230733784267708e-07, 'epoch': 0.88}
 88%|████████▊ | 9167/10395 [26:13:16<2:43:34,  7.99s/it] 88%|████████▊ | 9168/10395 [26:13:23<2:41:00,  7.87s/it]                                                         {'loss': 0.8137, 'learning_rate': 7.219105864314646e-07, 'epoch': 0.88}
 88%|████████▊ | 9168/10395 [26:13:23<2:41:00,  7.87s/it] 88%|████████▊ | 9169/10395 [26:13:30<2:36:34,  7.66s/it]                                                         {'loss': 0.8583, 'learning_rate': 7.207486951332543e-07, 'epoch': 0.88}
 88%|████████▊ | 9169/10395 [26:13:30<2:36:34,  7.66s/it] 88%|████████▊ | 9170/10395 [26:13:39<2:40:05,  7.84s/it]                                                         {'loss': 0.8313, 'learning_rate': 7.195877046449285e-07, 'epoch': 0.88}
 88%|████████▊ | 9170/10395 [26:13:39<2:40:05,  7.84s/it] 88%|████████▊ | 9171/10395 [26:13:47<2:39:46,  7.83s/it]                                                         {'loss': 0.8129, 'learning_rate': 7.184276150791969e-07, 'epoch': 0.88}
 88%|████████▊ | 9171/10395 [26:13:47<2:39:46,  7.83s/it] 88%|████████▊ | 9172/10395 [26:13:55<2:45:22,  8.11s/it]                                                         {'loss': 0.7874, 'learning_rate': 7.172684265486796e-07, 'epoch': 0.88}
 88%|████████▊ | 9172/10395 [26:13:55<2:45:22,  8.11s/it] 88%|████████▊ | 9173/10395 [26:14:03<2:42:58,  8.00s/it]                                                         {'loss': 0.8687, 'learning_rate': 7.161101391659043e-07, 'epoch': 0.88}
 88%|████████▊ | 9173/10395 [26:14:03<2:42:58,  8.00s/it] 88%|████████▊ | 9174/10395 [26:14:10<2:37:54,  7.76s/it]                                                         {'loss': 0.9049, 'learning_rate': 7.149527530433153e-07, 'epoch': 0.88}
 88%|████████▊ | 9174/10395 [26:14:10<2:37:54,  7.76s/it] 88%|████████▊ | 9175/10395 [26:14:18<2:35:00,  7.62s/it]                                                         {'loss': 0.8958, 'learning_rate': 7.137962682932742e-07, 'epoch': 0.88}
 88%|████████▊ | 9175/10395 [26:14:18<2:35:00,  7.62s/it] 88%|████████▊ | 9176/10395 [26:14:35<3:33:17, 10.50s/it]                                                         {'loss': 0.3913, 'learning_rate': 7.126406850280432e-07, 'epoch': 0.88}
 88%|████████▊ | 9176/10395 [26:14:35<3:33:17, 10.50s/it] 88%|████████▊ | 9177/10395 [26:14:43<3:17:16,  9.72s/it]                                                         {'loss': 0.9079, 'learning_rate': 7.114860033598103e-07, 'epoch': 0.88}
 88%|████████▊ | 9177/10395 [26:14:43<3:17:16,  9.72s/it] 88%|████████▊ | 9178/10395 [26:14:51<3:08:42,  9.30s/it]                                                         {'loss': 0.8244, 'learning_rate': 7.103322234006649e-07, 'epoch': 0.88}
 88%|████████▊ | 9178/10395 [26:14:51<3:08:42,  9.30s/it] 88%|████████▊ | 9179/10395 [26:14:59<2:58:20,  8.80s/it]                                                         {'loss': 0.8845, 'learning_rate': 7.091793452626162e-07, 'epoch': 0.88}
 88%|████████▊ | 9179/10395 [26:14:59<2:58:20,  8.80s/it] 88%|████████▊ | 9180/10395 [26:15:07<2:58:34,  8.82s/it]                                                         {'loss': 0.8927, 'learning_rate': 7.080273690575823e-07, 'epoch': 0.88}
 88%|████████▊ | 9180/10395 [26:15:07<2:58:34,  8.82s/it] 88%|████████▊ | 9181/10395 [26:15:15<2:52:28,  8.52s/it]                                                         {'loss': 0.9325, 'learning_rate': 7.068762948973928e-07, 'epoch': 0.88}
 88%|████████▊ | 9181/10395 [26:15:15<2:52:28,  8.52s/it] 88%|████████▊ | 9182/10395 [26:15:31<3:34:51, 10.63s/it]                                                         {'loss': 0.3572, 'learning_rate': 7.057261228937939e-07, 'epoch': 0.88}
 88%|████████▊ | 9182/10395 [26:15:31<3:34:51, 10.63s/it] 88%|████████▊ | 9183/10395 [26:15:39<3:18:08,  9.81s/it]                                                         {'loss': 0.867, 'learning_rate': 7.045768531584418e-07, 'epoch': 0.88}
 88%|████████▊ | 9183/10395 [26:15:39<3:18:08,  9.81s/it] 88%|████████▊ | 9184/10395 [26:15:56<4:05:20, 12.16s/it]                                                         {'loss': 0.4026, 'learning_rate': 7.034284858029027e-07, 'epoch': 0.88}
 88%|████████▊ | 9184/10395 [26:15:56<4:05:20, 12.16s/it] 88%|████████▊ | 9185/10395 [26:16:04<3:38:10, 10.82s/it]                                                         {'loss': 0.8769, 'learning_rate': 7.022810209386611e-07, 'epoch': 0.88}
 88%|████████▊ | 9185/10395 [26:16:04<3:38:10, 10.82s/it] 88%|████████▊ | 9186/10395 [26:16:12<3:17:52,  9.82s/it]                                                         {'loss': 0.9077, 'learning_rate': 7.011344586771073e-07, 'epoch': 0.88}
 88%|████████▊ | 9186/10395 [26:16:12<3:17:52,  9.82s/it] 88%|████████▊ | 9187/10395 [26:16:19<3:02:33,  9.07s/it]                                                         {'loss': 0.8723, 'learning_rate': 6.999887991295506e-07, 'epoch': 0.88}
 88%|████████▊ | 9187/10395 [26:16:19<3:02:33,  9.07s/it] 88%|████████▊ | 9188/10395 [26:16:26<2:52:36,  8.58s/it]                                                         {'loss': 0.9596, 'learning_rate': 6.988440424072063e-07, 'epoch': 0.88}
 88%|████████▊ | 9188/10395 [26:16:26<2:52:36,  8.58s/it] 88%|████████▊ | 9189/10395 [26:16:34<2:44:25,  8.18s/it]                                                         {'loss': 0.9268, 'learning_rate': 6.977001886212043e-07, 'epoch': 0.88}
 88%|████████▊ | 9189/10395 [26:16:34<2:44:25,  8.18s/it] 88%|████████▊ | 9190/10395 [26:16:41<2:42:32,  8.09s/it]                                                         {'loss': 0.8615, 'learning_rate': 6.965572378825891e-07, 'epoch': 0.88}
 88%|████████▊ | 9190/10395 [26:16:41<2:42:32,  8.09s/it] 88%|████████▊ | 9191/10395 [26:16:49<2:40:26,  8.00s/it]                                                         {'loss': 0.8877, 'learning_rate': 6.954151903023176e-07, 'epoch': 0.88}
 88%|████████▊ | 9191/10395 [26:16:49<2:40:26,  8.00s/it] 88%|████████▊ | 9192/10395 [26:16:57<2:40:07,  7.99s/it]                                                         {'loss': 0.8489, 'learning_rate': 6.942740459912534e-07, 'epoch': 0.88}
 88%|████████▊ | 9192/10395 [26:16:57<2:40:07,  7.99s/it] 88%|████████▊ | 9193/10395 [26:17:05<2:38:56,  7.93s/it]                                                         {'loss': 0.8423, 'learning_rate': 6.931338050601799e-07, 'epoch': 0.88}
 88%|████████▊ | 9193/10395 [26:17:05<2:38:56,  7.93s/it] 88%|████████▊ | 9194/10395 [26:17:13<2:36:58,  7.84s/it]                                                         {'loss': 0.8085, 'learning_rate': 6.919944676197876e-07, 'epoch': 0.88}
 88%|████████▊ | 9194/10395 [26:17:13<2:36:58,  7.84s/it] 88%|████████▊ | 9195/10395 [26:17:20<2:35:25,  7.77s/it]                                                         {'loss': 0.8849, 'learning_rate': 6.908560337806802e-07, 'epoch': 0.88}
 88%|████████▊ | 9195/10395 [26:17:20<2:35:25,  7.77s/it] 88%|████████▊ | 9196/10395 [26:17:28<2:33:21,  7.67s/it]                                                         {'loss': 0.8994, 'learning_rate': 6.89718503653376e-07, 'epoch': 0.88}
 88%|████████▊ | 9196/10395 [26:17:28<2:33:21,  7.67s/it] 88%|████████▊ | 9197/10395 [26:17:36<2:34:37,  7.74s/it]                                                         {'loss': 0.7849, 'learning_rate': 6.885818773483033e-07, 'epoch': 0.88}
 88%|████████▊ | 9197/10395 [26:17:36<2:34:37,  7.74s/it] 88%|████████▊ | 9198/10395 [26:17:45<2:45:00,  8.27s/it]                                                         {'loss': 0.8173, 'learning_rate': 6.874461549758015e-07, 'epoch': 0.88}
 88%|████████▊ | 9198/10395 [26:17:45<2:45:00,  8.27s/it] 88%|████████▊ | 9199/10395 [26:17:54<2:45:53,  8.32s/it]                                                         {'loss': 0.9016, 'learning_rate': 6.863113366461294e-07, 'epoch': 0.88}
 88%|████████▊ | 9199/10395 [26:17:54<2:45:53,  8.32s/it] 89%|████████▊ | 9200/10395 [26:18:02<2:48:40,  8.47s/it]                                                         {'loss': 0.8176, 'learning_rate': 6.851774224694463e-07, 'epoch': 0.88}
 89%|████████▊ | 9200/10395 [26:18:02<2:48:40,  8.47s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 9201/10395 [26:19:44<12:05:53, 36.48s/it]                                                          {'loss': 0.8152, 'learning_rate': 6.840444125558354e-07, 'epoch': 0.89}
 89%|████████▊ | 9201/10395 [26:19:44<12:05:53, 36.48s/it] 89%|████████▊ | 9202/10395 [26:19:52<9:12:54, 27.81s/it]                                                          {'loss': 0.8586, 'learning_rate': 6.829123070152843e-07, 'epoch': 0.89}
 89%|████████▊ | 9202/10395 [26:19:52<9:12:54, 27.81s/it] 89%|████████▊ | 9203/10395 [26:20:00<7:14:10, 21.85s/it]                                                         {'loss': 0.8485, 'learning_rate': 6.817811059576939e-07, 'epoch': 0.89}
 89%|████████▊ | 9203/10395 [26:20:00<7:14:10, 21.85s/it] 89%|████████▊ | 9204/10395 [26:20:07<5:48:49, 17.57s/it]                                                         {'loss': 0.9169, 'learning_rate': 6.806508094928833e-07, 'epoch': 0.89}
 89%|████████▊ | 9204/10395 [26:20:07<5:48:49, 17.57s/it] 89%|████████▊ | 9205/10395 [26:20:15<4:47:11, 14.48s/it]                                                         {'loss': 0.9031, 'learning_rate': 6.795214177305743e-07, 'epoch': 0.89}
 89%|████████▊ | 9205/10395 [26:20:15<4:47:11, 14.48s/it] 89%|████████▊ | 9206/10395 [26:20:24<4:14:03, 12.82s/it]                                                         {'loss': 0.9323, 'learning_rate': 6.783929307804082e-07, 'epoch': 0.89}
 89%|████████▊ | 9206/10395 [26:20:24<4:14:03, 12.82s/it] 89%|████████▊ | 9207/10395 [26:20:31<3:41:12, 11.17s/it]                                                         {'loss': 0.8528, 'learning_rate': 6.772653487519377e-07, 'epoch': 0.89}
 89%|████████▊ | 9207/10395 [26:20:31<3:41:12, 11.17s/it] 89%|████████▊ | 9208/10395 [26:20:39<3:23:41, 10.30s/it]                                                         {'loss': 0.8628, 'learning_rate': 6.761386717546226e-07, 'epoch': 0.89}
 89%|████████▊ | 9208/10395 [26:20:39<3:23:41, 10.30s/it] 89%|████████▊ | 9209/10395 [26:20:46<3:05:11,  9.37s/it]                                                         {'loss': 0.8876, 'learning_rate': 6.750128998978422e-07, 'epoch': 0.89}
 89%|████████▊ | 9209/10395 [26:20:46<3:05:11,  9.37s/it] 89%|████████▊ | 9210/10395 [26:20:54<2:53:27,  8.78s/it]                                                         {'loss': 0.8272, 'learning_rate': 6.738880332908815e-07, 'epoch': 0.89}
 89%|████████▊ | 9210/10395 [26:20:54<2:53:27,  8.78s/it] 89%|████████▊ | 9211/10395 [26:21:02<2:47:47,  8.50s/it]                                                         {'loss': 0.8407, 'learning_rate': 6.727640720429395e-07, 'epoch': 0.89}
 89%|████████▊ | 9211/10395 [26:21:02<2:47:47,  8.50s/it] 89%|████████▊ | 9212/10395 [26:21:10<2:45:52,  8.41s/it]                                                         {'loss': 0.7921, 'learning_rate': 6.716410162631281e-07, 'epoch': 0.89}
 89%|████████▊ | 9212/10395 [26:21:10<2:45:52,  8.41s/it] 89%|████████▊ | 9213/10395 [26:21:18<2:42:10,  8.23s/it]                                                         {'loss': 0.9446, 'learning_rate': 6.705188660604745e-07, 'epoch': 0.89}
 89%|████████▊ | 9213/10395 [26:21:18<2:42:10,  8.23s/it] 89%|████████▊ | 9214/10395 [26:21:25<2:37:45,  8.01s/it]                                                         {'loss': 0.8388, 'learning_rate': 6.693976215439102e-07, 'epoch': 0.89}
 89%|████████▊ | 9214/10395 [26:21:25<2:37:45,  8.01s/it] 89%|████████▊ | 9215/10395 [26:21:33<2:35:06,  7.89s/it]                                                         {'loss': 0.8581, 'learning_rate': 6.682772828222872e-07, 'epoch': 0.89}
 89%|████████▊ | 9215/10395 [26:21:33<2:35:06,  7.89s/it] 89%|████████▊ | 9216/10395 [26:21:41<2:35:19,  7.90s/it]                                                         {'loss': 0.8482, 'learning_rate': 6.67157850004363e-07, 'epoch': 0.89}
 89%|████████▊ | 9216/10395 [26:21:41<2:35:19,  7.90s/it] 89%|████████▊ | 9217/10395 [26:21:49<2:36:11,  7.96s/it]                                                         {'loss': 0.8508, 'learning_rate': 6.660393231988094e-07, 'epoch': 0.89}
 89%|████████▊ | 9217/10395 [26:21:49<2:36:11,  7.96s/it] 89%|████████▊ | 9218/10395 [26:21:56<2:34:05,  7.86s/it]                                                         {'loss': 0.8427, 'learning_rate': 6.64921702514213e-07, 'epoch': 0.89}
 89%|████████▊ | 9218/10395 [26:21:56<2:34:05,  7.86s/it] 89%|████████▊ | 9219/10395 [26:22:04<2:30:30,  7.68s/it]                                                         {'loss': 0.8747, 'learning_rate': 6.638049880590658e-07, 'epoch': 0.89}
 89%|████████▊ | 9219/10395 [26:22:04<2:30:30,  7.68s/it] 89%|████████▊ | 9220/10395 [26:22:21<3:28:30, 10.65s/it]                                                         {'loss': 0.3668, 'learning_rate': 6.626891799417801e-07, 'epoch': 0.89}
 89%|████████▊ | 9220/10395 [26:22:21<3:28:30, 10.65s/it] 89%|████████▊ | 9221/10395 [26:22:30<3:15:38, 10.00s/it]                                                         {'loss': 0.8049, 'learning_rate': 6.615742782706769e-07, 'epoch': 0.89}
 89%|████████▊ | 9221/10395 [26:22:30<3:15:38, 10.00s/it] 89%|████████▊ | 9222/10395 [26:22:37<2:59:11,  9.17s/it]                                                         {'loss': 0.828, 'learning_rate': 6.604602831539841e-07, 'epoch': 0.89}
 89%|████████▊ | 9222/10395 [26:22:37<2:59:11,  9.17s/it] 89%|████████▊ | 9223/10395 [26:22:46<2:57:17,  9.08s/it]                                                         {'loss': 0.7843, 'learning_rate': 6.593471946998497e-07, 'epoch': 0.89}
 89%|████████▊ | 9223/10395 [26:22:46<2:57:17,  9.08s/it] 89%|████████▊ | 9224/10395 [26:22:53<2:48:19,  8.62s/it]                                                         {'loss': 0.8909, 'learning_rate': 6.582350130163295e-07, 'epoch': 0.89}
 89%|████████▊ | 9224/10395 [26:22:53<2:48:19,  8.62s/it] 89%|████████▊ | 9225/10395 [26:23:02<2:47:14,  8.58s/it]                                                         {'loss': 0.8232, 'learning_rate': 6.571237382113882e-07, 'epoch': 0.89}
 89%|████████▊ | 9225/10395 [26:23:02<2:47:14,  8.58s/it] 89%|████████▉ | 9226/10395 [26:23:10<2:43:15,  8.38s/it]                                                         {'loss': 0.8859, 'learning_rate': 6.560133703929106e-07, 'epoch': 0.89}
 89%|████████▉ | 9226/10395 [26:23:10<2:43:15,  8.38s/it] 89%|████████▉ | 9227/10395 [26:23:27<3:34:06, 11.00s/it]                                                         {'loss': 0.3417, 'learning_rate': 6.54903909668686e-07, 'epoch': 0.89}
 89%|████████▉ | 9227/10395 [26:23:27<3:34:06, 11.00s/it] 89%|████████▉ | 9228/10395 [26:23:34<3:09:49,  9.76s/it]                                                         {'loss': 0.8943, 'learning_rate': 6.537953561464183e-07, 'epoch': 0.89}
 89%|████████▉ | 9228/10395 [26:23:34<3:09:49,  9.76s/it] 89%|████████▉ | 9229/10395 [26:23:41<2:57:36,  9.14s/it]                                                         {'loss': 0.8743, 'learning_rate': 6.52687709933727e-07, 'epoch': 0.89}
 89%|████████▉ | 9229/10395 [26:23:41<2:57:36,  9.14s/it] 89%|████████▉ | 9230/10395 [26:23:49<2:51:01,  8.81s/it]                                                         {'loss': 0.8221, 'learning_rate': 6.515809711381349e-07, 'epoch': 0.89}
 89%|████████▉ | 9230/10395 [26:23:49<2:51:01,  8.81s/it] 89%|████████▉ | 9231/10395 [26:23:57<2:45:11,  8.52s/it]                                                         {'loss': 0.9038, 'learning_rate': 6.504751398670872e-07, 'epoch': 0.89}
 89%|████████▉ | 9231/10395 [26:23:57<2:45:11,  8.52s/it] 89%|████████▉ | 9232/10395 [26:24:06<2:49:00,  8.72s/it]                                                         {'loss': 0.8674, 'learning_rate': 6.493702162279325e-07, 'epoch': 0.89}
 89%|████████▉ | 9232/10395 [26:24:06<2:49:00,  8.72s/it] 89%|████████▉ | 9233/10395 [26:24:15<2:45:20,  8.54s/it]                                                         {'loss': 0.8541, 'learning_rate': 6.482662003279327e-07, 'epoch': 0.89}
 89%|████████▉ | 9233/10395 [26:24:15<2:45:20,  8.54s/it] 89%|████████▉ | 9234/10395 [26:24:22<2:40:20,  8.29s/it]                                                         {'loss': 0.88, 'learning_rate': 6.471630922742678e-07, 'epoch': 0.89}
 89%|████████▉ | 9234/10395 [26:24:22<2:40:20,  8.29s/it] 89%|████████▉ | 9235/10395 [26:24:30<2:37:07,  8.13s/it]                                                         {'loss': 0.8298, 'learning_rate': 6.460608921740208e-07, 'epoch': 0.89}
 89%|████████▉ | 9235/10395 [26:24:30<2:37:07,  8.13s/it] 89%|████████▉ | 9236/10395 [26:24:48<3:36:20, 11.20s/it]                                                         {'loss': 0.3954, 'learning_rate': 6.449596001341929e-07, 'epoch': 0.89}
 89%|████████▉ | 9236/10395 [26:24:48<3:36:20, 11.20s/it] 89%|████████▉ | 9237/10395 [26:24:56<3:14:00, 10.05s/it]                                                         {'loss': 0.8435, 'learning_rate': 6.438592162616963e-07, 'epoch': 0.89}
 89%|████████▉ | 9237/10395 [26:24:56<3:14:00, 10.05s/it] 89%|████████▉ | 9238/10395 [26:25:03<2:59:01,  9.28s/it]                                                         {'loss': 0.752, 'learning_rate': 6.427597406633534e-07, 'epoch': 0.89}
 89%|████████▉ | 9238/10395 [26:25:03<2:59:01,  9.28s/it] 89%|████████▉ | 9239/10395 [26:25:11<2:52:31,  8.95s/it]                                                         {'loss': 0.7781, 'learning_rate': 6.416611734458977e-07, 'epoch': 0.89}
 89%|████████▉ | 9239/10395 [26:25:11<2:52:31,  8.95s/it] 89%|████████▉ | 9240/10395 [26:25:19<2:42:58,  8.47s/it]                                                         {'loss': 0.8816, 'learning_rate': 6.405635147159772e-07, 'epoch': 0.89}
 89%|████████▉ | 9240/10395 [26:25:19<2:42:58,  8.47s/it] 89%|████████▉ | 9241/10395 [26:25:26<2:38:18,  8.23s/it]                                                         {'loss': 0.8706, 'learning_rate': 6.394667645801478e-07, 'epoch': 0.89}
 89%|████████▉ | 9241/10395 [26:25:26<2:38:18,  8.23s/it] 89%|████████▉ | 9242/10395 [26:25:34<2:35:03,  8.07s/it]                                                         {'loss': 0.7915, 'learning_rate': 6.383709231448832e-07, 'epoch': 0.89}
 89%|████████▉ | 9242/10395 [26:25:34<2:35:03,  8.07s/it] 89%|████████▉ | 9243/10395 [26:25:51<3:28:21, 10.85s/it]                                                         {'loss': 0.318, 'learning_rate': 6.372759905165615e-07, 'epoch': 0.89}
 89%|████████▉ | 9243/10395 [26:25:51<3:28:21, 10.85s/it] 89%|████████▉ | 9244/10395 [26:25:59<3:09:06,  9.86s/it]                                                         {'loss': 0.8626, 'learning_rate': 6.36181966801479e-07, 'epoch': 0.89}
 89%|████████▉ | 9244/10395 [26:25:59<3:09:06,  9.86s/it] 89%|████████▉ | 9245/10395 [26:26:07<2:57:25,  9.26s/it]                                                         {'loss': 0.8885, 'learning_rate': 6.350888521058429e-07, 'epoch': 0.89}
 89%|████████▉ | 9245/10395 [26:26:07<2:57:25,  9.26s/it] 89%|████████▉ | 9246/10395 [26:26:16<2:56:53,  9.24s/it]                                                         {'loss': 0.84, 'learning_rate': 6.339966465357661e-07, 'epoch': 0.89}
 89%|████████▉ | 9246/10395 [26:26:16<2:56:53,  9.24s/it] 89%|████████▉ | 9247/10395 [26:26:24<2:47:36,  8.76s/it]                                                         {'loss': 0.8893, 'learning_rate': 6.329053501972793e-07, 'epoch': 0.89}
 89%|████████▉ | 9247/10395 [26:26:24<2:47:36,  8.76s/it] 89%|████████▉ | 9248/10395 [26:26:32<2:42:32,  8.50s/it]                                                         {'loss': 0.8172, 'learning_rate': 6.318149631963244e-07, 'epoch': 0.89}
 89%|████████▉ | 9248/10395 [26:26:32<2:42:32,  8.50s/it] 89%|████████▉ | 9249/10395 [26:26:39<2:37:59,  8.27s/it]                                                         {'loss': 0.7801, 'learning_rate': 6.307254856387524e-07, 'epoch': 0.89}
 89%|████████▉ | 9249/10395 [26:26:39<2:37:59,  8.27s/it] 89%|████████▉ | 9250/10395 [26:26:47<2:32:43,  8.00s/it]                                                         {'loss': 0.8706, 'learning_rate': 6.296369176303297e-07, 'epoch': 0.89}
 89%|████████▉ | 9250/10395 [26:26:47<2:32:43,  8.00s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▉ | 9251/10395 [26:28:31<11:43:48, 36.91s/it]                                                          {'loss': 0.825, 'learning_rate': 6.285492592767284e-07, 'epoch': 0.89}
 89%|████████▉ | 9251/10395 [26:28:31<11:43:48, 36.91s/it] 89%|████████▉ | 9252/10395 [26:28:38<8:53:11, 27.99s/it]                                                          {'loss': 0.9379, 'learning_rate': 6.274625106835375e-07, 'epoch': 0.89}
 89%|████████▉ | 9252/10395 [26:28:38<8:53:11, 27.99s/it] 89%|████████▉ | 9253/10395 [26:28:47<7:02:57, 22.22s/it]                                                         {'loss': 0.8313, 'learning_rate': 6.263766719562614e-07, 'epoch': 0.89}
 89%|████████▉ | 9253/10395 [26:28:47<7:02:57, 22.22s/it] 89%|████████▉ | 9254/10395 [26:28:55<5:42:25, 18.01s/it]                                                         {'loss': 0.8636, 'learning_rate': 6.252917432003025e-07, 'epoch': 0.89}
 89%|████████▉ | 9254/10395 [26:28:55<5:42:25, 18.01s/it] 89%|████████▉ | 9255/10395 [26:29:03<4:42:28, 14.87s/it]                                                         {'loss': 0.8648, 'learning_rate': 6.242077245209877e-07, 'epoch': 0.89}
 89%|████████▉ | 9255/10395 [26:29:03<4:42:28, 14.87s/it] 89%|████████▉ | 9256/10395 [26:29:11<4:06:58, 13.01s/it]                                                         {'loss': 0.8273, 'learning_rate': 6.231246160235516e-07, 'epoch': 0.89}
 89%|████████▉ | 9256/10395 [26:29:11<4:06:58, 13.01s/it] 89%|████████▉ | 9257/10395 [26:29:19<3:38:40, 11.53s/it]                                                         {'loss': 0.8521, 'learning_rate': 6.22042417813139e-07, 'epoch': 0.89}
 89%|████████▉ | 9257/10395 [26:29:19<3:38:40, 11.53s/it] 89%|████████▉ | 9258/10395 [26:29:27<3:14:36, 10.27s/it]                                                         {'loss': 0.8255, 'learning_rate': 6.209611299948082e-07, 'epoch': 0.89}
 89%|████████▉ | 9258/10395 [26:29:27<3:14:36, 10.27s/it] 89%|████████▉ | 9259/10395 [26:29:35<3:03:33,  9.70s/it]                                                         {'loss': 0.8376, 'learning_rate': 6.198807526735273e-07, 'epoch': 0.89}
 89%|████████▉ | 9259/10395 [26:29:35<3:03:33,  9.70s/it] 89%|████████▉ | 9260/10395 [26:29:43<2:51:48,  9.08s/it]                                                         {'loss': 0.7853, 'learning_rate': 6.188012859541781e-07, 'epoch': 0.89}
 89%|████████▉ | 9260/10395 [26:29:43<2:51:48,  9.08s/it] 89%|████████▉ | 9261/10395 [26:29:50<2:42:57,  8.62s/it]                                                         {'loss': 0.8574, 'learning_rate': 6.177227299415534e-07, 'epoch': 0.89}
 89%|████████▉ | 9261/10395 [26:29:50<2:42:57,  8.62s/it] 89%|████████▉ | 9262/10395 [26:29:58<2:37:18,  8.33s/it]                                                         {'loss': 0.8592, 'learning_rate': 6.166450847403538e-07, 'epoch': 0.89}
 89%|████████▉ | 9262/10395 [26:29:58<2:37:18,  8.33s/it] 89%|████████▉ | 9263/10395 [26:30:06<2:33:15,  8.12s/it]                                                         {'loss': 0.7856, 'learning_rate': 6.155683504551968e-07, 'epoch': 0.89}
 89%|████████▉ | 9263/10395 [26:30:06<2:33:15,  8.12s/it] 89%|████████▉ | 9264/10395 [26:30:15<2:37:58,  8.38s/it]                                                         {'loss': 0.8208, 'learning_rate': 6.144925271906122e-07, 'epoch': 0.89}
 89%|████████▉ | 9264/10395 [26:30:15<2:37:58,  8.38s/it] 89%|████████▉ | 9265/10395 [26:30:22<2:31:17,  8.03s/it]                                                         {'loss': 0.907, 'learning_rate': 6.13417615051034e-07, 'epoch': 0.89}
 89%|████████▉ | 9265/10395 [26:30:22<2:31:17,  8.03s/it] 89%|████████▉ | 9266/10395 [26:30:30<2:33:48,  8.17s/it]                                                         {'loss': 0.8327, 'learning_rate': 6.123436141408168e-07, 'epoch': 0.89}
 89%|████████▉ | 9266/10395 [26:30:30<2:33:48,  8.17s/it] 89%|████████▉ | 9267/10395 [26:30:39<2:34:20,  8.21s/it]                                                         {'loss': 0.8747, 'learning_rate': 6.112705245642192e-07, 'epoch': 0.89}
 89%|████████▉ | 9267/10395 [26:30:39<2:34:20,  8.21s/it] 89%|████████▉ | 9268/10395 [26:30:46<2:28:12,  7.89s/it]                                                         {'loss': 0.8045, 'learning_rate': 6.101983464254135e-07, 'epoch': 0.89}
 89%|████████▉ | 9268/10395 [26:30:46<2:28:12,  7.89s/it] 89%|████████▉ | 9269/10395 [26:30:53<2:25:43,  7.77s/it]                                                         {'loss': 0.9421, 'learning_rate': 6.091270798284887e-07, 'epoch': 0.89}
 89%|████████▉ | 9269/10395 [26:30:53<2:25:43,  7.77s/it] 89%|████████▉ | 9270/10395 [26:31:01<2:24:38,  7.71s/it]                                                         {'loss': 0.8517, 'learning_rate': 6.080567248774372e-07, 'epoch': 0.89}
 89%|████████▉ | 9270/10395 [26:31:01<2:24:38,  7.71s/it] 89%|████████▉ | 9271/10395 [26:31:12<2:41:07,  8.60s/it]                                                         {'loss': 0.871, 'learning_rate': 6.06987281676168e-07, 'epoch': 0.89}
 89%|████████▉ | 9271/10395 [26:31:12<2:41:07,  8.60s/it] 89%|████████▉ | 9272/10395 [26:31:20<2:37:46,  8.43s/it]                                                         {'loss': 0.9344, 'learning_rate': 6.059187503285013e-07, 'epoch': 0.89}
 89%|████████▉ | 9272/10395 [26:31:20<2:37:46,  8.43s/it] 89%|████████▉ | 9273/10395 [26:31:27<2:29:33,  8.00s/it]                                                         {'loss': 0.8339, 'learning_rate': 6.048511309381666e-07, 'epoch': 0.89}
 89%|████████▉ | 9273/10395 [26:31:27<2:29:33,  8.00s/it] 89%|████████▉ | 9274/10395 [26:31:35<2:30:30,  8.06s/it]                                                         {'loss': 0.8841, 'learning_rate': 6.037844236088076e-07, 'epoch': 0.89}
 89%|████████▉ | 9274/10395 [26:31:35<2:30:30,  8.06s/it] 89%|████████▉ | 9275/10395 [26:31:43<2:32:33,  8.17s/it]                                                         {'loss': 0.8781, 'learning_rate': 6.027186284439768e-07, 'epoch': 0.89}
 89%|████████▉ | 9275/10395 [26:31:43<2:32:33,  8.17s/it] 89%|████████▉ | 9276/10395 [26:32:00<3:18:41, 10.65s/it]                                                         {'loss': 0.3363, 'learning_rate': 6.016537455471383e-07, 'epoch': 0.89}
 89%|████████▉ | 9276/10395 [26:32:00<3:18:41, 10.65s/it] 89%|████████▉ | 9277/10395 [26:32:09<3:08:41, 10.13s/it]                                                         {'loss': 0.8871, 'learning_rate': 6.005897750216705e-07, 'epoch': 0.89}
 89%|████████▉ | 9277/10395 [26:32:09<3:08:41, 10.13s/it] 89%|████████▉ | 9278/10395 [26:32:16<2:56:18,  9.47s/it]                                                         {'loss': 0.8095, 'learning_rate': 5.995267169708608e-07, 'epoch': 0.89}
 89%|████████▉ | 9278/10395 [26:32:16<2:56:18,  9.47s/it] 89%|████████▉ | 9279/10395 [26:32:34<3:39:19, 11.79s/it]                                                         {'loss': 0.4186, 'learning_rate': 5.984645714979076e-07, 'epoch': 0.89}
 89%|████████▉ | 9279/10395 [26:32:34<3:39:19, 11.79s/it] 89%|████████▉ | 9280/10395 [26:32:42<3:18:03, 10.66s/it]                                                         {'loss': 0.8871, 'learning_rate': 5.974033387059242e-07, 'epoch': 0.89}
 89%|████████▉ | 9280/10395 [26:32:42<3:18:03, 10.66s/it] 89%|████████▉ | 9281/10395 [26:32:50<3:02:30,  9.83s/it]                                                         {'loss': 0.883, 'learning_rate': 5.963430186979291e-07, 'epoch': 0.89}
 89%|████████▉ | 9281/10395 [26:32:50<3:02:30,  9.83s/it] 89%|████████▉ | 9282/10395 [26:32:57<2:49:13,  9.12s/it]                                                         {'loss': 0.8382, 'learning_rate': 5.952836115768612e-07, 'epoch': 0.89}
 89%|████████▉ | 9282/10395 [26:32:57<2:49:13,  9.12s/it] 89%|████████▉ | 9283/10395 [26:33:05<2:45:01,  8.90s/it]                                                         {'loss': 0.8189, 'learning_rate': 5.942251174455604e-07, 'epoch': 0.89}
 89%|████████▉ | 9283/10395 [26:33:05<2:45:01,  8.90s/it] 89%|████████▉ | 9284/10395 [26:33:13<2:36:38,  8.46s/it]                                                         {'loss': 0.8745, 'learning_rate': 5.931675364067846e-07, 'epoch': 0.89}
 89%|████████▉ | 9284/10395 [26:33:13<2:36:38,  8.46s/it] 89%|████████▉ | 9285/10395 [26:33:22<2:37:42,  8.52s/it]                                                         {'loss': 0.813, 'learning_rate': 5.921108685632026e-07, 'epoch': 0.89}
 89%|████████▉ | 9285/10395 [26:33:22<2:37:42,  8.52s/it] 89%|████████▉ | 9286/10395 [26:33:29<2:33:41,  8.31s/it]                                                         {'loss': 0.8279, 'learning_rate': 5.910551140173926e-07, 'epoch': 0.89}
 89%|████████▉ | 9286/10395 [26:33:29<2:33:41,  8.31s/it] 89%|████████▉ | 9287/10395 [26:33:36<2:26:14,  7.92s/it]                                                         {'loss': 0.9314, 'learning_rate': 5.900002728718446e-07, 'epoch': 0.89}
 89%|████████▉ | 9287/10395 [26:33:36<2:26:14,  7.92s/it] 89%|████████▉ | 9288/10395 [26:33:44<2:22:31,  7.72s/it]                                                         {'loss': 0.8228, 'learning_rate': 5.889463452289623e-07, 'epoch': 0.89}
 89%|████████▉ | 9288/10395 [26:33:44<2:22:31,  7.72s/it] 89%|████████▉ | 9289/10395 [26:33:51<2:22:21,  7.72s/it]                                                         {'loss': 0.8906, 'learning_rate': 5.878933311910572e-07, 'epoch': 0.89}
 89%|████████▉ | 9289/10395 [26:33:51<2:22:21,  7.72s/it] 89%|████████▉ | 9290/10395 [26:33:59<2:21:35,  7.69s/it]                                                         {'loss': 0.9423, 'learning_rate': 5.868412308603533e-07, 'epoch': 0.89}
 89%|████████▉ | 9290/10395 [26:33:59<2:21:35,  7.69s/it] 89%|████████▉ | 9291/10395 [26:34:07<2:24:24,  7.85s/it]                                                         {'loss': 0.8303, 'learning_rate': 5.857900443389864e-07, 'epoch': 0.89}
 89%|████████▉ | 9291/10395 [26:34:07<2:24:24,  7.85s/it] 89%|████████▉ | 9292/10395 [26:34:16<2:27:31,  8.03s/it]                                                         {'loss': 0.8658, 'learning_rate': 5.847397717290037e-07, 'epoch': 0.89}
 89%|████████▉ | 9292/10395 [26:34:16<2:27:31,  8.03s/it] 89%|████████▉ | 9293/10395 [26:34:23<2:23:07,  7.79s/it]                                                         {'loss': 0.8699, 'learning_rate': 5.836904131323628e-07, 'epoch': 0.89}
 89%|████████▉ | 9293/10395 [26:34:23<2:23:07,  7.79s/it] 89%|████████▉ | 9294/10395 [26:34:31<2:26:41,  7.99s/it]                                                         {'loss': 0.8024, 'learning_rate': 5.826419686509354e-07, 'epoch': 0.89}
 89%|████████▉ | 9294/10395 [26:34:31<2:26:41,  7.99s/it] 89%|████████▉ | 9295/10395 [26:34:39<2:23:43,  7.84s/it]                                                         {'loss': 0.8248, 'learning_rate': 5.815944383864991e-07, 'epoch': 0.89}
 89%|████████▉ | 9295/10395 [26:34:39<2:23:43,  7.84s/it] 89%|████████▉ | 9296/10395 [26:34:46<2:21:42,  7.74s/it]                                                         {'loss': 0.8535, 'learning_rate': 5.805478224407501e-07, 'epoch': 0.89}
 89%|████████▉ | 9296/10395 [26:34:46<2:21:42,  7.74s/it] 89%|████████▉ | 9297/10395 [26:34:54<2:23:22,  7.83s/it]                                                         {'loss': 0.8669, 'learning_rate': 5.795021209152874e-07, 'epoch': 0.89}
 89%|████████▉ | 9297/10395 [26:34:54<2:23:22,  7.83s/it] 89%|████████▉ | 9298/10395 [26:35:02<2:21:04,  7.72s/it]                                                         {'loss': 0.9346, 'learning_rate': 5.784573339116273e-07, 'epoch': 0.89}
 89%|████████▉ | 9298/10395 [26:35:02<2:21:04,  7.72s/it] 89%|████████▉ | 9299/10395 [26:35:10<2:23:01,  7.83s/it]                                                         {'loss': 0.8745, 'learning_rate': 5.774134615311955e-07, 'epoch': 0.89}
 89%|████████▉ | 9299/10395 [26:35:10<2:23:01,  7.83s/it] 89%|████████▉ | 9300/10395 [26:35:18<2:25:31,  7.97s/it]                                                         {'loss': 0.8833, 'learning_rate': 5.763705038753276e-07, 'epoch': 0.89}
 89%|████████▉ | 9300/10395 [26:35:18<2:25:31,  7.97s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▉ | 9301/10395 [26:37:03<11:16:42, 37.11s/it]                                                          {'loss': 0.7614, 'learning_rate': 5.753284610452725e-07, 'epoch': 0.89}
 89%|████████▉ | 9301/10395 [26:37:03<11:16:42, 37.11s/it] 89%|████████▉ | 9302/10395 [26:37:10<8:31:27, 28.08s/it]                                                          {'loss': 0.8726, 'learning_rate': 5.742873331421917e-07, 'epoch': 0.89}
 89%|████████▉ | 9302/10395 [26:37:10<8:31:27, 28.08s/it] 89%|████████▉ | 9303/10395 [26:37:18<6:37:38, 21.85s/it]                                                         {'loss': 0.8906, 'learning_rate': 5.73247120267153e-07, 'epoch': 0.89}
 89%|████████▉ | 9303/10395 [26:37:18<6:37:38, 21.85s/it] 90%|████████▉ | 9304/10395 [26:37:25<5:18:51, 17.54s/it]                                                         {'loss': 0.8766, 'learning_rate': 5.722078225211391e-07, 'epoch': 0.9}
 90%|████████▉ | 9304/10395 [26:37:25<5:18:51, 17.54s/it] 90%|████████▉ | 9305/10395 [26:37:33<4:23:34, 14.51s/it]                                                         {'loss': 0.903, 'learning_rate': 5.711694400050427e-07, 'epoch': 0.9}
 90%|████████▉ | 9305/10395 [26:37:33<4:23:34, 14.51s/it] 90%|████████▉ | 9306/10395 [26:37:41<3:48:22, 12.58s/it]                                                         {'loss': 0.9428, 'learning_rate': 5.701319728196675e-07, 'epoch': 0.9}
 90%|████████▉ | 9306/10395 [26:37:41<3:48:22, 12.58s/it] 90%|████████▉ | 9307/10395 [26:37:48<3:20:57, 11.08s/it]                                                         {'loss': 0.8806, 'learning_rate': 5.690954210657285e-07, 'epoch': 0.9}
 90%|████████▉ | 9307/10395 [26:37:48<3:20:57, 11.08s/it] 90%|████████▉ | 9308/10395 [26:37:56<3:01:33, 10.02s/it]                                                         {'loss': 0.8607, 'learning_rate': 5.680597848438518e-07, 'epoch': 0.9}
 90%|████████▉ | 9308/10395 [26:37:56<3:01:33, 10.02s/it] 90%|████████▉ | 9309/10395 [26:38:03<2:48:25,  9.30s/it]                                                         {'loss': 0.9309, 'learning_rate': 5.670250642545739e-07, 'epoch': 0.9}
 90%|████████▉ | 9309/10395 [26:38:03<2:48:25,  9.30s/it] 90%|████████▉ | 9310/10395 [26:38:11<2:40:01,  8.85s/it]                                                         {'loss': 0.7678, 'learning_rate': 5.659912593983463e-07, 'epoch': 0.9}
 90%|████████▉ | 9310/10395 [26:38:11<2:40:01,  8.85s/it] 90%|████████▉ | 9311/10395 [26:38:19<2:34:39,  8.56s/it]                                                         {'loss': 0.8718, 'learning_rate': 5.649583703755257e-07, 'epoch': 0.9}
 90%|████████▉ | 9311/10395 [26:38:19<2:34:39,  8.56s/it] 90%|████████▉ | 9312/10395 [26:38:27<2:29:04,  8.26s/it]                                                         {'loss': 0.8337, 'learning_rate': 5.639263972863851e-07, 'epoch': 0.9}
 90%|████████▉ | 9312/10395 [26:38:27<2:29:04,  8.26s/it] 90%|████████▉ | 9313/10395 [26:38:34<2:24:47,  8.03s/it]                                                         {'loss': 0.8189, 'learning_rate': 5.628953402311043e-07, 'epoch': 0.9}
 90%|████████▉ | 9313/10395 [26:38:34<2:24:47,  8.03s/it] 90%|████████▉ | 9314/10395 [26:38:42<2:23:42,  7.98s/it]                                                         {'loss': 0.8299, 'learning_rate': 5.618651993097757e-07, 'epoch': 0.9}
 90%|████████▉ | 9314/10395 [26:38:42<2:23:42,  7.98s/it] 90%|████████▉ | 9315/10395 [26:38:50<2:21:37,  7.87s/it]                                                         {'loss': 0.8536, 'learning_rate': 5.608359746224057e-07, 'epoch': 0.9}
 90%|████████▉ | 9315/10395 [26:38:50<2:21:37,  7.87s/it] 90%|████████▉ | 9316/10395 [26:38:58<2:23:09,  7.96s/it]                                                         {'loss': 0.8283, 'learning_rate': 5.598076662689067e-07, 'epoch': 0.9}
 90%|████████▉ | 9316/10395 [26:38:58<2:23:09,  7.96s/it] 90%|████████▉ | 9317/10395 [26:39:06<2:24:26,  8.04s/it]                                                         {'loss': 0.8959, 'learning_rate': 5.587802743491044e-07, 'epoch': 0.9}
 90%|████████▉ | 9317/10395 [26:39:06<2:24:26,  8.04s/it] 90%|████████▉ | 9318/10395 [26:39:13<2:18:47,  7.73s/it]                                                         {'loss': 1.024, 'learning_rate': 5.577537989627402e-07, 'epoch': 0.9}
 90%|████████▉ | 9318/10395 [26:39:13<2:18:47,  7.73s/it] 90%|████████▉ | 9319/10395 [26:39:21<2:22:25,  7.94s/it]                                                         {'loss': 0.7834, 'learning_rate': 5.567282402094575e-07, 'epoch': 0.9}
 90%|████████▉ | 9319/10395 [26:39:21<2:22:25,  7.94s/it] 90%|████████▉ | 9320/10395 [26:39:29<2:21:13,  7.88s/it]                                                         {'loss': 0.8285, 'learning_rate': 5.55703598188817e-07, 'epoch': 0.9}
 90%|████████▉ | 9320/10395 [26:39:29<2:21:13,  7.88s/it] 90%|████████▉ | 9321/10395 [26:39:46<3:10:40, 10.65s/it]                                                         {'loss': 0.339, 'learning_rate': 5.54679873000289e-07, 'epoch': 0.9}
 90%|████████▉ | 9321/10395 [26:39:46<3:10:40, 10.65s/it] 90%|████████▉ | 9322/10395 [26:39:54<2:55:24,  9.81s/it]                                                         {'loss': 0.8901, 'learning_rate': 5.536570647432527e-07, 'epoch': 0.9}
 90%|████████▉ | 9322/10395 [26:39:54<2:55:24,  9.81s/it] 90%|████████▉ | 9323/10395 [26:40:02<2:43:44,  9.16s/it]                                                         {'loss': 0.8151, 'learning_rate': 5.526351735170032e-07, 'epoch': 0.9}
 90%|████████▉ | 9323/10395 [26:40:02<2:43:44,  9.16s/it] 90%|████████▉ | 9324/10395 [26:40:10<2:36:06,  8.75s/it]                                                         {'loss': 0.9011, 'learning_rate': 5.516141994207414e-07, 'epoch': 0.9}
 90%|████████▉ | 9324/10395 [26:40:10<2:36:06,  8.75s/it] 90%|████████▉ | 9325/10395 [26:40:17<2:27:40,  8.28s/it]                                                         {'loss': 0.8768, 'learning_rate': 5.50594142553581e-07, 'epoch': 0.9}
 90%|████████▉ | 9325/10395 [26:40:17<2:27:40,  8.28s/it] 90%|████████▉ | 9326/10395 [26:40:24<2:21:02,  7.92s/it]                                                         {'loss': 0.842, 'learning_rate': 5.495750030145508e-07, 'epoch': 0.9}
 90%|████████▉ | 9326/10395 [26:40:24<2:21:02,  7.92s/it] 90%|████████▉ | 9327/10395 [26:40:31<2:18:29,  7.78s/it]                                                         {'loss': 0.8763, 'learning_rate': 5.485567809025805e-07, 'epoch': 0.9}
 90%|████████▉ | 9327/10395 [26:40:31<2:18:29,  7.78s/it] 90%|████████▉ | 9328/10395 [26:40:39<2:17:47,  7.75s/it]                                                         {'loss': 0.7403, 'learning_rate': 5.47539476316521e-07, 'epoch': 0.9}
 90%|████████▉ | 9328/10395 [26:40:39<2:17:47,  7.75s/it] 90%|████████▉ | 9329/10395 [26:40:46<2:16:22,  7.68s/it]                                                         {'loss': 0.9038, 'learning_rate': 5.465230893551299e-07, 'epoch': 0.9}
 90%|████████▉ | 9329/10395 [26:40:46<2:16:22,  7.68s/it] 90%|████████▉ | 9330/10395 [26:40:54<2:16:59,  7.72s/it]                                                         {'loss': 0.9301, 'learning_rate': 5.455076201170739e-07, 'epoch': 0.9}
 90%|████████▉ | 9330/10395 [26:40:54<2:16:59,  7.72s/it] 90%|████████▉ | 9331/10395 [26:41:02<2:14:26,  7.58s/it]                                                         {'loss': 0.9961, 'learning_rate': 5.444930687009353e-07, 'epoch': 0.9}
 90%|████████▉ | 9331/10395 [26:41:02<2:14:26,  7.58s/it] 90%|████████▉ | 9332/10395 [26:41:09<2:13:42,  7.55s/it]                                                         {'loss': 0.9133, 'learning_rate': 5.43479435205202e-07, 'epoch': 0.9}
 90%|████████▉ | 9332/10395 [26:41:09<2:13:42,  7.55s/it] 90%|████████▉ | 9333/10395 [26:41:16<2:12:57,  7.51s/it]                                                         {'loss': 0.8582, 'learning_rate': 5.424667197282751e-07, 'epoch': 0.9}
 90%|████████▉ | 9333/10395 [26:41:16<2:12:57,  7.51s/it] 90%|████████▉ | 9334/10395 [26:41:24<2:12:53,  7.52s/it]                                                         {'loss': 0.8782, 'learning_rate': 5.414549223684729e-07, 'epoch': 0.9}
 90%|████████▉ | 9334/10395 [26:41:24<2:12:53,  7.52s/it] 90%|████████▉ | 9335/10395 [26:41:32<2:17:31,  7.78s/it]                                                         {'loss': 0.7989, 'learning_rate': 5.404440432240099e-07, 'epoch': 0.9}
 90%|████████▉ | 9335/10395 [26:41:32<2:17:31,  7.78s/it] 90%|████████▉ | 9336/10395 [26:41:40<2:17:45,  7.80s/it]                                                         {'loss': 0.7548, 'learning_rate': 5.394340823930244e-07, 'epoch': 0.9}
 90%|████████▉ | 9336/10395 [26:41:40<2:17:45,  7.80s/it] 90%|████████▉ | 9337/10395 [26:41:48<2:15:36,  7.69s/it]                                                         {'loss': 0.8603, 'learning_rate': 5.384250399735624e-07, 'epoch': 0.9}
 90%|████████▉ | 9337/10395 [26:41:48<2:15:36,  7.69s/it] 90%|████████▉ | 9338/10395 [26:41:55<2:15:09,  7.67s/it]                                                         {'loss': 0.8941, 'learning_rate': 5.374169160635767e-07, 'epoch': 0.9}
 90%|████████▉ | 9338/10395 [26:41:55<2:15:09,  7.67s/it] 90%|████████▉ | 9339/10395 [26:42:03<2:15:04,  7.67s/it]                                                         {'loss': 0.8121, 'learning_rate': 5.364097107609356e-07, 'epoch': 0.9}
 90%|████████▉ | 9339/10395 [26:42:03<2:15:04,  7.67s/it] 90%|████████▉ | 9340/10395 [26:42:10<2:13:47,  7.61s/it]                                                         {'loss': 0.8333, 'learning_rate': 5.354034241634154e-07, 'epoch': 0.9}
 90%|████████▉ | 9340/10395 [26:42:10<2:13:47,  7.61s/it] 90%|████████▉ | 9341/10395 [26:42:18<2:15:08,  7.69s/it]                                                         {'loss': 0.8061, 'learning_rate': 5.343980563687068e-07, 'epoch': 0.9}
 90%|████████▉ | 9341/10395 [26:42:18<2:15:08,  7.69s/it] 90%|████████▉ | 9342/10395 [26:42:26<2:13:52,  7.63s/it]                                                         {'loss': 0.8742, 'learning_rate': 5.333936074744062e-07, 'epoch': 0.9}
 90%|████████▉ | 9342/10395 [26:42:26<2:13:52,  7.63s/it] 90%|████████▉ | 9343/10395 [26:42:43<3:03:45, 10.48s/it]                                                         {'loss': 0.3506, 'learning_rate': 5.323900775780221e-07, 'epoch': 0.9}
 90%|████████▉ | 9343/10395 [26:42:43<3:03:45, 10.48s/it] 90%|████████▉ | 9344/10395 [26:42:51<2:53:18,  9.89s/it]                                                         {'loss': 0.8932, 'learning_rate': 5.313874667769781e-07, 'epoch': 0.9}
 90%|████████▉ | 9344/10395 [26:42:51<2:53:18,  9.89s/it] 90%|████████▉ | 9345/10395 [26:42:59<2:40:59,  9.20s/it]                                                         {'loss': 0.8403, 'learning_rate': 5.303857751686048e-07, 'epoch': 0.9}
 90%|████████▉ | 9345/10395 [26:42:59<2:40:59,  9.20s/it]WARNING: tokenization mismatch: 1 vs. 789. (ignored)
 90%|████████▉ | 9346/10395 [26:43:07<2:33:45,  8.79s/it]                                                         {'loss': 0.8883, 'learning_rate': 5.293850028501424e-07, 'epoch': 0.9}
 90%|████████▉ | 9346/10395 [26:43:07<2:33:45,  8.79s/it] 90%|████████▉ | 9347/10395 [26:43:14<2:27:18,  8.43s/it]                                                         {'loss': 0.8478, 'learning_rate': 5.283851499187475e-07, 'epoch': 0.9}
 90%|████████▉ | 9347/10395 [26:43:14<2:27:18,  8.43s/it] 90%|████████▉ | 9348/10395 [26:43:23<2:28:20,  8.50s/it]                                                         {'loss': 0.9011, 'learning_rate': 5.273862164714805e-07, 'epoch': 0.9}
 90%|████████▉ | 9348/10395 [26:43:23<2:28:20,  8.50s/it] 90%|████████▉ | 9349/10395 [26:43:40<3:13:11, 11.08s/it]                                                         {'loss': 0.3655, 'learning_rate': 5.263882026053157e-07, 'epoch': 0.9}
 90%|████████▉ | 9349/10395 [26:43:40<3:13:11, 11.08s/it] 90%|████████▉ | 9350/10395 [26:43:48<2:56:04, 10.11s/it]                                                         {'loss': 0.8996, 'learning_rate': 5.253911084171381e-07, 'epoch': 0.9}
 90%|████████▉ | 9350/10395 [26:43:48<2:56:04, 10.11s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 90%|████████▉ | 9351/10395 [26:45:31<11:02:36, 38.08s/it]                                                          {'loss': 0.8106, 'learning_rate': 5.243949340037469e-07, 'epoch': 0.9}
 90%|████████▉ | 9351/10395 [26:45:31<11:02:36, 38.08s/it] 90%|████████▉ | 9352/10395 [26:45:39<8:23:01, 28.94s/it]                                                          {'loss': 0.8252, 'learning_rate': 5.233996794618445e-07, 'epoch': 0.9}
 90%|████████▉ | 9352/10395 [26:45:39<8:23:01, 28.94s/it] 90%|████████▉ | 9353/10395 [26:45:47<6:31:19, 22.53s/it]                                                         {'loss': 0.8445, 'learning_rate': 5.224053448880506e-07, 'epoch': 0.9}
 90%|████████▉ | 9353/10395 [26:45:47<6:31:19, 22.53s/it] 90%|████████▉ | 9354/10395 [26:46:03<6:00:32, 20.78s/it]                                                         {'loss': 0.3316, 'learning_rate': 5.214119303788901e-07, 'epoch': 0.9}
 90%|████████▉ | 9354/10395 [26:46:03<6:00:32, 20.78s/it] 90%|████████▉ | 9355/10395 [26:46:11<4:51:52, 16.84s/it]                                                         {'loss': 0.8409, 'learning_rate': 5.204194360308046e-07, 'epoch': 0.9}
 90%|████████▉ | 9355/10395 [26:46:11<4:51:52, 16.84s/it] 90%|█████████ | 9356/10395 [26:46:18<4:02:48, 14.02s/it]                                                         {'loss': 0.8708, 'learning_rate': 5.19427861940145e-07, 'epoch': 0.9}
 90%|█████████ | 9356/10395 [26:46:18<4:02:48, 14.02s/it] 90%|█████████ | 9357/10395 [26:46:26<3:28:48, 12.07s/it]                                                         {'loss': 0.89, 'learning_rate': 5.184372082031653e-07, 'epoch': 0.9}
 90%|█████████ | 9357/10395 [26:46:26<3:28:48, 12.07s/it] 90%|█████████ | 9358/10395 [26:46:34<3:06:28, 10.79s/it]                                                         {'loss': 0.8215, 'learning_rate': 5.174474749160396e-07, 'epoch': 0.9}
 90%|█████████ | 9358/10395 [26:46:34<3:06:28, 10.79s/it] 90%|█████████ | 9359/10395 [26:46:43<2:56:30, 10.22s/it]                                                         {'loss': 0.8317, 'learning_rate': 5.164586621748502e-07, 'epoch': 0.9}
 90%|█████████ | 9359/10395 [26:46:43<2:56:30, 10.22s/it] 90%|█████████ | 9360/10395 [26:47:01<3:37:38, 12.62s/it]                                                         {'loss': 0.4019, 'learning_rate': 5.154707700755857e-07, 'epoch': 0.9}
 90%|█████████ | 9360/10395 [26:47:01<3:37:38, 12.62s/it] 90%|█████████ | 9361/10395 [26:47:10<3:17:21, 11.45s/it]                                                         {'loss': 0.893, 'learning_rate': 5.144837987141526e-07, 'epoch': 0.9}
 90%|█████████ | 9361/10395 [26:47:10<3:17:21, 11.45s/it] 90%|█████████ | 9362/10395 [26:47:26<3:43:31, 12.98s/it]                                                         {'loss': 0.3339, 'learning_rate': 5.13497748186359e-07, 'epoch': 0.9}
 90%|█████████ | 9362/10395 [26:47:26<3:43:31, 12.98s/it] 90%|█████████ | 9363/10395 [26:47:34<3:15:22, 11.36s/it]                                                         {'loss': 0.9089, 'learning_rate': 5.125126185879336e-07, 'epoch': 0.9}
 90%|█████████ | 9363/10395 [26:47:34<3:15:22, 11.36s/it] 90%|█████████ | 9364/10395 [26:47:41<2:56:34, 10.28s/it]                                                         {'loss': 0.8193, 'learning_rate': 5.115284100145079e-07, 'epoch': 0.9}
 90%|█████████ | 9364/10395 [26:47:41<2:56:34, 10.28s/it] 90%|█████████ | 9365/10395 [26:47:49<2:44:20,  9.57s/it]                                                         {'loss': 0.8375, 'learning_rate': 5.105451225616265e-07, 'epoch': 0.9}
 90%|█████████ | 9365/10395 [26:47:49<2:44:20,  9.57s/it] 90%|█████████ | 9366/10395 [26:47:58<2:36:54,  9.15s/it]                                                         {'loss': 0.8127, 'learning_rate': 5.095627563247452e-07, 'epoch': 0.9}
 90%|█████████ | 9366/10395 [26:47:58<2:36:54,  9.15s/it] 90%|█████████ | 9367/10395 [26:48:05<2:27:17,  8.60s/it]                                                         {'loss': 0.9444, 'learning_rate': 5.08581311399231e-07, 'epoch': 0.9}
 90%|█████████ | 9367/10395 [26:48:05<2:27:17,  8.60s/it] 90%|█████████ | 9368/10395 [26:48:13<2:26:58,  8.59s/it]                                                         {'loss': 0.7604, 'learning_rate': 5.076007878803601e-07, 'epoch': 0.9}
 90%|█████████ | 9368/10395 [26:48:13<2:26:58,  8.59s/it] 90%|█████████ | 9369/10395 [26:48:21<2:22:16,  8.32s/it]                                                         {'loss': 0.9681, 'learning_rate': 5.066211858633196e-07, 'epoch': 0.9}
 90%|█████████ | 9369/10395 [26:48:21<2:22:16,  8.32s/it] 90%|█████████ | 9370/10395 [26:48:29<2:22:29,  8.34s/it]                                                         {'loss': 0.7863, 'learning_rate': 5.056425054432068e-07, 'epoch': 0.9}
 90%|█████████ | 9370/10395 [26:48:29<2:22:29,  8.34s/it] 90%|█████████ | 9371/10395 [26:48:37<2:18:53,  8.14s/it]                                                         {'loss': 0.8272, 'learning_rate': 5.046647467150289e-07, 'epoch': 0.9}
 90%|█████████ | 9371/10395 [26:48:37<2:18:53,  8.14s/it] 90%|█████████ | 9372/10395 [26:48:44<2:14:23,  7.88s/it]                                                         {'loss': 0.7979, 'learning_rate': 5.03687909773708e-07, 'epoch': 0.9}
 90%|█████████ | 9372/10395 [26:48:44<2:14:23,  7.88s/it] 90%|█████████ | 9373/10395 [26:48:52<2:11:57,  7.75s/it]                                                         {'loss': 0.8654, 'learning_rate': 5.027119947140691e-07, 'epoch': 0.9}
 90%|█████████ | 9373/10395 [26:48:52<2:11:57,  7.75s/it] 90%|█████████ | 9374/10395 [26:48:59<2:11:19,  7.72s/it]                                                         {'loss': 0.8222, 'learning_rate': 5.017370016308542e-07, 'epoch': 0.9}
 90%|█████████ | 9374/10395 [26:48:59<2:11:19,  7.72s/it] 90%|█████████ | 9375/10395 [26:49:07<2:10:44,  7.69s/it]                                                         {'loss': 0.8524, 'learning_rate': 5.007629306187145e-07, 'epoch': 0.9}
 90%|█████████ | 9375/10395 [26:49:07<2:10:44,  7.69s/it] 90%|█████████ | 9376/10395 [26:49:15<2:09:06,  7.60s/it]                                                         {'loss': 0.8744, 'learning_rate': 4.997897817722075e-07, 'epoch': 0.9}
 90%|█████████ | 9376/10395 [26:49:15<2:09:06,  7.60s/it] 90%|█████████ | 9377/10395 [26:49:22<2:09:10,  7.61s/it]                                                         {'loss': 0.8853, 'learning_rate': 4.988175551858088e-07, 'epoch': 0.9}
 90%|█████████ | 9377/10395 [26:49:22<2:09:10,  7.61s/it] 90%|█████████ | 9378/10395 [26:49:30<2:12:15,  7.80s/it]                                                         {'loss': 0.8588, 'learning_rate': 4.978462509538972e-07, 'epoch': 0.9}
 90%|█████████ | 9378/10395 [26:49:30<2:12:15,  7.80s/it] 90%|█████████ | 9379/10395 [26:49:38<2:08:51,  7.61s/it]                                                         {'loss': 0.9015, 'learning_rate': 4.968758691707643e-07, 'epoch': 0.9}
 90%|█████████ | 9379/10395 [26:49:38<2:08:51,  7.61s/it] 90%|█████████ | 9380/10395 [26:49:45<2:09:02,  7.63s/it]                                                         {'loss': 0.839, 'learning_rate': 4.959064099306155e-07, 'epoch': 0.9}
 90%|█████████ | 9380/10395 [26:49:45<2:09:02,  7.63s/it] 90%|█████████ | 9381/10395 [26:49:53<2:09:01,  7.63s/it]                                                         {'loss': 0.8423, 'learning_rate': 4.9493787332756e-07, 'epoch': 0.9}
 90%|█████████ | 9381/10395 [26:49:53<2:09:01,  7.63s/it] 90%|█████████ | 9382/10395 [26:50:00<2:05:02,  7.41s/it]                                                         {'loss': 0.8669, 'learning_rate': 4.93970259455624e-07, 'epoch': 0.9}
 90%|█████████ | 9382/10395 [26:50:00<2:05:02,  7.41s/it] 90%|█████████ | 9383/10395 [26:50:08<2:09:36,  7.68s/it]                                                         {'loss': 0.8154, 'learning_rate': 4.93003568408742e-07, 'epoch': 0.9}
 90%|█████████ | 9383/10395 [26:50:08<2:09:36,  7.68s/it] 90%|█████████ | 9384/10395 [26:50:16<2:12:36,  7.87s/it]                                                         {'loss': 0.8053, 'learning_rate': 4.920378002807558e-07, 'epoch': 0.9}
 90%|█████████ | 9384/10395 [26:50:16<2:12:36,  7.87s/it] 90%|█████████ | 9385/10395 [26:50:24<2:12:19,  7.86s/it]                                                         {'loss': 0.827, 'learning_rate': 4.910729551654214e-07, 'epoch': 0.9}
 90%|█████████ | 9385/10395 [26:50:24<2:12:19,  7.86s/it] 90%|█████████ | 9386/10395 [26:50:32<2:12:01,  7.85s/it]                                                         {'loss': 0.8776, 'learning_rate': 4.901090331564051e-07, 'epoch': 0.9}
 90%|█████████ | 9386/10395 [26:50:32<2:12:01,  7.85s/it] 90%|█████████ | 9387/10395 [26:50:39<2:09:49,  7.73s/it]                                                         {'loss': 0.8375, 'learning_rate': 4.891460343472798e-07, 'epoch': 0.9}
 90%|█████████ | 9387/10395 [26:50:39<2:09:49,  7.73s/it] 90%|█████████ | 9388/10395 [26:50:47<2:09:23,  7.71s/it]                                                         {'loss': 0.8372, 'learning_rate': 4.88183958831534e-07, 'epoch': 0.9}
 90%|█████████ | 9388/10395 [26:50:47<2:09:23,  7.71s/it] 90%|█████████ | 9389/10395 [26:50:54<2:06:17,  7.53s/it]                                                         {'loss': 0.878, 'learning_rate': 4.872228067025608e-07, 'epoch': 0.9}
 90%|█████████ | 9389/10395 [26:50:54<2:06:17,  7.53s/it] 90%|█████████ | 9390/10395 [26:51:01<2:03:27,  7.37s/it]                                                         {'loss': 0.8647, 'learning_rate': 4.8626257805367e-07, 'epoch': 0.9}
 90%|█████████ | 9390/10395 [26:51:01<2:03:27,  7.37s/it] 90%|█████████ | 9391/10395 [26:51:09<2:06:20,  7.55s/it]                                                         {'loss': 0.8239, 'learning_rate': 4.853032729780771e-07, 'epoch': 0.9}
 90%|█████████ | 9391/10395 [26:51:09<2:06:20,  7.55s/it] 90%|█████████ | 9392/10395 [26:51:17<2:06:23,  7.56s/it]                                                         {'loss': 0.8733, 'learning_rate': 4.843448915689097e-07, 'epoch': 0.9}
 90%|█████████ | 9392/10395 [26:51:17<2:06:23,  7.56s/it] 90%|█████████ | 9393/10395 [26:51:24<2:05:56,  7.54s/it]                                                         {'loss': 0.8873, 'learning_rate': 4.833874339192046e-07, 'epoch': 0.9}
 90%|█████████ | 9393/10395 [26:51:24<2:05:56,  7.54s/it] 90%|█████████ | 9394/10395 [26:51:32<2:08:39,  7.71s/it]                                                         {'loss': 0.7591, 'learning_rate': 4.824309001219107e-07, 'epoch': 0.9}
 90%|█████████ | 9394/10395 [26:51:32<2:08:39,  7.71s/it] 90%|█████████ | 9395/10395 [26:51:40<2:06:29,  7.59s/it]                                                         {'loss': 0.8759, 'learning_rate': 4.814752902698861e-07, 'epoch': 0.9}
 90%|█████████ | 9395/10395 [26:51:40<2:06:29,  7.59s/it] 90%|█████████ | 9396/10395 [26:51:47<2:03:46,  7.43s/it]                                                         {'loss': 0.8733, 'learning_rate': 4.805206044558985e-07, 'epoch': 0.9}
 90%|█████████ | 9396/10395 [26:51:47<2:03:46,  7.43s/it] 90%|█████████ | 9397/10395 [26:51:55<2:06:08,  7.58s/it]                                                         {'loss': 0.7976, 'learning_rate': 4.795668427726275e-07, 'epoch': 0.9}
 90%|█████████ | 9397/10395 [26:51:55<2:06:08,  7.58s/it] 90%|█████████ | 9398/10395 [26:52:11<2:46:54, 10.04s/it]                                                         {'loss': 0.371, 'learning_rate': 4.78614005312662e-07, 'epoch': 0.9}
 90%|█████████ | 9398/10395 [26:52:11<2:46:54, 10.04s/it] 90%|█████████ | 9399/10395 [26:52:19<2:36:27,  9.42s/it]                                                         {'loss': 0.8357, 'learning_rate': 4.776620921685027e-07, 'epoch': 0.9}
 90%|█████████ | 9399/10395 [26:52:19<2:36:27,  9.42s/it] 90%|█████████ | 9400/10395 [26:52:26<2:28:37,  8.96s/it]                                                         {'loss': 0.8424, 'learning_rate': 4.7671110343255777e-07, 'epoch': 0.9}
 90%|█████████ | 9400/10395 [26:52:26<2:28:37,  8.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 90%|█████████ | 9401/10395 [26:54:07<10:05:40, 36.56s/it]                                                          {'loss': 0.8918, 'learning_rate': 4.757610391971468e-07, 'epoch': 0.9}
 90%|█████████ | 9401/10395 [26:54:07<10:05:40, 36.56s/it] 90%|█████████ | 9402/10395 [26:54:15<7:41:35, 27.89s/it]                                                          {'loss': 0.9274, 'learning_rate': 4.7481189955450256e-07, 'epoch': 0.9}
 90%|█████████ | 9402/10395 [26:54:15<7:41:35, 27.89s/it] 90%|█████████ | 9403/10395 [26:54:23<6:00:58, 21.83s/it]                                                         {'loss': 0.8484, 'learning_rate': 4.7386368459676145e-07, 'epoch': 0.9}
 90%|█████████ | 9403/10395 [26:54:23<6:00:58, 21.83s/it] 90%|█████████ | 9404/10395 [26:54:30<4:50:43, 17.60s/it]                                                         {'loss': 0.8187, 'learning_rate': 4.729163944159776e-07, 'epoch': 0.9}
 90%|█████████ | 9404/10395 [26:54:30<4:50:43, 17.60s/it] 90%|█████████ | 9405/10395 [26:54:40<4:10:51, 15.20s/it]                                                         {'loss': 0.8971, 'learning_rate': 4.7197002910411073e-07, 'epoch': 0.9}
 90%|█████████ | 9405/10395 [26:54:40<4:10:51, 15.20s/it] 90%|█████████ | 9406/10395 [26:54:47<3:32:01, 12.86s/it]                                                         {'loss': 0.9186, 'learning_rate': 4.7102458875303067e-07, 'epoch': 0.9}
 90%|█████████ | 9406/10395 [26:54:47<3:32:01, 12.86s/it] 90%|█████████ | 9407/10395 [26:54:55<3:04:55, 11.23s/it]                                                         {'loss': 0.8797, 'learning_rate': 4.70080073454523e-07, 'epoch': 0.9}
 90%|█████████ | 9407/10395 [26:54:55<3:04:55, 11.23s/it] 91%|█████████ | 9408/10395 [26:55:02<2:44:58, 10.03s/it]                                                         {'loss': 0.8883, 'learning_rate': 4.6913648330027427e-07, 'epoch': 0.91}
 91%|█████████ | 9408/10395 [26:55:02<2:44:58, 10.03s/it] 91%|█████████ | 9409/10395 [26:55:10<2:35:02,  9.43s/it]                                                         {'loss': 0.8647, 'learning_rate': 4.681938183818879e-07, 'epoch': 0.91}
 91%|█████████ | 9409/10395 [26:55:10<2:35:02,  9.43s/it] 91%|█████████ | 9410/10395 [26:55:17<2:24:18,  8.79s/it]                                                         {'loss': 0.8348, 'learning_rate': 4.6725207879087744e-07, 'epoch': 0.91}
 91%|█████████ | 9410/10395 [26:55:17<2:24:18,  8.79s/it] 91%|█████████ | 9411/10395 [26:55:25<2:19:37,  8.51s/it]                                                         {'loss': 0.9465, 'learning_rate': 4.6631126461866183e-07, 'epoch': 0.91}
 91%|█████████ | 9411/10395 [26:55:25<2:19:37,  8.51s/it] 91%|█████████ | 9412/10395 [26:55:34<2:20:26,  8.57s/it]                                                         {'loss': 0.904, 'learning_rate': 4.65371375956577e-07, 'epoch': 0.91}
 91%|█████████ | 9412/10395 [26:55:34<2:20:26,  8.57s/it] 91%|█████████ | 9413/10395 [26:55:42<2:15:30,  8.28s/it]                                                         {'loss': 0.8832, 'learning_rate': 4.6443241289586106e-07, 'epoch': 0.91}
 91%|█████████ | 9413/10395 [26:55:42<2:15:30,  8.28s/it] 91%|█████████ | 9414/10395 [26:55:49<2:09:15,  7.91s/it]                                                         {'loss': 0.8484, 'learning_rate': 4.6349437552767105e-07, 'epoch': 0.91}
 91%|█████████ | 9414/10395 [26:55:49<2:09:15,  7.91s/it] 91%|█████████ | 9415/10395 [26:55:57<2:10:23,  7.98s/it]                                                         {'loss': 0.8871, 'learning_rate': 4.625572639430664e-07, 'epoch': 0.91}
 91%|█████████ | 9415/10395 [26:55:57<2:10:23,  7.98s/it] 91%|█████████ | 9416/10395 [26:56:04<2:08:23,  7.87s/it]                                                         {'loss': 0.8808, 'learning_rate': 4.6162107823302217e-07, 'epoch': 0.91}
 91%|█████████ | 9416/10395 [26:56:04<2:08:23,  7.87s/it] 91%|█████████ | 9417/10395 [26:56:12<2:06:34,  7.76s/it]                                                         {'loss': 0.8673, 'learning_rate': 4.606858184884178e-07, 'epoch': 0.91}
 91%|█████████ | 9417/10395 [26:56:12<2:06:34,  7.76s/it] 91%|█████████ | 9418/10395 [26:56:19<2:04:42,  7.66s/it]                                                         {'loss': 0.8636, 'learning_rate': 4.5975148480005174e-07, 'epoch': 0.91}
 91%|█████████ | 9418/10395 [26:56:19<2:04:42,  7.66s/it] 91%|█████████ | 9419/10395 [26:56:27<2:02:34,  7.53s/it]                                                         {'loss': 0.8233, 'learning_rate': 4.588180772586215e-07, 'epoch': 0.91}
 91%|█████████ | 9419/10395 [26:56:27<2:02:34,  7.53s/it] 91%|█████████ | 9420/10395 [26:56:34<2:01:22,  7.47s/it]                                                         {'loss': 0.8666, 'learning_rate': 4.5788559595474233e-07, 'epoch': 0.91}
 91%|█████████ | 9420/10395 [26:56:34<2:01:22,  7.47s/it] 91%|█████████ | 9421/10395 [26:56:41<2:01:41,  7.50s/it]                                                         {'loss': 0.8725, 'learning_rate': 4.569540409789397e-07, 'epoch': 0.91}
 91%|█████████ | 9421/10395 [26:56:41<2:01:41,  7.50s/it] 91%|█████████ | 9422/10395 [26:56:49<2:02:39,  7.56s/it]                                                         {'loss': 0.7634, 'learning_rate': 4.560234124216456e-07, 'epoch': 0.91}
 91%|█████████ | 9422/10395 [26:56:49<2:02:39,  7.56s/it] 91%|█████████ | 9423/10395 [26:56:57<2:01:28,  7.50s/it]                                                         {'loss': 0.8887, 'learning_rate': 4.550937103732012e-07, 'epoch': 0.91}
 91%|█████████ | 9423/10395 [26:56:57<2:01:28,  7.50s/it] 91%|█████████ | 9424/10395 [26:57:04<1:59:54,  7.41s/it]                                                         {'loss': 0.7929, 'learning_rate': 4.5416493492386306e-07, 'epoch': 0.91}
 91%|█████████ | 9424/10395 [26:57:04<1:59:54,  7.41s/it] 91%|█████████ | 9425/10395 [26:57:12<2:03:03,  7.61s/it]                                                         {'loss': 0.8037, 'learning_rate': 4.5323708616379247e-07, 'epoch': 0.91}
 91%|█████████ | 9425/10395 [26:57:12<2:03:03,  7.61s/it] 91%|█████████ | 9426/10395 [26:57:19<2:02:15,  7.57s/it]                                                         {'loss': 0.8552, 'learning_rate': 4.523101641830663e-07, 'epoch': 0.91}
 91%|█████████ | 9426/10395 [26:57:19<2:02:15,  7.57s/it] 91%|█████████ | 9427/10395 [26:57:27<2:02:09,  7.57s/it]                                                         {'loss': 0.9166, 'learning_rate': 4.513841690716636e-07, 'epoch': 0.91}
 91%|█████████ | 9427/10395 [26:57:27<2:02:09,  7.57s/it] 91%|█████████ | 9428/10395 [26:57:43<2:45:46, 10.29s/it]                                                         {'loss': 0.3498, 'learning_rate': 4.504591009194803e-07, 'epoch': 0.91}
 91%|█████████ | 9428/10395 [26:57:43<2:45:46, 10.29s/it] 91%|█████████ | 9429/10395 [26:57:51<2:33:48,  9.55s/it]                                                         {'loss': 0.863, 'learning_rate': 4.4953495981632236e-07, 'epoch': 0.91}
 91%|█████████ | 9429/10395 [26:57:51<2:33:48,  9.55s/it] 91%|█████████ | 9430/10395 [26:57:59<2:25:32,  9.05s/it]                                                         {'loss': 0.8463, 'learning_rate': 4.48611745851899e-07, 'epoch': 0.91}
 91%|█████████ | 9430/10395 [26:57:59<2:25:32,  9.05s/it] 91%|█████████ | 9431/10395 [26:58:06<2:16:54,  8.52s/it]                                                         {'loss': 0.8739, 'learning_rate': 4.476894591158365e-07, 'epoch': 0.91}
 91%|█████████ | 9431/10395 [26:58:06<2:16:54,  8.52s/it] 91%|█████████ | 9432/10395 [26:58:14<2:11:48,  8.21s/it]                                                         {'loss': 0.8522, 'learning_rate': 4.4676809969766865e-07, 'epoch': 0.91}
 91%|█████████ | 9432/10395 [26:58:14<2:11:48,  8.21s/it] 91%|█████████ | 9433/10395 [26:58:23<2:16:26,  8.51s/it]                                                         {'loss': 0.7971, 'learning_rate': 4.458476676868373e-07, 'epoch': 0.91}
 91%|█████████ | 9433/10395 [26:58:23<2:16:26,  8.51s/it] 91%|█████████ | 9434/10395 [26:58:32<2:15:42,  8.47s/it]                                                         {'loss': 0.8006, 'learning_rate': 4.449281631726976e-07, 'epoch': 0.91}
 91%|█████████ | 9434/10395 [26:58:32<2:15:42,  8.47s/it] 91%|█████████ | 9435/10395 [26:58:39<2:11:49,  8.24s/it]                                                         {'loss': 0.9192, 'learning_rate': 4.440095862445115e-07, 'epoch': 0.91}
 91%|█████████ | 9435/10395 [26:58:39<2:11:49,  8.24s/it] 91%|█████████ | 9436/10395 [26:58:48<2:15:39,  8.49s/it]                                                         {'loss': 0.8142, 'learning_rate': 4.4309193699145547e-07, 'epoch': 0.91}
 91%|█████████ | 9436/10395 [26:58:48<2:15:39,  8.49s/it] 91%|█████████ | 9437/10395 [26:58:55<2:08:58,  8.08s/it]                                                         {'loss': 0.8661, 'learning_rate': 4.4217521550261046e-07, 'epoch': 0.91}
 91%|█████████ | 9437/10395 [26:58:55<2:08:58,  8.08s/it] 91%|█████████ | 9438/10395 [26:59:03<2:07:01,  7.96s/it]                                                         {'loss': 0.856, 'learning_rate': 4.412594218669697e-07, 'epoch': 0.91}
 91%|█████████ | 9438/10395 [26:59:03<2:07:01,  7.96s/it] 91%|█████████ | 9439/10395 [26:59:11<2:05:15,  7.86s/it]                                                         {'loss': 0.8289, 'learning_rate': 4.403445561734365e-07, 'epoch': 0.91}
 91%|█████████ | 9439/10395 [26:59:11<2:05:15,  7.86s/it] 91%|█████████ | 9440/10395 [26:59:18<2:02:33,  7.70s/it]                                                         {'loss': 0.8633, 'learning_rate': 4.394306185108266e-07, 'epoch': 0.91}
 91%|█████████ | 9440/10395 [26:59:18<2:02:33,  7.70s/it] 91%|█████████ | 9441/10395 [26:59:26<2:04:55,  7.86s/it]                                                         {'loss': 0.8204, 'learning_rate': 4.3851760896786e-07, 'epoch': 0.91}
 91%|█████████ | 9441/10395 [26:59:26<2:04:55,  7.86s/it] 91%|█████████ | 9442/10395 [26:59:34<2:03:06,  7.75s/it]                                                         {'loss': 0.8546, 'learning_rate': 4.376055276331714e-07, 'epoch': 0.91}
 91%|█████████ | 9442/10395 [26:59:34<2:03:06,  7.75s/it] 91%|█████████ | 9443/10395 [26:59:41<2:02:26,  7.72s/it]                                                         {'loss': 0.9113, 'learning_rate': 4.366943745953023e-07, 'epoch': 0.91}
 91%|█████████ | 9443/10395 [26:59:41<2:02:26,  7.72s/it] 91%|█████████ | 9444/10395 [26:59:58<2:44:42, 10.39s/it]                                                         {'loss': 0.3346, 'learning_rate': 4.3578414994270846e-07, 'epoch': 0.91}
 91%|█████████ | 9444/10395 [26:59:58<2:44:42, 10.39s/it] 91%|█████████ | 9445/10395 [27:00:06<2:33:29,  9.69s/it]                                                         {'loss': 0.8226, 'learning_rate': 4.348748537637504e-07, 'epoch': 0.91}
 91%|█████████ | 9445/10395 [27:00:06<2:33:29,  9.69s/it] 91%|█████████ | 9446/10395 [27:00:14<2:24:15,  9.12s/it]                                                         {'loss': 0.9334, 'learning_rate': 4.3396648614669856e-07, 'epoch': 0.91}
 91%|█████████ | 9446/10395 [27:00:14<2:24:15,  9.12s/it] 91%|█████████ | 9447/10395 [27:00:22<2:18:25,  8.76s/it]                                                         {'loss': 0.827, 'learning_rate': 4.3305904717973803e-07, 'epoch': 0.91}
 91%|█████████ | 9447/10395 [27:00:22<2:18:25,  8.76s/it] 91%|█████████ | 9448/10395 [27:00:31<2:18:41,  8.79s/it]                                                         {'loss': 0.8765, 'learning_rate': 4.3215253695096273e-07, 'epoch': 0.91}
 91%|█████████ | 9448/10395 [27:00:31<2:18:41,  8.79s/it] 91%|█████████ | 9449/10395 [27:00:39<2:18:29,  8.78s/it]                                                         {'loss': 0.8239, 'learning_rate': 4.3124695554837005e-07, 'epoch': 0.91}
 91%|█████████ | 9449/10395 [27:00:39<2:18:29,  8.78s/it] 91%|█████████ | 9450/10395 [27:00:47<2:11:48,  8.37s/it]                                                         {'loss': 0.8273, 'learning_rate': 4.3034230305987635e-07, 'epoch': 0.91}
 91%|█████████ | 9450/10395 [27:00:47<2:11:48,  8.37s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 91%|█████████ | 9451/10395 [27:02:30<9:39:23, 36.83s/it]                                                         {'loss': 0.8707, 'learning_rate': 4.294385795733014e-07, 'epoch': 0.91}
 91%|█████████ | 9451/10395 [27:02:30<9:39:23, 36.83s/it] 91%|█████████ | 9452/10395 [27:02:39<7:24:51, 28.30s/it]                                                         {'loss': 0.8404, 'learning_rate': 4.2853578517637604e-07, 'epoch': 0.91}
 91%|█████████ | 9452/10395 [27:02:39<7:24:51, 28.30s/it] 91%|█████████ | 9453/10395 [27:02:47<5:52:12, 22.43s/it]                                                         {'loss': 0.8432, 'learning_rate': 4.276339199567425e-07, 'epoch': 0.91}
 91%|█████████ | 9453/10395 [27:02:47<5:52:12, 22.43s/it] 91%|█████████ | 9454/10395 [27:02:55<4:41:53, 17.97s/it]                                                         {'loss': 0.8401, 'learning_rate': 4.2673298400195075e-07, 'epoch': 0.91}
 91%|█████████ | 9454/10395 [27:02:55<4:41:53, 17.97s/it] 91%|█████████ | 9455/10395 [27:03:02<3:50:52, 14.74s/it]                                                         {'loss': 0.9148, 'learning_rate': 4.2583297739946407e-07, 'epoch': 0.91}
 91%|█████████ | 9455/10395 [27:03:02<3:50:52, 14.74s/it] 91%|█████████ | 9456/10395 [27:03:10<3:18:31, 12.69s/it]                                                         {'loss': 0.9303, 'learning_rate': 4.2493390023665147e-07, 'epoch': 0.91}
 91%|█████████ | 9456/10395 [27:03:10<3:18:31, 12.69s/it] 91%|█████████ | 9457/10395 [27:03:17<2:53:15, 11.08s/it]                                                         {'loss': 0.8693, 'learning_rate': 4.240357526007932e-07, 'epoch': 0.91}
 91%|█████████ | 9457/10395 [27:03:17<2:53:15, 11.08s/it] 91%|█████████ | 9458/10395 [27:03:25<2:35:25,  9.95s/it]                                                         {'loss': 0.8098, 'learning_rate': 4.2313853457908174e-07, 'epoch': 0.91}
 91%|█████████ | 9458/10395 [27:03:25<2:35:25,  9.95s/it] 91%|█████████ | 9459/10395 [27:03:32<2:23:33,  9.20s/it]                                                         {'loss': 0.8463, 'learning_rate': 4.222422462586151e-07, 'epoch': 0.91}
 91%|█████████ | 9459/10395 [27:03:32<2:23:33,  9.20s/it] 91%|█████████ | 9460/10395 [27:03:39<2:15:05,  8.67s/it]                                                         {'loss': 0.8494, 'learning_rate': 4.213468877264026e-07, 'epoch': 0.91}
 91%|█████████ | 9460/10395 [27:03:39<2:15:05,  8.67s/it] 91%|█████████ | 9461/10395 [27:03:48<2:14:24,  8.63s/it]                                                         {'loss': 0.8492, 'learning_rate': 4.204524590693659e-07, 'epoch': 0.91}
 91%|█████████ | 9461/10395 [27:03:48<2:14:24,  8.63s/it] 91%|█████████ | 9462/10395 [27:03:56<2:11:40,  8.47s/it]                                                         {'loss': 0.8465, 'learning_rate': 4.195589603743311e-07, 'epoch': 0.91}
 91%|█████████ | 9462/10395 [27:03:56<2:11:40,  8.47s/it] 91%|█████████ | 9463/10395 [27:04:05<2:12:06,  8.50s/it]                                                         {'loss': 0.8629, 'learning_rate': 4.186663917280398e-07, 'epoch': 0.91}
 91%|█████████ | 9463/10395 [27:04:05<2:12:06,  8.50s/it] 91%|█████████ | 9464/10395 [27:04:13<2:12:06,  8.51s/it]                                                         {'loss': 0.7654, 'learning_rate': 4.1777475321713943e-07, 'epoch': 0.91}
 91%|█████████ | 9464/10395 [27:04:13<2:12:06,  8.51s/it] 91%|█████████ | 9465/10395 [27:04:22<2:12:39,  8.56s/it]                                                         {'loss': 0.8174, 'learning_rate': 4.168840449281897e-07, 'epoch': 0.91}
 91%|█████████ | 9465/10395 [27:04:22<2:12:39,  8.56s/it] 91%|█████████ | 9466/10395 [27:04:30<2:11:50,  8.52s/it]                                                         {'loss': 0.8446, 'learning_rate': 4.159942669476569e-07, 'epoch': 0.91}
 91%|█████████ | 9466/10395 [27:04:30<2:11:50,  8.52s/it] 91%|█████████ | 9467/10395 [27:04:39<2:11:04,  8.48s/it]                                                         {'loss': 0.8353, 'learning_rate': 4.1510541936192084e-07, 'epoch': 0.91}
 91%|█████████ | 9467/10395 [27:04:39<2:11:04,  8.48s/it] 91%|█████████ | 9468/10395 [27:04:46<2:07:29,  8.25s/it]                                                         {'loss': 0.8608, 'learning_rate': 4.142175022572659e-07, 'epoch': 0.91}
 91%|█████████ | 9468/10395 [27:04:46<2:07:29,  8.25s/it] 91%|█████████ | 9469/10395 [27:04:55<2:08:09,  8.30s/it]                                                         {'loss': 0.7597, 'learning_rate': 4.13330515719893e-07, 'epoch': 0.91}
 91%|█████████ | 9469/10395 [27:04:55<2:08:09,  8.30s/it] 91%|█████████ | 9470/10395 [27:05:03<2:07:37,  8.28s/it]                                                         {'loss': 0.8172, 'learning_rate': 4.1244445983590456e-07, 'epoch': 0.91}
 91%|█████████ | 9470/10395 [27:05:03<2:07:37,  8.28s/it] 91%|█████████ | 9471/10395 [27:05:11<2:04:52,  8.11s/it]                                                         {'loss': 0.7846, 'learning_rate': 4.1155933469131937e-07, 'epoch': 0.91}
 91%|█████████ | 9471/10395 [27:05:11<2:04:52,  8.11s/it] 91%|█████████ | 9472/10395 [27:05:18<2:02:27,  7.96s/it]                                                         {'loss': 0.8183, 'learning_rate': 4.1067514037206544e-07, 'epoch': 0.91}
 91%|█████████ | 9472/10395 [27:05:18<2:02:27,  7.96s/it] 91%|█████████ | 9473/10395 [27:05:26<2:00:49,  7.86s/it]                                                         {'loss': 0.8341, 'learning_rate': 4.097918769639764e-07, 'epoch': 0.91}
 91%|█████████ | 9473/10395 [27:05:26<2:00:49,  7.86s/it] 91%|█████████ | 9474/10395 [27:05:35<2:07:49,  8.33s/it]                                                         {'loss': 0.851, 'learning_rate': 4.0890954455279574e-07, 'epoch': 0.91}
 91%|█████████ | 9474/10395 [27:05:35<2:07:49,  8.33s/it] 91%|█████████ | 9475/10395 [27:05:43<2:04:59,  8.15s/it]                                                         {'loss': 0.8834, 'learning_rate': 4.080281432241817e-07, 'epoch': 0.91}
 91%|█████████ | 9475/10395 [27:05:43<2:04:59,  8.15s/it] 91%|█████████ | 9476/10395 [27:05:52<2:05:56,  8.22s/it]                                                         {'loss': 0.8425, 'learning_rate': 4.0714767306369584e-07, 'epoch': 0.91}
 91%|█████████ | 9476/10395 [27:05:52<2:05:56,  8.22s/it] 91%|█████████ | 9477/10395 [27:05:59<2:01:18,  7.93s/it]                                                         {'loss': 0.878, 'learning_rate': 4.0626813415681534e-07, 'epoch': 0.91}
 91%|█████████ | 9477/10395 [27:05:59<2:01:18,  7.93s/it] 91%|█████████ | 9478/10395 [27:06:07<2:02:58,  8.05s/it]                                                         {'loss': 0.8135, 'learning_rate': 4.053895265889218e-07, 'epoch': 0.91}
 91%|█████████ | 9478/10395 [27:06:07<2:02:58,  8.05s/it] 91%|█████████ | 9479/10395 [27:06:15<2:02:04,  8.00s/it]                                                         {'loss': 0.8713, 'learning_rate': 4.0451185044530825e-07, 'epoch': 0.91}
 91%|█████████ | 9479/10395 [27:06:15<2:02:04,  8.00s/it] 91%|█████████ | 9480/10395 [27:06:24<2:05:40,  8.24s/it]                                                         {'loss': 0.7746, 'learning_rate': 4.036351058111809e-07, 'epoch': 0.91}
 91%|█████████ | 9480/10395 [27:06:24<2:05:40,  8.24s/it] 91%|█████████ | 9481/10395 [27:06:40<2:42:36, 10.67s/it]                                                         {'loss': 0.395, 'learning_rate': 4.0275929277164946e-07, 'epoch': 0.91}
 91%|█████████ | 9481/10395 [27:06:40<2:42:36, 10.67s/it] 91%|█████████ | 9482/10395 [27:06:50<2:37:08, 10.33s/it]                                                         {'loss': 0.9083, 'learning_rate': 4.0188441141173484e-07, 'epoch': 0.91}
 91%|█████████ | 9482/10395 [27:06:50<2:37:08, 10.33s/it] 91%|█████████ | 9483/10395 [27:06:58<2:26:22,  9.63s/it]                                                         {'loss': 0.8358, 'learning_rate': 4.0101046181637236e-07, 'epoch': 0.91}
 91%|█████████ | 9483/10395 [27:06:58<2:26:22,  9.63s/it] 91%|█████████ | 9484/10395 [27:07:06<2:19:21,  9.18s/it]                                                         {'loss': 0.8277, 'learning_rate': 4.001374440703998e-07, 'epoch': 0.91}
 91%|█████████ | 9484/10395 [27:07:06<2:19:21,  9.18s/it] 91%|█████████ | 9485/10395 [27:07:14<2:15:33,  8.94s/it]                                                         {'loss': 0.8979, 'learning_rate': 3.9926535825856925e-07, 'epoch': 0.91}
 91%|█████████ | 9485/10395 [27:07:14<2:15:33,  8.94s/it] 91%|█████████▏| 9486/10395 [27:07:31<2:51:14, 11.30s/it]                                                         {'loss': 0.3043, 'learning_rate': 3.98394204465542e-07, 'epoch': 0.91}
 91%|█████████▏| 9486/10395 [27:07:31<2:51:14, 11.30s/it] 91%|█████████▏| 9487/10395 [27:07:40<2:38:31, 10.48s/it]                                                         {'loss': 0.8317, 'learning_rate': 3.975239827758848e-07, 'epoch': 0.91}
 91%|█████████▏| 9487/10395 [27:07:40<2:38:31, 10.48s/it] 91%|█████████▏| 9488/10395 [27:07:47<2:25:07,  9.60s/it]                                                         {'loss': 0.9105, 'learning_rate': 3.9665469327408003e-07, 'epoch': 0.91}
 91%|█████████▏| 9488/10395 [27:07:47<2:25:07,  9.60s/it] 91%|█████████▏| 9489/10395 [27:07:55<2:16:46,  9.06s/it]                                                         {'loss': 0.8186, 'learning_rate': 3.957863360445158e-07, 'epoch': 0.91}
 91%|█████████▏| 9489/10395 [27:07:55<2:16:46,  9.06s/it] 91%|█████████▏| 9490/10395 [27:08:04<2:15:51,  9.01s/it]                                                         {'loss': 0.8048, 'learning_rate': 3.949189111714891e-07, 'epoch': 0.91}
 91%|█████████▏| 9490/10395 [27:08:04<2:15:51,  9.01s/it] 91%|█████████▏| 9491/10395 [27:08:11<2:09:12,  8.58s/it]                                                         {'loss': 0.8285, 'learning_rate': 3.940524187392092e-07, 'epoch': 0.91}
 91%|█████████▏| 9491/10395 [27:08:11<2:09:12,  8.58s/it] 91%|█████████▏| 9492/10395 [27:08:19<2:04:22,  8.26s/it]                                                         {'loss': 0.8338, 'learning_rate': 3.931868588317911e-07, 'epoch': 0.91}
 91%|█████████▏| 9492/10395 [27:08:19<2:04:22,  8.26s/it] 91%|█████████▏| 9493/10395 [27:08:27<2:04:04,  8.25s/it]                                                         {'loss': 0.8799, 'learning_rate': 3.92322231533262e-07, 'epoch': 0.91}
 91%|█████████▏| 9493/10395 [27:08:27<2:04:04,  8.25s/it] 91%|█████████▏| 9494/10395 [27:08:35<2:03:38,  8.23s/it]                                                         {'loss': 0.9172, 'learning_rate': 3.914585369275614e-07, 'epoch': 0.91}
 91%|█████████▏| 9494/10395 [27:08:35<2:03:38,  8.23s/it] 91%|█████████▏| 9495/10395 [27:08:43<2:02:05,  8.14s/it]                                                         {'loss': 0.8551, 'learning_rate': 3.905957750985323e-07, 'epoch': 0.91}
 91%|█████████▏| 9495/10395 [27:08:43<2:02:05,  8.14s/it] 91%|█████████▏| 9496/10395 [27:08:51<1:58:45,  7.93s/it]                                                         {'loss': 0.8618, 'learning_rate': 3.8973394612992877e-07, 'epoch': 0.91}
 91%|█████████▏| 9496/10395 [27:08:51<1:58:45,  7.93s/it] 91%|█████████▏| 9497/10395 [27:08:58<1:54:57,  7.68s/it]                                                         {'loss': 0.8485, 'learning_rate': 3.888730501054172e-07, 'epoch': 0.91}
 91%|█████████▏| 9497/10395 [27:08:58<1:54:57,  7.68s/it] 91%|█████████▏| 9498/10395 [27:09:06<1:56:18,  7.78s/it]                                                         {'loss': 0.8961, 'learning_rate': 3.880130871085708e-07, 'epoch': 0.91}
 91%|█████████▏| 9498/10395 [27:09:06<1:56:18,  7.78s/it] 91%|█████████▏| 9499/10395 [27:09:13<1:55:49,  7.76s/it]                                                         {'loss': 0.8896, 'learning_rate': 3.871540572228738e-07, 'epoch': 0.91}
 91%|█████████▏| 9499/10395 [27:09:13<1:55:49,  7.76s/it] 91%|█████████▏| 9500/10395 [27:09:22<2:00:29,  8.08s/it]                                                         {'loss': 0.8048, 'learning_rate': 3.8629596053171627e-07, 'epoch': 0.91}
 91%|█████████▏| 9500/10395 [27:09:22<2:00:29,  8.08s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 91%|█████████▏| 9501/10395 [27:11:02<8:52:02, 35.71s/it]                                                         {'loss': 0.874, 'learning_rate': 3.8543879711840257e-07, 'epoch': 0.91}
 91%|█████████▏| 9501/10395 [27:11:02<8:52:02, 35.71s/it] 91%|█████████▏| 9502/10395 [27:11:11<6:49:53, 27.54s/it]                                                         {'loss': 0.8658, 'learning_rate': 3.8458256706614625e-07, 'epoch': 0.91}
 91%|█████████▏| 9502/10395 [27:11:11<6:49:53, 27.54s/it] 91%|█████████▏| 9503/10395 [27:11:29<6:06:38, 24.66s/it]                                                         {'loss': 0.3577, 'learning_rate': 3.8372727045806526e-07, 'epoch': 0.91}
 91%|█████████▏| 9503/10395 [27:11:29<6:06:38, 24.66s/it] 91%|█████████▏| 9504/10395 [27:11:37<4:54:14, 19.81s/it]                                                         {'loss': 0.8692, 'learning_rate': 3.8287290737718975e-07, 'epoch': 0.91}
 91%|█████████▏| 9504/10395 [27:11:37<4:54:14, 19.81s/it] 91%|█████████▏| 9505/10395 [27:11:45<3:57:51, 16.03s/it]                                                         {'loss': 0.8923, 'learning_rate': 3.820194779064612e-07, 'epoch': 0.91}
 91%|█████████▏| 9505/10395 [27:11:45<3:57:51, 16.03s/it] 91%|█████████▏| 9506/10395 [27:11:52<3:20:10, 13.51s/it]                                                         {'loss': 0.8437, 'learning_rate': 3.811669821287278e-07, 'epoch': 0.91}
 91%|█████████▏| 9506/10395 [27:11:52<3:20:10, 13.51s/it] 91%|█████████▏| 9507/10395 [27:12:00<2:54:49, 11.81s/it]                                                         {'loss': 0.8986, 'learning_rate': 3.803154201267489e-07, 'epoch': 0.91}
 91%|█████████▏| 9507/10395 [27:12:00<2:54:49, 11.81s/it] 91%|█████████▏| 9508/10395 [27:12:08<2:37:26, 10.65s/it]                                                         {'loss': 0.7628, 'learning_rate': 3.7946479198319063e-07, 'epoch': 0.91}
 91%|█████████▏| 9508/10395 [27:12:08<2:37:26, 10.65s/it] 91%|█████████▏| 9509/10395 [27:12:15<2:21:32,  9.59s/it]                                                         {'loss': 0.8884, 'learning_rate': 3.786150977806302e-07, 'epoch': 0.91}
 91%|█████████▏| 9509/10395 [27:12:15<2:21:32,  9.59s/it] 91%|█████████▏| 9510/10395 [27:12:31<2:48:08, 11.40s/it]                                                         {'loss': 0.3813, 'learning_rate': 3.7776633760155944e-07, 'epoch': 0.91}
 91%|█████████▏| 9510/10395 [27:12:31<2:48:08, 11.40s/it] 91%|█████████▏| 9511/10395 [27:12:38<2:30:43, 10.23s/it]                                                         {'loss': 0.8874, 'learning_rate': 3.7691851152836577e-07, 'epoch': 0.91}
 91%|█████████▏| 9511/10395 [27:12:38<2:30:43, 10.23s/it] 92%|█████████▏| 9512/10395 [27:12:47<2:24:34,  9.82s/it]                                                         {'loss': 0.8477, 'learning_rate': 3.760716196433589e-07, 'epoch': 0.92}
 92%|█████████▏| 9512/10395 [27:12:47<2:24:34,  9.82s/it] 92%|█████████▏| 9513/10395 [27:12:55<2:14:53,  9.18s/it]                                                         {'loss': 0.8492, 'learning_rate': 3.752256620287542e-07, 'epoch': 0.92}
 92%|█████████▏| 9513/10395 [27:12:55<2:14:53,  9.18s/it] 92%|█████████▏| 9514/10395 [27:13:03<2:10:03,  8.86s/it]                                                         {'loss': 0.8057, 'learning_rate': 3.7438063876667375e-07, 'epoch': 0.92}
 92%|█████████▏| 9514/10395 [27:13:03<2:10:03,  8.86s/it] 92%|█████████▏| 9515/10395 [27:13:20<2:43:55, 11.18s/it]                                                         {'loss': 0.3174, 'learning_rate': 3.7353654993915077e-07, 'epoch': 0.92}
 92%|█████████▏| 9515/10395 [27:13:20<2:43:55, 11.18s/it] 92%|█████████▏| 9516/10395 [27:13:27<2:26:56, 10.03s/it]                                                         {'loss': 0.8676, 'learning_rate': 3.7269339562812646e-07, 'epoch': 0.92}
 92%|█████████▏| 9516/10395 [27:13:27<2:26:56, 10.03s/it] 92%|█████████▏| 9517/10395 [27:13:35<2:16:43,  9.34s/it]                                                         {'loss': 0.8922, 'learning_rate': 3.718511759154553e-07, 'epoch': 0.92}
 92%|█████████▏| 9517/10395 [27:13:35<2:16:43,  9.34s/it] 92%|█████████▏| 9518/10395 [27:13:43<2:12:30,  9.07s/it]                                                         {'loss': 0.8612, 'learning_rate': 3.710098908828963e-07, 'epoch': 0.92}
 92%|█████████▏| 9518/10395 [27:13:43<2:12:30,  9.07s/it] 92%|█████████▏| 9519/10395 [27:13:50<2:05:14,  8.58s/it]                                                         {'loss': 0.853, 'learning_rate': 3.7016954061211975e-07, 'epoch': 0.92}
 92%|█████████▏| 9519/10395 [27:13:50<2:05:14,  8.58s/it] 92%|█████████▏| 9520/10395 [27:13:58<1:59:26,  8.19s/it]                                                         {'loss': 0.8574, 'learning_rate': 3.693301251847037e-07, 'epoch': 0.92}
 92%|█████████▏| 9520/10395 [27:13:58<1:59:26,  8.19s/it] 92%|█████████▏| 9521/10395 [27:14:06<1:59:57,  8.23s/it]                                                         {'loss': 0.8117, 'learning_rate': 3.684916446821407e-07, 'epoch': 0.92}
 92%|█████████▏| 9521/10395 [27:14:06<1:59:57,  8.23s/it] 92%|█████████▏| 9522/10395 [27:14:16<2:05:08,  8.60s/it]                                                         {'loss': 0.8281, 'learning_rate': 3.676540991858235e-07, 'epoch': 0.92}
 92%|█████████▏| 9522/10395 [27:14:16<2:05:08,  8.60s/it] 92%|█████████▏| 9523/10395 [27:14:24<2:06:05,  8.68s/it]                                                         {'loss': 0.8614, 'learning_rate': 3.668174887770648e-07, 'epoch': 0.92}
 92%|█████████▏| 9523/10395 [27:14:24<2:06:05,  8.68s/it] 92%|█████████▏| 9524/10395 [27:14:33<2:05:05,  8.62s/it]                                                         {'loss': 0.8201, 'learning_rate': 3.659818135370763e-07, 'epoch': 0.92}
 92%|█████████▏| 9524/10395 [27:14:33<2:05:05,  8.62s/it] 92%|█████████▏| 9525/10395 [27:14:40<1:59:58,  8.27s/it]                                                         {'loss': 0.862, 'learning_rate': 3.6514707354698644e-07, 'epoch': 0.92}
 92%|█████████▏| 9525/10395 [27:14:40<1:59:58,  8.27s/it] 92%|█████████▏| 9526/10395 [27:14:49<2:02:08,  8.43s/it]                                                         {'loss': 0.8117, 'learning_rate': 3.6431326888782924e-07, 'epoch': 0.92}
 92%|█████████▏| 9526/10395 [27:14:49<2:02:08,  8.43s/it] 92%|█████████▏| 9527/10395 [27:14:57<1:57:22,  8.11s/it]                                                         {'loss': 0.901, 'learning_rate': 3.634803996405467e-07, 'epoch': 0.92}
 92%|█████████▏| 9527/10395 [27:14:57<1:57:22,  8.11s/it] 92%|█████████▏| 9528/10395 [27:15:05<1:56:49,  8.09s/it]                                                         {'loss': 0.8637, 'learning_rate': 3.62648465885993e-07, 'epoch': 0.92}
 92%|█████████▏| 9528/10395 [27:15:05<1:56:49,  8.09s/it] 92%|█████████▏| 9529/10395 [27:15:13<1:56:13,  8.05s/it]                                                         {'loss': 0.7902, 'learning_rate': 3.6181746770493355e-07, 'epoch': 0.92}
 92%|█████████▏| 9529/10395 [27:15:13<1:56:13,  8.05s/it] 92%|█████████▏| 9530/10395 [27:15:21<1:57:57,  8.18s/it]                                                         {'loss': 0.8833, 'learning_rate': 3.6098740517803596e-07, 'epoch': 0.92}
 92%|█████████▏| 9530/10395 [27:15:21<1:57:57,  8.18s/it] 92%|█████████▏| 9531/10395 [27:15:28<1:54:07,  7.92s/it]                                                         {'loss': 0.903, 'learning_rate': 3.6015827838588366e-07, 'epoch': 0.92}
 92%|█████████▏| 9531/10395 [27:15:28<1:54:07,  7.92s/it] 92%|█████████▏| 9532/10395 [27:15:36<1:51:24,  7.75s/it]                                                         {'loss': 0.8859, 'learning_rate': 3.593300874089656e-07, 'epoch': 0.92}
 92%|█████████▏| 9532/10395 [27:15:36<1:51:24,  7.75s/it] 92%|█████████▏| 9533/10395 [27:15:43<1:49:04,  7.59s/it]                                                         {'loss': 0.8922, 'learning_rate': 3.5850283232767844e-07, 'epoch': 0.92}
 92%|█████████▏| 9533/10395 [27:15:43<1:49:04,  7.59s/it] 92%|█████████▏| 9534/10395 [27:15:50<1:49:00,  7.60s/it]                                                         {'loss': 0.9183, 'learning_rate': 3.5767651322233367e-07, 'epoch': 0.92}
 92%|█████████▏| 9534/10395 [27:15:50<1:49:00,  7.60s/it] 92%|█████████▏| 9535/10395 [27:15:58<1:50:28,  7.71s/it]                                                         {'loss': 0.7509, 'learning_rate': 3.5685113017314697e-07, 'epoch': 0.92}
 92%|█████████▏| 9535/10395 [27:15:58<1:50:28,  7.71s/it] 92%|█████████▏| 9536/10395 [27:16:06<1:49:49,  7.67s/it]                                                         {'loss': 0.8097, 'learning_rate': 3.560266832602444e-07, 'epoch': 0.92}
 92%|█████████▏| 9536/10395 [27:16:06<1:49:49,  7.67s/it] 92%|█████████▏| 9537/10395 [27:16:14<1:50:47,  7.75s/it]                                                         {'loss': 0.8545, 'learning_rate': 3.55203172563664e-07, 'epoch': 0.92}
 92%|█████████▏| 9537/10395 [27:16:14<1:50:47,  7.75s/it] 92%|█████████▏| 9538/10395 [27:16:22<1:51:01,  7.77s/it]                                                         {'loss': 0.8477, 'learning_rate': 3.5438059816334636e-07, 'epoch': 0.92}
 92%|█████████▏| 9538/10395 [27:16:22<1:51:01,  7.77s/it] 92%|█████████▏| 9539/10395 [27:16:29<1:50:06,  7.72s/it]                                                         {'loss': 0.8403, 'learning_rate': 3.535589601391498e-07, 'epoch': 0.92}
 92%|█████████▏| 9539/10395 [27:16:29<1:50:06,  7.72s/it] 92%|█████████▏| 9540/10395 [27:16:38<1:51:50,  7.85s/it]                                                         {'loss': 0.8676, 'learning_rate': 3.527382585708339e-07, 'epoch': 0.92}
 92%|█████████▏| 9540/10395 [27:16:38<1:51:50,  7.85s/it] 92%|█████████▏| 9541/10395 [27:16:45<1:50:49,  7.79s/it]                                                         {'loss': 0.8939, 'learning_rate': 3.519184935380704e-07, 'epoch': 0.92}
 92%|█████████▏| 9541/10395 [27:16:45<1:50:49,  7.79s/it] 92%|█████████▏| 9542/10395 [27:17:01<2:25:19, 10.22s/it]                                                         {'loss': 0.3365, 'learning_rate': 3.5109966512044344e-07, 'epoch': 0.92}
 92%|█████████▏| 9542/10395 [27:17:01<2:25:19, 10.22s/it] 92%|█████████▏| 9543/10395 [27:17:10<2:19:27,  9.82s/it]                                                         {'loss': 0.791, 'learning_rate': 3.502817733974395e-07, 'epoch': 0.92}
 92%|█████████▏| 9543/10395 [27:17:10<2:19:27,  9.82s/it] 92%|█████████▏| 9544/10395 [27:17:18<2:09:51,  9.16s/it]                                                         {'loss': 0.9283, 'learning_rate': 3.494648184484606e-07, 'epoch': 0.92}
 92%|█████████▏| 9544/10395 [27:17:18<2:09:51,  9.16s/it] 92%|█████████▏| 9545/10395 [27:17:25<2:03:28,  8.72s/it]                                                         {'loss': 0.8288, 'learning_rate': 3.4864880035281323e-07, 'epoch': 0.92}
 92%|█████████▏| 9545/10395 [27:17:25<2:03:28,  8.72s/it] 92%|█████████▏| 9546/10395 [27:17:33<1:59:04,  8.42s/it]                                                         {'loss': 0.9068, 'learning_rate': 3.478337191897152e-07, 'epoch': 0.92}
 92%|█████████▏| 9546/10395 [27:17:33<1:59:04,  8.42s/it] 92%|█████████▏| 9547/10395 [27:17:41<1:58:04,  8.35s/it]                                                         {'loss': 0.909, 'learning_rate': 3.470195750382943e-07, 'epoch': 0.92}
 92%|█████████▏| 9547/10395 [27:17:41<1:58:04,  8.35s/it] 92%|█████████▏| 9548/10395 [27:17:49<1:55:11,  8.16s/it]                                                         {'loss': 0.8655, 'learning_rate': 3.46206367977584e-07, 'epoch': 0.92}
 92%|█████████▏| 9548/10395 [27:17:49<1:55:11,  8.16s/it] 92%|█████████▏| 9549/10395 [27:18:06<2:34:36, 10.97s/it]                                                         {'loss': 0.3977, 'learning_rate': 3.453940980865289e-07, 'epoch': 0.92}
 92%|█████████▏| 9549/10395 [27:18:06<2:34:36, 10.97s/it] 92%|█████████▏| 9550/10395 [27:18:24<3:01:18, 12.87s/it]                                                         {'loss': 0.3652, 'learning_rate': 3.445827654439815e-07, 'epoch': 0.92}
 92%|█████████▏| 9550/10395 [27:18:24<3:01:18, 12.87s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 92%|█████████▏| 9551/10395 [27:20:05<9:12:53, 39.31s/it]                                                         {'loss': 0.8699, 'learning_rate': 3.437723701287077e-07, 'epoch': 0.92}
 92%|█████████▏| 9551/10395 [27:20:05<9:12:53, 39.31s/it] 92%|█████████▏| 9552/10395 [27:20:12<6:59:11, 29.84s/it]                                                         {'loss': 0.8598, 'learning_rate': 3.4296291221937563e-07, 'epoch': 0.92}
 92%|█████████▏| 9552/10395 [27:20:12<6:59:11, 29.84s/it] 92%|█████████▏| 9553/10395 [27:20:20<5:25:01, 23.16s/it]                                                         {'loss': 0.9208, 'learning_rate': 3.42154391794568e-07, 'epoch': 0.92}
 92%|█████████▏| 9553/10395 [27:20:20<5:25:01, 23.16s/it] 92%|█████████▏| 9554/10395 [27:20:28<4:21:00, 18.62s/it]                                                         {'loss': 0.8155, 'learning_rate': 3.4134680893277315e-07, 'epoch': 0.92}
 92%|█████████▏| 9554/10395 [27:20:28<4:21:00, 18.62s/it] 92%|█████████▏| 9555/10395 [27:20:37<3:38:20, 15.60s/it]                                                         {'loss': 0.8696, 'learning_rate': 3.405401637123873e-07, 'epoch': 0.92}
 92%|█████████▏| 9555/10395 [27:20:37<3:38:20, 15.60s/it] 92%|█████████▏| 9556/10395 [27:20:44<3:05:05, 13.24s/it]                                                         {'loss': 0.9471, 'learning_rate': 3.397344562117222e-07, 'epoch': 0.92}
 92%|█████████▏| 9556/10395 [27:20:44<3:05:05, 13.24s/it] 92%|█████████▏| 9557/10395 [27:20:53<2:44:41, 11.79s/it]                                                         {'loss': 0.8024, 'learning_rate': 3.3892968650899084e-07, 'epoch': 0.92}
 92%|█████████▏| 9557/10395 [27:20:53<2:44:41, 11.79s/it] 92%|█████████▏| 9558/10395 [27:21:01<2:29:51, 10.74s/it]                                                         {'loss': 0.8553, 'learning_rate': 3.3812585468231963e-07, 'epoch': 0.92}
 92%|█████████▏| 9558/10395 [27:21:01<2:29:51, 10.74s/it] 92%|█████████▏| 9559/10395 [27:21:09<2:16:21,  9.79s/it]                                                         {'loss': 0.839, 'learning_rate': 3.373229608097439e-07, 'epoch': 0.92}
 92%|█████████▏| 9559/10395 [27:21:09<2:16:21,  9.79s/it] 92%|█████████▏| 9560/10395 [27:21:16<2:07:50,  9.19s/it]                                                         {'loss': 0.8991, 'learning_rate': 3.365210049692047e-07, 'epoch': 0.92}
 92%|█████████▏| 9560/10395 [27:21:16<2:07:50,  9.19s/it] 92%|█████████▏| 9561/10395 [27:21:24<2:00:28,  8.67s/it]                                                         {'loss': 0.8643, 'learning_rate': 3.3571998723855634e-07, 'epoch': 0.92}
 92%|█████████▏| 9561/10395 [27:21:24<2:00:28,  8.67s/it] 92%|█████████▏| 9562/10395 [27:21:32<1:57:42,  8.48s/it]                                                         {'loss': 0.8154, 'learning_rate': 3.3491990769556e-07, 'epoch': 0.92}
 92%|█████████▏| 9562/10395 [27:21:32<1:57:42,  8.48s/it] 92%|█████████▏| 9563/10395 [27:21:40<1:53:57,  8.22s/it]                                                         {'loss': 0.8214, 'learning_rate': 3.341207664178825e-07, 'epoch': 0.92}
 92%|█████████▏| 9563/10395 [27:21:40<1:53:57,  8.22s/it] 92%|█████████▏| 9564/10395 [27:21:46<1:48:36,  7.84s/it]                                                         {'loss': 0.9761, 'learning_rate': 3.333225634831072e-07, 'epoch': 0.92}
 92%|█████████▏| 9564/10395 [27:21:46<1:48:36,  7.84s/it] 92%|█████████▏| 9565/10395 [27:21:54<1:46:41,  7.71s/it]                                                         {'loss': 0.8824, 'learning_rate': 3.3252529896871777e-07, 'epoch': 0.92}
 92%|█████████▏| 9565/10395 [27:21:54<1:46:41,  7.71s/it] 92%|█████████▏| 9566/10395 [27:22:02<1:48:21,  7.84s/it]                                                         {'loss': 0.853, 'learning_rate': 3.3172897295211225e-07, 'epoch': 0.92}
 92%|█████████▏| 9566/10395 [27:22:02<1:48:21,  7.84s/it] 92%|█████████▏| 9567/10395 [27:22:11<1:52:52,  8.18s/it]                                                         {'loss': 0.7406, 'learning_rate': 3.3093358551059887e-07, 'epoch': 0.92}
 92%|█████████▏| 9567/10395 [27:22:11<1:52:52,  8.18s/it] 92%|█████████▏| 9568/10395 [27:22:20<1:57:21,  8.51s/it]                                                         {'loss': 0.8573, 'learning_rate': 3.3013913672138906e-07, 'epoch': 0.92}
 92%|█████████▏| 9568/10395 [27:22:20<1:57:21,  8.51s/it] 92%|█████████▏| 9569/10395 [27:22:28<1:53:24,  8.24s/it]                                                         {'loss': 0.8426, 'learning_rate': 3.2934562666160794e-07, 'epoch': 0.92}
 92%|█████████▏| 9569/10395 [27:22:28<1:53:24,  8.24s/it] 92%|█████████▏| 9570/10395 [27:22:36<1:50:45,  8.06s/it]                                                         {'loss': 0.8636, 'learning_rate': 3.2855305540828717e-07, 'epoch': 0.92}
 92%|█████████▏| 9570/10395 [27:22:36<1:50:45,  8.06s/it] 92%|█████████▏| 9571/10395 [27:22:43<1:48:51,  7.93s/it]                                                         {'loss': 0.895, 'learning_rate': 3.2776142303836746e-07, 'epoch': 0.92}
 92%|█████████▏| 9571/10395 [27:22:43<1:48:51,  7.93s/it] 92%|█████████▏| 9572/10395 [27:22:51<1:49:13,  7.96s/it]                                                         {'loss': 0.9175, 'learning_rate': 3.269707296286995e-07, 'epoch': 0.92}
 92%|█████████▏| 9572/10395 [27:22:51<1:49:13,  7.96s/it] 92%|█████████▏| 9573/10395 [27:23:00<1:52:16,  8.19s/it]                                                         {'loss': 0.7569, 'learning_rate': 3.2618097525604076e-07, 'epoch': 0.92}
 92%|█████████▏| 9573/10395 [27:23:00<1:52:16,  8.19s/it] 92%|█████████▏| 9574/10395 [27:23:07<1:48:29,  7.93s/it]                                                         {'loss': 0.8188, 'learning_rate': 3.2539215999706e-07, 'epoch': 0.92}
 92%|█████████▏| 9574/10395 [27:23:07<1:48:29,  7.93s/it] 92%|█████████▏| 9575/10395 [27:23:15<1:49:17,  8.00s/it]                                                         {'loss': 0.8522, 'learning_rate': 3.246042839283348e-07, 'epoch': 0.92}
 92%|█████████▏| 9575/10395 [27:23:15<1:49:17,  8.00s/it] 92%|█████████▏| 9576/10395 [27:23:23<1:49:28,  8.02s/it]                                                         {'loss': 0.8522, 'learning_rate': 3.238173471263495e-07, 'epoch': 0.92}
 92%|█████████▏| 9576/10395 [27:23:23<1:49:28,  8.02s/it] 92%|█████████▏| 9577/10395 [27:23:31<1:48:41,  7.97s/it]                                                         {'loss': 0.8432, 'learning_rate': 3.230313496674975e-07, 'epoch': 0.92}
 92%|█████████▏| 9577/10395 [27:23:31<1:48:41,  7.97s/it] 92%|█████████▏| 9578/10395 [27:23:40<1:49:58,  8.08s/it]                                                         {'loss': 0.8455, 'learning_rate': 3.222462916280822e-07, 'epoch': 0.92}
 92%|█████████▏| 9578/10395 [27:23:40<1:49:58,  8.08s/it] 92%|█████████▏| 9579/10395 [27:23:47<1:47:20,  7.89s/it]                                                         {'loss': 0.9091, 'learning_rate': 3.2146217308431484e-07, 'epoch': 0.92}
 92%|█████████▏| 9579/10395 [27:23:47<1:47:20,  7.89s/it] 92%|█████████▏| 9580/10395 [27:23:55<1:46:43,  7.86s/it]                                                         {'loss': 0.8017, 'learning_rate': 3.2067899411231783e-07, 'epoch': 0.92}
 92%|█████████▏| 9580/10395 [27:23:55<1:46:43,  7.86s/it] 92%|█████████▏| 9581/10395 [27:24:04<1:50:15,  8.13s/it]                                                         {'loss': 0.794, 'learning_rate': 3.1989675478811824e-07, 'epoch': 0.92}
 92%|█████████▏| 9581/10395 [27:24:04<1:50:15,  8.13s/it] 92%|█████████▏| 9582/10395 [27:24:11<1:46:59,  7.90s/it]                                                         {'loss': 0.9133, 'learning_rate': 3.1911545518765517e-07, 'epoch': 0.92}
 92%|█████████▏| 9582/10395 [27:24:11<1:46:59,  7.90s/it] 92%|█████████▏| 9583/10395 [27:24:19<1:46:14,  7.85s/it]                                                         {'loss': 0.8751, 'learning_rate': 3.183350953867781e-07, 'epoch': 0.92}
 92%|█████████▏| 9583/10395 [27:24:19<1:46:14,  7.85s/it] 92%|█████████▏| 9584/10395 [27:24:37<2:26:59, 10.87s/it]                                                         {'loss': 0.3405, 'learning_rate': 3.175556754612374e-07, 'epoch': 0.92}
 92%|█████████▏| 9584/10395 [27:24:37<2:26:59, 10.87s/it] 92%|█████████▏| 9585/10395 [27:24:45<2:16:00, 10.08s/it]                                                         {'loss': 0.8061, 'learning_rate': 3.1677719548670047e-07, 'epoch': 0.92}
 92%|█████████▏| 9585/10395 [27:24:45<2:16:00, 10.08s/it] 92%|█████████▏| 9586/10395 [27:24:53<2:07:15,  9.44s/it]                                                         {'loss': 0.7653, 'learning_rate': 3.159996555387412e-07, 'epoch': 0.92}
 92%|█████████▏| 9586/10395 [27:24:53<2:07:15,  9.44s/it] 92%|█████████▏| 9587/10395 [27:25:01<2:01:43,  9.04s/it]                                                         {'loss': 0.9055, 'learning_rate': 3.152230556928393e-07, 'epoch': 0.92}
 92%|█████████▏| 9587/10395 [27:25:01<2:01:43,  9.04s/it] 92%|█████████▏| 9588/10395 [27:25:10<2:01:30,  9.03s/it]                                                         {'loss': 0.805, 'learning_rate': 3.1444739602438877e-07, 'epoch': 0.92}
 92%|█████████▏| 9588/10395 [27:25:10<2:01:30,  9.03s/it] 92%|█████████▏| 9589/10395 [27:25:18<1:57:24,  8.74s/it]                                                         {'loss': 0.9097, 'learning_rate': 3.1367267660868507e-07, 'epoch': 0.92}
 92%|█████████▏| 9589/10395 [27:25:18<1:57:24,  8.74s/it] 92%|█████████▏| 9590/10395 [27:25:25<1:50:44,  8.25s/it]                                                         {'loss': 0.9041, 'learning_rate': 3.1289889752093905e-07, 'epoch': 0.92}
 92%|█████████▏| 9590/10395 [27:25:25<1:50:44,  8.25s/it] 92%|█████████▏| 9591/10395 [27:25:33<1:49:51,  8.20s/it]                                                         {'loss': 0.9656, 'learning_rate': 3.1212605883626734e-07, 'epoch': 0.92}
 92%|█████████▏| 9591/10395 [27:25:33<1:49:51,  8.20s/it] 92%|█████████▏| 9592/10395 [27:25:42<1:52:21,  8.40s/it]                                                         {'loss': 0.7697, 'learning_rate': 3.1135416062969435e-07, 'epoch': 0.92}
 92%|█████████▏| 9592/10395 [27:25:42<1:52:21,  8.40s/it] 92%|█████████▏| 9593/10395 [27:25:51<1:53:08,  8.46s/it]                                                         {'loss': 0.7993, 'learning_rate': 3.105832029761535e-07, 'epoch': 0.92}
 92%|█████████▏| 9593/10395 [27:25:51<1:53:08,  8.46s/it] 92%|█████████▏| 9594/10395 [27:25:58<1:49:29,  8.20s/it]                                                         {'loss': 0.8212, 'learning_rate': 3.0981318595049046e-07, 'epoch': 0.92}
 92%|█████████▏| 9594/10395 [27:25:58<1:49:29,  8.20s/it] 92%|█████████▏| 9595/10395 [27:26:06<1:45:59,  7.95s/it]                                                         {'loss': 0.8088, 'learning_rate': 3.0904410962745437e-07, 'epoch': 0.92}
 92%|█████████▏| 9595/10395 [27:26:06<1:45:59,  7.95s/it] 92%|█████████▏| 9596/10395 [27:26:13<1:43:31,  7.77s/it]                                                         {'loss': 0.8606, 'learning_rate': 3.082759740817065e-07, 'epoch': 0.92}
 92%|█████████▏| 9596/10395 [27:26:13<1:43:31,  7.77s/it] 92%|█████████▏| 9597/10395 [27:26:20<1:42:07,  7.68s/it]                                                         {'loss': 0.8576, 'learning_rate': 3.075087793878162e-07, 'epoch': 0.92}
 92%|█████████▏| 9597/10395 [27:26:20<1:42:07,  7.68s/it] 92%|█████████▏| 9598/10395 [27:26:28<1:40:09,  7.54s/it]                                                         {'loss': 0.9153, 'learning_rate': 3.0674252562026053e-07, 'epoch': 0.92}
 92%|█████████▏| 9598/10395 [27:26:28<1:40:09,  7.54s/it] 92%|█████████▏| 9599/10395 [27:26:36<1:44:30,  7.88s/it]                                                         {'loss': 0.859, 'learning_rate': 3.059772128534266e-07, 'epoch': 0.92}
 92%|█████████▏| 9599/10395 [27:26:36<1:44:30,  7.88s/it] 92%|█████████▏| 9600/10395 [27:26:45<1:45:40,  7.98s/it]                                                         {'loss': 0.8271, 'learning_rate': 3.052128411616073e-07, 'epoch': 0.92}
 92%|█████████▏| 9600/10395 [27:26:45<1:45:40,  7.98s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 92%|█████████▏| 9601/10395 [27:28:30<8:10:54, 37.10s/it]                                                         {'loss': 0.814, 'learning_rate': 3.044494106190077e-07, 'epoch': 0.92}
 92%|█████████▏| 9601/10395 [27:28:30<8:10:54, 37.10s/it] 92%|█████████▏| 9602/10395 [27:28:37<6:13:27, 28.26s/it]                                                         {'loss': 0.8517, 'learning_rate': 3.0368692129974176e-07, 'epoch': 0.92}
 92%|█████████▏| 9602/10395 [27:28:37<6:13:27, 28.26s/it] 92%|█████████▏| 9603/10395 [27:28:46<4:55:20, 22.37s/it]                                                         {'loss': 0.8334, 'learning_rate': 3.029253732778259e-07, 'epoch': 0.92}
 92%|█████████▏| 9603/10395 [27:28:46<4:55:20, 22.37s/it] 92%|█████████▏| 9604/10395 [27:28:54<4:00:19, 18.23s/it]                                                         {'loss': 0.8833, 'learning_rate': 3.021647666271943e-07, 'epoch': 0.92}
 92%|█████████▏| 9604/10395 [27:28:54<4:00:19, 18.23s/it] 92%|█████████▏| 9605/10395 [27:29:02<3:19:03, 15.12s/it]                                                         {'loss': 0.8551, 'learning_rate': 3.0140510142168234e-07, 'epoch': 0.92}
 92%|█████████▏| 9605/10395 [27:29:02<3:19:03, 15.12s/it] 92%|█████████▏| 9606/10395 [27:29:10<2:51:15, 13.02s/it]                                                         {'loss': 0.8175, 'learning_rate': 3.0064637773503547e-07, 'epoch': 0.92}
 92%|█████████▏| 9606/10395 [27:29:10<2:51:15, 13.02s/it] 92%|█████████▏| 9607/10395 [27:29:18<2:30:32, 11.46s/it]                                                         {'loss': 0.8072, 'learning_rate': 2.9988859564091257e-07, 'epoch': 0.92}
 92%|█████████▏| 9607/10395 [27:29:18<2:30:32, 11.46s/it] 92%|█████████▏| 9608/10395 [27:29:26<2:16:09, 10.38s/it]                                                         {'loss': 0.7909, 'learning_rate': 2.9913175521287475e-07, 'epoch': 0.92}
 92%|█████████▏| 9608/10395 [27:29:26<2:16:09, 10.38s/it] 92%|█████████▏| 9609/10395 [27:29:33<2:03:40,  9.44s/it]                                                         {'loss': 0.8874, 'learning_rate': 2.983758565243944e-07, 'epoch': 0.92}
 92%|█████████▏| 9609/10395 [27:29:33<2:03:40,  9.44s/it] 92%|█████████▏| 9610/10395 [27:29:41<1:55:34,  8.83s/it]                                                         {'loss': 0.8716, 'learning_rate': 2.97620899648855e-07, 'epoch': 0.92}
 92%|█████████▏| 9610/10395 [27:29:41<1:55:34,  8.83s/it] 92%|█████████▏| 9611/10395 [27:29:48<1:49:17,  8.36s/it]                                                         {'loss': 0.8669, 'learning_rate': 2.968668846595435e-07, 'epoch': 0.92}
 92%|█████████▏| 9611/10395 [27:29:48<1:49:17,  8.36s/it] 92%|█████████▏| 9612/10395 [27:29:56<1:46:21,  8.15s/it]                                                         {'loss': 0.8726, 'learning_rate': 2.9611381162966024e-07, 'epoch': 0.92}
 92%|█████████▏| 9612/10395 [27:29:56<1:46:21,  8.15s/it] 92%|█████████▏| 9613/10395 [27:30:03<1:44:58,  8.05s/it]                                                         {'loss': 0.906, 'learning_rate': 2.953616806323112e-07, 'epoch': 0.92}
 92%|█████████▏| 9613/10395 [27:30:04<1:44:58,  8.05s/it] 92%|█████████▏| 9614/10395 [27:30:12<1:46:45,  8.20s/it]                                                         {'loss': 0.8988, 'learning_rate': 2.94610491740509e-07, 'epoch': 0.92}
 92%|█████████▏| 9614/10395 [27:30:12<1:46:45,  8.20s/it] 92%|█████████▏| 9615/10395 [27:30:21<1:48:24,  8.34s/it]                                                         {'loss': 0.8231, 'learning_rate': 2.9386024502718214e-07, 'epoch': 0.92}
 92%|█████████▏| 9615/10395 [27:30:21<1:48:24,  8.34s/it] 93%|█████████▎| 9616/10395 [27:30:28<1:46:01,  8.17s/it]                                                         {'loss': 0.8364, 'learning_rate': 2.931109405651589e-07, 'epoch': 0.93}
 93%|█████████▎| 9616/10395 [27:30:28<1:46:01,  8.17s/it] 93%|█████████▎| 9617/10395 [27:30:36<1:41:42,  7.84s/it]                                                         {'loss': 0.852, 'learning_rate': 2.923625784271822e-07, 'epoch': 0.93}
 93%|█████████▎| 9617/10395 [27:30:36<1:41:42,  7.84s/it] 93%|█████████▎| 9618/10395 [27:30:44<1:43:02,  7.96s/it]                                                         {'loss': 0.8706, 'learning_rate': 2.9161515868590285e-07, 'epoch': 0.93}
 93%|█████████▎| 9618/10395 [27:30:44<1:43:02,  7.96s/it] 93%|█████████▎| 9619/10395 [27:30:53<1:45:59,  8.20s/it]                                                         {'loss': 0.7912, 'learning_rate': 2.90868681413875e-07, 'epoch': 0.93}
 93%|█████████▎| 9619/10395 [27:30:53<1:45:59,  8.20s/it] 93%|█████████▎| 9620/10395 [27:31:00<1:43:15,  7.99s/it]                                                         {'loss': 0.8931, 'learning_rate': 2.9012314668356854e-07, 'epoch': 0.93}
 93%|█████████▎| 9620/10395 [27:31:00<1:43:15,  7.99s/it] 93%|█████████▎| 9621/10395 [27:31:08<1:42:31,  7.95s/it]                                                         {'loss': 0.8322, 'learning_rate': 2.8937855456735665e-07, 'epoch': 0.93}
 93%|█████████▎| 9621/10395 [27:31:08<1:42:31,  7.95s/it] 93%|█████████▎| 9622/10395 [27:31:15<1:40:16,  7.78s/it]                                                         {'loss': 0.8895, 'learning_rate': 2.886349051375215e-07, 'epoch': 0.93}
 93%|█████████▎| 9622/10395 [27:31:15<1:40:16,  7.78s/it] 93%|█████████▎| 9623/10395 [27:31:23<1:39:43,  7.75s/it]                                                         {'loss': 0.8394, 'learning_rate': 2.878921984662575e-07, 'epoch': 0.93}
 93%|█████████▎| 9623/10395 [27:31:23<1:39:43,  7.75s/it] 93%|█████████▎| 9624/10395 [27:31:30<1:38:18,  7.65s/it]                                                         {'loss': 0.9015, 'learning_rate': 2.871504346256637e-07, 'epoch': 0.93}
 93%|█████████▎| 9624/10395 [27:31:30<1:38:18,  7.65s/it] 93%|█████████▎| 9625/10395 [27:31:38<1:37:02,  7.56s/it]                                                         {'loss': 0.8516, 'learning_rate': 2.864096136877492e-07, 'epoch': 0.93}
 93%|█████████▎| 9625/10395 [27:31:38<1:37:02,  7.56s/it] 93%|█████████▎| 9626/10395 [27:31:45<1:36:02,  7.49s/it]                                                         {'loss': 0.8827, 'learning_rate': 2.856697357244331e-07, 'epoch': 0.93}
 93%|█████████▎| 9626/10395 [27:31:45<1:36:02,  7.49s/it] 93%|█████████▎| 9627/10395 [27:31:52<1:35:35,  7.47s/it]                                                         {'loss': 0.8786, 'learning_rate': 2.849308008075369e-07, 'epoch': 0.93}
 93%|█████████▎| 9627/10395 [27:31:52<1:35:35,  7.47s/it] 93%|█████████▎| 9628/10395 [27:32:00<1:33:58,  7.35s/it]                                                         {'loss': 0.8916, 'learning_rate': 2.8419280900879975e-07, 'epoch': 0.93}
 93%|█████████▎| 9628/10395 [27:32:00<1:33:58,  7.35s/it] 93%|█████████▎| 9629/10395 [27:32:08<1:36:38,  7.57s/it]                                                         {'loss': 0.833, 'learning_rate': 2.834557603998611e-07, 'epoch': 0.93}
 93%|█████████▎| 9629/10395 [27:32:08<1:36:38,  7.57s/it] 93%|█████████▎| 9630/10395 [27:32:16<1:38:53,  7.76s/it]                                                         {'loss': 0.8498, 'learning_rate': 2.827196550522726e-07, 'epoch': 0.93}
 93%|█████████▎| 9630/10395 [27:32:16<1:38:53,  7.76s/it] 93%|█████████▎| 9631/10395 [27:32:23<1:37:07,  7.63s/it]                                                         {'loss': 0.9223, 'learning_rate': 2.8198449303749374e-07, 'epoch': 0.93}
 93%|█████████▎| 9631/10395 [27:32:23<1:37:07,  7.63s/it] 93%|█████████▎| 9632/10395 [27:32:31<1:39:34,  7.83s/it]                                                         {'loss': 0.7812, 'learning_rate': 2.81250274426893e-07, 'epoch': 0.93}
 93%|█████████▎| 9632/10395 [27:32:31<1:39:34,  7.83s/it] 93%|█████████▎| 9633/10395 [27:32:39<1:38:47,  7.78s/it]                                                         {'loss': 0.8224, 'learning_rate': 2.805169992917467e-07, 'epoch': 0.93}
 93%|█████████▎| 9633/10395 [27:32:39<1:38:47,  7.78s/it] 93%|█████████▎| 9634/10395 [27:32:47<1:38:23,  7.76s/it]                                                         {'loss': 0.8131, 'learning_rate': 2.797846677032401e-07, 'epoch': 0.93}
 93%|█████████▎| 9634/10395 [27:32:47<1:38:23,  7.76s/it] 93%|█████████▎| 9635/10395 [27:32:54<1:37:47,  7.72s/it]                                                         {'loss': 0.847, 'learning_rate': 2.790532797324663e-07, 'epoch': 0.93}
 93%|█████████▎| 9635/10395 [27:32:54<1:37:47,  7.72s/it] 93%|█████████▎| 9636/10395 [27:33:03<1:40:31,  7.95s/it]                                                         {'loss': 0.8906, 'learning_rate': 2.7832283545042415e-07, 'epoch': 0.93}
 93%|█████████▎| 9636/10395 [27:33:03<1:40:31,  7.95s/it] 93%|█████████▎| 9637/10395 [27:33:13<1:48:15,  8.57s/it]                                                         {'loss': 0.8728, 'learning_rate': 2.77593334928028e-07, 'epoch': 0.93}
 93%|█████████▎| 9637/10395 [27:33:13<1:48:15,  8.57s/it] 93%|█████████▎| 9638/10395 [27:33:21<1:46:12,  8.42s/it]                                                         {'loss': 0.7432, 'learning_rate': 2.7686477823609225e-07, 'epoch': 0.93}
 93%|█████████▎| 9638/10395 [27:33:21<1:46:12,  8.42s/it] 93%|█████████▎| 9639/10395 [27:33:28<1:41:55,  8.09s/it]                                                         {'loss': 0.8101, 'learning_rate': 2.7613716544534596e-07, 'epoch': 0.93}
 93%|█████████▎| 9639/10395 [27:33:28<1:41:55,  8.09s/it] 93%|█████████▎| 9640/10395 [27:33:36<1:40:42,  8.00s/it]                                                         {'loss': 0.8154, 'learning_rate': 2.754104966264248e-07, 'epoch': 0.93}
 93%|█████████▎| 9640/10395 [27:33:36<1:40:42,  8.00s/it] 93%|█████████▎| 9641/10395 [27:33:44<1:39:56,  7.95s/it]                                                         {'loss': 0.8559, 'learning_rate': 2.746847718498691e-07, 'epoch': 0.93}
 93%|█████████▎| 9641/10395 [27:33:44<1:39:56,  7.95s/it] 93%|█████████▎| 9642/10395 [27:33:52<1:40:07,  7.98s/it]                                                         {'loss': 0.8586, 'learning_rate': 2.739599911861346e-07, 'epoch': 0.93}
 93%|█████████▎| 9642/10395 [27:33:52<1:40:07,  7.98s/it] 93%|█████████▎| 9643/10395 [27:34:00<1:38:18,  7.84s/it]                                                         {'loss': 0.9277, 'learning_rate': 2.732361547055795e-07, 'epoch': 0.93}
 93%|█████████▎| 9643/10395 [27:34:00<1:38:18,  7.84s/it] 93%|█████████▎| 9644/10395 [27:34:18<2:17:31, 10.99s/it]                                                         {'loss': 0.3364, 'learning_rate': 2.72513262478471e-07, 'epoch': 0.93}
 93%|█████████▎| 9644/10395 [27:34:18<2:17:31, 10.99s/it] 93%|█████████▎| 9645/10395 [27:34:26<2:07:11, 10.17s/it]                                                         {'loss': 0.8445, 'learning_rate': 2.7179131457498844e-07, 'epoch': 0.93}
 93%|█████████▎| 9645/10395 [27:34:26<2:07:11, 10.17s/it] 93%|█████████▎| 9646/10395 [27:34:34<1:57:10,  9.39s/it]                                                         {'loss': 0.8153, 'learning_rate': 2.7107031106521573e-07, 'epoch': 0.93}
 93%|█████████▎| 9646/10395 [27:34:34<1:57:10,  9.39s/it] 93%|█████████▎| 9647/10395 [27:34:41<1:50:29,  8.86s/it]                                                         {'loss': 0.8644, 'learning_rate': 2.703502520191448e-07, 'epoch': 0.93}
 93%|█████████▎| 9647/10395 [27:34:41<1:50:29,  8.86s/it] 93%|█████████▎| 9648/10395 [27:34:49<1:44:38,  8.40s/it]                                                         {'loss': 0.8759, 'learning_rate': 2.6963113750668066e-07, 'epoch': 0.93}
 93%|█████████▎| 9648/10395 [27:34:49<1:44:38,  8.40s/it] 93%|█████████▎| 9649/10395 [27:34:56<1:40:37,  8.09s/it]                                                         {'loss': 0.8455, 'learning_rate': 2.68912967597631e-07, 'epoch': 0.93}
 93%|█████████▎| 9649/10395 [27:34:56<1:40:37,  8.09s/it] 93%|█████████▎| 9650/10395 [27:35:04<1:39:48,  8.04s/it]                                                         {'loss': 0.8978, 'learning_rate': 2.681957423617165e-07, 'epoch': 0.93}
 93%|█████████▎| 9650/10395 [27:35:04<1:39:48,  8.04s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 93%|█████████▎| 9651/10395 [27:36:46<7:29:39, 36.26s/it]                                                         {'loss': 0.8466, 'learning_rate': 2.674794618685617e-07, 'epoch': 0.93}
 93%|█████████▎| 9651/10395 [27:36:46<7:29:39, 36.26s/it] 93%|█████████▎| 9652/10395 [27:36:54<5:43:25, 27.73s/it]                                                         {'loss': 0.8711, 'learning_rate': 2.667641261877019e-07, 'epoch': 0.93}
 93%|█████████▎| 9652/10395 [27:36:54<5:43:25, 27.73s/it] 93%|█████████▎| 9653/10395 [27:37:01<4:26:43, 21.57s/it]                                                         {'loss': 0.8763, 'learning_rate': 2.6604973538858046e-07, 'epoch': 0.93}
 93%|█████████▎| 9653/10395 [27:37:01<4:26:43, 21.57s/it] 93%|█████████▎| 9654/10395 [27:37:10<3:40:03, 17.82s/it]                                                         {'loss': 0.7716, 'learning_rate': 2.653362895405498e-07, 'epoch': 0.93}
 93%|█████████▎| 9654/10395 [27:37:10<3:40:03, 17.82s/it] 93%|█████████▎| 9655/10395 [27:37:18<3:01:47, 14.74s/it]                                                         {'loss': 0.8981, 'learning_rate': 2.6462378871286777e-07, 'epoch': 0.93}
 93%|█████████▎| 9655/10395 [27:37:18<3:01:47, 14.74s/it] 93%|█████████▎| 9656/10395 [27:37:26<2:36:27, 12.70s/it]                                                         {'loss': 0.8335, 'learning_rate': 2.639122329747057e-07, 'epoch': 0.93}
 93%|█████████▎| 9656/10395 [27:37:26<2:36:27, 12.70s/it] 93%|█████████▎| 9657/10395 [27:37:33<2:18:10, 11.23s/it]                                                         {'loss': 0.8379, 'learning_rate': 2.6320162239513725e-07, 'epoch': 0.93}
 93%|█████████▎| 9657/10395 [27:37:33<2:18:10, 11.23s/it] 93%|█████████▎| 9658/10395 [27:37:41<2:05:36, 10.23s/it]                                                         {'loss': 0.8047, 'learning_rate': 2.6249195704314724e-07, 'epoch': 0.93}
 93%|█████████▎| 9658/10395 [27:37:41<2:05:36, 10.23s/it] 93%|█████████▎| 9659/10395 [27:37:50<1:57:48,  9.60s/it]                                                         {'loss': 0.9119, 'learning_rate': 2.617832369876294e-07, 'epoch': 0.93}
 93%|█████████▎| 9659/10395 [27:37:50<1:57:48,  9.60s/it] 93%|█████████▎| 9660/10395 [27:37:57<1:50:56,  9.06s/it]                                                         {'loss': 0.7958, 'learning_rate': 2.6107546229738433e-07, 'epoch': 0.93}
 93%|█████████▎| 9660/10395 [27:37:57<1:50:56,  9.06s/it] 93%|█████████▎| 9661/10395 [27:38:06<1:48:41,  8.89s/it]                                                         {'loss': 0.8372, 'learning_rate': 2.603686330411215e-07, 'epoch': 0.93}
 93%|█████████▎| 9661/10395 [27:38:06<1:48:41,  8.89s/it] 93%|█████████▎| 9662/10395 [27:38:15<1:48:55,  8.92s/it]                                                         {'loss': 0.851, 'learning_rate': 2.5966274928745705e-07, 'epoch': 0.93}
 93%|█████████▎| 9662/10395 [27:38:15<1:48:55,  8.92s/it] 93%|█████████▎| 9663/10395 [27:38:22<1:43:37,  8.49s/it]                                                         {'loss': 0.8544, 'learning_rate': 2.5895781110491735e-07, 'epoch': 0.93}
 93%|█████████▎| 9663/10395 [27:38:22<1:43:37,  8.49s/it] 93%|█████████▎| 9664/10395 [27:38:30<1:39:33,  8.17s/it]                                                         {'loss': 0.9513, 'learning_rate': 2.5825381856193876e-07, 'epoch': 0.93}
 93%|█████████▎| 9664/10395 [27:38:30<1:39:33,  8.17s/it] 93%|█████████▎| 9665/10395 [27:38:37<1:37:58,  8.05s/it]                                                         {'loss': 0.8839, 'learning_rate': 2.5755077172685995e-07, 'epoch': 0.93}
 93%|█████████▎| 9665/10395 [27:38:37<1:37:58,  8.05s/it] 93%|█████████▎| 9666/10395 [27:38:46<1:37:54,  8.06s/it]                                                         {'loss': 0.9122, 'learning_rate': 2.568486706679318e-07, 'epoch': 0.93}
 93%|█████████▎| 9666/10395 [27:38:46<1:37:54,  8.06s/it] 93%|█████████▎| 9667/10395 [27:38:53<1:37:11,  8.01s/it]                                                         {'loss': 0.8402, 'learning_rate': 2.5614751545331553e-07, 'epoch': 0.93}
 93%|█████████▎| 9667/10395 [27:38:53<1:37:11,  8.01s/it] 93%|█████████▎| 9668/10395 [27:39:01<1:36:39,  7.98s/it]                                                         {'loss': 0.872, 'learning_rate': 2.5544730615107425e-07, 'epoch': 0.93}
 93%|█████████▎| 9668/10395 [27:39:01<1:36:39,  7.98s/it] 93%|█████████▎| 9669/10395 [27:39:09<1:35:52,  7.92s/it]                                                         {'loss': 0.8181, 'learning_rate': 2.5474804282918487e-07, 'epoch': 0.93}
 93%|█████████▎| 9669/10395 [27:39:09<1:35:52,  7.92s/it] 93%|█████████▎| 9670/10395 [27:39:17<1:36:01,  7.95s/it]                                                         {'loss': 0.8007, 'learning_rate': 2.5404972555552967e-07, 'epoch': 0.93}
 93%|█████████▎| 9670/10395 [27:39:17<1:36:01,  7.95s/it] 93%|█████████▎| 9671/10395 [27:39:25<1:34:08,  7.80s/it]                                                         {'loss': 0.8504, 'learning_rate': 2.5335235439789885e-07, 'epoch': 0.93}
 93%|█████████▎| 9671/10395 [27:39:25<1:34:08,  7.80s/it] 93%|█████████▎| 9672/10395 [27:39:32<1:34:07,  7.81s/it]                                                         {'loss': 0.7889, 'learning_rate': 2.526559294239961e-07, 'epoch': 0.93}
 93%|█████████▎| 9672/10395 [27:39:32<1:34:07,  7.81s/it] 93%|█████████▎| 9673/10395 [27:39:41<1:35:11,  7.91s/it]                                                         {'loss': 0.8361, 'learning_rate': 2.5196045070142283e-07, 'epoch': 0.93}
 93%|█████████▎| 9673/10395 [27:39:41<1:35:11,  7.91s/it] 93%|█████████▎| 9674/10395 [27:39:48<1:33:35,  7.79s/it]                                                         {'loss': 0.8765, 'learning_rate': 2.512659182976973e-07, 'epoch': 0.93}
 93%|█████████▎| 9674/10395 [27:39:48<1:33:35,  7.79s/it] 93%|█████████▎| 9675/10395 [27:39:55<1:31:41,  7.64s/it]                                                         {'loss': 0.9312, 'learning_rate': 2.505723322802445e-07, 'epoch': 0.93}
 93%|█████████▎| 9675/10395 [27:39:55<1:31:41,  7.64s/it] 93%|█████████▎| 9676/10395 [27:40:03<1:30:33,  7.56s/it]                                                         {'loss': 0.8294, 'learning_rate': 2.498796927163938e-07, 'epoch': 0.93}
 93%|█████████▎| 9676/10395 [27:40:03<1:30:33,  7.56s/it] 93%|█████████▎| 9677/10395 [27:40:10<1:29:25,  7.47s/it]                                                         {'loss': 0.8171, 'learning_rate': 2.4918799967338703e-07, 'epoch': 0.93}
 93%|█████████▎| 9677/10395 [27:40:10<1:29:25,  7.47s/it] 93%|█████████▎| 9678/10395 [27:40:18<1:29:39,  7.50s/it]                                                         {'loss': 0.8517, 'learning_rate': 2.484972532183716e-07, 'epoch': 0.93}
 93%|█████████▎| 9678/10395 [27:40:18<1:29:39,  7.50s/it] 93%|█████████▎| 9679/10395 [27:40:25<1:28:14,  7.39s/it]                                                         {'loss': 0.8495, 'learning_rate': 2.4780745341840497e-07, 'epoch': 0.93}
 93%|█████████▎| 9679/10395 [27:40:25<1:28:14,  7.39s/it] 93%|█████████▎| 9680/10395 [27:40:32<1:28:31,  7.43s/it]                                                         {'loss': 0.8235, 'learning_rate': 2.4711860034044907e-07, 'epoch': 0.93}
 93%|█████████▎| 9680/10395 [27:40:32<1:28:31,  7.43s/it] 93%|█████████▎| 9681/10395 [27:40:41<1:31:54,  7.72s/it]                                                         {'loss': 0.8463, 'learning_rate': 2.464306940513772e-07, 'epoch': 0.93}
 93%|█████████▎| 9681/10395 [27:40:41<1:31:54,  7.72s/it] 93%|█████████▎| 9682/10395 [27:40:49<1:32:17,  7.77s/it]                                                         {'loss': 0.7751, 'learning_rate': 2.4574373461797027e-07, 'epoch': 0.93}
 93%|█████████▎| 9682/10395 [27:40:49<1:32:17,  7.77s/it] 93%|█████████▎| 9683/10395 [27:40:56<1:32:41,  7.81s/it]                                                         {'loss': 0.8435, 'learning_rate': 2.4505772210691837e-07, 'epoch': 0.93}
 93%|█████████▎| 9683/10395 [27:40:56<1:32:41,  7.81s/it] 93%|█████████▎| 9684/10395 [27:41:04<1:32:33,  7.81s/it]                                                         {'loss': 0.8292, 'learning_rate': 2.443726565848137e-07, 'epoch': 0.93}
 93%|█████████▎| 9684/10395 [27:41:04<1:32:33,  7.81s/it] 93%|█████████▎| 9685/10395 [27:41:12<1:31:11,  7.71s/it]                                                         {'loss': 0.9696, 'learning_rate': 2.436885381181664e-07, 'epoch': 0.93}
 93%|█████████▎| 9685/10395 [27:41:12<1:31:11,  7.71s/it] 93%|█████████▎| 9686/10395 [27:41:18<1:27:30,  7.41s/it]                                                         {'loss': 0.8861, 'learning_rate': 2.430053667733856e-07, 'epoch': 0.93}
 93%|█████████▎| 9686/10395 [27:41:18<1:27:30,  7.41s/it] 93%|█████████▎| 9687/10395 [27:41:27<1:29:52,  7.62s/it]                                                         {'loss': 0.8687, 'learning_rate': 2.423231426167916e-07, 'epoch': 0.93}
 93%|█████████▎| 9687/10395 [27:41:27<1:29:52,  7.62s/it] 93%|█████████▎| 9688/10395 [27:41:34<1:29:24,  7.59s/it]                                                         {'loss': 0.9204, 'learning_rate': 2.416418657146158e-07, 'epoch': 0.93}
 93%|█████████▎| 9688/10395 [27:41:34<1:29:24,  7.59s/it] 93%|█████████▎| 9689/10395 [27:41:43<1:32:39,  7.87s/it]                                                         {'loss': 0.8471, 'learning_rate': 2.409615361329942e-07, 'epoch': 0.93}
 93%|█████████▎| 9689/10395 [27:41:43<1:32:39,  7.87s/it] 93%|█████████▎| 9690/10395 [27:41:51<1:32:56,  7.91s/it]                                                         {'loss': 0.8855, 'learning_rate': 2.4028215393797073e-07, 'epoch': 0.93}
 93%|█████████▎| 9690/10395 [27:41:51<1:32:56,  7.91s/it] 93%|█████████▎| 9691/10395 [27:41:59<1:33:43,  7.99s/it]                                                         {'loss': 0.8598, 'learning_rate': 2.396037191955003e-07, 'epoch': 0.93}
 93%|█████████▎| 9691/10395 [27:41:59<1:33:43,  7.99s/it] 93%|█████████▎| 9692/10395 [27:42:06<1:31:31,  7.81s/it]                                                         {'loss': 0.8784, 'learning_rate': 2.3892623197144136e-07, 'epoch': 0.93}
 93%|█████████▎| 9692/10395 [27:42:06<1:31:31,  7.81s/it] 93%|█████████▎| 9693/10395 [27:42:14<1:31:37,  7.83s/it]                                                         {'loss': 0.9073, 'learning_rate': 2.382496923315647e-07, 'epoch': 0.93}
 93%|█████████▎| 9693/10395 [27:42:14<1:31:37,  7.83s/it] 93%|█████████▎| 9694/10395 [27:42:22<1:32:41,  7.93s/it]                                                         {'loss': 0.8343, 'learning_rate': 2.3757410034154883e-07, 'epoch': 0.93}
 93%|█████████▎| 9694/10395 [27:42:22<1:32:41,  7.93s/it] 93%|█████████▎| 9695/10395 [27:42:30<1:32:59,  7.97s/it]                                                         {'loss': 0.8796, 'learning_rate': 2.3689945606697463e-07, 'epoch': 0.93}
 93%|█████████▎| 9695/10395 [27:42:30<1:32:59,  7.97s/it] 93%|█████████▎| 9696/10395 [27:42:48<2:07:23, 10.94s/it]                                                         {'loss': 0.3793, 'learning_rate': 2.3622575957333748e-07, 'epoch': 0.93}
 93%|█████████▎| 9696/10395 [27:42:48<2:07:23, 10.94s/it] 93%|█████████▎| 9697/10395 [27:42:56<1:58:20, 10.17s/it]                                                         {'loss': 0.8324, 'learning_rate': 2.3555301092604066e-07, 'epoch': 0.93}
 93%|█████████▎| 9697/10395 [27:42:56<1:58:20, 10.17s/it] 93%|█████████▎| 9698/10395 [27:43:04<1:50:28,  9.51s/it]                                                         {'loss': 0.8758, 'learning_rate': 2.3488121019038857e-07, 'epoch': 0.93}
 93%|█████████▎| 9698/10395 [27:43:04<1:50:28,  9.51s/it] 93%|█████████▎| 9699/10395 [27:43:12<1:44:43,  9.03s/it]                                                         {'loss': 0.8717, 'learning_rate': 2.3421035743160125e-07, 'epoch': 0.93}
 93%|█████████▎| 9699/10395 [27:43:12<1:44:43,  9.03s/it] 93%|█████████▎| 9700/10395 [27:43:20<1:40:07,  8.64s/it]                                                         {'loss': 0.8976, 'learning_rate': 2.335404527148022e-07, 'epoch': 0.93}
 93%|█████████▎| 9700/10395 [27:43:20<1:40:07,  8.64s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 93%|█████████▎| 9701/10395 [27:45:03<7:06:57, 36.91s/it]                                                         {'loss': 0.9431, 'learning_rate': 2.3287149610502602e-07, 'epoch': 0.93}
 93%|█████████▎| 9701/10395 [27:45:03<7:06:57, 36.91s/it] 93%|█████████▎| 9702/10395 [27:45:11<5:25:17, 28.16s/it]                                                         {'loss': 0.8855, 'learning_rate': 2.32203487667213e-07, 'epoch': 0.93}
 93%|█████████▎| 9702/10395 [27:45:11<5:25:17, 28.16s/it] 93%|█████████▎| 9703/10395 [27:45:19<4:15:58, 22.19s/it]                                                         {'loss': 0.8283, 'learning_rate': 2.315364274662102e-07, 'epoch': 0.93}
 93%|█████████▎| 9703/10395 [27:45:19<4:15:58, 22.19s/it] 93%|█████████▎| 9704/10395 [27:45:27<3:27:25, 18.01s/it]                                                         {'loss': 0.7981, 'learning_rate': 2.3087031556677574e-07, 'epoch': 0.93}
 93%|█████████▎| 9704/10395 [27:45:27<3:27:25, 18.01s/it] 93%|█████████▎| 9705/10395 [27:45:35<2:51:57, 14.95s/it]                                                         {'loss': 0.8046, 'learning_rate': 2.3020515203357574e-07, 'epoch': 0.93}
 93%|█████████▎| 9705/10395 [27:45:35<2:51:57, 14.95s/it] 93%|█████████▎| 9706/10395 [27:45:43<2:29:12, 12.99s/it]                                                         {'loss': 0.8559, 'learning_rate': 2.2954093693117962e-07, 'epoch': 0.93}
 93%|█████████▎| 9706/10395 [27:45:43<2:29:12, 12.99s/it] 93%|█████████▎| 9707/10395 [27:45:51<2:09:41, 11.31s/it]                                                         {'loss': 0.8626, 'learning_rate': 2.2887767032407138e-07, 'epoch': 0.93}
 93%|█████████▎| 9707/10395 [27:45:51<2:09:41, 11.31s/it] 93%|█████████▎| 9708/10395 [27:46:09<2:32:56, 13.36s/it]                                                         {'loss': 0.3871, 'learning_rate': 2.2821535227663838e-07, 'epoch': 0.93}
 93%|█████████▎| 9708/10395 [27:46:09<2:32:56, 13.36s/it] 93%|█████████▎| 9709/10395 [27:46:16<2:12:34, 11.60s/it]                                                         {'loss': 0.909, 'learning_rate': 2.2755398285317477e-07, 'epoch': 0.93}
 93%|█████████▎| 9709/10395 [27:46:16<2:12:34, 11.60s/it] 93%|█████████▎| 9710/10395 [27:46:24<1:58:33, 10.38s/it]                                                         {'loss': 0.8587, 'learning_rate': 2.2689356211788805e-07, 'epoch': 0.93}
 93%|█████████▎| 9710/10395 [27:46:24<1:58:33, 10.38s/it] 93%|█████████▎| 9711/10395 [27:46:33<1:52:45,  9.89s/it]                                                         {'loss': 0.8295, 'learning_rate': 2.2623409013488806e-07, 'epoch': 0.93}
 93%|█████████▎| 9711/10395 [27:46:33<1:52:45,  9.89s/it] 93%|█████████▎| 9712/10395 [27:46:40<1:44:14,  9.16s/it]                                                         {'loss': 0.8467, 'learning_rate': 2.2557556696819582e-07, 'epoch': 0.93}
 93%|█████████▎| 9712/10395 [27:46:40<1:44:14,  9.16s/it] 93%|█████████▎| 9713/10395 [27:46:48<1:41:01,  8.89s/it]                                                         {'loss': 0.897, 'learning_rate': 2.249179926817413e-07, 'epoch': 0.93}
 93%|█████████▎| 9713/10395 [27:46:48<1:41:01,  8.89s/it] 93%|█████████▎| 9714/10395 [27:46:57<1:38:08,  8.65s/it]                                                         {'loss': 0.8895, 'learning_rate': 2.2426136733935677e-07, 'epoch': 0.93}
 93%|█████████▎| 9714/10395 [27:46:57<1:38:08,  8.65s/it] 93%|█████████▎| 9715/10395 [27:47:05<1:37:26,  8.60s/it]                                                         {'loss': 0.8711, 'learning_rate': 2.23605691004789e-07, 'epoch': 0.93}
 93%|█████████▎| 9715/10395 [27:47:05<1:37:26,  8.60s/it] 93%|█████████▎| 9716/10395 [27:47:13<1:34:50,  8.38s/it]                                                         {'loss': 0.8991, 'learning_rate': 2.2295096374168822e-07, 'epoch': 0.93}
 93%|█████████▎| 9716/10395 [27:47:13<1:34:50,  8.38s/it] 93%|█████████▎| 9717/10395 [27:47:23<1:41:13,  8.96s/it]                                                         {'loss': 0.8016, 'learning_rate': 2.2229718561361468e-07, 'epoch': 0.93}
 93%|█████████▎| 9717/10395 [27:47:23<1:41:13,  8.96s/it] 93%|█████████▎| 9718/10395 [27:47:31<1:35:53,  8.50s/it]                                                         {'loss': 0.8845, 'learning_rate': 2.216443566840354e-07, 'epoch': 0.93}
 93%|█████████▎| 9718/10395 [27:47:31<1:35:53,  8.50s/it] 93%|█████████▎| 9719/10395 [27:47:38<1:33:06,  8.26s/it]                                                         {'loss': 0.8369, 'learning_rate': 2.2099247701632408e-07, 'epoch': 0.93}
 93%|█████████▎| 9719/10395 [27:47:38<1:33:06,  8.26s/it] 94%|█████████▎| 9720/10395 [27:47:48<1:37:39,  8.68s/it]                                                         {'loss': 0.8192, 'learning_rate': 2.2034154667376574e-07, 'epoch': 0.94}
 94%|█████████▎| 9720/10395 [27:47:48<1:37:39,  8.68s/it] 94%|█████████▎| 9721/10395 [27:47:56<1:34:37,  8.42s/it]                                                         {'loss': 0.9002, 'learning_rate': 2.1969156571955196e-07, 'epoch': 0.94}
 94%|█████████▎| 9721/10395 [27:47:56<1:34:37,  8.42s/it] 94%|█████████▎| 9722/10395 [27:48:04<1:32:12,  8.22s/it]                                                         {'loss': 0.9038, 'learning_rate': 2.19042534216779e-07, 'epoch': 0.94}
 94%|█████████▎| 9722/10395 [27:48:04<1:32:12,  8.22s/it] 94%|█████████▎| 9723/10395 [27:48:21<2:04:23, 11.11s/it]                                                         {'loss': 0.3943, 'learning_rate': 2.1839445222845645e-07, 'epoch': 0.94}
 94%|█████████▎| 9723/10395 [27:48:21<2:04:23, 11.11s/it] 94%|█████████▎| 9724/10395 [27:48:30<1:55:58, 10.37s/it]                                                         {'loss': 0.8627, 'learning_rate': 2.1774731981749618e-07, 'epoch': 0.94}
 94%|█████████▎| 9724/10395 [27:48:30<1:55:58, 10.37s/it] 94%|█████████▎| 9725/10395 [27:48:38<1:47:20,  9.61s/it]                                                         {'loss': 0.8642, 'learning_rate': 2.171011370467213e-07, 'epoch': 0.94}
 94%|█████████▎| 9725/10395 [27:48:38<1:47:20,  9.61s/it] 94%|█████████▎| 9726/10395 [27:48:54<2:10:16, 11.68s/it]                                                         {'loss': 0.373, 'learning_rate': 2.1645590397886273e-07, 'epoch': 0.94}
 94%|█████████▎| 9726/10395 [27:48:54<2:10:16, 11.68s/it] 94%|█████████▎| 9727/10395 [27:49:11<2:25:29, 13.07s/it]                                                         {'loss': 0.3867, 'learning_rate': 2.1581162067655592e-07, 'epoch': 0.94}
 94%|█████████▎| 9727/10395 [27:49:11<2:25:29, 13.07s/it] 94%|█████████▎| 9728/10395 [27:49:19<2:10:49, 11.77s/it]                                                         {'loss': 0.8981, 'learning_rate': 2.1516828720234862e-07, 'epoch': 0.94}
 94%|█████████▎| 9728/10395 [27:49:19<2:10:49, 11.77s/it] 94%|█████████▎| 9729/10395 [27:49:27<1:56:11, 10.47s/it]                                                         {'loss': 0.8995, 'learning_rate': 2.145259036186953e-07, 'epoch': 0.94}
 94%|█████████▎| 9729/10395 [27:49:27<1:56:11, 10.47s/it] 94%|█████████▎| 9730/10395 [27:49:35<1:46:28,  9.61s/it]                                                         {'loss': 0.8426, 'learning_rate': 2.1388446998795498e-07, 'epoch': 0.94}
 94%|█████████▎| 9730/10395 [27:49:35<1:46:28,  9.61s/it] 94%|█████████▎| 9731/10395 [27:49:43<1:41:04,  9.13s/it]                                                         {'loss': 0.8533, 'learning_rate': 2.1324398637239563e-07, 'epoch': 0.94}
 94%|█████████▎| 9731/10395 [27:49:43<1:41:04,  9.13s/it] 94%|█████████▎| 9732/10395 [27:49:50<1:36:44,  8.75s/it]                                                         {'loss': 0.8278, 'learning_rate': 2.126044528341975e-07, 'epoch': 0.94}
 94%|█████████▎| 9732/10395 [27:49:50<1:36:44,  8.75s/it] 94%|█████████▎| 9733/10395 [27:49:58<1:33:21,  8.46s/it]                                                         {'loss': 0.8202, 'learning_rate': 2.1196586943544207e-07, 'epoch': 0.94}
 94%|█████████▎| 9733/10395 [27:49:58<1:33:21,  8.46s/it] 94%|█████████▎| 9734/10395 [27:50:06<1:30:42,  8.23s/it]                                                         {'loss': 0.8271, 'learning_rate': 2.1132823623812416e-07, 'epoch': 0.94}
 94%|█████████▎| 9734/10395 [27:50:06<1:30:42,  8.23s/it] 94%|█████████▎| 9735/10395 [27:50:14<1:29:19,  8.12s/it]                                                         {'loss': 0.8325, 'learning_rate': 2.1069155330414204e-07, 'epoch': 0.94}
 94%|█████████▎| 9735/10395 [27:50:14<1:29:19,  8.12s/it] 94%|█████████▎| 9736/10395 [27:50:22<1:28:09,  8.03s/it]                                                         {'loss': 0.7851, 'learning_rate': 2.1005582069530295e-07, 'epoch': 0.94}
 94%|█████████▎| 9736/10395 [27:50:22<1:28:09,  8.03s/it] 94%|█████████▎| 9737/10395 [27:50:29<1:26:30,  7.89s/it]                                                         {'loss': 0.9028, 'learning_rate': 2.0942103847332528e-07, 'epoch': 0.94}
 94%|█████████▎| 9737/10395 [27:50:29<1:26:30,  7.89s/it] 94%|█████████▎| 9738/10395 [27:50:37<1:26:17,  7.88s/it]                                                         {'loss': 0.9463, 'learning_rate': 2.0878720669983088e-07, 'epoch': 0.94}
 94%|█████████▎| 9738/10395 [27:50:37<1:26:17,  7.88s/it] 94%|█████████▎| 9739/10395 [27:50:45<1:27:14,  7.98s/it]                                                         {'loss': 0.8279, 'learning_rate': 2.0815432543634938e-07, 'epoch': 0.94}
 94%|█████████▎| 9739/10395 [27:50:45<1:27:14,  7.98s/it] 94%|█████████▎| 9740/10395 [27:50:53<1:25:01,  7.79s/it]                                                         {'loss': 0.8606, 'learning_rate': 2.0752239474432168e-07, 'epoch': 0.94}
 94%|█████████▎| 9740/10395 [27:50:53<1:25:01,  7.79s/it] 94%|█████████▎| 9741/10395 [27:51:00<1:23:30,  7.66s/it]                                                         {'loss': 0.8144, 'learning_rate': 2.06891414685092e-07, 'epoch': 0.94}
 94%|█████████▎| 9741/10395 [27:51:00<1:23:30,  7.66s/it] 94%|█████████▎| 9742/10395 [27:51:08<1:24:31,  7.77s/it]                                                         {'loss': 0.7723, 'learning_rate': 2.06261385319918e-07, 'epoch': 0.94}
 94%|█████████▎| 9742/10395 [27:51:08<1:24:31,  7.77s/it] 94%|█████████▎| 9743/10395 [27:51:16<1:24:05,  7.74s/it]                                                         {'loss': 0.8562, 'learning_rate': 2.056323067099575e-07, 'epoch': 0.94}
 94%|█████████▎| 9743/10395 [27:51:16<1:24:05,  7.74s/it] 94%|█████████▎| 9744/10395 [27:51:23<1:24:22,  7.78s/it]                                                         {'loss': 0.9056, 'learning_rate': 2.0500417891628155e-07, 'epoch': 0.94}
 94%|█████████▎| 9744/10395 [27:51:23<1:24:22,  7.78s/it] 94%|█████████▎| 9745/10395 [27:51:32<1:27:54,  8.11s/it]                                                         {'loss': 0.8393, 'learning_rate': 2.043770019998703e-07, 'epoch': 0.94}
 94%|█████████▎| 9745/10395 [27:51:32<1:27:54,  8.11s/it] 94%|█████████▍| 9746/10395 [27:51:40<1:26:29,  8.00s/it]                                                         {'loss': 0.8466, 'learning_rate': 2.037507760216051e-07, 'epoch': 0.94}
 94%|█████████▍| 9746/10395 [27:51:40<1:26:29,  8.00s/it] 94%|█████████▍| 9747/10395 [27:51:48<1:25:25,  7.91s/it]                                                         {'loss': 0.8415, 'learning_rate': 2.0312550104227947e-07, 'epoch': 0.94}
 94%|█████████▍| 9747/10395 [27:51:48<1:25:25,  7.91s/it] 94%|█████████▍| 9748/10395 [27:51:55<1:23:08,  7.71s/it]                                                         {'loss': 0.8955, 'learning_rate': 2.0250117712259487e-07, 'epoch': 0.94}
 94%|█████████▍| 9748/10395 [27:51:55<1:23:08,  7.71s/it] 94%|█████████▍| 9749/10395 [27:52:03<1:23:25,  7.75s/it]                                                         {'loss': 0.8101, 'learning_rate': 2.018778043231584e-07, 'epoch': 0.94}
 94%|█████████▍| 9749/10395 [27:52:03<1:23:25,  7.75s/it] 94%|█████████▍| 9750/10395 [27:52:20<1:54:09, 10.62s/it]                                                         {'loss': 0.3329, 'learning_rate': 2.0125538270448608e-07, 'epoch': 0.94}
 94%|█████████▍| 9750/10395 [27:52:20<1:54:09, 10.62s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 94%|█████████▍| 9751/10395 [27:54:01<6:44:35, 37.70s/it]                                                         {'loss': 0.8946, 'learning_rate': 2.006339123270007e-07, 'epoch': 0.94}
 94%|█████████▍| 9751/10395 [27:54:01<6:44:35, 37.70s/it] 94%|█████████▍| 9752/10395 [27:54:09<5:07:46, 28.72s/it]                                                         {'loss': 0.8583, 'learning_rate': 2.0001339325103508e-07, 'epoch': 0.94}
 94%|█████████▍| 9752/10395 [27:54:09<5:07:46, 28.72s/it] 94%|█████████▍| 9753/10395 [27:54:18<4:05:07, 22.91s/it]                                                         {'loss': 0.8026, 'learning_rate': 1.993938255368244e-07, 'epoch': 0.94}
 94%|█████████▍| 9753/10395 [27:54:18<4:05:07, 22.91s/it] 94%|█████████▍| 9754/10395 [27:54:26<3:17:15, 18.46s/it]                                                         {'loss': 0.8074, 'learning_rate': 1.9877520924451943e-07, 'epoch': 0.94}
 94%|█████████▍| 9754/10395 [27:54:26<3:17:15, 18.46s/it] 94%|█████████▍| 9755/10395 [27:54:34<2:42:06, 15.20s/it]                                                         {'loss': 0.8994, 'learning_rate': 1.9815754443417102e-07, 'epoch': 0.94}
 94%|█████████▍| 9755/10395 [27:54:34<2:42:06, 15.20s/it] 94%|█████████▍| 9756/10395 [27:54:42<2:18:37, 13.02s/it]                                                         {'loss': 0.9689, 'learning_rate': 1.975408311657412e-07, 'epoch': 0.94}
 94%|█████████▍| 9756/10395 [27:54:42<2:18:37, 13.02s/it] 94%|█████████▍| 9757/10395 [27:54:57<2:26:50, 13.81s/it]                                                         {'loss': 0.2996, 'learning_rate': 1.9692506949909985e-07, 'epoch': 0.94}
 94%|█████████▍| 9757/10395 [27:54:57<2:26:50, 13.81s/it] 94%|█████████▍| 9758/10395 [27:55:06<2:08:24, 12.09s/it]                                                         {'loss': 0.8463, 'learning_rate': 1.963102594940236e-07, 'epoch': 0.94}
 94%|█████████▍| 9758/10395 [27:55:06<2:08:24, 12.09s/it] 94%|█████████▍| 9759/10395 [27:55:13<1:54:55, 10.84s/it]                                                         {'loss': 0.8395, 'learning_rate': 1.9569640121019695e-07, 'epoch': 0.94}
 94%|█████████▍| 9759/10395 [27:55:13<1:54:55, 10.84s/it] 94%|█████████▍| 9760/10395 [27:55:21<1:43:56,  9.82s/it]                                                         {'loss': 0.9305, 'learning_rate': 1.950834947072122e-07, 'epoch': 0.94}
 94%|█████████▍| 9760/10395 [27:55:21<1:43:56,  9.82s/it] 94%|█████████▍| 9761/10395 [27:55:28<1:34:46,  8.97s/it]                                                         {'loss': 0.8365, 'learning_rate': 1.9447154004456737e-07, 'epoch': 0.94}
 94%|█████████▍| 9761/10395 [27:55:28<1:34:46,  8.97s/it] 94%|█████████▍| 9762/10395 [27:55:35<1:30:19,  8.56s/it]                                                         {'loss': 0.8789, 'learning_rate': 1.9386053728167152e-07, 'epoch': 0.94}
 94%|█████████▍| 9762/10395 [27:55:35<1:30:19,  8.56s/it] 94%|█████████▍| 9763/10395 [27:55:43<1:25:35,  8.13s/it]                                                         {'loss': 0.8809, 'learning_rate': 1.932504864778395e-07, 'epoch': 0.94}
 94%|█████████▍| 9763/10395 [27:55:43<1:25:35,  8.13s/it] 94%|█████████▍| 9764/10395 [27:55:51<1:26:14,  8.20s/it]                                                         {'loss': 0.8336, 'learning_rate': 1.926413876922928e-07, 'epoch': 0.94}
 94%|█████████▍| 9764/10395 [27:55:51<1:26:14,  8.20s/it] 94%|█████████▍| 9765/10395 [27:55:58<1:23:11,  7.92s/it]                                                         {'loss': 0.9184, 'learning_rate': 1.9203324098416076e-07, 'epoch': 0.94}
 94%|█████████▍| 9765/10395 [27:55:58<1:23:11,  7.92s/it] 94%|█████████▍| 9766/10395 [27:56:05<1:20:43,  7.70s/it]                                                         {'loss': 0.8469, 'learning_rate': 1.9142604641248285e-07, 'epoch': 0.94}
 94%|█████████▍| 9766/10395 [27:56:05<1:20:43,  7.70s/it] 94%|█████████▍| 9767/10395 [27:56:13<1:18:51,  7.53s/it]                                                         {'loss': 0.9366, 'learning_rate': 1.9081980403620416e-07, 'epoch': 0.94}
 94%|█████████▍| 9767/10395 [27:56:13<1:18:51,  7.53s/it] 94%|█████████▍| 9768/10395 [27:56:20<1:18:40,  7.53s/it]                                                         {'loss': 0.9902, 'learning_rate': 1.9021451391417534e-07, 'epoch': 0.94}
 94%|█████████▍| 9768/10395 [27:56:20<1:18:40,  7.53s/it] 94%|█████████▍| 9769/10395 [27:56:28<1:18:25,  7.52s/it]                                                         {'loss': 0.8484, 'learning_rate': 1.896101761051583e-07, 'epoch': 0.94}
 94%|█████████▍| 9769/10395 [27:56:28<1:18:25,  7.52s/it] 94%|█████████▍| 9770/10395 [27:56:36<1:21:41,  7.84s/it]                                                         {'loss': 0.7196, 'learning_rate': 1.8900679066782169e-07, 'epoch': 0.94}
 94%|█████████▍| 9770/10395 [27:56:36<1:21:41,  7.84s/it] 94%|█████████▍| 9771/10395 [27:56:45<1:24:06,  8.09s/it]                                                         {'loss': 0.8545, 'learning_rate': 1.884043576607375e-07, 'epoch': 0.94}
 94%|█████████▍| 9771/10395 [27:56:45<1:24:06,  8.09s/it] 94%|█████████▍| 9772/10395 [27:56:53<1:22:48,  7.98s/it]                                                         {'loss': 0.9124, 'learning_rate': 1.878028771423923e-07, 'epoch': 0.94}
 94%|█████████▍| 9772/10395 [27:56:53<1:22:48,  7.98s/it] 94%|█████████▍| 9773/10395 [27:57:00<1:22:06,  7.92s/it]                                                         {'loss': 0.8364, 'learning_rate': 1.8720234917117496e-07, 'epoch': 0.94}
 94%|█████████▍| 9773/10395 [27:57:00<1:22:06,  7.92s/it] 94%|█████████▍| 9774/10395 [27:57:08<1:20:56,  7.82s/it]                                                         {'loss': 0.8877, 'learning_rate': 1.8660277380538327e-07, 'epoch': 0.94}
 94%|█████████▍| 9774/10395 [27:57:08<1:20:56,  7.82s/it] 94%|█████████▍| 9775/10395 [27:57:16<1:20:15,  7.77s/it]                                                         {'loss': 0.8146, 'learning_rate': 1.86004151103224e-07, 'epoch': 0.94}
 94%|█████████▍| 9775/10395 [27:57:16<1:20:15,  7.77s/it] 94%|█████████▍| 9776/10395 [27:57:24<1:20:42,  7.82s/it]                                                         {'loss': 0.8882, 'learning_rate': 1.8540648112280735e-07, 'epoch': 0.94}
 94%|█████████▍| 9776/10395 [27:57:24<1:20:42,  7.82s/it] 94%|█████████▍| 9777/10395 [27:57:31<1:19:15,  7.69s/it]                                                         {'loss': 0.8743, 'learning_rate': 1.8480976392215578e-07, 'epoch': 0.94}
 94%|█████████▍| 9777/10395 [27:57:31<1:19:15,  7.69s/it] 94%|█████████▍| 9778/10395 [27:57:39<1:19:32,  7.74s/it]                                                         {'loss': 0.8407, 'learning_rate': 1.842139995591985e-07, 'epoch': 0.94}
 94%|█████████▍| 9778/10395 [27:57:39<1:19:32,  7.74s/it] 94%|█████████▍| 9779/10395 [27:57:47<1:19:42,  7.76s/it]                                                         {'loss': 0.9172, 'learning_rate': 1.8361918809176815e-07, 'epoch': 0.94}
 94%|█████████▍| 9779/10395 [27:57:47<1:19:42,  7.76s/it] 94%|█████████▍| 9780/10395 [27:57:54<1:19:46,  7.78s/it]                                                         {'loss': 0.7906, 'learning_rate': 1.8302532957761076e-07, 'epoch': 0.94}
 94%|█████████▍| 9780/10395 [27:57:54<1:19:46,  7.78s/it] 94%|█████████▍| 9781/10395 [27:58:12<1:50:33, 10.80s/it]                                                         {'loss': 0.3427, 'learning_rate': 1.8243242407437466e-07, 'epoch': 0.94}
 94%|█████████▍| 9781/10395 [27:58:12<1:50:33, 10.80s/it] 94%|█████████▍| 9782/10395 [27:58:19<1:39:12,  9.71s/it]                                                         {'loss': 0.8915, 'learning_rate': 1.818404716396194e-07, 'epoch': 0.94}
 94%|█████████▍| 9782/10395 [27:58:19<1:39:12,  9.71s/it] 94%|█████████▍| 9783/10395 [27:58:27<1:32:16,  9.05s/it]                                                         {'loss': 0.9122, 'learning_rate': 1.8124947233081002e-07, 'epoch': 0.94}
 94%|█████████▍| 9783/10395 [27:58:27<1:32:16,  9.05s/it] 94%|█████████▍| 9784/10395 [27:58:34<1:26:57,  8.54s/it]                                                         {'loss': 0.9151, 'learning_rate': 1.806594262053174e-07, 'epoch': 0.94}
 94%|█████████▍| 9784/10395 [27:58:34<1:26:57,  8.54s/it] 94%|█████████▍| 9785/10395 [27:58:43<1:27:39,  8.62s/it]                                                         {'loss': 0.8078, 'learning_rate': 1.8007033332042456e-07, 'epoch': 0.94}
 94%|█████████▍| 9785/10395 [27:58:43<1:27:39,  8.62s/it] 94%|█████████▍| 9786/10395 [27:58:51<1:25:16,  8.40s/it]                                                         {'loss': 0.9156, 'learning_rate': 1.794821937333191e-07, 'epoch': 0.94}
 94%|█████████▍| 9786/10395 [27:58:51<1:25:16,  8.40s/it] 94%|█████████▍| 9787/10395 [27:58:58<1:22:10,  8.11s/it]                                                         {'loss': 0.8711, 'learning_rate': 1.7889500750109422e-07, 'epoch': 0.94}
 94%|█████████▍| 9787/10395 [27:58:58<1:22:10,  8.11s/it] 94%|█████████▍| 9788/10395 [27:59:06<1:20:29,  7.96s/it]                                                         {'loss': 0.8014, 'learning_rate': 1.7830877468075658e-07, 'epoch': 0.94}
 94%|█████████▍| 9788/10395 [27:59:06<1:20:29,  7.96s/it] 94%|█████████▍| 9789/10395 [27:59:13<1:18:27,  7.77s/it]                                                         {'loss': 0.8639, 'learning_rate': 1.7772349532921286e-07, 'epoch': 0.94}
 94%|█████████▍| 9789/10395 [27:59:13<1:18:27,  7.77s/it] 94%|█████████▍| 9790/10395 [27:59:21<1:19:17,  7.86s/it]                                                         {'loss': 0.8184, 'learning_rate': 1.7713916950328092e-07, 'epoch': 0.94}
 94%|█████████▍| 9790/10395 [27:59:21<1:19:17,  7.86s/it] 94%|█████████▍| 9791/10395 [27:59:29<1:17:26,  7.69s/it]                                                         {'loss': 0.8958, 'learning_rate': 1.7655579725968875e-07, 'epoch': 0.94}
 94%|█████████▍| 9791/10395 [27:59:29<1:17:26,  7.69s/it] 94%|█████████▍| 9792/10395 [27:59:36<1:16:25,  7.60s/it]                                                         {'loss': 0.8156, 'learning_rate': 1.7597337865506548e-07, 'epoch': 0.94}
 94%|█████████▍| 9792/10395 [27:59:36<1:16:25,  7.60s/it] 94%|█████████▍| 9793/10395 [27:59:44<1:17:58,  7.77s/it]                                                         {'loss': 0.8968, 'learning_rate': 1.7539191374595255e-07, 'epoch': 0.94}
 94%|█████████▍| 9793/10395 [27:59:44<1:17:58,  7.77s/it] 94%|█████████▍| 9794/10395 [27:59:52<1:17:12,  7.71s/it]                                                         {'loss': 0.8184, 'learning_rate': 1.7481140258879814e-07, 'epoch': 0.94}
 94%|█████████▍| 9794/10395 [27:59:52<1:17:12,  7.71s/it] 94%|█████████▍| 9795/10395 [28:00:00<1:19:12,  7.92s/it]                                                         {'loss': 0.8508, 'learning_rate': 1.7423184523995606e-07, 'epoch': 0.94}
 94%|█████████▍| 9795/10395 [28:00:00<1:19:12,  7.92s/it] 94%|█████████▍| 9796/10395 [28:00:09<1:22:06,  8.22s/it]                                                         {'loss': 0.7654, 'learning_rate': 1.736532417556891e-07, 'epoch': 0.94}
 94%|█████████▍| 9796/10395 [28:00:09<1:22:06,  8.22s/it] 94%|█████████▍| 9797/10395 [28:00:17<1:19:47,  8.01s/it]                                                         {'loss': 0.7584, 'learning_rate': 1.7307559219216675e-07, 'epoch': 0.94}
 94%|█████████▍| 9797/10395 [28:00:17<1:19:47,  8.01s/it] 94%|█████████▍| 9798/10395 [28:00:25<1:19:17,  7.97s/it]                                                         {'loss': 0.8591, 'learning_rate': 1.7249889660546416e-07, 'epoch': 0.94}
 94%|█████████▍| 9798/10395 [28:00:25<1:19:17,  7.97s/it] 94%|█████████▍| 9799/10395 [28:00:32<1:19:01,  7.95s/it]                                                         {'loss': 0.7928, 'learning_rate': 1.7192315505156875e-07, 'epoch': 0.94}
 94%|█████████▍| 9799/10395 [28:00:32<1:19:01,  7.95s/it] 94%|█████████▍| 9800/10395 [28:00:40<1:17:43,  7.84s/it]                                                         {'loss': 0.8677, 'learning_rate': 1.7134836758636919e-07, 'epoch': 0.94}
 94%|█████████▍| 9800/10395 [28:00:40<1:17:43,  7.84s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 94%|█████████▍| 9801/10395 [28:02:22<5:56:27, 36.01s/it]                                                         {'loss': 0.9519, 'learning_rate': 1.7077453426566749e-07, 'epoch': 0.94}
 94%|█████████▍| 9801/10395 [28:02:22<5:56:27, 36.01s/it] 94%|█████████▍| 9802/10395 [28:02:29<4:30:13, 27.34s/it]                                                         {'loss': 0.812, 'learning_rate': 1.7020165514516794e-07, 'epoch': 0.94}
 94%|█████████▍| 9802/10395 [28:02:29<4:30:13, 27.34s/it] 94%|█████████▍| 9803/10395 [28:02:36<3:31:14, 21.41s/it]                                                         {'loss': 0.8223, 'learning_rate': 1.6962973028048614e-07, 'epoch': 0.94}
 94%|█████████▍| 9803/10395 [28:02:36<3:31:14, 21.41s/it] 94%|█████████▍| 9804/10395 [28:02:44<2:50:04, 17.27s/it]                                                         {'loss': 0.834, 'learning_rate': 1.6905875972714314e-07, 'epoch': 0.94}
 94%|█████████▍| 9804/10395 [28:02:44<2:50:04, 17.27s/it] 94%|█████████▍| 9805/10395 [28:02:52<2:22:19, 14.47s/it]                                                         {'loss': 0.8966, 'learning_rate': 1.6848874354056577e-07, 'epoch': 0.94}
 94%|█████████▍| 9805/10395 [28:02:52<2:22:19, 14.47s/it] 94%|█████████▍| 9806/10395 [28:03:00<2:02:52, 12.52s/it]                                                         {'loss': 0.8411, 'learning_rate': 1.6791968177609197e-07, 'epoch': 0.94}
 94%|█████████▍| 9806/10395 [28:03:00<2:02:52, 12.52s/it] 94%|█████████▍| 9807/10395 [28:03:07<1:47:54, 11.01s/it]                                                         {'loss': 0.8777, 'learning_rate': 1.673515744889642e-07, 'epoch': 0.94}
 94%|█████████▍| 9807/10395 [28:03:07<1:47:54, 11.01s/it] 94%|█████████▍| 9808/10395 [28:03:17<1:44:32, 10.69s/it]                                                         {'loss': 0.8381, 'learning_rate': 1.6678442173433173e-07, 'epoch': 0.94}
 94%|█████████▍| 9808/10395 [28:03:17<1:44:32, 10.69s/it] 94%|█████████▍| 9809/10395 [28:03:25<1:36:19,  9.86s/it]                                                         {'loss': 0.8767, 'learning_rate': 1.6621822356725492e-07, 'epoch': 0.94}
 94%|█████████▍| 9809/10395 [28:03:25<1:36:19,  9.86s/it] 94%|█████████▍| 9810/10395 [28:03:33<1:30:11,  9.25s/it]                                                         {'loss': 0.911, 'learning_rate': 1.656529800426987e-07, 'epoch': 0.94}
 94%|█████████▍| 9810/10395 [28:03:33<1:30:11,  9.25s/it] 94%|█████████▍| 9811/10395 [28:03:41<1:24:34,  8.69s/it]                                                         {'loss': 0.8607, 'learning_rate': 1.6508869121553473e-07, 'epoch': 0.94}
 94%|█████████▍| 9811/10395 [28:03:41<1:24:34,  8.69s/it] 94%|█████████▍| 9812/10395 [28:03:49<1:23:07,  8.56s/it]                                                         {'loss': 0.8465, 'learning_rate': 1.645253571405425e-07, 'epoch': 0.94}
 94%|█████████▍| 9812/10395 [28:03:49<1:23:07,  8.56s/it] 94%|█████████▍| 9813/10395 [28:03:56<1:19:56,  8.24s/it]                                                         {'loss': 0.8703, 'learning_rate': 1.6396297787241166e-07, 'epoch': 0.94}
 94%|█████████▍| 9813/10395 [28:03:56<1:19:56,  8.24s/it] 94%|█████████▍| 9814/10395 [28:04:04<1:17:54,  8.05s/it]                                                         {'loss': 0.8065, 'learning_rate': 1.6340155346573404e-07, 'epoch': 0.94}
 94%|█████████▍| 9814/10395 [28:04:04<1:17:54,  8.05s/it] 94%|█████████▍| 9815/10395 [28:04:11<1:15:32,  7.82s/it]                                                         {'loss': 0.8374, 'learning_rate': 1.6284108397501386e-07, 'epoch': 0.94}
 94%|█████████▍| 9815/10395 [28:04:11<1:15:32,  7.82s/it] 94%|█████████▍| 9816/10395 [28:04:19<1:16:49,  7.96s/it]                                                         {'loss': 0.8513, 'learning_rate': 1.6228156945465756e-07, 'epoch': 0.94}
 94%|█████████▍| 9816/10395 [28:04:19<1:16:49,  7.96s/it] 94%|█████████▍| 9817/10395 [28:04:27<1:15:44,  7.86s/it]                                                         {'loss': 0.8821, 'learning_rate': 1.6172300995898395e-07, 'epoch': 0.94}
 94%|█████████▍| 9817/10395 [28:04:27<1:15:44,  7.86s/it] 94%|█████████▍| 9818/10395 [28:04:35<1:16:30,  7.96s/it]                                                         {'loss': 0.8604, 'learning_rate': 1.6116540554221627e-07, 'epoch': 0.94}
 94%|█████████▍| 9818/10395 [28:04:35<1:16:30,  7.96s/it] 94%|█████████▍| 9819/10395 [28:04:43<1:15:35,  7.87s/it]                                                         {'loss': 0.8105, 'learning_rate': 1.606087562584857e-07, 'epoch': 0.94}
 94%|█████████▍| 9819/10395 [28:04:43<1:15:35,  7.87s/it] 94%|█████████▍| 9820/10395 [28:04:50<1:14:19,  7.76s/it]                                                         {'loss': 0.8499, 'learning_rate': 1.6005306216182903e-07, 'epoch': 0.94}
 94%|█████████▍| 9820/10395 [28:04:50<1:14:19,  7.76s/it] 94%|█████████▍| 9821/10395 [28:04:59<1:15:39,  7.91s/it]                                                         {'loss': 0.791, 'learning_rate': 1.594983233061942e-07, 'epoch': 0.94}
 94%|█████████▍| 9821/10395 [28:04:59<1:15:39,  7.91s/it] 94%|█████████▍| 9822/10395 [28:05:07<1:15:47,  7.94s/it]                                                         {'loss': 0.834, 'learning_rate': 1.5894453974543256e-07, 'epoch': 0.94}
 94%|█████████▍| 9822/10395 [28:05:07<1:15:47,  7.94s/it] 94%|█████████▍| 9823/10395 [28:05:14<1:15:11,  7.89s/it]                                                         {'loss': 0.8831, 'learning_rate': 1.5839171153330445e-07, 'epoch': 0.94}
 94%|█████████▍| 9823/10395 [28:05:14<1:15:11,  7.89s/it] 95%|█████████▍| 9824/10395 [28:05:22<1:14:51,  7.87s/it]                                                         {'loss': 0.763, 'learning_rate': 1.578398387234781e-07, 'epoch': 0.95}
 95%|█████████▍| 9824/10395 [28:05:22<1:14:51,  7.87s/it] 95%|█████████▍| 9825/10395 [28:05:30<1:13:57,  7.79s/it]                                                         {'loss': 0.7963, 'learning_rate': 1.5728892136952612e-07, 'epoch': 0.95}
 95%|█████████▍| 9825/10395 [28:05:30<1:13:57,  7.79s/it] 95%|█████████▍| 9826/10395 [28:05:38<1:14:13,  7.83s/it]                                                         {'loss': 0.8206, 'learning_rate': 1.5673895952493246e-07, 'epoch': 0.95}
 95%|█████████▍| 9826/10395 [28:05:38<1:14:13,  7.83s/it] 95%|█████████▍| 9827/10395 [28:05:46<1:14:04,  7.83s/it]                                                         {'loss': 0.8477, 'learning_rate': 1.561899532430866e-07, 'epoch': 0.95}
 95%|█████████▍| 9827/10395 [28:05:46<1:14:04,  7.83s/it] 95%|█████████▍| 9828/10395 [28:05:53<1:12:36,  7.68s/it]                                                         {'loss': 0.8978, 'learning_rate': 1.5564190257728151e-07, 'epoch': 0.95}
 95%|█████████▍| 9828/10395 [28:05:53<1:12:36,  7.68s/it] 95%|█████████▍| 9829/10395 [28:06:01<1:14:30,  7.90s/it]                                                         {'loss': 0.8196, 'learning_rate': 1.5509480758072459e-07, 'epoch': 0.95}
 95%|█████████▍| 9829/10395 [28:06:01<1:14:30,  7.90s/it] 95%|█████████▍| 9830/10395 [28:06:09<1:13:46,  7.83s/it]                                                         {'loss': 0.8943, 'learning_rate': 1.545486683065245e-07, 'epoch': 0.95}
 95%|█████████▍| 9830/10395 [28:06:09<1:13:46,  7.83s/it] 95%|█████████▍| 9831/10395 [28:06:17<1:14:15,  7.90s/it]                                                         {'loss': 0.8857, 'learning_rate': 1.5400348480769988e-07, 'epoch': 0.95}
 95%|█████████▍| 9831/10395 [28:06:17<1:14:15,  7.90s/it] 95%|█████████▍| 9832/10395 [28:06:25<1:13:20,  7.82s/it]                                                         {'loss': 0.8899, 'learning_rate': 1.5345925713717625e-07, 'epoch': 0.95}
 95%|█████████▍| 9832/10395 [28:06:25<1:13:20,  7.82s/it] 95%|█████████▍| 9833/10395 [28:06:32<1:12:37,  7.75s/it]                                                         {'loss': 0.831, 'learning_rate': 1.5291598534778685e-07, 'epoch': 0.95}
 95%|█████████▍| 9833/10395 [28:06:32<1:12:37,  7.75s/it] 95%|█████████▍| 9834/10395 [28:06:40<1:11:16,  7.62s/it]                                                         {'loss': 0.9215, 'learning_rate': 1.523736694922684e-07, 'epoch': 0.95}
 95%|█████████▍| 9834/10395 [28:06:40<1:11:16,  7.62s/it] 95%|█████████▍| 9835/10395 [28:06:47<1:10:29,  7.55s/it]                                                         {'loss': 0.9174, 'learning_rate': 1.51832309623271e-07, 'epoch': 0.95}
 95%|█████████▍| 9835/10395 [28:06:47<1:10:29,  7.55s/it] 95%|█████████▍| 9836/10395 [28:06:55<1:10:28,  7.56s/it]                                                         {'loss': 0.863, 'learning_rate': 1.5129190579334707e-07, 'epoch': 0.95}
 95%|█████████▍| 9836/10395 [28:06:55<1:10:28,  7.56s/it] 95%|█████████▍| 9837/10395 [28:07:03<1:11:22,  7.67s/it]                                                         {'loss': 0.8633, 'learning_rate': 1.5075245805495798e-07, 'epoch': 0.95}
 95%|█████████▍| 9837/10395 [28:07:03<1:11:22,  7.67s/it] 95%|█████████▍| 9838/10395 [28:07:10<1:11:02,  7.65s/it]                                                         {'loss': 0.8846, 'learning_rate': 1.502139664604718e-07, 'epoch': 0.95}
 95%|█████████▍| 9838/10395 [28:07:10<1:11:02,  7.65s/it] 95%|█████████▍| 9839/10395 [28:07:18<1:11:05,  7.67s/it]                                                         {'loss': 0.8767, 'learning_rate': 1.4967643106216457e-07, 'epoch': 0.95}
 95%|█████████▍| 9839/10395 [28:07:18<1:11:05,  7.67s/it] 95%|█████████▍| 9840/10395 [28:07:27<1:14:57,  8.10s/it]                                                         {'loss': 0.7805, 'learning_rate': 1.4913985191222115e-07, 'epoch': 0.95}
 95%|█████████▍| 9840/10395 [28:07:27<1:14:57,  8.10s/it] 95%|█████████▍| 9841/10395 [28:07:36<1:16:12,  8.25s/it]                                                         {'loss': 0.8628, 'learning_rate': 1.4860422906272764e-07, 'epoch': 0.95}
 95%|█████████▍| 9841/10395 [28:07:36<1:16:12,  8.25s/it] 95%|█████████▍| 9842/10395 [28:07:43<1:14:51,  8.12s/it]                                                         {'loss': 0.8357, 'learning_rate': 1.4806956256568362e-07, 'epoch': 0.95}
 95%|█████████▍| 9842/10395 [28:07:43<1:14:51,  8.12s/it] 95%|█████████▍| 9843/10395 [28:08:01<1:42:03, 11.09s/it]                                                         {'loss': 0.3717, 'learning_rate': 1.4753585247299307e-07, 'epoch': 0.95}
 95%|█████████▍| 9843/10395 [28:08:01<1:42:03, 11.09s/it] 95%|█████████▍| 9844/10395 [28:08:10<1:34:27, 10.29s/it]                                                         {'loss': 0.7748, 'learning_rate': 1.470030988364668e-07, 'epoch': 0.95}
 95%|█████████▍| 9844/10395 [28:08:10<1:34:27, 10.29s/it] 95%|█████████▍| 9845/10395 [28:08:17<1:26:37,  9.45s/it]                                                         {'loss': 0.8245, 'learning_rate': 1.4647130170782453e-07, 'epoch': 0.95}
 95%|█████████▍| 9845/10395 [28:08:17<1:26:37,  9.45s/it] 95%|█████████▍| 9846/10395 [28:08:25<1:21:10,  8.87s/it]                                                         {'loss': 0.9466, 'learning_rate': 1.4594046113869053e-07, 'epoch': 0.95}
 95%|█████████▍| 9846/10395 [28:08:25<1:21:10,  8.87s/it] 95%|█████████▍| 9847/10395 [28:08:32<1:15:53,  8.31s/it]                                                         {'loss': 0.8235, 'learning_rate': 1.4541057718059804e-07, 'epoch': 0.95}
 95%|█████████▍| 9847/10395 [28:08:32<1:15:53,  8.31s/it] 95%|█████████▍| 9848/10395 [28:08:39<1:13:11,  8.03s/it]                                                         {'loss': 0.8885, 'learning_rate': 1.4488164988498922e-07, 'epoch': 0.95}
 95%|█████████▍| 9848/10395 [28:08:39<1:13:11,  8.03s/it] 95%|█████████▍| 9849/10395 [28:08:47<1:12:49,  8.00s/it]                                                         {'loss': 0.8722, 'learning_rate': 1.4435367930320743e-07, 'epoch': 0.95}
 95%|█████████▍| 9849/10395 [28:08:47<1:12:49,  8.00s/it] 95%|█████████▍| 9850/10395 [28:08:55<1:12:15,  7.96s/it]                                                         {'loss': 0.8267, 'learning_rate': 1.4382666548650948e-07, 'epoch': 0.95}
 95%|█████████▍| 9850/10395 [28:08:55<1:12:15,  7.96s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 95%|█████████▍| 9851/10395 [28:10:35<5:21:29, 35.46s/it]                                                         {'loss': 0.8519, 'learning_rate': 1.4330060848605554e-07, 'epoch': 0.95}
 95%|█████████▍| 9851/10395 [28:10:35<5:21:29, 35.46s/it] 95%|█████████▍| 9852/10395 [28:10:42<4:04:26, 27.01s/it]                                                         {'loss': 0.9253, 'learning_rate': 1.4277550835291476e-07, 'epoch': 0.95}
 95%|█████████▍| 9852/10395 [28:10:42<4:04:26, 27.01s/it] 95%|█████████▍| 9853/10395 [28:10:49<3:10:46, 21.12s/it]                                                         {'loss': 0.8323, 'learning_rate': 1.4225136513806414e-07, 'epoch': 0.95}
 95%|█████████▍| 9853/10395 [28:10:49<3:10:46, 21.12s/it] 95%|█████████▍| 9854/10395 [28:10:57<2:33:15, 17.00s/it]                                                         {'loss': 0.9161, 'learning_rate': 1.41728178892383e-07, 'epoch': 0.95}
 95%|█████████▍| 9854/10395 [28:10:57<2:33:15, 17.00s/it] 95%|█████████▍| 9855/10395 [28:11:04<2:07:56, 14.22s/it]                                                         {'loss': 0.85, 'learning_rate': 1.4120594966666512e-07, 'epoch': 0.95}
 95%|█████████▍| 9855/10395 [28:11:04<2:07:56, 14.22s/it] 95%|█████████▍| 9856/10395 [28:11:13<1:53:29, 12.63s/it]                                                         {'loss': 0.7491, 'learning_rate': 1.4068467751160442e-07, 'epoch': 0.95}
 95%|█████████▍| 9856/10395 [28:11:13<1:53:29, 12.63s/it] 95%|█████████▍| 9857/10395 [28:11:31<2:05:21, 13.98s/it]                                                         {'loss': 0.3211, 'learning_rate': 1.4016436247780485e-07, 'epoch': 0.95}
 95%|█████████▍| 9857/10395 [28:11:31<2:05:21, 13.98s/it] 95%|█████████▍| 9858/10395 [28:11:38<1:48:27, 12.12s/it]                                                         {'loss': 0.8822, 'learning_rate': 1.3964500461577934e-07, 'epoch': 0.95}
 95%|█████████▍| 9858/10395 [28:11:38<1:48:27, 12.12s/it] 95%|█████████▍| 9859/10395 [28:11:46<1:36:28, 10.80s/it]                                                         {'loss': 0.878, 'learning_rate': 1.3912660397594534e-07, 'epoch': 0.95}
 95%|█████████▍| 9859/10395 [28:11:46<1:36:28, 10.80s/it] 95%|█████████▍| 9860/10395 [28:11:54<1:29:33, 10.04s/it]                                                         {'loss': 0.8456, 'learning_rate': 1.3860916060862705e-07, 'epoch': 0.95}
 95%|█████████▍| 9860/10395 [28:11:54<1:29:33, 10.04s/it] 95%|█████████▍| 9861/10395 [28:12:02<1:22:32,  9.27s/it]                                                         {'loss': 0.9278, 'learning_rate': 1.380926745640576e-07, 'epoch': 0.95}
 95%|█████████▍| 9861/10395 [28:12:02<1:22:32,  9.27s/it] 95%|█████████▍| 9862/10395 [28:12:09<1:17:49,  8.76s/it]                                                         {'loss': 0.8244, 'learning_rate': 1.375771458923769e-07, 'epoch': 0.95}
 95%|█████████▍| 9862/10395 [28:12:09<1:17:49,  8.76s/it] 95%|█████████▍| 9863/10395 [28:12:17<1:15:35,  8.53s/it]                                                         {'loss': 0.7318, 'learning_rate': 1.3706257464363048e-07, 'epoch': 0.95}
 95%|█████████▍| 9863/10395 [28:12:17<1:15:35,  8.53s/it] 95%|█████████▍| 9864/10395 [28:12:25<1:12:12,  8.16s/it]                                                         {'loss': 0.8705, 'learning_rate': 1.3654896086777281e-07, 'epoch': 0.95}
 95%|█████████▍| 9864/10395 [28:12:25<1:12:12,  8.16s/it] 95%|█████████▍| 9865/10395 [28:12:32<1:11:01,  8.04s/it]                                                         {'loss': 0.8141, 'learning_rate': 1.3603630461466288e-07, 'epoch': 0.95}
 95%|█████████▍| 9865/10395 [28:12:32<1:11:01,  8.04s/it] 95%|█████████▍| 9866/10395 [28:12:40<1:09:39,  7.90s/it]                                                         {'loss': 0.8922, 'learning_rate': 1.355246059340698e-07, 'epoch': 0.95}
 95%|█████████▍| 9866/10395 [28:12:40<1:09:39,  7.90s/it] 95%|█████████▍| 9867/10395 [28:12:47<1:08:10,  7.75s/it]                                                         {'loss': 0.8211, 'learning_rate': 1.3501386487566714e-07, 'epoch': 0.95}
 95%|█████████▍| 9867/10395 [28:12:47<1:08:10,  7.75s/it] 95%|█████████▍| 9868/10395 [28:12:55<1:06:45,  7.60s/it]                                                         {'loss': 0.9263, 'learning_rate': 1.3450408148903638e-07, 'epoch': 0.95}
 95%|█████████▍| 9868/10395 [28:12:55<1:06:45,  7.60s/it] 95%|█████████▍| 9869/10395 [28:13:06<1:15:21,  8.60s/it]                                                         {'loss': 0.8763, 'learning_rate': 1.3399525582366792e-07, 'epoch': 0.95}
 95%|█████████▍| 9869/10395 [28:13:06<1:15:21,  8.60s/it] 95%|█████████▍| 9870/10395 [28:13:14<1:13:36,  8.41s/it]                                                         {'loss': 0.8264, 'learning_rate': 1.3348738792895666e-07, 'epoch': 0.95}
 95%|█████████▍| 9870/10395 [28:13:14<1:13:36,  8.41s/it] 95%|█████████▍| 9871/10395 [28:13:21<1:12:11,  8.27s/it]                                                         {'loss': 0.8365, 'learning_rate': 1.3298047785420321e-07, 'epoch': 0.95}
 95%|█████████▍| 9871/10395 [28:13:21<1:12:11,  8.27s/it] 95%|█████████▍| 9872/10395 [28:13:28<1:08:51,  7.90s/it]                                                         {'loss': 0.9442, 'learning_rate': 1.324745256486204e-07, 'epoch': 0.95}
 95%|█████████▍| 9872/10395 [28:13:28<1:08:51,  7.90s/it] 95%|█████████▍| 9873/10395 [28:13:36<1:07:50,  7.80s/it]                                                         {'loss': 0.8609, 'learning_rate': 1.319695313613234e-07, 'epoch': 0.95}
 95%|█████████▍| 9873/10395 [28:13:36<1:07:50,  7.80s/it] 95%|█████████▍| 9874/10395 [28:13:52<1:28:57, 10.24s/it]                                                         {'loss': 0.3908, 'learning_rate': 1.3146549504133522e-07, 'epoch': 0.95}
 95%|█████████▍| 9874/10395 [28:13:52<1:28:57, 10.24s/it] 95%|█████████▍| 9875/10395 [28:14:00<1:22:07,  9.48s/it]                                                         {'loss': 0.9118, 'learning_rate': 1.309624167375889e-07, 'epoch': 0.95}
 95%|█████████▍| 9875/10395 [28:14:00<1:22:07,  9.48s/it] 95%|█████████▌| 9876/10395 [28:14:08<1:18:37,  9.09s/it]                                                         {'loss': 0.8489, 'learning_rate': 1.3046029649891988e-07, 'epoch': 0.95}
 95%|█████████▌| 9876/10395 [28:14:08<1:18:37,  9.09s/it] 95%|█████████▌| 9877/10395 [28:14:15<1:13:38,  8.53s/it]                                                         {'loss': 0.8614, 'learning_rate': 1.299591343740758e-07, 'epoch': 0.95}
 95%|█████████▌| 9877/10395 [28:14:15<1:13:38,  8.53s/it] 95%|█████████▌| 9878/10395 [28:14:33<1:38:16, 11.41s/it]                                                         {'loss': 0.3457, 'learning_rate': 1.2945893041170553e-07, 'epoch': 0.95}
 95%|█████████▌| 9878/10395 [28:14:33<1:38:16, 11.41s/it] 95%|█████████▌| 9879/10395 [28:14:41<1:28:14, 10.26s/it]                                                         {'loss': 0.7954, 'learning_rate': 1.2895968466036912e-07, 'epoch': 0.95}
 95%|█████████▌| 9879/10395 [28:14:41<1:28:14, 10.26s/it] 95%|█████████▌| 9880/10395 [28:14:49<1:21:33,  9.50s/it]                                                         {'loss': 0.8124, 'learning_rate': 1.2846139716853111e-07, 'epoch': 0.95}
 95%|█████████▌| 9880/10395 [28:14:49<1:21:33,  9.50s/it] 95%|█████████▌| 9881/10395 [28:14:57<1:19:53,  9.33s/it]                                                         {'loss': 0.7578, 'learning_rate': 1.279640679845662e-07, 'epoch': 0.95}
 95%|█████████▌| 9881/10395 [28:14:57<1:19:53,  9.33s/it] 95%|█████████▌| 9882/10395 [28:15:05<1:14:53,  8.76s/it]                                                         {'loss': 0.8653, 'learning_rate': 1.2746769715675234e-07, 'epoch': 0.95}
 95%|█████████▌| 9882/10395 [28:15:05<1:14:53,  8.76s/it] 95%|█████████▌| 9883/10395 [28:15:14<1:16:28,  8.96s/it]                                                         {'loss': 0.7655, 'learning_rate': 1.269722847332766e-07, 'epoch': 0.95}
 95%|█████████▌| 9883/10395 [28:15:14<1:16:28,  8.96s/it] 95%|█████████▌| 9884/10395 [28:15:22<1:12:49,  8.55s/it]                                                         {'loss': 0.8356, 'learning_rate': 1.2647783076223274e-07, 'epoch': 0.95}
 95%|█████████▌| 9884/10395 [28:15:22<1:12:49,  8.55s/it] 95%|█████████▌| 9885/10395 [28:15:30<1:10:28,  8.29s/it]                                                         {'loss': 0.7643, 'learning_rate': 1.2598433529162235e-07, 'epoch': 0.95}
 95%|█████████▌| 9885/10395 [28:15:30<1:10:28,  8.29s/it] 95%|█████████▌| 9886/10395 [28:15:38<1:09:33,  8.20s/it]                                                         {'loss': 0.8437, 'learning_rate': 1.2549179836935155e-07, 'epoch': 0.95}
 95%|█████████▌| 9886/10395 [28:15:38<1:09:33,  8.20s/it] 95%|█████████▌| 9887/10395 [28:15:47<1:12:19,  8.54s/it]                                                         {'loss': 0.8216, 'learning_rate': 1.250002200432343e-07, 'epoch': 0.95}
 95%|█████████▌| 9887/10395 [28:15:47<1:12:19,  8.54s/it] 95%|█████████▌| 9888/10395 [28:15:54<1:09:19,  8.20s/it]                                                         {'loss': 0.8972, 'learning_rate': 1.2450960036099247e-07, 'epoch': 0.95}
 95%|█████████▌| 9888/10395 [28:15:54<1:09:19,  8.20s/it] 95%|█████████▌| 9889/10395 [28:16:02<1:07:43,  8.03s/it]                                                         {'loss': 0.8618, 'learning_rate': 1.240199393702557e-07, 'epoch': 0.95}
 95%|█████████▌| 9889/10395 [28:16:02<1:07:43,  8.03s/it] 95%|█████████▌| 9890/10395 [28:16:09<1:05:28,  7.78s/it]                                                         {'loss': 0.8617, 'learning_rate': 1.2353123711855707e-07, 'epoch': 0.95}
 95%|█████████▌| 9890/10395 [28:16:09<1:05:28,  7.78s/it] 95%|█████████▌| 9891/10395 [28:16:17<1:05:31,  7.80s/it]                                                         {'loss': 0.8958, 'learning_rate': 1.230434936533409e-07, 'epoch': 0.95}
 95%|█████████▌| 9891/10395 [28:16:17<1:05:31,  7.80s/it] 95%|█████████▌| 9892/10395 [28:16:25<1:06:08,  7.89s/it]                                                         {'loss': 0.8251, 'learning_rate': 1.2255670902195592e-07, 'epoch': 0.95}
 95%|█████████▌| 9892/10395 [28:16:25<1:06:08,  7.89s/it] 95%|█████████▌| 9893/10395 [28:16:34<1:09:05,  8.26s/it]                                                         {'loss': 0.8474, 'learning_rate': 1.2207088327165552e-07, 'epoch': 0.95}
 95%|█████████▌| 9893/10395 [28:16:34<1:09:05,  8.26s/it] 95%|█████████▌| 9894/10395 [28:16:42<1:06:59,  8.02s/it]                                                         {'loss': 0.8458, 'learning_rate': 1.2158601644960521e-07, 'epoch': 0.95}
 95%|█████████▌| 9894/10395 [28:16:42<1:06:59,  8.02s/it] 95%|█████████▌| 9895/10395 [28:16:49<1:05:33,  7.87s/it]                                                         {'loss': 0.8087, 'learning_rate': 1.2110210860287408e-07, 'epoch': 0.95}
 95%|█████████▌| 9895/10395 [28:16:49<1:05:33,  7.87s/it] 95%|█████████▌| 9896/10395 [28:17:05<1:26:28, 10.40s/it]                                                         {'loss': 0.3473, 'learning_rate': 1.2061915977843897e-07, 'epoch': 0.95}
 95%|█████████▌| 9896/10395 [28:17:06<1:26:28, 10.40s/it] 95%|█████████▌| 9897/10395 [28:17:13<1:20:17,  9.67s/it]                                                         {'loss': 0.8438, 'learning_rate': 1.2013717002318458e-07, 'epoch': 0.95}
 95%|█████████▌| 9897/10395 [28:17:13<1:20:17,  9.67s/it] 95%|█████████▌| 9898/10395 [28:17:21<1:14:56,  9.05s/it]                                                         {'loss': 0.8926, 'learning_rate': 1.1965613938389907e-07, 'epoch': 0.95}
 95%|█████████▌| 9898/10395 [28:17:21<1:14:56,  9.05s/it] 95%|█████████▌| 9899/10395 [28:17:38<1:35:28, 11.55s/it]                                                         {'loss': 0.3347, 'learning_rate': 1.1917606790728286e-07, 'epoch': 0.95}
 95%|█████████▌| 9899/10395 [28:17:38<1:35:28, 11.55s/it] 95%|█████████▌| 9900/10395 [28:17:47<1:28:31, 10.73s/it]                                                         {'loss': 0.8327, 'learning_rate': 1.1869695563993755e-07, 'epoch': 0.95}
 95%|█████████▌| 9900/10395 [28:17:47<1:28:31, 10.73s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 95%|█████████▌| 9901/10395 [28:19:25<5:02:34, 36.75s/it]                                                         {'loss': 0.9206, 'learning_rate': 1.1821880262837482e-07, 'epoch': 0.95}
 95%|█████████▌| 9901/10395 [28:19:25<5:02:34, 36.75s/it] 95%|█████████▌| 9902/10395 [28:19:33<3:50:34, 28.06s/it]                                                         {'loss': 0.8017, 'learning_rate': 1.1774160891901421e-07, 'epoch': 0.95}
 95%|█████████▌| 9902/10395 [28:19:33<3:50:34, 28.06s/it] 95%|█████████▌| 9903/10395 [28:19:41<3:02:12, 22.22s/it]                                                         {'loss': 0.8088, 'learning_rate': 1.1726537455817866e-07, 'epoch': 0.95}
 95%|█████████▌| 9903/10395 [28:19:41<3:02:12, 22.22s/it] 95%|█████████▌| 9904/10395 [28:19:49<2:25:27, 17.77s/it]                                                         {'loss': 0.795, 'learning_rate': 1.167900995921012e-07, 'epoch': 0.95}
 95%|█████████▌| 9904/10395 [28:19:49<2:25:27, 17.77s/it] 95%|█████████▌| 9905/10395 [28:19:57<2:02:24, 14.99s/it]                                                         {'loss': 0.7802, 'learning_rate': 1.1631578406692156e-07, 'epoch': 0.95}
 95%|█████████▌| 9905/10395 [28:19:57<2:02:24, 14.99s/it] 95%|█████████▌| 9906/10395 [28:20:05<1:43:52, 12.74s/it]                                                         {'loss': 0.7328, 'learning_rate': 1.1584242802868295e-07, 'epoch': 0.95}
 95%|█████████▌| 9906/10395 [28:20:05<1:43:52, 12.74s/it] 95%|█████████▌| 9907/10395 [28:20:12<1:31:54, 11.30s/it]                                                         {'loss': 0.8369, 'learning_rate': 1.153700315233397e-07, 'epoch': 0.95}
 95%|█████████▌| 9907/10395 [28:20:12<1:31:54, 11.30s/it] 95%|█████████▌| 9908/10395 [28:20:20<1:22:27, 10.16s/it]                                                         {'loss': 0.9102, 'learning_rate': 1.1489859459675068e-07, 'epoch': 0.95}
 95%|█████████▌| 9908/10395 [28:20:20<1:22:27, 10.16s/it] 95%|█████████▌| 9909/10395 [28:20:28<1:16:30,  9.45s/it]                                                         {'loss': 0.8327, 'learning_rate': 1.1442811729468039e-07, 'epoch': 0.95}
 95%|█████████▌| 9909/10395 [28:20:28<1:16:30,  9.45s/it] 95%|█████████▌| 9910/10395 [28:20:36<1:14:26,  9.21s/it]                                                         {'loss': 0.7609, 'learning_rate': 1.1395859966280453e-07, 'epoch': 0.95}
 95%|█████████▌| 9910/10395 [28:20:36<1:14:26,  9.21s/it] 95%|█████████▌| 9911/10395 [28:20:44<1:09:25,  8.61s/it]                                                         {'loss': 0.8309, 'learning_rate': 1.1349004174669886e-07, 'epoch': 0.95}
 95%|█████████▌| 9911/10395 [28:20:44<1:09:25,  8.61s/it] 95%|█████████▌| 9912/10395 [28:20:53<1:10:03,  8.70s/it]                                                         {'loss': 0.8315, 'learning_rate': 1.1302244359185365e-07, 'epoch': 0.95}
 95%|█████████▌| 9912/10395 [28:20:53<1:10:03,  8.70s/it] 95%|█████████▌| 9913/10395 [28:21:00<1:06:39,  8.30s/it]                                                         {'loss': 0.8303, 'learning_rate': 1.125558052436615e-07, 'epoch': 0.95}
 95%|█████████▌| 9913/10395 [28:21:00<1:06:39,  8.30s/it] 95%|█████████▌| 9914/10395 [28:21:09<1:07:43,  8.45s/it]                                                         {'loss': 0.8302, 'learning_rate': 1.1209012674742281e-07, 'epoch': 0.95}
 95%|█████████▌| 9914/10395 [28:21:09<1:07:43,  8.45s/it] 95%|█████████▌| 9915/10395 [28:21:17<1:06:31,  8.32s/it]                                                         {'loss': 0.8866, 'learning_rate': 1.1162540814834255e-07, 'epoch': 0.95}
 95%|█████████▌| 9915/10395 [28:21:17<1:06:31,  8.32s/it] 95%|█████████▌| 9916/10395 [28:21:24<1:04:37,  8.10s/it]                                                         {'loss': 0.9205, 'learning_rate': 1.1116164949153686e-07, 'epoch': 0.95}
 95%|█████████▌| 9916/10395 [28:21:24<1:04:37,  8.10s/it] 95%|█████████▌| 9917/10395 [28:21:32<1:03:28,  7.97s/it]                                                         {'loss': 0.7836, 'learning_rate': 1.1069885082202526e-07, 'epoch': 0.95}
 95%|█████████▌| 9917/10395 [28:21:32<1:03:28,  7.97s/it] 95%|█████████▌| 9918/10395 [28:21:40<1:03:41,  8.01s/it]                                                         {'loss': 0.8918, 'learning_rate': 1.1023701218473626e-07, 'epoch': 0.95}
 95%|█████████▌| 9918/10395 [28:21:40<1:03:41,  8.01s/it] 95%|█████████▌| 9919/10395 [28:21:48<1:03:51,  8.05s/it]                                                         {'loss': 0.8776, 'learning_rate': 1.097761336245029e-07, 'epoch': 0.95}
 95%|█████████▌| 9919/10395 [28:21:48<1:03:51,  8.05s/it] 95%|█████████▌| 9920/10395 [28:21:57<1:06:40,  8.42s/it]                                                         {'loss': 0.832, 'learning_rate': 1.0931621518606717e-07, 'epoch': 0.95}
 95%|█████████▌| 9920/10395 [28:21:57<1:06:40,  8.42s/it] 95%|█████████▌| 9921/10395 [28:22:06<1:06:07,  8.37s/it]                                                         {'loss': 0.8864, 'learning_rate': 1.0885725691407778e-07, 'epoch': 0.95}
 95%|█████████▌| 9921/10395 [28:22:06<1:06:07,  8.37s/it] 95%|█████████▌| 9922/10395 [28:22:13<1:03:17,  8.03s/it]                                                         {'loss': 0.895, 'learning_rate': 1.08399258853088e-07, 'epoch': 0.95}
 95%|█████████▌| 9922/10395 [28:22:13<1:03:17,  8.03s/it] 95%|█████████▌| 9923/10395 [28:22:20<1:01:10,  7.78s/it]                                                         {'loss': 0.8906, 'learning_rate': 1.0794222104755891e-07, 'epoch': 0.95}
 95%|█████████▌| 9923/10395 [28:22:21<1:01:10,  7.78s/it] 95%|█████████▌| 9924/10395 [28:22:29<1:02:36,  7.98s/it]                                                         {'loss': 0.8519, 'learning_rate': 1.074861435418606e-07, 'epoch': 0.95}
 95%|█████████▌| 9924/10395 [28:22:29<1:02:36,  7.98s/it] 95%|█████████▌| 9925/10395 [28:22:36<1:01:32,  7.86s/it]                                                         {'loss': 0.8425, 'learning_rate': 1.0703102638026652e-07, 'epoch': 0.95}
 95%|█████████▌| 9925/10395 [28:22:36<1:01:32,  7.86s/it] 95%|█████████▌| 9926/10395 [28:22:54<1:24:30, 10.81s/it]                                                         {'loss': 0.3316, 'learning_rate': 1.0657686960696023e-07, 'epoch': 0.95}
 95%|█████████▌| 9926/10395 [28:22:54<1:24:30, 10.81s/it] 95%|█████████▌| 9927/10395 [28:23:02<1:18:46, 10.10s/it]                                                         {'loss': 0.9409, 'learning_rate': 1.0612367326602757e-07, 'epoch': 0.95}
 95%|█████████▌| 9927/10395 [28:23:02<1:18:46, 10.10s/it] 96%|█████████▌| 9928/10395 [28:23:10<1:12:24,  9.30s/it]                                                         {'loss': 0.8824, 'learning_rate': 1.0567143740146558e-07, 'epoch': 0.96}
 96%|█████████▌| 9928/10395 [28:23:10<1:12:24,  9.30s/it] 96%|█████████▌| 9929/10395 [28:23:17<1:07:58,  8.75s/it]                                                         {'loss': 0.8205, 'learning_rate': 1.05220162057178e-07, 'epoch': 0.96}
 96%|█████████▌| 9929/10395 [28:23:17<1:07:58,  8.75s/it] 96%|█████████▌| 9930/10395 [28:23:25<1:05:13,  8.42s/it]                                                         {'loss': 0.8191, 'learning_rate': 1.0476984727696981e-07, 'epoch': 0.96}
 96%|█████████▌| 9930/10395 [28:23:25<1:05:13,  8.42s/it] 96%|█████████▌| 9931/10395 [28:23:32<1:02:57,  8.14s/it]                                                         {'loss': 0.9071, 'learning_rate': 1.0432049310455939e-07, 'epoch': 0.96}
 96%|█████████▌| 9931/10395 [28:23:32<1:02:57,  8.14s/it] 96%|█████████▌| 9932/10395 [28:23:39<1:00:21,  7.82s/it]                                                         {'loss': 0.8264, 'learning_rate': 1.0387209958356848e-07, 'epoch': 0.96}
 96%|█████████▌| 9932/10395 [28:23:39<1:00:21,  7.82s/it] 96%|█████████▌| 9933/10395 [28:23:47<59:28,  7.72s/it]                                                         {'loss': 0.9209, 'learning_rate': 1.0342466675752561e-07, 'epoch': 0.96}
 96%|█████████▌| 9933/10395 [28:23:47<59:28,  7.72s/it] 96%|█████████▌| 9934/10395 [28:23:55<1:00:26,  7.87s/it]                                                         {'loss': 0.8828, 'learning_rate': 1.0297819466986714e-07, 'epoch': 0.96}
 96%|█████████▌| 9934/10395 [28:23:55<1:00:26,  7.87s/it] 96%|█████████▌| 9935/10395 [28:24:04<1:01:40,  8.04s/it]                                                         {'loss': 0.8102, 'learning_rate': 1.0253268336393507e-07, 'epoch': 0.96}
 96%|█████████▌| 9935/10395 [28:24:04<1:01:40,  8.04s/it] 96%|█████████▌| 9936/10395 [28:24:12<1:01:20,  8.02s/it]                                                         {'loss': 0.6868, 'learning_rate': 1.0208813288298036e-07, 'epoch': 0.96}
 96%|█████████▌| 9936/10395 [28:24:12<1:01:20,  8.02s/it] 96%|█████████▌| 9937/10395 [28:24:20<1:01:57,  8.12s/it]                                                         {'loss': 0.881, 'learning_rate': 1.0164454327015738e-07, 'epoch': 0.96}
 96%|█████████▌| 9937/10395 [28:24:20<1:01:57,  8.12s/it] 96%|█████████▌| 9938/10395 [28:24:27<59:54,  7.87s/it]                                                         {'loss': 0.8948, 'learning_rate': 1.0120191456852945e-07, 'epoch': 0.96}
 96%|█████████▌| 9938/10395 [28:24:27<59:54,  7.87s/it] 96%|█████████▌| 9939/10395 [28:24:35<59:53,  7.88s/it]                                                       {'loss': 0.8351, 'learning_rate': 1.0076024682106444e-07, 'epoch': 0.96}
 96%|█████████▌| 9939/10395 [28:24:35<59:53,  7.88s/it] 96%|█████████▌| 9940/10395 [28:24:43<1:00:32,  7.98s/it]                                                         {'loss': 0.8222, 'learning_rate': 1.0031954007064137e-07, 'epoch': 0.96}
 96%|█████████▌| 9940/10395 [28:24:43<1:00:32,  7.98s/it] 96%|█████████▌| 9941/10395 [28:24:51<1:00:40,  8.02s/it]                                                         {'loss': 0.852, 'learning_rate': 9.987979436004158e-08, 'epoch': 0.96}
 96%|█████████▌| 9941/10395 [28:24:51<1:00:40,  8.02s/it] 96%|█████████▌| 9942/10395 [28:24:59<58:30,  7.75s/it]                                                         {'loss': 0.9283, 'learning_rate': 9.944100973195425e-08, 'epoch': 0.96}
 96%|█████████▌| 9942/10395 [28:24:59<58:30,  7.75s/it] 96%|█████████▌| 9943/10395 [28:25:06<57:37,  7.65s/it]                                                       {'loss': 0.8137, 'learning_rate': 9.900318622897642e-08, 'epoch': 0.96}
 96%|█████████▌| 9943/10395 [28:25:06<57:37,  7.65s/it] 96%|█████████▌| 9944/10395 [28:25:23<1:19:26, 10.57s/it]                                                         {'loss': 0.3292, 'learning_rate': 9.856632389361076e-08, 'epoch': 0.96}
 96%|█████████▌| 9944/10395 [28:25:23<1:19:26, 10.57s/it] 96%|█████████▌| 9945/10395 [28:25:31<1:13:43,  9.83s/it]                                                         {'loss': 0.8611, 'learning_rate': 9.813042276826779e-08, 'epoch': 0.96}
 96%|█████████▌| 9945/10395 [28:25:31<1:13:43,  9.83s/it] 96%|█████████▌| 9946/10395 [28:25:39<1:08:28,  9.15s/it]                                                         {'loss': 0.8013, 'learning_rate': 9.769548289526143e-08, 'epoch': 0.96}
 96%|█████████▌| 9946/10395 [28:25:39<1:08:28,  9.15s/it] 96%|█████████▌| 9947/10395 [28:25:46<1:04:36,  8.65s/it]                                                         {'loss': 0.8349, 'learning_rate': 9.726150431681681e-08, 'epoch': 0.96}
 96%|█████████▌| 9947/10395 [28:25:46<1:04:36,  8.65s/it] 96%|█████████▌| 9948/10395 [28:25:56<1:05:48,  8.83s/it]                                                         {'loss': 0.8154, 'learning_rate': 9.682848707506354e-08, 'epoch': 0.96}
 96%|█████████▌| 9948/10395 [28:25:56<1:05:48,  8.83s/it] 96%|█████████▌| 9949/10395 [28:26:03<1:02:23,  8.39s/it]                                                         {'loss': 0.8555, 'learning_rate': 9.63964312120369e-08, 'epoch': 0.96}
 96%|█████████▌| 9949/10395 [28:26:03<1:02:23,  8.39s/it] 96%|█████████▌| 9950/10395 [28:26:11<1:00:33,  8.16s/it]                                                         {'loss': 0.8947, 'learning_rate': 9.596533676968112e-08, 'epoch': 0.96}
 96%|█████████▌| 9950/10395 [28:26:11<1:00:33,  8.16s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 96%|█████████▌| 9951/10395 [28:27:51<4:25:04, 35.82s/it]                                                         {'loss': 0.8287, 'learning_rate': 9.553520378984604e-08, 'epoch': 0.96}
 96%|█████████▌| 9951/10395 [28:27:51<4:25:04, 35.82s/it] 96%|█████████▌| 9952/10395 [28:27:59<3:21:39, 27.31s/it]                                                         {'loss': 0.9162, 'learning_rate': 9.510603231428606e-08, 'epoch': 0.96}
 96%|█████████▌| 9952/10395 [28:27:59<3:21:39, 27.31s/it] 96%|█████████▌| 9953/10395 [28:28:06<2:37:28, 21.38s/it]                                                         {'loss': 0.8684, 'learning_rate': 9.467782238466672e-08, 'epoch': 0.96}
 96%|█████████▌| 9953/10395 [28:28:06<2:37:28, 21.38s/it] 96%|█████████▌| 9954/10395 [28:28:14<2:06:50, 17.26s/it]                                                         {'loss': 0.7971, 'learning_rate': 9.425057404255589e-08, 'epoch': 0.96}
 96%|█████████▌| 9954/10395 [28:28:14<2:06:50, 17.26s/it] 96%|█████████▌| 9955/10395 [28:28:21<1:45:12, 14.35s/it]                                                         {'loss': 0.9141, 'learning_rate': 9.38242873294315e-08, 'epoch': 0.96}
 96%|█████████▌| 9955/10395 [28:28:21<1:45:12, 14.35s/it] 96%|█████████▌| 9956/10395 [28:28:29<1:30:30, 12.37s/it]                                                         {'loss': 0.8856, 'learning_rate': 9.339896228667488e-08, 'epoch': 0.96}
 96%|█████████▌| 9956/10395 [28:28:29<1:30:30, 12.37s/it] 96%|█████████▌| 9957/10395 [28:28:37<1:20:23, 11.01s/it]                                                         {'loss': 0.846, 'learning_rate': 9.297459895557747e-08, 'epoch': 0.96}
 96%|█████████▌| 9957/10395 [28:28:37<1:20:23, 11.01s/it] 96%|█████████▌| 9958/10395 [28:28:45<1:14:05, 10.17s/it]                                                         {'loss': 0.8257, 'learning_rate': 9.255119737733409e-08, 'epoch': 0.96}
 96%|█████████▌| 9958/10395 [28:28:45<1:14:05, 10.17s/it] 96%|█████████▌| 9959/10395 [28:28:53<1:08:21,  9.41s/it]                                                         {'loss': 0.883, 'learning_rate': 9.212875759304851e-08, 'epoch': 0.96}
 96%|█████████▌| 9959/10395 [28:28:53<1:08:21,  9.41s/it] 96%|█████████▌| 9960/10395 [28:29:02<1:07:29,  9.31s/it]                                                         {'loss': 0.9187, 'learning_rate': 9.170727964372905e-08, 'epoch': 0.96}
 96%|█████████▌| 9960/10395 [28:29:02<1:07:29,  9.31s/it] 96%|█████████▌| 9961/10395 [28:29:09<1:03:37,  8.80s/it]                                                         {'loss': 0.8691, 'learning_rate': 9.128676357029298e-08, 'epoch': 0.96}
 96%|█████████▌| 9961/10395 [28:29:09<1:03:37,  8.80s/it] 96%|█████████▌| 9962/10395 [28:29:17<59:53,  8.30s/it]                                                         {'loss': 0.8279, 'learning_rate': 9.08672094135643e-08, 'epoch': 0.96}
 96%|█████████▌| 9962/10395 [28:29:17<59:53,  8.30s/it] 96%|█████████▌| 9963/10395 [28:29:24<58:18,  8.10s/it]                                                       {'loss': 0.8467, 'learning_rate': 9.044861721426934e-08, 'epoch': 0.96}
 96%|█████████▌| 9963/10395 [28:29:24<58:18,  8.10s/it] 96%|█████████▌| 9964/10395 [28:29:33<59:05,  8.23s/it]                                                       {'loss': 0.8852, 'learning_rate': 9.003098701304669e-08, 'epoch': 0.96}
 96%|█████████▌| 9964/10395 [28:29:33<59:05,  8.23s/it] 96%|█████████▌| 9965/10395 [28:29:40<57:56,  8.09s/it]                                                       {'loss': 0.8955, 'learning_rate': 8.961431885043836e-08, 'epoch': 0.96}
 96%|█████████▌| 9965/10395 [28:29:40<57:56,  8.09s/it] 96%|█████████▌| 9966/10395 [28:29:49<59:21,  8.30s/it]                                                       {'loss': 0.8191, 'learning_rate': 8.919861276689312e-08, 'epoch': 0.96}
 96%|█████████▌| 9966/10395 [28:29:49<59:21,  8.30s/it] 96%|█████████▌| 9967/10395 [28:29:57<57:17,  8.03s/it]                                                       {'loss': 0.8452, 'learning_rate': 8.878386880276757e-08, 'epoch': 0.96}
 96%|█████████▌| 9967/10395 [28:29:57<57:17,  8.03s/it] 96%|█████████▌| 9968/10395 [28:30:04<56:33,  7.95s/it]                                                       {'loss': 0.8554, 'learning_rate': 8.837008699832284e-08, 'epoch': 0.96}
 96%|█████████▌| 9968/10395 [28:30:04<56:33,  7.95s/it] 96%|█████████▌| 9969/10395 [28:30:12<56:45,  8.00s/it]                                                       {'loss': 0.8147, 'learning_rate': 8.79572673937279e-08, 'epoch': 0.96}
 96%|█████████▌| 9969/10395 [28:30:12<56:45,  8.00s/it] 96%|█████████▌| 9970/10395 [28:30:20<56:14,  7.94s/it]                                                       {'loss': 0.833, 'learning_rate': 8.75454100290618e-08, 'epoch': 0.96}
 96%|█████████▌| 9970/10395 [28:30:20<56:14,  7.94s/it] 96%|█████████▌| 9971/10395 [28:30:28<56:13,  7.96s/it]                                                       {'loss': 0.8716, 'learning_rate': 8.713451494430259e-08, 'epoch': 0.96}
 96%|█████████▌| 9971/10395 [28:30:28<56:13,  7.96s/it] 96%|█████████▌| 9972/10395 [28:30:37<57:20,  8.13s/it]                                                       {'loss': 0.8828, 'learning_rate': 8.672458217934166e-08, 'epoch': 0.96}
 96%|█████████▌| 9972/10395 [28:30:37<57:20,  8.13s/it] 96%|█████████▌| 9973/10395 [28:30:45<56:32,  8.04s/it]                                                       {'loss': 0.8728, 'learning_rate': 8.631561177397274e-08, 'epoch': 0.96}
 96%|█████████▌| 9973/10395 [28:30:45<56:32,  8.04s/it] 96%|█████████▌| 9974/10395 [28:30:53<57:37,  8.21s/it]                                                       {'loss': 0.8147, 'learning_rate': 8.590760376789964e-08, 'epoch': 0.96}
 96%|█████████▌| 9974/10395 [28:30:53<57:37,  8.21s/it] 96%|█████████▌| 9975/10395 [28:31:01<55:59,  8.00s/it]                                                       {'loss': 0.8017, 'learning_rate': 8.550055820072955e-08, 'epoch': 0.96}
 96%|█████████▌| 9975/10395 [28:31:01<55:59,  8.00s/it] 96%|█████████▌| 9976/10395 [28:31:10<58:09,  8.33s/it]                                                       {'loss': 0.8565, 'learning_rate': 8.509447511197644e-08, 'epoch': 0.96}
 96%|█████████▌| 9976/10395 [28:31:10<58:09,  8.33s/it] 96%|█████████▌| 9977/10395 [28:31:18<56:50,  8.16s/it]                                                       {'loss': 0.8951, 'learning_rate': 8.46893545410643e-08, 'epoch': 0.96}
 96%|█████████▌| 9977/10395 [28:31:18<56:50,  8.16s/it] 96%|█████████▌| 9978/10395 [28:31:25<54:58,  7.91s/it]                                                       {'loss': 0.9454, 'learning_rate': 8.42851965273217e-08, 'epoch': 0.96}
 96%|█████████▌| 9978/10395 [28:31:25<54:58,  7.91s/it] 96%|█████████▌| 9979/10395 [28:31:42<1:14:09, 10.70s/it]                                                         {'loss': 0.3354, 'learning_rate': 8.388200110998168e-08, 'epoch': 0.96}
 96%|█████████▌| 9979/10395 [28:31:42<1:14:09, 10.70s/it] 96%|█████████▌| 9980/10395 [28:31:50<1:07:27,  9.75s/it]                                                         {'loss': 0.912, 'learning_rate': 8.347976832818627e-08, 'epoch': 0.96}
 96%|█████████▌| 9980/10395 [28:31:50<1:07:27,  9.75s/it] 96%|█████████▌| 9981/10395 [28:31:57<1:02:50,  9.11s/it]                                                         {'loss': 0.8361, 'learning_rate': 8.307849822098313e-08, 'epoch': 0.96}
 96%|█████████▌| 9981/10395 [28:31:57<1:02:50,  9.11s/it] 96%|█████████▌| 9982/10395 [28:32:05<1:00:11,  8.75s/it]                                                         {'loss': 0.7874, 'learning_rate': 8.267819082732664e-08, 'epoch': 0.96}
 96%|█████████▌| 9982/10395 [28:32:05<1:00:11,  8.75s/it] 96%|█████████▌| 9983/10395 [28:32:13<57:36,  8.39s/it]                                                         {'loss': 0.8277, 'learning_rate': 8.227884618607796e-08, 'epoch': 0.96}
 96%|█████████▌| 9983/10395 [28:32:13<57:36,  8.39s/it] 96%|█████████▌| 9984/10395 [28:32:20<55:13,  8.06s/it]                                                       {'loss': 0.8269, 'learning_rate': 8.188046433600383e-08, 'epoch': 0.96}
 96%|█████████▌| 9984/10395 [28:32:20<55:13,  8.06s/it] 96%|█████████▌| 9985/10395 [28:32:29<57:11,  8.37s/it]                                                       {'loss': 0.8481, 'learning_rate': 8.148304531577999e-08, 'epoch': 0.96}
 96%|█████████▌| 9985/10395 [28:32:29<57:11,  8.37s/it] 96%|█████████▌| 9986/10395 [28:32:37<55:10,  8.09s/it]                                                       {'loss': 0.8695, 'learning_rate': 8.108658916398671e-08, 'epoch': 0.96}
 96%|█████████▌| 9986/10395 [28:32:37<55:10,  8.09s/it] 96%|█████████▌| 9987/10395 [28:32:44<53:37,  7.88s/it]                                                       {'loss': 0.911, 'learning_rate': 8.069109591910984e-08, 'epoch': 0.96}
 96%|█████████▌| 9987/10395 [28:32:44<53:37,  7.88s/it] 96%|█████████▌| 9988/10395 [28:32:52<54:41,  8.06s/it]                                                       {'loss': 0.8235, 'learning_rate': 8.029656561954424e-08, 'epoch': 0.96}
 96%|█████████▌| 9988/10395 [28:32:53<54:41,  8.06s/it] 96%|█████████▌| 9989/10395 [28:33:09<1:11:02, 10.50s/it]                                                         {'loss': 0.2798, 'learning_rate': 7.990299830358928e-08, 'epoch': 0.96}
 96%|█████████▌| 9989/10395 [28:33:09<1:11:02, 10.50s/it] 96%|█████████▌| 9990/10395 [28:33:25<1:22:48, 12.27s/it]                                                         {'loss': 0.3375, 'learning_rate': 7.951039400945215e-08, 'epoch': 0.96}
 96%|█████████▌| 9990/10395 [28:33:25<1:22:48, 12.27s/it] 96%|█████████▌| 9991/10395 [28:33:33<1:13:01, 10.85s/it]                                                         {'loss': 0.886, 'learning_rate': 7.911875277524572e-08, 'epoch': 0.96}
 96%|█████████▌| 9991/10395 [28:33:33<1:13:01, 10.85s/it] 96%|█████████▌| 9992/10395 [28:33:41<1:07:41, 10.08s/it]                                                         {'loss': 0.8603, 'learning_rate': 7.872807463898958e-08, 'epoch': 0.96}
 96%|█████████▌| 9992/10395 [28:33:41<1:07:41, 10.08s/it] 96%|█████████▌| 9993/10395 [28:33:48<1:02:19,  9.30s/it]                                                         {'loss': 0.8347, 'learning_rate': 7.833835963861002e-08, 'epoch': 0.96}
 96%|█████████▌| 9993/10395 [28:33:48<1:02:19,  9.30s/it] 96%|█████████▌| 9994/10395 [28:33:56<59:14,  8.86s/it]                                                         {'loss': 0.8601, 'learning_rate': 7.794960781194017e-08, 'epoch': 0.96}
 96%|█████████▌| 9994/10395 [28:33:56<59:14,  8.86s/it] 96%|█████████▌| 9995/10395 [28:34:05<58:09,  8.72s/it]                                                       {'loss': 0.8819, 'learning_rate': 7.756181919671869e-08, 'epoch': 0.96}
 96%|█████████▌| 9995/10395 [28:34:05<58:09,  8.72s/it] 96%|█████████▌| 9996/10395 [28:34:13<56:45,  8.54s/it]                                                       {'loss': 0.8229, 'learning_rate': 7.717499383059213e-08, 'epoch': 0.96}
 96%|█████████▌| 9996/10395 [28:34:13<56:45,  8.54s/it] 96%|█████████▌| 9997/10395 [28:34:21<55:51,  8.42s/it]                                                       {'loss': 0.8314, 'learning_rate': 7.678913175111157e-08, 'epoch': 0.96}
 96%|█████████▌| 9997/10395 [28:34:21<55:51,  8.42s/it] 96%|█████████▌| 9998/10395 [28:34:29<55:47,  8.43s/it]                                                       {'loss': 0.855, 'learning_rate': 7.640423299573596e-08, 'epoch': 0.96}
 96%|█████████▌| 9998/10395 [28:34:29<55:47,  8.43s/it] 96%|█████████▌| 9999/10395 [28:34:37<54:05,  8.20s/it]                                                       {'loss': 0.8698, 'learning_rate': 7.602029760183095e-08, 'epoch': 0.96}
 96%|█████████▌| 9999/10395 [28:34:37<54:05,  8.20s/it] 96%|█████████▌| 10000/10395 [28:34:47<57:21,  8.71s/it]                                                        {'loss': 0.792, 'learning_rate': 7.56373256066667e-08, 'epoch': 0.96}
 96%|█████████▌| 10000/10395 [28:34:47<57:21,  8.71s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 96%|█████████▌| 10001/10395 [28:36:27<3:58:01, 36.25s/it]                                                          {'loss': 0.8518, 'learning_rate': 7.52553170474235e-08, 'epoch': 0.96}
 96%|█████████▌| 10001/10395 [28:36:27<3:58:01, 36.25s/it] 96%|█████████▌| 10002/10395 [28:36:35<3:00:38, 27.58s/it]                                                          {'loss': 0.8228, 'learning_rate': 7.487427196118501e-08, 'epoch': 0.96}
 96%|█████████▌| 10002/10395 [28:36:35<3:00:38, 27.58s/it] 96%|█████████▌| 10003/10395 [28:36:42<2:20:09, 21.45s/it]                                                          {'loss': 0.9914, 'learning_rate': 7.449419038494166e-08, 'epoch': 0.96}
 96%|█████████▌| 10003/10395 [28:36:42<2:20:09, 21.45s/it] 96%|█████████▌| 10004/10395 [28:36:50<1:53:27, 17.41s/it]                                                          {'loss': 0.8246, 'learning_rate': 7.411507235559168e-08, 'epoch': 0.96}
 96%|█████████▌| 10004/10395 [28:36:50<1:53:27, 17.41s/it] 96%|█████████▌| 10005/10395 [28:36:59<1:36:24, 14.83s/it]                                                          {'loss': 0.7536, 'learning_rate': 7.373691790993897e-08, 'epoch': 0.96}
 96%|█████████▌| 10005/10395 [28:36:59<1:36:24, 14.83s/it] 96%|█████████▋| 10006/10395 [28:37:06<1:21:27, 12.56s/it]                                                          {'loss': 0.9809, 'learning_rate': 7.335972708469308e-08, 'epoch': 0.96}
 96%|█████████▋| 10006/10395 [28:37:06<1:21:27, 12.56s/it] 96%|█████████▋| 10007/10395 [28:37:14<1:13:23, 11.35s/it]                                                          {'loss': 0.8481, 'learning_rate': 7.298349991647135e-08, 'epoch': 0.96}
 96%|█████████▋| 10007/10395 [28:37:14<1:13:23, 11.35s/it] 96%|█████████▋| 10008/10395 [28:37:22<1:05:52, 10.21s/it]                                                          {'loss': 0.8258, 'learning_rate': 7.260823644179793e-08, 'epoch': 0.96}
 96%|█████████▋| 10008/10395 [28:37:22<1:05:52, 10.21s/it] 96%|█████████▋| 10009/10395 [28:37:30<1:01:33,  9.57s/it]                                                          {'loss': 0.8516, 'learning_rate': 7.223393669710255e-08, 'epoch': 0.96}
 96%|█████████▋| 10009/10395 [28:37:30<1:01:33,  9.57s/it] 96%|█████████▋| 10010/10395 [28:37:38<58:21,  9.10s/it]                                                          {'loss': 0.8739, 'learning_rate': 7.186060071872059e-08, 'epoch': 0.96}
 96%|█████████▋| 10010/10395 [28:37:38<58:21,  9.10s/it] 96%|█████████▋| 10011/10395 [28:37:46<55:56,  8.74s/it]                                                        {'loss': 0.8112, 'learning_rate': 7.148822854289417e-08, 'epoch': 0.96}
 96%|█████████▋| 10011/10395 [28:37:46<55:56,  8.74s/it] 96%|█████████▋| 10012/10395 [28:37:54<53:57,  8.45s/it]                                                        {'loss': 0.9002, 'learning_rate': 7.111682020577437e-08, 'epoch': 0.96}
 96%|█████████▋| 10012/10395 [28:37:54<53:57,  8.45s/it] 96%|█████████▋| 10013/10395 [28:38:02<53:04,  8.34s/it]                                                        {'loss': 0.8809, 'learning_rate': 7.074637574341459e-08, 'epoch': 0.96}
 96%|█████████▋| 10013/10395 [28:38:02<53:04,  8.34s/it] 96%|█████████▋| 10014/10395 [28:38:10<51:47,  8.16s/it]                                                        {'loss': 0.8879, 'learning_rate': 7.037689519177826e-08, 'epoch': 0.96}
 96%|█████████▋| 10014/10395 [28:38:10<51:47,  8.16s/it] 96%|█████████▋| 10015/10395 [28:38:17<50:31,  7.98s/it]                                                        {'loss': 0.8495, 'learning_rate': 7.000837858673338e-08, 'epoch': 0.96}
 96%|█████████▋| 10015/10395 [28:38:17<50:31,  7.98s/it] 96%|█████████▋| 10016/10395 [28:38:25<50:07,  7.94s/it]                                                        {'loss': 0.8406, 'learning_rate': 6.964082596405463e-08, 'epoch': 0.96}
 96%|█████████▋| 10016/10395 [28:38:25<50:07,  7.94s/it] 96%|█████████▋| 10017/10395 [28:38:33<49:28,  7.85s/it]                                                        {'loss': 0.9221, 'learning_rate': 6.927423735942352e-08, 'epoch': 0.96}
 96%|█████████▋| 10017/10395 [28:38:33<49:28,  7.85s/it] 96%|█████████▋| 10018/10395 [28:38:41<50:55,  8.10s/it]                                                        {'loss': 0.857, 'learning_rate': 6.890861280842709e-08, 'epoch': 0.96}
 96%|█████████▋| 10018/10395 [28:38:41<50:55,  8.10s/it] 96%|█████████▋| 10019/10395 [28:38:50<52:04,  8.31s/it]                                                        {'loss': 0.8414, 'learning_rate': 6.85439523465592e-08, 'epoch': 0.96}
 96%|█████████▋| 10019/10395 [28:38:50<52:04,  8.31s/it] 96%|█████████▋| 10020/10395 [28:38:57<50:07,  8.02s/it]                                                        {'loss': 0.8701, 'learning_rate': 6.818025600922151e-08, 'epoch': 0.96}
 96%|█████████▋| 10020/10395 [28:38:57<50:07,  8.02s/it] 96%|█████████▋| 10021/10395 [28:39:06<50:02,  8.03s/it]                                                        {'loss': 0.9185, 'learning_rate': 6.781752383172024e-08, 'epoch': 0.96}
 96%|█████████▋| 10021/10395 [28:39:06<50:02,  8.03s/it] 96%|█████████▋| 10022/10395 [28:39:14<49:59,  8.04s/it]                                                        {'loss': 0.8375, 'learning_rate': 6.745575584926722e-08, 'epoch': 0.96}
 96%|█████████▋| 10022/10395 [28:39:14<49:59,  8.04s/it] 96%|█████████▋| 10023/10395 [28:39:21<48:47,  7.87s/it]                                                        {'loss': 0.8529, 'learning_rate': 6.709495209698546e-08, 'epoch': 0.96}
 96%|█████████▋| 10023/10395 [28:39:21<48:47,  7.87s/it] 96%|█████████▋| 10024/10395 [28:39:29<48:07,  7.78s/it]                                                        {'loss': 0.8551, 'learning_rate': 6.673511260989807e-08, 'epoch': 0.96}
 96%|█████████▋| 10024/10395 [28:39:29<48:07,  7.78s/it] 96%|█████████▋| 10025/10395 [28:39:36<46:56,  7.61s/it]                                                        {'loss': 0.9898, 'learning_rate': 6.63762374229382e-08, 'epoch': 0.96}
 96%|█████████▋| 10025/10395 [28:39:36<46:56,  7.61s/it] 96%|█████████▋| 10026/10395 [28:39:45<49:36,  8.07s/it]                                                        {'loss': 0.8626, 'learning_rate': 6.601832657094575e-08, 'epoch': 0.96}
 96%|█████████▋| 10026/10395 [28:39:45<49:36,  8.07s/it] 96%|█████████▋| 10027/10395 [28:39:53<48:49,  7.96s/it]                                                        {'loss': 0.9322, 'learning_rate': 6.566138008866518e-08, 'epoch': 0.96}
 96%|█████████▋| 10027/10395 [28:39:53<48:49,  7.96s/it] 96%|█████████▋| 10028/10395 [28:40:01<48:47,  7.98s/it]                                                        {'loss': 0.8645, 'learning_rate': 6.530539801074765e-08, 'epoch': 0.96}
 96%|█████████▋| 10028/10395 [28:40:01<48:47,  7.98s/it] 96%|█████████▋| 10029/10395 [28:40:08<47:35,  7.80s/it]                                                        {'loss': 0.8626, 'learning_rate': 6.495038037175106e-08, 'epoch': 0.96}
 96%|█████████▋| 10029/10395 [28:40:08<47:35,  7.80s/it] 96%|█████████▋| 10030/10395 [28:40:17<50:12,  8.25s/it]                                                        {'loss': 0.7965, 'learning_rate': 6.459632720614118e-08, 'epoch': 0.96}
 96%|█████████▋| 10030/10395 [28:40:17<50:12,  8.25s/it] 96%|█████████▋| 10031/10395 [28:40:25<49:02,  8.08s/it]                                                        {'loss': 0.8307, 'learning_rate': 6.424323854828718e-08, 'epoch': 0.96}
 96%|█████████▋| 10031/10395 [28:40:25<49:02,  8.08s/it] 97%|█████████▋| 10032/10395 [28:40:33<48:12,  7.97s/it]                                                        {'loss': 0.8954, 'learning_rate': 6.38911144324672e-08, 'epoch': 0.97}
 97%|█████████▋| 10032/10395 [28:40:33<48:12,  7.97s/it] 97%|█████████▋| 10033/10395 [28:40:40<46:49,  7.76s/it]                                                        {'loss': 0.9145, 'learning_rate': 6.35399548928639e-08, 'epoch': 0.97}
 97%|█████████▋| 10033/10395 [28:40:40<46:49,  7.76s/it] 97%|█████████▋| 10034/10395 [28:40:48<47:18,  7.86s/it]                                                        {'loss': 0.7464, 'learning_rate': 6.31897599635678e-08, 'epoch': 0.97}
 97%|█████████▋| 10034/10395 [28:40:48<47:18,  7.86s/it] 97%|█████████▋| 10035/10395 [28:40:56<47:54,  7.98s/it]                                                        {'loss': 0.789, 'learning_rate': 6.284052967857501e-08, 'epoch': 0.97}
 97%|█████████▋| 10035/10395 [28:40:56<47:54,  7.98s/it] 97%|█████████▋| 10036/10395 [28:41:04<47:16,  7.90s/it]                                                        {'loss': 0.8225, 'learning_rate': 6.249226407178732e-08, 'epoch': 0.97}
 97%|█████████▋| 10036/10395 [28:41:04<47:16,  7.90s/it] 97%|█████████▋| 10037/10395 [28:41:14<50:09,  8.41s/it]                                                        {'loss': 0.7952, 'learning_rate': 6.214496317701435e-08, 'epoch': 0.97}
 97%|█████████▋| 10037/10395 [28:41:14<50:09,  8.41s/it] 97%|█████████▋| 10038/10395 [28:41:22<49:46,  8.36s/it]                                                        {'loss': 0.7493, 'learning_rate': 6.179862702797135e-08, 'epoch': 0.97}
 97%|█████████▋| 10038/10395 [28:41:22<49:46,  8.36s/it] 97%|█████████▋| 10039/10395 [28:41:30<49:38,  8.37s/it]                                                        {'loss': 0.7687, 'learning_rate': 6.14532556582792e-08, 'epoch': 0.97}
 97%|█████████▋| 10039/10395 [28:41:30<49:38,  8.37s/it] 97%|█████████▋| 10040/10395 [28:41:38<48:14,  8.15s/it]                                                        {'loss': 0.9014, 'learning_rate': 6.110884910146664e-08, 'epoch': 0.97}
 97%|█████████▋| 10040/10395 [28:41:38<48:14,  8.15s/it] 97%|█████████▋| 10041/10395 [28:41:45<46:39,  7.91s/it]                                                        {'loss': 0.8212, 'learning_rate': 6.076540739096804e-08, 'epoch': 0.97}
 97%|█████████▋| 10041/10395 [28:41:45<46:39,  7.91s/it] 97%|█████████▋| 10042/10395 [28:41:53<46:37,  7.93s/it]                                                        {'loss': 0.8885, 'learning_rate': 6.042293056012228e-08, 'epoch': 0.97}
 97%|█████████▋| 10042/10395 [28:41:53<46:37,  7.93s/it] 97%|█████████▋| 10043/10395 [28:42:01<45:24,  7.74s/it]                                                        {'loss': 0.779, 'learning_rate': 6.008141864217831e-08, 'epoch': 0.97}
 97%|█████████▋| 10043/10395 [28:42:01<45:24,  7.74s/it] 97%|█████████▋| 10044/10395 [28:42:09<45:43,  7.82s/it]                                                        {'loss': 0.7876, 'learning_rate': 5.974087167028741e-08, 'epoch': 0.97}
 97%|█████████▋| 10044/10395 [28:42:09<45:43,  7.82s/it] 97%|█████████▋| 10045/10395 [28:42:16<45:31,  7.80s/it]                                                        {'loss': 0.8312, 'learning_rate': 5.940128967751091e-08, 'epoch': 0.97}
 97%|█████████▋| 10045/10395 [28:42:16<45:31,  7.80s/it] 97%|█████████▋| 10046/10395 [28:42:23<44:05,  7.58s/it]                                                        {'loss': 0.8109, 'learning_rate': 5.906267269681465e-08, 'epoch': 0.97}
 97%|█████████▋| 10046/10395 [28:42:23<44:05,  7.58s/it] 97%|█████████▋| 10047/10395 [28:42:32<44:49,  7.73s/it]                                                        {'loss': 0.8672, 'learning_rate': 5.872502076107012e-08, 'epoch': 0.97}
 97%|█████████▋| 10047/10395 [28:42:32<44:49,  7.73s/it] 97%|█████████▋| 10048/10395 [28:42:40<45:16,  7.83s/it]                                                        {'loss': 0.7419, 'learning_rate': 5.838833390305554e-08, 'epoch': 0.97}
 97%|█████████▋| 10048/10395 [28:42:40<45:16,  7.83s/it] 97%|█████████▋| 10049/10395 [28:42:48<45:53,  7.96s/it]                                                        {'loss': 0.8387, 'learning_rate': 5.8052612155455877e-08, 'epoch': 0.97}
 97%|█████████▋| 10049/10395 [28:42:48<45:53,  7.96s/it] 97%|█████████▋| 10050/10395 [28:42:56<45:12,  7.86s/it]                                                        {'loss': 0.8198, 'learning_rate': 5.7717855550862846e-08, 'epoch': 0.97}
 97%|█████████▋| 10050/10395 [28:42:56<45:12,  7.86s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 97%|█████████▋| 10051/10395 [28:44:41<3:32:19, 37.03s/it]                                                          {'loss': 0.8081, 'learning_rate': 5.738406412177488e-08, 'epoch': 0.97}
 97%|█████████▋| 10051/10395 [28:44:41<3:32:19, 37.03s/it] 97%|█████████▋| 10052/10395 [28:44:49<2:42:09, 28.37s/it]                                                          {'loss': 0.8403, 'learning_rate': 5.705123790059275e-08, 'epoch': 0.97}
 97%|█████████▋| 10052/10395 [28:44:49<2:42:09, 28.37s/it] 97%|█████████▋| 10053/10395 [28:44:57<2:07:21, 22.34s/it]                                                          {'loss': 0.8331, 'learning_rate': 5.6719376919629475e-08, 'epoch': 0.97}
 97%|█████████▋| 10053/10395 [28:44:57<2:07:21, 22.34s/it] 97%|█████████▋| 10054/10395 [28:45:06<1:43:32, 18.22s/it]                                                          {'loss': 0.8156, 'learning_rate': 5.638848121110041e-08, 'epoch': 0.97}
 97%|█████████▋| 10054/10395 [28:45:06<1:43:32, 18.22s/it] 97%|█████████▋| 10055/10395 [28:45:13<1:25:31, 15.09s/it]                                                          {'loss': 0.8292, 'learning_rate': 5.605855080712763e-08, 'epoch': 0.97}
 97%|█████████▋| 10055/10395 [28:45:13<1:25:31, 15.09s/it] 97%|█████████▋| 10056/10395 [28:45:21<1:12:46, 12.88s/it]                                                          {'loss': 0.869, 'learning_rate': 5.5729585739739966e-08, 'epoch': 0.97}
 97%|█████████▋| 10056/10395 [28:45:21<1:12:46, 12.88s/it] 97%|█████████▋| 10057/10395 [28:45:29<1:03:49, 11.33s/it]                                                          {'loss': 0.9144, 'learning_rate': 5.540158604087298e-08, 'epoch': 0.97}
 97%|█████████▋| 10057/10395 [28:45:29<1:03:49, 11.33s/it] 97%|█████████▋| 10058/10395 [28:45:47<1:14:53, 13.33s/it]                                                          {'loss': 0.3526, 'learning_rate': 5.507455174236898e-08, 'epoch': 0.97}
 97%|█████████▋| 10058/10395 [28:45:47<1:14:53, 13.33s/it] 97%|█████████▋| 10059/10395 [28:45:55<1:05:20, 11.67s/it]                                                          {'loss': 0.8798, 'learning_rate': 5.474848287597478e-08, 'epoch': 0.97}
 97%|█████████▋| 10059/10395 [28:45:55<1:05:20, 11.67s/it] 97%|█████████▋| 10060/10395 [28:46:03<59:05, 10.58s/it]                                                          {'loss': 0.8358, 'learning_rate': 5.442337947334508e-08, 'epoch': 0.97}
 97%|█████████▋| 10060/10395 [28:46:03<59:05, 10.58s/it] 97%|█████████▋| 10061/10395 [28:46:10<53:54,  9.68s/it]                                                        {'loss': 0.882, 'learning_rate': 5.4099241566040184e-08, 'epoch': 0.97}
 97%|█████████▋| 10061/10395 [28:46:10<53:54,  9.68s/it] 97%|█████████▋| 10062/10395 [28:46:19<51:31,  9.28s/it]                                                        {'loss': 0.883, 'learning_rate': 5.377606918552603e-08, 'epoch': 0.97}
 97%|█████████▋| 10062/10395 [28:46:19<51:31,  9.28s/it] 97%|█████████▋| 10063/10395 [28:46:26<48:45,  8.81s/it]                                                        {'loss': 0.8847, 'learning_rate': 5.34538623631764e-08, 'epoch': 0.97}
 97%|█████████▋| 10063/10395 [28:46:26<48:45,  8.81s/it] 97%|█████████▋| 10064/10395 [28:46:34<47:17,  8.57s/it]                                                        {'loss': 0.8792, 'learning_rate': 5.313262113026962e-08, 'epoch': 0.97}
 97%|█████████▋| 10064/10395 [28:46:34<47:17,  8.57s/it] 97%|█████████▋| 10065/10395 [28:46:42<45:25,  8.26s/it]                                                        {'loss': 0.8378, 'learning_rate': 5.281234551799075e-08, 'epoch': 0.97}
 97%|█████████▋| 10065/10395 [28:46:42<45:25,  8.26s/it] 97%|█████████▋| 10066/10395 [28:46:49<43:52,  8.00s/it]                                                        {'loss': 0.8826, 'learning_rate': 5.249303555743268e-08, 'epoch': 0.97}
 97%|█████████▋| 10066/10395 [28:46:49<43:52,  8.00s/it] 97%|█████████▋| 10067/10395 [28:46:58<45:09,  8.26s/it]                                                        {'loss': 0.8112, 'learning_rate': 5.2174691279593955e-08, 'epoch': 0.97}
 97%|█████████▋| 10067/10395 [28:46:58<45:09,  8.26s/it] 97%|█████████▋| 10068/10395 [28:47:06<43:33,  7.99s/it]                                                        {'loss': 0.8022, 'learning_rate': 5.185731271537653e-08, 'epoch': 0.97}
 97%|█████████▋| 10068/10395 [28:47:06<43:33,  7.99s/it] 97%|█████████▋| 10069/10395 [28:47:14<44:13,  8.14s/it]                                                        {'loss': 0.7865, 'learning_rate': 5.1540899895591304e-08, 'epoch': 0.97}
 97%|█████████▋| 10069/10395 [28:47:14<44:13,  8.14s/it] 97%|█████████▋| 10070/10395 [28:47:21<42:56,  7.93s/it]                                                        {'loss': 0.8547, 'learning_rate': 5.1225452850957035e-08, 'epoch': 0.97}
 97%|█████████▋| 10070/10395 [28:47:21<42:56,  7.93s/it] 97%|█████████▋| 10071/10395 [28:47:30<43:14,  8.01s/it]                                                        {'loss': 0.889, 'learning_rate': 5.091097161209369e-08, 'epoch': 0.97}
 97%|█████████▋| 10071/10395 [28:47:30<43:14,  8.01s/it] 97%|█████████▋| 10072/10395 [28:47:37<42:40,  7.93s/it]                                                        {'loss': 0.8823, 'learning_rate': 5.059745620953349e-08, 'epoch': 0.97}
 97%|█████████▋| 10072/10395 [28:47:37<42:40,  7.93s/it] 97%|█████████▋| 10073/10395 [28:47:45<42:18,  7.88s/it]                                                        {'loss': 0.8752, 'learning_rate': 5.028490667370989e-08, 'epoch': 0.97}
 97%|█████████▋| 10073/10395 [28:47:45<42:18,  7.88s/it] 97%|█████████▋| 10074/10395 [28:47:53<42:12,  7.89s/it]                                                        {'loss': 0.8151, 'learning_rate': 4.997332303496416e-08, 'epoch': 0.97}
 97%|█████████▋| 10074/10395 [28:47:53<42:12,  7.89s/it] 97%|█████████▋| 10075/10395 [28:48:01<41:40,  7.81s/it]                                                        {'loss': 0.8735, 'learning_rate': 4.9662705323545444e-08, 'epoch': 0.97}
 97%|█████████▋| 10075/10395 [28:48:01<41:40,  7.81s/it] 97%|█████████▋| 10076/10395 [28:48:08<40:34,  7.63s/it]                                                        {'loss': 0.7671, 'learning_rate': 4.93530535696074e-08, 'epoch': 0.97}
 97%|█████████▋| 10076/10395 [28:48:08<40:34,  7.63s/it] 97%|█████████▋| 10077/10395 [28:48:18<44:16,  8.35s/it]                                                        {'loss': 0.788, 'learning_rate': 4.904436780321043e-08, 'epoch': 0.97}
 97%|█████████▋| 10077/10395 [28:48:18<44:16,  8.35s/it] 97%|█████████▋| 10078/10395 [28:48:26<42:53,  8.12s/it]                                                        {'loss': 0.8873, 'learning_rate': 4.873664805432054e-08, 'epoch': 0.97}
 97%|█████████▋| 10078/10395 [28:48:26<42:53,  8.12s/it] 97%|█████████▋| 10079/10395 [28:48:34<43:08,  8.19s/it]                                                        {'loss': 0.9181, 'learning_rate': 4.8429894352810534e-08, 'epoch': 0.97}
 97%|█████████▋| 10079/10395 [28:48:34<43:08,  8.19s/it] 97%|█████████▋| 10080/10395 [28:48:42<42:07,  8.02s/it]                                                        {'loss': 0.8519, 'learning_rate': 4.8124106728461016e-08, 'epoch': 0.97}
 97%|█████████▋| 10080/10395 [28:48:42<42:07,  8.02s/it] 97%|█████████▋| 10081/10395 [28:48:50<42:05,  8.04s/it]                                                        {'loss': 0.8229, 'learning_rate': 4.781928521095491e-08, 'epoch': 0.97}
 97%|█████████▋| 10081/10395 [28:48:50<42:05,  8.04s/it] 97%|█████████▋| 10082/10395 [28:48:57<40:39,  7.80s/it]                                                        {'loss': 0.9049, 'learning_rate': 4.7515429829885215e-08, 'epoch': 0.97}
 97%|█████████▋| 10082/10395 [28:48:57<40:39,  7.80s/it] 97%|█████████▋| 10083/10395 [28:49:05<41:21,  7.95s/it]                                                        {'loss': 0.8407, 'learning_rate': 4.721254061474945e-08, 'epoch': 0.97}
 97%|█████████▋| 10083/10395 [28:49:05<41:21,  7.95s/it] 97%|█████████▋| 10084/10395 [28:49:13<40:41,  7.85s/it]                                                        {'loss': 0.8872, 'learning_rate': 4.691061759495075e-08, 'epoch': 0.97}
 97%|█████████▋| 10084/10395 [28:49:13<40:41,  7.85s/it] 97%|█████████▋| 10085/10395 [28:49:21<41:46,  8.09s/it]                                                        {'loss': 0.8741, 'learning_rate': 4.6609660799799005e-08, 'epoch': 0.97}
 97%|█████████▋| 10085/10395 [28:49:21<41:46,  8.09s/it] 97%|█████████▋| 10086/10395 [28:49:30<43:08,  8.38s/it]                                                        {'loss': 0.837, 'learning_rate': 4.6309670258511964e-08, 'epoch': 0.97}
 97%|█████████▋| 10086/10395 [28:49:30<43:08,  8.38s/it] 97%|█████████▋| 10087/10395 [28:49:38<42:12,  8.22s/it]                                                        {'loss': 0.891, 'learning_rate': 4.601064600020966e-08, 'epoch': 0.97}
 97%|█████████▋| 10087/10395 [28:49:38<42:12,  8.22s/it] 97%|█████████▋| 10088/10395 [28:49:47<42:23,  8.28s/it]                                                        {'loss': 0.8646, 'learning_rate': 4.571258805392331e-08, 'epoch': 0.97}
 97%|█████████▋| 10088/10395 [28:49:47<42:23,  8.28s/it] 97%|█████████▋| 10089/10395 [28:49:54<41:00,  8.04s/it]                                                        {'loss': 0.9375, 'learning_rate': 4.541549644858645e-08, 'epoch': 0.97}
 97%|█████████▋| 10089/10395 [28:49:54<41:00,  8.04s/it] 97%|█████████▋| 10090/10395 [28:50:03<41:50,  8.23s/it]                                                        {'loss': 0.7772, 'learning_rate': 4.511937121303933e-08, 'epoch': 0.97}
 97%|█████████▋| 10090/10395 [28:50:03<41:50,  8.23s/it] 97%|█████████▋| 10091/10395 [28:50:10<40:12,  7.94s/it]                                                        {'loss': 0.8644, 'learning_rate': 4.482421237603007e-08, 'epoch': 0.97}
 97%|█████████▋| 10091/10395 [28:50:10<40:12,  7.94s/it] 97%|█████████▋| 10092/10395 [28:50:19<41:02,  8.13s/it]                                                        {'loss': 0.8003, 'learning_rate': 4.453001996621242e-08, 'epoch': 0.97}
 97%|█████████▋| 10092/10395 [28:50:19<41:02,  8.13s/it] 97%|█████████▋| 10093/10395 [28:50:26<39:48,  7.91s/it]                                                        {'loss': 0.7563, 'learning_rate': 4.423679401214576e-08, 'epoch': 0.97}
 97%|█████████▋| 10093/10395 [28:50:26<39:48,  7.91s/it] 97%|█████████▋| 10094/10395 [28:50:34<39:11,  7.81s/it]                                                        {'loss': 0.9128, 'learning_rate': 4.394453454229508e-08, 'epoch': 0.97}
 97%|█████████▋| 10094/10395 [28:50:34<39:11,  7.81s/it] 97%|█████████▋| 10095/10395 [28:50:41<38:51,  7.77s/it]                                                        {'loss': 0.8498, 'learning_rate': 4.365324158503326e-08, 'epoch': 0.97}
 97%|█████████▋| 10095/10395 [28:50:41<38:51,  7.77s/it] 97%|█████████▋| 10096/10395 [28:50:49<38:28,  7.72s/it]                                                        {'loss': 0.8396, 'learning_rate': 4.336291516863767e-08, 'epoch': 0.97}
 97%|█████████▋| 10096/10395 [28:50:49<38:28,  7.72s/it] 97%|█████████▋| 10097/10395 [28:50:56<38:00,  7.65s/it]                                                        {'loss': 0.8218, 'learning_rate': 4.307355532129243e-08, 'epoch': 0.97}
 97%|█████████▋| 10097/10395 [28:50:56<38:00,  7.65s/it] 97%|█████████▋| 10098/10395 [28:51:04<37:29,  7.58s/it]                                                        {'loss': 0.8913, 'learning_rate': 4.278516207108952e-08, 'epoch': 0.97}
 97%|█████████▋| 10098/10395 [28:51:04<37:29,  7.58s/it] 97%|█████████▋| 10099/10395 [28:51:12<37:34,  7.62s/it]                                                        {'loss': 0.8519, 'learning_rate': 4.2497735446023204e-08, 'epoch': 0.97}
 97%|█████████▋| 10099/10395 [28:51:12<37:34,  7.62s/it] 97%|█████████▋| 10100/10395 [28:51:19<37:12,  7.57s/it]                                                        {'loss': 0.851, 'learning_rate': 4.221127547399895e-08, 'epoch': 0.97}
 97%|█████████▋| 10100/10395 [28:51:19<37:12,  7.57s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 97%|█████████▋| 10101/10395 [28:53:02<2:57:42, 36.27s/it]                                                          {'loss': 0.8277, 'learning_rate': 4.192578218282339e-08, 'epoch': 0.97}
 97%|█████████▋| 10101/10395 [28:53:02<2:57:42, 36.27s/it] 97%|█████████▋| 10102/10395 [28:53:11<2:17:15, 28.11s/it]                                                          {'loss': 0.7844, 'learning_rate': 4.1641255600212146e-08, 'epoch': 0.97}
 97%|█████████▋| 10102/10395 [28:53:11<2:17:15, 28.11s/it] 97%|█████████▋| 10103/10395 [28:53:19<1:47:21, 22.06s/it]                                                          {'loss': 0.7984, 'learning_rate': 4.1357695753786456e-08, 'epoch': 0.97}
 97%|█████████▋| 10103/10395 [28:53:19<1:47:21, 22.06s/it] 97%|█████████▋| 10104/10395 [28:53:27<1:26:22, 17.81s/it]                                                          {'loss': 0.8291, 'learning_rate': 4.107510267107429e-08, 'epoch': 0.97}
 97%|█████████▋| 10104/10395 [28:53:27<1:26:22, 17.81s/it] 97%|█████████▋| 10105/10395 [28:53:35<1:11:45, 14.85s/it]                                                          {'loss': 0.7818, 'learning_rate': 4.0793476379510365e-08, 'epoch': 0.97}
 97%|█████████▋| 10105/10395 [28:53:35<1:11:45, 14.85s/it] 97%|█████████▋| 10106/10395 [28:53:44<1:02:16, 12.93s/it]                                                          {'loss': 0.8255, 'learning_rate': 4.0512816906430604e-08, 'epoch': 0.97}
 97%|█████████▋| 10106/10395 [28:53:44<1:02:16, 12.93s/it] 97%|█████████▋| 10107/10395 [28:53:51<53:47, 11.21s/it]                                                          {'loss': 0.8625, 'learning_rate': 4.0233124279084327e-08, 'epoch': 0.97}
 97%|█████████▋| 10107/10395 [28:53:51<53:47, 11.21s/it] 97%|█████████▋| 10108/10395 [28:53:58<48:02, 10.04s/it]                                                        {'loss': 0.9666, 'learning_rate': 3.9954398524622015e-08, 'epoch': 0.97}
 97%|█████████▋| 10108/10395 [28:53:58<48:02, 10.04s/it] 97%|█████████▋| 10109/10395 [28:54:06<44:52,  9.42s/it]                                                        {'loss': 0.9084, 'learning_rate': 3.9676639670102044e-08, 'epoch': 0.97}
 97%|█████████▋| 10109/10395 [28:54:06<44:52,  9.42s/it] 97%|█████████▋| 10110/10395 [28:54:13<41:47,  8.80s/it]                                                        {'loss': 0.8804, 'learning_rate': 3.93998477424884e-08, 'epoch': 0.97}
 97%|█████████▋| 10110/10395 [28:54:13<41:47,  8.80s/it] 97%|█████████▋| 10111/10395 [28:54:21<40:19,  8.52s/it]                                                        {'loss': 0.8424, 'learning_rate': 3.9124022768651794e-08, 'epoch': 0.97}
 97%|█████████▋| 10111/10395 [28:54:21<40:19,  8.52s/it] 97%|█████████▋| 10112/10395 [28:54:29<39:00,  8.27s/it]                                                        {'loss': 0.8425, 'learning_rate': 3.88491647753686e-08, 'epoch': 0.97}
 97%|█████████▋| 10112/10395 [28:54:29<39:00,  8.27s/it] 97%|█████████▋| 10113/10395 [28:54:37<38:32,  8.20s/it]                                                        {'loss': 0.797, 'learning_rate': 3.857527378932191e-08, 'epoch': 0.97}
 97%|█████████▋| 10113/10395 [28:54:37<38:32,  8.20s/it] 97%|█████████▋| 10114/10395 [28:54:44<37:02,  7.91s/it]                                                        {'loss': 0.8472, 'learning_rate': 3.830234983709935e-08, 'epoch': 0.97}
 97%|█████████▋| 10114/10395 [28:54:44<37:02,  7.91s/it] 97%|█████████▋| 10115/10395 [28:54:52<36:51,  7.90s/it]                                                        {'loss': 0.7476, 'learning_rate': 3.803039294519639e-08, 'epoch': 0.97}
 97%|█████████▋| 10115/10395 [28:54:52<36:51,  7.90s/it] 97%|█████████▋| 10116/10395 [28:54:59<35:56,  7.73s/it]                                                        {'loss': 0.8602, 'learning_rate': 3.7759403140014136e-08, 'epoch': 0.97}
 97%|█████████▋| 10116/10395 [28:54:59<35:56,  7.73s/it] 97%|█████████▋| 10117/10395 [28:55:09<38:30,  8.31s/it]                                                        {'loss': 0.8222, 'learning_rate': 3.748938044785933e-08, 'epoch': 0.97}
 97%|█████████▋| 10117/10395 [28:55:09<38:30,  8.31s/it] 97%|█████████▋| 10118/10395 [28:55:17<37:18,  8.08s/it]                                                        {'loss': 0.8683, 'learning_rate': 3.722032489494653e-08, 'epoch': 0.97}
 97%|█████████▋| 10118/10395 [28:55:17<37:18,  8.08s/it] 97%|█████████▋| 10119/10395 [28:55:25<37:41,  8.19s/it]                                                        {'loss': 0.8148, 'learning_rate': 3.6952236507392655e-08, 'epoch': 0.97}
 97%|█████████▋| 10119/10395 [28:55:25<37:41,  8.19s/it] 97%|█████████▋| 10120/10395 [28:55:33<37:08,  8.10s/it]                                                        {'loss': 0.7838, 'learning_rate': 3.668511531122576e-08, 'epoch': 0.97}
 97%|█████████▋| 10120/10395 [28:55:33<37:08,  8.10s/it] 97%|█████████▋| 10121/10395 [28:55:41<36:42,  8.04s/it]                                                        {'loss': 0.8009, 'learning_rate': 3.641896133237621e-08, 'epoch': 0.97}
 97%|█████████▋| 10121/10395 [28:55:41<36:42,  8.04s/it] 97%|█████████▋| 10122/10395 [28:55:48<35:40,  7.84s/it]                                                        {'loss': 0.8219, 'learning_rate': 3.6153774596681125e-08, 'epoch': 0.97}
 97%|█████████▋| 10122/10395 [28:55:48<35:40,  7.84s/it] 97%|█████████▋| 10123/10395 [28:55:56<36:04,  7.96s/it]                                                        {'loss': 0.8312, 'learning_rate': 3.588955512988434e-08, 'epoch': 0.97}
 97%|█████████▋| 10123/10395 [28:55:56<36:04,  7.96s/it] 97%|█████████▋| 10124/10395 [28:56:04<35:22,  7.83s/it]                                                        {'loss': 0.8397, 'learning_rate': 3.5626302957637584e-08, 'epoch': 0.97}
 97%|█████████▋| 10124/10395 [28:56:04<35:22,  7.83s/it] 97%|█████████▋| 10125/10395 [28:56:13<36:18,  8.07s/it]                                                        {'loss': 0.8274, 'learning_rate': 3.5364018105494834e-08, 'epoch': 0.97}
 97%|█████████▋| 10125/10395 [28:56:13<36:18,  8.07s/it] 97%|█████████▋| 10126/10395 [28:56:21<35:55,  8.01s/it]                                                        {'loss': 0.9124, 'learning_rate': 3.510270059891796e-08, 'epoch': 0.97}
 97%|█████████▋| 10126/10395 [28:56:21<35:55,  8.01s/it] 97%|█████████▋| 10127/10395 [28:56:29<36:35,  8.19s/it]                                                        {'loss': 0.7407, 'learning_rate': 3.4842350463276664e-08, 'epoch': 0.97}
 97%|█████████▋| 10127/10395 [28:56:29<36:35,  8.19s/it] 97%|█████████▋| 10128/10395 [28:56:37<35:39,  8.01s/it]                                                        {'loss': 0.9192, 'learning_rate': 3.458296772384406e-08, 'epoch': 0.97}
 97%|█████████▋| 10128/10395 [28:56:37<35:39,  8.01s/it] 97%|█████████▋| 10129/10395 [28:56:45<35:31,  8.01s/it]                                                        {'loss': 0.7315, 'learning_rate': 3.4324552405801124e-08, 'epoch': 0.97}
 97%|█████████▋| 10129/10395 [28:56:45<35:31,  8.01s/it] 97%|█████████▋| 10130/10395 [28:56:52<34:28,  7.80s/it]                                                        {'loss': 0.8813, 'learning_rate': 3.4067104534233345e-08, 'epoch': 0.97}
 97%|█████████▋| 10130/10395 [28:56:52<34:28,  7.80s/it] 97%|█████████▋| 10131/10395 [28:57:00<34:05,  7.75s/it]                                                        {'loss': 0.8002, 'learning_rate': 3.381062413413405e-08, 'epoch': 0.97}
 97%|█████████▋| 10131/10395 [28:57:00<34:05,  7.75s/it] 97%|█████████▋| 10132/10395 [28:57:07<33:38,  7.67s/it]                                                        {'loss': 0.8689, 'learning_rate': 3.355511123040112e-08, 'epoch': 0.97}
 97%|█████████▋| 10132/10395 [28:57:07<33:38,  7.67s/it] 97%|█████████▋| 10133/10395 [28:57:15<33:55,  7.77s/it]                                                        {'loss': 0.7998, 'learning_rate': 3.330056584784025e-08, 'epoch': 0.97}
 97%|█████████▋| 10133/10395 [28:57:15<33:55,  7.77s/it] 97%|█████████▋| 10134/10395 [28:57:23<33:37,  7.73s/it]                                                        {'loss': 0.8856, 'learning_rate': 3.3046988011161685e-08, 'epoch': 0.97}
 97%|█████████▋| 10134/10395 [28:57:23<33:37,  7.73s/it] 97%|█████████▋| 10135/10395 [28:57:31<34:05,  7.87s/it]                                                        {'loss': 0.8555, 'learning_rate': 3.2794377744981286e-08, 'epoch': 0.97}
 97%|█████████▋| 10135/10395 [28:57:31<34:05,  7.87s/it] 98%|█████████▊| 10136/10395 [28:57:39<33:37,  7.79s/it]                                                        {'loss': 0.8531, 'learning_rate': 3.254273507382277e-08, 'epoch': 0.98}
 98%|█████████▊| 10136/10395 [28:57:39<33:37,  7.79s/it] 98%|█████████▊| 10137/10395 [28:57:46<33:20,  7.75s/it]                                                        {'loss': 0.7697, 'learning_rate': 3.229206002211549e-08, 'epoch': 0.98}
 98%|█████████▊| 10137/10395 [28:57:46<33:20,  7.75s/it] 98%|█████████▊| 10138/10395 [28:57:54<33:01,  7.71s/it]                                                        {'loss': 0.9366, 'learning_rate': 3.204235261419442e-08, 'epoch': 0.98}
 98%|█████████▊| 10138/10395 [28:57:54<33:01,  7.71s/it] 98%|█████████▊| 10139/10395 [28:58:02<33:04,  7.75s/it]                                                        {'loss': 0.9185, 'learning_rate': 3.179361287429905e-08, 'epoch': 0.98}
 98%|█████████▊| 10139/10395 [28:58:02<33:04,  7.75s/it] 98%|█████████▊| 10140/10395 [28:58:09<32:54,  7.74s/it]                                                        {'loss': 0.8545, 'learning_rate': 3.1545840826577855e-08, 'epoch': 0.98}
 98%|█████████▊| 10140/10395 [28:58:09<32:54,  7.74s/it] 98%|█████████▊| 10141/10395 [28:58:17<32:49,  7.75s/it]                                                        {'loss': 0.9252, 'learning_rate': 3.129903649508492e-08, 'epoch': 0.98}
 98%|█████████▊| 10141/10395 [28:58:17<32:49,  7.75s/it] 98%|█████████▊| 10142/10395 [28:58:26<33:35,  7.97s/it]                                                        {'loss': 0.8615, 'learning_rate': 3.1053199903776645e-08, 'epoch': 0.98}
 98%|█████████▊| 10142/10395 [28:58:26<33:35,  7.97s/it] 98%|█████████▊| 10143/10395 [28:58:44<46:08, 10.99s/it]                                                        {'loss': 0.3603, 'learning_rate': 3.08083310765217e-08, 'epoch': 0.98}
 98%|█████████▊| 10143/10395 [28:58:44<46:08, 10.99s/it] 98%|█████████▊| 10144/10395 [28:58:52<41:57, 10.03s/it]                                                        {'loss': 0.8, 'learning_rate': 3.0564430037088866e-08, 'epoch': 0.98}
 98%|█████████▊| 10144/10395 [28:58:52<41:57, 10.03s/it] 98%|█████████▊| 10145/10395 [28:58:59<38:56,  9.35s/it]                                                        {'loss': 0.8288, 'learning_rate': 3.032149680915586e-08, 'epoch': 0.98}
 98%|█████████▊| 10145/10395 [28:58:59<38:56,  9.35s/it] 98%|█████████▊| 10146/10395 [28:59:08<37:33,  9.05s/it]                                                        {'loss': 0.8594, 'learning_rate': 3.007953141630715e-08, 'epoch': 0.98}
 98%|█████████▊| 10146/10395 [28:59:08<37:33,  9.05s/it] 98%|█████████▊| 10147/10395 [28:59:25<48:21, 11.70s/it]                                                        {'loss': 0.3488, 'learning_rate': 2.9838533882031727e-08, 'epoch': 0.98}
 98%|█████████▊| 10147/10395 [28:59:25<48:21, 11.70s/it] 98%|█████████▊| 10148/10395 [28:59:35<45:20, 11.01s/it]                                                        {'loss': 0.877, 'learning_rate': 2.959850422972532e-08, 'epoch': 0.98}
 98%|█████████▊| 10148/10395 [28:59:35<45:20, 11.01s/it] 98%|█████████▊| 10149/10395 [28:59:43<41:08, 10.04s/it]                                                        {'loss': 0.8751, 'learning_rate': 2.9359442482689292e-08, 'epoch': 0.98}
 98%|█████████▊| 10149/10395 [28:59:43<41:08, 10.04s/it] 98%|█████████▊| 10150/10395 [28:59:50<37:46,  9.25s/it]                                                        {'loss': 0.9141, 'learning_rate': 2.9121348664131745e-08, 'epoch': 0.98}
 98%|█████████▊| 10150/10395 [28:59:50<37:46,  9.25s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 98%|█████████▊| 10151/10395 [29:01:31<2:29:04, 36.66s/it]                                                          {'loss': 0.9773, 'learning_rate': 2.8884222797165296e-08, 'epoch': 0.98}
 98%|█████████▊| 10151/10395 [29:01:31<2:29:04, 36.66s/it] 98%|█████████▊| 10152/10395 [29:01:39<1:53:59, 28.15s/it]                                                          {'loss': 0.8815, 'learning_rate': 2.8648064904809313e-08, 'epoch': 0.98}
 98%|█████████▊| 10152/10395 [29:01:39<1:53:59, 28.15s/it] 98%|█████████▊| 10153/10395 [29:01:47<1:28:55, 22.05s/it]                                                          {'loss': 0.8113, 'learning_rate': 2.8412875009992124e-08, 'epoch': 0.98}
 98%|█████████▊| 10153/10395 [29:01:47<1:28:55, 22.05s/it] 98%|█████████▊| 10154/10395 [29:01:55<1:11:56, 17.91s/it]                                                          {'loss': 0.9069, 'learning_rate': 2.8178653135542132e-08, 'epoch': 0.98}
 98%|█████████▊| 10154/10395 [29:01:55<1:11:56, 17.91s/it] 98%|█████████▊| 10155/10395 [29:02:03<59:09, 14.79s/it]                                                          {'loss': 0.8274, 'learning_rate': 2.7945399304198927e-08, 'epoch': 0.98}
 98%|█████████▊| 10155/10395 [29:02:03<59:09, 14.79s/it] 98%|█████████▊| 10156/10395 [29:02:10<50:22, 12.65s/it]                                                        {'loss': 0.8508, 'learning_rate': 2.7713113538606616e-08, 'epoch': 0.98}
 98%|█████████▊| 10156/10395 [29:02:10<50:22, 12.65s/it] 98%|█████████▊| 10157/10395 [29:02:17<43:46, 11.03s/it]                                                        {'loss': 0.9403, 'learning_rate': 2.7481795861313832e-08, 'epoch': 0.98}
 98%|█████████▊| 10157/10395 [29:02:17<43:46, 11.03s/it] 98%|█████████▊| 10158/10395 [29:02:25<39:51, 10.09s/it]                                                        {'loss': 0.818, 'learning_rate': 2.725144629477705e-08, 'epoch': 0.98}
 98%|█████████▊| 10158/10395 [29:02:25<39:51, 10.09s/it] 98%|█████████▊| 10159/10395 [29:02:34<37:27,  9.52s/it]                                                        {'loss': 0.8829, 'learning_rate': 2.7022064861358388e-08, 'epoch': 0.98}
 98%|█████████▊| 10159/10395 [29:02:34<37:27,  9.52s/it] 98%|█████████▊| 10160/10395 [29:02:41<34:41,  8.86s/it]                                                        {'loss': 0.8204, 'learning_rate': 2.6793651583325587e-08, 'epoch': 0.98}
 98%|█████████▊| 10160/10395 [29:02:41<34:41,  8.86s/it] 98%|█████████▊| 10161/10395 [29:02:49<33:21,  8.55s/it]                                                        {'loss': 0.8235, 'learning_rate': 2.656620648285091e-08, 'epoch': 0.98}
 98%|█████████▊| 10161/10395 [29:02:49<33:21,  8.55s/it] 98%|█████████▊| 10162/10395 [29:02:56<31:50,  8.20s/it]                                                        {'loss': 0.8844, 'learning_rate': 2.6339729582016693e-08, 'epoch': 0.98}
 98%|█████████▊| 10162/10395 [29:02:56<31:50,  8.20s/it] 98%|█████████▊| 10163/10395 [29:03:04<31:11,  8.07s/it]                                                        {'loss': 0.7738, 'learning_rate': 2.6114220902807574e-08, 'epoch': 0.98}
 98%|█████████▊| 10163/10395 [29:03:04<31:11,  8.07s/it] 98%|█████████▊| 10164/10395 [29:03:14<33:43,  8.76s/it]                                                        {'loss': 0.7601, 'learning_rate': 2.588968046711604e-08, 'epoch': 0.98}
 98%|█████████▊| 10164/10395 [29:03:14<33:43,  8.76s/it] 98%|█████████▊| 10165/10395 [29:03:23<33:30,  8.74s/it]                                                        {'loss': 0.8075, 'learning_rate': 2.56661082967391e-08, 'epoch': 0.98}
 98%|█████████▊| 10165/10395 [29:03:23<33:30,  8.74s/it] 98%|█████████▊| 10166/10395 [29:03:31<32:04,  8.40s/it]                                                        {'loss': 0.877, 'learning_rate': 2.5443504413380504e-08, 'epoch': 0.98}
 98%|█████████▊| 10166/10395 [29:03:31<32:04,  8.40s/it] 98%|█████████▊| 10167/10395 [29:03:38<30:55,  8.14s/it]                                                        {'loss': 0.8036, 'learning_rate': 2.5221868838651854e-08, 'epoch': 0.98}
 98%|█████████▊| 10167/10395 [29:03:38<30:55,  8.14s/it] 98%|█████████▊| 10168/10395 [29:03:45<29:34,  7.82s/it]                                                        {'loss': 0.8927, 'learning_rate': 2.5001201594068157e-08, 'epoch': 0.98}
 98%|█████████▊| 10168/10395 [29:03:45<29:34,  7.82s/it] 98%|█████████▊| 10169/10395 [29:03:53<29:21,  7.80s/it]                                                        {'loss': 0.8221, 'learning_rate': 2.4781502701050065e-08, 'epoch': 0.98}
 98%|█████████▊| 10169/10395 [29:03:53<29:21,  7.80s/it] 98%|█████████▊| 10170/10395 [29:04:02<30:52,  8.23s/it]                                                        {'loss': 0.8528, 'learning_rate': 2.4562772180927174e-08, 'epoch': 0.98}
 98%|█████████▊| 10170/10395 [29:04:02<30:52,  8.23s/it] 98%|█████████▊| 10171/10395 [29:04:10<29:58,  8.03s/it]                                                        {'loss': 0.9024, 'learning_rate': 2.4345010054933614e-08, 'epoch': 0.98}
 98%|█████████▊| 10171/10395 [29:04:10<29:58,  8.03s/it] 98%|█████████▊| 10172/10395 [29:04:18<30:21,  8.17s/it]                                                        {'loss': 0.861, 'learning_rate': 2.412821634420692e-08, 'epoch': 0.98}
 98%|█████████▊| 10172/10395 [29:04:18<30:21,  8.17s/it] 98%|█████████▊| 10173/10395 [29:04:27<30:36,  8.27s/it]                                                        {'loss': 0.8406, 'learning_rate': 2.3912391069794706e-08, 'epoch': 0.98}
 98%|█████████▊| 10173/10395 [29:04:27<30:36,  8.27s/it] 98%|█████████▊| 10174/10395 [29:04:34<29:44,  8.07s/it]                                                        {'loss': 0.9368, 'learning_rate': 2.3697534252649092e-08, 'epoch': 0.98}
 98%|█████████▊| 10174/10395 [29:04:34<29:44,  8.07s/it] 98%|█████████▊| 10175/10395 [29:04:43<29:52,  8.15s/it]                                                        {'loss': 0.8644, 'learning_rate': 2.348364591362784e-08, 'epoch': 0.98}
 98%|█████████▊| 10175/10395 [29:04:43<29:52,  8.15s/it] 98%|█████████▊| 10176/10395 [29:04:52<31:21,  8.59s/it]                                                        {'loss': 0.8561, 'learning_rate': 2.3270726073493233e-08, 'epoch': 0.98}
 98%|█████████▊| 10176/10395 [29:04:52<31:21,  8.59s/it] 98%|█████████▊| 10177/10395 [29:05:00<30:31,  8.40s/it]                                                        {'loss': 0.8205, 'learning_rate': 2.3058774752917623e-08, 'epoch': 0.98}
 98%|█████████▊| 10177/10395 [29:05:00<30:31,  8.40s/it] 98%|█████████▊| 10178/10395 [29:05:08<29:19,  8.11s/it]                                                        {'loss': 0.9157, 'learning_rate': 2.2847791972474553e-08, 'epoch': 0.98}
 98%|█████████▊| 10178/10395 [29:05:08<29:19,  8.11s/it] 98%|█████████▊| 10179/10395 [29:05:16<28:57,  8.04s/it]                                                        {'loss': 0.8685, 'learning_rate': 2.263777775264653e-08, 'epoch': 0.98}
 98%|█████████▊| 10179/10395 [29:05:16<28:57,  8.04s/it] 98%|█████████▊| 10180/10395 [29:05:23<28:39,  8.00s/it]                                                        {'loss': 0.8724, 'learning_rate': 2.2428732113821683e-08, 'epoch': 0.98}
 98%|█████████▊| 10180/10395 [29:05:23<28:39,  8.00s/it] 98%|█████████▊| 10181/10395 [29:05:41<39:02, 10.95s/it]                                                        {'loss': 0.3381, 'learning_rate': 2.2220655076292675e-08, 'epoch': 0.98}
 98%|█████████▊| 10181/10395 [29:05:41<39:02, 10.95s/it] 98%|█████████▊| 10182/10395 [29:05:49<35:10,  9.91s/it]                                                        {'loss': 0.8464, 'learning_rate': 2.201354666026001e-08, 'epoch': 0.98}
 98%|█████████▊| 10182/10395 [29:05:49<35:10,  9.91s/it] 98%|█████████▊| 10183/10395 [29:05:56<32:26,  9.18s/it]                                                        {'loss': 0.8054, 'learning_rate': 2.180740688582983e-08, 'epoch': 0.98}
 98%|█████████▊| 10183/10395 [29:05:56<32:26,  9.18s/it] 98%|█████████▊| 10184/10395 [29:06:05<31:45,  9.03s/it]                                                        {'loss': 0.8652, 'learning_rate': 2.1602235773012792e-08, 'epoch': 0.98}
 98%|█████████▊| 10184/10395 [29:06:05<31:45,  9.03s/it] 98%|█████████▊| 10185/10395 [29:06:13<30:31,  8.72s/it]                                                        {'loss': 0.8441, 'learning_rate': 2.13980333417263e-08, 'epoch': 0.98}
 98%|█████████▊| 10185/10395 [29:06:13<30:31,  8.72s/it] 98%|█████████▊| 10186/10395 [29:06:21<29:34,  8.49s/it]                                                        {'loss': 0.9197, 'learning_rate': 2.1194799611795603e-08, 'epoch': 0.98}
 98%|█████████▊| 10186/10395 [29:06:21<29:34,  8.49s/it] 98%|█████████▊| 10187/10395 [29:06:29<28:40,  8.27s/it]                                                        {'loss': 0.8734, 'learning_rate': 2.0992534602948256e-08, 'epoch': 0.98}
 98%|█████████▊| 10187/10395 [29:06:29<28:40,  8.27s/it] 98%|█████████▊| 10188/10395 [29:06:36<27:33,  7.99s/it]                                                        {'loss': 0.7719, 'learning_rate': 2.0791238334820772e-08, 'epoch': 0.98}
 98%|█████████▊| 10188/10395 [29:06:36<27:33,  7.99s/it] 98%|█████████▊| 10189/10395 [29:06:44<27:31,  8.02s/it]                                                        {'loss': 0.7523, 'learning_rate': 2.059091082695419e-08, 'epoch': 0.98}
 98%|█████████▊| 10189/10395 [29:06:44<27:31,  8.02s/it] 98%|█████████▊| 10190/10395 [29:06:52<27:17,  7.99s/it]                                                        {'loss': 0.8792, 'learning_rate': 2.0391552098795174e-08, 'epoch': 0.98}
 98%|█████████▊| 10190/10395 [29:06:52<27:17,  7.99s/it] 98%|█████████▊| 10191/10395 [29:06:59<26:33,  7.81s/it]                                                        {'loss': 0.8731, 'learning_rate': 2.0193162169698243e-08, 'epoch': 0.98}
 98%|█████████▊| 10191/10395 [29:06:59<26:33,  7.81s/it] 98%|█████████▊| 10192/10395 [29:07:07<26:16,  7.76s/it]                                                        {'loss': 0.8579, 'learning_rate': 1.9995741058922437e-08, 'epoch': 0.98}
 98%|█████████▊| 10192/10395 [29:07:07<26:16,  7.76s/it] 98%|█████████▊| 10193/10395 [29:07:15<26:06,  7.76s/it]                                                        {'loss': 0.8528, 'learning_rate': 1.979928878563242e-08, 'epoch': 0.98}
 98%|█████████▊| 10193/10395 [29:07:15<26:06,  7.76s/it] 98%|█████████▊| 10194/10395 [29:07:22<25:44,  7.68s/it]                                                        {'loss': 0.8884, 'learning_rate': 1.960380536889961e-08, 'epoch': 0.98}
 98%|█████████▊| 10194/10395 [29:07:22<25:44,  7.68s/it] 98%|█████████▊| 10195/10395 [29:07:29<25:11,  7.56s/it]                                                        {'loss': 0.8528, 'learning_rate': 1.9409290827701043e-08, 'epoch': 0.98}
 98%|█████████▊| 10195/10395 [29:07:29<25:11,  7.56s/it] 98%|█████████▊| 10196/10395 [29:07:38<25:44,  7.76s/it]                                                        {'loss': 0.8102, 'learning_rate': 1.921574518092051e-08, 'epoch': 0.98}
 98%|█████████▊| 10196/10395 [29:07:38<25:44,  7.76s/it] 98%|█████████▊| 10197/10395 [29:07:45<25:31,  7.74s/it]                                                        {'loss': 0.8283, 'learning_rate': 1.9023168447346308e-08, 'epoch': 0.98}
 98%|█████████▊| 10197/10395 [29:07:45<25:31,  7.74s/it] 98%|█████████▊| 10198/10395 [29:07:54<26:14,  7.99s/it]                                                        {'loss': 0.8478, 'learning_rate': 1.8831560645673484e-08, 'epoch': 0.98}
 98%|█████████▊| 10198/10395 [29:07:54<26:14,  7.99s/it] 98%|█████████▊| 10199/10395 [29:08:02<25:53,  7.93s/it]                                                        {'loss': 0.7662, 'learning_rate': 1.864092179450272e-08, 'epoch': 0.98}
 98%|█████████▊| 10199/10395 [29:08:02<25:53,  7.93s/it] 98%|█████████▊| 10200/10395 [29:08:10<25:54,  7.97s/it]                                                        {'loss': 0.9182, 'learning_rate': 1.845125191234143e-08, 'epoch': 0.98}
 98%|█████████▊| 10200/10395 [29:08:10<25:54,  7.97s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 98%|█████████▊| 10201/10395 [29:09:53<1:58:17, 36.59s/it]                                                          {'loss': 0.8205, 'learning_rate': 1.826255101760155e-08, 'epoch': 0.98}
 98%|█████████▊| 10201/10395 [29:09:53<1:58:17, 36.59s/it] 98%|█████████▊| 10202/10395 [29:10:01<1:29:29, 27.82s/it]                                                          {'loss': 0.8987, 'learning_rate': 1.807481912860287e-08, 'epoch': 0.98}
 98%|█████████▊| 10202/10395 [29:10:01<1:29:29, 27.82s/it] 98%|█████████▊| 10203/10395 [29:10:08<1:09:26, 21.70s/it]                                                          {'loss': 0.7762, 'learning_rate': 1.7888056263568598e-08, 'epoch': 0.98}
 98%|█████████▊| 10203/10395 [29:10:08<1:09:26, 21.70s/it] 98%|█████████▊| 10204/10395 [29:10:16<55:51, 17.55s/it]                                                          {'loss': 0.8003, 'learning_rate': 1.770226244062978e-08, 'epoch': 0.98}
 98%|█████████▊| 10204/10395 [29:10:16<55:51, 17.55s/it] 98%|█████████▊| 10205/10395 [29:10:23<46:09, 14.57s/it]                                                        {'loss': 0.8166, 'learning_rate': 1.7517437677823102e-08, 'epoch': 0.98}
 98%|█████████▊| 10205/10395 [29:10:23<46:09, 14.57s/it] 98%|█████████▊| 10206/10395 [29:10:31<39:13, 12.45s/it]                                                        {'loss': 0.8365, 'learning_rate': 1.7333581993090875e-08, 'epoch': 0.98}
 98%|█████████▊| 10206/10395 [29:10:31<39:13, 12.45s/it] 98%|█████████▊| 10207/10395 [29:10:39<34:30, 11.01s/it]                                                        {'loss': 0.8616, 'learning_rate': 1.715069540428216e-08, 'epoch': 0.98}
 98%|█████████▊| 10207/10395 [29:10:39<34:30, 11.01s/it] 98%|█████████▊| 10208/10395 [29:10:47<31:35, 10.13s/it]                                                        {'loss': 0.8282, 'learning_rate': 1.6968777929150525e-08, 'epoch': 0.98}
 98%|█████████▊| 10208/10395 [29:10:47<31:35, 10.13s/it] 98%|█████████▊| 10209/10395 [29:10:55<29:52,  9.64s/it]                                                        {'loss': 0.787, 'learning_rate': 1.6787829585355187e-08, 'epoch': 0.98}
 98%|█████████▊| 10209/10395 [29:10:55<29:52,  9.64s/it] 98%|█████████▊| 10210/10395 [29:11:03<28:27,  9.23s/it]                                                        {'loss': 0.844, 'learning_rate': 1.660785039046431e-08, 'epoch': 0.98}
 98%|█████████▊| 10210/10395 [29:11:03<28:27,  9.23s/it] 98%|█████████▊| 10211/10395 [29:11:11<26:52,  8.76s/it]                                                        {'loss': 0.8297, 'learning_rate': 1.642884036194836e-08, 'epoch': 0.98}
 98%|█████████▊| 10211/10395 [29:11:11<26:52,  8.76s/it] 98%|█████████▊| 10212/10395 [29:11:19<26:01,  8.53s/it]                                                        {'loss': 0.8549, 'learning_rate': 1.6250799517185668e-08, 'epoch': 0.98}
 98%|█████████▊| 10212/10395 [29:11:19<26:01,  8.53s/it] 98%|█████████▊| 10213/10395 [29:11:28<25:51,  8.52s/it]                                                        {'loss': 0.8472, 'learning_rate': 1.6073727873459066e-08, 'epoch': 0.98}
 98%|█████████▊| 10213/10395 [29:11:28<25:51,  8.52s/it] 98%|█████████▊| 10214/10395 [29:11:35<24:32,  8.14s/it]                                                        {'loss': 0.8189, 'learning_rate': 1.5897625447960363e-08, 'epoch': 0.98}
 98%|█████████▊| 10214/10395 [29:11:35<24:32,  8.14s/it] 98%|█████████▊| 10215/10395 [29:11:43<24:08,  8.05s/it]                                                        {'loss': 0.7784, 'learning_rate': 1.5722492257783663e-08, 'epoch': 0.98}
 98%|█████████▊| 10215/10395 [29:11:43<24:08,  8.05s/it] 98%|█████████▊| 10216/10395 [29:11:51<24:06,  8.08s/it]                                                        {'loss': 0.895, 'learning_rate': 1.5548328319930915e-08, 'epoch': 0.98}
 98%|█████████▊| 10216/10395 [29:11:51<24:06,  8.08s/it] 98%|█████████▊| 10217/10395 [29:11:58<23:13,  7.83s/it]                                                        {'loss': 0.9353, 'learning_rate': 1.5375133651309716e-08, 'epoch': 0.98}
 98%|█████████▊| 10217/10395 [29:11:58<23:13,  7.83s/it] 98%|█████████▊| 10218/10395 [29:12:07<23:54,  8.11s/it]                                                        {'loss': 0.8477, 'learning_rate': 1.5202908268733274e-08, 'epoch': 0.98}
 98%|█████████▊| 10218/10395 [29:12:07<23:54,  8.11s/it] 98%|█████████▊| 10219/10395 [29:12:15<23:33,  8.03s/it]                                                        {'loss': 0.885, 'learning_rate': 1.5031652188920442e-08, 'epoch': 0.98}
 98%|█████████▊| 10219/10395 [29:12:15<23:33,  8.03s/it] 98%|█████████▊| 10220/10395 [29:12:22<23:07,  7.93s/it]                                                        {'loss': 0.8806, 'learning_rate': 1.4861365428497921e-08, 'epoch': 0.98}
 98%|█████████▊| 10220/10395 [29:12:22<23:07,  7.93s/it] 98%|█████████▊| 10221/10395 [29:12:40<31:21, 10.81s/it]                                                        {'loss': 0.3476, 'learning_rate': 1.4692048003994707e-08, 'epoch': 0.98}
 98%|█████████▊| 10221/10395 [29:12:40<31:21, 10.81s/it] 98%|█████████▊| 10222/10395 [29:12:48<28:30,  9.88s/it]                                                        {'loss': 0.8439, 'learning_rate': 1.4523699931849877e-08, 'epoch': 0.98}
 98%|█████████▊| 10222/10395 [29:12:48<28:30,  9.88s/it] 98%|█████████▊| 10223/10395 [29:12:55<26:27,  9.23s/it]                                                        {'loss': 0.8119, 'learning_rate': 1.4356321228404801e-08, 'epoch': 0.98}
 98%|█████████▊| 10223/10395 [29:12:55<26:27,  9.23s/it] 98%|█████████▊| 10224/10395 [29:13:04<26:04,  9.15s/it]                                                        {'loss': 0.8047, 'learning_rate': 1.4189911909907594e-08, 'epoch': 0.98}
 98%|█████████▊| 10224/10395 [29:13:04<26:04,  9.15s/it] 98%|█████████▊| 10225/10395 [29:13:12<24:35,  8.68s/it]                                                        {'loss': 0.8101, 'learning_rate': 1.4024471992515331e-08, 'epoch': 0.98}
 98%|█████████▊| 10225/10395 [29:13:12<24:35,  8.68s/it] 98%|█████████▊| 10226/10395 [29:13:19<23:28,  8.33s/it]                                                        {'loss': 0.8154, 'learning_rate': 1.386000149228628e-08, 'epoch': 0.98}
 98%|█████████▊| 10226/10395 [29:13:19<23:28,  8.33s/it] 98%|█████████▊| 10227/10395 [29:13:27<23:02,  8.23s/it]                                                        {'loss': 0.8619, 'learning_rate': 1.3696500425188774e-08, 'epoch': 0.98}
 98%|█████████▊| 10227/10395 [29:13:27<23:02,  8.23s/it] 98%|█████████▊| 10228/10395 [29:13:35<22:30,  8.09s/it]                                                        {'loss': 0.9137, 'learning_rate': 1.3533968807093457e-08, 'epoch': 0.98}
 98%|█████████▊| 10228/10395 [29:13:35<22:30,  8.09s/it] 98%|█████████▊| 10229/10395 [29:13:43<21:49,  7.89s/it]                                                        {'loss': 0.8199, 'learning_rate': 1.3372406653779923e-08, 'epoch': 0.98}
 98%|█████████▊| 10229/10395 [29:13:43<21:49,  7.89s/it] 98%|█████████▊| 10230/10395 [29:13:51<21:41,  7.89s/it]                                                        {'loss': 0.8108, 'learning_rate': 1.3211813980931187e-08, 'epoch': 0.98}
 98%|█████████▊| 10230/10395 [29:13:51<21:41,  7.89s/it] 98%|█████████▊| 10231/10395 [29:13:59<22:05,  8.08s/it]                                                        {'loss': 0.8324, 'learning_rate': 1.305219080413811e-08, 'epoch': 0.98}
 98%|█████████▊| 10231/10395 [29:13:59<22:05,  8.08s/it] 98%|█████████▊| 10232/10395 [29:14:07<21:41,  7.99s/it]                                                        {'loss': 0.8436, 'learning_rate': 1.2893537138896073e-08, 'epoch': 0.98}
 98%|█████████▊| 10232/10395 [29:14:07<21:41,  7.99s/it] 98%|█████████▊| 10233/10395 [29:14:14<21:16,  7.88s/it]                                                        {'loss': 0.8733, 'learning_rate': 1.273585300060609e-08, 'epoch': 0.98}
 98%|█████████▊| 10233/10395 [29:14:14<21:16,  7.88s/it] 98%|█████████▊| 10234/10395 [29:14:22<20:40,  7.71s/it]                                                        {'loss': 0.8389, 'learning_rate': 1.257913840457703e-08, 'epoch': 0.98}
 98%|█████████▊| 10234/10395 [29:14:22<20:40,  7.71s/it] 98%|█████████▊| 10235/10395 [29:14:29<20:28,  7.68s/it]                                                        {'loss': 0.9007, 'learning_rate': 1.2423393366022274e-08, 'epoch': 0.98}
 98%|█████████▊| 10235/10395 [29:14:29<20:28,  7.68s/it] 98%|█████████▊| 10236/10395 [29:14:37<20:29,  7.73s/it]                                                        {'loss': 0.8566, 'learning_rate': 1.2268617900060842e-08, 'epoch': 0.98}
 98%|█████████▊| 10236/10395 [29:14:37<20:29,  7.73s/it] 98%|█████████▊| 10237/10395 [29:14:45<20:00,  7.60s/it]                                                        {'loss': 0.8709, 'learning_rate': 1.2114812021718491e-08, 'epoch': 0.98}
 98%|█████████▊| 10237/10395 [29:14:45<20:00,  7.60s/it] 98%|█████████▊| 10238/10395 [29:14:52<19:52,  7.60s/it]                                                        {'loss': 0.8251, 'learning_rate': 1.1961975745926613e-08, 'epoch': 0.98}
 98%|█████████▊| 10238/10395 [29:14:52<19:52,  7.60s/it] 98%|█████████▊| 10239/10395 [29:15:00<19:37,  7.55s/it]                                                        {'loss': 0.8832, 'learning_rate': 1.1810109087520005e-08, 'epoch': 0.98}
 98%|█████████▊| 10239/10395 [29:15:00<19:37,  7.55s/it] 99%|█████████▊| 10240/10395 [29:15:08<20:33,  7.96s/it]                                                        {'loss': 0.7698, 'learning_rate': 1.1659212061244651e-08, 'epoch': 0.99}
 99%|█████████▊| 10240/10395 [29:15:08<20:33,  7.96s/it] 99%|█████████▊| 10241/10395 [29:15:15<19:39,  7.66s/it]                                                        {'loss': 0.9419, 'learning_rate': 1.1509284681746612e-08, 'epoch': 0.99}
 99%|█████████▊| 10241/10395 [29:15:15<19:39,  7.66s/it] 99%|█████████▊| 10242/10395 [29:15:23<19:29,  7.64s/it]                                                        {'loss': 0.9182, 'learning_rate': 1.1360326963582024e-08, 'epoch': 0.99}
 99%|█████████▊| 10242/10395 [29:15:23<19:29,  7.64s/it] 99%|█████████▊| 10243/10395 [29:15:31<19:33,  7.72s/it]                                                        {'loss': 0.8182, 'learning_rate': 1.1212338921211542e-08, 'epoch': 0.99}
 99%|█████████▊| 10243/10395 [29:15:31<19:33,  7.72s/it] 99%|█████████▊| 10244/10395 [29:15:48<26:47, 10.65s/it]                                                        {'loss': 0.3927, 'learning_rate': 1.1065320569001448e-08, 'epoch': 0.99}
 99%|█████████▊| 10244/10395 [29:15:48<26:47, 10.65s/it] 99%|█████████▊| 10245/10395 [29:15:56<24:23,  9.76s/it]                                                        {'loss': 0.9654, 'learning_rate': 1.0919271921222552e-08, 'epoch': 0.99}
 99%|█████████▊| 10245/10395 [29:15:56<24:23,  9.76s/it] 99%|█████████▊| 10246/10395 [29:16:13<29:14, 11.78s/it]                                                        {'loss': 0.3654, 'learning_rate': 1.0774192992054622e-08, 'epoch': 0.99}
 99%|█████████▊| 10246/10395 [29:16:13<29:14, 11.78s/it] 99%|█████████▊| 10247/10395 [29:16:21<26:26, 10.72s/it]                                                        {'loss': 0.8605, 'learning_rate': 1.0630083795580837e-08, 'epoch': 0.99}
 99%|█████████▊| 10247/10395 [29:16:21<26:26, 10.72s/it] 99%|█████████▊| 10248/10395 [29:16:28<23:47,  9.71s/it]                                                        {'loss': 0.8249, 'learning_rate': 1.0486944345791118e-08, 'epoch': 0.99}
 99%|█████████▊| 10248/10395 [29:16:28<23:47,  9.71s/it] 99%|█████████▊| 10249/10395 [29:16:36<22:04,  9.07s/it]                                                        {'loss': 0.8821, 'learning_rate': 1.0344774656581014e-08, 'epoch': 0.99}
 99%|█████████▊| 10249/10395 [29:16:36<22:04,  9.07s/it] 99%|█████████▊| 10250/10395 [29:16:43<20:29,  8.48s/it]                                                        {'loss': 0.9298, 'learning_rate': 1.020357474175282e-08, 'epoch': 0.99}
 99%|█████████▊| 10250/10395 [29:16:43<20:29,  8.48s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 99%|█████████▊| 10251/10395 [29:18:25<1:27:39, 36.53s/it]                                                          {'loss': 0.858, 'learning_rate': 1.0063344615013349e-08, 'epoch': 0.99}
 99%|█████████▊| 10251/10395 [29:18:25<1:27:39, 36.53s/it] 99%|█████████▊| 10252/10395 [29:18:33<1:06:26, 27.88s/it]                                                          {'loss': 0.8085, 'learning_rate': 9.924084289975045e-09, 'epoch': 0.99}
 99%|█████████▊| 10252/10395 [29:18:33<1:06:26, 27.88s/it] 99%|█████████▊| 10253/10395 [29:18:40<51:42, 21.85s/it]                                                          {'loss': 0.8171, 'learning_rate': 9.785793780158203e-09, 'epoch': 0.99}
 99%|█████████▊| 10253/10395 [29:18:40<51:42, 21.85s/it] 99%|█████████▊| 10254/10395 [29:18:49<42:17, 18.00s/it]                                                        {'loss': 0.7814, 'learning_rate': 9.648473098987643e-09, 'epoch': 0.99}
 99%|█████████▊| 10254/10395 [29:18:49<42:17, 18.00s/it] 99%|█████████▊| 10255/10395 [29:19:06<41:19, 17.71s/it]                                                        {'loss': 0.3567, 'learning_rate': 9.51212225979381e-09, 'epoch': 0.99}
 99%|█████████▊| 10255/10395 [29:19:06<41:19, 17.71s/it] 99%|█████████▊| 10256/10395 [29:19:14<34:13, 14.78s/it]                                                        {'loss': 0.8334, 'learning_rate': 9.376741275812784e-09, 'epoch': 0.99}
 99%|█████████▊| 10256/10395 [29:19:14<34:13, 14.78s/it] 99%|█████████▊| 10257/10395 [29:19:31<35:19, 15.36s/it]                                                        {'loss': 0.384, 'learning_rate': 9.242330160187386e-09, 'epoch': 0.99}
 99%|█████████▊| 10257/10395 [29:19:31<35:19, 15.36s/it] 99%|█████████▊| 10258/10395 [29:19:39<29:45, 13.04s/it]                                                        {'loss': 0.7818, 'learning_rate': 9.108888925967175e-09, 'epoch': 0.99}
 99%|█████████▊| 10258/10395 [29:19:39<29:45, 13.04s/it] 99%|█████████▊| 10259/10395 [29:19:46<25:33, 11.28s/it]                                                        {'loss': 0.8189, 'learning_rate': 8.976417586105124e-09, 'epoch': 0.99}
 99%|█████████▊| 10259/10395 [29:19:46<25:33, 11.28s/it] 99%|█████████▊| 10260/10395 [29:19:56<24:21, 10.83s/it]                                                        {'loss': 0.8026, 'learning_rate': 8.844916153462058e-09, 'epoch': 0.99}
 99%|█████████▊| 10260/10395 [29:19:56<24:21, 10.83s/it] 99%|█████████▊| 10261/10395 [29:20:05<23:05, 10.34s/it]                                                        {'loss': 0.8937, 'learning_rate': 8.714384640802209e-09, 'epoch': 0.99}
 99%|█████████▊| 10261/10395 [29:20:05<23:05, 10.34s/it] 99%|█████████▊| 10262/10395 [29:20:13<21:16,  9.60s/it]                                                        {'loss': 0.8385, 'learning_rate': 8.584823060799885e-09, 'epoch': 0.99}
 99%|█████████▊| 10262/10395 [29:20:13<21:16,  9.60s/it] 99%|█████████▊| 10263/10395 [29:20:20<19:49,  9.01s/it]                                                        {'loss': 0.8195, 'learning_rate': 8.45623142602947e-09, 'epoch': 0.99}
 99%|█████████▊| 10263/10395 [29:20:20<19:49,  9.01s/it] 99%|█████████▊| 10264/10395 [29:20:28<18:49,  8.62s/it]                                                        {'loss': 0.8827, 'learning_rate': 8.328609748977645e-09, 'epoch': 0.99}
 99%|█████████▊| 10264/10395 [29:20:28<18:49,  8.62s/it] 99%|█████████▊| 10265/10395 [29:20:35<17:53,  8.26s/it]                                                        {'loss': 0.7987, 'learning_rate': 8.201958042031166e-09, 'epoch': 0.99}
 99%|█████████▊| 10265/10395 [29:20:35<17:53,  8.26s/it] 99%|█████████▉| 10266/10395 [29:20:43<17:28,  8.13s/it]                                                        {'loss': 0.7963, 'learning_rate': 8.076276317486864e-09, 'epoch': 0.99}
 99%|█████████▉| 10266/10395 [29:20:43<17:28,  8.13s/it] 99%|█████████▉| 10267/10395 [29:20:52<17:53,  8.39s/it]                                                        {'loss': 0.8841, 'learning_rate': 7.95156458754498e-09, 'epoch': 0.99}
 99%|█████████▉| 10267/10395 [29:20:52<17:53,  8.39s/it] 99%|█████████▉| 10268/10395 [29:21:00<17:07,  8.09s/it]                                                        {'loss': 0.947, 'learning_rate': 7.827822864311386e-09, 'epoch': 0.99}
 99%|█████████▉| 10268/10395 [29:21:00<17:07,  8.09s/it] 99%|█████████▉| 10269/10395 [29:21:07<16:49,  8.01s/it]                                                        {'loss': 0.8964, 'learning_rate': 7.705051159798693e-09, 'epoch': 0.99}
 99%|█████████▉| 10269/10395 [29:21:07<16:49,  8.01s/it] 99%|█████████▉| 10270/10395 [29:21:15<16:26,  7.89s/it]                                                        {'loss': 0.8842, 'learning_rate': 7.583249485927369e-09, 'epoch': 0.99}
 99%|█████████▉| 10270/10395 [29:21:15<16:26,  7.89s/it] 99%|█████████▉| 10271/10395 [29:21:23<16:03,  7.77s/it]                                                        {'loss': 0.7848, 'learning_rate': 7.462417854520176e-09, 'epoch': 0.99}
 99%|█████████▉| 10271/10395 [29:21:23<16:03,  7.77s/it] 99%|█████████▉| 10272/10395 [29:21:30<15:38,  7.63s/it]                                                        {'loss': 0.8792, 'learning_rate': 7.3425562773066225e-09, 'epoch': 0.99}
 99%|█████████▉| 10272/10395 [29:21:30<15:38,  7.63s/it] 99%|█████████▉| 10273/10395 [29:21:38<15:34,  7.66s/it]                                                        {'loss': 0.8948, 'learning_rate': 7.223664765924065e-09, 'epoch': 0.99}
 99%|█████████▉| 10273/10395 [29:21:38<15:34,  7.66s/it] 99%|█████████▉| 10274/10395 [29:21:56<21:52, 10.85s/it]                                                        {'loss': 0.3631, 'learning_rate': 7.1057433319132725e-09, 'epoch': 0.99}
 99%|█████████▉| 10274/10395 [29:21:56<21:52, 10.85s/it] 99%|█████████▉| 10275/10395 [29:22:04<20:04, 10.04s/it]                                                        {'loss': 0.8128, 'learning_rate': 6.988791986721755e-09, 'epoch': 0.99}
 99%|█████████▉| 10275/10395 [29:22:04<20:04, 10.04s/it] 99%|█████████▉| 10276/10395 [29:22:11<18:15,  9.20s/it]                                                        {'loss': 0.8963, 'learning_rate': 6.872810741702651e-09, 'epoch': 0.99}
 99%|█████████▉| 10276/10395 [29:22:11<18:15,  9.20s/it] 99%|█████████▉| 10277/10395 [29:22:19<17:04,  8.68s/it]                                                        {'loss': 0.8776, 'learning_rate': 6.757799608116955e-09, 'epoch': 0.99}
 99%|█████████▉| 10277/10395 [29:22:19<17:04,  8.68s/it] 99%|█████████▉| 10278/10395 [29:22:26<16:11,  8.31s/it]                                                        {'loss': 0.8358, 'learning_rate': 6.643758597127958e-09, 'epoch': 0.99}
 99%|█████████▉| 10278/10395 [29:22:26<16:11,  8.31s/it] 99%|█████████▉| 10279/10395 [29:22:34<15:47,  8.17s/it]                                                        {'loss': 0.9096, 'learning_rate': 6.5306877198068054e-09, 'epoch': 0.99}
 99%|█████████▉| 10279/10395 [29:22:34<15:47,  8.17s/it] 99%|█████████▉| 10280/10395 [29:22:42<15:41,  8.19s/it]                                                        {'loss': 0.8498, 'learning_rate': 6.418586987130271e-09, 'epoch': 0.99}
 99%|█████████▉| 10280/10395 [29:22:42<15:41,  8.19s/it] 99%|█████████▉| 10281/10395 [29:22:49<14:57,  7.88s/it]                                                        {'loss': 0.8821, 'learning_rate': 6.307456409980761e-09, 'epoch': 0.99}
 99%|█████████▉| 10281/10395 [29:22:49<14:57,  7.88s/it] 99%|█████████▉| 10282/10395 [29:22:58<15:19,  8.14s/it]                                                        {'loss': 0.729, 'learning_rate': 6.197295999147423e-09, 'epoch': 0.99}
 99%|█████████▉| 10282/10395 [29:22:58<15:19,  8.14s/it] 99%|█████████▉| 10283/10395 [29:23:05<14:45,  7.90s/it]                                                        {'loss': 0.8603, 'learning_rate': 6.0881057653239264e-09, 'epoch': 0.99}
 99%|█████████▉| 10283/10395 [29:23:05<14:45,  7.90s/it] 99%|█████████▉| 10284/10395 [29:23:13<14:26,  7.80s/it]                                                        {'loss': 0.838, 'learning_rate': 5.979885719109568e-09, 'epoch': 0.99}
 99%|█████████▉| 10284/10395 [29:23:13<14:26,  7.80s/it] 99%|█████████▉| 10285/10395 [29:23:20<14:02,  7.66s/it]                                                        {'loss': 0.8587, 'learning_rate': 5.8726358710103905e-09, 'epoch': 0.99}
 99%|█████████▉| 10285/10395 [29:23:20<14:02,  7.66s/it] 99%|█████████▉| 10286/10395 [29:23:28<13:44,  7.56s/it]                                                        {'loss': 0.9049, 'learning_rate': 5.766356231439174e-09, 'epoch': 0.99}
 99%|█████████▉| 10286/10395 [29:23:28<13:44,  7.56s/it] 99%|█████████▉| 10287/10395 [29:23:36<14:09,  7.87s/it]                                                        {'loss': 0.7688, 'learning_rate': 5.6610468107110015e-09, 'epoch': 0.99}
 99%|█████████▉| 10287/10395 [29:23:36<14:09,  7.87s/it] 99%|█████████▉| 10288/10395 [29:23:44<13:53,  7.79s/it]                                                        {'loss': 0.8248, 'learning_rate': 5.5567076190510275e-09, 'epoch': 0.99}
 99%|█████████▉| 10288/10395 [29:23:44<13:53,  7.79s/it] 99%|█████████▉| 10289/10395 [29:23:53<14:16,  8.08s/it]                                                        {'loss': 0.8172, 'learning_rate': 5.453338666587815e-09, 'epoch': 0.99}
 99%|█████████▉| 10289/10395 [29:23:53<14:16,  8.08s/it] 99%|█████████▉| 10290/10395 [29:24:00<13:59,  8.00s/it]                                                        {'loss': 0.8837, 'learning_rate': 5.3509399633566716e-09, 'epoch': 0.99}
 99%|█████████▉| 10290/10395 [29:24:00<13:59,  8.00s/it] 99%|█████████▉| 10291/10395 [29:24:08<13:30,  7.79s/it]                                                        {'loss': 0.8654, 'learning_rate': 5.2495115192963135e-09, 'epoch': 0.99}
 99%|█████████▉| 10291/10395 [29:24:08<13:30,  7.79s/it] 99%|█████████▉| 10292/10395 [29:24:15<13:11,  7.69s/it]                                                        {'loss': 0.8789, 'learning_rate': 5.1490533442555276e-09, 'epoch': 0.99}
 99%|█████████▉| 10292/10395 [29:24:15<13:11,  7.69s/it] 99%|█████████▉| 10293/10395 [29:24:23<13:02,  7.67s/it]                                                        {'loss': 0.822, 'learning_rate': 5.049565447985405e-09, 'epoch': 0.99}
 99%|█████████▉| 10293/10395 [29:24:23<13:02,  7.67s/it] 99%|█████████▉| 10294/10395 [29:24:31<12:59,  7.72s/it]                                                        {'loss': 0.8752, 'learning_rate': 4.951047840143774e-09, 'epoch': 0.99}
 99%|█████████▉| 10294/10395 [29:24:31<12:59,  7.72s/it] 99%|█████████▉| 10295/10395 [29:24:39<13:15,  7.96s/it]                                                        {'loss': 0.8141, 'learning_rate': 4.8535005302952074e-09, 'epoch': 0.99}
 99%|█████████▉| 10295/10395 [29:24:39<13:15,  7.96s/it] 99%|█████████▉| 10296/10395 [29:24:47<13:03,  7.92s/it]                                                        {'loss': 0.9431, 'learning_rate': 4.756923527908796e-09, 'epoch': 0.99}
 99%|█████████▉| 10296/10395 [29:24:47<13:03,  7.92s/it] 99%|█████████▉| 10297/10395 [29:24:55<12:49,  7.85s/it]                                                        {'loss': 0.8737, 'learning_rate': 4.6613168423614854e-09, 'epoch': 0.99}
 99%|█████████▉| 10297/10395 [29:24:55<12:49,  7.85s/it] 99%|█████████▉| 10298/10395 [29:25:03<13:07,  8.12s/it]                                                        {'loss': 0.8066, 'learning_rate': 4.566680482932517e-09, 'epoch': 0.99}
 99%|█████████▉| 10298/10395 [29:25:03<13:07,  8.12s/it] 99%|█████████▉| 10299/10395 [29:25:11<12:34,  7.86s/it]                                                        {'loss': 0.8652, 'learning_rate': 4.473014458808988e-09, 'epoch': 0.99}
 99%|█████████▉| 10299/10395 [29:25:11<12:34,  7.86s/it] 99%|█████████▉| 10300/10395 [29:25:19<12:45,  8.06s/it]                                                        {'loss': 0.8256, 'learning_rate': 4.380318779085846e-09, 'epoch': 0.99}
 99%|█████████▉| 10300/10395 [29:25:19<12:45,  8.06s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 99%|█████████▉| 10301/10395 [29:27:02<57:02, 36.41s/it]                                                        {'loss': 0.8534, 'learning_rate': 4.288593452760337e-09, 'epoch': 0.99}
 99%|█████████▉| 10301/10395 [29:27:02<57:02, 36.41s/it] 99%|█████████▉| 10302/10395 [29:27:09<43:01, 27.76s/it]                                                        {'loss': 0.9218, 'learning_rate': 4.19783848873756e-09, 'epoch': 0.99}
 99%|█████████▉| 10302/10395 [29:27:09<43:01, 27.76s/it] 99%|█████████▉| 10303/10395 [29:27:17<33:13, 21.67s/it]                                                        {'loss': 0.9193, 'learning_rate': 4.108053895827135e-09, 'epoch': 0.99}
 99%|█████████▉| 10303/10395 [29:27:17<33:13, 21.67s/it] 99%|█████████▉| 10304/10395 [29:27:26<27:02, 17.83s/it]                                                        {'loss': 0.788, 'learning_rate': 4.019239682746534e-09, 'epoch': 0.99}
 99%|█████████▉| 10304/10395 [29:27:26<27:02, 17.83s/it] 99%|█████████▉| 10305/10395 [29:27:34<22:21, 14.91s/it]                                                        {'loss': 0.8552, 'learning_rate': 3.931395858115528e-09, 'epoch': 0.99}
 99%|█████████▉| 10305/10395 [29:27:34<22:21, 14.91s/it] 99%|█████████▉| 10306/10395 [29:27:41<18:53, 12.74s/it]                                                        {'loss': 0.8979, 'learning_rate': 3.844522430462849e-09, 'epoch': 0.99}
 99%|█████████▉| 10306/10395 [29:27:41<18:53, 12.74s/it] 99%|█████████▉| 10307/10395 [29:27:49<16:23, 11.17s/it]                                                        {'loss': 0.8185, 'learning_rate': 3.758619408222864e-09, 'epoch': 0.99}
 99%|█████████▉| 10307/10395 [29:27:49<16:23, 11.17s/it] 99%|█████████▉| 10308/10395 [29:27:58<15:04, 10.40s/it]                                                        {'loss': 0.7482, 'learning_rate': 3.673686799734455e-09, 'epoch': 0.99}
 99%|█████████▉| 10308/10395 [29:27:58<15:04, 10.40s/it] 99%|█████████▉| 10309/10395 [29:28:06<13:55,  9.72s/it]                                                        {'loss': 0.7994, 'learning_rate': 3.58972461324103e-09, 'epoch': 0.99}
 99%|█████████▉| 10309/10395 [29:28:06<13:55,  9.72s/it] 99%|█████████▉| 10310/10395 [29:28:14<13:18,  9.40s/it]                                                        {'loss': 0.8092, 'learning_rate': 3.5067328568949566e-09, 'epoch': 0.99}
 99%|█████████▉| 10310/10395 [29:28:14<13:18,  9.40s/it] 99%|█████████▉| 10311/10395 [29:28:22<12:31,  8.95s/it]                                                        {'loss': 0.8699, 'learning_rate': 3.4247115387531225e-09, 'epoch': 0.99}
 99%|█████████▉| 10311/10395 [29:28:22<12:31,  8.95s/it] 99%|█████████▉| 10312/10395 [29:28:31<12:06,  8.76s/it]                                                        {'loss': 0.825, 'learning_rate': 3.343660666778048e-09, 'epoch': 0.99}
 99%|█████████▉| 10312/10395 [29:28:31<12:06,  8.76s/it] 99%|█████████▉| 10313/10395 [29:28:39<11:48,  8.64s/it]                                                        {'loss': 0.7564, 'learning_rate': 3.263580248836773e-09, 'epoch': 0.99}
 99%|█████████▉| 10313/10395 [29:28:39<11:48,  8.64s/it] 99%|█████████▉| 10314/10395 [29:28:47<11:26,  8.47s/it]                                                        {'loss': 0.7515, 'learning_rate': 3.184470292704189e-09, 'epoch': 0.99}
 99%|█████████▉| 10314/10395 [29:28:47<11:26,  8.47s/it] 99%|█████████▉| 10315/10395 [29:28:55<10:56,  8.21s/it]                                                        {'loss': 0.8748, 'learning_rate': 3.10633080605971e-09, 'epoch': 0.99}
 99%|█████████▉| 10315/10395 [29:28:55<10:56,  8.21s/it] 99%|█████████▉| 10316/10395 [29:29:02<10:25,  7.92s/it]                                                        {'loss': 0.9333, 'learning_rate': 3.029161796489488e-09, 'epoch': 0.99}
 99%|█████████▉| 10316/10395 [29:29:02<10:25,  7.92s/it] 99%|█████████▉| 10317/10395 [29:29:10<10:12,  7.85s/it]                                                        {'loss': 0.8717, 'learning_rate': 2.9529632714841994e-09, 'epoch': 0.99}
 99%|█████████▉| 10317/10395 [29:29:10<10:12,  7.85s/it] 99%|█████████▉| 10318/10395 [29:29:17<09:58,  7.77s/it]                                                        {'loss': 0.8621, 'learning_rate': 2.8777352384423696e-09, 'epoch': 0.99}
 99%|█████████▉| 10318/10395 [29:29:17<09:58,  7.77s/it] 99%|█████████▉| 10319/10395 [29:29:24<09:40,  7.64s/it]                                                        {'loss': 0.83, 'learning_rate': 2.8034777046648255e-09, 'epoch': 0.99}
 99%|█████████▉| 10319/10395 [29:29:24<09:40,  7.64s/it] 99%|█████████▉| 10320/10395 [29:29:32<09:37,  7.70s/it]                                                        {'loss': 0.82, 'learning_rate': 2.7301906773624653e-09, 'epoch': 0.99}
 99%|█████████▉| 10320/10395 [29:29:32<09:37,  7.70s/it] 99%|█████████▉| 10321/10395 [29:29:42<10:11,  8.27s/it]                                                        {'loss': 0.8623, 'learning_rate': 2.6578741636484885e-09, 'epoch': 0.99}
 99%|█████████▉| 10321/10395 [29:29:42<10:11,  8.27s/it] 99%|█████████▉| 10322/10395 [29:29:51<10:13,  8.40s/it]                                                        {'loss': 0.8425, 'learning_rate': 2.586528170543945e-09, 'epoch': 0.99}
 99%|█████████▉| 10322/10395 [29:29:51<10:13,  8.40s/it] 99%|█████████▉| 10323/10395 [29:29:58<09:37,  8.02s/it]                                                        {'loss': 0.8598, 'learning_rate': 2.5161527049755165e-09, 'epoch': 0.99}
 99%|█████████▉| 10323/10395 [29:29:58<09:37,  8.02s/it] 99%|█████████▉| 10324/10395 [29:30:06<09:29,  8.02s/it]                                                        {'loss': 0.832, 'learning_rate': 2.4467477737732946e-09, 'epoch': 0.99}
 99%|█████████▉| 10324/10395 [29:30:06<09:29,  8.02s/it] 99%|█████████▉| 10325/10395 [29:30:13<09:01,  7.73s/it]                                                        {'loss': 0.7974, 'learning_rate': 2.378313383676334e-09, 'epoch': 0.99}
 99%|█████████▉| 10325/10395 [29:30:13<09:01,  7.73s/it] 99%|█████████▉| 10326/10395 [29:30:21<08:59,  7.82s/it]                                                        {'loss': 0.9497, 'learning_rate': 2.310849541327098e-09, 'epoch': 0.99}
 99%|█████████▉| 10326/10395 [29:30:21<08:59,  7.82s/it] 99%|█████████▉| 10327/10395 [29:30:28<08:45,  7.73s/it]                                                        {'loss': 0.7881, 'learning_rate': 2.244356253275903e-09, 'epoch': 0.99}
 99%|█████████▉| 10327/10395 [29:30:28<08:45,  7.73s/it] 99%|█████████▉| 10328/10395 [29:30:36<08:30,  7.62s/it]                                                        {'loss': 0.854, 'learning_rate': 2.178833525977586e-09, 'epoch': 0.99}
 99%|█████████▉| 10328/10395 [29:30:36<08:30,  7.62s/it] 99%|█████████▉| 10329/10395 [29:30:43<08:21,  7.61s/it]                                                        {'loss': 0.8919, 'learning_rate': 2.114281365792614e-09, 'epoch': 0.99}
 99%|█████████▉| 10329/10395 [29:30:43<08:21,  7.61s/it] 99%|█████████▉| 10330/10395 [29:30:52<08:33,  7.91s/it]                                                        {'loss': 0.8518, 'learning_rate': 2.0506997789870865e-09, 'epoch': 0.99}
 99%|█████████▉| 10330/10395 [29:30:52<08:33,  7.91s/it] 99%|█████████▉| 10331/10395 [29:31:00<08:29,  7.97s/it]                                                        {'loss': 0.7871, 'learning_rate': 1.9880887717338425e-09, 'epoch': 0.99}
 99%|█████████▉| 10331/10395 [29:31:00<08:29,  7.97s/it] 99%|█████████▉| 10332/10395 [29:31:08<08:14,  7.85s/it]                                                        {'loss': 0.8525, 'learning_rate': 1.9264483501124643e-09, 'epoch': 0.99}
 99%|█████████▉| 10332/10395 [29:31:08<08:14,  7.85s/it] 99%|█████████▉| 10333/10395 [29:31:15<08:03,  7.80s/it]                                                        {'loss': 0.781, 'learning_rate': 1.865778520104833e-09, 'epoch': 0.99}
 99%|█████████▉| 10333/10395 [29:31:15<08:03,  7.80s/it] 99%|█████████▉| 10334/10395 [29:31:23<07:46,  7.65s/it]                                                        {'loss': 0.8558, 'learning_rate': 1.8060792876006815e-09, 'epoch': 0.99}
 99%|█████████▉| 10334/10395 [29:31:23<07:46,  7.65s/it] 99%|█████████▉| 10335/10395 [29:31:30<07:30,  7.51s/it]                                                        {'loss': 0.8869, 'learning_rate': 1.747350658396485e-09, 'epoch': 0.99}
 99%|█████████▉| 10335/10395 [29:31:30<07:30,  7.51s/it] 99%|█████████▉| 10336/10395 [29:31:37<07:24,  7.53s/it]                                                        {'loss': 0.8068, 'learning_rate': 1.6895926381932381e-09, 'epoch': 0.99}
 99%|█████████▉| 10336/10395 [29:31:37<07:24,  7.53s/it] 99%|█████████▉| 10337/10395 [29:31:45<07:22,  7.62s/it]                                                        {'loss': 0.831, 'learning_rate': 1.6328052325975675e-09, 'epoch': 0.99}
 99%|█████████▉| 10337/10395 [29:31:45<07:22,  7.62s/it] 99%|█████████▉| 10338/10395 [29:32:02<09:47, 10.31s/it]                                                        {'loss': 0.3459, 'learning_rate': 1.5769884471239506e-09, 'epoch': 0.99}
 99%|█████████▉| 10338/10395 [29:32:02<09:47, 10.31s/it] 99%|█████████▉| 10339/10395 [29:32:09<08:53,  9.52s/it]                                                        {'loss': 0.8305, 'learning_rate': 1.5221422871880553e-09, 'epoch': 0.99}
 99%|█████████▉| 10339/10395 [29:32:09<08:53,  9.52s/it] 99%|█████████▉| 10340/10395 [29:32:17<08:13,  8.97s/it]                                                        {'loss': 0.8763, 'learning_rate': 1.468266758116732e-09, 'epoch': 0.99}
 99%|█████████▉| 10340/10395 [29:32:17<08:13,  8.97s/it] 99%|█████████▉| 10341/10395 [29:32:24<07:36,  8.45s/it]                                                        {'loss': 0.8773, 'learning_rate': 1.4153618651380208e-09, 'epoch': 0.99}
 99%|█████████▉| 10341/10395 [29:32:24<07:36,  8.45s/it] 99%|█████████▉| 10342/10395 [29:32:32<07:16,  8.23s/it]                                                        {'loss': 0.8154, 'learning_rate': 1.3634276133900337e-09, 'epoch': 0.99}
 99%|█████████▉| 10342/10395 [29:32:32<07:16,  8.23s/it] 99%|█████████▉| 10343/10395 [29:32:40<06:56,  8.00s/it]                                                        {'loss': 0.8838, 'learning_rate': 1.3124640079131835e-09, 'epoch': 0.99}
 99%|█████████▉| 10343/10395 [29:32:40<06:56,  8.00s/it]100%|█████████▉| 10344/10395 [29:32:48<06:51,  8.07s/it]                                                        {'loss': 0.9226, 'learning_rate': 1.2624710536546235e-09, 'epoch': 1.0}
100%|█████████▉| 10344/10395 [29:32:48<06:51,  8.07s/it]100%|█████████▉| 10345/10395 [29:32:55<06:37,  7.95s/it]                                                        {'loss': 0.9315, 'learning_rate': 1.2134487554682495e-09, 'epoch': 1.0}
100%|█████████▉| 10345/10395 [29:32:55<06:37,  7.95s/it]100%|█████████▉| 10346/10395 [29:33:03<06:25,  7.87s/it]                                                        {'loss': 0.8447, 'learning_rate': 1.1653971181124767e-09, 'epoch': 1.0}
100%|█████████▉| 10346/10395 [29:33:03<06:25,  7.87s/it]100%|█████████▉| 10347/10395 [29:33:11<06:19,  7.90s/it]                                                        {'loss': 0.872, 'learning_rate': 1.1183161462524627e-09, 'epoch': 1.0}
100%|█████████▉| 10347/10395 [29:33:11<06:19,  7.90s/it]100%|█████████▉| 10348/10395 [29:33:18<06:03,  7.74s/it]                                                        {'loss': 0.8532, 'learning_rate': 1.0722058444589955e-09, 'epoch': 1.0}
100%|█████████▉| 10348/10395 [29:33:18<06:03,  7.74s/it]100%|█████████▉| 10349/10395 [29:33:28<06:16,  8.19s/it]                                                        {'loss': 0.8422, 'learning_rate': 1.0270662172073842e-09, 'epoch': 1.0}
100%|█████████▉| 10349/10395 [29:33:28<06:16,  8.19s/it]100%|█████████▉| 10350/10395 [29:33:35<06:01,  8.04s/it]                                                        {'loss': 0.7898, 'learning_rate': 9.82897268880789e-10, 'epoch': 1.0}
100%|█████████▉| 10350/10395 [29:33:35<06:01,  8.04s/it]/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/akane38/miniconda3/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 10351/10395 [29:35:18<26:42, 36.42s/it]                                                        {'loss': 0.8845, 'learning_rate': 9.396990037668919e-10, 'epoch': 1.0}
100%|█████████▉| 10351/10395 [29:35:18<26:42, 36.42s/it]100%|█████████▉| 10352/10395 [29:35:26<19:53, 27.76s/it]                                                        {'loss': 0.8781, 'learning_rate': 8.974714260578943e-10, 'epoch': 1.0}
100%|█████████▉| 10352/10395 [29:35:26<19:53, 27.76s/it]100%|█████████▉| 10353/10395 [29:35:33<15:14, 21.78s/it]                                                        {'loss': 0.9211, 'learning_rate': 8.562145398549604e-10, 'epoch': 1.0}
100%|█████████▉| 10353/10395 [29:35:33<15:14, 21.78s/it]100%|█████████▉| 10354/10395 [29:35:41<11:56, 17.48s/it]                                                        {'loss': 0.7865, 'learning_rate': 8.159283491626646e-10, 'epoch': 1.0}
100%|█████████▉| 10354/10395 [29:35:41<11:56, 17.48s/it]100%|█████████▉| 10355/10395 [29:35:49<09:49, 14.75s/it]                                                        {'loss': 0.8401, 'learning_rate': 7.766128578912124e-10, 'epoch': 1.0}
100%|█████████▉| 10355/10395 [29:35:49<09:49, 14.75s/it]100%|█████████▉| 10356/10395 [29:35:58<08:19, 12.81s/it]                                                        {'loss': 0.8428, 'learning_rate': 7.382680698586608e-10, 'epoch': 1.0}
100%|█████████▉| 10356/10395 [29:35:58<08:19, 12.81s/it]100%|█████████▉| 10357/10395 [29:36:05<07:07, 11.26s/it]                                                        {'loss': 0.8222, 'learning_rate': 7.008939887853672e-10, 'epoch': 1.0}
100%|█████████▉| 10357/10395 [29:36:05<07:07, 11.26s/it]100%|█████████▉| 10358/10395 [29:36:22<08:00, 12.98s/it]                                                        {'loss': 0.3479, 'learning_rate': 6.644906183017608e-10, 'epoch': 1.0}
100%|█████████▉| 10358/10395 [29:36:22<08:00, 12.98s/it]100%|█████████▉| 10359/10395 [29:36:40<08:42, 14.52s/it]                                                        {'loss': 0.3656, 'learning_rate': 6.29057961939461e-10, 'epoch': 1.0}
100%|█████████▉| 10359/10395 [29:36:40<08:42, 14.52s/it]100%|█████████▉| 10360/10395 [29:36:47<07:10, 12.31s/it]                                                        {'loss': 0.8193, 'learning_rate': 5.945960231401593e-10, 'epoch': 1.0}
100%|█████████▉| 10360/10395 [29:36:47<07:10, 12.31s/it]100%|█████████▉| 10361/10395 [29:36:55<06:12, 10.94s/it]                                                        {'loss': 0.9338, 'learning_rate': 5.611048052489576e-10, 'epoch': 1.0}
100%|█████████▉| 10361/10395 [29:36:55<06:12, 10.94s/it]100%|█████████▉| 10362/10395 [29:37:03<05:27,  9.93s/it]                                                        {'loss': 0.8405, 'learning_rate': 5.285843115165889e-10, 'epoch': 1.0}
100%|█████████▉| 10362/10395 [29:37:03<05:27,  9.93s/it]100%|█████████▉| 10363/10395 [29:37:11<05:01,  9.42s/it]                                                        {'loss': 0.7854, 'learning_rate': 4.970345451005276e-10, 'epoch': 1.0}
100%|█████████▉| 10363/10395 [29:37:11<05:01,  9.42s/it]100%|█████████▉| 10364/10395 [29:37:19<04:42,  9.10s/it]                                                        {'loss': 0.8611, 'learning_rate': 4.664555090627687e-10, 'epoch': 1.0}
100%|█████████▉| 10364/10395 [29:37:19<04:42,  9.10s/it]100%|█████████▉| 10365/10395 [29:37:27<04:22,  8.75s/it]                                                        {'loss': 0.8173, 'learning_rate': 4.368472063731588e-10, 'epoch': 1.0}
100%|█████████▉| 10365/10395 [29:37:27<04:22,  8.75s/it]100%|█████████▉| 10366/10395 [29:37:35<04:03,  8.41s/it]                                                        {'loss': 0.7921, 'learning_rate': 4.082096399049551e-10, 'epoch': 1.0}
100%|█████████▉| 10366/10395 [29:37:35<04:03,  8.41s/it]100%|█████████▉| 10367/10395 [29:37:44<03:59,  8.56s/it]                                                        {'loss': 0.8007, 'learning_rate': 3.80542812438156e-10, 'epoch': 1.0}
100%|█████████▉| 10367/10395 [29:37:44<03:59,  8.56s/it]100%|█████████▉| 10368/10395 [29:37:52<03:44,  8.33s/it]                                                        {'loss': 0.9001, 'learning_rate': 3.538467266595014e-10, 'epoch': 1.0}
100%|█████████▉| 10368/10395 [29:37:52<03:44,  8.33s/it]100%|█████████▉| 10369/10395 [29:38:00<03:37,  8.35s/it]                                                        {'loss': 0.8469, 'learning_rate': 3.281213851602516e-10, 'epoch': 1.0}
100%|█████████▉| 10369/10395 [29:38:00<03:37,  8.35s/it]100%|█████████▉| 10370/10395 [29:38:08<03:26,  8.27s/it]                                                        {'loss': 0.8452, 'learning_rate': 3.033667904372983e-10, 'epoch': 1.0}
100%|█████████▉| 10370/10395 [29:38:08<03:26,  8.27s/it]100%|█████████▉| 10371/10395 [29:38:15<03:09,  7.92s/it]                                                        {'loss': 0.9389, 'learning_rate': 2.795829448942744e-10, 'epoch': 1.0}
100%|█████████▉| 10371/10395 [29:38:15<03:09,  7.92s/it]100%|█████████▉| 10372/10395 [29:38:24<03:10,  8.29s/it]                                                        {'loss': 0.8345, 'learning_rate': 2.567698508393335e-10, 'epoch': 1.0}
100%|█████████▉| 10372/10395 [29:38:24<03:10,  8.29s/it]100%|█████████▉| 10373/10395 [29:38:32<02:57,  8.06s/it]                                                        {'loss': 0.8601, 'learning_rate': 2.349275104884807e-10, 'epoch': 1.0}
100%|█████████▉| 10373/10395 [29:38:32<02:57,  8.06s/it]100%|█████████▉| 10374/10395 [29:38:41<02:53,  8.24s/it]                                                        {'loss': 0.8115, 'learning_rate': 2.140559259611319e-10, 'epoch': 1.0}
100%|█████████▉| 10374/10395 [29:38:41<02:53,  8.24s/it]100%|█████████▉| 10375/10395 [29:38:49<02:48,  8.41s/it]                                                        {'loss': 0.8434, 'learning_rate': 1.94155099283444e-10, 'epoch': 1.0}
100%|█████████▉| 10375/10395 [29:38:49<02:48,  8.41s/it]100%|█████████▉| 10376/10395 [29:38:57<02:34,  8.14s/it]                                                        {'loss': 0.8586, 'learning_rate': 1.752250323872051e-10, 'epoch': 1.0}
100%|█████████▉| 10376/10395 [29:38:57<02:34,  8.14s/it]100%|█████████▉| 10377/10395 [29:39:05<02:26,  8.12s/it]                                                        {'loss': 0.8515, 'learning_rate': 1.5726572710983435e-10, 'epoch': 1.0}
100%|█████████▉| 10377/10395 [29:39:05<02:26,  8.12s/it]100%|█████████▉| 10378/10395 [29:39:13<02:18,  8.14s/it]                                                        {'loss': 0.8785, 'learning_rate': 1.4027718519660227e-10, 'epoch': 1.0}
100%|█████████▉| 10378/10395 [29:39:13<02:18,  8.14s/it]100%|█████████▉| 10379/10395 [29:39:21<02:08,  8.05s/it]                                                        {'loss': 0.8402, 'learning_rate': 1.2425940829507987e-10, 'epoch': 1.0}
100%|█████████▉| 10379/10395 [29:39:21<02:08,  8.05s/it]100%|█████████▉| 10380/10395 [29:39:29<01:59,  7.99s/it]                                                        {'loss': 0.7976, 'learning_rate': 1.092123979606896e-10, 'epoch': 1.0}
100%|█████████▉| 10380/10395 [29:39:29<01:59,  7.99s/it]100%|█████████▉| 10381/10395 [29:39:36<01:47,  7.71s/it]                                                        {'loss': 0.9062, 'learning_rate': 9.513615565448498e-11, 'epoch': 1.0}
100%|█████████▉| 10381/10395 [29:39:36<01:47,  7.71s/it]100%|█████████▉| 10382/10395 [29:39:44<01:41,  7.83s/it]                                                        {'loss': 0.8083, 'learning_rate': 8.203068274204029e-11, 'epoch': 1.0}
100%|█████████▉| 10382/10395 [29:39:44<01:41,  7.83s/it]100%|█████████▉| 10383/10395 [29:39:51<01:32,  7.72s/it]                                                        {'loss': 0.8543, 'learning_rate': 6.989598049567115e-11, 'epoch': 1.0}
100%|█████████▉| 10383/10395 [29:39:51<01:32,  7.72s/it]100%|█████████▉| 10384/10395 [29:39:59<01:23,  7.57s/it]                                                        {'loss': 0.8665, 'learning_rate': 5.873205009443438e-11, 'epoch': 1.0}
100%|█████████▉| 10384/10395 [29:39:59<01:23,  7.57s/it]100%|█████████▉| 10385/10395 [29:40:07<01:16,  7.68s/it]                                                        {'loss': 0.8433, 'learning_rate': 4.85388926219077e-11, 'epoch': 1.0}
100%|█████████▉| 10385/10395 [29:40:07<01:16,  7.68s/it]100%|█████████▉| 10386/10395 [29:40:14<01:08,  7.59s/it]                                                        {'loss': 0.8782, 'learning_rate': 3.931650906729978e-11, 'epoch': 1.0}
100%|█████████▉| 10386/10395 [29:40:14<01:08,  7.59s/it]100%|█████████▉| 10387/10395 [29:40:22<01:01,  7.75s/it]                                                        {'loss': 0.7734, 'learning_rate': 3.10649003254504e-11, 'epoch': 1.0}
100%|█████████▉| 10387/10395 [29:40:22<01:01,  7.75s/it]100%|█████████▉| 10388/10395 [29:40:30<00:53,  7.71s/it]                                                        {'loss': 0.8301, 'learning_rate': 2.3784067197940575e-11, 'epoch': 1.0}
100%|█████████▉| 10388/10395 [29:40:30<00:53,  7.71s/it]100%|█████████▉| 10389/10395 [29:40:38<00:46,  7.74s/it]                                                        {'loss': 0.8897, 'learning_rate': 1.7474010390872153e-11, 'epoch': 1.0}
100%|█████████▉| 10389/10395 [29:40:38<00:46,  7.74s/it]100%|█████████▉| 10390/10395 [29:40:45<00:38,  7.61s/it]                                                        {'loss': 0.9437, 'learning_rate': 1.2134730518198468e-11, 'epoch': 1.0}
100%|█████████▉| 10390/10395 [29:40:45<00:38,  7.61s/it]100%|█████████▉| 10391/10395 [29:40:53<00:31,  7.88s/it]                                                        {'loss': 0.8409, 'learning_rate': 7.766228097283447e-12, 'epoch': 1.0}
100%|█████████▉| 10391/10395 [29:40:53<00:31,  7.88s/it]100%|█████████▉| 10392/10395 [29:41:01<00:23,  7.88s/it]                                                        {'loss': 0.8166, 'learning_rate': 4.368503552232284e-12, 'epoch': 1.0}
100%|█████████▉| 10392/10395 [29:41:01<00:23,  7.88s/it]100%|█████████▉| 10393/10395 [29:41:09<00:15,  7.76s/it]                                                        {'loss': 0.8849, 'learning_rate': 1.94155721278122e-12, 'epoch': 1.0}
100%|█████████▉| 10393/10395 [29:41:09<00:15,  7.76s/it]100%|█████████▉| 10394/10395 [29:41:16<00:07,  7.68s/it]                                                        {'loss': 0.8797, 'learning_rate': 4.853893154077583e-13, 'epoch': 1.0}
100%|█████████▉| 10394/10395 [29:41:16<00:07,  7.68s/it]100%|██████████| 10395/10395 [29:41:28<00:00,  9.05s/it]                                                        {'loss': 0.5261, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 10395/10395 [29:41:28<00:00,  9.05s/it]                                                        {'train_runtime': 106892.8306, 'train_samples_per_second': 6.224, 'train_steps_per_second': 0.097, 'train_loss': 0.8889569774248556, 'epoch': 1.0}
100%|██████████| 10395/10395 [29:41:29<00:00,  9.05s/it]100%|██████████| 10395/10395 [29:41:29<00:00, 10.28s/it]
[2024-04-02 08:35:36,879] [INFO] [launch.py:347:main] Process 320557 exits successfully.
wandb: - 1.291 MB of 1.291 MB uploadedwandb: \ 1.291 MB of 1.291 MB uploadedwandb: | 1.291 MB of 1.291 MB uploadedwandb: / 1.291 MB of 1.291 MB uploadedwandb: - 2.579 MB of 10.955 MB uploaded (0.002 MB deduped)wandb: \ 2.581 MB of 10.955 MB uploaded (0.002 MB deduped)wandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄███████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:                     train/loss █▇▇▇▁▇▇▆▆▇▇▇▁▇▆▇▇▇▆▆▆▆▅▆▆▅▁▆▇▅▆▇▅▆▆▆▅▆▅▆
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 1.0
wandb:              train/global_step 10395
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.5261
wandb:               train/total_flos 4922406243336192.0
wandb:               train/train_loss 0.88896
wandb:            train/train_runtime 106892.8306
wandb: train/train_samples_per_second 6.224
wandb:   train/train_steps_per_second 0.097
wandb: 
wandb: 🚀 View run multi-ve-shared-resampler-clip-dino-llava-pretrained-7b-it at: https://wandb.ai/compyle/multi-ve-llava/runs/j0ubrpag
wandb: ️⚡ View job at https://wandb.ai/compyle/multi-ve-llava/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1NDcyNDExNg==/version_details/v2
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20240401_025352-j0ubrpag/logs
[2024-04-02 08:36:06,914] [INFO] [launch.py:347:main] Process 320556 exits successfully.
